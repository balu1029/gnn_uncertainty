wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_164817-o6zb4v2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/o6zb4v2r
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
53
Uncertainty Slope: 0.656940221786499, Uncertainty Bias: 0.026700302958488464
0.00043201447 0.0067358017
0.44074464 2.8812816

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.429311359614543, Test Loss Force: 10.722413107421158, time: 14.379531145095825

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.42931
wandb:   test_error_force 10.72241
wandb:          test_loss 6.04466
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_54 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/o6zb4v2r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_164817-o6zb4v2r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 51 steps.
Found uncertainty sample 1 after 3026 steps.
Found uncertainty sample 2 after 123 steps.
Found uncertainty sample 3 after 1660 steps.
Found uncertainty sample 4 after 66 steps.
Found uncertainty sample 5 after 92 steps.
Found uncertainty sample 6 after 574 steps.
Found uncertainty sample 7 after 891 steps.
Found uncertainty sample 8 after 84 steps.
Found uncertainty sample 9 after 552 steps.
Found uncertainty sample 10 after 345 steps.
Found uncertainty sample 11 after 496 steps.
Found uncertainty sample 12 after 1670 steps.
Found uncertainty sample 13 after 1827 steps.
Found uncertainty sample 14 after 1709 steps.
Found uncertainty sample 15 after 605 steps.
Found uncertainty sample 16 after 329 steps.
Found uncertainty sample 17 after 2196 steps.
Found uncertainty sample 18 after 352 steps.
Found uncertainty sample 19 after 565 steps.
Found uncertainty sample 20 after 954 steps.
Found uncertainty sample 21 after 2311 steps.
Found uncertainty sample 22 after 112 steps.
Found uncertainty sample 23 after 2667 steps.
Found uncertainty sample 24 after 1166 steps.
Found uncertainty sample 25 after 913 steps.
Found uncertainty sample 26 after 167 steps.
Found uncertainty sample 28 after 169 steps.
Found uncertainty sample 29 after 78 steps.
Found uncertainty sample 30 after 726 steps.
Found uncertainty sample 31 after 244 steps.
Found uncertainty sample 32 after 577 steps.
Found uncertainty sample 34 after 943 steps.
Found uncertainty sample 35 after 2188 steps.
Found uncertainty sample 36 after 141 steps.
Found uncertainty sample 37 after 1387 steps.
Found uncertainty sample 38 after 1296 steps.
Found uncertainty sample 39 after 98 steps.
Found uncertainty sample 40 after 893 steps.
Found uncertainty sample 42 after 148 steps.
Found uncertainty sample 43 after 25 steps.
Found uncertainty sample 44 after 72 steps.
Found uncertainty sample 45 after 109 steps.
Found uncertainty sample 46 after 1325 steps.
Found uncertainty sample 47 after 430 steps.
Found uncertainty sample 48 after 1703 steps.
Found uncertainty sample 49 after 926 steps.
Found uncertainty sample 50 after 822 steps.
Found uncertainty sample 51 after 354 steps.
Found uncertainty sample 52 after 270 steps.
Found uncertainty sample 53 after 1168 steps.
Found uncertainty sample 54 after 1069 steps.
Found uncertainty sample 55 after 1209 steps.
Found uncertainty sample 56 after 719 steps.
Found uncertainty sample 57 after 1538 steps.
Found uncertainty sample 58 after 1119 steps.
Found uncertainty sample 59 after 22 steps.
Found uncertainty sample 60 after 349 steps.
Found uncertainty sample 61 after 2088 steps.
Found uncertainty sample 62 after 1854 steps.
Found uncertainty sample 63 after 1194 steps.
Found uncertainty sample 64 after 84 steps.
Found uncertainty sample 65 after 1696 steps.
Found uncertainty sample 66 after 376 steps.
Found uncertainty sample 67 after 389 steps.
Found uncertainty sample 68 after 1914 steps.
Found uncertainty sample 69 after 238 steps.
Found uncertainty sample 70 after 295 steps.
Found uncertainty sample 71 after 1120 steps.
Found uncertainty sample 72 after 3557 steps.
Found uncertainty sample 73 after 236 steps.
Found uncertainty sample 74 after 40 steps.
Found uncertainty sample 75 after 1385 steps.
Found uncertainty sample 76 after 96 steps.
Found uncertainty sample 78 after 1223 steps.
Found uncertainty sample 79 after 178 steps.
Found uncertainty sample 80 after 654 steps.
Found uncertainty sample 81 after 37 steps.
Found uncertainty sample 82 after 135 steps.
Found uncertainty sample 83 after 1537 steps.
Found uncertainty sample 84 after 3427 steps.
Found uncertainty sample 85 after 2044 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 3056 steps.
Found uncertainty sample 88 after 252 steps.
Found uncertainty sample 89 after 1166 steps.
Found uncertainty sample 90 after 966 steps.
Found uncertainty sample 91 after 69 steps.
Found uncertainty sample 92 after 754 steps.
Found uncertainty sample 93 after 886 steps.
Found uncertainty sample 94 after 3618 steps.
Found uncertainty sample 95 after 962 steps.
Found uncertainty sample 96 after 507 steps.
Found uncertainty sample 97 after 2505 steps.
Found uncertainty sample 98 after 510 steps.
Found uncertainty sample 99 after 1286 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_173939-4qg5vjla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4qg5vjla
Training model 0. Added 97 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.398040150484708, Training Loss Force: 2.8425115635165494, time: 1.4630801677703857
Validation Loss Energy: 3.040312494364135, Validation Loss Force: 2.7051215035863665, time: 0.0705251693725586
Test Loss Energy: 13.809658888039616, Test Loss Force: 10.628181973059318, time: 16.02381730079651


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4837498656802828, Training Loss Force: 2.571433540876378, time: 1.014392614364624
Validation Loss Energy: 2.2360186244625018, Validation Loss Force: 2.6171729803426844, time: 0.07576155662536621
Test Loss Energy: 13.247293946998285, Test Loss Force: 10.54189944637578, time: 16.17492651939392


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5285866660606353, Training Loss Force: 2.4839757963352604, time: 1.0036425590515137
Validation Loss Energy: 1.308595619606325, Validation Loss Force: 2.6475731081596217, time: 0.06979775428771973
Test Loss Energy: 12.655022613745613, Test Loss Force: 10.559410535059483, time: 16.071573734283447


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4538154225484103, Training Loss Force: 2.4474089419514873, time: 1.0445857048034668
Validation Loss Energy: 1.0449353106046908, Validation Loss Force: 2.6089567115270946, time: 0.06834554672241211
Test Loss Energy: 11.996683474941657, Test Loss Force: 10.635927879534792, time: 16.24818730354309


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5072405380892029, Training Loss Force: 2.4451217719616816, time: 1.0302836894989014
Validation Loss Energy: 1.0875635372393984, Validation Loss Force: 2.5975299989655185, time: 0.0674440860748291
Test Loss Energy: 12.249924516365034, Test Loss Force: 10.549320302530488, time: 16.178027868270874


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.1188902708972361, Training Loss Force: 2.4423355447485653, time: 1.0526907444000244
Validation Loss Energy: 1.0711966870062684, Validation Loss Force: 2.596649119824228, time: 0.06975913047790527
Test Loss Energy: 11.981550884447635, Test Loss Force: 10.604864960100798, time: 16.315869092941284


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.282773990910547, Training Loss Force: 2.451026520325864, time: 1.0096449851989746
Validation Loss Energy: 1.9624023326081441, Validation Loss Force: 2.598003838908053, time: 0.07105231285095215
Test Loss Energy: 11.566859370205876, Test Loss Force: 10.755588599794239, time: 16.660380601882935


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.674739961682206, Training Loss Force: 2.4541234902845916, time: 1.0129811763763428
Validation Loss Energy: 1.3069820476403595, Validation Loss Force: 2.6156911171765347, time: 0.07026052474975586
Test Loss Energy: 11.871837426804204, Test Loss Force: 10.57503767489242, time: 16.292255401611328


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4573229427211778, Training Loss Force: 2.444200653324734, time: 1.0242033004760742
Validation Loss Energy: 1.373887334582709, Validation Loss Force: 2.590652639724393, time: 0.07527852058410645
Test Loss Energy: 11.69477215305467, Test Loss Force: 10.593410728663883, time: 16.385199546813965


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.311460373479494, Training Loss Force: 2.4202156633643237, time: 0.9866032600402832
Validation Loss Energy: 1.3008800223653543, Validation Loss Force: 2.5931084577348305, time: 0.06942391395568848
Test Loss Energy: 12.519767960501145, Test Loss Force: 10.523165850453813, time: 16.344120025634766


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2229342086970447, Training Loss Force: 2.421245969407471, time: 1.031078815460205
Validation Loss Energy: 1.366872031805681, Validation Loss Force: 2.5916397320482907, time: 0.06903910636901855
Test Loss Energy: 11.550709804255924, Test Loss Force: 10.561229996127649, time: 16.401817083358765


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.1304263100332281, Training Loss Force: 2.4290468091689843, time: 1.0208089351654053
Validation Loss Energy: 1.1740075963986194, Validation Loss Force: 2.6036382589766096, time: 0.07196593284606934
Test Loss Energy: 12.20035371524301, Test Loss Force: 10.597882368120791, time: 16.31545352935791


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4535825106217697, Training Loss Force: 2.421479501626732, time: 1.043403148651123
Validation Loss Energy: 1.24516174464899, Validation Loss Force: 2.599323153597675, time: 0.07067298889160156
Test Loss Energy: 12.306809264472353, Test Loss Force: 10.542842225208025, time: 16.479345560073853


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4052023224430987, Training Loss Force: 2.4474968962641284, time: 1.0060338973999023
Validation Loss Energy: 1.270542130574704, Validation Loss Force: 2.601282419412694, time: 0.0749814510345459
Test Loss Energy: 12.349279414666368, Test Loss Force: 10.64958512722148, time: 16.44439959526062


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2289015688416982, Training Loss Force: 2.414703297797613, time: 0.994422435760498
Validation Loss Energy: 1.412110497503527, Validation Loss Force: 2.6003483223455266, time: 0.07099080085754395
Test Loss Energy: 12.522229949128285, Test Loss Force: 10.568309606570086, time: 16.32401180267334


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.232367948901638, Training Loss Force: 2.413952012099253, time: 1.0316886901855469
Validation Loss Energy: 1.309197271638622, Validation Loss Force: 2.5970151879001335, time: 0.0701451301574707
Test Loss Energy: 12.430184371889881, Test Loss Force: 10.423940459325694, time: 16.483354806900024


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3611593375679785, Training Loss Force: 2.41648506449345, time: 1.0612587928771973
Validation Loss Energy: 1.8207389972885828, Validation Loss Force: 2.6166917923183344, time: 0.06976485252380371
Test Loss Energy: 11.477544943125567, Test Loss Force: 10.533396917137289, time: 16.35588788986206


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4685973714562304, Training Loss Force: 2.419803884493748, time: 1.0344007015228271
Validation Loss Energy: 1.2025953087022774, Validation Loss Force: 2.596964864673154, time: 0.07097196578979492
Test Loss Energy: 11.653069276436856, Test Loss Force: 10.5724724050874, time: 16.39951753616333


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.176615394053622, Training Loss Force: 2.3991348436921465, time: 1.013871192932129
Validation Loss Energy: 1.1829578940537597, Validation Loss Force: 2.5723525759663177, time: 0.07267570495605469
Test Loss Energy: 12.28791106592184, Test Loss Force: 10.516175676064776, time: 16.343303680419922


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5527784778833824, Training Loss Force: 2.4082905536344055, time: 1.0739648342132568
Validation Loss Energy: 1.4271906540769135, Validation Loss Force: 2.5943418221341243, time: 0.09281778335571289
Test Loss Energy: 11.649854969206316, Test Loss Force: 10.525571358061148, time: 16.773595809936523

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–…â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–„â–â–ƒâ–ƒâ–„â–„â–„â–â–‚â–ƒâ–‚
wandb:   test_error_force â–…â–ƒâ–„â–…â–„â–…â–ˆâ–„â–…â–ƒâ–„â–…â–„â–†â–„â–â–ƒâ–„â–ƒâ–ƒ
wandb:          test_loss â–ˆâ–†â–„â–„â–ƒâ–„â–‡â–„â–‚â–ƒâ–‚â–„â–ƒâ–†â–ƒâ–â–â–‚â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–‚â–â–â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–‚â–â–â–â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–„â–‚â–â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–…â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚
wandb:         valid_loss â–ˆâ–„â–ƒâ–‚â–‚â–â–†â–ƒâ–â–â–‚â–‚â–‚â–…â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 887
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.64985
wandb:   test_error_force 10.52557
wandb:          test_loss 5.89859
wandb: train_error_energy 1.55278
wandb:  train_error_force 2.40829
wandb:         train_loss 1.09288
wandb: valid_error_energy 1.42719
wandb:  valid_error_force 2.59434
wandb:         valid_loss 1.30955
wandb: 
wandb: ğŸš€ View run al_54_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4qg5vjla
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_173939-4qg5vjla/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6442999243736267, Uncertainty Bias: 0.032323211431503296
0.00011062622 0.0086193085
0.725349 3.8230662
Found uncertainty sample 0 after 1603 steps.
Found uncertainty sample 1 after 2060 steps.
Found uncertainty sample 2 after 552 steps.
Found uncertainty sample 3 after 327 steps.
Found uncertainty sample 4 after 122 steps.
Found uncertainty sample 5 after 3 steps.
Found uncertainty sample 6 after 235 steps.
Found uncertainty sample 7 after 1570 steps.
Found uncertainty sample 8 after 2742 steps.
Found uncertainty sample 9 after 321 steps.
Found uncertainty sample 10 after 287 steps.
Found uncertainty sample 12 after 45 steps.
Found uncertainty sample 13 after 826 steps.
Found uncertainty sample 14 after 447 steps.
Found uncertainty sample 15 after 1598 steps.
Found uncertainty sample 16 after 381 steps.
Found uncertainty sample 17 after 1204 steps.
Found uncertainty sample 18 after 390 steps.
Found uncertainty sample 19 after 3882 steps.
Found uncertainty sample 20 after 2596 steps.
Found uncertainty sample 22 after 33 steps.
Found uncertainty sample 23 after 1969 steps.
Found uncertainty sample 24 after 425 steps.
Found uncertainty sample 25 after 217 steps.
Found uncertainty sample 26 after 686 steps.
Found uncertainty sample 27 after 2150 steps.
Found uncertainty sample 28 after 2093 steps.
Found uncertainty sample 29 after 1524 steps.
Found uncertainty sample 30 after 928 steps.
Found uncertainty sample 31 after 3099 steps.
Found uncertainty sample 32 after 98 steps.
Found uncertainty sample 34 after 610 steps.
Found uncertainty sample 35 after 493 steps.
Found uncertainty sample 36 after 560 steps.
Found uncertainty sample 37 after 746 steps.
Found uncertainty sample 38 after 1537 steps.
Found uncertainty sample 39 after 881 steps.
Found uncertainty sample 40 after 220 steps.
Found uncertainty sample 41 after 241 steps.
Found uncertainty sample 42 after 612 steps.
Found uncertainty sample 43 after 241 steps.
Found uncertainty sample 45 after 149 steps.
Found uncertainty sample 46 after 69 steps.
Found uncertainty sample 47 after 183 steps.
Found uncertainty sample 49 after 1091 steps.
Found uncertainty sample 50 after 372 steps.
Found uncertainty sample 51 after 1017 steps.
Found uncertainty sample 53 after 287 steps.
Found uncertainty sample 54 after 2113 steps.
Found uncertainty sample 55 after 29 steps.
Found uncertainty sample 57 after 3456 steps.
Found uncertainty sample 58 after 3376 steps.
Found uncertainty sample 59 after 3 steps.
Found uncertainty sample 60 after 559 steps.
Found uncertainty sample 61 after 323 steps.
Found uncertainty sample 63 after 6 steps.
Found uncertainty sample 64 after 58 steps.
Found uncertainty sample 65 after 114 steps.
Found uncertainty sample 66 after 2369 steps.
Found uncertainty sample 67 after 96 steps.
Found uncertainty sample 68 after 3244 steps.
Found uncertainty sample 69 after 424 steps.
Found uncertainty sample 70 after 1212 steps.
Found uncertainty sample 71 after 1311 steps.
Found uncertainty sample 72 after 1943 steps.
Found uncertainty sample 73 after 2814 steps.
Found uncertainty sample 74 after 174 steps.
Found uncertainty sample 75 after 802 steps.
Found uncertainty sample 76 after 1175 steps.
Found uncertainty sample 77 after 2234 steps.
Found uncertainty sample 78 after 520 steps.
Found uncertainty sample 80 after 881 steps.
Found uncertainty sample 81 after 16 steps.
Found uncertainty sample 82 after 2525 steps.
Found uncertainty sample 84 after 1436 steps.
Found uncertainty sample 85 after 355 steps.
Found uncertainty sample 86 after 2046 steps.
Found uncertainty sample 88 after 382 steps.
Found uncertainty sample 89 after 155 steps.
Found uncertainty sample 90 after 612 steps.
Found uncertainty sample 91 after 2154 steps.
Found uncertainty sample 93 after 2080 steps.
Found uncertainty sample 94 after 114 steps.
Found uncertainty sample 95 after 2977 steps.
Found uncertainty sample 96 after 3643 steps.
Found uncertainty sample 97 after 225 steps.
Found uncertainty sample 98 after 1816 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_185442-xo62iwz4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xo62iwz4
Training model 1. Added 87 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8152565344872325, Training Loss Force: 2.9296422440228036, time: 1.1405251026153564
Validation Loss Energy: 1.1947746116244287, Validation Loss Force: 2.6815292622370253, time: 0.0744321346282959
Test Loss Energy: 11.736750757028718, Test Loss Force: 10.53348016508688, time: 16.682075023651123


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4673414027395852, Training Loss Force: 2.6224654667976046, time: 1.148449182510376
Validation Loss Energy: 1.0973094317529388, Validation Loss Force: 2.6297758313330513, time: 0.08064651489257812
Test Loss Energy: 11.75860180959501, Test Loss Force: 10.498004880489463, time: 16.6914484500885


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.253958183311451, Training Loss Force: 2.5752644491191186, time: 1.1523125171661377
Validation Loss Energy: 1.073380291985809, Validation Loss Force: 2.613152911582104, time: 0.0827338695526123
Test Loss Energy: 11.96590407978143, Test Loss Force: 10.488241936630766, time: 16.628888845443726


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2897083737190007, Training Loss Force: 2.551789080339886, time: 1.1723284721374512
Validation Loss Energy: 1.06564109181537, Validation Loss Force: 2.6270588224144404, time: 0.07572436332702637
Test Loss Energy: 12.094143302592999, Test Loss Force: 10.53312285455351, time: 16.7935791015625


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2581714409004698, Training Loss Force: 2.5382419325988943, time: 1.1584477424621582
Validation Loss Energy: 3.131533140707226, Validation Loss Force: 2.6312735040085613, time: 0.08206725120544434
Test Loss Energy: 13.781096442854986, Test Loss Force: 10.430223678995132, time: 16.779395818710327


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7043301949343133, Training Loss Force: 2.557230338515789, time: 1.1641311645507812
Validation Loss Energy: 1.530762646610046, Validation Loss Force: 2.624833466970038, time: 0.08032464981079102
Test Loss Energy: 11.49928045022384, Test Loss Force: 10.605407703903023, time: 16.71255397796631


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5010492986764687, Training Loss Force: 2.5473812296702354, time: 1.1217811107635498
Validation Loss Energy: 1.0691390014287496, Validation Loss Force: 2.6226234756967046, time: 0.07762718200683594
Test Loss Energy: 12.039072027968855, Test Loss Force: 10.481259386619813, time: 17.122309684753418


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4097772624493605, Training Loss Force: 2.5331310938869214, time: 1.1449062824249268
Validation Loss Energy: 1.2517680042049486, Validation Loss Force: 2.635317398367756, time: 0.07792282104492188
Test Loss Energy: 12.355129457743057, Test Loss Force: 10.453005856986428, time: 16.796706914901733


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8421190673618233, Training Loss Force: 2.5906704819875697, time: 1.1471538543701172
Validation Loss Energy: 1.043827865607419, Validation Loss Force: 2.62306992733429, time: 0.07533097267150879
Test Loss Energy: 11.997693357627513, Test Loss Force: 10.454508004029385, time: 16.76736879348755


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2425914926547348, Training Loss Force: 2.550870878976588, time: 1.1468801498413086
Validation Loss Energy: 1.1594072918347074, Validation Loss Force: 2.6374710543471696, time: 0.07954216003417969
Test Loss Energy: 12.06020588070322, Test Loss Force: 10.42226561895329, time: 16.702155351638794


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.278227430446077, Training Loss Force: 2.542295531023125, time: 1.3530614376068115
Validation Loss Energy: 1.276441304257769, Validation Loss Force: 2.6154236915322757, time: 0.07783150672912598
Test Loss Energy: 12.274286638035138, Test Loss Force: 10.402855640435714, time: 16.691242456436157


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3038496745700854, Training Loss Force: 2.5893307391995273, time: 1.1573035717010498
Validation Loss Energy: 1.0507395158970176, Validation Loss Force: 2.6133268161850736, time: 0.08488726615905762
Test Loss Energy: 11.789630356374039, Test Loss Force: 10.351562587900306, time: 16.801819562911987


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3029404230698782, Training Loss Force: 2.552214866844154, time: 1.185816764831543
Validation Loss Energy: 1.0411043992835762, Validation Loss Force: 2.595195312970466, time: 0.0783226490020752
Test Loss Energy: 11.929736524969975, Test Loss Force: 10.389116226668373, time: 16.74383568763733


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4890018276333004, Training Loss Force: 2.540444173549374, time: 1.1853253841400146
Validation Loss Energy: 2.3413213129323576, Validation Loss Force: 2.626819230413422, time: 0.07349514961242676
Test Loss Energy: 11.325749339189414, Test Loss Force: 10.495082365436266, time: 16.788803100585938


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7876890348063486, Training Loss Force: 2.5706813506487456, time: 1.1720268726348877
Validation Loss Energy: 2.5736667692655835, Validation Loss Force: 2.6454866982622782, time: 0.07604265213012695
Test Loss Energy: 13.433157566529582, Test Loss Force: 10.400320891459176, time: 17.07433247566223


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8585355566530246, Training Loss Force: 2.5741142624201414, time: 1.1660375595092773
Validation Loss Energy: 1.050907631102193, Validation Loss Force: 2.619193480172833, time: 0.07592940330505371
Test Loss Energy: 12.013987600231966, Test Loss Force: 10.451956593338538, time: 16.793797731399536


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.190899173657004, Training Loss Force: 2.546169191228821, time: 1.1780328750610352
Validation Loss Energy: 1.0540907978778038, Validation Loss Force: 2.6026970364967728, time: 0.07786703109741211
Test Loss Energy: 11.930776224336862, Test Loss Force: 10.365216986354572, time: 16.90181875228882


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4721738870619585, Training Loss Force: 2.5505899136116805, time: 1.139084815979004
Validation Loss Energy: 1.0895818103780879, Validation Loss Force: 2.6325451675009552, time: 0.0764153003692627
Test Loss Energy: 11.77043971279424, Test Loss Force: 10.458785905008035, time: 16.706304788589478


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.539160511092734, Training Loss Force: 2.548997333599876, time: 1.126495122909546
Validation Loss Energy: 1.043355695683479, Validation Loss Force: 2.611590664854275, time: 0.08144378662109375
Test Loss Energy: 11.814142853163482, Test Loss Force: 10.515956686205886, time: 16.83188223838806


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3531252019166398, Training Loss Force: 2.517287394037835, time: 1.1734957695007324
Validation Loss Energy: 2.4800869433213877, Validation Loss Force: 2.6400003531757634, time: 0.08085989952087402
Test Loss Energy: 11.349269011381713, Test Loss Force: 10.394675396223676, time: 16.53173279762268

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–ƒâ–ˆâ–â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–â–‡â–ƒâ–ƒâ–‚â–‚â–
wandb:   test_error_force â–†â–…â–…â–†â–ƒâ–ˆâ–…â–„â–„â–ƒâ–‚â–â–‚â–…â–‚â–„â–â–„â–†â–‚
wandb:          test_loss â–†â–…â–…â–‡â–ˆâ–†â–…â–†â–…â–ƒâ–ƒâ–â–‚â–ƒâ–†â–ƒâ–â–…â–†â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–‚â–‚â–‚â–ƒâ–â–â–â–â–‚â–ƒâ–ƒâ–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–â–‚â–
wandb: valid_error_energy â–‚â–â–â–â–ˆâ–ƒâ–â–‚â–â–â–‚â–â–â–…â–†â–â–â–â–â–†
wandb:  valid_error_force â–ˆâ–„â–‚â–„â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–„â–…â–ƒâ–‚â–„â–‚â–…
wandb:         valid_loss â–ƒâ–‚â–‚â–‚â–†â–„â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–„â–ˆâ–â–â–ƒâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 965
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.34927
wandb:   test_error_force 10.39468
wandb:          test_loss 5.80664
wandb: train_error_energy 1.35313
wandb:  train_error_force 2.51729
wandb:         train_loss 1.14892
wandb: valid_error_energy 2.48009
wandb:  valid_error_force 2.64
wandb:         valid_loss 1.36863
wandb: 
wandb: ğŸš€ View run al_54_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xo62iwz4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_185442-xo62iwz4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6135623455047607, Uncertainty Bias: 0.0409700870513916
0.00037574768 0.007961273
0.6803024 3.7469454
Found uncertainty sample 1 after 3715 steps.
Found uncertainty sample 2 after 227 steps.
Found uncertainty sample 4 after 1218 steps.
Found uncertainty sample 5 after 1020 steps.
Found uncertainty sample 7 after 2524 steps.
Found uncertainty sample 8 after 1430 steps.
Found uncertainty sample 9 after 117 steps.
Found uncertainty sample 10 after 811 steps.
Found uncertainty sample 11 after 178 steps.
Found uncertainty sample 12 after 1131 steps.
Found uncertainty sample 13 after 2404 steps.
Found uncertainty sample 14 after 304 steps.
Found uncertainty sample 15 after 2541 steps.
Found uncertainty sample 16 after 1334 steps.
Found uncertainty sample 17 after 340 steps.
Found uncertainty sample 18 after 17 steps.
Found uncertainty sample 19 after 218 steps.
Found uncertainty sample 20 after 387 steps.
Found uncertainty sample 21 after 1120 steps.
Found uncertainty sample 22 after 672 steps.
Found uncertainty sample 23 after 1241 steps.
Found uncertainty sample 24 after 975 steps.
Found uncertainty sample 25 after 135 steps.
Found uncertainty sample 26 after 1311 steps.
Found uncertainty sample 27 after 81 steps.
Found uncertainty sample 28 after 40 steps.
Found uncertainty sample 30 after 36 steps.
Found uncertainty sample 31 after 1366 steps.
Found uncertainty sample 32 after 1802 steps.
Found uncertainty sample 33 after 3968 steps.
Found uncertainty sample 34 after 3823 steps.
Found uncertainty sample 35 after 161 steps.
Found uncertainty sample 36 after 536 steps.
Found uncertainty sample 37 after 157 steps.
Found uncertainty sample 38 after 3546 steps.
Found uncertainty sample 39 after 653 steps.
Found uncertainty sample 40 after 523 steps.
Found uncertainty sample 41 after 112 steps.
Found uncertainty sample 42 after 1578 steps.
Found uncertainty sample 44 after 2141 steps.
Found uncertainty sample 45 after 2651 steps.
Found uncertainty sample 46 after 1077 steps.
Found uncertainty sample 47 after 2301 steps.
Found uncertainty sample 48 after 941 steps.
Found uncertainty sample 49 after 802 steps.
Found uncertainty sample 50 after 633 steps.
Found uncertainty sample 51 after 3541 steps.
Found uncertainty sample 52 after 2421 steps.
Found uncertainty sample 53 after 25 steps.
Found uncertainty sample 54 after 525 steps.
Found uncertainty sample 55 after 2424 steps.
Found uncertainty sample 56 after 499 steps.
Found uncertainty sample 57 after 15 steps.
Found uncertainty sample 59 after 4 steps.
Found uncertainty sample 60 after 1860 steps.
Found uncertainty sample 61 after 3694 steps.
Found uncertainty sample 62 after 3677 steps.
Found uncertainty sample 63 after 3887 steps.
Found uncertainty sample 64 after 846 steps.
Found uncertainty sample 66 after 618 steps.
Found uncertainty sample 67 after 2370 steps.
Found uncertainty sample 68 after 115 steps.
Found uncertainty sample 69 after 685 steps.
Found uncertainty sample 70 after 1999 steps.
Found uncertainty sample 71 after 2734 steps.
Found uncertainty sample 72 after 1632 steps.
Found uncertainty sample 73 after 709 steps.
Found uncertainty sample 74 after 1579 steps.
Found uncertainty sample 75 after 12 steps.
Found uncertainty sample 76 after 1638 steps.
Found uncertainty sample 77 after 2956 steps.
Found uncertainty sample 78 after 53 steps.
Found uncertainty sample 79 after 917 steps.
Found uncertainty sample 80 after 1108 steps.
Found uncertainty sample 81 after 19 steps.
Found uncertainty sample 82 after 2019 steps.
Found uncertainty sample 83 after 38 steps.
Found uncertainty sample 84 after 1853 steps.
Found uncertainty sample 85 after 1348 steps.
Found uncertainty sample 86 after 314 steps.
Found uncertainty sample 87 after 1383 steps.
Found uncertainty sample 88 after 97 steps.
Found uncertainty sample 89 after 803 steps.
Found uncertainty sample 91 after 1660 steps.
Found uncertainty sample 92 after 3258 steps.
Found uncertainty sample 93 after 964 steps.
Found uncertainty sample 94 after 303 steps.
Found uncertainty sample 95 after 690 steps.
Found uncertainty sample 96 after 253 steps.
Found uncertainty sample 98 after 81 steps.
Found uncertainty sample 99 after 362 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_201134-qgp8tthr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qgp8tthr
Training model 2. Added 91 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.090719850824853, Training Loss Force: 3.059016776845118, time: 1.160813331604004
Validation Loss Energy: 1.1707427100464531, Validation Loss Force: 2.688816555375804, time: 0.08399391174316406
Test Loss Energy: 12.047932828365727, Test Loss Force: 10.319748054010365, time: 16.683680295944214


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4505148625025062, Training Loss Force: 2.7220218286078404, time: 1.19673490524292
Validation Loss Energy: 1.2161226819865363, Validation Loss Force: 2.663096933006269, time: 0.07918453216552734
Test Loss Energy: 11.65471594624778, Test Loss Force: 10.352307925651113, time: 16.8294415473938


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2656674728140402, Training Loss Force: 2.6942220985525465, time: 1.1996855735778809
Validation Loss Energy: 1.1753520727017315, Validation Loss Force: 2.6724107380421365, time: 0.0797736644744873
Test Loss Energy: 11.656105355086089, Test Loss Force: 10.238445099587546, time: 16.66444182395935


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3041212669896403, Training Loss Force: 2.687318848962544, time: 1.1879253387451172
Validation Loss Energy: 1.1137611189306675, Validation Loss Force: 2.653042085052754, time: 0.07894611358642578
Test Loss Energy: 11.681107001196205, Test Loss Force: 10.236444994385872, time: 16.864020824432373


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.329254225322042, Training Loss Force: 2.6907496474448513, time: 1.1782517433166504
Validation Loss Energy: 1.3292043170693797, Validation Loss Force: 2.679121763431254, time: 0.07782959938049316
Test Loss Energy: 11.58953322606962, Test Loss Force: 10.266202475731522, time: 17.138039350509644


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.777292539139414, Training Loss Force: 2.6914061503100952, time: 1.20231032371521
Validation Loss Energy: 1.1805680974450898, Validation Loss Force: 2.649708727938215, time: 0.07897472381591797
Test Loss Energy: 11.663748166912807, Test Loss Force: 10.269584467984439, time: 16.71556568145752


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5069075763847992, Training Loss Force: 2.700302140310054, time: 1.212737798690796
Validation Loss Energy: 1.1121979815262544, Validation Loss Force: 2.640401602976725, time: 0.08251833915710449
Test Loss Energy: 11.600114627097094, Test Loss Force: 10.122279002531416, time: 16.780797958374023


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6467137177632125, Training Loss Force: 2.7068794157655174, time: 1.162674903869629
Validation Loss Energy: 1.2746022797815513, Validation Loss Force: 2.6490527446343117, time: 0.07805442810058594
Test Loss Energy: 11.671608844760419, Test Loss Force: 10.242109981915196, time: 16.752108812332153


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.415980757161747, Training Loss Force: 2.704259382633733, time: 1.1854252815246582
Validation Loss Energy: 1.3211846651096446, Validation Loss Force: 2.651694491381599, time: 0.07946348190307617
Test Loss Energy: 11.639774314948012, Test Loss Force: 10.214664482472365, time: 16.826476335525513


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7457094275043368, Training Loss Force: 2.680009599296467, time: 1.2108829021453857
Validation Loss Energy: 2.8580101472250123, Validation Loss Force: 2.6560810735563765, time: 0.08140206336975098
Test Loss Energy: 13.498557863608495, Test Loss Force: 10.09609847834595, time: 16.90948724746704


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8808862672175863, Training Loss Force: 2.695663955495478, time: 1.1874589920043945
Validation Loss Energy: 1.9149640070831044, Validation Loss Force: 2.667009452569366, time: 0.08591151237487793
Test Loss Energy: 11.345431370439417, Test Loss Force: 10.157102871456939, time: 16.75110125541687


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7238193770672656, Training Loss Force: 2.674167152265215, time: 1.259434700012207
Validation Loss Energy: 1.074842337597971, Validation Loss Force: 2.6389050436469446, time: 0.08931732177734375
Test Loss Energy: 11.846597042063829, Test Loss Force: 10.135017897375102, time: 17.09901738166809


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6247716572116924, Training Loss Force: 2.6675709431847974, time: 1.2317512035369873
Validation Loss Energy: 1.9158573556965668, Validation Loss Force: 2.654009137153518, time: 0.0860445499420166
Test Loss Energy: 11.38011858812615, Test Loss Force: 10.171268728115521, time: 16.730487823486328


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5692727996959905, Training Loss Force: 2.689708264334647, time: 1.2178864479064941
Validation Loss Energy: 1.0811380850299332, Validation Loss Force: 2.659539125392635, time: 0.08356070518493652
Test Loss Energy: 11.866646857457711, Test Loss Force: 10.01638575934654, time: 16.914493799209595


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4240315338821754, Training Loss Force: 2.6957085905379117, time: 1.2148723602294922
Validation Loss Energy: 1.155414834048222, Validation Loss Force: 2.6625311307064665, time: 0.07874298095703125
Test Loss Energy: 11.809689554183032, Test Loss Force: 10.145996484200174, time: 16.953343391418457


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.288443780189653, Training Loss Force: 2.6662214062192784, time: 1.1860072612762451
Validation Loss Energy: 1.0620072426884013, Validation Loss Force: 2.6457452171407003, time: 0.08188843727111816
Test Loss Energy: 11.795486774083665, Test Loss Force: 10.1378017746543, time: 16.757325172424316


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4085118317885026, Training Loss Force: 2.661151749327843, time: 1.269622564315796
Validation Loss Energy: 1.3149507083656773, Validation Loss Force: 2.6510725764570227, time: 0.07778620719909668
Test Loss Energy: 11.604057503109882, Test Loss Force: 10.059357635587645, time: 16.88177180290222


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2985731295282432, Training Loss Force: 2.6716294594845746, time: 1.2147140502929688
Validation Loss Energy: 1.068582551233076, Validation Loss Force: 2.636566126938119, time: 0.07922601699829102
Test Loss Energy: 11.686973169715971, Test Loss Force: 10.093600951256803, time: 16.799099683761597


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3847496652037314, Training Loss Force: 2.6741265455100574, time: 1.2325854301452637
Validation Loss Energy: 1.8210969379406616, Validation Loss Force: 2.621284343453095, time: 0.08564162254333496
Test Loss Energy: 12.580418689723203, Test Loss Force: 10.011267120294832, time: 16.873151063919067


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.35074595945546, Training Loss Force: 2.6505146755381257, time: 1.1932439804077148
Validation Loss Energy: 1.332397837960276, Validation Loss Force: 2.63519359432262, time: 0.08632397651672363
Test Loss Energy: 12.320436009983469, Test Loss Force: 10.006183744574672, time: 17.136051893234253

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–‚â–…â–„
wandb:   test_error_force â–‡â–ˆâ–†â–†â–†â–†â–ƒâ–†â–…â–ƒâ–„â–„â–„â–â–„â–„â–‚â–ƒâ–â–
wandb:          test_loss â–ˆâ–‡â–…â–…â–…â–…â–ƒâ–†â–„â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–„â–â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–â–â–‚â–â–â–‚â–‚â–ˆâ–„â–â–„â–â–â–â–‚â–â–„â–‚
wandb:  valid_error_force â–ˆâ–…â–†â–„â–‡â–„â–ƒâ–„â–„â–…â–†â–ƒâ–„â–…â–…â–„â–„â–ƒâ–â–‚
wandb:         valid_loss â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ˆâ–„â–â–…â–ƒâ–â–‚â–ƒâ–‚â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1046
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.32044
wandb:   test_error_force 10.00618
wandb:          test_loss 5.66523
wandb: train_error_energy 1.35075
wandb:  train_error_force 2.65051
wandb:         train_loss 1.21215
wandb: valid_error_energy 1.3324
wandb:  valid_error_force 2.63519
wandb:         valid_loss 1.30675
wandb: 
wandb: ğŸš€ View run al_54_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qgp8tthr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_201134-qgp8tthr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6419154405593872, Uncertainty Bias: 0.03375634551048279
0.00021362305 0.0062179565
0.5586572 4.0534573
Found uncertainty sample 0 after 14 steps.
Found uncertainty sample 1 after 372 steps.
Found uncertainty sample 3 after 1257 steps.
Found uncertainty sample 6 after 1367 steps.
Found uncertainty sample 8 after 7 steps.
Found uncertainty sample 9 after 1094 steps.
Found uncertainty sample 10 after 2105 steps.
Found uncertainty sample 11 after 1701 steps.
Found uncertainty sample 12 after 802 steps.
Found uncertainty sample 13 after 107 steps.
Found uncertainty sample 14 after 3611 steps.
Found uncertainty sample 15 after 267 steps.
Found uncertainty sample 17 after 846 steps.
Found uncertainty sample 18 after 2176 steps.
Found uncertainty sample 19 after 404 steps.
Found uncertainty sample 22 after 1694 steps.
Found uncertainty sample 23 after 953 steps.
Found uncertainty sample 24 after 211 steps.
Found uncertainty sample 26 after 7 steps.
Found uncertainty sample 28 after 3002 steps.
Found uncertainty sample 29 after 2950 steps.
Found uncertainty sample 30 after 2048 steps.
Found uncertainty sample 31 after 1640 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 3205 steps.
Found uncertainty sample 35 after 577 steps.
Found uncertainty sample 36 after 1503 steps.
Found uncertainty sample 37 after 1832 steps.
Found uncertainty sample 38 after 1931 steps.
Found uncertainty sample 39 after 2795 steps.
Found uncertainty sample 40 after 2697 steps.
Found uncertainty sample 43 after 1848 steps.
Found uncertainty sample 44 after 619 steps.
Found uncertainty sample 45 after 524 steps.
Found uncertainty sample 46 after 1154 steps.
Found uncertainty sample 47 after 877 steps.
Found uncertainty sample 48 after 854 steps.
Found uncertainty sample 49 after 1169 steps.
Found uncertainty sample 51 after 50 steps.
Found uncertainty sample 52 after 481 steps.
Found uncertainty sample 53 after 632 steps.
Found uncertainty sample 54 after 1323 steps.
Found uncertainty sample 55 after 574 steps.
Found uncertainty sample 56 after 552 steps.
Found uncertainty sample 57 after 1073 steps.
Found uncertainty sample 58 after 557 steps.
Found uncertainty sample 59 after 720 steps.
Found uncertainty sample 60 after 4 steps.
Found uncertainty sample 62 after 2177 steps.
Found uncertainty sample 63 after 74 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1290 steps.
Found uncertainty sample 66 after 273 steps.
Found uncertainty sample 68 after 334 steps.
Found uncertainty sample 69 after 2271 steps.
Found uncertainty sample 71 after 112 steps.
Found uncertainty sample 74 after 1062 steps.
Found uncertainty sample 75 after 1134 steps.
Found uncertainty sample 78 after 2501 steps.
Found uncertainty sample 79 after 1270 steps.
Found uncertainty sample 80 after 3505 steps.
Found uncertainty sample 82 after 1012 steps.
Found uncertainty sample 83 after 1493 steps.
Found uncertainty sample 84 after 1454 steps.
Found uncertainty sample 85 after 1847 steps.
Found uncertainty sample 86 after 69 steps.
Found uncertainty sample 87 after 3693 steps.
Found uncertainty sample 88 after 378 steps.
Found uncertainty sample 89 after 741 steps.
Found uncertainty sample 90 after 985 steps.
Found uncertainty sample 91 after 924 steps.
Found uncertainty sample 92 after 586 steps.
Found uncertainty sample 93 after 732 steps.
Found uncertainty sample 95 after 1612 steps.
Found uncertainty sample 96 after 2190 steps.
Found uncertainty sample 97 after 763 steps.
Found uncertainty sample 99 after 830 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_214345-9ay32hw0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9ay32hw0
Training model 3. Added 79 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.498399965235881, Training Loss Force: 3.1168174903447357, time: 1.218435287475586
Validation Loss Energy: 1.2843352594846278, Validation Loss Force: 2.710130446024012, time: 0.08086061477661133
Test Loss Energy: 12.215218389288008, Test Loss Force: 9.94955334292236, time: 16.104369401931763


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.506340720937051, Training Loss Force: 2.799777788525685, time: 1.2575104236602783
Validation Loss Energy: 1.5273897657221047, Validation Loss Force: 2.6893338158017945, time: 0.08111405372619629
Test Loss Energy: 11.524833028764878, Test Loss Force: 9.913447599200522, time: 16.800330877304077


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5808290994831118, Training Loss Force: 2.7757973394253574, time: 1.2524278163909912
Validation Loss Energy: 1.4642937911937148, Validation Loss Force: 2.6753586548650747, time: 0.08160638809204102
Test Loss Energy: 12.276528345089174, Test Loss Force: 9.943472521345921, time: 16.685827493667603


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5717742507114885, Training Loss Force: 2.7773022011332933, time: 1.27970552444458
Validation Loss Energy: 1.4865494609946244, Validation Loss Force: 2.671351278245812, time: 0.08561444282531738
Test Loss Energy: 11.51205807317762, Test Loss Force: 9.981628518625353, time: 16.87682604789734


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.449909028772567, Training Loss Force: 2.768160468451423, time: 1.271496295928955
Validation Loss Energy: 1.2376678145427902, Validation Loss Force: 2.670836689849573, time: 0.08258986473083496
Test Loss Energy: 12.107437984288147, Test Loss Force: 9.937350658698207, time: 16.833325386047363


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4140751837217553, Training Loss Force: 2.7546755995261343, time: 1.262331485748291
Validation Loss Energy: 1.1395325118766308, Validation Loss Force: 2.6822257713254873, time: 0.08525753021240234
Test Loss Energy: 11.806715790252062, Test Loss Force: 10.119324954729219, time: 16.707623720169067


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.405732022121877, Training Loss Force: 2.760367449148413, time: 1.247359037399292
Validation Loss Energy: 1.1306291974112812, Validation Loss Force: 2.6707672170760435, time: 0.0828709602355957
Test Loss Energy: 11.862850154995675, Test Loss Force: 10.006455564145691, time: 16.766327619552612


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.465841037973578, Training Loss Force: 2.763801452716912, time: 1.277583360671997
Validation Loss Energy: 1.323067778076756, Validation Loss Force: 2.670396918286366, time: 0.08101177215576172
Test Loss Energy: 12.169673889331031, Test Loss Force: 9.881068898638063, time: 17.13142418861389


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4355536523167058, Training Loss Force: 2.739821315353389, time: 1.294294834136963
Validation Loss Energy: 1.1175665346345733, Validation Loss Force: 2.676328824333882, time: 0.07900762557983398
Test Loss Energy: 11.774016045081844, Test Loss Force: 9.98227975243135, time: 16.835733652114868


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4747238652870087, Training Loss Force: 2.7760630536981807, time: 1.2614059448242188
Validation Loss Energy: 1.1249785224950717, Validation Loss Force: 2.655983321801314, time: 0.0803365707397461
Test Loss Energy: 11.634055122054246, Test Loss Force: 9.970586987546215, time: 16.830381393432617


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0751509071349776, Training Loss Force: 2.797970815682529, time: 1.3038854598999023
Validation Loss Energy: 1.1378500238100004, Validation Loss Force: 2.695222078696709, time: 0.08165812492370605
Test Loss Energy: 11.747577056810888, Test Loss Force: 9.998691662272643, time: 16.68515133857727


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6485971434792606, Training Loss Force: 2.762714483738102, time: 1.2744619846343994
Validation Loss Energy: 1.1371650935171265, Validation Loss Force: 2.6733196734958136, time: 0.08844566345214844
Test Loss Energy: 11.677836273567827, Test Loss Force: 10.059001178425033, time: 16.888147592544556


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5102692869931003, Training Loss Force: 2.769179033468604, time: 1.3181276321411133
Validation Loss Energy: 1.244551519854575, Validation Loss Force: 2.66835437421077, time: 0.08736705780029297
Test Loss Energy: 11.608939655870547, Test Loss Force: 9.922431340945316, time: 16.745254516601562


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4269025297450464, Training Loss Force: 2.7517611848666945, time: 1.2650535106658936
Validation Loss Energy: 1.3837284201561335, Validation Loss Force: 2.648738781138553, time: 0.08220124244689941
Test Loss Energy: 12.190484771544398, Test Loss Force: 9.895591235775399, time: 16.852657794952393


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7047232588223185, Training Loss Force: 2.7478066826266265, time: 1.2427356243133545
Validation Loss Energy: 1.3255347295444897, Validation Loss Force: 2.675732739030233, time: 0.08359837532043457
Test Loss Energy: 11.444215013961387, Test Loss Force: 9.940722191330298, time: 16.937410593032837


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.392344459613358, Training Loss Force: 2.752613988609671, time: 1.2582135200500488
Validation Loss Energy: 1.560780117499706, Validation Loss Force: 2.6392929332991506, time: 0.07936406135559082
Test Loss Energy: 11.38461329190967, Test Loss Force: 9.860944695428143, time: 16.86828351020813


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9899730226737034, Training Loss Force: 2.760035525795542, time: 1.2938907146453857
Validation Loss Energy: 2.291114096577706, Validation Loss Force: 2.6951209869044574, time: 0.08204269409179688
Test Loss Energy: 11.142954599454418, Test Loss Force: 9.929674131731696, time: 16.91862201690674


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5404072600625611, Training Loss Force: 2.750022202456755, time: 1.26377534866333
Validation Loss Energy: 1.1191166458939497, Validation Loss Force: 2.650913145348538, time: 0.08396053314208984
Test Loss Energy: 11.866616784299135, Test Loss Force: 9.809010173886563, time: 16.666448831558228


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7928632966174252, Training Loss Force: 2.751700249864417, time: 1.2592782974243164
Validation Loss Energy: 1.237875564855941, Validation Loss Force: 2.6687064141304817, time: 0.08411455154418945
Test Loss Energy: 11.530752577257696, Test Loss Force: 9.948626302485245, time: 17.13315176963806


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4239172967542386, Training Loss Force: 2.7477556214104775, time: 1.2640960216522217
Validation Loss Energy: 1.110938342167741, Validation Loss Force: 2.649699375834086, time: 0.08486461639404297
Test Loss Energy: 11.669458177910272, Test Loss Force: 9.896888695080317, time: 16.75818657875061

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–ƒâ–ˆâ–ƒâ–‡â–…â–…â–‡â–…â–„â–…â–„â–„â–‡â–ƒâ–‚â–â–…â–ƒâ–„
wandb:   test_error_force â–„â–ƒâ–„â–…â–„â–ˆâ–…â–ƒâ–…â–…â–…â–‡â–„â–ƒâ–„â–‚â–„â–â–„â–ƒ
wandb:          test_loss â–…â–‚â–†â–„â–…â–ˆâ–†â–„â–…â–…â–‡â–‡â–„â–…â–ƒâ–â–ƒâ–ƒâ–„â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–ƒâ–‚â–â–â–‚â–â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–â–â–â–â–‚â–ƒâ–‚â–„â–ˆâ–â–‚â–
wandb:  valid_error_force â–ˆâ–†â–…â–„â–„â–…â–„â–„â–…â–ƒâ–‡â–„â–„â–‚â–…â–â–‡â–‚â–„â–‚
wandb:         valid_loss â–†â–„â–„â–…â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–„â–ƒâ–„â–‚â–„â–ˆâ–†â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1117
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.66946
wandb:   test_error_force 9.89689
wandb:          test_loss 5.55742
wandb: train_error_energy 1.42392
wandb:  train_error_force 2.74776
wandb:         train_loss 1.24451
wandb: valid_error_energy 1.11094
wandb:  valid_error_force 2.6497
wandb:         valid_loss 1.29317
wandb: 
wandb: ğŸš€ View run al_54_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9ay32hw0
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_214345-9ay32hw0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6627479791641235, Uncertainty Bias: 0.03111688792705536
0.00036907196 0.0056324005
0.51947904 4.0497
Found uncertainty sample 0 after 1306 steps.
Found uncertainty sample 3 after 142 steps.
Found uncertainty sample 4 after 474 steps.
Found uncertainty sample 5 after 1914 steps.
Found uncertainty sample 6 after 755 steps.
Found uncertainty sample 7 after 681 steps.
Found uncertainty sample 8 after 258 steps.
Found uncertainty sample 9 after 206 steps.
Found uncertainty sample 11 after 1352 steps.
Found uncertainty sample 12 after 1506 steps.
Found uncertainty sample 13 after 384 steps.
Found uncertainty sample 14 after 787 steps.
Found uncertainty sample 15 after 486 steps.
Found uncertainty sample 16 after 226 steps.
Found uncertainty sample 17 after 881 steps.
Found uncertainty sample 19 after 267 steps.
Found uncertainty sample 20 after 3069 steps.
Found uncertainty sample 21 after 3501 steps.
Found uncertainty sample 22 after 752 steps.
Found uncertainty sample 23 after 812 steps.
Found uncertainty sample 24 after 1268 steps.
Found uncertainty sample 25 after 2538 steps.
Found uncertainty sample 26 after 689 steps.
Found uncertainty sample 27 after 1715 steps.
Found uncertainty sample 28 after 1194 steps.
Found uncertainty sample 29 after 158 steps.
Found uncertainty sample 30 after 3290 steps.
Found uncertainty sample 31 after 1661 steps.
Found uncertainty sample 32 after 1640 steps.
Found uncertainty sample 33 after 2377 steps.
Found uncertainty sample 34 after 909 steps.
Found uncertainty sample 36 after 861 steps.
Found uncertainty sample 37 after 1750 steps.
Found uncertainty sample 38 after 3801 steps.
Found uncertainty sample 39 after 44 steps.
Found uncertainty sample 40 after 77 steps.
Found uncertainty sample 41 after 1356 steps.
Found uncertainty sample 42 after 127 steps.
Found uncertainty sample 43 after 1280 steps.
Found uncertainty sample 44 after 2388 steps.
Found uncertainty sample 45 after 1781 steps.
Found uncertainty sample 46 after 3226 steps.
Found uncertainty sample 47 after 101 steps.
Found uncertainty sample 48 after 338 steps.
Found uncertainty sample 49 after 3605 steps.
Found uncertainty sample 50 after 360 steps.
Found uncertainty sample 51 after 2 steps.
Found uncertainty sample 52 after 437 steps.
Found uncertainty sample 53 after 1451 steps.
Found uncertainty sample 54 after 458 steps.
Found uncertainty sample 55 after 2659 steps.
Found uncertainty sample 56 after 3039 steps.
Found uncertainty sample 57 after 3642 steps.
Found uncertainty sample 58 after 966 steps.
Found uncertainty sample 59 after 2470 steps.
Found uncertainty sample 60 after 2113 steps.
Found uncertainty sample 61 after 264 steps.
Found uncertainty sample 62 after 632 steps.
Found uncertainty sample 63 after 24 steps.
Found uncertainty sample 64 after 655 steps.
Found uncertainty sample 65 after 499 steps.
Found uncertainty sample 66 after 163 steps.
Found uncertainty sample 68 after 84 steps.
Found uncertainty sample 69 after 3251 steps.
Found uncertainty sample 71 after 3296 steps.
Found uncertainty sample 72 after 3336 steps.
Found uncertainty sample 75 after 18 steps.
Found uncertainty sample 76 after 1422 steps.
Found uncertainty sample 77 after 1986 steps.
Found uncertainty sample 78 after 559 steps.
Found uncertainty sample 79 after 3815 steps.
Found uncertainty sample 81 after 2485 steps.
Found uncertainty sample 82 after 3177 steps.
Found uncertainty sample 83 after 1456 steps.
Found uncertainty sample 84 after 74 steps.
Found uncertainty sample 85 after 1533 steps.
Found uncertainty sample 86 after 2781 steps.
Found uncertainty sample 87 after 2000 steps.
Found uncertainty sample 89 after 198 steps.
Found uncertainty sample 90 after 2331 steps.
Found uncertainty sample 91 after 306 steps.
Found uncertainty sample 92 after 2717 steps.
Found uncertainty sample 95 after 145 steps.
Found uncertainty sample 96 after 1263 steps.
Found uncertainty sample 98 after 377 steps.
Found uncertainty sample 99 after 1160 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_231154-3re973o5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3re973o5
Training model 4. Added 86 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.871461766121941, Training Loss Force: 3.2525956364406983, time: 1.4202096462249756
Validation Loss Energy: 1.6700783811240905, Validation Loss Force: 2.739112394050535, time: 0.09610843658447266
Test Loss Energy: 11.24630345943332, Test Loss Force: 9.868712225292722, time: 16.928746223449707


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.634990985749372, Training Loss Force: 2.8718222791886263, time: 1.3799481391906738
Validation Loss Energy: 2.2333523841091623, Validation Loss Force: 2.728725991738733, time: 0.0845956802368164
Test Loss Energy: 11.108747074061593, Test Loss Force: 9.908765983904809, time: 16.514176607131958


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4916557977447562, Training Loss Force: 2.83366945041935, time: 1.3599438667297363
Validation Loss Energy: 1.29970599929345, Validation Loss Force: 2.7257869816816327, time: 0.08225011825561523
Test Loss Energy: 11.350797505663921, Test Loss Force: 9.85382076100179, time: 16.437426567077637


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5398436993964892, Training Loss Force: 2.8573624143989367, time: 1.3469040393829346
Validation Loss Energy: 2.3200203370946135, Validation Loss Force: 2.723470109218254, time: 0.08450913429260254
Test Loss Energy: 11.217477602478091, Test Loss Force: 9.838539954463071, time: 16.436442852020264


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7563338483062825, Training Loss Force: 2.8633277676960573, time: 1.3291630744934082
Validation Loss Energy: 1.5840377984572906, Validation Loss Force: 2.7161033231943787, time: 0.0820012092590332
Test Loss Energy: 11.344771784791742, Test Loss Force: 9.868106415992496, time: 16.561617374420166


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4699789593185428, Training Loss Force: 2.844203371040329, time: 1.3624851703643799
Validation Loss Energy: 1.3612100007630292, Validation Loss Force: 2.7094820334710703, time: 0.08609366416931152
Test Loss Energy: 11.95843647010093, Test Loss Force: 9.798995494980652, time: 17.289644956588745


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3662096731325468, Training Loss Force: 2.831602922532852, time: 1.367582082748413
Validation Loss Energy: 1.5766779151769394, Validation Loss Force: 2.7127287722878433, time: 0.08705973625183105
Test Loss Energy: 12.10474323528929, Test Loss Force: 9.87724403960423, time: 17.04983878135681


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5524278915913847, Training Loss Force: 2.8705512837036706, time: 1.3312361240386963
Validation Loss Energy: 1.3872291131338372, Validation Loss Force: 2.7035452287023434, time: 0.08571267127990723
Test Loss Energy: 11.465065356411671, Test Loss Force: 9.801110432176428, time: 16.994171380996704


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5492058690498094, Training Loss Force: 2.815265429468698, time: 1.3956503868103027
Validation Loss Energy: 2.007644027008606, Validation Loss Force: 2.71502716321211, time: 0.0864248275756836
Test Loss Energy: 12.736784635004064, Test Loss Force: 9.745671900353193, time: 17.15177822113037


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6398468123856922, Training Loss Force: 2.8414694627054846, time: 1.3695054054260254
Validation Loss Energy: 1.8820780009210294, Validation Loss Force: 2.7000544445016335, time: 0.08471298217773438
Test Loss Energy: 12.51379873930168, Test Loss Force: 9.762753846136532, time: 17.125619888305664


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.501818912710764, Training Loss Force: 2.8214718807134282, time: 1.363722562789917
Validation Loss Energy: 1.1464490608874398, Validation Loss Force: 2.7015692627013803, time: 0.08912825584411621
Test Loss Energy: 11.58739998103998, Test Loss Force: 9.778646724690931, time: 17.037785291671753


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.818952103761227, Training Loss Force: 2.845627990656832, time: 1.392930507659912
Validation Loss Energy: 1.8914004900535881, Validation Loss Force: 2.782269237237675, time: 0.08862948417663574
Test Loss Energy: 11.18944797308288, Test Loss Force: 9.783924813504036, time: 17.125585794448853


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8770650621581857, Training Loss Force: 2.8297967358959446, time: 1.3738481998443604
Validation Loss Energy: 1.6362351203036718, Validation Loss Force: 2.691043246835082, time: 0.0880436897277832
Test Loss Energy: 12.248504283588415, Test Loss Force: 9.833106915903768, time: 17.005356788635254


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.591839243443588, Training Loss Force: 2.843693950912161, time: 1.3532793521881104
Validation Loss Energy: 1.5085836863299085, Validation Loss Force: 2.7066826369684662, time: 0.08659696578979492
Test Loss Energy: 11.310357027869903, Test Loss Force: 9.825190559111602, time: 17.12645983695984


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.651340151364544, Training Loss Force: 2.8107485448255525, time: 1.3753833770751953
Validation Loss Energy: 2.758282203492604, Validation Loss Force: 2.697981840091338, time: 0.08482217788696289
Test Loss Energy: 12.873693349276131, Test Loss Force: 9.814738725879302, time: 17.12017059326172


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6195031073205062, Training Loss Force: 2.812989457811598, time: 1.368262529373169
Validation Loss Energy: 1.4377714465531102, Validation Loss Force: 2.691271705378804, time: 0.08376312255859375
Test Loss Energy: 12.057587851134492, Test Loss Force: 9.687832948504575, time: 17.051857948303223


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.535029497241172, Training Loss Force: 2.8024557657194795, time: 1.3680462837219238
Validation Loss Energy: 1.1965168863567406, Validation Loss Force: 2.7296745623003855, time: 0.08619284629821777
Test Loss Energy: 11.5002309746781, Test Loss Force: 9.7362884080353, time: 17.18395209312439


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.93884845480876, Training Loss Force: 2.844908001692903, time: 1.3761498928070068
Validation Loss Energy: 1.3140829667039966, Validation Loss Force: 2.7083900639794405, time: 0.09102153778076172
Test Loss Energy: 11.4233382496602, Test Loss Force: 9.763107957695363, time: 17.105760097503662


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4967367326331085, Training Loss Force: 2.817268725177467, time: 1.6174931526184082
Validation Loss Energy: 1.2888541071320865, Validation Loss Force: 2.69603237171874, time: 0.08810973167419434
Test Loss Energy: 11.90579390730758, Test Loss Force: 9.740812574094505, time: 17.279988050460815


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9993255911431786, Training Loss Force: 2.821787402893209, time: 1.355698585510254
Validation Loss Energy: 2.4706958720918832, Validation Loss Force: 2.7009241901856273, time: 0.08802151679992676
Test Loss Energy: 12.89558374549864, Test Loss Force: 9.715116619939634, time: 17.189201831817627

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–â–‚â–„â–…â–‚â–‡â–‡â–ƒâ–â–…â–‚â–ˆâ–…â–ƒâ–‚â–„â–ˆ
wandb:   test_error_force â–‡â–ˆâ–†â–†â–‡â–…â–‡â–…â–ƒâ–ƒâ–„â–„â–†â–…â–…â–â–ƒâ–ƒâ–ƒâ–‚
wandb:          test_loss â–ˆâ–„â–„â–ƒâ–…â–„â–‡â–„â–…â–†â–…â–â–†â–„â–ˆâ–ƒâ–â–â–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–„â–‚â–„
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–‚â–â–
wandb: valid_error_energy â–ƒâ–†â–‚â–†â–ƒâ–‚â–ƒâ–‚â–…â–„â–â–„â–ƒâ–ƒâ–ˆâ–‚â–â–‚â–‚â–‡
wandb:  valid_error_force â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ˆâ–â–‚â–‚â–â–„â–‚â–â–‚
wandb:         valid_loss â–ˆâ–…â–â–†â–ƒâ–‚â–„â–‚â–„â–ƒâ–„â–†â–„â–„â–†â–…â–…â–„â–‚â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1194
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.89558
wandb:   test_error_force 9.71512
wandb:          test_loss 5.53377
wandb: train_error_energy 1.99933
wandb:  train_error_force 2.82179
wandb:         train_loss 1.29978
wandb: valid_error_energy 2.4707
wandb:  valid_error_force 2.70092
wandb:         valid_loss 1.405
wandb: 
wandb: ğŸš€ View run al_54_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3re973o5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_231154-3re973o5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6908663511276245, Uncertainty Bias: 0.027549967169761658
0.0001296997 0.06352043
0.56593996 4.2874284
Found uncertainty sample 0 after 38 steps.
Found uncertainty sample 1 after 2647 steps.
Found uncertainty sample 2 after 17 steps.
Found uncertainty sample 3 after 345 steps.
Found uncertainty sample 4 after 363 steps.
Found uncertainty sample 6 after 1376 steps.
Found uncertainty sample 9 after 375 steps.
Found uncertainty sample 11 after 27 steps.
Found uncertainty sample 12 after 985 steps.
Found uncertainty sample 13 after 2787 steps.
Found uncertainty sample 14 after 1366 steps.
Found uncertainty sample 16 after 502 steps.
Found uncertainty sample 18 after 1209 steps.
Found uncertainty sample 19 after 1188 steps.
Found uncertainty sample 20 after 1679 steps.
Found uncertainty sample 21 after 1968 steps.
Found uncertainty sample 22 after 169 steps.
Found uncertainty sample 23 after 273 steps.
Found uncertainty sample 24 after 2486 steps.
Found uncertainty sample 25 after 3691 steps.
Found uncertainty sample 27 after 2680 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1101 steps.
Found uncertainty sample 31 after 1722 steps.
Found uncertainty sample 32 after 707 steps.
Found uncertainty sample 33 after 95 steps.
Found uncertainty sample 34 after 3970 steps.
Found uncertainty sample 36 after 124 steps.
Found uncertainty sample 38 after 339 steps.
Found uncertainty sample 40 after 2223 steps.
Found uncertainty sample 42 after 149 steps.
Found uncertainty sample 43 after 2974 steps.
Found uncertainty sample 44 after 32 steps.
Found uncertainty sample 45 after 465 steps.
Found uncertainty sample 46 after 2594 steps.
Found uncertainty sample 47 after 1801 steps.
Found uncertainty sample 48 after 1693 steps.
Found uncertainty sample 50 after 1215 steps.
Found uncertainty sample 53 after 1558 steps.
Found uncertainty sample 54 after 2391 steps.
Found uncertainty sample 55 after 1994 steps.
Found uncertainty sample 56 after 2345 steps.
Found uncertainty sample 57 after 2132 steps.
Found uncertainty sample 58 after 792 steps.
Found uncertainty sample 59 after 3131 steps.
Found uncertainty sample 60 after 3942 steps.
Found uncertainty sample 61 after 107 steps.
Found uncertainty sample 62 after 287 steps.
Found uncertainty sample 63 after 1074 steps.
Found uncertainty sample 64 after 2465 steps.
Found uncertainty sample 65 after 3151 steps.
Found uncertainty sample 66 after 398 steps.
Found uncertainty sample 67 after 800 steps.
Found uncertainty sample 68 after 137 steps.
Found uncertainty sample 69 after 1205 steps.
Found uncertainty sample 70 after 80 steps.
Found uncertainty sample 72 after 1943 steps.
Found uncertainty sample 74 after 1000 steps.
Found uncertainty sample 75 after 1721 steps.
Found uncertainty sample 76 after 600 steps.
Found uncertainty sample 77 after 3287 steps.
Found uncertainty sample 78 after 3203 steps.
Found uncertainty sample 79 after 1505 steps.
Found uncertainty sample 81 after 1728 steps.
Found uncertainty sample 82 after 3536 steps.
Found uncertainty sample 84 after 1094 steps.
Found uncertainty sample 85 after 3119 steps.
Found uncertainty sample 86 after 1295 steps.
Found uncertainty sample 87 after 399 steps.
Found uncertainty sample 88 after 797 steps.
Found uncertainty sample 89 after 1318 steps.
Found uncertainty sample 90 after 2646 steps.
Found uncertainty sample 91 after 3802 steps.
Found uncertainty sample 92 after 912 steps.
Found uncertainty sample 94 after 2426 steps.
Found uncertainty sample 97 after 159 steps.
Found uncertainty sample 99 after 1940 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_005412-7v3mufe2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7v3mufe2
Training model 5. Added 78 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.957053350532253, Training Loss Force: 3.2248389667006294, time: 1.5195655822753906
Validation Loss Energy: 1.487706227207719, Validation Loss Force: 2.8066530674007892, time: 0.0927433967590332
Test Loss Energy: 11.382218887448648, Test Loss Force: 9.542956218198485, time: 17.015398740768433


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5149664723476497, Training Loss Force: 2.932217228634269, time: 1.438206434249878
Validation Loss Energy: 1.511394772962674, Validation Loss Force: 2.7554436172203167, time: 0.08989191055297852
Test Loss Energy: 12.105147933547492, Test Loss Force: 9.65061739844329, time: 17.11685276031494


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.694542838393263, Training Loss Force: 2.8866879124980116, time: 1.4547004699707031
Validation Loss Energy: 1.62841843127045, Validation Loss Force: 2.7180988840801836, time: 0.0877683162689209
Test Loss Energy: 12.262051194632969, Test Loss Force: 9.600307354409695, time: 17.042014360427856


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.528318883350496, Training Loss Force: 2.8993142662167317, time: 1.4446759223937988
Validation Loss Energy: 1.2695717384367506, Validation Loss Force: 2.7374546222591025, time: 0.09131073951721191
Test Loss Energy: 11.478289926471028, Test Loss Force: 9.633259086441452, time: 17.227608680725098


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8652851748699644, Training Loss Force: 2.88735540779676, time: 1.4391891956329346
Validation Loss Energy: 1.2068102129655445, Validation Loss Force: 2.7349357888803674, time: 0.08982300758361816
Test Loss Energy: 11.757998187348804, Test Loss Force: 9.565402429251826, time: 17.169114112854004


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6429350205855862, Training Loss Force: 2.9022445420765832, time: 1.4593346118927002
Validation Loss Energy: 1.5011500995622553, Validation Loss Force: 2.69644030159408, time: 0.09914231300354004
Test Loss Energy: 11.430613132782966, Test Loss Force: 9.58049531235784, time: 17.055270195007324


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.053965814285127, Training Loss Force: 2.9027287305676746, time: 1.449065923690796
Validation Loss Energy: 1.9179415389024508, Validation Loss Force: 2.733336356405168, time: 0.09169363975524902
Test Loss Energy: 12.400094369731905, Test Loss Force: 9.608675400810506, time: 17.165201902389526


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3685807787302773, Training Loss Force: 2.8866725204933, time: 1.465069055557251
Validation Loss Energy: 1.188347823400088, Validation Loss Force: 2.7233282689722977, time: 0.08890795707702637
Test Loss Energy: 11.804667989552492, Test Loss Force: 9.538897045937945, time: 17.53477454185486


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.69135954775794, Training Loss Force: 2.886204575716404, time: 1.4270055294036865
Validation Loss Energy: 1.5856823214345404, Validation Loss Force: 2.698301815654036, time: 0.08737850189208984
Test Loss Energy: 11.368153215584433, Test Loss Force: 9.664612133280325, time: 17.05616855621338


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4549373839835027, Training Loss Force: 2.8847669068089927, time: 1.4281768798828125
Validation Loss Energy: 1.6152508913260102, Validation Loss Force: 2.7189897833330408, time: 0.08937644958496094
Test Loss Energy: 11.178853738851432, Test Loss Force: 9.608294228538504, time: 17.23632001876831


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6022804942932818, Training Loss Force: 2.8842594939259802, time: 1.4630978107452393
Validation Loss Energy: 1.276305698747899, Validation Loss Force: 2.7115811355097317, time: 0.08825564384460449
Test Loss Energy: 11.69327682831455, Test Loss Force: 9.599241545628194, time: 17.11562418937683


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5741705534342663, Training Loss Force: 2.8861584386693675, time: 1.4513065814971924
Validation Loss Energy: 1.3048792715607904, Validation Loss Force: 2.702689956512835, time: 0.09302663803100586
Test Loss Energy: 11.406310457945795, Test Loss Force: 9.588912136125487, time: 17.211860418319702


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5368290002878733, Training Loss Force: 2.8689249768204723, time: 1.5271129608154297
Validation Loss Energy: 1.5198911595638405, Validation Loss Force: 2.716814973784764, time: 0.09007120132446289
Test Loss Energy: 12.191408538395324, Test Loss Force: 9.543013370723147, time: 17.179943799972534


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5867145710612323, Training Loss Force: 2.881200971771532, time: 1.4288666248321533
Validation Loss Energy: 1.163857668719793, Validation Loss Force: 2.708439941868128, time: 0.0904698371887207
Test Loss Energy: 11.59550174312163, Test Loss Force: 9.571583650131132, time: 17.100355625152588


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7682250343499635, Training Loss Force: 2.883821615050514, time: 1.4711191654205322
Validation Loss Energy: 1.300400059021307, Validation Loss Force: 2.7046316314653254, time: 0.08809137344360352
Test Loss Energy: 11.740220222115965, Test Loss Force: 9.529570911326752, time: 17.22636318206787


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.553008463301248, Training Loss Force: 2.881115951124888, time: 1.4992139339447021
Validation Loss Energy: 1.2300468516888388, Validation Loss Force: 2.698119672292667, time: 0.09280061721801758
Test Loss Energy: 11.693592360986592, Test Loss Force: 9.53376062599716, time: 17.446062088012695


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5627417366492609, Training Loss Force: 2.8766271638121297, time: 1.4673922061920166
Validation Loss Energy: 2.12827859952132, Validation Loss Force: 2.706713365310604, time: 0.0866849422454834
Test Loss Energy: 11.04215843721734, Test Loss Force: 9.652727350648135, time: 17.243199586868286


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7564565886667676, Training Loss Force: 2.875194621861803, time: 1.4442675113677979
Validation Loss Energy: 1.773245895153645, Validation Loss Force: 2.6887775882752667, time: 0.09075355529785156
Test Loss Energy: 11.172898171584096, Test Loss Force: 9.612276345616484, time: 17.177512645721436


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5192652157194053, Training Loss Force: 2.8628809512912525, time: 1.4712018966674805
Validation Loss Energy: 1.4979859709986214, Validation Loss Force: 2.692455637227702, time: 0.08975839614868164
Test Loss Energy: 12.073188331291886, Test Loss Force: 9.5809043707344, time: 17.04713797569275


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.523402610244657, Training Loss Force: 2.8784379093068146, time: 1.4481120109558105
Validation Loss Energy: 1.1725000149461153, Validation Loss Force: 2.676918006894007, time: 0.09365296363830566
Test Loss Energy: 11.622315594316854, Test Loss Force: 9.525875074490397, time: 17.16498899459839

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–‡â–ƒâ–…â–ƒâ–ˆâ–…â–ƒâ–‚â–„â–ƒâ–‡â–„â–…â–„â–â–‚â–†â–„
wandb:   test_error_force â–‚â–‡â–…â–†â–ƒâ–„â–…â–‚â–ˆâ–…â–…â–„â–‚â–ƒâ–â–â–‡â–…â–„â–
wandb:          test_loss â–ƒâ–‡â–‡â–ˆâ–„â–…â–ˆâ–†â–…â–â–…â–â–„â–„â–â–ƒâ–ƒâ–ƒâ–…â–‚
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–ƒâ–„â–‚â–â–â–â–â–â–‚â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–ƒâ–„â–„â–‚â–â–ƒâ–†â–â–„â–„â–‚â–‚â–„â–â–‚â–â–ˆâ–…â–ƒâ–
wandb:  valid_error_force â–ˆâ–…â–ƒâ–„â–„â–‚â–„â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–
wandb:         valid_loss â–„â–ƒâ–„â–‡â–„â–ƒâ–†â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–…â–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1264
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.62232
wandb:   test_error_force 9.52588
wandb:          test_loss 5.35634
wandb: train_error_energy 1.5234
wandb:  train_error_force 2.87844
wandb:         train_loss 1.30185
wandb: valid_error_energy 1.1725
wandb:  valid_error_force 2.67692
wandb:         valid_loss 1.32364
wandb: 
wandb: ğŸš€ View run al_54_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7v3mufe2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_005412-7v3mufe2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6676296591758728, Uncertainty Bias: 0.02902698516845703
0.00030517578 0.0060253143
0.463402 4.0938416
Found uncertainty sample 0 after 3344 steps.
Found uncertainty sample 1 after 3940 steps.
Found uncertainty sample 3 after 1751 steps.
Found uncertainty sample 4 after 2369 steps.
Found uncertainty sample 5 after 774 steps.
Found uncertainty sample 6 after 1586 steps.
Found uncertainty sample 7 after 1120 steps.
Found uncertainty sample 8 after 2372 steps.
Found uncertainty sample 9 after 945 steps.
Found uncertainty sample 10 after 1430 steps.
Found uncertainty sample 11 after 584 steps.
Found uncertainty sample 12 after 2285 steps.
Found uncertainty sample 13 after 403 steps.
Found uncertainty sample 14 after 653 steps.
Found uncertainty sample 15 after 2004 steps.
Found uncertainty sample 16 after 45 steps.
Found uncertainty sample 17 after 1228 steps.
Found uncertainty sample 18 after 1518 steps.
Found uncertainty sample 19 after 620 steps.
Found uncertainty sample 20 after 126 steps.
Found uncertainty sample 21 after 3354 steps.
Found uncertainty sample 22 after 2083 steps.
Found uncertainty sample 23 after 2589 steps.
Found uncertainty sample 24 after 3000 steps.
Found uncertainty sample 25 after 768 steps.
Found uncertainty sample 26 after 97 steps.
Found uncertainty sample 27 after 1229 steps.
Found uncertainty sample 28 after 1999 steps.
Found uncertainty sample 29 after 53 steps.
Found uncertainty sample 30 after 1621 steps.
Found uncertainty sample 31 after 3746 steps.
Found uncertainty sample 32 after 301 steps.
Found uncertainty sample 35 after 3760 steps.
Found uncertainty sample 36 after 1405 steps.
Found uncertainty sample 37 after 1129 steps.
Found uncertainty sample 38 after 898 steps.
Found uncertainty sample 39 after 432 steps.
Found uncertainty sample 40 after 174 steps.
Found uncertainty sample 41 after 1518 steps.
Found uncertainty sample 42 after 761 steps.
Found uncertainty sample 43 after 391 steps.
Found uncertainty sample 44 after 1356 steps.
Found uncertainty sample 47 after 2723 steps.
Found uncertainty sample 48 after 2360 steps.
Found uncertainty sample 49 after 3542 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 3163 steps.
Found uncertainty sample 56 after 1595 steps.
Found uncertainty sample 57 after 1387 steps.
Found uncertainty sample 59 after 79 steps.
Found uncertainty sample 61 after 236 steps.
Found uncertainty sample 63 after 26 steps.
Found uncertainty sample 65 after 82 steps.
Found uncertainty sample 66 after 836 steps.
Found uncertainty sample 67 after 1134 steps.
Found uncertainty sample 68 after 550 steps.
Found uncertainty sample 69 after 512 steps.
Found uncertainty sample 70 after 2731 steps.
Found uncertainty sample 72 after 1124 steps.
Found uncertainty sample 73 after 3480 steps.
Found uncertainty sample 76 after 2044 steps.
Found uncertainty sample 77 after 1148 steps.
Found uncertainty sample 78 after 493 steps.
Found uncertainty sample 79 after 371 steps.
Found uncertainty sample 80 after 2487 steps.
Found uncertainty sample 82 after 95 steps.
Found uncertainty sample 83 after 724 steps.
Found uncertainty sample 85 after 872 steps.
Found uncertainty sample 86 after 1924 steps.
Found uncertainty sample 88 after 2295 steps.
Found uncertainty sample 89 after 1292 steps.
Found uncertainty sample 92 after 1432 steps.
Found uncertainty sample 93 after 239 steps.
Found uncertainty sample 95 after 51 steps.
Found uncertainty sample 96 after 506 steps.
Found uncertainty sample 97 after 3826 steps.
Found uncertainty sample 98 after 609 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_023409-gh62s1nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gh62s1nv
Training model 6. Added 77 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.918797751476472, Training Loss Force: 3.1753728200369387, time: 1.5626459121704102
Validation Loss Energy: 1.3710172962935592, Validation Loss Force: 2.8564006946382463, time: 0.1348714828491211
Test Loss Energy: 11.588493298204554, Test Loss Force: 9.51631358208938, time: 17.055043697357178


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6656328565708098, Training Loss Force: 2.966483336837393, time: 1.5587875843048096
Validation Loss Energy: 1.5119106973737886, Validation Loss Force: 2.7047695750012277, time: 0.12342643737792969
Test Loss Energy: 11.321380799044492, Test Loss Force: 9.367800074731926, time: 17.208072185516357


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4702684550188956, Training Loss Force: 2.940228783654644, time: 1.5427970886230469
Validation Loss Energy: 1.1612586187812375, Validation Loss Force: 2.607282573553437, time: 0.12586283683776855
Test Loss Energy: 11.399449622853751, Test Loss Force: 9.409712787291694, time: 17.189595222473145


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8279074407707223, Training Loss Force: 2.9262593856074868, time: 1.7508132457733154
Validation Loss Energy: 1.0815092188289084, Validation Loss Force: 2.909567072607705, time: 0.12909555435180664
Test Loss Energy: 11.773544760588356, Test Loss Force: 9.384603672424783, time: 17.470335483551025


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4484498012505127, Training Loss Force: 2.934076933507415, time: 1.529512882232666
Validation Loss Energy: 2.3160269886315445, Validation Loss Force: 2.815186639749326, time: 0.12407612800598145
Test Loss Energy: 11.064859442395589, Test Loss Force: 9.407836994427027, time: 17.282750129699707


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9739325067978821, Training Loss Force: 2.9629472977835962, time: 1.5294101238250732
Validation Loss Energy: 1.0555130692137742, Validation Loss Force: 2.800947281870963, time: 0.1210472583770752
Test Loss Energy: 11.500531365848222, Test Loss Force: 9.344654640591319, time: 17.232985258102417


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8177230126283934, Training Loss Force: 2.9302542609446993, time: 1.509016752243042
Validation Loss Energy: 1.8197958821210056, Validation Loss Force: 2.8951294278548936, time: 0.12359213829040527
Test Loss Energy: 12.274559851911379, Test Loss Force: 9.368997302610191, time: 17.262468576431274


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7803385396727702, Training Loss Force: 2.9262695117519804, time: 1.5641121864318848
Validation Loss Energy: 2.009859529343301, Validation Loss Force: 2.7250351393104073, time: 0.12080216407775879
Test Loss Energy: 11.178081848679328, Test Loss Force: 9.419590679725198, time: 17.26648998260498


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6193956972214805, Training Loss Force: 2.933070193282212, time: 1.5523173809051514
Validation Loss Energy: 1.330939466389022, Validation Loss Force: 2.468914184920742, time: 0.12303709983825684
Test Loss Energy: 11.353790803857772, Test Loss Force: 9.343854808355918, time: 17.148437023162842


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.56863079538756, Training Loss Force: 2.9270598652821582, time: 1.5347263813018799
Validation Loss Energy: 1.1366727720354803, Validation Loss Force: 2.589971160803281, time: 0.11857366561889648
Test Loss Energy: 11.940169262282854, Test Loss Force: 9.271398911796506, time: 17.33738613128662


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5044797985408254, Training Loss Force: 2.936114356192654, time: 1.5270793437957764
Validation Loss Energy: 1.5167706741528084, Validation Loss Force: 2.5297786806032168, time: 0.12740254402160645
Test Loss Energy: 11.931587332258017, Test Loss Force: 9.339811579672546, time: 17.238471031188965


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.530602467969429, Training Loss Force: 2.9424440182561997, time: 1.5491843223571777
Validation Loss Energy: 1.1076067664063693, Validation Loss Force: 2.5857125020528393, time: 0.12460708618164062
Test Loss Energy: 11.721842733614496, Test Loss Force: 9.341699767397733, time: 17.314270496368408


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.600831990543804, Training Loss Force: 2.914486984498504, time: 1.5558388233184814
Validation Loss Energy: 1.6024107863606574, Validation Loss Force: 2.8172484447060446, time: 0.12555289268493652
Test Loss Energy: 11.835644289522913, Test Loss Force: 9.329614703778141, time: 17.301347255706787


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.577437721946366, Training Loss Force: 2.9187590511125183, time: 1.5216355323791504
Validation Loss Energy: 1.2710989147740963, Validation Loss Force: 2.4403038716987724, time: 0.12726497650146484
Test Loss Energy: 11.294269942182817, Test Loss Force: 9.390830345789226, time: 17.423142433166504


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4606420516612002, Training Loss Force: 2.9218501017831175, time: 1.543053388595581
Validation Loss Energy: 1.5965734590328737, Validation Loss Force: 2.976660514978364, time: 0.12314343452453613
Test Loss Energy: 12.068000531902936, Test Loss Force: 9.329841919571551, time: 17.31291389465332


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6853523897447695, Training Loss Force: 2.9183787269096277, time: 1.526318073272705
Validation Loss Energy: 1.0654352341899598, Validation Loss Force: 2.7279328442409385, time: 0.11822819709777832
Test Loss Energy: 11.592315224067857, Test Loss Force: 9.414792936057948, time: 17.339853286743164


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6007484763599646, Training Loss Force: 2.9192199179264797, time: 1.541891098022461
Validation Loss Energy: 1.3739261903486732, Validation Loss Force: 2.9350032371544743, time: 0.12305045127868652
Test Loss Energy: 11.512289327326638, Test Loss Force: 9.36032063444151, time: 17.265283823013306


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5075054308719271, Training Loss Force: 2.9124470594361958, time: 1.5452957153320312
Validation Loss Energy: 0.9454908246950489, Validation Loss Force: 2.6543431408724096, time: 0.12196040153503418
Test Loss Energy: 11.571747930242068, Test Loss Force: 9.345812851239344, time: 17.30025863647461


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8182215078771928, Training Loss Force: 2.9300963673136513, time: 1.5504090785980225
Validation Loss Energy: 0.8960215338900019, Validation Loss Force: 2.4546547868192454, time: 0.12734770774841309
Test Loss Energy: 11.404039675664011, Test Loss Force: 9.316969297333147, time: 17.1509690284729


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7926465356261692, Training Loss Force: 2.92520596968798, time: 1.5500524044036865
Validation Loss Energy: 1.3023569868102933, Validation Loss Force: 2.71747106842324, time: 0.12659692764282227
Test Loss Energy: 11.282712947186345, Test Loss Force: 9.342953970597986, time: 17.28060746192932

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ƒâ–…â–â–„â–ˆâ–‚â–ƒâ–†â–†â–…â–…â–‚â–‡â–„â–„â–„â–ƒâ–‚
wandb:   test_error_force â–ˆâ–„â–…â–„â–…â–ƒâ–„â–…â–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–…â–„â–ƒâ–‚â–ƒ
wandb:          test_loss â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–‚â–â–‚â–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–„â–‚â–‚â–ˆâ–‚â–†â–†â–ƒâ–‚â–„â–‚â–„â–ƒâ–„â–‚â–ƒâ–â–â–ƒ
wandb:  valid_error_force â–†â–„â–ƒâ–‡â–†â–†â–‡â–…â–â–ƒâ–‚â–ƒâ–†â–â–ˆâ–…â–‡â–„â–â–…
wandb:         valid_loss â–ˆâ–„â–‚â–†â–…â–„â–†â–„â–â–ƒâ–â–„â–†â–â–†â–ƒâ–‡â–ƒâ–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1333
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.28271
wandb:   test_error_force 9.34295
wandb:          test_loss 5.23529
wandb: train_error_energy 1.79265
wandb:  train_error_force 2.92521
wandb:         train_loss 1.33344
wandb: valid_error_energy 1.30236
wandb:  valid_error_force 2.71747
wandb:         valid_loss 1.36447
wandb: 
wandb: ğŸš€ View run al_54_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gh62s1nv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_023409-gh62s1nv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6593080163002014, Uncertainty Bias: 0.035310447216033936
0.00023651123 0.015711784
0.5464289 3.832729
Found uncertainty sample 0 after 1354 steps.
Found uncertainty sample 2 after 2741 steps.
Found uncertainty sample 3 after 2010 steps.
Found uncertainty sample 5 after 391 steps.
Found uncertainty sample 6 after 260 steps.
Found uncertainty sample 8 after 695 steps.
Found uncertainty sample 9 after 3070 steps.
Found uncertainty sample 10 after 2560 steps.
Found uncertainty sample 12 after 3969 steps.
Found uncertainty sample 13 after 2930 steps.
Found uncertainty sample 15 after 1032 steps.
Found uncertainty sample 16 after 752 steps.
Found uncertainty sample 17 after 385 steps.
Found uncertainty sample 18 after 2109 steps.
Found uncertainty sample 19 after 3424 steps.
Found uncertainty sample 22 after 938 steps.
Found uncertainty sample 24 after 1493 steps.
Found uncertainty sample 25 after 1921 steps.
Found uncertainty sample 26 after 927 steps.
Found uncertainty sample 27 after 624 steps.
Found uncertainty sample 29 after 127 steps.
Found uncertainty sample 30 after 1287 steps.
Found uncertainty sample 31 after 3 steps.
Found uncertainty sample 32 after 1013 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 35 after 3698 steps.
Found uncertainty sample 36 after 2507 steps.
Found uncertainty sample 37 after 2244 steps.
Found uncertainty sample 38 after 4 steps.
Found uncertainty sample 39 after 2691 steps.
Found uncertainty sample 41 after 1400 steps.
Found uncertainty sample 42 after 260 steps.
Found uncertainty sample 43 after 2362 steps.
Found uncertainty sample 45 after 1672 steps.
Found uncertainty sample 47 after 887 steps.
Found uncertainty sample 48 after 601 steps.
Found uncertainty sample 49 after 1094 steps.
Found uncertainty sample 51 after 1035 steps.
Found uncertainty sample 52 after 778 steps.
Found uncertainty sample 53 after 181 steps.
Found uncertainty sample 54 after 1885 steps.
Found uncertainty sample 55 after 13 steps.
Found uncertainty sample 56 after 2702 steps.
Found uncertainty sample 57 after 1486 steps.
Found uncertainty sample 59 after 2748 steps.
Found uncertainty sample 60 after 2877 steps.
Found uncertainty sample 62 after 1864 steps.
Found uncertainty sample 64 after 3468 steps.
Found uncertainty sample 65 after 1822 steps.
Found uncertainty sample 66 after 331 steps.
Found uncertainty sample 67 after 9 steps.
Found uncertainty sample 68 after 517 steps.
Found uncertainty sample 69 after 2453 steps.
Found uncertainty sample 70 after 3535 steps.
Found uncertainty sample 71 after 2720 steps.
Found uncertainty sample 72 after 1912 steps.
Found uncertainty sample 73 after 985 steps.
Found uncertainty sample 74 after 2224 steps.
Found uncertainty sample 75 after 1279 steps.
Found uncertainty sample 76 after 74 steps.
Found uncertainty sample 77 after 1102 steps.
Found uncertainty sample 78 after 1645 steps.
Found uncertainty sample 79 after 1969 steps.
Found uncertainty sample 80 after 3500 steps.
Found uncertainty sample 81 after 635 steps.
Found uncertainty sample 82 after 506 steps.
Found uncertainty sample 84 after 1333 steps.
Found uncertainty sample 85 after 2254 steps.
Found uncertainty sample 88 after 2561 steps.
Found uncertainty sample 89 after 1317 steps.
Found uncertainty sample 90 after 537 steps.
Found uncertainty sample 91 after 12 steps.
Found uncertainty sample 92 after 2570 steps.
Found uncertainty sample 95 after 1214 steps.
Found uncertainty sample 97 after 71 steps.
Found uncertainty sample 98 after 986 steps.
Found uncertainty sample 99 after 367 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_041728-2t9ox524
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2t9ox524
Training model 7. Added 78 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.722579435164874, Training Loss Force: 3.3999661300613524, time: 1.5823018550872803
Validation Loss Energy: 1.3938085410577115, Validation Loss Force: 2.8688690534644725, time: 0.13822197914123535
Test Loss Energy: 11.629683210395344, Test Loss Force: 9.361047981457972, time: 17.356080293655396


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6165860813136048, Training Loss Force: 2.9868907047629722, time: 1.592057466506958
Validation Loss Energy: 1.1988603677830576, Validation Loss Force: 2.832139221170819, time: 0.1251375675201416
Test Loss Energy: 11.591505491799019, Test Loss Force: 9.315319885544048, time: 17.47163200378418


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6384404380552722, Training Loss Force: 2.986462648633238, time: 1.6043241024017334
Validation Loss Energy: 1.1907223115049752, Validation Loss Force: 2.646372810128498, time: 0.1279160976409912
Test Loss Energy: 11.471983073561137, Test Loss Force: 9.305148200408308, time: 17.333369731903076


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4885011206340444, Training Loss Force: 2.958248620702409, time: 1.7945454120635986
Validation Loss Energy: 1.1888532266940572, Validation Loss Force: 2.7462100844115565, time: 0.12266397476196289
Test Loss Energy: 11.580501182607266, Test Loss Force: 9.304995377094164, time: 17.366220951080322


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6063571819979097, Training Loss Force: 2.9698290306419612, time: 1.5742969512939453
Validation Loss Energy: 1.354886308353253, Validation Loss Force: 2.8128208914084163, time: 0.12815308570861816
Test Loss Energy: 11.575139719937406, Test Loss Force: 9.283405404684375, time: 17.458630084991455


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7242607376784689, Training Loss Force: 2.9772531337282633, time: 1.626601219177246
Validation Loss Energy: 2.3215374933203927, Validation Loss Force: 2.5383347425354916, time: 0.12482833862304688
Test Loss Energy: 11.056936030139177, Test Loss Force: 9.312900364936008, time: 17.35092306137085


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.75854520982055, Training Loss Force: 2.9631188655654537, time: 1.604933500289917
Validation Loss Energy: 1.4519355979274362, Validation Loss Force: 2.7706133981249392, time: 0.12126493453979492
Test Loss Energy: 11.064394262067799, Test Loss Force: 9.303503493816446, time: 17.480732917785645


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7132504594354083, Training Loss Force: 2.955164232996329, time: 1.574509859085083
Validation Loss Energy: 1.7396832531243818, Validation Loss Force: 2.8109069387645937, time: 0.12994003295898438
Test Loss Energy: 12.12723931490486, Test Loss Force: 9.253978369014511, time: 17.820785522460938


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8717238755140622, Training Loss Force: 2.967875913531768, time: 1.6186256408691406
Validation Loss Energy: 1.5264492669169922, Validation Loss Force: 2.756820046545869, time: 0.12383151054382324
Test Loss Energy: 11.770805188640162, Test Loss Force: 9.274709915726731, time: 17.29742932319641


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.757591892357559, Training Loss Force: 2.9629343892387143, time: 1.6107542514801025
Validation Loss Energy: 1.2711030341532963, Validation Loss Force: 2.8994974171559855, time: 0.1282815933227539
Test Loss Energy: 11.273004208692097, Test Loss Force: 9.297037540887276, time: 17.411110639572144


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4790848662832352, Training Loss Force: 2.9717204937020445, time: 1.6037876605987549
Validation Loss Energy: 1.348911371493286, Validation Loss Force: 2.6848648460430233, time: 0.12552762031555176
Test Loss Energy: 11.396596851041318, Test Loss Force: 9.23541808196811, time: 17.46471667289734


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5806903372766221, Training Loss Force: 2.96339423138903, time: 1.596369981765747
Validation Loss Energy: 1.8726602650613002, Validation Loss Force: 2.619779879368634, time: 0.13134217262268066
Test Loss Energy: 12.11106988826606, Test Loss Force: 9.293588528718857, time: 17.42882251739502


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.16481698948643, Training Loss Force: 2.991656619009825, time: 1.596987247467041
Validation Loss Energy: 2.7168475948146424, Validation Loss Force: 2.7994079700651637, time: 0.13247060775756836
Test Loss Energy: 10.969088538065778, Test Loss Force: 9.241232511971141, time: 17.526036739349365


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.140993923733692, Training Loss Force: 2.975104518168607, time: 1.6030323505401611
Validation Loss Energy: 1.9913527729505183, Validation Loss Force: 2.5308233329013365, time: 0.1275501251220703
Test Loss Energy: 10.979104578634324, Test Loss Force: 9.257729404482914, time: 17.349703550338745


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6344323668600937, Training Loss Force: 2.9677405256303815, time: 1.6141908168792725
Validation Loss Energy: 1.5001117376675075, Validation Loss Force: 2.8471608157588264, time: 0.12919306755065918
Test Loss Energy: 11.501048065521024, Test Loss Force: 9.291890400184888, time: 17.425312757492065


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.708928634761962, Training Loss Force: 2.948004524217504, time: 1.618929147720337
Validation Loss Energy: 1.206988626618719, Validation Loss Force: 2.802479468264092, time: 0.12411093711853027
Test Loss Energy: 11.82997824344079, Test Loss Force: 9.187121587223052, time: 17.516584634780884


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6331356391719623, Training Loss Force: 2.949968187748155, time: 1.6032519340515137
Validation Loss Energy: 1.3724865229856773, Validation Loss Force: 2.9006856910532295, time: 0.12793993949890137
Test Loss Energy: 11.831113636913297, Test Loss Force: 9.23354948446454, time: 17.653791189193726


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5970883789025008, Training Loss Force: 2.9416037123733005, time: 1.6587305068969727
Validation Loss Energy: 1.1175854615119771, Validation Loss Force: 2.5638339224505584, time: 0.12256050109863281
Test Loss Energy: 11.401686648026692, Test Loss Force: 9.280574396157892, time: 17.51775813102722


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5594411687051086, Training Loss Force: 2.9613795968666112, time: 1.6448290348052979
Validation Loss Energy: 1.43495679721401, Validation Loss Force: 2.944485380064663, time: 0.128251314163208
Test Loss Energy: 11.669383584912199, Test Loss Force: 9.231430289741427, time: 17.52091121673584


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6881126993778253, Training Loss Force: 2.9708225196431424, time: 1.6182258129119873
Validation Loss Energy: 1.6056519027814957, Validation Loss Force: 2.658089103914353, time: 0.11978578567504883
Test Loss Energy: 11.287078307009644, Test Loss Force: 9.23554128912004, time: 17.38985252380371

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–…â–„â–…â–…â–‚â–‚â–ˆâ–†â–ƒâ–„â–ˆâ–â–â–„â–†â–†â–„â–…â–ƒ
wandb:   test_error_force â–ˆâ–†â–†â–†â–…â–†â–†â–„â–…â–…â–ƒâ–…â–ƒâ–„â–…â–â–ƒâ–…â–ƒâ–ƒ
wandb:          test_loss â–ˆâ–†â–…â–…â–„â–„â–‚â–ˆâ–…â–ƒâ–„â–†â–â–‚â–„â–‚â–„â–„â–„â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–…â–…â–‚â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–‚
wandb: valid_error_energy â–‚â–â–â–â–‚â–†â–‚â–„â–ƒâ–‚â–‚â–„â–ˆâ–…â–ƒâ–â–‚â–â–‚â–ƒ
wandb:  valid_error_force â–‡â–†â–ƒâ–…â–†â–â–…â–†â–…â–‡â–„â–ƒâ–†â–â–†â–†â–‡â–‚â–ˆâ–ƒ
wandb:         valid_loss â–…â–†â–‚â–„â–…â–ƒâ–†â–‡â–‡â–†â–…â–†â–ˆâ–‚â–†â–„â–‡â–â–‡â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1403
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.28708
wandb:   test_error_force 9.23554
wandb:          test_loss 5.17795
wandb: train_error_energy 1.68811
wandb:  train_error_force 2.97082
wandb:         train_loss 1.36057
wandb: valid_error_energy 1.60565
wandb:  valid_error_force 2.65809
wandb:         valid_loss 1.40104
wandb: 
wandb: ğŸš€ View run al_54_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2t9ox524
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_041728-2t9ox524/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6782533526420593, Uncertainty Bias: 0.02770349383354187
5.1498413e-05 0.017002106
0.70035726 4.877091
Found uncertainty sample 0 after 530 steps.
Found uncertainty sample 1 after 1253 steps.
Found uncertainty sample 2 after 274 steps.
Found uncertainty sample 3 after 2306 steps.
Found uncertainty sample 4 after 125 steps.
Found uncertainty sample 5 after 427 steps.
Found uncertainty sample 6 after 2465 steps.
Found uncertainty sample 7 after 98 steps.
Found uncertainty sample 9 after 2590 steps.
Found uncertainty sample 10 after 457 steps.
Found uncertainty sample 12 after 35 steps.
Found uncertainty sample 13 after 155 steps.
Found uncertainty sample 14 after 1018 steps.
Found uncertainty sample 16 after 1128 steps.
Found uncertainty sample 18 after 2749 steps.
Found uncertainty sample 19 after 3688 steps.
Found uncertainty sample 20 after 376 steps.
Found uncertainty sample 22 after 3606 steps.
Found uncertainty sample 23 after 1454 steps.
Found uncertainty sample 25 after 936 steps.
Found uncertainty sample 28 after 336 steps.
Found uncertainty sample 29 after 3537 steps.
Found uncertainty sample 30 after 487 steps.
Found uncertainty sample 31 after 1566 steps.
Found uncertainty sample 32 after 3176 steps.
Found uncertainty sample 35 after 3867 steps.
Found uncertainty sample 36 after 537 steps.
Found uncertainty sample 37 after 608 steps.
Found uncertainty sample 38 after 386 steps.
Found uncertainty sample 39 after 946 steps.
Found uncertainty sample 40 after 550 steps.
Found uncertainty sample 44 after 861 steps.
Found uncertainty sample 47 after 1116 steps.
Found uncertainty sample 48 after 359 steps.
Found uncertainty sample 49 after 827 steps.
Found uncertainty sample 50 after 835 steps.
Found uncertainty sample 51 after 1274 steps.
Found uncertainty sample 52 after 1199 steps.
Found uncertainty sample 53 after 31 steps.
Found uncertainty sample 56 after 2542 steps.
Found uncertainty sample 57 after 461 steps.
Found uncertainty sample 58 after 2799 steps.
Found uncertainty sample 59 after 3499 steps.
Found uncertainty sample 61 after 3389 steps.
Found uncertainty sample 63 after 1103 steps.
Found uncertainty sample 64 after 3799 steps.
Found uncertainty sample 66 after 2189 steps.
Found uncertainty sample 67 after 2369 steps.
Found uncertainty sample 68 after 2083 steps.
Found uncertainty sample 69 after 3145 steps.
Found uncertainty sample 70 after 553 steps.
Found uncertainty sample 71 after 3279 steps.
Found uncertainty sample 73 after 3803 steps.
Found uncertainty sample 75 after 566 steps.
Found uncertainty sample 77 after 14 steps.
Found uncertainty sample 78 after 31 steps.
Found uncertainty sample 79 after 152 steps.
Found uncertainty sample 80 after 2242 steps.
Found uncertainty sample 81 after 1965 steps.
Found uncertainty sample 83 after 3456 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 186 steps.
Found uncertainty sample 90 after 111 steps.
Found uncertainty sample 91 after 2429 steps.
Found uncertainty sample 92 after 2410 steps.
Found uncertainty sample 93 after 1611 steps.
Found uncertainty sample 95 after 1904 steps.
Found uncertainty sample 96 after 454 steps.
Found uncertainty sample 97 after 2622 steps.
Found uncertainty sample 98 after 1042 steps.
Found uncertainty sample 99 after 419 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_060721-py7gyxy3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/py7gyxy3
Training model 8. Added 72 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.869420212115372, Training Loss Force: 3.1592755234828047, time: 1.6436216831207275
Validation Loss Energy: 2.42746866545463, Validation Loss Force: 2.7554511879712784, time: 0.13084959983825684
Test Loss Energy: 11.026206732039364, Test Loss Force: 9.172040059077675, time: 17.370417594909668


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0249444491001567, Training Loss Force: 3.0388268264599705, time: 1.639723300933838
Validation Loss Energy: 1.3464148606964303, Validation Loss Force: 2.788794667893662, time: 0.12506747245788574
Test Loss Energy: 11.604896450503313, Test Loss Force: 9.194911239442149, time: 17.559037685394287


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9333716006761281, Training Loss Force: 3.0094575164103046, time: 1.673663854598999
Validation Loss Energy: 1.1565228357183588, Validation Loss Force: 2.7944338753488562, time: 0.12785911560058594
Test Loss Energy: 11.359985212346386, Test Loss Force: 9.229653674413841, time: 17.907116889953613


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6284756729730123, Training Loss Force: 2.9871845655474174, time: 1.644343376159668
Validation Loss Energy: 1.187357279704428, Validation Loss Force: 2.6980633369987475, time: 0.11988258361816406
Test Loss Energy: 11.507986445434586, Test Loss Force: 9.184882887951193, time: 17.452674865722656


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6505312346110785, Training Loss Force: 3.0101145259285325, time: 1.6351041793823242
Validation Loss Energy: 1.4614339956852778, Validation Loss Force: 2.7223951739162873, time: 0.1338028907775879
Test Loss Energy: 11.85005576773656, Test Loss Force: 9.17964666560075, time: 17.582932233810425


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5018933836932629, Training Loss Force: 2.9972908258704734, time: 1.7119102478027344
Validation Loss Energy: 1.2991693109844777, Validation Loss Force: 2.8494295916866847, time: 0.12197661399841309
Test Loss Energy: 11.283211227107808, Test Loss Force: 9.163952202742479, time: 17.462846994400024


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6340927780951566, Training Loss Force: 2.9849563008822173, time: 1.6303565502166748
Validation Loss Energy: 1.2023199226360513, Validation Loss Force: 2.6966376977919446, time: 0.12406420707702637
Test Loss Energy: 11.394879640577606, Test Loss Force: 9.17961250745428, time: 17.59207534790039


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.591990230958441, Training Loss Force: 3.0082123602275432, time: 1.6712071895599365
Validation Loss Energy: 1.2565723693647728, Validation Loss Force: 2.628570077907852, time: 0.1283705234527588
Test Loss Energy: 11.638811087860171, Test Loss Force: 9.172366806813507, time: 17.522665977478027


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6553866394116572, Training Loss Force: 3.012541227527823, time: 1.6817247867584229
Validation Loss Energy: 1.7365484055534375, Validation Loss Force: 2.8706094355090443, time: 0.13241076469421387
Test Loss Energy: 11.024495387916712, Test Loss Force: 9.127230017560146, time: 17.452956914901733


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7111819703337792, Training Loss Force: 2.9991391395225837, time: 1.6556782722473145
Validation Loss Energy: 1.5387374864041632, Validation Loss Force: 2.8124272123584158, time: 0.1266167163848877
Test Loss Energy: 11.99165280302647, Test Loss Force: 9.122383515178974, time: 17.53611660003662


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8335981900824068, Training Loss Force: 2.9944518571881322, time: 1.6981732845306396
Validation Loss Energy: 1.2324422706934435, Validation Loss Force: 2.683677462822364, time: 0.12969660758972168
Test Loss Energy: 11.4020557611906, Test Loss Force: 9.14059264715321, time: 17.603220224380493


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7184849398644941, Training Loss Force: 2.9974647256328097, time: 1.6936595439910889
Validation Loss Energy: 1.5332509743157887, Validation Loss Force: 2.8848886511645286, time: 0.12261795997619629
Test Loss Energy: 11.171261509060857, Test Loss Force: 9.225601217201888, time: 17.441563844680786


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.628878492349421, Training Loss Force: 2.978855282459002, time: 1.6986069679260254
Validation Loss Energy: 1.2357651066908373, Validation Loss Force: 2.6655418402285562, time: 0.12914514541625977
Test Loss Energy: 11.484399776642931, Test Loss Force: 9.169196459835087, time: 17.542088985443115


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1598981579737133, Training Loss Force: 2.9870493376069684, time: 1.6750154495239258
Validation Loss Energy: 1.3133946407066475, Validation Loss Force: 2.87151380624523, time: 0.12885522842407227
Test Loss Energy: 11.360444591618315, Test Loss Force: 9.142732761117966, time: 17.448028326034546


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6264556148506804, Training Loss Force: 2.989968989970275, time: 1.872915267944336
Validation Loss Energy: 1.1289178180229666, Validation Loss Force: 2.6302172729148534, time: 0.12902212142944336
Test Loss Energy: 11.341845459881116, Test Loss Force: 9.129282845219702, time: 17.851430416107178


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6489975984481844, Training Loss Force: 2.9905301452618143, time: 1.7398862838745117
Validation Loss Energy: 1.3503082307129777, Validation Loss Force: 2.8076368196874983, time: 0.129500150680542
Test Loss Energy: 11.405111108298703, Test Loss Force: 9.190810867560575, time: 17.539528131484985


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.601760815123694, Training Loss Force: 2.9827652945738916, time: 1.6806070804595947
Validation Loss Energy: 1.1448746786911572, Validation Loss Force: 2.8128466096947706, time: 0.12228512763977051
Test Loss Energy: 11.192672254958508, Test Loss Force: 9.134510757697516, time: 17.437819957733154


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5881511171836784, Training Loss Force: 2.9877959375719976, time: 1.6948473453521729
Validation Loss Energy: 1.4440324575983077, Validation Loss Force: 2.85761001076978, time: 0.12065815925598145
Test Loss Energy: 11.11763724346959, Test Loss Force: 9.109142703095838, time: 17.573169469833374


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7128625850752035, Training Loss Force: 2.972106872856537, time: 1.7187244892120361
Validation Loss Energy: 1.1910652776569906, Validation Loss Force: 2.667002215822124, time: 0.12698769569396973
Test Loss Energy: 11.455811846916257, Test Loss Force: 9.162356660565393, time: 17.527890920639038


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7004491771216852, Training Loss Force: 2.981328008802629, time: 1.7227058410644531
Validation Loss Energy: 1.7928101629877253, Validation Loss Force: 2.7102512440356774, time: 0.14483070373535156
Test Loss Energy: 11.034126758792114, Test Loss Force: 9.10427822863323, time: 17.44693374633789

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–ƒâ–„â–‡â–ƒâ–„â–…â–â–ˆâ–„â–‚â–„â–ƒâ–ƒâ–„â–‚â–‚â–„â–
wandb:   test_error_force â–…â–†â–ˆâ–†â–…â–„â–…â–…â–‚â–‚â–ƒâ–ˆâ–…â–ƒâ–‚â–†â–ƒâ–â–„â–
wandb:          test_loss â–ƒâ–†â–ˆâ–‡â–‡â–„â–…â–†â–â–‡â–…â–…â–„â–„â–ƒâ–†â–ƒâ–â–…â–
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–‚â–‚â–‚â–â–ƒâ–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–â–â–ƒâ–‚â–â–‚â–„â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–â–…
wandb:  valid_error_force â–„â–…â–†â–ƒâ–„â–‡â–ƒâ–â–ˆâ–†â–ƒâ–ˆâ–‚â–ˆâ–â–†â–†â–‡â–‚â–ƒ
wandb:         valid_loss â–‡â–…â–ˆâ–‚â–„â–„â–ƒâ–‚â–†â–‡â–„â–†â–‚â–†â–‚â–†â–ƒâ–…â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1467
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.03413
wandb:   test_error_force 9.10428
wandb:          test_loss 5.088
wandb: train_error_energy 1.70045
wandb:  train_error_force 2.98133
wandb:         train_loss 1.37121
wandb: valid_error_energy 1.79281
wandb:  valid_error_force 2.71025
wandb:         valid_loss 1.33881
wandb: 
wandb: ğŸš€ View run al_54_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/py7gyxy3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_060721-py7gyxy3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6968547701835632, Uncertainty Bias: 0.02684420347213745
0.0007324219 0.006181717
0.54076594 4.0230265
Found uncertainty sample 1 after 649 steps.
Found uncertainty sample 2 after 622 steps.
Found uncertainty sample 3 after 1016 steps.
Found uncertainty sample 7 after 2272 steps.
Found uncertainty sample 8 after 925 steps.
Found uncertainty sample 9 after 194 steps.
Found uncertainty sample 12 after 111 steps.
Found uncertainty sample 13 after 2289 steps.
Found uncertainty sample 15 after 238 steps.
Found uncertainty sample 18 after 353 steps.
Found uncertainty sample 19 after 1388 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 683 steps.
Found uncertainty sample 23 after 3294 steps.
Found uncertainty sample 25 after 472 steps.
Found uncertainty sample 26 after 1983 steps.
Found uncertainty sample 27 after 713 steps.
Found uncertainty sample 28 after 2292 steps.
Found uncertainty sample 29 after 2406 steps.
Found uncertainty sample 31 after 1086 steps.
Found uncertainty sample 32 after 2152 steps.
Found uncertainty sample 34 after 1929 steps.
Found uncertainty sample 36 after 18 steps.
Found uncertainty sample 37 after 1975 steps.
Found uncertainty sample 38 after 2341 steps.
Found uncertainty sample 39 after 143 steps.
Found uncertainty sample 40 after 1154 steps.
Found uncertainty sample 41 after 974 steps.
Found uncertainty sample 42 after 1663 steps.
Found uncertainty sample 44 after 630 steps.
Found uncertainty sample 45 after 3469 steps.
Found uncertainty sample 46 after 3804 steps.
Found uncertainty sample 48 after 1464 steps.
Found uncertainty sample 49 after 424 steps.
Found uncertainty sample 50 after 662 steps.
Found uncertainty sample 54 after 229 steps.
Found uncertainty sample 55 after 2833 steps.
Found uncertainty sample 56 after 3314 steps.
Found uncertainty sample 57 after 1492 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 3531 steps.
Found uncertainty sample 60 after 711 steps.
Found uncertainty sample 61 after 2154 steps.
Found uncertainty sample 62 after 2523 steps.
Found uncertainty sample 64 after 850 steps.
Found uncertainty sample 65 after 50 steps.
Found uncertainty sample 67 after 61 steps.
Found uncertainty sample 68 after 1885 steps.
Found uncertainty sample 69 after 15 steps.
Found uncertainty sample 71 after 3178 steps.
Found uncertainty sample 72 after 265 steps.
Found uncertainty sample 74 after 1415 steps.
Found uncertainty sample 75 after 764 steps.
Found uncertainty sample 76 after 638 steps.
Found uncertainty sample 77 after 794 steps.
Found uncertainty sample 78 after 1709 steps.
Found uncertainty sample 79 after 85 steps.
Found uncertainty sample 80 after 1091 steps.
Found uncertainty sample 81 after 335 steps.
Found uncertainty sample 82 after 3481 steps.
Found uncertainty sample 83 after 520 steps.
Found uncertainty sample 85 after 277 steps.
Found uncertainty sample 86 after 485 steps.
Found uncertainty sample 87 after 557 steps.
Found uncertainty sample 89 after 2224 steps.
Found uncertainty sample 90 after 2994 steps.
Found uncertainty sample 91 after 113 steps.
Found uncertainty sample 93 after 2080 steps.
Found uncertainty sample 94 after 609 steps.
Found uncertainty sample 95 after 2719 steps.
Found uncertainty sample 97 after 2716 steps.
Found uncertainty sample 98 after 174 steps.
Found uncertainty sample 99 after 280 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_074901-f63zsq1m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/f63zsq1m
Training model 9. Added 75 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.202695051895735, Training Loss Force: 3.3764746334271654, time: 1.7397217750549316
Validation Loss Energy: 1.3884331965404417, Validation Loss Force: 2.8515796849597637, time: 0.13161420822143555
Test Loss Energy: 11.702434079453724, Test Loss Force: 9.053726988448123, time: 17.52482295036316


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8174317550898145, Training Loss Force: 3.0592057394490815, time: 1.7572972774505615
Validation Loss Energy: 1.2395268792421414, Validation Loss Force: 2.8183858387034437, time: 0.1265425682067871
Test Loss Energy: 11.43559988175186, Test Loss Force: 9.147690654030843, time: 17.587512969970703


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6787578388747342, Training Loss Force: 3.05461714069166, time: 1.7600195407867432
Validation Loss Energy: 1.3876144420908652, Validation Loss Force: 2.775000982310873, time: 0.12296199798583984
Test Loss Energy: 11.074995738292618, Test Loss Force: 9.0562943520426, time: 17.637908935546875


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5247685068557129, Training Loss Force: 3.0312594859264954, time: 1.7332649230957031
Validation Loss Energy: 1.4413308685180524, Validation Loss Force: 2.8296153777363005, time: 0.13522601127624512
Test Loss Energy: 11.22291026797914, Test Loss Force: 9.10853432435688, time: 17.75847339630127


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.612764290465883, Training Loss Force: 3.0501965458048423, time: 1.7546122074127197
Validation Loss Energy: 1.173087638822219, Validation Loss Force: 2.8163864924421578, time: 0.1262056827545166
Test Loss Energy: 11.272859224264534, Test Loss Force: 9.095200536830156, time: 17.56834602355957


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.679888360281723, Training Loss Force: 3.034028283977296, time: 1.7160735130310059
Validation Loss Energy: 1.1755687854480055, Validation Loss Force: 2.6115571531478126, time: 0.12844276428222656
Test Loss Energy: 11.221435545381153, Test Loss Force: 9.086616354466107, time: 17.44274878501892


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5752986700144789, Training Loss Force: 3.032246216413031, time: 1.7565391063690186
Validation Loss Energy: 1.3473254105014156, Validation Loss Force: 2.7474250786063115, time: 0.13956546783447266
Test Loss Energy: 11.176854211890051, Test Loss Force: 9.070661725444054, time: 17.654284954071045


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6590198775094789, Training Loss Force: 3.0304385511748646, time: 1.736215353012085
Validation Loss Energy: 1.8043085193470039, Validation Loss Force: 2.9388037541371697, time: 0.13372159004211426
Test Loss Energy: 11.004690196147063, Test Loss Force: 9.080150937808174, time: 17.715893030166626


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6266668299481821, Training Loss Force: 3.0329870273836517, time: 1.7508108615875244
Validation Loss Energy: 1.2361238266849268, Validation Loss Force: 2.9210787334484527, time: 0.12494683265686035
Test Loss Energy: 11.17962768084394, Test Loss Force: 9.068159996786308, time: 17.63788366317749


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8093662750364832, Training Loss Force: 3.0478214453598036, time: 1.688659906387329
Validation Loss Energy: 1.4509641481110398, Validation Loss Force: 2.8467468738165467, time: 0.12974786758422852
Test Loss Energy: 11.00959994122891, Test Loss Force: 9.116983688130817, time: 17.76068425178528


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7145671151686568, Training Loss Force: 3.0192809342761415, time: 1.7825772762298584
Validation Loss Energy: 1.282916634355922, Validation Loss Force: 2.7374490555304547, time: 0.13315844535827637
Test Loss Energy: 11.196742082695458, Test Loss Force: 8.981433964459598, time: 17.70422077178955


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.574484076694567, Training Loss Force: 3.0344531088740836, time: 1.8316643238067627
Validation Loss Energy: 1.2074547288084325, Validation Loss Force: 2.7419777006203336, time: 0.12603116035461426
Test Loss Energy: 11.239469339975557, Test Loss Force: 9.01774350057966, time: 17.946358919143677


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7972279165234621, Training Loss Force: 3.027295752459834, time: 1.784862756729126
Validation Loss Energy: 1.5286273608351713, Validation Loss Force: 2.7351190455874663, time: 0.1292870044708252
Test Loss Energy: 10.952397105000502, Test Loss Force: 9.00189553357593, time: 17.724315404891968


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6167761030720371, Training Loss Force: 3.0245443689918208, time: 1.7871067523956299
Validation Loss Energy: 1.5162827503867944, Validation Loss Force: 2.9117185018956593, time: 0.1241297721862793
Test Loss Energy: 11.456915978107, Test Loss Force: 9.018999694978351, time: 17.71701192855835


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6971625768468925, Training Loss Force: 3.0334069303645257, time: 1.8063230514526367
Validation Loss Energy: 2.191073970702707, Validation Loss Force: 2.7329429000243137, time: 0.1264050006866455
Test Loss Energy: 10.910873590128448, Test Loss Force: 9.055453725887018, time: 17.648563385009766


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7251306855780983, Training Loss Force: 3.0223842324124726, time: 1.7623560428619385
Validation Loss Energy: 1.6480407044170442, Validation Loss Force: 2.7353911472837895, time: 0.12392663955688477
Test Loss Energy: 11.956453245785292, Test Loss Force: 9.00742282530335, time: 17.702857732772827


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2829843300863693, Training Loss Force: 3.0363901448860333, time: 1.7361812591552734
Validation Loss Energy: 1.221268732950787, Validation Loss Force: 2.764549115270169, time: 0.13311171531677246
Test Loss Energy: 11.207928747425461, Test Loss Force: 9.01289426554677, time: 17.640703201293945


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.859056094116399, Training Loss Force: 3.0305891868520844, time: 1.982719898223877
Validation Loss Energy: 1.2275816259069856, Validation Loss Force: 2.8024131128586056, time: 0.12700843811035156
Test Loss Energy: 11.388149730280139, Test Loss Force: 8.99385050899163, time: 17.621388912200928


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.724701994124371, Training Loss Force: 3.0261083785170553, time: 1.8348536491394043
Validation Loss Energy: 1.8663802714714124, Validation Loss Force: 2.6892536549092605, time: 0.1289658546447754
Test Loss Energy: 10.817778763231836, Test Loss Force: 9.00499662228932, time: 17.72317385673523


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.158208927912933, Training Loss Force: 3.0272912990769156, time: 1.7356534004211426
Validation Loss Energy: 1.2942091330897902, Validation Loss Force: 2.7359875665911573, time: 0.1305255889892578
Test Loss Energy: 11.116606889211994, Test Loss Force: 8.9718475937362, time: 17.935747146606445

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–‚â–…â–‚â–ˆâ–ƒâ–…â–â–ƒ
wandb:   test_error_force â–„â–ˆâ–„â–†â–†â–†â–…â–…â–…â–‡â–â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–‚â–‚â–
wandb:          test_loss â–†â–ˆâ–ƒâ–…â–…â–„â–…â–…â–„â–„â–‚â–„â–ƒâ–ƒâ–…â–„â–„â–„â–„â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–‚â–ƒâ–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–‚â–‚â–â–‚
wandb: valid_error_energy â–‚â–â–‚â–ƒâ–â–â–‚â–…â–â–ƒâ–‚â–â–ƒâ–ƒâ–ˆâ–„â–â–â–†â–‚
wandb:  valid_error_force â–†â–…â–„â–†â–…â–â–„â–ˆâ–ˆâ–†â–„â–„â–„â–‡â–„â–„â–„â–…â–ƒâ–„
wandb:         valid_loss â–…â–‡â–…â–…â–…â–â–„â–‡â–†â–…â–„â–ƒâ–…â–‡â–‡â–„â–ˆâ–†â–‡â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1534
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.11661
wandb:   test_error_force 8.97185
wandb:          test_loss 4.98133
wandb: train_error_energy 2.15821
wandb:  train_error_force 3.02729
wandb:         train_loss 1.42683
wandb: valid_error_energy 1.29421
wandb:  valid_error_force 2.73599
wandb:         valid_loss 1.40472
wandb: 
wandb: ğŸš€ View run al_54_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/f63zsq1m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_074901-f63zsq1m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6871448159217834, Uncertainty Bias: 0.028489544987678528
0.00010681152 0.009883881
1.0616716 4.415367
Found uncertainty sample 1 after 1018 steps.
Found uncertainty sample 3 after 1628 steps.
Found uncertainty sample 4 after 250 steps.
Found uncertainty sample 6 after 329 steps.
Found uncertainty sample 7 after 16 steps.
Found uncertainty sample 8 after 20 steps.
Found uncertainty sample 10 after 1166 steps.
Found uncertainty sample 11 after 1786 steps.
Found uncertainty sample 12 after 2122 steps.
Found uncertainty sample 13 after 629 steps.
Found uncertainty sample 15 after 1053 steps.
Found uncertainty sample 16 after 1342 steps.
Found uncertainty sample 18 after 528 steps.
Found uncertainty sample 19 after 646 steps.
Found uncertainty sample 20 after 2911 steps.
Found uncertainty sample 21 after 554 steps.
Found uncertainty sample 22 after 1818 steps.
Found uncertainty sample 23 after 2842 steps.
Found uncertainty sample 24 after 1423 steps.
Found uncertainty sample 25 after 390 steps.
Found uncertainty sample 26 after 2652 steps.
Found uncertainty sample 27 after 629 steps.
Found uncertainty sample 29 after 1012 steps.
Found uncertainty sample 30 after 857 steps.
Found uncertainty sample 31 after 2341 steps.
Found uncertainty sample 32 after 114 steps.
Found uncertainty sample 33 after 437 steps.
Found uncertainty sample 34 after 1017 steps.
Found uncertainty sample 35 after 2430 steps.
Found uncertainty sample 37 after 3422 steps.
Found uncertainty sample 40 after 403 steps.
Found uncertainty sample 41 after 2297 steps.
Found uncertainty sample 42 after 1574 steps.
Found uncertainty sample 44 after 85 steps.
Found uncertainty sample 46 after 556 steps.
Found uncertainty sample 47 after 1876 steps.
Found uncertainty sample 48 after 726 steps.
Found uncertainty sample 49 after 1570 steps.
Found uncertainty sample 50 after 1565 steps.
Found uncertainty sample 55 after 1725 steps.
Found uncertainty sample 56 after 1246 steps.
Found uncertainty sample 57 after 1420 steps.
Found uncertainty sample 58 after 918 steps.
Found uncertainty sample 60 after 1143 steps.
Found uncertainty sample 61 after 2861 steps.
Found uncertainty sample 62 after 2425 steps.
Found uncertainty sample 63 after 2285 steps.
Found uncertainty sample 64 after 579 steps.
Found uncertainty sample 65 after 627 steps.
Found uncertainty sample 66 after 272 steps.
Found uncertainty sample 69 after 921 steps.
Found uncertainty sample 71 after 3474 steps.
Found uncertainty sample 72 after 179 steps.
Found uncertainty sample 74 after 359 steps.
Found uncertainty sample 76 after 2065 steps.
Found uncertainty sample 79 after 401 steps.
Found uncertainty sample 80 after 3908 steps.
Found uncertainty sample 82 after 2782 steps.
Found uncertainty sample 86 after 1717 steps.
Found uncertainty sample 87 after 935 steps.
Found uncertainty sample 88 after 1948 steps.
Found uncertainty sample 90 after 3461 steps.
Found uncertainty sample 91 after 762 steps.
Found uncertainty sample 92 after 2686 steps.
Found uncertainty sample 93 after 25 steps.
Found uncertainty sample 94 after 1626 steps.
Found uncertainty sample 96 after 3532 steps.
Found uncertainty sample 97 after 1087 steps.
Found uncertainty sample 98 after 516 steps.
Found uncertainty sample 99 after 1503 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_093727-boz9xbnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/boz9xbnh
Training model 10. Added 70 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.829005649536341, Training Loss Force: 3.317168266021109, time: 1.7721943855285645
Validation Loss Energy: 1.3087365691756974, Validation Loss Force: 2.7669942451616016, time: 0.13454771041870117
Test Loss Energy: 11.031126656948338, Test Loss Force: 8.982760228525024, time: 17.73580050468445


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7965825947110445, Training Loss Force: 3.072621448981155, time: 1.8235321044921875
Validation Loss Energy: 1.645766974100689, Validation Loss Force: 2.839442769157251, time: 0.1341254711151123
Test Loss Energy: 11.804171131915625, Test Loss Force: 8.963485446319044, time: 17.74142861366272


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9007829373070706, Training Loss Force: 3.085800790390329, time: 1.7932512760162354
Validation Loss Energy: 1.6964486984053129, Validation Loss Force: 2.825728910463277, time: 0.1379859447479248
Test Loss Energy: 11.599950933798047, Test Loss Force: 8.926688542231474, time: 17.820770025253296


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7213895198501254, Training Loss Force: 3.0573910130011823, time: 1.7887673377990723
Validation Loss Energy: 1.549437518208004, Validation Loss Force: 2.6889146411345854, time: 0.13110017776489258
Test Loss Energy: 11.634165659215192, Test Loss Force: 8.93137132799746, time: 17.646308422088623


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8015466136484997, Training Loss Force: 3.0629140406027973, time: 1.7881948947906494
Validation Loss Energy: 1.2541747793359956, Validation Loss Force: 2.7956808225660517, time: 0.127838134765625
Test Loss Energy: 11.131149170976284, Test Loss Force: 8.935380281953657, time: 17.803659200668335


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6219302620693425, Training Loss Force: 3.0449654244645052, time: 1.7821476459503174
Validation Loss Energy: 1.2282902147966144, Validation Loss Force: 2.714638716887039, time: 0.13237786293029785
Test Loss Energy: 11.16300895683255, Test Loss Force: 8.933166139241429, time: 17.64115619659424


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7093043267501742, Training Loss Force: 3.049448649501999, time: 2.053175210952759
Validation Loss Energy: 1.2851883606499637, Validation Loss Force: 2.742713510813052, time: 0.13317108154296875
Test Loss Energy: 11.202971484048389, Test Loss Force: 8.904519410870547, time: 17.660193920135498


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.698935861551423, Training Loss Force: 3.062864857441844, time: 1.8213064670562744
Validation Loss Energy: 1.3325662871691706, Validation Loss Force: 2.7344664023207517, time: 0.12726140022277832
Test Loss Energy: 10.926486469809587, Test Loss Force: 8.901992048447461, time: 17.753644704818726


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7728827395901683, Training Loss Force: 3.0505219236921364, time: 1.8555617332458496
Validation Loss Energy: 1.647227962034408, Validation Loss Force: 2.762356826193937, time: 0.13804292678833008
Test Loss Energy: 11.487299022187473, Test Loss Force: 8.910429045340244, time: 17.698502779006958


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8273058477457493, Training Loss Force: 3.037993346222085, time: 1.8372514247894287
Validation Loss Energy: 1.5374206210751462, Validation Loss Force: 2.7435538641697836, time: 0.1287548542022705
Test Loss Energy: 10.680433799299651, Test Loss Force: 8.896187262000321, time: 17.853229999542236


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8255227388321114, Training Loss Force: 3.0502690917837016, time: 1.8459885120391846
Validation Loss Energy: 1.364472883092882, Validation Loss Force: 2.8401380535654104, time: 0.1259748935699463
Test Loss Energy: 10.834989675253912, Test Loss Force: 8.912721390389164, time: 18.18409824371338


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9217600520055202, Training Loss Force: 3.0678118355095614, time: 1.807823657989502
Validation Loss Energy: 1.2550484773973296, Validation Loss Force: 2.764680935404558, time: 0.13300132751464844
Test Loss Energy: 10.88360348868741, Test Loss Force: 8.89676772665535, time: 17.703777313232422


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7116134247203225, Training Loss Force: 3.0454720012248737, time: 1.8555171489715576
Validation Loss Energy: 1.2516887896562847, Validation Loss Force: 2.7420400479811935, time: 0.13047361373901367
Test Loss Energy: 10.988845003764107, Test Loss Force: 8.877927454725377, time: 17.809708833694458


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9994906934004215, Training Loss Force: 3.0466700770179203, time: 1.8251564502716064
Validation Loss Energy: 2.21148126392327, Validation Loss Force: 2.7582255341949655, time: 0.12589526176452637
Test Loss Energy: 10.68950237915485, Test Loss Force: 8.866427407071525, time: 17.822314977645874


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7964027426151876, Training Loss Force: 3.062714016909011, time: 1.885633945465088
Validation Loss Energy: 1.1396303192989796, Validation Loss Force: 2.6945468345116828, time: 0.13057255744934082
Test Loss Energy: 11.242024817001386, Test Loss Force: 8.908529605245445, time: 17.749091625213623


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8370579090812864, Training Loss Force: 3.054421515084621, time: 1.845970869064331
Validation Loss Energy: 1.1882052594794077, Validation Loss Force: 2.6969846163213003, time: 0.13255810737609863
Test Loss Energy: 10.810200663022668, Test Loss Force: 8.872490410453063, time: 17.85884189605713


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.884639623516192, Training Loss Force: 3.038986365998647, time: 1.877633810043335
Validation Loss Energy: 1.8469463764222727, Validation Loss Force: 2.7785435370880114, time: 0.1341092586517334
Test Loss Energy: 10.668802966748068, Test Loss Force: 8.861850928918516, time: 17.86737060546875


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5888489639328316, Training Loss Force: 3.0406963848784807, time: 1.8200187683105469
Validation Loss Energy: 1.3807726542458014, Validation Loss Force: 2.668043194079336, time: 0.12502598762512207
Test Loss Energy: 11.421892802808767, Test Loss Force: 8.883624627855644, time: 17.71263027191162


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.763125936515169, Training Loss Force: 3.0273124773249425, time: 1.8398470878601074
Validation Loss Energy: 2.5898711823567595, Validation Loss Force: 2.815306213080689, time: 0.13118743896484375
Test Loss Energy: 10.570620436655542, Test Loss Force: 8.888528693125558, time: 17.82113242149353


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7914565928766932, Training Loss Force: 3.046608308596841, time: 1.793954610824585
Validation Loss Energy: 2.0506426637675643, Validation Loss Force: 2.7837851687831514, time: 0.12801551818847656
Test Loss Energy: 10.595862127099807, Test Loss Force: 8.893708602332417, time: 18.165849924087524

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–‡â–‡â–„â–„â–…â–ƒâ–†â–‚â–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–‚â–†â–â–
wandb:   test_error_force â–ˆâ–‡â–…â–…â–…â–…â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–„â–‚â–â–‚â–ƒâ–ƒ
wandb:          test_loss â–…â–ˆâ–…â–†â–†â–†â–„â–ƒâ–†â–„â–„â–„â–„â–‚â–„â–‚â–â–„â–â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–„â–ƒâ–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–†â–â–â–„â–‚â–ˆâ–…
wandb:  valid_error_force â–…â–ˆâ–‡â–‚â–†â–ƒâ–„â–„â–…â–„â–ˆâ–…â–„â–…â–‚â–‚â–…â–â–‡â–†
wandb:         valid_loss â–ƒâ–‡â–†â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–…â–…â–„â–„â–„â–…â–â–â–…â–‚â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1597
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.59586
wandb:   test_error_force 8.89371
wandb:          test_loss 4.92601
wandb: train_error_energy 1.79146
wandb:  train_error_force 3.04661
wandb:         train_loss 1.38777
wandb: valid_error_energy 2.05064
wandb:  valid_error_force 2.78379
wandb:         valid_loss 1.38849
wandb: 
wandb: ğŸš€ View run al_54_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/boz9xbnh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_093727-boz9xbnh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.667975902557373, Uncertainty Bias: 0.03336140513420105
9.918213e-05 0.063869
0.5981886 3.5665798
Found uncertainty sample 0 after 945 steps.
Found uncertainty sample 1 after 1179 steps.
Found uncertainty sample 2 after 2596 steps.
Found uncertainty sample 4 after 476 steps.
Found uncertainty sample 6 after 280 steps.
Found uncertainty sample 7 after 546 steps.
Found uncertainty sample 9 after 1613 steps.
Found uncertainty sample 11 after 950 steps.
Found uncertainty sample 12 after 2339 steps.
Found uncertainty sample 14 after 2701 steps.
Found uncertainty sample 16 after 1088 steps.
Found uncertainty sample 17 after 109 steps.
Found uncertainty sample 18 after 127 steps.
Found uncertainty sample 19 after 2912 steps.
Found uncertainty sample 21 after 3967 steps.
Found uncertainty sample 22 after 2163 steps.
Found uncertainty sample 25 after 2198 steps.
Found uncertainty sample 26 after 579 steps.
Found uncertainty sample 29 after 2183 steps.
Found uncertainty sample 34 after 1868 steps.
Found uncertainty sample 35 after 3416 steps.
Found uncertainty sample 36 after 172 steps.
Found uncertainty sample 37 after 3391 steps.
Found uncertainty sample 38 after 3224 steps.
Found uncertainty sample 39 after 2504 steps.
Found uncertainty sample 41 after 787 steps.
Found uncertainty sample 42 after 40 steps.
Found uncertainty sample 47 after 2566 steps.
Found uncertainty sample 48 after 375 steps.
Found uncertainty sample 50 after 5 steps.
Found uncertainty sample 52 after 527 steps.
Found uncertainty sample 53 after 1436 steps.
Found uncertainty sample 55 after 380 steps.
Found uncertainty sample 57 after 136 steps.
Found uncertainty sample 58 after 685 steps.
Found uncertainty sample 59 after 3474 steps.
Found uncertainty sample 60 after 3196 steps.
Found uncertainty sample 62 after 971 steps.
Found uncertainty sample 64 after 3447 steps.
Found uncertainty sample 71 after 2155 steps.
Found uncertainty sample 75 after 2426 steps.
Found uncertainty sample 77 after 691 steps.
Found uncertainty sample 78 after 3833 steps.
Found uncertainty sample 79 after 1883 steps.
Found uncertainty sample 80 after 1904 steps.
Found uncertainty sample 81 after 1967 steps.
Found uncertainty sample 83 after 777 steps.
Found uncertainty sample 84 after 2154 steps.
Found uncertainty sample 85 after 5 steps.
Found uncertainty sample 87 after 1303 steps.
Found uncertainty sample 89 after 370 steps.
Found uncertainty sample 95 after 1160 steps.
Found uncertainty sample 96 after 628 steps.
Found uncertainty sample 97 after 2176 steps.
Found uncertainty sample 98 after 224 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_114701-v41zk8rh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/v41zk8rh
Training model 11. Added 55 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.572436229680209, Training Loss Force: 3.389324978675339, time: 1.87371826171875
Validation Loss Energy: 1.231054540908735, Validation Loss Force: 2.7957275830866966, time: 0.13110136985778809
Test Loss Energy: 11.108781339462313, Test Loss Force: 8.830163621883202, time: 17.70105481147766


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7322194347380702, Training Loss Force: 3.072698886630035, time: 1.867426872253418
Validation Loss Energy: 1.1970167229220618, Validation Loss Force: 2.6506598591950454, time: 0.13212966918945312
Test Loss Energy: 10.965868816827314, Test Loss Force: 8.832329374276533, time: 17.888248205184937


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.153169310302545, Training Loss Force: 3.0869861868883555, time: 1.8906712532043457
Validation Loss Energy: 1.9082376731902042, Validation Loss Force: 2.7926177857946692, time: 0.13525390625
Test Loss Energy: 11.563781606959882, Test Loss Force: 8.861322795010201, time: 17.876652479171753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7303920961099144, Training Loss Force: 3.0765222743032763, time: 1.8740546703338623
Validation Loss Energy: 1.3610710552159704, Validation Loss Force: 2.6943073538452373, time: 0.12564659118652344
Test Loss Energy: 10.614043736701284, Test Loss Force: 8.825643825268807, time: 17.702600955963135


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6036977465810611, Training Loss Force: 3.066838273248105, time: 1.904601812362671
Validation Loss Energy: 1.3216034501058482, Validation Loss Force: 2.730941104402423, time: 0.13020110130310059
Test Loss Energy: 11.057595737030786, Test Loss Force: 8.784028981072709, time: 17.88482689857483


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8877776073820565, Training Loss Force: 3.0598433960831173, time: 1.8968510627746582
Validation Loss Energy: 1.318587841862548, Validation Loss Force: 2.864171179823688, time: 0.13687777519226074
Test Loss Energy: 10.71817133247127, Test Loss Force: 8.849639986117246, time: 17.87088418006897


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7535636983142018, Training Loss Force: 3.0676578584248806, time: 1.9822759628295898
Validation Loss Energy: 1.5073433635198044, Validation Loss Force: 2.750434452113525, time: 0.1315457820892334
Test Loss Energy: 11.124915143700994, Test Loss Force: 8.820449110312454, time: 17.725718021392822


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.895170771135526, Training Loss Force: 3.072361161767147, time: 1.847630500793457
Validation Loss Energy: 1.8520495635759322, Validation Loss Force: 2.892629410018989, time: 0.13407254219055176
Test Loss Energy: 10.518596175950732, Test Loss Force: 8.832485177393487, time: 17.89314913749695


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7331289932371459, Training Loss Force: 3.0628348875450744, time: 1.9076566696166992
Validation Loss Energy: 1.4140309075525812, Validation Loss Force: 2.813384912355051, time: 0.1297757625579834
Test Loss Energy: 10.993137202200378, Test Loss Force: 8.800147461943563, time: 17.80749011039734


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6815194579866284, Training Loss Force: 3.054994544197196, time: 2.0930898189544678
Validation Loss Energy: 1.7216163239620932, Validation Loss Force: 2.829210342559858, time: 0.13071393966674805
Test Loss Energy: 10.567491112095482, Test Loss Force: 8.810542469077177, time: 18.22052240371704


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3628781762987128, Training Loss Force: 3.0822102934045175, time: 1.8959569931030273
Validation Loss Energy: 1.4149888302183626, Validation Loss Force: 2.735635081333154, time: 0.13404130935668945
Test Loss Energy: 10.509209829737188, Test Loss Force: 8.750167369283567, time: 17.942160606384277


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7441187893249965, Training Loss Force: 3.0692836129623875, time: 1.9011216163635254
Validation Loss Energy: 2.3015971372988404, Validation Loss Force: 2.7798659691456766, time: 0.13271236419677734
Test Loss Energy: 10.449342177771653, Test Loss Force: 8.794829814965748, time: 17.802791118621826


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8867538988299504, Training Loss Force: 3.060424896557708, time: 1.8985426425933838
Validation Loss Energy: 1.6140677388191227, Validation Loss Force: 2.7643370229086726, time: 0.13966870307922363
Test Loss Energy: 10.435722063371017, Test Loss Force: 8.698992324400658, time: 17.932763814926147


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3098306908068826, Training Loss Force: 3.088775166474026, time: 1.933851957321167
Validation Loss Energy: 1.4118769175694488, Validation Loss Force: 2.701252181837579, time: 0.13082122802734375
Test Loss Energy: 10.59143351991261, Test Loss Force: 8.735346011965197, time: 17.97539472579956


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.808597636667349, Training Loss Force: 3.0444385022529894, time: 1.8625514507293701
Validation Loss Energy: 1.4215585163671025, Validation Loss Force: 2.7970501264789345, time: 0.13027667999267578
Test Loss Energy: 10.545895156763926, Test Loss Force: 8.696993361689891, time: 17.81847620010376


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7967745815902192, Training Loss Force: 3.059628117839995, time: 1.8889901638031006
Validation Loss Energy: 1.4178121636541539, Validation Loss Force: 2.8013582177797725, time: 0.1304943561553955
Test Loss Energy: 10.686919505663425, Test Loss Force: 8.722050225084967, time: 17.89438247680664


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9081940642943942, Training Loss Force: 3.0583410944586316, time: 1.8930838108062744
Validation Loss Energy: 1.2841564004931614, Validation Loss Force: 2.7558985302854473, time: 0.130964994430542
Test Loss Energy: 10.826882023515063, Test Loss Force: 8.751255785395319, time: 17.926427364349365


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8596533809056472, Training Loss Force: 3.055095182086958, time: 1.9003064632415771
Validation Loss Energy: 1.4592680372355518, Validation Loss Force: 2.759954560113095, time: 0.12925291061401367
Test Loss Energy: 10.53824424957308, Test Loss Force: 8.752223768975911, time: 17.878906726837158


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6456027941444584, Training Loss Force: 3.0590449644752056, time: 1.9118521213531494
Validation Loss Energy: 1.4381938499229352, Validation Loss Force: 2.7464929855614573, time: 0.1341402530670166
Test Loss Energy: 10.999766549981993, Test Loss Force: 8.721559574204818, time: 17.91133952140808


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.623784024759403, Training Loss Force: 3.044084822289376, time: 1.8596489429473877
Validation Loss Energy: 1.5708109171854612, Validation Loss Force: 2.842627160613164, time: 0.13284087181091309
Test Loss Energy: 10.404868690758834, Test Loss Force: 8.734113581377347, time: 17.919892072677612

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–ˆâ–‚â–…â–ƒâ–…â–‚â–…â–‚â–‚â–â–â–‚â–‚â–ƒâ–„â–‚â–…â–
wandb:   test_error_force â–‡â–‡â–ˆâ–†â–…â–ˆâ–†â–‡â–…â–†â–ƒâ–…â–â–ƒâ–â–‚â–ƒâ–ƒâ–‚â–ƒ
wandb:          test_loss â–†â–…â–ˆâ–…â–„â–…â–…â–„â–„â–„â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–â–‚â–â–â–ƒâ–â–‚â–ƒâ–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–â–‚â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–â–â–
wandb: valid_error_energy â–â–â–†â–‚â–‚â–‚â–ƒâ–…â–‚â–„â–‚â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb:  valid_error_force â–…â–â–…â–‚â–ƒâ–‡â–„â–ˆâ–†â–†â–ƒâ–…â–„â–‚â–…â–…â–„â–„â–„â–‡
wandb:         valid_loss â–‡â–â–†â–ƒâ–ƒâ–ˆâ–…â–ˆâ–ˆâ–†â–…â–‡â–ˆâ–…â–†â–‡â–†â–†â–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1646
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.40487
wandb:   test_error_force 8.73411
wandb:          test_loss 4.84853
wandb: train_error_energy 1.62378
wandb:  train_error_force 3.04408
wandb:         train_loss 1.37405
wandb: valid_error_energy 1.57081
wandb:  valid_error_force 2.84263
wandb:         valid_loss 1.43954
wandb: 
wandb: ğŸš€ View run al_54_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/v41zk8rh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_114701-v41zk8rh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6685130000114441, Uncertainty Bias: 0.03190276026725769
8.058548e-05 0.0006046295
0.64161867 4.0072865
Found uncertainty sample 0 after 536 steps.
Found uncertainty sample 1 after 114 steps.
Found uncertainty sample 2 after 2135 steps.
Found uncertainty sample 5 after 53 steps.
Found uncertainty sample 7 after 389 steps.
Found uncertainty sample 8 after 1170 steps.
Found uncertainty sample 9 after 1163 steps.
Found uncertainty sample 10 after 32 steps.
Found uncertainty sample 11 after 1217 steps.
Found uncertainty sample 13 after 291 steps.
Found uncertainty sample 15 after 1690 steps.
Found uncertainty sample 16 after 144 steps.
Found uncertainty sample 17 after 1526 steps.
Found uncertainty sample 18 after 3962 steps.
Found uncertainty sample 19 after 715 steps.
Found uncertainty sample 23 after 7 steps.
Found uncertainty sample 24 after 2278 steps.
Found uncertainty sample 25 after 2815 steps.
Found uncertainty sample 26 after 2390 steps.
Found uncertainty sample 27 after 3918 steps.
Found uncertainty sample 28 after 591 steps.
Found uncertainty sample 30 after 670 steps.
Found uncertainty sample 32 after 520 steps.
Found uncertainty sample 33 after 1277 steps.
Found uncertainty sample 35 after 3335 steps.
Found uncertainty sample 36 after 1706 steps.
Found uncertainty sample 38 after 531 steps.
Found uncertainty sample 39 after 2587 steps.
Found uncertainty sample 40 after 50 steps.
Found uncertainty sample 41 after 323 steps.
Found uncertainty sample 42 after 662 steps.
Found uncertainty sample 43 after 1750 steps.
Found uncertainty sample 44 after 2410 steps.
Found uncertainty sample 45 after 2742 steps.
Found uncertainty sample 47 after 1276 steps.
Found uncertainty sample 49 after 3680 steps.
Found uncertainty sample 50 after 543 steps.
Found uncertainty sample 51 after 1645 steps.
Found uncertainty sample 52 after 3402 steps.
Found uncertainty sample 53 after 3851 steps.
Found uncertainty sample 54 after 21 steps.
Found uncertainty sample 55 after 1580 steps.
Found uncertainty sample 56 after 413 steps.
Found uncertainty sample 60 after 3984 steps.
Found uncertainty sample 61 after 1772 steps.
Found uncertainty sample 62 after 1014 steps.
Found uncertainty sample 65 after 3740 steps.
Found uncertainty sample 67 after 704 steps.
Found uncertainty sample 68 after 724 steps.
Found uncertainty sample 69 after 45 steps.
Found uncertainty sample 72 after 296 steps.
Found uncertainty sample 74 after 1500 steps.
Found uncertainty sample 75 after 1383 steps.
Found uncertainty sample 80 after 597 steps.
Found uncertainty sample 81 after 1753 steps.
Found uncertainty sample 83 after 190 steps.
Found uncertainty sample 84 after 16 steps.
Found uncertainty sample 86 after 3095 steps.
Found uncertainty sample 87 after 1717 steps.
Found uncertainty sample 90 after 2503 steps.
Found uncertainty sample 93 after 1838 steps.
Found uncertainty sample 94 after 2175 steps.
Found uncertainty sample 95 after 3450 steps.
Found uncertainty sample 96 after 1511 steps.
Found uncertainty sample 97 after 3389 steps.
Found uncertainty sample 98 after 3907 steps.
Found uncertainty sample 99 after 1417 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_134324-c7q06wx8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/c7q06wx8
Training model 12. Added 67 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6130207808252806, Training Loss Force: 3.2756672211170077, time: 1.9645130634307861
Validation Loss Energy: 1.3355685352637148, Validation Loss Force: 2.7456386040485325, time: 0.136427640914917
Test Loss Energy: 10.927835401827233, Test Loss Force: 8.725915509643949, time: 17.800838232040405


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6487337343001012, Training Loss Force: 3.099445642596459, time: 1.9272444248199463
Validation Loss Energy: 1.3304523776323052, Validation Loss Force: 2.6617515660265734, time: 0.13149523735046387
Test Loss Energy: 10.957564097065283, Test Loss Force: 8.7415773438946, time: 18.001559734344482


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9081819378659277, Training Loss Force: 3.084888605946403, time: 1.9628171920776367
Validation Loss Energy: 1.5414305027223003, Validation Loss Force: 2.808029496726342, time: 0.13086485862731934
Test Loss Energy: 11.065687715659703, Test Loss Force: 8.683428347993512, time: 17.94561743736267


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9807328917304545, Training Loss Force: 3.093152596058767, time: 1.961350679397583
Validation Loss Energy: 2.7840666225836044, Validation Loss Force: 2.7591963716712105, time: 0.13737201690673828
Test Loss Energy: 10.366853392400257, Test Loss Force: 8.735145166727186, time: 17.890450477600098


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9308932423449405, Training Loss Force: 3.0920027738242224, time: 1.9795691967010498
Validation Loss Energy: 1.7512737388427881, Validation Loss Force: 2.7553554402385294, time: 0.14132380485534668
Test Loss Energy: 11.403742035798519, Test Loss Force: 8.693704274932143, time: 17.9316828250885


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7928598326395264, Training Loss Force: 3.0806465278003277, time: 1.9521715641021729
Validation Loss Energy: 1.2018994119539665, Validation Loss Force: 2.6931235333309127, time: 0.13288593292236328
Test Loss Energy: 10.8413306909735, Test Loss Force: 8.62702283984697, time: 17.96220111846924


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6603675013337469, Training Loss Force: 3.0870480966821394, time: 2.0106725692749023
Validation Loss Energy: 2.524673990432822, Validation Loss Force: 2.759416702791106, time: 0.13513684272766113
Test Loss Energy: 11.842738938876254, Test Loss Force: 8.635569930894022, time: 17.82882046699524


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8725518643605088, Training Loss Force: 3.0983063724053297, time: 1.9402761459350586
Validation Loss Energy: 1.4048598334392535, Validation Loss Force: 2.7514670802777657, time: 0.13097381591796875
Test Loss Energy: 10.447507425978262, Test Loss Force: 8.676194463972967, time: 17.907667636871338


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.684483794518029, Training Loss Force: 3.100336199598591, time: 1.9716556072235107
Validation Loss Energy: 1.4049486784284786, Validation Loss Force: 2.7652492983995387, time: 0.13202667236328125
Test Loss Energy: 10.561363378443483, Test Loss Force: 8.710024533686653, time: 17.964733600616455


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8249204125246532, Training Loss Force: 3.0719052381266607, time: 1.949944257736206
Validation Loss Energy: 1.2444757010103866, Validation Loss Force: 2.8032472314792507, time: 0.12628626823425293
Test Loss Energy: 10.620394321365112, Test Loss Force: 8.647215475930535, time: 18.200909852981567


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7054352560814667, Training Loss Force: 3.0852126679002794, time: 1.9589438438415527
Validation Loss Energy: 2.098976787266672, Validation Loss Force: 2.8094250755984445, time: 0.13747882843017578
Test Loss Energy: 10.324369714181277, Test Loss Force: 8.718957460233892, time: 17.965182304382324


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7931623616622911, Training Loss Force: 3.070899746733705, time: 1.9576213359832764
Validation Loss Energy: 1.4460325275343175, Validation Loss Force: 2.8721229176939156, time: 0.13456106185913086
Test Loss Energy: 10.349003543504914, Test Loss Force: 8.627614109201708, time: 17.847262382507324


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8148561650467274, Training Loss Force: 3.0861818229874216, time: 2.2156200408935547
Validation Loss Energy: 1.3658862198293722, Validation Loss Force: 2.792963368309149, time: 0.13010907173156738
Test Loss Energy: 10.658419333228002, Test Loss Force: 8.682389604588408, time: 17.77535581588745


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9194523820455927, Training Loss Force: 3.0897313382371214, time: 1.9849269390106201
Validation Loss Energy: 1.3973062836692316, Validation Loss Force: 2.730900912621583, time: 0.13274836540222168
Test Loss Energy: 10.877361571230027, Test Loss Force: 8.591949917230439, time: 18.007156372070312


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8092324062944074, Training Loss Force: 3.087217865411899, time: 2.0032594203948975
Validation Loss Energy: 1.3131604484324177, Validation Loss Force: 2.910486362176668, time: 0.12978100776672363
Test Loss Energy: 10.758761819321219, Test Loss Force: 8.601126343563918, time: 17.871548414230347


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6970250321310174, Training Loss Force: 3.0666451743744423, time: 2.148214340209961
Validation Loss Energy: 1.9336039752924385, Validation Loss Force: 2.7151795802424976, time: 0.1398918628692627
Test Loss Energy: 10.32548911744433, Test Loss Force: 8.661306604357423, time: 17.86036992073059


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7490770046306428, Training Loss Force: 3.0738654812118207, time: 1.987567663192749
Validation Loss Energy: 2.1506359177873455, Validation Loss Force: 2.70959470405891, time: 0.12862610816955566
Test Loss Energy: 11.500963507204307, Test Loss Force: 8.598573347375485, time: 17.98356866836548


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8315940191884974, Training Loss Force: 3.0678198901948, time: 1.9742646217346191
Validation Loss Energy: 2.572080028931702, Validation Loss Force: 2.8091283689614954, time: 0.1271352767944336
Test Loss Energy: 10.210928192131489, Test Loss Force: 8.622642534377333, time: 18.17378067970276


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.937649279889557, Training Loss Force: 3.074274441962836, time: 2.092083215713501
Validation Loss Energy: 1.2651554855982785, Validation Loss Force: 2.786528675330128, time: 0.17118144035339355
Test Loss Energy: 10.68946197694584, Test Loss Force: 8.646823895333219, time: 17.87113857269287


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0510235908854577, Training Loss Force: 3.0912852596129947, time: 2.0098304748535156
Validation Loss Energy: 1.7501118512393368, Validation Loss Force: 2.821652840412496, time: 0.13476133346557617
Test Loss Energy: 10.2622312706075, Test Loss Force: 8.628353720508304, time: 17.97901940345764

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–…â–‚â–†â–„â–ˆâ–‚â–ƒâ–ƒâ–â–‚â–ƒâ–„â–ƒâ–â–‡â–â–ƒâ–
wandb:   test_error_force â–‡â–ˆâ–…â–ˆâ–†â–ƒâ–ƒâ–…â–‡â–„â–‡â–ƒâ–…â–â–â–„â–â–‚â–„â–ƒ
wandb:          test_loss â–‡â–ˆâ–…â–ƒâ–…â–„â–…â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–„â–â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–‚â–‚â–ƒâ–ˆâ–ƒâ–â–‡â–‚â–‚â–â–…â–‚â–‚â–‚â–â–„â–…â–‡â–â–ƒ
wandb:  valid_error_force â–ƒâ–â–…â–„â–„â–‚â–„â–„â–„â–…â–…â–‡â–…â–ƒâ–ˆâ–ƒâ–‚â–…â–…â–†
wandb:         valid_loss â–‚â–‚â–ƒâ–‡â–ƒâ–ƒâ–‡â–…â–„â–‚â–†â–ˆâ–…â–â–†â–ƒâ–ƒâ–ˆâ–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1706
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.26223
wandb:   test_error_force 8.62835
wandb:          test_loss 4.80894
wandb: train_error_energy 2.05102
wandb:  train_error_force 3.09129
wandb:         train_loss 1.43425
wandb: valid_error_energy 1.75011
wandb:  valid_error_force 2.82165
wandb:         valid_loss 1.42118
wandb: 
wandb: ğŸš€ View run al_54_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/c7q06wx8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_134324-c7q06wx8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6563570499420166, Uncertainty Bias: 0.0329432487487793
0.000102996826 0.0030460358
0.64442974 4.530767
Found uncertainty sample 2 after 505 steps.
Found uncertainty sample 3 after 3510 steps.
Found uncertainty sample 4 after 2742 steps.
Found uncertainty sample 5 after 2426 steps.
Found uncertainty sample 9 after 117 steps.
Found uncertainty sample 10 after 1371 steps.
Found uncertainty sample 11 after 1348 steps.
Found uncertainty sample 12 after 73 steps.
Found uncertainty sample 14 after 638 steps.
Found uncertainty sample 15 after 3512 steps.
Found uncertainty sample 16 after 595 steps.
Found uncertainty sample 17 after 853 steps.
Found uncertainty sample 19 after 746 steps.
Found uncertainty sample 20 after 1642 steps.
Found uncertainty sample 22 after 1486 steps.
Found uncertainty sample 23 after 1784 steps.
Found uncertainty sample 25 after 1632 steps.
Found uncertainty sample 26 after 156 steps.
Found uncertainty sample 27 after 833 steps.
Found uncertainty sample 28 after 2163 steps.
Found uncertainty sample 30 after 225 steps.
Found uncertainty sample 33 after 2134 steps.
Found uncertainty sample 34 after 2222 steps.
Found uncertainty sample 35 after 3044 steps.
Found uncertainty sample 38 after 2011 steps.
Found uncertainty sample 39 after 2636 steps.
Found uncertainty sample 40 after 1678 steps.
Found uncertainty sample 42 after 1671 steps.
Found uncertainty sample 43 after 271 steps.
Found uncertainty sample 45 after 2056 steps.
Found uncertainty sample 48 after 385 steps.
Found uncertainty sample 49 after 3986 steps.
Found uncertainty sample 50 after 8 steps.
Found uncertainty sample 52 after 1897 steps.
Found uncertainty sample 56 after 253 steps.
Found uncertainty sample 60 after 1848 steps.
Found uncertainty sample 65 after 816 steps.
Found uncertainty sample 66 after 1481 steps.
Found uncertainty sample 68 after 2266 steps.
Found uncertainty sample 69 after 1797 steps.
Found uncertainty sample 72 after 1266 steps.
Found uncertainty sample 73 after 98 steps.
Found uncertainty sample 75 after 3533 steps.
Found uncertainty sample 76 after 147 steps.
Found uncertainty sample 77 after 2386 steps.
Found uncertainty sample 78 after 517 steps.
Found uncertainty sample 80 after 1630 steps.
Found uncertainty sample 82 after 2671 steps.
Found uncertainty sample 83 after 25 steps.
Found uncertainty sample 84 after 1806 steps.
Found uncertainty sample 86 after 1854 steps.
Found uncertainty sample 89 after 974 steps.
Found uncertainty sample 90 after 1123 steps.
Found uncertainty sample 92 after 382 steps.
Found uncertainty sample 93 after 3685 steps.
Found uncertainty sample 94 after 2150 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 3566 steps.
Found uncertainty sample 97 after 1027 steps.
Found uncertainty sample 98 after 2012 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_154703-7rlzqwlm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7rlzqwlm
Training model 13. Added 60 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8179175088101385, Training Loss Force: 3.3137945086264393, time: 1.9988951683044434
Validation Loss Energy: 1.4757997739712416, Validation Loss Force: 2.760851471432892, time: 0.13449907302856445
Test Loss Energy: 10.974832847106562, Test Loss Force: 8.637414853188089, time: 17.894994735717773


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7503162503818417, Training Loss Force: 3.1030774772798977, time: 1.9938924312591553
Validation Loss Energy: 1.3931384739303283, Validation Loss Force: 2.8066348085308235, time: 0.1383519172668457
Test Loss Energy: 10.668999992802195, Test Loss Force: 8.59994069448124, time: 17.95969533920288


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7725596227731006, Training Loss Force: 3.1048337052706, time: 1.984830379486084
Validation Loss Energy: 1.555928435146372, Validation Loss Force: 2.793080826283626, time: 0.13105535507202148
Test Loss Energy: 10.247975049913107, Test Loss Force: 8.554413621008, time: 17.963751792907715


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7995077168935139, Training Loss Force: 3.1083716993787767, time: 2.0116753578186035
Validation Loss Energy: 1.510823014263218, Validation Loss Force: 2.799521308660441, time: 0.13824129104614258
Test Loss Energy: 10.472572426706524, Test Loss Force: 8.591271837219772, time: 17.81061100959778


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.783015143612063, Training Loss Force: 3.110209104443023, time: 2.0497019290924072
Validation Loss Energy: 1.2897054269442547, Validation Loss Force: 2.769741091745767, time: 0.13399052619934082
Test Loss Energy: 10.551950843540437, Test Loss Force: 8.546258343719677, time: 18.322792768478394


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9111734332899077, Training Loss Force: 3.1056711963166737, time: 2.020231008529663
Validation Loss Energy: 3.3459519494400976, Validation Loss Force: 2.8107049778492375, time: 0.13062739372253418
Test Loss Energy: 10.150704619274585, Test Loss Force: 8.57202314111227, time: 17.96777057647705


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8448502581501667, Training Loss Force: 3.091638465284407, time: 1.9849722385406494
Validation Loss Energy: 1.2799851950497825, Validation Loss Force: 2.80059746864271, time: 0.1362154483795166
Test Loss Energy: 10.457904676124633, Test Loss Force: 8.557450534375079, time: 17.875592947006226


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7945880000069065, Training Loss Force: 3.0959945255920718, time: 2.0814812183380127
Validation Loss Energy: 1.439413464502468, Validation Loss Force: 2.7547178271391655, time: 0.14371252059936523
Test Loss Energy: 10.685355412297232, Test Loss Force: 8.59987753105545, time: 17.89989995956421


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7577896321744018, Training Loss Force: 3.075320067857431, time: 2.0752406120300293
Validation Loss Energy: 1.6888722137132606, Validation Loss Force: 2.7195549176254055, time: 0.1367499828338623
Test Loss Energy: 10.371801529839766, Test Loss Force: 8.527831760751852, time: 17.950098514556885


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8180783641491909, Training Loss Force: 3.086358218710833, time: 2.012775182723999
Validation Loss Energy: 2.327247175560273, Validation Loss Force: 2.759966695581548, time: 0.13280010223388672
Test Loss Energy: 11.558701999128095, Test Loss Force: 8.544786624240638, time: 17.88856291770935


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.766311836250906, Training Loss Force: 3.089314981571659, time: 2.014648199081421
Validation Loss Energy: 1.3870901119194916, Validation Loss Force: 2.7917560561999286, time: 0.14040613174438477
Test Loss Energy: 10.402697314512311, Test Loss Force: 8.544409826076675, time: 17.956138372421265


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.656903150997056, Training Loss Force: 3.0994127560879794, time: 2.000396490097046
Validation Loss Energy: 1.3076556774740775, Validation Loss Force: 2.761228227627802, time: 0.13301992416381836
Test Loss Energy: 10.331201408760382, Test Loss Force: 8.608858516832383, time: 17.95852279663086


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.10966630706256, Training Loss Force: 3.1011303611031873, time: 2.0160176753997803
Validation Loss Energy: 1.2632536127556226, Validation Loss Force: 2.7727859809817565, time: 0.13579869270324707
Test Loss Energy: 10.306321934565535, Test Loss Force: 8.535960369038175, time: 17.843080043792725


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6612552477939244, Training Loss Force: 3.0817979626992913, time: 2.002549886703491
Validation Loss Energy: 1.96776175628148, Validation Loss Force: 2.7465229345615847, time: 0.13280749320983887
Test Loss Energy: 10.16719857861583, Test Loss Force: 8.536209012365104, time: 17.94842791557312


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7008497247227334, Training Loss Force: 3.067408349705521, time: 1.9824199676513672
Validation Loss Energy: 1.2730961456784957, Validation Loss Force: 2.6723617508300324, time: 0.1349196434020996
Test Loss Energy: 10.545478049655516, Test Loss Force: 8.483224956708396, time: 17.85999059677124


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9723086906052998, Training Loss Force: 3.0933954382046145, time: 2.2244555950164795
Validation Loss Energy: 2.417289122779395, Validation Loss Force: 2.7385986963308797, time: 0.13390564918518066
Test Loss Energy: 10.100016275517547, Test Loss Force: 8.577193360130956, time: 17.847182750701904


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9839891984230071, Training Loss Force: 3.093133287794849, time: 1.98893141746521
Validation Loss Energy: 1.896670623399407, Validation Loss Force: 2.750253088094167, time: 0.13733553886413574
Test Loss Energy: 10.319085483896647, Test Loss Force: 8.510167447716384, time: 17.99869728088379


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6627162418004375, Training Loss Force: 3.0844242724019715, time: 1.9981739521026611
Validation Loss Energy: 1.3138086383162135, Validation Loss Force: 2.6886581262784763, time: 0.13436245918273926
Test Loss Energy: 10.422748132500251, Test Loss Force: 8.501148521914919, time: 18.24155592918396


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7297765044440878, Training Loss Force: 3.0703182386868653, time: 2.2317376136779785
Validation Loss Energy: 1.2224863435080064, Validation Loss Force: 2.752207343853402, time: 0.13084721565246582
Test Loss Energy: 10.499385219348948, Test Loss Force: 8.516974492471292, time: 17.912933111190796


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7108009222130844, Training Loss Force: 3.079844044992306, time: 1.987534761428833
Validation Loss Energy: 1.3618062530685373, Validation Loss Force: 2.7665609310036263, time: 0.1442556381225586
Test Loss Energy: 10.665805714136718, Test Loss Force: 8.52977294606538, time: 17.97244691848755

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–‚â–ƒâ–ƒâ–â–ƒâ–„â–‚â–ˆâ–‚â–‚â–‚â–â–ƒâ–â–‚â–ƒâ–ƒâ–„
wandb:   test_error_force â–ˆâ–†â–„â–†â–„â–…â–„â–†â–ƒâ–„â–„â–‡â–ƒâ–ƒâ–â–…â–‚â–‚â–ƒâ–ƒ
wandb:          test_loss â–ˆâ–ˆâ–ƒâ–…â–„â–ƒâ–„â–ˆâ–ƒâ–‡â–„â–†â–„â–‚â–â–‚â–â–‚â–„â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–„â–â–â–ƒâ–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–‚â–‚â–‚â–‚â–â–ˆâ–â–‚â–ƒâ–…â–‚â–â–â–ƒâ–â–…â–ƒâ–â–â–
wandb:  valid_error_force â–…â–ˆâ–‡â–‡â–†â–ˆâ–‡â–…â–ƒâ–…â–‡â–…â–†â–…â–â–„â–…â–‚â–…â–†
wandb:         valid_loss â–ƒâ–†â–„â–ƒâ–ƒâ–ˆâ–„â–„â–ƒâ–…â–„â–…â–…â–„â–ƒâ–†â–…â–â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1760
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.66581
wandb:   test_error_force 8.52977
wandb:          test_loss 4.71795
wandb: train_error_energy 1.7108
wandb:  train_error_force 3.07984
wandb:         train_loss 1.39166
wandb: valid_error_energy 1.36181
wandb:  valid_error_force 2.76656
wandb:         valid_loss 1.39118
wandb: 
wandb: ğŸš€ View run al_54_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7rlzqwlm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_154703-7rlzqwlm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6495673656463623, Uncertainty Bias: 0.038561612367630005
0.00022125244 0.00045967102
0.93761903 4.0911603
Found uncertainty sample 1 after 648 steps.
Found uncertainty sample 2 after 1762 steps.
Found uncertainty sample 3 after 486 steps.
Found uncertainty sample 4 after 12 steps.
Found uncertainty sample 5 after 2921 steps.
Found uncertainty sample 6 after 1382 steps.
Found uncertainty sample 8 after 1086 steps.
Found uncertainty sample 10 after 1199 steps.
Found uncertainty sample 11 after 986 steps.
Found uncertainty sample 15 after 3973 steps.
Found uncertainty sample 16 after 2657 steps.
Found uncertainty sample 18 after 721 steps.
Found uncertainty sample 21 after 1576 steps.
Found uncertainty sample 23 after 2232 steps.
Found uncertainty sample 24 after 2389 steps.
Found uncertainty sample 26 after 327 steps.
Found uncertainty sample 27 after 1297 steps.
Found uncertainty sample 28 after 1418 steps.
Found uncertainty sample 34 after 1915 steps.
Found uncertainty sample 36 after 334 steps.
Found uncertainty sample 38 after 246 steps.
Found uncertainty sample 39 after 3214 steps.
Found uncertainty sample 41 after 625 steps.
Found uncertainty sample 42 after 474 steps.
Found uncertainty sample 43 after 315 steps.
Found uncertainty sample 45 after 665 steps.
Found uncertainty sample 48 after 2791 steps.
Found uncertainty sample 50 after 173 steps.
Found uncertainty sample 53 after 5 steps.
Found uncertainty sample 54 after 1872 steps.
Found uncertainty sample 55 after 374 steps.
Found uncertainty sample 57 after 1121 steps.
Found uncertainty sample 59 after 2801 steps.
Found uncertainty sample 60 after 1095 steps.
Found uncertainty sample 64 after 2368 steps.
Found uncertainty sample 66 after 998 steps.
Found uncertainty sample 67 after 943 steps.
Found uncertainty sample 68 after 902 steps.
Found uncertainty sample 69 after 1602 steps.
Found uncertainty sample 71 after 2914 steps.
Found uncertainty sample 73 after 2288 steps.
Found uncertainty sample 74 after 3657 steps.
Found uncertainty sample 75 after 2536 steps.
Found uncertainty sample 76 after 181 steps.
Found uncertainty sample 81 after 1229 steps.
Found uncertainty sample 83 after 2972 steps.
Found uncertainty sample 84 after 1149 steps.
Found uncertainty sample 85 after 3770 steps.
Found uncertainty sample 89 after 3227 steps.
Found uncertainty sample 90 after 278 steps.
Found uncertainty sample 91 after 1298 steps.
Found uncertainty sample 95 after 51 steps.
Found uncertainty sample 97 after 1919 steps.
Found uncertainty sample 99 after 1330 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_175615-47p4kwv4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/47p4kwv4
Training model 14. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.081096985312274, Training Loss Force: 3.3400230084080507, time: 2.1058332920074463
Validation Loss Energy: 1.5769828605722875, Validation Loss Force: 2.7842480979375352, time: 0.13727688789367676
Test Loss Energy: 10.176729951225987, Test Loss Force: 8.489914478786536, time: 17.86612868309021


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8642074952440206, Training Loss Force: 3.117185884001756, time: 2.0470104217529297
Validation Loss Energy: 1.5238602370900034, Validation Loss Force: 2.836903004878798, time: 0.13266611099243164
Test Loss Energy: 10.208006036146863, Test Loss Force: 8.523627244995179, time: 17.93092441558838


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.738827358828531, Training Loss Force: 3.109392237318661, time: 2.0786118507385254
Validation Loss Energy: 1.951218663419348, Validation Loss Force: 2.723340404440751, time: 0.1371021270751953
Test Loss Energy: 10.146977510830009, Test Loss Force: 8.528124084537207, time: 18.02200412750244


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7866990805475473, Training Loss Force: 3.100984762116816, time: 2.0531907081604004
Validation Loss Energy: 1.3086414894503862, Validation Loss Force: 2.74327163102732, time: 0.13460946083068848
Test Loss Energy: 10.33853319725671, Test Loss Force: 8.487062014747165, time: 18.254666805267334


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9512868880737175, Training Loss Force: 3.0987063996962543, time: 2.0973000526428223
Validation Loss Energy: 1.873118462496333, Validation Loss Force: 2.748106334858277, time: 0.13705825805664062
Test Loss Energy: 11.136500575062948, Test Loss Force: 8.437817040373403, time: 17.994500875473022


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7302753166603113, Training Loss Force: 3.0999182706632515, time: 2.0611917972564697
Validation Loss Energy: 1.2104115523972077, Validation Loss Force: 2.727733889359052, time: 0.14154839515686035
Test Loss Energy: 10.601869213712154, Test Loss Force: 8.48440889438633, time: 18.05870819091797


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9271917621309653, Training Loss Force: 3.1148926457196553, time: 2.0746216773986816
Validation Loss Energy: 3.8907454153243197, Validation Loss Force: 2.7426222164632215, time: 0.13491582870483398
Test Loss Energy: 10.0979533239896, Test Loss Force: 8.46472088487779, time: 17.91438913345337


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0919749071420193, Training Loss Force: 3.11281704504208, time: 2.1215856075286865
Validation Loss Energy: 1.3732249495408602, Validation Loss Force: 2.7785345189876014, time: 0.13459038734436035
Test Loss Energy: 10.54695160178323, Test Loss Force: 8.46579981598341, time: 18.07631254196167


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6537270942923177, Training Loss Force: 3.094396821981205, time: 2.1007611751556396
Validation Loss Energy: 1.4114398180359924, Validation Loss Force: 2.7980274213604117, time: 0.14093685150146484
Test Loss Energy: 10.808946091427389, Test Loss Force: 8.410146188096823, time: 18.044140577316284


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7672818505260663, Training Loss Force: 3.080581002304016, time: 2.1048028469085693
Validation Loss Energy: 1.2615470207539456, Validation Loss Force: 2.7572397778859434, time: 0.13344049453735352
Test Loss Energy: 10.517506099729745, Test Loss Force: 8.413161897765335, time: 17.934813022613525


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7785566148344045, Training Loss Force: 3.099230433952052, time: 2.08221435546875
Validation Loss Energy: 1.642036486564388, Validation Loss Force: 2.7586234439587383, time: 0.13123440742492676
Test Loss Energy: 10.999921620972122, Test Loss Force: 8.461349025819723, time: 18.09493589401245


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.001766651462985, Training Loss Force: 3.0980451582753252, time: 2.0726354122161865
Validation Loss Energy: 1.2735783913812888, Validation Loss Force: 2.7708747003676857, time: 0.1379551887512207
Test Loss Energy: 10.395446288464948, Test Loss Force: 8.458703595122172, time: 18.091354608535767


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.656656318626427, Training Loss Force: 3.094382547717008, time: 2.1005027294158936
Validation Loss Energy: 1.9372420551331797, Validation Loss Force: 2.7799702896405436, time: 0.13595151901245117
Test Loss Energy: 11.11185214983508, Test Loss Force: 8.395278888654355, time: 18.007241249084473


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8433910806728635, Training Loss Force: 3.093014566146334, time: 2.0331814289093018
Validation Loss Energy: 1.741177919766422, Validation Loss Force: 2.826460044603931, time: 0.1395556926727295
Test Loss Energy: 10.122681098708295, Test Loss Force: 8.45633032907452, time: 18.050200939178467


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1129651452567644, Training Loss Force: 3.102804691737151, time: 2.099757432937622
Validation Loss Energy: 1.5467585300460605, Validation Loss Force: 2.777314960075355, time: 0.13268828392028809
Test Loss Energy: 10.8424634030898, Test Loss Force: 8.46301352781524, time: 18.012274980545044


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7505560576297006, Training Loss Force: 3.0988667253877984, time: 2.043827533721924
Validation Loss Energy: 1.3197481707819778, Validation Loss Force: 2.7637133266309286, time: 0.13820958137512207
Test Loss Energy: 10.253748112418892, Test Loss Force: 8.376868230610791, time: 17.947482347488403


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8566719865579144, Training Loss Force: 3.0938032211964477, time: 2.1054322719573975
Validation Loss Energy: 1.4148054065094047, Validation Loss Force: 2.8251152342971, time: 0.1339414119720459
Test Loss Energy: 10.661759477671167, Test Loss Force: 8.438269650969616, time: 18.392320156097412


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.09868105138907, Training Loss Force: 3.091073008388131, time: 2.034914493560791
Validation Loss Energy: 1.970628955539019, Validation Loss Force: 2.7441186644584294, time: 0.13332819938659668
Test Loss Energy: 10.141502731715203, Test Loss Force: 8.459627292024674, time: 17.981945514678955


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9498344855981644, Training Loss Force: 3.0874098665490446, time: 2.0591394901275635
Validation Loss Energy: 2.2230129649871513, Validation Loss Force: 2.7876550472048036, time: 0.139143705368042
Test Loss Energy: 11.223923727361013, Test Loss Force: 8.37852404967542, time: 17.920409679412842


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6984784663503514, Training Loss Force: 3.0823295996681295, time: 2.0714645385742188
Validation Loss Energy: 1.5665599405205537, Validation Loss Force: 2.7011157969856985, time: 0.13167428970336914
Test Loss Energy: 10.178876215988724, Test Loss Force: 8.401105895383806, time: 18.015580654144287

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–â–‚â–‡â–„â–â–„â–…â–„â–‡â–ƒâ–‡â–â–†â–‚â–…â–â–ˆâ–‚
wandb:   test_error_force â–†â–ˆâ–ˆâ–†â–„â–†â–…â–…â–ƒâ–ƒâ–…â–…â–‚â–…â–…â–â–„â–…â–â–‚
wandb:          test_loss â–‡â–„â–…â–…â–‡â–…â–ƒâ–…â–…â–…â–†â–„â–‡â–…â–ˆâ–â–„â–‚â–‡â–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–â–‚â–ƒâ–â–‚â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–
wandb: valid_error_energy â–‚â–‚â–ƒâ–â–ƒâ–â–ˆâ–â–‚â–â–‚â–â–ƒâ–‚â–‚â–â–‚â–ƒâ–„â–‚
wandb:  valid_error_force â–…â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–…â–†â–„â–„â–…â–…â–‡â–…â–„â–‡â–ƒâ–…â–
wandb:         valid_loss â–„â–ƒâ–‚â–â–ƒâ–â–ˆâ–‚â–ƒâ–‚â–ƒâ–â–…â–„â–„â–‚â–‚â–„â–‡â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1808
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.17888
wandb:   test_error_force 8.40111
wandb:          test_loss 4.63114
wandb: train_error_energy 1.69848
wandb:  train_error_force 3.08233
wandb:         train_loss 1.3986
wandb: valid_error_energy 1.56656
wandb:  valid_error_force 2.70112
wandb:         valid_loss 1.34181
wandb: 
wandb: ğŸš€ View run al_54_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/47p4kwv4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_175615-47p4kwv4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6563856601715088, Uncertainty Bias: 0.03418076038360596
6.1035156e-05 0.0034065247
0.65365475 3.4381719
Found uncertainty sample 0 after 2271 steps.
Found uncertainty sample 1 after 328 steps.
Found uncertainty sample 2 after 2936 steps.
Found uncertainty sample 4 after 16 steps.
Found uncertainty sample 5 after 1312 steps.
Found uncertainty sample 7 after 1809 steps.
Found uncertainty sample 8 after 112 steps.
Found uncertainty sample 9 after 3858 steps.
Found uncertainty sample 10 after 2251 steps.
Found uncertainty sample 11 after 3727 steps.
Found uncertainty sample 12 after 3777 steps.
Found uncertainty sample 13 after 803 steps.
Found uncertainty sample 14 after 429 steps.
Found uncertainty sample 19 after 688 steps.
Found uncertainty sample 20 after 1736 steps.
Found uncertainty sample 22 after 1266 steps.
Found uncertainty sample 23 after 1094 steps.
Found uncertainty sample 24 after 58 steps.
Found uncertainty sample 25 after 1646 steps.
Found uncertainty sample 26 after 3645 steps.
Found uncertainty sample 27 after 3522 steps.
Found uncertainty sample 28 after 1350 steps.
Found uncertainty sample 29 after 2242 steps.
Found uncertainty sample 30 after 3163 steps.
Found uncertainty sample 33 after 2853 steps.
Found uncertainty sample 35 after 2588 steps.
Found uncertainty sample 36 after 474 steps.
Found uncertainty sample 37 after 1079 steps.
Found uncertainty sample 39 after 1706 steps.
Found uncertainty sample 41 after 3603 steps.
Found uncertainty sample 42 after 11 steps.
Found uncertainty sample 43 after 3876 steps.
Found uncertainty sample 44 after 246 steps.
Found uncertainty sample 45 after 2962 steps.
Found uncertainty sample 46 after 1590 steps.
Found uncertainty sample 48 after 1814 steps.
Found uncertainty sample 51 after 1163 steps.
Found uncertainty sample 53 after 431 steps.
Found uncertainty sample 54 after 1900 steps.
Found uncertainty sample 57 after 2972 steps.
Found uncertainty sample 58 after 740 steps.
Found uncertainty sample 62 after 1442 steps.
Found uncertainty sample 63 after 196 steps.
Found uncertainty sample 64 after 745 steps.
Found uncertainty sample 66 after 1638 steps.
Found uncertainty sample 68 after 842 steps.
Found uncertainty sample 69 after 433 steps.
Found uncertainty sample 70 after 2085 steps.
Found uncertainty sample 72 after 217 steps.
Found uncertainty sample 73 after 1121 steps.
Found uncertainty sample 78 after 624 steps.
Found uncertainty sample 79 after 2824 steps.
Found uncertainty sample 82 after 155 steps.
Found uncertainty sample 83 after 3507 steps.
Found uncertainty sample 86 after 30 steps.
Found uncertainty sample 87 after 1759 steps.
Found uncertainty sample 88 after 2653 steps.
Found uncertainty sample 89 after 1676 steps.
Found uncertainty sample 90 after 624 steps.
Found uncertainty sample 94 after 513 steps.
Found uncertainty sample 96 after 3436 steps.
Found uncertainty sample 97 after 3366 steps.
Found uncertainty sample 98 after 2115 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_200104-bmaqfugf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/bmaqfugf
Training model 15. Added 63 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.57865250596417, Training Loss Force: 3.3771299058724003, time: 2.1086199283599854
Validation Loss Energy: 1.9679429532989787, Validation Loss Force: 2.8140467963913216, time: 0.14492130279541016
Test Loss Energy: 10.922857918692742, Test Loss Force: 8.36751580005585, time: 17.93541169166565


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.958157122696711, Training Loss Force: 3.139220536334757, time: 2.1135494709014893
Validation Loss Energy: 1.4038170738288738, Validation Loss Force: 2.8382839989218427, time: 0.1309223175048828
Test Loss Energy: 10.363873762128225, Test Loss Force: 8.359527470999847, time: 17.942792892456055


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9334343561270146, Training Loss Force: 3.110253997767943, time: 2.140986919403076
Validation Loss Energy: 2.2325178201502247, Validation Loss Force: 2.8140569278374614, time: 0.13772010803222656
Test Loss Energy: 10.965343014533092, Test Loss Force: 8.326708044078211, time: 18.031999349594116


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8800492925249082, Training Loss Force: 3.1027180888666557, time: 2.1992270946502686
Validation Loss Energy: 1.8199278692572545, Validation Loss Force: 2.7682006665942387, time: 0.13152670860290527
Test Loss Energy: 10.993013197636431, Test Loss Force: 8.303091843062445, time: 18.209505081176758


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8212627490862845, Training Loss Force: 3.1032004581696944, time: 2.1474812030792236
Validation Loss Energy: 1.233191162698485, Validation Loss Force: 2.7698901687389657, time: 0.14123868942260742
Test Loss Energy: 10.244773389357412, Test Loss Force: 8.351753072200149, time: 18.041855096817017


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8590211411146984, Training Loss Force: 3.1104577702288942, time: 2.137342929840088
Validation Loss Energy: 1.4215967597929158, Validation Loss Force: 2.77410084228846, time: 0.13783669471740723
Test Loss Energy: 10.11270631371952, Test Loss Force: 8.346337329554194, time: 18.02785086631775


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6587638994731417, Training Loss Force: 3.106314863580827, time: 2.174699544906616
Validation Loss Energy: 1.2886781985068034, Validation Loss Force: 2.851674764685075, time: 0.13588762283325195
Test Loss Energy: 10.034233617043448, Test Loss Force: 8.32122656856773, time: 17.890694856643677


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.008336158195216, Training Loss Force: 3.1227110834969, time: 2.135923385620117
Validation Loss Energy: 1.342038354300506, Validation Loss Force: 2.7932081930350967, time: 0.13432884216308594
Test Loss Energy: 10.421630417325801, Test Loss Force: 8.325177525954965, time: 17.98821711540222


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7928009278792492, Training Loss Force: 3.1180868152180317, time: 2.147366762161255
Validation Loss Energy: 1.5869371177391298, Validation Loss Force: 2.7450070030161084, time: 0.1331033706665039
Test Loss Energy: 10.84710090891009, Test Loss Force: 8.319699771700577, time: 18.019374132156372


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.877240864712707, Training Loss Force: 3.1010270223768273, time: 2.146843194961548
Validation Loss Energy: 1.2167041824611267, Validation Loss Force: 2.753903080734215, time: 0.142103910446167
Test Loss Energy: 10.174034665955885, Test Loss Force: 8.335113002261737, time: 17.941550970077515


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9596478077124975, Training Loss Force: 3.129380526366529, time: 2.16894793510437
Validation Loss Energy: 1.3141450357284241, Validation Loss Force: 2.7473698566581213, time: 0.1388258934020996
Test Loss Energy: 10.055991535616391, Test Loss Force: 8.292943921737548, time: 17.993289470672607


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1770628034102804, Training Loss Force: 3.116479596870831, time: 2.164238452911377
Validation Loss Energy: 1.417073403095252, Validation Loss Force: 2.772565649861861, time: 0.1367034912109375
Test Loss Energy: 10.101579464217473, Test Loss Force: 8.272833195257087, time: 18.080817937850952


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8951349101534496, Training Loss Force: 3.1000352124862784, time: 2.188915729522705
Validation Loss Energy: 1.343513092053986, Validation Loss Force: 2.8184813637670465, time: 0.1409313678741455
Test Loss Energy: 10.364883663466996, Test Loss Force: 8.31762452790313, time: 17.979785203933716


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7465056159170036, Training Loss Force: 3.0971058602316255, time: 2.1488707065582275
Validation Loss Energy: 2.110323116266568, Validation Loss Force: 2.790540393997736, time: 0.13155078887939453
Test Loss Energy: 10.95865457432389, Test Loss Force: 8.285282662180121, time: 18.06222414970398


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0809719035409766, Training Loss Force: 3.1237163969502304, time: 2.1632883548736572
Validation Loss Energy: 2.409114381759521, Validation Loss Force: 2.7635524481729963, time: 0.13382339477539062
Test Loss Energy: 9.719860955654458, Test Loss Force: 8.254225049499807, time: 18.026967763900757


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8769942680687255, Training Loss Force: 3.102026135060552, time: 2.1701905727386475
Validation Loss Energy: 1.298916971174855, Validation Loss Force: 2.820724755412269, time: 0.1349482536315918
Test Loss Energy: 10.239044520265157, Test Loss Force: 8.311858847287565, time: 18.250791311264038


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8523171354647578, Training Loss Force: 3.10008491299446, time: 2.134371042251587
Validation Loss Energy: 1.9650240391322977, Validation Loss Force: 2.787771057829832, time: 0.13463211059570312
Test Loss Energy: 9.842650021196045, Test Loss Force: 8.313441369731551, time: 17.993605852127075


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.097833830314677, Training Loss Force: 3.1096498850528813, time: 2.1642684936523438
Validation Loss Energy: 1.5845748764372685, Validation Loss Force: 2.795210990668144, time: 0.1339130401611328
Test Loss Energy: 9.91008619976328, Test Loss Force: 8.25328373958444, time: 18.024506092071533


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9349100449419314, Training Loss Force: 3.11377369121709, time: 2.223698139190674
Validation Loss Energy: 1.8313316468968002, Validation Loss Force: 2.7597665160193587, time: 0.133192777633667
Test Loss Energy: 9.734218391716647, Test Loss Force: 8.267782609025923, time: 17.994076251983643


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8480796321702058, Training Loss Force: 3.099797164073068, time: 2.1141090393066406
Validation Loss Energy: 1.4071184779209718, Validation Loss Force: 2.7261448109991386, time: 0.14003801345825195
Test Loss Energy: 10.295019612450043, Test Loss Force: 8.210443340730452, time: 17.992441177368164

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–ˆâ–ˆâ–„â–ƒâ–ƒâ–…â–‡â–ƒâ–ƒâ–ƒâ–…â–ˆâ–â–„â–‚â–‚â–â–„
wandb:   test_error_force â–ˆâ–ˆâ–†â–…â–‡â–‡â–†â–†â–†â–‡â–…â–„â–†â–„â–ƒâ–†â–†â–ƒâ–„â–
wandb:          test_loss â–‡â–‡â–ˆâ–ˆâ–†â–…â–…â–†â–‡â–…â–„â–ƒâ–…â–‡â–â–†â–„â–ƒâ–ƒâ–„
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–
wandb: valid_error_energy â–…â–‚â–‡â–…â–â–‚â–â–‚â–ƒâ–â–‚â–‚â–‚â–†â–ˆâ–â–…â–ƒâ–…â–‚
wandb:  valid_error_force â–†â–‡â–†â–ƒâ–ƒâ–„â–ˆâ–…â–‚â–ƒâ–‚â–„â–†â–…â–ƒâ–†â–„â–…â–ƒâ–
wandb:         valid_loss â–„â–…â–†â–†â–‚â–ƒâ–‡â–ƒâ–„â–ƒâ–â–„â–„â–…â–ˆâ–†â–…â–„â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1864
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.29502
wandb:   test_error_force 8.21044
wandb:          test_loss 4.58121
wandb: train_error_energy 1.84808
wandb:  train_error_force 3.0998
wandb:         train_loss 1.41138
wandb: valid_error_energy 1.40712
wandb:  valid_error_force 2.72614
wandb:         valid_loss 1.39909
wandb: 
wandb: ğŸš€ View run al_54_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/bmaqfugf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_200104-bmaqfugf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6809312701225281, Uncertainty Bias: 0.028575077652931213
3.8146973e-06 0.0017790794
0.9159119 4.366051
Found uncertainty sample 0 after 3033 steps.
Found uncertainty sample 1 after 2652 steps.
Found uncertainty sample 2 after 3338 steps.
Found uncertainty sample 3 after 1442 steps.
Found uncertainty sample 4 after 2787 steps.
Found uncertainty sample 6 after 3019 steps.
Found uncertainty sample 8 after 1459 steps.
Found uncertainty sample 11 after 3180 steps.
Found uncertainty sample 12 after 2045 steps.
Found uncertainty sample 13 after 1467 steps.
Found uncertainty sample 14 after 756 steps.
Found uncertainty sample 15 after 2370 steps.
Found uncertainty sample 18 after 1557 steps.
Found uncertainty sample 19 after 167 steps.
Found uncertainty sample 21 after 1768 steps.
Found uncertainty sample 24 after 1669 steps.
Found uncertainty sample 26 after 1256 steps.
Found uncertainty sample 27 after 1222 steps.
Found uncertainty sample 28 after 1735 steps.
Found uncertainty sample 29 after 1352 steps.
Found uncertainty sample 31 after 370 steps.
Found uncertainty sample 34 after 1287 steps.
Found uncertainty sample 36 after 156 steps.
Found uncertainty sample 38 after 1350 steps.
Found uncertainty sample 39 after 1936 steps.
Found uncertainty sample 40 after 1218 steps.
Found uncertainty sample 41 after 731 steps.
Found uncertainty sample 42 after 1980 steps.
Found uncertainty sample 43 after 1688 steps.
Found uncertainty sample 44 after 1097 steps.
Found uncertainty sample 45 after 835 steps.
Found uncertainty sample 46 after 654 steps.
Found uncertainty sample 47 after 1888 steps.
Found uncertainty sample 50 after 1278 steps.
Found uncertainty sample 53 after 273 steps.
Found uncertainty sample 54 after 2766 steps.
Found uncertainty sample 56 after 99 steps.
Found uncertainty sample 58 after 2324 steps.
Found uncertainty sample 60 after 2159 steps.
Found uncertainty sample 61 after 4 steps.
Found uncertainty sample 62 after 2071 steps.
Found uncertainty sample 64 after 2271 steps.
Found uncertainty sample 65 after 1693 steps.
Found uncertainty sample 66 after 63 steps.
Found uncertainty sample 68 after 3439 steps.
Found uncertainty sample 69 after 2301 steps.
Found uncertainty sample 71 after 1282 steps.
Found uncertainty sample 72 after 1849 steps.
Found uncertainty sample 74 after 120 steps.
Found uncertainty sample 75 after 981 steps.
Found uncertainty sample 76 after 21 steps.
Found uncertainty sample 77 after 390 steps.
Found uncertainty sample 78 after 2020 steps.
Found uncertainty sample 79 after 1744 steps.
Found uncertainty sample 80 after 1413 steps.
Found uncertainty sample 84 after 1215 steps.
Found uncertainty sample 85 after 1543 steps.
Found uncertainty sample 86 after 1428 steps.
Found uncertainty sample 87 after 815 steps.
Found uncertainty sample 88 after 2600 steps.
Found uncertainty sample 89 after 1229 steps.
Found uncertainty sample 90 after 957 steps.
Found uncertainty sample 91 after 793 steps.
Found uncertainty sample 92 after 1546 steps.
Found uncertainty sample 93 after 1300 steps.
Found uncertainty sample 94 after 948 steps.
Found uncertainty sample 95 after 3437 steps.
Found uncertainty sample 97 after 733 steps.
Found uncertainty sample 99 after 2307 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_215404-x8d7q5me
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/x8d7q5me
Training model 16. Added 69 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.130384658881454, Training Loss Force: 3.2607140616670134, time: 2.236988067626953
Validation Loss Energy: 1.338878122446926, Validation Loss Force: 2.759368160917294, time: 0.13504838943481445
Test Loss Energy: 10.046417079441012, Test Loss Force: 8.29504300395749, time: 17.85321569442749


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8657207072096051, Training Loss Force: 3.1180919659346378, time: 2.241412401199341
Validation Loss Energy: 1.3511530374526277, Validation Loss Force: 2.8183328434467123, time: 0.13517451286315918
Test Loss Energy: 10.003950412678456, Test Loss Force: 8.242704007992655, time: 18.02592945098877


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8217836523244384, Training Loss Force: 3.1067167958048736, time: 2.1889219284057617
Validation Loss Energy: 1.2881286510546537, Validation Loss Force: 2.7271718724347305, time: 0.1336965560913086
Test Loss Energy: 10.082923450422852, Test Loss Force: 8.18825634920557, time: 17.963937759399414


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9008196394973627, Training Loss Force: 3.1237724858170295, time: 2.193727493286133
Validation Loss Energy: 1.5187975757209027, Validation Loss Force: 2.7660142782503736, time: 0.14683794975280762
Test Loss Energy: 9.752264497233467, Test Loss Force: 8.235215933735251, time: 17.936589241027832


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0626824228161755, Training Loss Force: 3.1369142618461923, time: 2.235936403274536
Validation Loss Energy: 2.3276843864283023, Validation Loss Force: 2.853479943451111, time: 0.13390111923217773
Test Loss Energy: 9.758418676052516, Test Loss Force: 8.255214628490133, time: 17.9753315448761


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9656160360844146, Training Loss Force: 3.1266900831329827, time: 2.226330280303955
Validation Loss Energy: 1.3673388576701186, Validation Loss Force: 2.78237311239425, time: 0.13546252250671387
Test Loss Energy: 9.988213896828396, Test Loss Force: 8.219470704643323, time: 17.98207998275757


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7162395895878182, Training Loss Force: 3.1235813991866843, time: 2.2004778385162354
Validation Loss Energy: 1.3317154683625803, Validation Loss Force: 2.7879446284290825, time: 0.1378016471862793
Test Loss Energy: 10.187840446786781, Test Loss Force: 8.226023496207793, time: 18.250775575637817


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.810717244905749, Training Loss Force: 3.115638418419426, time: 2.2303121089935303
Validation Loss Energy: 1.4531117920235133, Validation Loss Force: 2.767879132347519, time: 0.13356685638427734
Test Loss Energy: 9.899700523749267, Test Loss Force: 8.219445884611295, time: 18.017160415649414


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8326157351450212, Training Loss Force: 3.109330146760584, time: 2.2652368545532227
Validation Loss Energy: 1.3947223195653127, Validation Loss Force: 2.806684575084938, time: 0.14343690872192383
Test Loss Energy: 9.895573137786807, Test Loss Force: 8.181839308876853, time: 18.05525016784668


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.810107120494965, Training Loss Force: 3.1249973303837564, time: 2.277567148208618
Validation Loss Energy: 1.4272532797742057, Validation Loss Force: 2.749297280785272, time: 0.14125514030456543
Test Loss Energy: 9.889356243211871, Test Loss Force: 8.179224112219247, time: 17.872605323791504


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7751894755699742, Training Loss Force: 3.117600213901955, time: 2.2358405590057373
Validation Loss Energy: 1.2064594533934216, Validation Loss Force: 2.7027785788329144, time: 0.132720947265625
Test Loss Energy: 9.986156657754973, Test Loss Force: 8.190959995643812, time: 18.042914152145386


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.298951387982397, Training Loss Force: 3.1262593935506775, time: 2.220823287963867
Validation Loss Energy: 1.4146202571145656, Validation Loss Force: 2.8199995220039824, time: 0.13646674156188965
Test Loss Energy: 10.180168391856105, Test Loss Force: 8.176443247385457, time: 18.065532445907593


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.431005414407562, Training Loss Force: 3.155363262060381, time: 2.1709959506988525
Validation Loss Energy: 1.3838425380934214, Validation Loss Force: 2.7619981061998473, time: 0.14388561248779297
Test Loss Energy: 9.839476708404497, Test Loss Force: 8.15757610593467, time: 17.957319974899292


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9407223045280673, Training Loss Force: 3.1228594510608794, time: 2.270169496536255
Validation Loss Energy: 1.5096467088325678, Validation Loss Force: 2.82872358780686, time: 0.14443683624267578
Test Loss Energy: 9.721674419811176, Test Loss Force: 8.160085615188645, time: 18.052496194839478


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9071470479266561, Training Loss Force: 3.125307085067626, time: 2.2164299488067627
Validation Loss Energy: 1.4041231325699512, Validation Loss Force: 2.8035481688299724, time: 0.14051580429077148
Test Loss Energy: 10.001877640391946, Test Loss Force: 8.14800485572867, time: 17.972103357315063


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7074473961520713, Training Loss Force: 3.1271644779232246, time: 2.2428622245788574
Validation Loss Energy: 1.58365124481996, Validation Loss Force: 2.8417314739736694, time: 0.13986849784851074
Test Loss Energy: 9.616206029356732, Test Loss Force: 8.159368981938941, time: 17.91151261329651


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7519851311734675, Training Loss Force: 3.1160656913079507, time: 2.2707998752593994
Validation Loss Energy: 1.3303086446986088, Validation Loss Force: 2.7633446978598455, time: 0.13620448112487793
Test Loss Energy: 9.8552362932444, Test Loss Force: 8.1455805319956, time: 18.017415285110474


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9270078435323055, Training Loss Force: 3.1041715378040498, time: 2.2325439453125
Validation Loss Energy: 1.3998659211689581, Validation Loss Force: 2.7682370729995975, time: 0.1382889747619629
Test Loss Energy: 10.128680248506265, Test Loss Force: 8.120921183155708, time: 18.00978660583496


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8159316525600637, Training Loss Force: 3.1266615559301068, time: 2.206594467163086
Validation Loss Energy: 1.6480027393276635, Validation Loss Force: 2.737343510355285, time: 0.14098644256591797
Test Loss Energy: 10.32814811813591, Test Loss Force: 8.10486101595333, time: 17.9114408493042


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.79286937655413, Training Loss Force: 3.1042707679362294, time: 2.300334930419922
Validation Loss Energy: 2.3789172168690973, Validation Loss Force: 2.8330322357805624, time: 0.14062714576721191
Test Loss Energy: 10.88593863750786, Test Loss Force: 8.080104161343662, time: 18.353172779083252

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–â–‚â–„â–…â–ˆ
wandb:   test_error_force â–ˆâ–†â–…â–†â–‡â–†â–†â–†â–„â–„â–…â–„â–„â–„â–ƒâ–„â–ƒâ–‚â–‚â–
wandb:          test_loss â–ˆâ–„â–ƒâ–ƒâ–„â–ƒâ–‡â–„â–‚â–ƒâ–„â–‡â–‚â–‚â–‚â–‚â–â–â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–â–„â–…â–‚â–‚â–â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–„â–ˆ
wandb:  valid_error_force â–„â–†â–‚â–„â–ˆâ–…â–…â–„â–†â–ƒâ–â–†â–„â–‡â–†â–‡â–„â–„â–ƒâ–‡
wandb:         valid_loss â–…â–ƒâ–â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–‚â–…â–…â–ˆâ–ƒâ–„â–‚â–‚â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1926
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.88594
wandb:   test_error_force 8.0801
wandb:          test_loss 4.53781
wandb: train_error_energy 1.79287
wandb:  train_error_force 3.10427
wandb:         train_loss 1.40851
wandb: valid_error_energy 2.37892
wandb:  valid_error_force 2.83303
wandb:         valid_loss 1.44735
wandb: 
wandb: ğŸš€ View run al_54_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/x8d7q5me
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_215404-x8d7q5me/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6383646726608276, Uncertainty Bias: 0.04165613651275635
0.00050354004 5.4359436e-05
0.6907988 3.9799986
Found uncertainty sample 0 after 1187 steps.
Found uncertainty sample 2 after 2435 steps.
Found uncertainty sample 3 after 1692 steps.
Found uncertainty sample 4 after 580 steps.
Found uncertainty sample 5 after 3191 steps.
Found uncertainty sample 7 after 998 steps.
Found uncertainty sample 9 after 211 steps.
Found uncertainty sample 10 after 1082 steps.
Found uncertainty sample 13 after 301 steps.
Found uncertainty sample 14 after 689 steps.
Found uncertainty sample 15 after 3847 steps.
Found uncertainty sample 19 after 1187 steps.
Found uncertainty sample 21 after 1973 steps.
Found uncertainty sample 22 after 14 steps.
Found uncertainty sample 23 after 2589 steps.
Found uncertainty sample 24 after 2312 steps.
Found uncertainty sample 26 after 870 steps.
Found uncertainty sample 27 after 2182 steps.
Found uncertainty sample 28 after 827 steps.
Found uncertainty sample 31 after 1993 steps.
Found uncertainty sample 32 after 1529 steps.
Found uncertainty sample 35 after 712 steps.
Found uncertainty sample 36 after 2269 steps.
Found uncertainty sample 41 after 82 steps.
Found uncertainty sample 44 after 824 steps.
Found uncertainty sample 46 after 2005 steps.
Found uncertainty sample 50 after 3457 steps.
Found uncertainty sample 52 after 3275 steps.
Found uncertainty sample 58 after 2226 steps.
Found uncertainty sample 60 after 3572 steps.
Found uncertainty sample 61 after 1630 steps.
Found uncertainty sample 62 after 2018 steps.
Found uncertainty sample 63 after 157 steps.
Found uncertainty sample 64 after 2149 steps.
Found uncertainty sample 71 after 3684 steps.
Found uncertainty sample 72 after 1009 steps.
Found uncertainty sample 74 after 904 steps.
Found uncertainty sample 75 after 890 steps.
Found uncertainty sample 76 after 3230 steps.
Found uncertainty sample 77 after 1736 steps.
Found uncertainty sample 79 after 871 steps.
Found uncertainty sample 80 after 714 steps.
Found uncertainty sample 81 after 2954 steps.
Found uncertainty sample 89 after 482 steps.
Found uncertainty sample 90 after 1010 steps.
Found uncertainty sample 94 after 1959 steps.
Found uncertainty sample 97 after 1564 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_001434-0n9cd68l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0n9cd68l
Training model 17. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.411502134780923, Training Loss Force: 3.386212973201571, time: 2.291250467300415
Validation Loss Energy: 2.4823705267474496, Validation Loss Force: 2.7319679431688693, time: 0.14705753326416016
Test Loss Energy: 9.54125718499825, Test Loss Force: 8.10846376776023, time: 17.92155385017395


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7755082011062389, Training Loss Force: 3.130869780590005, time: 2.2035393714904785
Validation Loss Energy: 1.677335613928169, Validation Loss Force: 2.787436831441794, time: 0.13687467575073242
Test Loss Energy: 9.591153875822124, Test Loss Force: 8.123480304494365, time: 17.989959239959717


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6290019806603269, Training Loss Force: 3.1247787235661546, time: 2.257626533508301
Validation Loss Energy: 1.340458238373716, Validation Loss Force: 2.7697106974073478, time: 0.14381885528564453
Test Loss Energy: 9.989071091433724, Test Loss Force: 8.080693733283342, time: 17.97749161720276


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8587314193069333, Training Loss Force: 3.136094467881427, time: 2.2240664958953857
Validation Loss Energy: 1.706312496231622, Validation Loss Force: 2.758811376717902, time: 0.15317440032958984
Test Loss Energy: 9.57224868709256, Test Loss Force: 8.173484986356591, time: 17.91704249382019


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7382798592835451, Training Loss Force: 3.126800979609406, time: 2.3047893047332764
Validation Loss Energy: 1.460483421101312, Validation Loss Force: 2.8229585722842163, time: 0.14422225952148438
Test Loss Energy: 9.775529044211654, Test Loss Force: 8.103249147814362, time: 18.00069761276245


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8223450739237814, Training Loss Force: 3.1273164838222947, time: 2.26723313331604
Validation Loss Energy: 1.356831657346651, Validation Loss Force: 2.762133155036852, time: 0.1355292797088623
Test Loss Energy: 9.710904521773926, Test Loss Force: 8.09855723844243, time: 18.03548765182495


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9579107601353432, Training Loss Force: 3.1384879708539457, time: 2.246032476425171
Validation Loss Energy: 1.3908347389465594, Validation Loss Force: 2.779266655139412, time: 0.13775920867919922
Test Loss Energy: 9.653845984478538, Test Loss Force: 8.111630267575396, time: 17.948717832565308


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7869649147437914, Training Loss Force: 3.1184689874838165, time: 2.2215330600738525
Validation Loss Energy: 1.2557842319227617, Validation Loss Force: 2.8098674078568298, time: 0.1407909393310547
Test Loss Energy: 9.627364952542248, Test Loss Force: 8.087817206050104, time: 18.34752321243286


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.037221746087967, Training Loss Force: 3.1313679920297046, time: 2.260824203491211
Validation Loss Energy: 3.143955407020245, Validation Loss Force: 2.755247334368182, time: 0.14180779457092285
Test Loss Energy: 11.266422677652308, Test Loss Force: 8.041513271403511, time: 18.030394792556763


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.832804515306885, Training Loss Force: 3.1231362046112188, time: 2.300403118133545
Validation Loss Energy: 1.4332216478943676, Validation Loss Force: 2.7162410440611353, time: 0.1379075050354004
Test Loss Energy: 10.263073780707266, Test Loss Force: 8.073292714501344, time: 17.926411628723145


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.791631766442394, Training Loss Force: 3.1384540353578187, time: 2.284487724304199
Validation Loss Energy: 1.3631219493845381, Validation Loss Force: 2.7578013494719733, time: 0.1420001983642578
Test Loss Energy: 9.938461299755497, Test Loss Force: 8.087248166304134, time: 18.016303777694702


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7642458794288005, Training Loss Force: 3.1277845918300393, time: 2.254384994506836
Validation Loss Energy: 1.6052720848858293, Validation Loss Force: 2.7893162703679977, time: 0.1335129737854004
Test Loss Energy: 10.095186546768163, Test Loss Force: 8.08325378959925, time: 18.015953302383423


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8660917353555437, Training Loss Force: 3.1263623968121235, time: 2.287461042404175
Validation Loss Energy: 1.6600701823566473, Validation Loss Force: 2.7814796524462153, time: 0.1454923152923584
Test Loss Energy: 9.50176091997914, Test Loss Force: 8.081784303806515, time: 18.001259565353394


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.848262546808068, Training Loss Force: 3.120748591596754, time: 2.2255022525787354
Validation Loss Energy: 1.547141966315348, Validation Loss Force: 2.7308040515431045, time: 0.13702702522277832
Test Loss Energy: 9.620919764968193, Test Loss Force: 8.09380879442357, time: 18.017648935317993


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9792473127563055, Training Loss Force: 3.1126813315370447, time: 2.2384514808654785
Validation Loss Energy: 3.495197614516792, Validation Loss Force: 2.7561233147882613, time: 0.14143848419189453
Test Loss Energy: 11.280030420508563, Test Loss Force: 8.082739664028407, time: 18.000511407852173


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2469666432533058, Training Loss Force: 3.130075702909809, time: 2.2548749446868896
Validation Loss Energy: 1.6812455171288012, Validation Loss Force: 2.7312201088422707, time: 0.1390836238861084
Test Loss Energy: 10.366015289051125, Test Loss Force: 8.035130699325935, time: 17.90906572341919


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0095667481479085, Training Loss Force: 3.1474766897110724, time: 2.2700891494750977
Validation Loss Energy: 1.4045322871255936, Validation Loss Force: 2.7413837306735713, time: 0.1359729766845703
Test Loss Energy: 9.944957554341428, Test Loss Force: 8.06617894124921, time: 18.324458837509155


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8753446727029404, Training Loss Force: 3.1338356833336323, time: 2.256361246109009
Validation Loss Energy: 1.7839543883850313, Validation Loss Force: 2.8161337629615297, time: 0.1429274082183838
Test Loss Energy: 9.500972466020517, Test Loss Force: 8.0419711724321, time: 18.022592782974243


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.900683979762669, Training Loss Force: 3.098733677422722, time: 2.2570035457611084
Validation Loss Energy: 1.369902391879899, Validation Loss Force: 2.800198334198635, time: 0.1335148811340332
Test Loss Energy: 9.78223207566185, Test Loss Force: 8.046095893359654, time: 17.96417999267578


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9306151322396228, Training Loss Force: 3.109931195195821, time: 2.2652764320373535
Validation Loss Energy: 1.3554015647569297, Validation Loss Force: 2.797328462911344, time: 0.13647723197937012
Test Loss Energy: 9.761238478841666, Test Loss Force: 8.050544340251175, time: 18.016531467437744

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–ƒâ–â–‚â–‚â–‚â–â–ˆâ–„â–ƒâ–ƒâ–â–â–ˆâ–„â–ƒâ–â–‚â–‚
wandb:   test_error_force â–…â–…â–ƒâ–ˆâ–„â–„â–…â–„â–â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–â–ƒâ–â–‚â–‚
wandb:          test_loss â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–…â–â–‚â–†â–„â–„â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–…â–‚â–â–‚â–‚â–â–â–â–‡â–‚â–â–‚â–‚â–‚â–ˆâ–‚â–â–ƒâ–â–
wandb:  valid_error_force â–‚â–†â–…â–„â–ˆâ–„â–…â–‡â–„â–â–„â–†â–…â–‚â–„â–‚â–ƒâ–ˆâ–‡â–†
wandb:         valid_loss â–†â–ƒâ–‚â–„â–„â–„â–…â–ƒâ–‡â–â–ƒâ–…â–…â–‚â–ˆâ–„â–†â–…â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1968
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.76124
wandb:   test_error_force 8.05054
wandb:          test_loss 4.41583
wandb: train_error_energy 1.93062
wandb:  train_error_force 3.10993
wandb:         train_loss 1.41415
wandb: valid_error_energy 1.3554
wandb:  valid_error_force 2.79733
wandb:         valid_loss 1.38161
wandb: 
wandb: ğŸš€ View run al_54_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0n9cd68l
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_001434-0n9cd68l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6715628504753113, Uncertainty Bias: 0.03166694939136505
0.00012588501 0.0004618168
0.54497635 3.3351064
Found uncertainty sample 2 after 2723 steps.
Found uncertainty sample 4 after 2262 steps.
Found uncertainty sample 7 after 390 steps.
Found uncertainty sample 8 after 346 steps.
Found uncertainty sample 9 after 2829 steps.
Found uncertainty sample 10 after 3278 steps.
Found uncertainty sample 11 after 796 steps.
Found uncertainty sample 13 after 845 steps.
Found uncertainty sample 14 after 1826 steps.
Found uncertainty sample 18 after 136 steps.
Found uncertainty sample 19 after 753 steps.
Found uncertainty sample 20 after 258 steps.
Found uncertainty sample 21 after 1192 steps.
Found uncertainty sample 23 after 1491 steps.
Found uncertainty sample 24 after 983 steps.
Found uncertainty sample 25 after 2909 steps.
Found uncertainty sample 26 after 3270 steps.
Found uncertainty sample 27 after 2932 steps.
Found uncertainty sample 28 after 3814 steps.
Found uncertainty sample 30 after 2256 steps.
Found uncertainty sample 32 after 1444 steps.
Found uncertainty sample 34 after 2855 steps.
Found uncertainty sample 36 after 1943 steps.
Found uncertainty sample 41 after 366 steps.
Found uncertainty sample 42 after 1066 steps.
Found uncertainty sample 43 after 259 steps.
Found uncertainty sample 47 after 2114 steps.
Found uncertainty sample 49 after 3206 steps.
Found uncertainty sample 52 after 1923 steps.
Found uncertainty sample 54 after 555 steps.
Found uncertainty sample 55 after 384 steps.
Found uncertainty sample 57 after 412 steps.
Found uncertainty sample 58 after 56 steps.
Found uncertainty sample 59 after 673 steps.
Found uncertainty sample 61 after 948 steps.
Found uncertainty sample 62 after 1324 steps.
Found uncertainty sample 64 after 1555 steps.
Found uncertainty sample 66 after 265 steps.
Found uncertainty sample 68 after 1215 steps.
Found uncertainty sample 69 after 1973 steps.
Found uncertainty sample 71 after 1057 steps.
Found uncertainty sample 72 after 2015 steps.
Found uncertainty sample 73 after 17 steps.
Found uncertainty sample 78 after 2182 steps.
Found uncertainty sample 79 after 423 steps.
Found uncertainty sample 81 after 3669 steps.
Found uncertainty sample 82 after 1082 steps.
Found uncertainty sample 83 after 2681 steps.
Found uncertainty sample 85 after 3246 steps.
Found uncertainty sample 87 after 2530 steps.
Found uncertainty sample 88 after 1027 steps.
Found uncertainty sample 90 after 2937 steps.
Found uncertainty sample 91 after 2740 steps.
Found uncertainty sample 93 after 2650 steps.
Found uncertainty sample 95 after 328 steps.
Found uncertainty sample 96 after 1615 steps.
Found uncertainty sample 98 after 1571 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_022328-a1prf2hy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/a1prf2hy
Training model 18. Added 57 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.392977510482875, Training Loss Force: 3.3125719622153977, time: 2.2942867279052734
Validation Loss Energy: 2.236998368704584, Validation Loss Force: 2.7819984715562267, time: 0.1364283561706543
Test Loss Energy: 9.43997419572814, Test Loss Force: 8.033319368596114, time: 17.817809104919434


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9456368689419477, Training Loss Force: 3.12826207528626, time: 2.356471538543701
Validation Loss Energy: 1.327983923147836, Validation Loss Force: 2.7661298435371102, time: 0.14903879165649414
Test Loss Energy: 9.70601998610366, Test Loss Force: 8.052525027770676, time: 18.01621675491333


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8459660859449418, Training Loss Force: 3.123347182729126, time: 2.3000857830047607
Validation Loss Energy: 2.130353875961367, Validation Loss Force: 2.809683483142294, time: 0.14686298370361328
Test Loss Energy: 9.369036613623807, Test Loss Force: 8.057852947840189, time: 17.95154309272766


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.837622530399606, Training Loss Force: 3.1395904272318287, time: 2.375077962875366
Validation Loss Energy: 1.7374476548992668, Validation Loss Force: 2.803854672909342, time: 0.13694500923156738
Test Loss Energy: 10.214121281673776, Test Loss Force: 8.05543453708046, time: 18.25248146057129


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.792008966348226, Training Loss Force: 3.1547440298313174, time: 2.2867486476898193
Validation Loss Energy: 1.2509913342239525, Validation Loss Force: 2.7596597461638863, time: 0.13858342170715332
Test Loss Energy: 9.6125665942653, Test Loss Force: 8.039630866081277, time: 18.024515867233276


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.814711874087142, Training Loss Force: 3.151470977784065, time: 2.369882822036743
Validation Loss Energy: 1.431234437101535, Validation Loss Force: 2.806959460145586, time: 0.14354920387268066
Test Loss Energy: 9.953199539694662, Test Loss Force: 8.014092792511518, time: 17.991061210632324


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7903595672646007, Training Loss Force: 3.1397391876173355, time: 2.3369524478912354
Validation Loss Energy: 1.5695405340406565, Validation Loss Force: 2.8118329084079345, time: 0.13695693016052246
Test Loss Energy: 9.474384142530102, Test Loss Force: 7.989504392356876, time: 17.90558433532715


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7879586432872436, Training Loss Force: 3.1384527375019697, time: 2.355576992034912
Validation Loss Energy: 1.3945763042728705, Validation Loss Force: 2.823019138291909, time: 0.14582490921020508
Test Loss Energy: 9.553398263314824, Test Loss Force: 7.97586276881623, time: 18.032962799072266


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8547558861151412, Training Loss Force: 3.1400621344214494, time: 2.326399087905884
Validation Loss Energy: 2.2018784343359883, Validation Loss Force: 2.843401269898982, time: 0.14159822463989258
Test Loss Energy: 10.286389394697329, Test Loss Force: 8.014514005592346, time: 18.00878930091858


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2461699881833592, Training Loss Force: 3.1568040534348674, time: 2.328146457672119
Validation Loss Energy: 1.37974241977488, Validation Loss Force: 2.75097141875893, time: 0.14024591445922852
Test Loss Energy: 9.43289492570136, Test Loss Force: 7.975212022317581, time: 17.84100604057312


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9618823679697528, Training Loss Force: 3.132877074254295, time: 2.3442981243133545
Validation Loss Energy: 1.444028560888254, Validation Loss Force: 2.77569504203873, time: 0.13891077041625977
Test Loss Energy: 9.967758077472414, Test Loss Force: 7.991973450437944, time: 18.033229112625122


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8853203550691908, Training Loss Force: 3.1333749450685624, time: 2.32063889503479
Validation Loss Energy: 1.5515724143118732, Validation Loss Force: 2.736291732644495, time: 0.14271187782287598
Test Loss Energy: 9.998527535293375, Test Loss Force: 7.964441124017886, time: 18.039999961853027


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.787947385448354, Training Loss Force: 3.139567603644371, time: 2.3308308124542236
Validation Loss Energy: 1.3602749573519919, Validation Loss Force: 2.8495491650180482, time: 0.14085054397583008
Test Loss Energy: 9.414977916993669, Test Loss Force: 7.980389653537468, time: 17.863192081451416


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.915015570646811, Training Loss Force: 3.140592949831698, time: 2.3703901767730713
Validation Loss Energy: 1.4097895613282352, Validation Loss Force: 2.736608368170004, time: 0.14090585708618164
Test Loss Energy: 9.43227156401024, Test Loss Force: 7.970654889566706, time: 18.295045375823975


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0556346537768735, Training Loss Force: 3.1290888249498576, time: 2.344404458999634
Validation Loss Energy: 1.7540743043584084, Validation Loss Force: 2.734938349575546, time: 0.1369168758392334
Test Loss Energy: 10.060796525940244, Test Loss Force: 7.934236646602759, time: 18.049020290374756


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.797052410326271, Training Loss Force: 3.112019265684234, time: 2.3141932487487793
Validation Loss Energy: 1.4367160504686989, Validation Loss Force: 2.756820269215015, time: 0.13662004470825195
Test Loss Energy: 9.60676890058823, Test Loss Force: 7.92091834332523, time: 17.896584510803223


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9268322377690015, Training Loss Force: 3.132576526574579, time: 2.2935304641723633
Validation Loss Energy: 2.586497967465099, Validation Loss Force: 2.7956044470489987, time: 0.14368605613708496
Test Loss Energy: 9.37406701973499, Test Loss Force: 7.986301524025079, time: 17.99038600921631


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7751491301052167, Training Loss Force: 3.132823205717008, time: 2.3034582138061523
Validation Loss Energy: 1.6424920119696695, Validation Loss Force: 2.8563807657496856, time: 0.13314175605773926
Test Loss Energy: 9.360819725764676, Test Loss Force: 8.086097468116716, time: 18.00611162185669


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6690633951406584, Training Loss Force: 3.1316874713005864, time: 2.3087360858917236
Validation Loss Energy: 1.748480243072551, Validation Loss Force: 2.762539080889879, time: 0.14734554290771484
Test Loss Energy: 9.267859661499442, Test Loss Force: 7.982769858468663, time: 17.96111488342285


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8139952047429597, Training Loss Force: 3.1056649597460977, time: 2.3582558631896973
Validation Loss Energy: 1.2378509042480292, Validation Loss Force: 2.818867694735231, time: 0.13951992988586426
Test Loss Energy: 9.594766749165807, Test Loss Force: 7.972070650307499, time: 18.00488018989563

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–‚â–ˆâ–ƒâ–†â–‚â–ƒâ–ˆâ–‚â–†â–†â–‚â–‚â–†â–ƒâ–‚â–‚â–â–ƒ
wandb:   test_error_force â–†â–‡â–‡â–‡â–†â–…â–„â–ƒâ–…â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–â–„â–ˆâ–„â–ƒ
wandb:          test_loss â–ˆâ–†â–„â–ˆâ–…â–†â–â–„â–‡â–‚â–†â–ƒâ–ƒâ–‚â–â–â–â–…â–„â–„
wandb: train_error_energy â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‡â–„â–ƒâ–‚â–ƒâ–…â–‚â–ƒâ–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–†â–â–†â–„â–â–‚â–ƒâ–‚â–†â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–ˆâ–ƒâ–„â–
wandb:  valid_error_force â–„â–ƒâ–…â–…â–‚â–…â–…â–†â–‡â–‚â–ƒâ–â–ˆâ–â–â–‚â–„â–ˆâ–ƒâ–†
wandb:         valid_loss â–†â–â–…â–ƒâ–â–‚â–‚â–„â–ˆâ–…â–†â–â–„â–â–„â–â–…â–„â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2019
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.59477
wandb:   test_error_force 7.97207
wandb:          test_loss 4.40366
wandb: train_error_energy 1.814
wandb:  train_error_force 3.10566
wandb:         train_loss 1.41376
wandb: valid_error_energy 1.23785
wandb:  valid_error_force 2.81887
wandb:         valid_loss 1.4084
wandb: 
wandb: ğŸš€ View run al_54_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/a1prf2hy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_022328-a1prf2hy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.649764358997345, Uncertainty Bias: 0.03768843412399292
0.0001335144 0.004249096
0.7016841 5.4969473
Found uncertainty sample 1 after 2085 steps.
Found uncertainty sample 3 after 999 steps.
Found uncertainty sample 5 after 2660 steps.
Found uncertainty sample 8 after 3633 steps.
Found uncertainty sample 10 after 3341 steps.
Found uncertainty sample 12 after 38 steps.
Found uncertainty sample 13 after 1287 steps.
Found uncertainty sample 14 after 2194 steps.
Found uncertainty sample 17 after 1127 steps.
Found uncertainty sample 19 after 887 steps.
Found uncertainty sample 20 after 3298 steps.
Found uncertainty sample 23 after 1233 steps.
Found uncertainty sample 24 after 1785 steps.
Found uncertainty sample 27 after 18 steps.
Found uncertainty sample 28 after 1250 steps.
Found uncertainty sample 29 after 3111 steps.
Found uncertainty sample 31 after 3469 steps.
Found uncertainty sample 34 after 2976 steps.
Found uncertainty sample 38 after 2484 steps.
Found uncertainty sample 40 after 36 steps.
Found uncertainty sample 41 after 1811 steps.
Found uncertainty sample 43 after 584 steps.
Found uncertainty sample 44 after 584 steps.
Found uncertainty sample 45 after 322 steps.
Found uncertainty sample 47 after 2179 steps.
Found uncertainty sample 49 after 660 steps.
Found uncertainty sample 51 after 1857 steps.
Found uncertainty sample 52 after 2412 steps.
Found uncertainty sample 55 after 479 steps.
Found uncertainty sample 58 after 2415 steps.
Found uncertainty sample 60 after 2514 steps.
Found uncertainty sample 61 after 549 steps.
Found uncertainty sample 62 after 3095 steps.
Found uncertainty sample 63 after 162 steps.
Found uncertainty sample 64 after 1431 steps.
Found uncertainty sample 65 after 2804 steps.
Found uncertainty sample 67 after 1826 steps.
Found uncertainty sample 70 after 431 steps.
Found uncertainty sample 71 after 5 steps.
Found uncertainty sample 74 after 632 steps.
Found uncertainty sample 75 after 37 steps.
Found uncertainty sample 76 after 2557 steps.
Found uncertainty sample 78 after 1779 steps.
Found uncertainty sample 80 after 3146 steps.
Found uncertainty sample 81 after 2879 steps.
Found uncertainty sample 82 after 2877 steps.
Found uncertainty sample 84 after 858 steps.
Found uncertainty sample 85 after 896 steps.
Found uncertainty sample 86 after 1017 steps.
Found uncertainty sample 87 after 1115 steps.
Found uncertainty sample 90 after 388 steps.
Found uncertainty sample 91 after 755 steps.
Found uncertainty sample 98 after 224 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_043617-y15a661n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/y15a661n
Training model 19. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.541553354813455, Training Loss Force: 3.276607512129303, time: 2.3656609058380127
Validation Loss Energy: 1.9386406400387521, Validation Loss Force: 2.7914913025854204, time: 0.13957834243774414
Test Loss Energy: 9.209895100936377, Test Loss Force: 7.938054676338911, time: 18.280707120895386


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7537144436131555, Training Loss Force: 3.1426409328152873, time: 2.3478639125823975
Validation Loss Energy: 1.3307395651632654, Validation Loss Force: 2.814574856270889, time: 0.1352224349975586
Test Loss Energy: 9.597645224692002, Test Loss Force: 7.960243694036441, time: 18.131996393203735


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9581286710957853, Training Loss Force: 3.148926081195904, time: 2.310410499572754
Validation Loss Energy: 1.2744957325952249, Validation Loss Force: 2.7978899231628014, time: 0.13454604148864746
Test Loss Energy: 9.36751183593446, Test Loss Force: 7.8994927706935565, time: 18.08715033531189


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9992855976460584, Training Loss Force: 3.136235981582804, time: 2.328277111053467
Validation Loss Energy: 1.4520646346975012, Validation Loss Force: 2.762152527252548, time: 0.1392514705657959
Test Loss Energy: 9.707591274830945, Test Loss Force: 7.913194587183642, time: 17.97406244277954


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9007836685182895, Training Loss Force: 3.1353346579882384, time: 2.297879457473755
Validation Loss Energy: 1.335319535491281, Validation Loss Force: 2.7891046233447936, time: 0.13657402992248535
Test Loss Energy: 9.614778232823989, Test Loss Force: 7.888723996494302, time: 18.12520432472229


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7875017194153495, Training Loss Force: 3.136484668762014, time: 2.3483774662017822
Validation Loss Energy: 1.7108994249704481, Validation Loss Force: 2.7281424872418296, time: 0.1433093547821045
Test Loss Energy: 9.258075252801401, Test Loss Force: 7.918885765734077, time: 18.09590220451355


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9629231728688648, Training Loss Force: 3.128797797553707, time: 2.3355424404144287
Validation Loss Energy: 1.6132543284290486, Validation Loss Force: 2.722833832133765, time: 0.13522696495056152
Test Loss Energy: 9.173199183718426, Test Loss Force: 7.8970544362914, time: 18.03475332260132


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1945637528922606, Training Loss Force: 3.1489783981681594, time: 2.3439202308654785
Validation Loss Energy: 1.379615220025269, Validation Loss Force: 2.794862847458486, time: 0.14660263061523438
Test Loss Energy: 9.408824330404599, Test Loss Force: 7.873491354107912, time: 18.14401364326477


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9464538520076184, Training Loss Force: 3.1386516985929, time: 2.3698248863220215
Validation Loss Energy: 1.6758960578997457, Validation Loss Force: 2.774129343939139, time: 0.14720916748046875
Test Loss Energy: 9.297073247225503, Test Loss Force: 7.88579906355729, time: 18.201388597488403


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8913061194438647, Training Loss Force: 3.1305789349033417, time: 2.3828306198120117
Validation Loss Energy: 1.6915646733585328, Validation Loss Force: 2.737955961841159, time: 0.1365978717803955
Test Loss Energy: 9.247569046328442, Test Loss Force: 7.892135838070842, time: 18.451168060302734


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9429833786586963, Training Loss Force: 3.1419841718822137, time: 2.3642396926879883
Validation Loss Energy: 1.3500231585389035, Validation Loss Force: 2.785907985085854, time: 0.15166831016540527
Test Loss Energy: 9.254748233013968, Test Loss Force: 7.837261242090328, time: 18.127506971359253


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7666181137683128, Training Loss Force: 3.1266941256590357, time: 2.401946544647217
Validation Loss Energy: 1.8079227735891306, Validation Loss Force: 2.7993426166708346, time: 0.14329838752746582
Test Loss Energy: 9.178932002564956, Test Loss Force: 7.849758835859863, time: 18.153804302215576


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7920267598343242, Training Loss Force: 3.1234428306889694, time: 2.307918071746826
Validation Loss Energy: 1.3745218859813166, Validation Loss Force: 2.7688971756827008, time: 0.13758444786071777
Test Loss Energy: 9.309359272663814, Test Loss Force: 7.849337585473209, time: 18.039150953292847


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8169893019691858, Training Loss Force: 3.133481094929631, time: 2.3354365825653076
Validation Loss Energy: 2.7290448539557017, Validation Loss Force: 2.783078416913977, time: 0.14284658432006836
Test Loss Energy: 9.150382544470826, Test Loss Force: 7.891330862294749, time: 18.12035369873047


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8012970313393233, Training Loss Force: 3.1317587901940303, time: 2.35249924659729
Validation Loss Energy: 1.7019934384753475, Validation Loss Force: 2.8190274598474345, time: 0.13965106010437012
Test Loss Energy: 9.181823922178017, Test Loss Force: 7.83682722611651, time: 18.061630249023438


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.867479114588293, Training Loss Force: 3.1180405551949195, time: 2.327563762664795
Validation Loss Energy: 1.348645448865762, Validation Loss Force: 2.7888059126855316, time: 0.14008593559265137
Test Loss Energy: 9.359647259628083, Test Loss Force: 7.879896533515738, time: 18.07647395133972


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9039155014915656, Training Loss Force: 3.1155289157424373, time: 2.382948875427246
Validation Loss Energy: 2.8112500719184688, Validation Loss Force: 2.7882806361702874, time: 0.14551687240600586
Test Loss Energy: 9.168114385713668, Test Loss Force: 7.8995954969472875, time: 18.223546743392944


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9138527972644266, Training Loss Force: 3.1221570465470445, time: 2.412252426147461
Validation Loss Energy: 1.6390920767804984, Validation Loss Force: 2.7536959984285025, time: 0.13799381256103516
Test Loss Energy: 9.186326348267414, Test Loss Force: 7.884487080628185, time: 18.110132217407227


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7870837240381938, Training Loss Force: 3.1092202809054443, time: 2.294524908065796
Validation Loss Energy: 1.9421271935256894, Validation Loss Force: 2.7646210374043036, time: 0.14196157455444336
Test Loss Energy: 9.964812973741882, Test Loss Force: 7.864052541914036, time: 18.072805166244507


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.945820711132408, Training Loss Force: 3.1058671884532174, time: 2.621939182281494
Validation Loss Energy: 1.3990569641618023, Validation Loss Force: 2.762127365639058, time: 0.14780282974243164
Test Loss Energy: 9.175372956864239, Test Loss Force: 7.85945729659919, time: 18.05473041534424

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–ƒâ–†â–…â–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–ƒâ–â–â–ˆâ–
wandb:   test_error_force â–‡â–ˆâ–…â–…â–„â–†â–„â–ƒâ–„â–„â–â–‚â–‚â–„â–â–ƒâ–…â–„â–ƒâ–‚
wandb:          test_loss â–†â–ˆâ–„â–‡â–…â–„â–„â–…â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–
wandb: train_error_energy â–ˆâ–â–ƒâ–ƒâ–‚â–â–ƒâ–…â–ƒâ–‚â–ƒâ–â–â–‚â–â–‚â–‚â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–â–â–‚â–â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–ƒâ–â–ˆâ–ƒâ–â–ˆâ–ƒâ–„â–‚
wandb:  valid_error_force â–†â–ˆâ–†â–„â–†â–â–â–†â–…â–‚â–†â–‡â–„â–…â–ˆâ–†â–†â–ƒâ–„â–„
wandb:         valid_loss â–…â–„â–â–ƒâ–‚â–ƒâ–â–†â–‚â–‡â–…â–ƒâ–‚â–ˆâ–„â–‚â–‡â–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2066
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.17537
wandb:   test_error_force 7.85946
wandb:          test_loss 4.28172
wandb: train_error_energy 1.94582
wandb:  train_error_force 3.10587
wandb:         train_loss 1.41998
wandb: valid_error_energy 1.39906
wandb:  valid_error_force 2.76213
wandb:         valid_loss 1.35676
wandb: 
wandb: ğŸš€ View run al_54_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/y15a661n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_043617-y15a661n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6398068070411682, Uncertainty Bias: 0.039073601365089417
0.00020599365 0.004196167
0.634384 3.9462736
Found uncertainty sample 3 after 3276 steps.
Found uncertainty sample 5 after 1494 steps.
Found uncertainty sample 7 after 1082 steps.
Found uncertainty sample 9 after 2782 steps.
Found uncertainty sample 10 after 1994 steps.
Found uncertainty sample 12 after 2490 steps.
Found uncertainty sample 17 after 757 steps.
Found uncertainty sample 21 after 229 steps.
Found uncertainty sample 23 after 1966 steps.
Found uncertainty sample 25 after 1981 steps.
Found uncertainty sample 26 after 1031 steps.
Found uncertainty sample 28 after 2132 steps.
Found uncertainty sample 29 after 600 steps.
Found uncertainty sample 30 after 876 steps.
Found uncertainty sample 31 after 3319 steps.
Found uncertainty sample 33 after 2235 steps.
Found uncertainty sample 34 after 2258 steps.
Found uncertainty sample 36 after 2779 steps.
Found uncertainty sample 39 after 2622 steps.
Found uncertainty sample 40 after 584 steps.
Found uncertainty sample 41 after 920 steps.
Found uncertainty sample 42 after 1636 steps.
Found uncertainty sample 44 after 2930 steps.
Found uncertainty sample 46 after 1053 steps.
Found uncertainty sample 47 after 20 steps.
Found uncertainty sample 48 after 1300 steps.
Found uncertainty sample 56 after 167 steps.
Found uncertainty sample 57 after 2424 steps.
Found uncertainty sample 62 after 2307 steps.
Found uncertainty sample 63 after 448 steps.
Found uncertainty sample 64 after 1082 steps.
Found uncertainty sample 66 after 664 steps.
Found uncertainty sample 70 after 852 steps.
Found uncertainty sample 72 after 2821 steps.
Found uncertainty sample 73 after 1449 steps.
Found uncertainty sample 74 after 327 steps.
Found uncertainty sample 77 after 721 steps.
Found uncertainty sample 78 after 3910 steps.
Found uncertainty sample 79 after 2991 steps.
Found uncertainty sample 80 after 491 steps.
Found uncertainty sample 81 after 1305 steps.
Found uncertainty sample 82 after 111 steps.
Found uncertainty sample 83 after 2007 steps.
Found uncertainty sample 84 after 542 steps.
Found uncertainty sample 85 after 3725 steps.
Found uncertainty sample 86 after 3025 steps.
Found uncertainty sample 88 after 1215 steps.
Found uncertainty sample 89 after 1301 steps.
Found uncertainty sample 91 after 1082 steps.
Found uncertainty sample 92 after 885 steps.
Found uncertainty sample 93 after 2182 steps.
Found uncertainty sample 94 after 1423 steps.
Found uncertainty sample 98 after 56 steps.
Found uncertainty sample 99 after 2057 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_064820-ucjch656
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ucjch656
Training model 20. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.426012825308249, Training Loss Force: 3.3846083500802293, time: 2.370253086090088
Validation Loss Energy: 1.7507858707440602, Validation Loss Force: 2.787820045041936, time: 0.1415393352508545
Test Loss Energy: 9.678729427080569, Test Loss Force: 7.825408903868248, time: 18.309470653533936


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9245631343804073, Training Loss Force: 3.135944957610735, time: 2.411407232284546
Validation Loss Energy: 1.7427873166859018, Validation Loss Force: 2.8191592799818235, time: 0.1370542049407959
Test Loss Energy: 9.791547074484134, Test Loss Force: 7.792889222259628, time: 18.14608097076416


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8182505732036573, Training Loss Force: 3.16143542019491, time: 2.4140567779541016
Validation Loss Energy: 1.4577745952738141, Validation Loss Force: 2.774984838797794, time: 0.13779449462890625
Test Loss Energy: 9.214623073383496, Test Loss Force: 7.8532753272717635, time: 18.146865367889404


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9049866479923716, Training Loss Force: 3.1717856636961486, time: 2.4347894191741943
Validation Loss Energy: 1.7368595856848716, Validation Loss Force: 2.7743566891371314, time: 0.14632797241210938
Test Loss Energy: 9.108485113309824, Test Loss Force: 7.8717336505022395, time: 18.012139081954956


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.976502643575135, Training Loss Force: 3.1556978112560263, time: 2.4163737297058105
Validation Loss Energy: 1.3144253205158605, Validation Loss Force: 2.7542183802448488, time: 0.14024114608764648
Test Loss Energy: 9.237735529174364, Test Loss Force: 7.821562409787244, time: 18.163931369781494


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.764327615327637, Training Loss Force: 3.1374304300111007, time: 2.426553249359131
Validation Loss Energy: 1.3642212669579836, Validation Loss Force: 2.7875668702230163, time: 0.139251708984375
Test Loss Energy: 9.493381392710534, Test Loss Force: 7.85069262165655, time: 18.114030599594116


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7585656789537054, Training Loss Force: 3.1489695206995485, time: 2.349111557006836
Validation Loss Energy: 2.300207347824532, Validation Loss Force: 2.8354506453744843, time: 0.14017534255981445
Test Loss Energy: 9.077656381195382, Test Loss Force: 7.856753356377574, time: 18.017253398895264


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8162851108718836, Training Loss Force: 3.1392544592158793, time: 2.417037010192871
Validation Loss Energy: 1.4134750696970588, Validation Loss Force: 2.7786012083968066, time: 0.1414635181427002
Test Loss Energy: 9.382113135514686, Test Loss Force: 7.7977395601459865, time: 18.113070487976074


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8747564233806182, Training Loss Force: 3.140650195950435, time: 2.4216437339782715
Validation Loss Energy: 1.2533486768046034, Validation Loss Force: 2.799796639059381, time: 0.14052462577819824
Test Loss Energy: 9.268049310326576, Test Loss Force: 7.879075593177948, time: 18.175113916397095


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7918897201919914, Training Loss Force: 3.137140634426226, time: 2.402944564819336
Validation Loss Energy: 1.927675854620403, Validation Loss Force: 2.8429345553691174, time: 0.15327763557434082
Test Loss Energy: 9.010270980519874, Test Loss Force: 7.804004625868093, time: 18.434837341308594


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1523925048282684, Training Loss Force: 3.1406309367310232, time: 2.3939125537872314
Validation Loss Energy: 2.8585405451306123, Validation Loss Force: 2.8578019515735695, time: 0.14793157577514648
Test Loss Energy: 10.44159709202434, Test Loss Force: 7.807083778756089, time: 18.210304737091064


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9396680055672821, Training Loss Force: 3.150198225663879, time: 2.4363925457000732
Validation Loss Energy: 1.4080297514006814, Validation Loss Force: 2.744356920444572, time: 0.14731860160827637
Test Loss Energy: 9.119293112252976, Test Loss Force: 7.791086005546853, time: 18.11625599861145


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0289520867162683, Training Loss Force: 3.161911978695076, time: 2.3913495540618896
Validation Loss Energy: 1.5842565152258783, Validation Loss Force: 2.7789908794021807, time: 0.14333033561706543
Test Loss Energy: 9.55851340960862, Test Loss Force: 7.81265303953719, time: 18.068277835845947


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7235882445299535, Training Loss Force: 3.1425272702632463, time: 2.6078999042510986
Validation Loss Energy: 2.6175623173443388, Validation Loss Force: 2.7855968049544204, time: 0.14661049842834473
Test Loss Energy: 9.169326540585361, Test Loss Force: 7.832406175690588, time: 18.046087741851807


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0871469754208545, Training Loss Force: 3.1314515374503733, time: 2.387763738632202
Validation Loss Energy: 1.6594424780342767, Validation Loss Force: 2.7875005148175296, time: 0.14267301559448242
Test Loss Energy: 9.627739437745031, Test Loss Force: 7.802280077814829, time: 18.171100854873657


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9591166391536592, Training Loss Force: 3.1502854754114615, time: 2.4725420475006104
Validation Loss Energy: 1.498076931344733, Validation Loss Force: 2.8004986035419184, time: 0.1431713104248047
Test Loss Energy: 9.117931120864794, Test Loss Force: 7.804679436955802, time: 18.044602632522583


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1879180958528637, Training Loss Force: 3.13982996590234, time: 2.607731580734253
Validation Loss Energy: 2.5455967627262077, Validation Loss Force: 2.8288580799710004, time: 0.13803982734680176
Test Loss Energy: 9.067191677453286, Test Loss Force: 7.744849414910123, time: 17.99328637123108


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0269024512930596, Training Loss Force: 3.131740302775021, time: 2.4350807666778564
Validation Loss Energy: 1.2988009048825402, Validation Loss Force: 2.7737797533800324, time: 0.15524649620056152
Test Loss Energy: 9.297493851755055, Test Loss Force: 7.709769989421882, time: 18.18205714225769


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7088178672664338, Training Loss Force: 3.1208538885874884, time: 2.435300588607788
Validation Loss Energy: 2.0155447736444154, Validation Loss Force: 2.7891743187874685, time: 0.1426076889038086
Test Loss Energy: 9.870005431733532, Test Loss Force: 7.739023021395178, time: 18.1652090549469


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7848888045005267, Training Loss Force: 3.159404022870291, time: 2.685030460357666
Validation Loss Energy: 1.5442748227250953, Validation Loss Force: 2.7698077811549724, time: 0.13873577117919922
Test Loss Energy: 9.526380363243824, Test Loss Force: 7.767097282547369, time: 18.0666401386261

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–‚â–â–‚â–ƒâ–â–ƒâ–‚â–â–ˆâ–‚â–„â–‚â–„â–‚â–â–‚â–…â–„
wandb:   test_error_force â–†â–„â–‡â–ˆâ–†â–‡â–‡â–…â–ˆâ–…â–…â–„â–…â–†â–…â–…â–‚â–â–‚â–ƒ
wandb:          test_loss â–†â–…â–‡â–…â–…â–†â–†â–…â–‡â–‡â–‡â–ƒâ–†â–‡â–ˆâ–‡â–â–â–ƒâ–„
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–â–â–â–‚â–â–ƒâ–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–â–
wandb:  train_error_force â–ˆâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–â–‚
wandb: valid_error_energy â–ƒâ–ƒâ–‚â–ƒâ–â–â–†â–‚â–â–„â–ˆâ–‚â–‚â–‡â–ƒâ–‚â–‡â–â–„â–‚
wandb:  valid_error_force â–„â–†â–ƒâ–ƒâ–‚â–„â–‡â–ƒâ–„â–‡â–ˆâ–â–ƒâ–„â–„â–„â–†â–ƒâ–„â–ƒ
wandb:         valid_loss â–ˆâ–…â–ƒâ–‚â–‚â–‚â–‡â–„â–‚â–‡â–‡â–â–ƒâ–‡â–‡â–†â–†â–â–‡â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2114
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.52638
wandb:   test_error_force 7.7671
wandb:          test_loss 4.27114
wandb: train_error_energy 1.78489
wandb:  train_error_force 3.1594
wandb:         train_loss 1.4299
wandb: valid_error_energy 1.54427
wandb:  valid_error_force 2.76981
wandb:         valid_loss 1.35735
wandb: 
wandb: ğŸš€ View run al_54_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ucjch656
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_064820-ucjch656/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6520587801933289, Uncertainty Bias: 0.04042932391166687
0.00010871887 0.0035860538
0.6241349 4.7584233
Found uncertainty sample 2 after 3692 steps.
Found uncertainty sample 3 after 3590 steps.
Found uncertainty sample 4 after 904 steps.
Found uncertainty sample 5 after 3352 steps.
Found uncertainty sample 7 after 3469 steps.
Found uncertainty sample 8 after 127 steps.
Found uncertainty sample 10 after 1186 steps.
Found uncertainty sample 11 after 1451 steps.
Found uncertainty sample 12 after 1485 steps.
Found uncertainty sample 13 after 1512 steps.
Found uncertainty sample 14 after 10 steps.
Found uncertainty sample 16 after 552 steps.
Found uncertainty sample 18 after 34 steps.
Found uncertainty sample 20 after 2391 steps.
Found uncertainty sample 22 after 967 steps.
Found uncertainty sample 23 after 2916 steps.
Found uncertainty sample 24 after 104 steps.
Found uncertainty sample 26 after 3254 steps.
Found uncertainty sample 27 after 2821 steps.
Found uncertainty sample 28 after 2031 steps.
Found uncertainty sample 29 after 1543 steps.
Found uncertainty sample 30 after 200 steps.
Found uncertainty sample 31 after 2773 steps.
Found uncertainty sample 32 after 809 steps.
Found uncertainty sample 34 after 1189 steps.
Found uncertainty sample 35 after 1069 steps.
Found uncertainty sample 36 after 1552 steps.
Found uncertainty sample 39 after 339 steps.
Found uncertainty sample 42 after 2200 steps.
Found uncertainty sample 44 after 1410 steps.
Found uncertainty sample 47 after 2551 steps.
Found uncertainty sample 48 after 61 steps.
Found uncertainty sample 49 after 2620 steps.
Found uncertainty sample 51 after 2324 steps.
Found uncertainty sample 52 after 1706 steps.
Found uncertainty sample 55 after 3338 steps.
Found uncertainty sample 56 after 3305 steps.
Found uncertainty sample 58 after 607 steps.
Found uncertainty sample 61 after 772 steps.
Found uncertainty sample 67 after 1065 steps.
Found uncertainty sample 70 after 1315 steps.
Found uncertainty sample 71 after 863 steps.
Found uncertainty sample 72 after 568 steps.
Found uncertainty sample 73 after 659 steps.
Found uncertainty sample 77 after 569 steps.
Found uncertainty sample 79 after 1778 steps.
Found uncertainty sample 80 after 2857 steps.
Found uncertainty sample 81 after 66 steps.
Found uncertainty sample 82 after 1157 steps.
Found uncertainty sample 84 after 1385 steps.
Found uncertainty sample 85 after 1195 steps.
Found uncertainty sample 86 after 136 steps.
Found uncertainty sample 87 after 1252 steps.
Found uncertainty sample 90 after 1351 steps.
Found uncertainty sample 92 after 789 steps.
Found uncertainty sample 95 after 1461 steps.
Found uncertainty sample 97 after 1895 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 1092 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_085215-34ahrz6z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/34ahrz6z
Training model 21. Added 59 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3523908911428952, Training Loss Force: 3.341339845989597, time: 2.4476091861724854
Validation Loss Energy: 2.010619554805639, Validation Loss Force: 2.7814667376357516, time: 0.1452779769897461
Test Loss Energy: 8.941756985358559, Test Loss Force: 7.755354432259894, time: 18.09960436820984


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7928466921885695, Training Loss Force: 3.1478921942457028, time: 2.440783739089966
Validation Loss Energy: 1.308834432265333, Validation Loss Force: 2.751956284391369, time: 0.1527261734008789
Test Loss Energy: 9.31954253659514, Test Loss Force: 7.740007179382739, time: 18.191044092178345


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.952931627688054, Training Loss Force: 3.152954629671111, time: 2.4587197303771973
Validation Loss Energy: 1.641527687565943, Validation Loss Force: 2.8153455141849455, time: 0.14026117324829102
Test Loss Energy: 8.990008839020186, Test Loss Force: 7.722768831257624, time: 18.20849609375


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8764601787088466, Training Loss Force: 3.1655076486164373, time: 2.4338455200195312
Validation Loss Energy: 1.3319591797427983, Validation Loss Force: 2.782364539632132, time: 0.1395425796508789
Test Loss Energy: 8.983683160658105, Test Loss Force: 7.734333429647655, time: 18.107089042663574


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8092851657534879, Training Loss Force: 3.1419688151166567, time: 2.5286824703216553
Validation Loss Energy: 1.378406237897454, Validation Loss Force: 2.7664376836313553, time: 0.14101791381835938
Test Loss Energy: 9.042353892518433, Test Loss Force: 7.71849016084632, time: 18.21912169456482


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8455926495259658, Training Loss Force: 3.1421001211472825, time: 2.508004903793335
Validation Loss Energy: 2.1001384522009765, Validation Loss Force: 2.776943881943666, time: 0.14664316177368164
Test Loss Energy: 9.861863976253552, Test Loss Force: 7.704703002617187, time: 18.232309341430664


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.122544381924922, Training Loss Force: 3.152121709534398, time: 2.53725266456604
Validation Loss Energy: 2.9036717956346942, Validation Loss Force: 2.8092046331439757, time: 0.14336085319519043
Test Loss Energy: 10.273533685987559, Test Loss Force: 7.74380890180992, time: 18.131561756134033


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.009865569243884, Training Loss Force: 3.1390300571996175, time: 2.4969451427459717
Validation Loss Energy: 1.4393988240061233, Validation Loss Force: 2.8106484198861716, time: 0.14261436462402344
Test Loss Energy: 9.402686020551071, Test Loss Force: 7.691652813975881, time: 18.222864866256714


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9604803998950777, Training Loss Force: 3.1480227373070484, time: 2.4302637577056885
Validation Loss Energy: 1.3578141849530574, Validation Loss Force: 2.7976397543773515, time: 0.14171314239501953
Test Loss Energy: 9.176684503781507, Test Loss Force: 7.667119764008202, time: 18.20759654045105


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8163851704000804, Training Loss Force: 3.1526597731528003, time: 2.435438871383667
Validation Loss Energy: 1.3780061014422218, Validation Loss Force: 2.8284469213930445, time: 0.1425793170928955
Test Loss Energy: 9.092420464745159, Test Loss Force: 7.676356133808412, time: 18.51729989051819


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8977429922757394, Training Loss Force: 3.140517830921773, time: 2.724081516265869
Validation Loss Energy: 1.4257909558256114, Validation Loss Force: 2.744008331896622, time: 0.13909912109375
Test Loss Energy: 9.319113076595261, Test Loss Force: 7.6977769546105606, time: 18.089659452438354


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0684664676934164, Training Loss Force: 3.1545185660648123, time: 2.4698574542999268
Validation Loss Energy: 1.4486658128540595, Validation Loss Force: 2.812559255161951, time: 0.14320778846740723
Test Loss Energy: 9.441643249034362, Test Loss Force: 7.702408692017584, time: 18.179056644439697


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2904622375648214, Training Loss Force: 3.1458708659553487, time: 2.431914806365967
Validation Loss Energy: 1.6619280780429821, Validation Loss Force: 2.7957708922355797, time: 0.14966464042663574
Test Loss Energy: 8.874125902506021, Test Loss Force: 7.724843161062347, time: 18.099202156066895


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.943351626600049, Training Loss Force: 3.1374492601672053, time: 2.6562013626098633
Validation Loss Energy: 1.495766237950154, Validation Loss Force: 2.7449997662688657, time: 0.14526081085205078
Test Loss Energy: 9.024808850870304, Test Loss Force: 7.683239357058983, time: 18.097522974014282


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8248225218439331, Training Loss Force: 3.1237878007625426, time: 2.44598126411438
Validation Loss Energy: 1.8322836131629279, Validation Loss Force: 2.796225582631564, time: 0.1499786376953125
Test Loss Energy: 9.547260900096617, Test Loss Force: 7.668095367303655, time: 18.23978590965271


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.883455885782396, Training Loss Force: 3.120085156693121, time: 2.4945976734161377
Validation Loss Energy: 1.3601387951692572, Validation Loss Force: 2.8039785882890507, time: 0.14341998100280762
Test Loss Energy: 9.17959592035162, Test Loss Force: 7.730207624519547, time: 18.157352209091187


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.070630431944468, Training Loss Force: 3.129043473712062, time: 2.523455858230591
Validation Loss Energy: 1.648376433821817, Validation Loss Force: 2.8296336366062667, time: 0.14647531509399414
Test Loss Energy: 8.899915526925486, Test Loss Force: 7.655503303525892, time: 18.125030994415283


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7875886353693706, Training Loss Force: 3.1360429964506444, time: 2.441338300704956
Validation Loss Energy: 2.2678357073895503, Validation Loss Force: 2.805381069904677, time: 0.14198994636535645
Test Loss Energy: 9.838242766930717, Test Loss Force: 7.661899294042575, time: 18.194567680358887


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1604831218504645, Training Loss Force: 3.133420359955352, time: 2.4694888591766357
Validation Loss Energy: 1.3247480951192134, Validation Loss Force: 2.7943740886831745, time: 0.14443540573120117
Test Loss Energy: 9.008483653757144, Test Loss Force: 7.665548493933833, time: 18.7094988822937


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8335695250247515, Training Loss Force: 3.127546688438588, time: 2.4799916744232178
Validation Loss Energy: 1.5085374824821285, Validation Loss Force: 2.7745911597477932, time: 0.14659452438354492
Test Loss Energy: 8.774894234672763, Test Loss Force: 7.718987393873056, time: 18.088406801223755

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–‚â–‚â–‚â–†â–ˆâ–„â–ƒâ–‚â–„â–„â–â–‚â–…â–ƒâ–‚â–†â–‚â–
wandb:   test_error_force â–ˆâ–‡â–†â–‡â–…â–„â–‡â–„â–‚â–‚â–„â–„â–†â–ƒâ–‚â–†â–â–â–‚â–…
wandb:          test_loss â–„â–…â–‚â–„â–ƒâ–†â–ˆâ–ƒâ–‚â–…â–ƒâ–‚â–â–‚â–†â–…â–‚â–ƒâ–â–
wandb: train_error_energy â–ˆâ–â–‚â–â–â–â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–â–â–‚â–â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–„â–â–‚â–â–â–„â–ˆâ–‚â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–…â–â–‚
wandb:  valid_error_force â–„â–‚â–‡â–„â–ƒâ–„â–†â–†â–…â–ˆâ–â–‡â–…â–â–…â–†â–ˆâ–†â–…â–„
wandb:         valid_loss â–ƒâ–â–ƒâ–ƒâ–â–„â–ˆâ–ƒâ–‚â–„â–â–ƒâ–…â–â–…â–„â–ƒâ–„â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2167
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.77489
wandb:   test_error_force 7.71899
wandb:          test_loss 4.18116
wandb: train_error_energy 1.83357
wandb:  train_error_force 3.12755
wandb:         train_loss 1.43049
wandb: valid_error_energy 1.50854
wandb:  valid_error_force 2.77459
wandb:         valid_loss 1.36114
wandb: 
wandb: ğŸš€ View run al_54_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/34ahrz6z
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_085215-34ahrz6z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6858421564102173, Uncertainty Bias: 0.03163512051105499
1.5258789e-05 0.014070511
0.55146074 4.44253
Found uncertainty sample 3 after 3643 steps.
Found uncertainty sample 5 after 585 steps.
Found uncertainty sample 6 after 3700 steps.
Found uncertainty sample 8 after 1361 steps.
Found uncertainty sample 11 after 905 steps.
Found uncertainty sample 13 after 3042 steps.
Found uncertainty sample 18 after 1974 steps.
Found uncertainty sample 19 after 3581 steps.
Found uncertainty sample 23 after 2179 steps.
Found uncertainty sample 26 after 1059 steps.
Found uncertainty sample 27 after 642 steps.
Found uncertainty sample 28 after 728 steps.
Found uncertainty sample 31 after 3930 steps.
Found uncertainty sample 34 after 541 steps.
Found uncertainty sample 35 after 556 steps.
Found uncertainty sample 36 after 1263 steps.
Found uncertainty sample 37 after 1502 steps.
Found uncertainty sample 38 after 3348 steps.
Found uncertainty sample 39 after 5 steps.
Found uncertainty sample 40 after 1452 steps.
Found uncertainty sample 41 after 2140 steps.
Found uncertainty sample 42 after 1195 steps.
Found uncertainty sample 43 after 934 steps.
Found uncertainty sample 45 after 3454 steps.
Found uncertainty sample 46 after 1890 steps.
Found uncertainty sample 48 after 1106 steps.
Found uncertainty sample 49 after 2712 steps.
Found uncertainty sample 51 after 273 steps.
Found uncertainty sample 52 after 1641 steps.
Found uncertainty sample 53 after 17 steps.
Found uncertainty sample 54 after 3280 steps.
Found uncertainty sample 58 after 2658 steps.
Found uncertainty sample 60 after 1588 steps.
Found uncertainty sample 62 after 2895 steps.
Found uncertainty sample 66 after 297 steps.
Found uncertainty sample 67 after 2243 steps.
Found uncertainty sample 69 after 1389 steps.
Found uncertainty sample 71 after 3526 steps.
Found uncertainty sample 73 after 1601 steps.
Found uncertainty sample 74 after 3076 steps.
Found uncertainty sample 75 after 888 steps.
Found uncertainty sample 79 after 2664 steps.
Found uncertainty sample 80 after 1525 steps.
Found uncertainty sample 81 after 1613 steps.
Found uncertainty sample 82 after 3119 steps.
Found uncertainty sample 85 after 1690 steps.
Found uncertainty sample 86 after 3939 steps.
Found uncertainty sample 90 after 332 steps.
Found uncertainty sample 91 after 915 steps.
Found uncertainty sample 92 after 222 steps.
Found uncertainty sample 94 after 1224 steps.
Found uncertainty sample 95 after 1267 steps.
Found uncertainty sample 96 after 2053 steps.
Found uncertainty sample 98 after 1420 steps.
Found uncertainty sample 99 after 1134 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_110755-vregefjj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/vregefjj
Training model 22. Added 55 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.562182002086182, Training Loss Force: 3.352494691031686, time: 2.51033091545105
Validation Loss Energy: 1.4394285503371047, Validation Loss Force: 2.791211630138135, time: 0.14887785911560059
Test Loss Energy: 9.227553860067076, Test Loss Force: 7.635450097965117, time: 17.91466784477234


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8672686442247104, Training Loss Force: 3.1542654401769696, time: 2.523733139038086
Validation Loss Energy: 1.6093310650796604, Validation Loss Force: 2.778378761920025, time: 0.14412379264831543
Test Loss Energy: 8.787480898432287, Test Loss Force: 7.646979092607942, time: 18.02909779548645


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1135523008021724, Training Loss Force: 3.1591589032145486, time: 2.497441291809082
Validation Loss Energy: 1.7078452949649026, Validation Loss Force: 2.7976826181879426, time: 0.13874268531799316
Test Loss Energy: 8.686040576506379, Test Loss Force: 7.604450661388048, time: 18.132373809814453


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.550457135538209, Training Loss Force: 3.1588767686827075, time: 2.5013582706451416
Validation Loss Energy: 2.7898938741325345, Validation Loss Force: 2.7547966520168234, time: 0.14464044570922852
Test Loss Energy: 10.18130054904825, Test Loss Force: 7.658200181288419, time: 18.024680852890015


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8056274904899436, Training Loss Force: 3.1535952346766174, time: 2.478355884552002
Validation Loss Energy: 1.4357795597082132, Validation Loss Force: 2.8361384703662553, time: 0.14678215980529785
Test Loss Energy: 9.070384393937319, Test Loss Force: 7.639425490668055, time: 18.024758338928223


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0624209780677827, Training Loss Force: 3.160771024650078, time: 2.5386552810668945
Validation Loss Energy: 1.9197685949120746, Validation Loss Force: 2.7947240132460003, time: 0.1446540355682373
Test Loss Energy: 8.795741084365131, Test Loss Force: 7.6389376726990275, time: 18.177353143692017


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.171017147584377, Training Loss Force: 3.1455651586198643, time: 2.525707960128784
Validation Loss Energy: 2.2295363916208246, Validation Loss Force: 2.8106517599233607, time: 0.1500232219696045
Test Loss Energy: 9.741374577029141, Test Loss Force: 7.623262084256843, time: 18.052286624908447


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.132390514533114, Training Loss Force: 3.1549680567620055, time: 2.4929091930389404
Validation Loss Energy: 2.2443915410222512, Validation Loss Force: 2.805670651128956, time: 0.1445140838623047
Test Loss Energy: 9.818505136011039, Test Loss Force: 7.628214793991588, time: 18.079370975494385


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8645532552241362, Training Loss Force: 3.145799940967331, time: 2.5320959091186523
Validation Loss Energy: 1.3895059608182354, Validation Loss Force: 2.8323812625324427, time: 0.14398431777954102
Test Loss Energy: 9.012347471730866, Test Loss Force: 7.680104569527101, time: 18.153558492660522


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9734664475515038, Training Loss Force: 3.154011937716306, time: 2.5435121059417725
Validation Loss Energy: 1.331623728674458, Validation Loss Force: 2.791776987099646, time: 0.14316987991333008
Test Loss Energy: 8.890195242278244, Test Loss Force: 7.617249595294642, time: 18.416558742523193


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9192768778181106, Training Loss Force: 3.13618773064703, time: 2.5807950496673584
Validation Loss Energy: 1.4016065258826755, Validation Loss Force: 2.783965530791353, time: 0.17370891571044922
Test Loss Energy: 9.1489595650528, Test Loss Force: 7.584292626457632, time: 18.136836290359497


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.967603902942944, Training Loss Force: 3.1560722126178935, time: 2.4758644104003906
Validation Loss Energy: 1.487731277486636, Validation Loss Force: 2.7789320947476552, time: 0.14256882667541504
Test Loss Energy: 9.185284797598943, Test Loss Force: 7.604503362861403, time: 18.110338926315308


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8449228005769227, Training Loss Force: 3.1400945753278937, time: 2.489323139190674
Validation Loss Energy: 2.0596282544823343, Validation Loss Force: 2.7565140991393644, time: 0.15282440185546875
Test Loss Energy: 8.620327647283357, Test Loss Force: 7.58959749852183, time: 17.970032930374146


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.772073207301369, Training Loss Force: 3.1256671574508554, time: 2.7987046241760254
Validation Loss Energy: 1.2753195527678711, Validation Loss Force: 2.765817327390801, time: 0.14397048950195312
Test Loss Energy: 8.939236305341462, Test Loss Force: 7.603970707953362, time: 18.01107358932495


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7963004724260063, Training Loss Force: 3.1503882136735015, time: 2.500892162322998
Validation Loss Energy: 1.7176348882983312, Validation Loss Force: 2.8129860005801213, time: 0.14916491508483887
Test Loss Energy: 9.164306528809806, Test Loss Force: 7.582901564504932, time: 18.152435064315796


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.925020876554366, Training Loss Force: 3.1452396195095065, time: 2.530972480773926
Validation Loss Energy: 1.5694706715961217, Validation Loss Force: 2.7608211884290457, time: 0.14363336563110352
Test Loss Energy: 8.648307991019863, Test Loss Force: 7.611400480200355, time: 18.072762727737427


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7998532795268203, Training Loss Force: 3.149715558812544, time: 2.7645468711853027
Validation Loss Energy: 1.3057647154195722, Validation Loss Force: 2.7774560209793, time: 0.14153695106506348
Test Loss Energy: 8.825790931465193, Test Loss Force: 7.656520847895659, time: 18.013847827911377


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.691003006342869, Training Loss Force: 3.145999357092448, time: 2.546583890914917
Validation Loss Energy: 1.4023435607556967, Validation Loss Force: 2.7710418135617045, time: 0.14628911018371582
Test Loss Energy: 8.85840116597036, Test Loss Force: 7.582562072166464, time: 18.12765598297119


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8567126030145769, Training Loss Force: 3.126005722706251, time: 2.530665159225464
Validation Loss Energy: 1.3284748529473203, Validation Loss Force: 2.7487766803220928, time: 0.1429286003112793
Test Loss Energy: 8.816772756443466, Test Loss Force: 7.56659005163489, time: 18.146069288253784


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.730519011772846, Training Loss Force: 3.1239348074004765, time: 2.5444772243499756
Validation Loss Energy: 1.892142479315106, Validation Loss Force: 2.7512193608529207, time: 0.14599871635437012
Test Loss Energy: 8.581331166076803, Test Loss Force: 7.584068283212784, time: 18.01404047012329

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–â–ˆâ–ƒâ–‚â–†â–†â–ƒâ–‚â–ƒâ–„â–â–ƒâ–„â–â–‚â–‚â–‚â–
wandb:   test_error_force â–…â–†â–ƒâ–‡â–…â–…â–„â–…â–ˆâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–„â–‡â–‚â–â–‚
wandb:          test_loss â–„â–ƒâ–ƒâ–ˆâ–„â–‚â–„â–…â–„â–ƒâ–‚â–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–„â–ˆâ–‚â–„â–…â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–ˆâ–‚â–„â–…â–…â–‚â–â–‚â–‚â–…â–â–ƒâ–‚â–â–‚â–â–„
wandb:  valid_error_force â–„â–ƒâ–…â–â–ˆâ–…â–†â–†â–ˆâ–„â–„â–ƒâ–‚â–‚â–†â–‚â–ƒâ–ƒâ–â–
wandb:         valid_loss â–‚â–ƒâ–ˆâ–†â–ƒâ–„â–†â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–„â–„â–„â–„â–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2216
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.58133
wandb:   test_error_force 7.58407
wandb:          test_loss 4.12919
wandb: train_error_energy 1.73052
wandb:  train_error_force 3.12393
wandb:         train_loss 1.41875
wandb: valid_error_energy 1.89214
wandb:  valid_error_force 2.75122
wandb:         valid_loss 1.38315
wandb: 
wandb: ğŸš€ View run al_54_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/vregefjj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_110755-vregefjj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6849445700645447, Uncertainty Bias: 0.0300896018743515
6.1035156e-05 0.0093307495
0.5580563 4.182311
Found uncertainty sample 0 after 732 steps.
Found uncertainty sample 1 after 1195 steps.
Found uncertainty sample 2 after 2382 steps.
Found uncertainty sample 3 after 954 steps.
Found uncertainty sample 4 after 2893 steps.
Found uncertainty sample 5 after 547 steps.
Found uncertainty sample 6 after 976 steps.
Found uncertainty sample 7 after 2596 steps.
Found uncertainty sample 9 after 3582 steps.
Found uncertainty sample 11 after 1023 steps.
Found uncertainty sample 14 after 3260 steps.
Found uncertainty sample 15 after 1486 steps.
Found uncertainty sample 17 after 1383 steps.
Found uncertainty sample 18 after 3721 steps.
Found uncertainty sample 21 after 1769 steps.
Found uncertainty sample 22 after 265 steps.
Found uncertainty sample 23 after 2113 steps.
Found uncertainty sample 24 after 224 steps.
Found uncertainty sample 27 after 1998 steps.
Found uncertainty sample 30 after 2971 steps.
Found uncertainty sample 35 after 723 steps.
Found uncertainty sample 36 after 3013 steps.
Found uncertainty sample 37 after 3001 steps.
Found uncertainty sample 39 after 1184 steps.
Found uncertainty sample 41 after 3365 steps.
Found uncertainty sample 43 after 1852 steps.
Found uncertainty sample 45 after 641 steps.
Found uncertainty sample 47 after 3826 steps.
Found uncertainty sample 48 after 10 steps.
Found uncertainty sample 49 after 2798 steps.
Found uncertainty sample 50 after 35 steps.
Found uncertainty sample 51 after 1894 steps.
Found uncertainty sample 52 after 2115 steps.
Found uncertainty sample 54 after 3860 steps.
Found uncertainty sample 57 after 753 steps.
Found uncertainty sample 58 after 2865 steps.
Found uncertainty sample 61 after 2693 steps.
Found uncertainty sample 62 after 1088 steps.
Found uncertainty sample 65 after 3059 steps.
Found uncertainty sample 67 after 1047 steps.
Found uncertainty sample 70 after 517 steps.
Found uncertainty sample 71 after 791 steps.
Found uncertainty sample 75 after 1336 steps.
Found uncertainty sample 79 after 2715 steps.
Found uncertainty sample 80 after 2971 steps.
Found uncertainty sample 86 after 28 steps.
Found uncertainty sample 87 after 1436 steps.
Found uncertainty sample 88 after 84 steps.
Found uncertainty sample 91 after 2378 steps.
Found uncertainty sample 93 after 942 steps.
Found uncertainty sample 94 after 1347 steps.
Found uncertainty sample 97 after 2812 steps.
Found uncertainty sample 98 after 2523 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_132636-nr4b9y3n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nr4b9y3n
Training model 23. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.9988635638371384, Training Loss Force: 3.369310137291402, time: 2.5313003063201904
Validation Loss Energy: 1.3752675492837423, Validation Loss Force: 2.75471237174509, time: 0.14551472663879395
Test Loss Energy: 8.784318819357441, Test Loss Force: 7.556121388812063, time: 18.0789897441864


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8181880007630018, Training Loss Force: 3.15786952524913, time: 2.6103570461273193
Validation Loss Energy: 1.3159280032471543, Validation Loss Force: 2.7440910534843344, time: 0.14719414710998535
Test Loss Energy: 8.780027490613223, Test Loss Force: 7.561734281087694, time: 18.24521493911743


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8212875301848352, Training Loss Force: 3.1502202473475154, time: 2.517641544342041
Validation Loss Energy: 1.589154958099857, Validation Loss Force: 2.8053914240199624, time: 0.14197945594787598
Test Loss Energy: 8.531338368451607, Test Loss Force: 7.546417012767781, time: 18.254865884780884


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9347830162605888, Training Loss Force: 3.133756147148948, time: 2.5737178325653076
Validation Loss Energy: 1.35554017630027, Validation Loss Force: 2.7753838619072964, time: 0.14708852767944336
Test Loss Energy: 8.749187760275102, Test Loss Force: 7.547414624168662, time: 18.084768056869507


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.157473381617128, Training Loss Force: 3.145228108589925, time: 2.5987439155578613
Validation Loss Energy: 1.962310258916303, Validation Loss Force: 2.8054497633361954, time: 0.15287423133850098
Test Loss Energy: 9.233221881026333, Test Loss Force: 7.52658110198245, time: 18.26579260826111


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.152483518161866, Training Loss Force: 3.1844685684338585, time: 2.5694210529327393
Validation Loss Energy: 1.7684287265179295, Validation Loss Force: 2.780610574769659, time: 0.15341687202453613
Test Loss Energy: 8.567117809775906, Test Loss Force: 7.54687347752209, time: 18.222512245178223


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9778885200967598, Training Loss Force: 3.155135261039802, time: 2.5614380836486816
Validation Loss Energy: 1.685762973094098, Validation Loss Force: 2.7965318640417878, time: 0.1464524269104004
Test Loss Energy: 9.126898331465664, Test Loss Force: 7.53431494701822, time: 18.133606910705566


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9877558665165702, Training Loss Force: 3.148482004181219, time: 2.5483720302581787
Validation Loss Energy: 2.489059062552829, Validation Loss Force: 2.8259764072189757, time: 0.15344524383544922
Test Loss Energy: 9.788225900053233, Test Loss Force: 7.511101329486679, time: 18.274066925048828


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2934840568152777, Training Loss Force: 3.14868058428898, time: 2.5439047813415527
Validation Loss Energy: 1.4539622768263845, Validation Loss Force: 2.7704511836521304, time: 0.1502840518951416
Test Loss Energy: 8.936652965527216, Test Loss Force: 7.485598108884386, time: 18.624253034591675


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.861621392757014, Training Loss Force: 3.142307520484419, time: 2.5420215129852295
Validation Loss Energy: 1.3168356583532423, Validation Loss Force: 2.7570885855358584, time: 0.15628576278686523
Test Loss Energy: 8.790057243404252, Test Loss Force: 7.517084892444435, time: 18.186375379562378


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8811024340775724, Training Loss Force: 3.15514123547252, time: 2.7872188091278076
Validation Loss Energy: 1.332715920835234, Validation Loss Force: 2.7722101585703873, time: 0.1490483283996582
Test Loss Energy: 8.682638187293373, Test Loss Force: 7.484476206131025, time: 18.222429275512695


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8978192276906392, Training Loss Force: 3.142938132050426, time: 2.5651774406433105
Validation Loss Energy: 1.4842935998772298, Validation Loss Force: 2.751221364875234, time: 0.14174818992614746
Test Loss Energy: 8.910933788495974, Test Loss Force: 7.513396554079006, time: 18.315120220184326


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7247584482666407, Training Loss Force: 3.138526657974082, time: 2.5904619693756104
Validation Loss Energy: 1.6690220943630956, Validation Loss Force: 2.740019102812753, time: 0.15112543106079102
Test Loss Energy: 8.534199240291398, Test Loss Force: 7.517287309190348, time: 18.250057458877563


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9919758419912312, Training Loss Force: 3.1391197105866877, time: 2.6465306282043457
Validation Loss Energy: 1.4690490021395757, Validation Loss Force: 2.7439150335244786, time: 0.14528155326843262
Test Loss Energy: 8.455493200340081, Test Loss Force: 7.485107117588582, time: 18.180039644241333


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9508747383787215, Training Loss Force: 3.1262005753235487, time: 2.6419286727905273
Validation Loss Energy: 1.4973206355905893, Validation Loss Force: 2.8141337486928064, time: 0.15036988258361816
Test Loss Energy: 8.524592938930732, Test Loss Force: 7.517153516510434, time: 18.365839958190918


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0255408494881464, Training Loss Force: 3.1338850914015506, time: 2.6077053546905518
Validation Loss Energy: 1.6308424632603062, Validation Loss Force: 2.7583500062475395, time: 0.14397859573364258
Test Loss Energy: 8.530950607038177, Test Loss Force: 7.477702505789267, time: 18.26960015296936


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9728683516843557, Training Loss Force: 3.13609774529608, time: 2.5965750217437744
Validation Loss Energy: 1.94716074090396, Validation Loss Force: 2.7692327380856137, time: 0.14918160438537598
Test Loss Energy: 8.423246630016687, Test Loss Force: 7.510636310040259, time: 18.172728061676025


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8494546973083719, Training Loss Force: 3.1294084066273022, time: 2.615710973739624
Validation Loss Energy: 1.6007289663014646, Validation Loss Force: 2.7801385161802923, time: 0.1492009162902832
Test Loss Energy: 8.928928668451158, Test Loss Force: 7.478395349580374, time: 18.2613468170166


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9633118780498335, Training Loss Force: 3.1192599278660165, time: 2.5746989250183105
Validation Loss Energy: 1.6567571994689605, Validation Loss Force: 2.7854725555709923, time: 0.1526341438293457
Test Loss Energy: 8.408562434560595, Test Loss Force: 7.464965299034185, time: 18.25483536720276


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0410299975355475, Training Loss Force: 3.1291148722416358, time: 2.547356128692627
Validation Loss Energy: 1.8933123273405241, Validation Loss Force: 2.8177329727675833, time: 0.14500880241394043
Test Loss Energy: 8.526517996469579, Test Loss Force: 7.456858565951286, time: 18.435912609100342

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–…â–ˆâ–„â–ƒâ–‚â–„â–‚â–â–‚â–‚â–â–„â–â–‚
wandb:   test_error_force â–ˆâ–ˆâ–‡â–‡â–†â–‡â–†â–…â–ƒâ–…â–ƒâ–…â–…â–ƒâ–…â–‚â–…â–‚â–‚â–
wandb:          test_loss â–‡â–†â–„â–‡â–‡â–„â–ˆâ–ˆâ–„â–„â–ƒâ–„â–„â–â–‚â–ƒâ–„â–ƒâ–„â–‚
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–â–‚â–‚â–â–â–‚
wandb: valid_error_energy â–â–â–ƒâ–â–…â–„â–ƒâ–ˆâ–‚â–â–â–‚â–ƒâ–‚â–‚â–ƒâ–…â–ƒâ–ƒâ–„
wandb:  valid_error_force â–‚â–â–†â–„â–†â–„â–†â–ˆâ–ƒâ–‚â–„â–‚â–â–â–‡â–‚â–ƒâ–„â–…â–‡
wandb:         valid_loss â–ƒâ–â–„â–‡â–…â–„â–„â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–†â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2263
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.52652
wandb:   test_error_force 7.45686
wandb:          test_loss 4.06826
wandb: train_error_energy 2.04103
wandb:  train_error_force 3.12911
wandb:         train_loss 1.44055
wandb: valid_error_energy 1.89331
wandb:  valid_error_force 2.81773
wandb:         valid_loss 1.41318
wandb: 
wandb: ğŸš€ View run al_54_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nr4b9y3n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_132636-nr4b9y3n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.684354305267334, Uncertainty Bias: 0.034272998571395874
0.00023651123 0.002380371
0.64974725 6.9533687
Found uncertainty sample 0 after 2424 steps.
Found uncertainty sample 1 after 392 steps.
Found uncertainty sample 3 after 1686 steps.
Found uncertainty sample 5 after 875 steps.
Found uncertainty sample 7 after 1828 steps.
Found uncertainty sample 8 after 3659 steps.
Found uncertainty sample 10 after 2964 steps.
Found uncertainty sample 11 after 3846 steps.
Found uncertainty sample 12 after 2999 steps.
Found uncertainty sample 14 after 2903 steps.
Found uncertainty sample 15 after 693 steps.
Found uncertainty sample 17 after 505 steps.
Found uncertainty sample 19 after 3433 steps.
Found uncertainty sample 20 after 1453 steps.
Found uncertainty sample 22 after 3742 steps.
Found uncertainty sample 23 after 695 steps.
Found uncertainty sample 24 after 3625 steps.
Found uncertainty sample 25 after 2315 steps.
Found uncertainty sample 26 after 3463 steps.
Found uncertainty sample 28 after 1874 steps.
Found uncertainty sample 29 after 1294 steps.
Found uncertainty sample 30 after 2273 steps.
Found uncertainty sample 33 after 2761 steps.
Found uncertainty sample 34 after 375 steps.
Found uncertainty sample 35 after 671 steps.
Found uncertainty sample 38 after 929 steps.
Found uncertainty sample 39 after 1408 steps.
Found uncertainty sample 40 after 1318 steps.
Found uncertainty sample 42 after 577 steps.
Found uncertainty sample 47 after 3703 steps.
Found uncertainty sample 49 after 737 steps.
Found uncertainty sample 52 after 1415 steps.
Found uncertainty sample 54 after 3634 steps.
Found uncertainty sample 57 after 1777 steps.
Found uncertainty sample 58 after 3792 steps.
Found uncertainty sample 59 after 1195 steps.
Found uncertainty sample 60 after 2943 steps.
Found uncertainty sample 62 after 2329 steps.
Found uncertainty sample 66 after 1395 steps.
Found uncertainty sample 67 after 833 steps.
Found uncertainty sample 71 after 509 steps.
Found uncertainty sample 73 after 2658 steps.
Found uncertainty sample 74 after 453 steps.
Found uncertainty sample 75 after 210 steps.
Found uncertainty sample 76 after 56 steps.
Found uncertainty sample 79 after 1716 steps.
Found uncertainty sample 81 after 2895 steps.
Found uncertainty sample 82 after 2010 steps.
Found uncertainty sample 88 after 3497 steps.
Found uncertainty sample 91 after 1209 steps.
Found uncertainty sample 92 after 1546 steps.
Found uncertainty sample 96 after 108 steps.
Found uncertainty sample 98 after 959 steps.
Found uncertainty sample 99 after 2367 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_154526-tiehv86d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/tiehv86d
Training model 24. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1984534257891717, Training Loss Force: 3.3039709793089305, time: 2.6107146739959717
Validation Loss Energy: 1.4428476907401124, Validation Loss Force: 2.7925642338650736, time: 0.14975500106811523
Test Loss Energy: 8.477455774008465, Test Loss Force: 7.446579004026283, time: 17.99432396888733


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0132218570863434, Training Loss Force: 3.1565166493829464, time: 2.652082681655884
Validation Loss Energy: 1.624727244838405, Validation Loss Force: 2.7738976566928013, time: 0.14414548873901367
Test Loss Energy: 8.332193567270759, Test Loss Force: 7.461675100096517, time: 18.148022651672363


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9008172361032099, Training Loss Force: 3.1554947566167764, time: 2.5326459407806396
Validation Loss Energy: 1.3837490727194182, Validation Loss Force: 2.795086963953862, time: 0.15003728866577148
Test Loss Energy: 8.4416414470741, Test Loss Force: 7.427102926580773, time: 18.159021139144897


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8801753708507647, Training Loss Force: 3.159678441445679, time: 2.6534066200256348
Validation Loss Energy: 2.9005490835322028, Validation Loss Force: 2.8239402092140393, time: 0.14376330375671387
Test Loss Energy: 10.004172149178748, Test Loss Force: 7.474078335775305, time: 17.997180223464966


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.5797848007918662, Training Loss Force: 3.183873924013961, time: 2.6806042194366455
Validation Loss Energy: 1.8658360680787647, Validation Loss Force: 2.8514722470968534, time: 0.14592337608337402
Test Loss Energy: 8.457629812220471, Test Loss Force: 7.4608713227700685, time: 18.126434326171875


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8892236841086536, Training Loss Force: 3.1575700330568233, time: 2.6248159408569336
Validation Loss Energy: 1.88804575670104, Validation Loss Force: 2.8508881859270847, time: 0.1479949951171875
Test Loss Energy: 9.092621669051741, Test Loss Force: 7.433137575203317, time: 18.16585636138916


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9301992801689902, Training Loss Force: 3.155276220576228, time: 2.599916458129883
Validation Loss Energy: 1.5537547389438249, Validation Loss Force: 2.7846240747904343, time: 0.15268731117248535
Test Loss Energy: 8.311431784186974, Test Loss Force: 7.415032120781363, time: 18.012892723083496


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.868229197098968, Training Loss Force: 3.1432627992172306, time: 2.6364316940307617
Validation Loss Energy: 1.3863839167231817, Validation Loss Force: 2.774878180276894, time: 0.1436171531677246
Test Loss Energy: 8.365366991502139, Test Loss Force: 7.410899001379844, time: 18.106560707092285


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8727946588544817, Training Loss Force: 3.1428161615136463, time: 2.6719532012939453
Validation Loss Energy: 2.011072797852175, Validation Loss Force: 2.7542171555645467, time: 0.14831924438476562
Test Loss Energy: 9.094918075772414, Test Loss Force: 7.389680744215295, time: 18.44124674797058


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8956508642916967, Training Loss Force: 3.1452340891661295, time: 2.662278890609741
Validation Loss Energy: 1.457392940357694, Validation Loss Force: 2.7778033848469477, time: 0.1425924301147461
Test Loss Energy: 8.740699652069775, Test Loss Force: 7.439132392862303, time: 18.056458234786987


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.765875990236596, Training Loss Force: 3.1365879743407685, time: 2.8276031017303467
Validation Loss Energy: 1.3877475425728436, Validation Loss Force: 2.8260210523827345, time: 0.1435391902923584
Test Loss Energy: 8.577307814403575, Test Loss Force: 7.43163988154328, time: 18.08931851387024


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0310727498980166, Training Loss Force: 3.154872271293155, time: 2.7212867736816406
Validation Loss Energy: 1.4377972205067513, Validation Loss Force: 2.862335050046368, time: 0.1532292366027832
Test Loss Energy: 8.336560731763365, Test Loss Force: 7.420090949268343, time: 18.2339129447937


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.920952655634554, Training Loss Force: 3.134680285410524, time: 2.676624059677124
Validation Loss Energy: 1.3586233646293588, Validation Loss Force: 2.855458136143534, time: 0.14892578125
Test Loss Energy: 8.421193373340142, Test Loss Force: 7.40236128808468, time: 18.236732006072998


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7336674030965475, Training Loss Force: 3.1425157411823808, time: 2.697129011154175
Validation Loss Energy: 1.3280063570642882, Validation Loss Force: 2.8052034912607997, time: 0.14556050300598145
Test Loss Energy: 8.485431593954857, Test Loss Force: 7.401410821920767, time: 18.058568716049194


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.870561060076287, Training Loss Force: 3.1349137494346357, time: 2.676272392272949
Validation Loss Energy: 1.7572419956283771, Validation Loss Force: 2.7865752131816266, time: 0.14680814743041992
Test Loss Energy: 8.34673831588276, Test Loss Force: 7.397547561202816, time: 18.195817708969116


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8359362046264327, Training Loss Force: 3.1501086370480267, time: 2.698453903198242
Validation Loss Energy: 1.7617757064413262, Validation Loss Force: 2.775583150792902, time: 0.14987397193908691
Test Loss Energy: 8.891015970439154, Test Loss Force: 7.394132772466062, time: 18.117770671844482


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9393515387394866, Training Loss Force: 3.139295332229548, time: 2.6825814247131348
Validation Loss Energy: 1.9341139989711862, Validation Loss Force: 2.846059494163068, time: 0.14922738075256348
Test Loss Energy: 8.269028089657855, Test Loss Force: 7.41381721460504, time: 18.05488395690918


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.780406326359359, Training Loss Force: 3.14640310218225, time: 2.6584365367889404
Validation Loss Energy: 1.480426950158194, Validation Loss Force: 2.76185359392414, time: 0.15009498596191406
Test Loss Energy: 8.71715068081478, Test Loss Force: 7.386467269370988, time: 18.196661233901978


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.01579269438657, Training Loss Force: 3.1383566750202827, time: 2.679373025894165
Validation Loss Energy: 1.6422225823030971, Validation Loss Force: 2.896181205565683, time: 0.1475973129272461
Test Loss Energy: 8.808273011152197, Test Loss Force: 7.396105392600801, time: 18.466973304748535


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9484448113381487, Training Loss Force: 3.1473030576637955, time: 2.652292490005493
Validation Loss Energy: 1.5786224291610402, Validation Loss Force: 2.7860842277148556, time: 0.1479027271270752
Test Loss Energy: 8.790869838895201, Test Loss Force: 7.409091347605448, time: 18.07320284843445

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–ˆâ–‚â–„â–â–â–„â–ƒâ–‚â–â–‚â–‚â–â–„â–â–ƒâ–ƒâ–ƒ
wandb:   test_error_force â–†â–‡â–„â–ˆâ–‡â–…â–ƒâ–ƒâ–â–…â–…â–„â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–ƒ
wandb:          test_loss â–‚â–ƒâ–…â–ˆâ–‡â–…â–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–„â–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–…â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–…â–‚â–‚â–‚â–â–‚â–â–ƒâ–â–â–‚â–‚â–‚â–â–ƒâ–‚
wandb: valid_error_energy â–‚â–‚â–â–ˆâ–ƒâ–ƒâ–‚â–â–„â–‚â–â–â–â–â–ƒâ–ƒâ–„â–‚â–‚â–‚
wandb:  valid_error_force â–ƒâ–‚â–ƒâ–„â–†â–†â–‚â–‚â–â–‚â–…â–†â–†â–„â–ƒâ–‚â–†â–â–ˆâ–ƒ
wandb:         valid_loss â–ƒâ–ƒâ–ƒâ–ˆâ–ˆâ–†â–‚â–ƒâ–…â–â–‚â–†â–‚â–ƒâ–ƒâ–‚â–…â–â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2311
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.79087
wandb:   test_error_force 7.40909
wandb:          test_loss 4.01569
wandb: train_error_energy 1.94844
wandb:  train_error_force 3.1473
wandb:         train_loss 1.42476
wandb: valid_error_energy 1.57862
wandb:  valid_error_force 2.78608
wandb:         valid_loss 1.40389
wandb: 
wandb: ğŸš€ View run al_54_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/tiehv86d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_154526-tiehv86d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6691540479660034, Uncertainty Bias: 0.03767448663711548
5.340576e-05 0.005760193
0.77103186 4.6632104
Found uncertainty sample 2 after 3467 steps.
Found uncertainty sample 6 after 2941 steps.
Found uncertainty sample 7 after 2893 steps.
Found uncertainty sample 8 after 3636 steps.
Found uncertainty sample 10 after 2042 steps.
Found uncertainty sample 11 after 1853 steps.
Found uncertainty sample 12 after 2392 steps.
Found uncertainty sample 16 after 3526 steps.
Found uncertainty sample 17 after 3190 steps.
Found uncertainty sample 19 after 1248 steps.
Found uncertainty sample 20 after 3617 steps.
Found uncertainty sample 21 after 2956 steps.
Found uncertainty sample 23 after 2218 steps.
Found uncertainty sample 26 after 1591 steps.
Found uncertainty sample 28 after 536 steps.
Found uncertainty sample 34 after 1808 steps.
Found uncertainty sample 39 after 1962 steps.
Found uncertainty sample 45 after 1359 steps.
Found uncertainty sample 46 after 642 steps.
Found uncertainty sample 47 after 3839 steps.
Found uncertainty sample 48 after 2691 steps.
Found uncertainty sample 49 after 266 steps.
Found uncertainty sample 50 after 580 steps.
Found uncertainty sample 51 after 2769 steps.
Found uncertainty sample 53 after 1662 steps.
Found uncertainty sample 55 after 468 steps.
Found uncertainty sample 56 after 684 steps.
Found uncertainty sample 61 after 1369 steps.
Found uncertainty sample 62 after 802 steps.
Found uncertainty sample 64 after 1169 steps.
Found uncertainty sample 66 after 3203 steps.
Found uncertainty sample 70 after 3222 steps.
Found uncertainty sample 72 after 3283 steps.
Found uncertainty sample 73 after 3370 steps.
Found uncertainty sample 75 after 873 steps.
Found uncertainty sample 77 after 2911 steps.
Found uncertainty sample 78 after 3648 steps.
Found uncertainty sample 80 after 1735 steps.
Found uncertainty sample 82 after 559 steps.
Found uncertainty sample 83 after 1902 steps.
Found uncertainty sample 84 after 3151 steps.
Found uncertainty sample 85 after 1262 steps.
Found uncertainty sample 86 after 539 steps.
Found uncertainty sample 87 after 1320 steps.
Found uncertainty sample 90 after 3263 steps.
Found uncertainty sample 91 after 1642 steps.
Found uncertainty sample 93 after 3642 steps.
Found uncertainty sample 95 after 481 steps.
Found uncertainty sample 96 after 2730 steps.
Found uncertainty sample 97 after 1123 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_181334-9m4lcs8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9m4lcs8d
Training model 25. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0983594490176545, Training Loss Force: 3.290081010960902, time: 2.644559621810913
Validation Loss Energy: 2.3118012849147003, Validation Loss Force: 2.8226910353053842, time: 0.15434479713439941
Test Loss Energy: 8.24302413860769, Test Loss Force: 7.401122457216143, time: 18.12849497795105


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.145121857914769, Training Loss Force: 3.1597516886302333, time: 2.6728358268737793
Validation Loss Energy: 1.576567693949705, Validation Loss Force: 2.7987507620809584, time: 0.15294146537780762
Test Loss Energy: 8.745156917125795, Test Loss Force: 7.348159549299263, time: 18.19552254676819


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.821665493514363, Training Loss Force: 3.1503432492073467, time: 2.623594284057617
Validation Loss Energy: 1.3131343404750577, Validation Loss Force: 2.7418675907276726, time: 0.14507365226745605
Test Loss Energy: 8.434056209794193, Test Loss Force: 7.33016267348241, time: 18.253363847732544


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.880229735675256, Training Loss Force: 3.1556950900935505, time: 2.669420003890991
Validation Loss Energy: 1.3680335297381268, Validation Loss Force: 2.8223781851553555, time: 0.14428043365478516
Test Loss Energy: 8.54107284330222, Test Loss Force: 7.339010897152865, time: 18.46605110168457


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9470454735124325, Training Loss Force: 3.1383542489076226, time: 2.63209867477417
Validation Loss Energy: 1.4389665118593045, Validation Loss Force: 2.8308557562136913, time: 0.14713335037231445
Test Loss Energy: 8.260990265097876, Test Loss Force: 7.31605702376295, time: 18.263965368270874


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.794284777370462, Training Loss Force: 3.1457657643484462, time: 2.700594425201416
Validation Loss Energy: 1.3103242001861626, Validation Loss Force: 2.764548558597304, time: 0.1448521614074707
Test Loss Energy: 8.435958230985795, Test Loss Force: 7.319953638220508, time: 18.226562023162842


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.016110472132252, Training Loss Force: 3.147035956419051, time: 2.656397819519043
Validation Loss Energy: 1.3505934698889113, Validation Loss Force: 2.7519774379602318, time: 0.1530921459197998
Test Loss Energy: 8.539160800833244, Test Loss Force: 7.320508049419656, time: 18.20769166946411


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9554167290807147, Training Loss Force: 3.142298754592628, time: 2.900653123855591
Validation Loss Energy: 1.3701717102118982, Validation Loss Force: 2.7651391885068772, time: 0.14683866500854492
Test Loss Energy: 8.552968502914156, Test Loss Force: 7.323364283679018, time: 18.165668725967407


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.875610002354958, Training Loss Force: 3.156324891718553, time: 2.713146686553955
Validation Loss Energy: 1.3837033698772165, Validation Loss Force: 2.780633732360836, time: 0.15042352676391602
Test Loss Energy: 8.514266471925012, Test Loss Force: 7.322022159974526, time: 18.277424573898315


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8427925436858401, Training Loss Force: 3.139715563812634, time: 2.6709718704223633
Validation Loss Energy: 1.7851352585331728, Validation Loss Force: 2.7594089093709986, time: 0.1491374969482422
Test Loss Energy: 8.166666628610102, Test Loss Force: 7.290912689865156, time: 18.281736850738525


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7591493975866495, Training Loss Force: 3.143718423859086, time: 2.725904703140259
Validation Loss Energy: 1.3664477357481155, Validation Loss Force: 2.8137900588660667, time: 0.16487932205200195
Test Loss Energy: 8.408284704347848, Test Loss Force: 7.339098430609162, time: 18.233431816101074


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.987575233016449, Training Loss Force: 3.1422208595091052, time: 2.6815025806427
Validation Loss Energy: 1.4284658246083555, Validation Loss Force: 2.776517136525496, time: 0.1521589756011963
Test Loss Energy: 8.233475281223445, Test Loss Force: 7.3239646929610025, time: 18.338557958602905


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.170109393781695, Training Loss Force: 3.1484144318935123, time: 2.6868247985839844
Validation Loss Energy: 1.3169943657870025, Validation Loss Force: 2.791459015559261, time: 0.14930105209350586
Test Loss Energy: 8.500588409919313, Test Loss Force: 7.306043086310319, time: 18.262070178985596


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9605993278753227, Training Loss Force: 3.1314648354421917, time: 2.6729917526245117
Validation Loss Energy: 1.2654324860158126, Validation Loss Force: 2.7961644599510067, time: 0.14699649810791016
Test Loss Energy: 8.462720917241349, Test Loss Force: 7.319139995834833, time: 18.236621618270874


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8076383438456327, Training Loss Force: 3.135683434809664, time: 2.6571834087371826
Validation Loss Energy: 1.53451840709441, Validation Loss Force: 2.7750617709877115, time: 0.14833450317382812
Test Loss Energy: 8.164900298032284, Test Loss Force: 7.268629626513166, time: 18.57397150993347


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2053607240096853, Training Loss Force: 3.132359655477442, time: 2.660804033279419
Validation Loss Energy: 1.3234711989018906, Validation Loss Force: 2.749658450139967, time: 0.15234589576721191
Test Loss Energy: 8.343450600114101, Test Loss Force: 7.328804230810879, time: 18.2427237033844


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9526396401147774, Training Loss Force: 3.1411719855243403, time: 2.6625664234161377
Validation Loss Energy: 1.4763219887857284, Validation Loss Force: 2.794569703527872, time: 0.15106630325317383
Test Loss Energy: 8.578812286065784, Test Loss Force: 7.287784202354555, time: 18.155987977981567


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9909862986538736, Training Loss Force: 3.128916411139388, time: 2.686248302459717
Validation Loss Energy: 1.5129249553334896, Validation Loss Force: 2.7786055504451523, time: 0.15155744552612305
Test Loss Energy: 8.159422662690218, Test Loss Force: 7.298348629231431, time: 18.289897680282593


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.056670979537182, Training Loss Force: 3.149052285716277, time: 2.6637041568756104
Validation Loss Energy: 1.5174713026204705, Validation Loss Force: 2.8170474858018446, time: 0.14905142784118652
Test Loss Energy: 8.656336708295195, Test Loss Force: 7.275041539622494, time: 18.285021543502808


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6955426802183515, Training Loss Force: 3.119578702269801, time: 2.6407814025878906
Validation Loss Energy: 1.3346082189046147, Validation Loss Force: 2.7895209033131056, time: 0.15032291412353516
Test Loss Energy: 8.299266130657855, Test Loss Force: 7.216683810632919, time: 18.077468156814575

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–„â–†â–‚â–„â–†â–†â–…â–â–„â–‚â–…â–…â–â–ƒâ–†â–â–‡â–ƒ
wandb:   test_error_force â–ˆâ–†â–…â–†â–…â–…â–…â–…â–…â–„â–†â–…â–„â–…â–ƒâ–…â–„â–„â–ƒâ–
wandb:          test_loss â–ˆâ–‡â–‡â–‡â–„â–†â–ƒâ–…â–„â–â–‚â–…â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–ƒâ–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–ˆâ–ƒâ–â–‚â–‚â–â–‚â–‚â–‚â–„â–‚â–‚â–â–â–ƒâ–â–‚â–ƒâ–ƒâ–
wandb:  valid_error_force â–‡â–…â–â–‡â–ˆâ–ƒâ–‚â–ƒâ–„â–‚â–‡â–„â–…â–…â–„â–‚â–…â–„â–‡â–…
wandb:         valid_loss â–†â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–ƒâ–ˆâ–‚â–â–ƒâ–‚â–â–†â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2356
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.29927
wandb:   test_error_force 7.21668
wandb:          test_loss 3.9612
wandb: train_error_energy 1.69554
wandb:  train_error_force 3.11958
wandb:         train_loss 1.40493
wandb: valid_error_energy 1.33461
wandb:  valid_error_force 2.78952
wandb:         valid_loss 1.37634
wandb: 
wandb: ğŸš€ View run al_54_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9m4lcs8d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_181334-9m4lcs8d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.690211296081543, Uncertainty Bias: 0.02972768247127533
6.1035156e-05 0.0053653717
0.48399186 7.0755215
Found uncertainty sample 1 after 1901 steps.
Found uncertainty sample 2 after 1495 steps.
Found uncertainty sample 3 after 2130 steps.
Found uncertainty sample 4 after 1853 steps.
Found uncertainty sample 5 after 1302 steps.
Found uncertainty sample 6 after 977 steps.
Found uncertainty sample 9 after 1489 steps.
Found uncertainty sample 10 after 1708 steps.
Found uncertainty sample 12 after 1947 steps.
Found uncertainty sample 13 after 82 steps.
Found uncertainty sample 14 after 1845 steps.
Found uncertainty sample 15 after 1824 steps.
Found uncertainty sample 17 after 4 steps.
Found uncertainty sample 18 after 1734 steps.
Found uncertainty sample 26 after 1208 steps.
Found uncertainty sample 27 after 1173 steps.
Found uncertainty sample 28 after 1562 steps.
Found uncertainty sample 31 after 529 steps.
Found uncertainty sample 36 after 3096 steps.
Found uncertainty sample 38 after 3302 steps.
Found uncertainty sample 39 after 2821 steps.
Found uncertainty sample 43 after 3076 steps.
Found uncertainty sample 47 after 754 steps.
Found uncertainty sample 48 after 22 steps.
Found uncertainty sample 49 after 1672 steps.
Found uncertainty sample 51 after 1028 steps.
Found uncertainty sample 52 after 3488 steps.
Found uncertainty sample 54 after 1643 steps.
Found uncertainty sample 55 after 764 steps.
Found uncertainty sample 56 after 2148 steps.
Found uncertainty sample 59 after 2652 steps.
Found uncertainty sample 65 after 511 steps.
Found uncertainty sample 68 after 3387 steps.
Found uncertainty sample 71 after 1879 steps.
Found uncertainty sample 77 after 3255 steps.
Found uncertainty sample 78 after 233 steps.
Found uncertainty sample 83 after 775 steps.
Found uncertainty sample 85 after 2866 steps.
Found uncertainty sample 91 after 13 steps.
Found uncertainty sample 92 after 1703 steps.
Found uncertainty sample 93 after 670 steps.
Found uncertainty sample 95 after 2087 steps.
Found uncertainty sample 99 after 478 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_203753-lbc5zum6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/lbc5zum6
Training model 26. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0951171435034563, Training Loss Force: 3.3647796470374414, time: 2.6686928272247314
Validation Loss Energy: 1.599400021171281, Validation Loss Force: 2.8148957225101716, time: 0.1525888442993164
Test Loss Energy: 8.750168120063305, Test Loss Force: 7.305536543148508, time: 18.046754837036133


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.863126977274983, Training Loss Force: 3.146068991460158, time: 2.729004144668579
Validation Loss Energy: 1.439854572080551, Validation Loss Force: 2.778303722417847, time: 0.14651799201965332
Test Loss Energy: 8.195502427567826, Test Loss Force: 7.2709178376103, time: 18.13434147834778


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0148724300961307, Training Loss Force: 3.1360864961344594, time: 2.7254796028137207
Validation Loss Energy: 1.4263729016384938, Validation Loss Force: 2.786953639395131, time: 0.1441643238067627
Test Loss Energy: 8.417094493691584, Test Loss Force: 7.228342172552102, time: 18.157710313796997


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0467994507183676, Training Loss Force: 3.1339689867797347, time: 2.705498456954956
Validation Loss Energy: 1.3879590225941885, Validation Loss Force: 2.8063904291431676, time: 0.1479189395904541
Test Loss Energy: 8.354824078428503, Test Loss Force: 7.272478930189154, time: 18.4654221534729


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9519790844905356, Training Loss Force: 3.137126886545126, time: 2.700209617614746
Validation Loss Energy: 1.3268346720184163, Validation Loss Force: 2.793992545101627, time: 0.1519484519958496
Test Loss Energy: 8.32251380374485, Test Loss Force: 7.239898906407794, time: 18.158571004867554


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.04860154032112, Training Loss Force: 3.151702440691238, time: 2.6521902084350586
Validation Loss Energy: 4.2432794378709655, Validation Loss Force: 2.8204754773034026, time: 0.1544201374053955
Test Loss Energy: 8.255036015192502, Test Loss Force: 7.280558838051907, time: 18.152250289916992


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0766371222105353, Training Loss Force: 3.1241107913091377, time: 2.6693851947784424
Validation Loss Energy: 1.348137596211187, Validation Loss Force: 2.792066568323925, time: 0.1484823226928711
Test Loss Energy: 8.220722147212488, Test Loss Force: 7.226159760776074, time: 18.074543237686157


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.845700701388131, Training Loss Force: 3.1306138704362554, time: 2.948084831237793
Validation Loss Energy: 1.345257370808611, Validation Loss Force: 2.785998611428247, time: 0.15038132667541504
Test Loss Energy: 8.18599532706038, Test Loss Force: 7.2801112124466245, time: 18.05883550643921


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0310333054314342, Training Loss Force: 3.134692299295523, time: 2.7019195556640625
Validation Loss Energy: 1.5296053793913726, Validation Loss Force: 2.761656420395421, time: 0.15245461463928223
Test Loss Energy: 8.068422485615155, Test Loss Force: 7.252770085377075, time: 18.162301778793335


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7568478385819435, Training Loss Force: 3.132652406467225, time: 2.7433998584747314
Validation Loss Energy: 1.3403933859849646, Validation Loss Force: 2.774527142368339, time: 0.14701390266418457
Test Loss Energy: 8.221201713599237, Test Loss Force: 7.223276736270779, time: 18.188109636306763


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9951718649933674, Training Loss Force: 3.132319887209306, time: 2.9423742294311523
Validation Loss Energy: 1.825268087716754, Validation Loss Force: 2.7559137831219434, time: 0.1458594799041748
Test Loss Energy: 8.841293600411364, Test Loss Force: 7.201981559157286, time: 18.123667240142822


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.147985509210282, Training Loss Force: 3.129638080798205, time: 2.7566750049591064
Validation Loss Energy: 2.0789564930217312, Validation Loss Force: 2.7607198739676484, time: 0.15448737144470215
Test Loss Energy: 8.059682947804056, Test Loss Force: 7.268322895684325, time: 18.224876880645752


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.11597506188137, Training Loss Force: 3.1246457494788458, time: 2.7367424964904785
Validation Loss Energy: 2.211879173687043, Validation Loss Force: 2.767494694067074, time: 0.14716410636901855
Test Loss Energy: 7.977203509873564, Test Loss Force: 7.249440794597514, time: 18.160555839538574


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0172341689079527, Training Loss Force: 3.1297723206039803, time: 2.7323267459869385
Validation Loss Energy: 1.3199796353591697, Validation Loss Force: 2.751598677743009, time: 0.14412522315979004
Test Loss Energy: 8.210245762083785, Test Loss Force: 7.196259211589651, time: 18.41557264328003


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9643569045575668, Training Loss Force: 3.1286375362889713, time: 2.699453115463257
Validation Loss Energy: 1.4133742562412404, Validation Loss Force: 2.8247708764629227, time: 0.15496134757995605
Test Loss Energy: 8.147928073344959, Test Loss Force: 7.264419076539218, time: 18.209936380386353


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0375754229132164, Training Loss Force: 3.1302720228255834, time: 2.7036306858062744
Validation Loss Energy: 1.40699350486282, Validation Loss Force: 2.7398723638455866, time: 0.1504991054534912
Test Loss Energy: 7.952269569173495, Test Loss Force: 7.184885131718811, time: 18.2005877494812


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8453015164723823, Training Loss Force: 3.1182064012302133, time: 2.7179503440856934
Validation Loss Energy: 2.24486404494991, Validation Loss Force: 2.783420214052976, time: 0.148223876953125
Test Loss Energy: 8.937832883502452, Test Loss Force: 7.198337276640152, time: 18.112741708755493


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9509386747818753, Training Loss Force: 3.130132287545287, time: 2.7491166591644287
Validation Loss Energy: 1.343678034223832, Validation Loss Force: 2.745696164022755, time: 0.15242886543273926
Test Loss Energy: 8.038843589587769, Test Loss Force: 7.203412456736773, time: 18.20723009109497


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9649491510451393, Training Loss Force: 3.1124782552647527, time: 2.7254691123962402
Validation Loss Energy: 1.3951673238534492, Validation Loss Force: 2.763439554916011, time: 0.1512894630432129
Test Loss Energy: 8.354546539408114, Test Loss Force: 7.190033762322606, time: 18.205465078353882


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.775710493750737, Training Loss Force: 3.1252800091808726, time: 2.7225513458251953
Validation Loss Energy: 1.5697059215487945, Validation Loss Force: 2.812275129331747, time: 0.14429545402526855
Test Loss Energy: 8.082279352110843, Test Loss Force: 7.255913483559805, time: 18.104636192321777

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‡â–‚â–â–ƒâ–‚â–â–ˆâ–‚â–„â–‚
wandb:   test_error_force â–ˆâ–†â–„â–†â–„â–‡â–ƒâ–‡â–…â–ƒâ–‚â–†â–…â–‚â–†â–â–‚â–‚â–â–…
wandb:          test_loss â–ˆâ–„â–†â–ˆâ–…â–‡â–„â–…â–„â–„â–ˆâ–ƒâ–â–‡â–ƒâ–â–„â–‚â–‚â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–
wandb: valid_error_energy â–‚â–â–â–â–â–ˆâ–â–â–‚â–â–‚â–ƒâ–ƒâ–â–â–â–ƒâ–â–â–‚
wandb:  valid_error_force â–‡â–„â–…â–†â–…â–ˆâ–…â–…â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–ˆâ–â–…â–â–ƒâ–‡
wandb:         valid_loss â–‚â–ƒâ–‚â–„â–‚â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–â–„â–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2394
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.08228
wandb:   test_error_force 7.25591
wandb:          test_loss 3.93379
wandb: train_error_energy 1.77571
wandb:  train_error_force 3.12528
wandb:         train_loss 1.41877
wandb: valid_error_energy 1.56971
wandb:  valid_error_force 2.81228
wandb:         valid_loss 1.39085
wandb: 
wandb: ğŸš€ View run al_54_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/lbc5zum6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_203753-lbc5zum6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6511817574501038, Uncertainty Bias: 0.0428767055273056
0.00011634827 0.022548676
0.7023414 6.5658154
Found uncertainty sample 3 after 1195 steps.
Found uncertainty sample 4 after 1478 steps.
Found uncertainty sample 8 after 513 steps.
Found uncertainty sample 11 after 1611 steps.
Found uncertainty sample 15 after 1203 steps.
Found uncertainty sample 16 after 231 steps.
Found uncertainty sample 20 after 1281 steps.
Found uncertainty sample 23 after 1936 steps.
Found uncertainty sample 24 after 2263 steps.
Found uncertainty sample 25 after 1727 steps.
Found uncertainty sample 26 after 2612 steps.
Found uncertainty sample 27 after 1551 steps.
Found uncertainty sample 30 after 2151 steps.
Found uncertainty sample 33 after 2467 steps.
Found uncertainty sample 35 after 1965 steps.
Found uncertainty sample 38 after 1877 steps.
Found uncertainty sample 43 after 2579 steps.
Found uncertainty sample 47 after 1073 steps.
Found uncertainty sample 51 after 557 steps.
Found uncertainty sample 52 after 3288 steps.
Found uncertainty sample 54 after 1293 steps.
Found uncertainty sample 58 after 2778 steps.
Found uncertainty sample 59 after 2659 steps.
Found uncertainty sample 61 after 3523 steps.
Found uncertainty sample 64 after 3094 steps.
Found uncertainty sample 65 after 40 steps.
Found uncertainty sample 66 after 1121 steps.
Found uncertainty sample 68 after 1491 steps.
Found uncertainty sample 70 after 2400 steps.
Found uncertainty sample 72 after 2462 steps.
Found uncertainty sample 73 after 162 steps.
Found uncertainty sample 74 after 1995 steps.
Found uncertainty sample 75 after 135 steps.
Found uncertainty sample 76 after 846 steps.
Found uncertainty sample 77 after 1904 steps.
Found uncertainty sample 78 after 2462 steps.
Found uncertainty sample 81 after 730 steps.
Found uncertainty sample 82 after 2118 steps.
Found uncertainty sample 83 after 1378 steps.
Found uncertainty sample 84 after 975 steps.
Found uncertainty sample 85 after 2148 steps.
Found uncertainty sample 86 after 3434 steps.
Found uncertainty sample 87 after 2731 steps.
Found uncertainty sample 90 after 3321 steps.
Found uncertainty sample 91 after 2728 steps.
Found uncertainty sample 96 after 1053 steps.
Found uncertainty sample 97 after 2611 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_230250-exhj8zet
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/exhj8zet
Training model 27. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1626047736026224, Training Loss Force: 3.347140213216016, time: 2.876224994659424
Validation Loss Energy: 1.351319872310214, Validation Loss Force: 2.7918800829142105, time: 0.1600644588470459
Test Loss Energy: 8.166089735987864, Test Loss Force: 7.183647932980142, time: 18.063666582107544


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9597491849114044, Training Loss Force: 3.1374073060425767, time: 2.774904489517212
Validation Loss Energy: 2.2003672901771494, Validation Loss Force: 2.80451310557385, time: 0.1442878246307373
Test Loss Energy: 9.038959659291526, Test Loss Force: 7.159518457432678, time: 17.487539768218994


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.071443981609075, Training Loss Force: 3.1329626534896255, time: 2.7562716007232666
Validation Loss Energy: 2.380282846741072, Validation Loss Force: 2.763555565541039, time: 0.1390237808227539
Test Loss Energy: 8.064240754391406, Test Loss Force: 7.177600101411511, time: 17.469398021697998


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9483020301655092, Training Loss Force: 3.1390893169610368, time: 2.745267152786255
Validation Loss Energy: 1.3066433678694032, Validation Loss Force: 2.7778825437283245, time: 0.1427147388458252
Test Loss Energy: 8.086247148415062, Test Loss Force: 7.175566898947782, time: 17.34324860572815


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0542129480828883, Training Loss Force: 3.1458269903524894, time: 2.692866563796997
Validation Loss Energy: 2.009457667202188, Validation Loss Force: 2.767481890591184, time: 0.14176535606384277
Test Loss Energy: 7.916516444777472, Test Loss Force: 7.176238240593718, time: 17.970653772354126


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0262113313352867, Training Loss Force: 3.1437180099008084, time: 2.761948585510254
Validation Loss Energy: 2.8147588923199987, Validation Loss Force: 2.825643405511241, time: 0.14804720878601074
Test Loss Energy: 8.032471656665301, Test Loss Force: 7.143485633068773, time: 18.083781719207764


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8920306292775282, Training Loss Force: 3.1223280473752917, time: 2.779834508895874
Validation Loss Energy: 1.9109581891478635, Validation Loss Force: 2.8179311483074585, time: 0.15083980560302734
Test Loss Energy: 8.651676835300904, Test Loss Force: 7.19014400336856, time: 18.014182567596436


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.071261363991343, Training Loss Force: 3.1289078801521586, time: 2.795088291168213
Validation Loss Energy: 1.8129728541514865, Validation Loss Force: 2.8155325562675246, time: 0.1517477035522461
Test Loss Energy: 7.943399952943736, Test Loss Force: 7.1567704800156795, time: 18.118154287338257


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0004832388627856, Training Loss Force: 3.1292304380985874, time: 2.8429651260375977
Validation Loss Energy: 2.4070819691300653, Validation Loss Force: 2.874258426137936, time: 0.15344762802124023
Test Loss Energy: 7.928144344158525, Test Loss Force: 7.22594518699428, time: 18.198442220687866


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9874266763531343, Training Loss Force: 3.13827460814958, time: 2.765345335006714
Validation Loss Energy: 1.9549333414462882, Validation Loss Force: 2.7638224345124334, time: 0.1462099552154541
Test Loss Energy: 8.716119815933698, Test Loss Force: 7.162394466111165, time: 18.355539083480835


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9558168506861267, Training Loss Force: 3.121095489790176, time: 3.0803375244140625
Validation Loss Energy: 1.4279800718665139, Validation Loss Force: 2.788904555117177, time: 0.15207433700561523
Test Loss Energy: 7.925892851320135, Test Loss Force: 7.127051876003423, time: 18.011428117752075


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9600907687796312, Training Loss Force: 3.120009841788845, time: 2.745396137237549
Validation Loss Energy: 1.5738838627338376, Validation Loss Force: 2.8040655405905355, time: 0.1497032642364502
Test Loss Energy: 8.390420212915998, Test Loss Force: 7.191884119609124, time: 18.185286283493042


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.043344053541739, Training Loss Force: 3.1231572036549706, time: 2.7941622734069824
Validation Loss Energy: 2.1252813614825588, Validation Loss Force: 2.764142187405986, time: 0.1522049903869629
Test Loss Energy: 7.954155886944178, Test Loss Force: 7.153076296293715, time: 18.116185426712036


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9519942634317207, Training Loss Force: 3.1223510198908144, time: 2.8570547103881836
Validation Loss Energy: 1.6305494863315517, Validation Loss Force: 2.805808705999431, time: 0.16680479049682617
Test Loss Energy: 8.356308987848465, Test Loss Force: 7.183052720865971, time: 18.001259326934814


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8334909426229913, Training Loss Force: 3.1186846017864953, time: 2.8500864505767822
Validation Loss Energy: 1.4592870754475284, Validation Loss Force: 2.7879678973548323, time: 0.15213823318481445
Test Loss Energy: 7.895477229927546, Test Loss Force: 7.174574281864288, time: 18.107364416122437


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.734440928118492, Training Loss Force: 3.119774963433383, time: 2.7903919219970703
Validation Loss Energy: 1.3980717645256449, Validation Loss Force: 2.7579043339519647, time: 0.1531362533569336
Test Loss Energy: 7.913234254934214, Test Loss Force: 7.135883815681047, time: 18.210767030715942


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8746394749468662, Training Loss Force: 3.106780391146416, time: 2.8247342109680176
Validation Loss Energy: 1.4929047724231221, Validation Loss Force: 2.8281788277413478, time: 0.15578651428222656
Test Loss Energy: 7.825996046266042, Test Loss Force: 7.197653188059967, time: 18.001709461212158


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.01659052049152, Training Loss Force: 3.118138316292743, time: 2.820267915725708
Validation Loss Energy: 1.3497096960487238, Validation Loss Force: 2.7713591170946517, time: 0.1535506248474121
Test Loss Energy: 8.012433084314582, Test Loss Force: 7.139270501473132, time: 18.096983671188354


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6704133217884791, Training Loss Force: 3.1104361963187146, time: 2.768183708190918
Validation Loss Energy: 1.4855720547785745, Validation Loss Force: 2.766691081119421, time: 0.14548540115356445
Test Loss Energy: 8.251731959472277, Test Loss Force: 7.095413703071899, time: 18.19052267074585


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2323908929534317, Training Loss Force: 3.1337386699222196, time: 2.8239827156066895
Validation Loss Energy: 1.4910483797535223, Validation Loss Force: 2.7733410951625546, time: 0.14997625350952148
Test Loss Energy: 7.9537587501104765, Test Loss Force: 7.056308288854898, time: 18.359498023986816

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–‚â–ƒâ–‚â–‚â–†â–‚â–‚â–†â–‚â–„â–‚â–„â–â–‚â–â–‚â–ƒâ–‚
wandb:   test_error_force â–†â–…â–†â–†â–†â–…â–‡â–…â–ˆâ–…â–„â–‡â–…â–†â–†â–„â–‡â–„â–ƒâ–
wandb:          test_loss â–ˆâ–ˆâ–…â–„â–„â–‚â–…â–„â–…â–…â–ƒâ–ˆâ–„â–†â–„â–‚â–„â–„â–ˆâ–
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–ƒ
wandb: valid_error_energy â–â–…â–†â–â–„â–ˆâ–„â–ƒâ–†â–„â–‚â–‚â–…â–ƒâ–‚â–â–‚â–â–‚â–‚
wandb:  valid_error_force â–ƒâ–„â–â–‚â–‚â–…â–…â–„â–ˆâ–â–ƒâ–„â–â–„â–ƒâ–â–…â–‚â–‚â–‚
wandb:         valid_loss â–…â–„â–†â–‚â–ƒâ–†â–ƒâ–…â–ˆâ–ƒâ–‚â–…â–ƒâ–‚â–â–â–ƒâ–ƒâ–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2436
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.95376
wandb:   test_error_force 7.05631
wandb:          test_loss 3.83893
wandb: train_error_energy 2.23239
wandb:  train_error_force 3.13374
wandb:         train_loss 1.45384
wandb: valid_error_energy 1.49105
wandb:  valid_error_force 2.77334
wandb:         valid_loss 1.37481
wandb: 
wandb: ğŸš€ View run al_54_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/exhj8zet
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_230250-exhj8zet/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7086426615715027, Uncertainty Bias: 0.02532707154750824
1.9073486e-06 0.0029611588
0.3971735 5.18254
Found uncertainty sample 1 after 1312 steps.
Found uncertainty sample 7 after 802 steps.
Found uncertainty sample 10 after 3193 steps.
Found uncertainty sample 11 after 3731 steps.
Found uncertainty sample 13 after 3533 steps.
Found uncertainty sample 15 after 1377 steps.
Found uncertainty sample 16 after 291 steps.
Found uncertainty sample 17 after 459 steps.
Found uncertainty sample 21 after 3464 steps.
Found uncertainty sample 22 after 1384 steps.
Found uncertainty sample 23 after 490 steps.
Found uncertainty sample 29 after 743 steps.
Found uncertainty sample 33 after 1304 steps.
Found uncertainty sample 37 after 3214 steps.
Found uncertainty sample 39 after 3992 steps.
Found uncertainty sample 41 after 1674 steps.
Found uncertainty sample 43 after 2105 steps.
Found uncertainty sample 44 after 1070 steps.
Found uncertainty sample 45 after 373 steps.
Found uncertainty sample 47 after 3919 steps.
Found uncertainty sample 54 after 2479 steps.
Found uncertainty sample 58 after 2025 steps.
Found uncertainty sample 60 after 3978 steps.
Found uncertainty sample 61 after 244 steps.
Found uncertainty sample 62 after 2289 steps.
Found uncertainty sample 64 after 44 steps.
Found uncertainty sample 66 after 312 steps.
Found uncertainty sample 68 after 3997 steps.
Found uncertainty sample 69 after 3425 steps.
Found uncertainty sample 70 after 3126 steps.
Found uncertainty sample 71 after 1123 steps.
Found uncertainty sample 72 after 497 steps.
Found uncertainty sample 73 after 225 steps.
Found uncertainty sample 74 after 668 steps.
Found uncertainty sample 78 after 16 steps.
Found uncertainty sample 80 after 1865 steps.
Found uncertainty sample 82 after 2210 steps.
Found uncertainty sample 83 after 3827 steps.
Found uncertainty sample 87 after 2011 steps.
Found uncertainty sample 92 after 1058 steps.
Found uncertainty sample 93 after 17 steps.
Found uncertainty sample 95 after 3865 steps.
Found uncertainty sample 99 after 3121 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_013210-adderklu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/adderklu
Training model 28. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3355713193976944, Training Loss Force: 3.294709704091055, time: 2.879462480545044
Validation Loss Energy: 1.4095726259128152, Validation Loss Force: 2.7723265031991344, time: 0.15858864784240723
Test Loss Energy: 8.284376746166695, Test Loss Force: 7.085006865328376, time: 18.058687925338745


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.05604045219285, Training Loss Force: 3.112059927425434, time: 2.7965033054351807
Validation Loss Energy: 4.298357764461933, Validation Loss Force: 2.815787289770466, time: 0.16634750366210938
Test Loss Energy: 10.238355537626989, Test Loss Force: 7.1186166254895955, time: 18.2423357963562


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0719411545605455, Training Loss Force: 3.134275619550452, time: 2.866183042526245
Validation Loss Energy: 1.6572438428873857, Validation Loss Force: 2.766305974831539, time: 0.1478419303894043
Test Loss Energy: 8.43939821747606, Test Loss Force: 7.076081649428943, time: 18.214561223983765


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9622334594714523, Training Loss Force: 3.1295663098507114, time: 2.835087776184082
Validation Loss Energy: 1.942365226842686, Validation Loss Force: 2.776371288234913, time: 0.1535813808441162
Test Loss Energy: 7.74822762761659, Test Loss Force: 7.093531873658347, time: 18.154144287109375


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6338288732981632, Training Loss Force: 3.1151464929032366, time: 2.8094699382781982
Validation Loss Energy: 1.4265040537654452, Validation Loss Force: 2.7873899595865765, time: 0.17577242851257324
Test Loss Energy: 8.214568038341865, Test Loss Force: 7.070166850434029, time: 18.26429581642151


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9087033100584974, Training Loss Force: 3.1309151624589604, time: 2.8094849586486816
Validation Loss Energy: 1.3187584064283289, Validation Loss Force: 2.794085398135479, time: 0.15763235092163086
Test Loss Energy: 8.046623330115358, Test Loss Force: 7.093278613735513, time: 18.230754137039185


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.164594795329086, Training Loss Force: 3.1110258319286177, time: 2.7567849159240723
Validation Loss Energy: 1.7916459373582418, Validation Loss Force: 2.7661753793774526, time: 0.15363550186157227
Test Loss Energy: 7.77680568528919, Test Loss Force: 7.107548735513129, time: 18.114758014678955


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8717248319792577, Training Loss Force: 3.1228287697048325, time: 3.044482469558716
Validation Loss Energy: 1.4528356822825628, Validation Loss Force: 2.7479614885788513, time: 0.15198111534118652
Test Loss Energy: 8.189236284640009, Test Loss Force: 7.058839710618124, time: 18.147186756134033


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2161825846537173, Training Loss Force: 3.1165807962236016, time: 2.857800006866455
Validation Loss Energy: 1.9937028787839266, Validation Loss Force: 2.7919690392380083, time: 0.15949559211730957
Test Loss Energy: 8.471430603397208, Test Loss Force: 7.058311688627285, time: 18.219524145126343


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4031117168814213, Training Loss Force: 3.1288472597933223, time: 2.8665008544921875
Validation Loss Energy: 1.2969994001574112, Validation Loss Force: 2.858229476333751, time: 0.15020227432250977
Test Loss Energy: 7.874431796662835, Test Loss Force: 7.132117249331168, time: 18.531099796295166


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0337276620465454, Training Loss Force: 3.134449772515161, time: 2.857208251953125
Validation Loss Energy: 1.9330805357976488, Validation Loss Force: 2.767752544938059, time: 0.15384697914123535
Test Loss Energy: 8.547430294569555, Test Loss Force: 7.053840217046592, time: 18.12325644493103


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0600250908666347, Training Loss Force: 3.1247929456599914, time: 2.889904737472534
Validation Loss Energy: 1.6966406948763892, Validation Loss Force: 2.7520691776483543, time: 0.15087485313415527
Test Loss Energy: 8.401235115768479, Test Loss Force: 7.085312770765826, time: 18.26521635055542


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9387096374992967, Training Loss Force: 3.116343859123939, time: 2.8511571884155273
Validation Loss Energy: 2.770483916016582, Validation Loss Force: 2.8038617983220115, time: 0.149522066116333
Test Loss Energy: 7.793329542917955, Test Loss Force: 7.120993001910447, time: 18.24966025352478


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0676433303056476, Training Loss Force: 3.1181352495313237, time: 2.846121072769165
Validation Loss Energy: 1.4375427653402424, Validation Loss Force: 2.7686490109195643, time: 0.14945697784423828
Test Loss Energy: 7.716314988732052, Test Loss Force: 7.0686499792480735, time: 18.11632013320923


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9094916173571004, Training Loss Force: 3.111588474039387, time: 2.8673386573791504
Validation Loss Energy: 1.3892409845345812, Validation Loss Force: 2.746239588073392, time: 0.15288209915161133
Test Loss Energy: 8.194395442481435, Test Loss Force: 7.045741033730128, time: 18.18036651611328


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.774451900508999, Training Loss Force: 3.1163161939099235, time: 2.8542444705963135
Validation Loss Energy: 1.7308946689364715, Validation Loss Force: 2.7952311422258505, time: 0.16375136375427246
Test Loss Energy: 7.73799059899588, Test Loss Force: 7.078205190280725, time: 18.55963897705078


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.934334607000148, Training Loss Force: 3.104262790456064, time: 2.9319636821746826
Validation Loss Energy: 1.9132525720275035, Validation Loss Force: 2.770422904670598, time: 0.1573631763458252
Test Loss Energy: 7.779314858790737, Test Loss Force: 7.0454509273097745, time: 18.51977276802063


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8054060898240738, Training Loss Force: 3.108193611710117, time: 3.076261043548584
Validation Loss Energy: 1.8271139036019224, Validation Loss Force: 2.810477409982099, time: 0.15598225593566895
Test Loss Energy: 7.738077246438823, Test Loss Force: 7.127775912127873, time: 18.887800455093384


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1105278748199114, Training Loss Force: 3.1177004823144348, time: 2.923442840576172
Validation Loss Energy: 1.5186923088821653, Validation Loss Force: 2.7526048082788837, time: 0.15760278701782227
Test Loss Energy: 8.176206052283726, Test Loss Force: 7.040797004594651, time: 18.6440327167511


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.026829628117957, Training Loss Force: 3.110156700012141, time: 2.949429512023926
Validation Loss Energy: 1.3557010547582027, Validation Loss Force: 2.7499741949888925, time: 0.15096354484558105
Test Loss Energy: 7.782605437781503, Test Loss Force: 7.053214008454662, time: 18.60007905960083

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–â–‚â–‚â–â–‚â–ƒâ–â–ƒâ–ƒâ–â–â–‚â–â–â–â–‚â–
wandb:   test_error_force â–„â–‡â–„â–…â–ƒâ–…â–†â–‚â–‚â–ˆâ–‚â–„â–‡â–ƒâ–â–„â–â–ˆâ–â–‚
wandb:          test_loss â–…â–ˆâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–ˆâ–‚â–ƒâ–â–â–‚â–â–ƒâ–â–‚â–‚â–„â–â–â–‚â–‚â–‚â–‚â–
wandb:  valid_error_force â–ƒâ–…â–‚â–ƒâ–„â–„â–‚â–â–„â–ˆâ–‚â–â–…â–‚â–â–„â–ƒâ–…â–â–
wandb:         valid_loss â–„â–ˆâ–‚â–ƒâ–‚â–â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–…â–â–â–‚â–„â–„â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2474
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.78261
wandb:   test_error_force 7.05321
wandb:          test_loss 3.87083
wandb: train_error_energy 2.02683
wandb:  train_error_force 3.11016
wandb:         train_loss 1.42458
wandb: valid_error_energy 1.3557
wandb:  valid_error_force 2.74997
wandb:         valid_loss 1.39429
wandb: 
wandb: ğŸš€ View run al_54_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/adderklu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_013210-adderklu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6986114382743835, Uncertainty Bias: 0.02699756622314453
0.0002670288 0.006447792
0.4586445 7.2357035
Found uncertainty sample 3 after 2268 steps.
Found uncertainty sample 5 after 1743 steps.
Found uncertainty sample 6 after 548 steps.
Found uncertainty sample 7 after 413 steps.
Found uncertainty sample 9 after 334 steps.
Found uncertainty sample 10 after 1768 steps.
Found uncertainty sample 13 after 533 steps.
Found uncertainty sample 14 after 3208 steps.
Found uncertainty sample 15 after 1466 steps.
Found uncertainty sample 16 after 1727 steps.
Found uncertainty sample 18 after 623 steps.
Found uncertainty sample 19 after 75 steps.
Found uncertainty sample 21 after 2520 steps.
Found uncertainty sample 23 after 2048 steps.
Found uncertainty sample 28 after 1835 steps.
Found uncertainty sample 30 after 24 steps.
Found uncertainty sample 31 after 1995 steps.
Found uncertainty sample 33 after 173 steps.
Found uncertainty sample 36 after 591 steps.
Found uncertainty sample 38 after 902 steps.
Found uncertainty sample 46 after 2893 steps.
Found uncertainty sample 48 after 3308 steps.
Found uncertainty sample 49 after 2960 steps.
Found uncertainty sample 51 after 1123 steps.
Found uncertainty sample 53 after 2281 steps.
Found uncertainty sample 55 after 1598 steps.
Found uncertainty sample 56 after 2119 steps.
Found uncertainty sample 58 after 1164 steps.
Found uncertainty sample 60 after 5 steps.
Found uncertainty sample 64 after 3519 steps.
Found uncertainty sample 65 after 1386 steps.
Found uncertainty sample 68 after 3472 steps.
Found uncertainty sample 70 after 24 steps.
Found uncertainty sample 71 after 3275 steps.
Found uncertainty sample 72 after 1388 steps.
Found uncertainty sample 74 after 1166 steps.
Found uncertainty sample 75 after 3164 steps.
Found uncertainty sample 76 after 1457 steps.
Found uncertainty sample 77 after 911 steps.
Found uncertainty sample 78 after 2259 steps.
Found uncertainty sample 79 after 355 steps.
Found uncertainty sample 80 after 3502 steps.
Found uncertainty sample 81 after 1130 steps.
Found uncertainty sample 83 after 338 steps.
Found uncertainty sample 84 after 1585 steps.
Found uncertainty sample 85 after 1152 steps.
Found uncertainty sample 86 after 3329 steps.
Found uncertainty sample 89 after 1101 steps.
Found uncertainty sample 92 after 1710 steps.
Found uncertainty sample 93 after 2482 steps.
Found uncertainty sample 96 after 1399 steps.
Found uncertainty sample 99 after 1134 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_034636-0n67uvuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0n67uvuw
Training model 29. Added 52 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4516364245954727, Training Loss Force: 3.2832596064269524, time: 2.8301639556884766
Validation Loss Energy: 1.3137803036673943, Validation Loss Force: 2.759911028295066, time: 0.1566617488861084
Test Loss Energy: 7.765801490346529, Test Loss Force: 7.02563624353915, time: 18.08390760421753


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9073423184404814, Training Loss Force: 3.1179701375410214, time: 2.805457830429077
Validation Loss Energy: 2.564611483108138, Validation Loss Force: 2.787135226083635, time: 0.16019392013549805
Test Loss Energy: 7.6469885985986, Test Loss Force: 7.028903977375027, time: 18.218748092651367


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8093312017393217, Training Loss Force: 3.1154866775519245, time: 2.871370792388916
Validation Loss Energy: 1.3875932328547154, Validation Loss Force: 2.7715295703258587, time: 0.15317654609680176
Test Loss Energy: 8.000143929850157, Test Loss Force: 6.9930813498944895, time: 18.211995840072632


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1287508342729864, Training Loss Force: 3.1306814227682622, time: 2.9166839122772217
Validation Loss Energy: 1.604044008878751, Validation Loss Force: 2.806081587037766, time: 0.15861296653747559
Test Loss Energy: 7.655972578168031, Test Loss Force: 6.990517931391059, time: 18.10938549041748


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.322302744461168, Training Loss Force: 3.1256793351579946, time: 2.9662041664123535
Validation Loss Energy: 2.762171342795379, Validation Loss Force: 2.7804246460328095, time: 0.2017533779144287
Test Loss Energy: 7.719898371820678, Test Loss Force: 7.048788819413727, time: 18.20424485206604


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9976572819905836, Training Loss Force: 3.1455344243989387, time: 2.90671968460083
Validation Loss Energy: 1.6922898510995332, Validation Loss Force: 2.756047273274927, time: 0.1588270664215088
Test Loss Energy: 8.387310217436774, Test Loss Force: 7.017259754363707, time: 18.264364004135132


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7916470943922211, Training Loss Force: 3.1107441883426485, time: 2.8980345726013184
Validation Loss Energy: 1.3551148782315479, Validation Loss Force: 2.79251001392804, time: 0.15081286430358887
Test Loss Energy: 7.773097171467009, Test Loss Force: 6.9859633727421455, time: 18.569114923477173


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7507004468266818, Training Loss Force: 3.118050893157477, time: 2.9097323417663574
Validation Loss Energy: 1.3842455692475508, Validation Loss Force: 2.7706105034260418, time: 0.1584010124206543
Test Loss Energy: 7.736205359027764, Test Loss Force: 7.017778920884218, time: 18.103727340698242


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.793756222179643, Training Loss Force: 3.1076526048230377, time: 2.8426826000213623
Validation Loss Energy: 1.491255462059235, Validation Loss Force: 2.7764702646702775, time: 0.15664124488830566
Test Loss Energy: 8.072746613174827, Test Loss Force: 7.010151420767251, time: 18.183929920196533


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7300789775969498, Training Loss Force: 3.117676129710494, time: 2.813261032104492
Validation Loss Energy: 1.5467524066445473, Validation Loss Force: 2.779809299848038, time: 0.15035367012023926
Test Loss Energy: 8.026540321863239, Test Loss Force: 6.977317421257532, time: 18.16355299949646


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.169152737979945, Training Loss Force: 3.1149284319100996, time: 2.850626230239868
Validation Loss Energy: 1.3394773251186178, Validation Loss Force: 2.773839094707422, time: 0.1545088291168213
Test Loss Energy: 8.018410274971021, Test Loss Force: 6.987226272862968, time: 18.103458881378174


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.086707143036956, Training Loss Force: 3.1087029718261374, time: 2.846050262451172
Validation Loss Energy: 1.9473328641537622, Validation Loss Force: 2.758655619650325, time: 0.15311574935913086
Test Loss Energy: 7.626478786055055, Test Loss Force: 6.99174921715639, time: 18.20216989517212


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9794352736332441, Training Loss Force: 3.114365715973775, time: 2.86564302444458
Validation Loss Energy: 2.022824496032233, Validation Loss Force: 2.807947443146068, time: 0.1528468132019043
Test Loss Energy: 8.429991602541199, Test Loss Force: 7.0537425573902865, time: 18.296082735061646


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3224852817214376, Training Loss Force: 3.1201534085168428, time: 2.879392623901367
Validation Loss Energy: 1.2823954215525915, Validation Loss Force: 2.7616838087003703, time: 0.15303325653076172
Test Loss Energy: 7.7395759147135506, Test Loss Force: 7.042474612592986, time: 18.107842206954956


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8130399170247657, Training Loss Force: 3.1096715206017933, time: 2.942627191543579
Validation Loss Energy: 1.3511933405680407, Validation Loss Force: 2.7525336654867596, time: 0.15550780296325684
Test Loss Energy: 7.770518352652494, Test Loss Force: 6.959135219426074, time: 18.272728443145752


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2690928043737646, Training Loss Force: 3.1037766029998735, time: 2.8211135864257812
Validation Loss Energy: 1.4499152094318604, Validation Loss Force: 2.75015177363277, time: 0.15345525741577148
Test Loss Energy: 7.720527763065845, Test Loss Force: 7.004676674295045, time: 18.242461442947388


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7839011549568724, Training Loss Force: 3.102534024607692, time: 2.8335444927215576
Validation Loss Energy: 1.390958988329987, Validation Loss Force: 2.7726301125796073, time: 0.15399622917175293
Test Loss Energy: 7.9125555104135294, Test Loss Force: 6.984672672786485, time: 18.442241191864014


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.980475745952334, Training Loss Force: 3.0983672788890746, time: 3.0432701110839844
Validation Loss Energy: 1.317277767942482, Validation Loss Force: 2.75147175632983, time: 0.15138649940490723
Test Loss Energy: 7.762519211901938, Test Loss Force: 7.026715696926327, time: 18.17885684967041


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8856210588176932, Training Loss Force: 3.1040258853366343, time: 2.8311567306518555
Validation Loss Energy: 2.3451194918890206, Validation Loss Force: 2.7557190589538294, time: 0.15134167671203613
Test Loss Energy: 7.416769567323788, Test Loss Force: 6.984241555008986, time: 18.256622076034546


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.118670576669464, Training Loss Force: 3.1118246579594, time: 2.8486926555633545
Validation Loss Energy: 1.4704130176602428, Validation Loss Force: 2.745630476624706, time: 0.16386032104492188
Test Loss Energy: 7.584831800558679, Test Loss Force: 6.983689172314098, time: 18.227413654327393

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–…â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–‚
wandb:   test_error_force â–†â–†â–„â–ƒâ–ˆâ–…â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–ˆâ–‡â–â–„â–ƒâ–†â–ƒâ–ƒ
wandb:          test_loss â–„â–„â–†â–‚â–ˆâ–†â–„â–ƒâ–…â–„â–†â–‚â–ˆâ–„â–‚â–‚â–„â–†â–â–…
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–ƒâ–‚â–â–â–â–â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–ƒâ–‚â–â–â–â–â–‚â–‚â–â–ƒâ–â–‚â–â–‚â–â–‚
wandb: valid_error_energy â–â–‡â–â–ƒâ–ˆâ–ƒâ–â–â–‚â–‚â–â–„â–…â–â–â–‚â–‚â–â–†â–‚
wandb:  valid_error_force â–ƒâ–†â–„â–ˆâ–…â–‚â–†â–„â–„â–…â–„â–‚â–ˆâ–ƒâ–‚â–‚â–„â–‚â–‚â–
wandb:         valid_loss â–…â–†â–ƒâ–…â–ˆâ–ƒâ–„â–‚â–ƒâ–ƒâ–„â–ƒâ–…â–â–â–‚â–ƒâ–‚â–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2520
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.58483
wandb:   test_error_force 6.98369
wandb:          test_loss 3.80657
wandb: train_error_energy 2.11867
wandb:  train_error_force 3.11182
wandb:         train_loss 1.43241
wandb: valid_error_energy 1.47041
wandb:  valid_error_force 2.74563
wandb:         valid_loss 1.39018
wandb: 
wandb: ğŸš€ View run al_54_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/0n67uvuw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_034636-0n67uvuw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.70562744140625, Uncertainty Bias: 0.025227993726730347
2.2888184e-05 0.0030446053
0.44565225 7.100427
Found uncertainty sample 0 after 1320 steps.
Found uncertainty sample 2 after 253 steps.
Found uncertainty sample 3 after 1911 steps.
Found uncertainty sample 5 after 3268 steps.
Found uncertainty sample 6 after 3626 steps.
Found uncertainty sample 8 after 1767 steps.
Found uncertainty sample 9 after 2529 steps.
Found uncertainty sample 10 after 2304 steps.
Found uncertainty sample 13 after 59 steps.
Found uncertainty sample 15 after 1700 steps.
Found uncertainty sample 17 after 2240 steps.
Found uncertainty sample 21 after 3058 steps.
Found uncertainty sample 26 after 480 steps.
Found uncertainty sample 28 after 2937 steps.
Found uncertainty sample 29 after 2245 steps.
Found uncertainty sample 30 after 1198 steps.
Found uncertainty sample 32 after 1425 steps.
Found uncertainty sample 33 after 3535 steps.
Found uncertainty sample 37 after 796 steps.
Found uncertainty sample 38 after 16 steps.
Found uncertainty sample 40 after 3556 steps.
Found uncertainty sample 41 after 952 steps.
Found uncertainty sample 42 after 1081 steps.
Found uncertainty sample 47 after 2805 steps.
Found uncertainty sample 49 after 1390 steps.
Found uncertainty sample 51 after 1478 steps.
Found uncertainty sample 52 after 1794 steps.
Found uncertainty sample 53 after 2852 steps.
Found uncertainty sample 55 after 3961 steps.
Found uncertainty sample 56 after 1187 steps.
Found uncertainty sample 57 after 1360 steps.
Found uncertainty sample 58 after 1271 steps.
Found uncertainty sample 59 after 1143 steps.
Found uncertainty sample 62 after 2324 steps.
Found uncertainty sample 63 after 2515 steps.
Found uncertainty sample 64 after 2846 steps.
Found uncertainty sample 69 after 1021 steps.
Found uncertainty sample 70 after 2447 steps.
Found uncertainty sample 73 after 1368 steps.
Found uncertainty sample 84 after 2894 steps.
Found uncertainty sample 86 after 222 steps.
Found uncertainty sample 88 after 783 steps.
Found uncertainty sample 89 after 614 steps.
Found uncertainty sample 92 after 364 steps.
Found uncertainty sample 93 after 1499 steps.
Found uncertainty sample 94 after 29 steps.
Found uncertainty sample 98 after 2394 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_061030-3zhyk7lh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3zhyk7lh
Training model 30. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7976245111623617, Training Loss Force: 3.2283718698011667, time: 2.8719496726989746
Validation Loss Energy: 1.4130961981452628, Validation Loss Force: 2.7816026771493405, time: 0.1614212989807129
Test Loss Energy: 7.63462434517584, Test Loss Force: 6.991353353383983, time: 18.11064863204956


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.991037264515748, Training Loss Force: 3.118726137847067, time: 3.002387523651123
Validation Loss Energy: 1.9356272584869112, Validation Loss Force: 2.8099485707605205, time: 0.15636014938354492
Test Loss Energy: 7.505562412331391, Test Loss Force: 6.982379817114077, time: 18.235841035842896


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8324995802424633, Training Loss Force: 3.1284532003237655, time: 2.9764304161071777
Validation Loss Energy: 1.416026691107532, Validation Loss Force: 2.760842230663336, time: 0.15865874290466309
Test Loss Energy: 7.6607382621414954, Test Loss Force: 6.952926408557201, time: 18.266380548477173


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9177871563357751, Training Loss Force: 3.1111212772711676, time: 3.028113603591919
Validation Loss Energy: 4.583189233189236, Validation Loss Force: 2.7569524233531233, time: 0.15735220909118652
Test Loss Energy: 10.052703409483653, Test Loss Force: 6.979658368802233, time: 18.090354442596436


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2341286774769116, Training Loss Force: 3.117885996163474, time: 3.0224950313568115
Validation Loss Energy: 1.3320048269177134, Validation Loss Force: 2.7567434483596704, time: 0.20533132553100586
Test Loss Energy: 7.898437288630877, Test Loss Force: 6.962989990737111, time: 18.117410898208618


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.159051995049881, Training Loss Force: 3.130867230757817, time: 2.949298143386841
Validation Loss Energy: 1.7176085020045386, Validation Loss Force: 2.7613057164905843, time: 0.15341687202453613
Test Loss Energy: 7.549613499471805, Test Loss Force: 6.941574329796951, time: 18.63301968574524


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.161538795685123, Training Loss Force: 3.123198618081138, time: 2.9614596366882324
Validation Loss Energy: 1.6108483883072988, Validation Loss Force: 2.7963040735055036, time: 0.15148401260375977
Test Loss Energy: 8.108634891913393, Test Loss Force: 6.992245447589064, time: 18.20274782180786


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1400683803105855, Training Loss Force: 3.1255959015962147, time: 2.9397618770599365
Validation Loss Energy: 1.5050456962702619, Validation Loss Force: 2.864458089018216, time: 0.15552520751953125
Test Loss Energy: 7.615744114043532, Test Loss Force: 7.026574193598607, time: 18.173766374588013


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0990416815777007, Training Loss Force: 3.106225217094501, time: 2.910618543624878
Validation Loss Energy: 1.3695893190607242, Validation Loss Force: 2.7689756665566403, time: 0.1599886417388916
Test Loss Energy: 7.855812536101169, Test Loss Force: 6.920914790322782, time: 18.219366788864136


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8318607795743205, Training Loss Force: 3.1200718814400097, time: 2.9629933834075928
Validation Loss Energy: 1.8988943644925014, Validation Loss Force: 2.7721674060943693, time: 0.15379714965820312
Test Loss Energy: 8.373244349716975, Test Loss Force: 6.953570750111938, time: 18.2417950630188


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1956510703855914, Training Loss Force: 3.1115070007099543, time: 2.9399547576904297
Validation Loss Energy: 3.6172665103329993, Validation Loss Force: 2.7912640687220014, time: 0.1512601375579834
Test Loss Energy: 7.561540948310291, Test Loss Force: 7.011623818745988, time: 18.1190345287323


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9995876222692845, Training Loss Force: 3.119863597820509, time: 2.977048873901367
Validation Loss Energy: 2.218363187881887, Validation Loss Force: 2.7877416655025695, time: 0.15623235702514648
Test Loss Energy: 7.549226418889688, Test Loss Force: 6.946199079356536, time: 18.229135274887085


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.951967150633874, Training Loss Force: 3.1220561081913862, time: 2.9841036796569824
Validation Loss Energy: 2.340131925689384, Validation Loss Force: 2.784567628161942, time: 0.15639090538024902
Test Loss Energy: 7.504854203203407, Test Loss Force: 6.921678680726932, time: 18.250499725341797


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.006975757041151, Training Loss Force: 3.1140827246809732, time: 3.0028815269470215
Validation Loss Energy: 1.6488343529204172, Validation Loss Force: 2.8243554871711947, time: 0.15366268157958984
Test Loss Energy: 7.509035684944451, Test Loss Force: 6.986337953541106, time: 18.12121319770813


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9749809442751254, Training Loss Force: 3.1160279623397984, time: 2.9795353412628174
Validation Loss Energy: 1.6296311987737457, Validation Loss Force: 2.7518668827292787, time: 0.18303704261779785
Test Loss Energy: 8.088348133232104, Test Loss Force: 6.898059574520004, time: 18.518641471862793


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9112968139387838, Training Loss Force: 3.0907323954901713, time: 2.956364631652832
Validation Loss Energy: 3.2472969369873423, Validation Loss Force: 2.7441959306520665, time: 0.1563854217529297
Test Loss Energy: 9.175594231704936, Test Loss Force: 6.886055979828455, time: 18.294387340545654


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7844053208955526, Training Loss Force: 3.1118115763645604, time: 2.921522855758667
Validation Loss Energy: 1.3179016312220853, Validation Loss Force: 2.739583895967037, time: 0.16690611839294434
Test Loss Energy: 7.650895803247371, Test Loss Force: 6.914409477416097, time: 18.1904296875


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9286063243796925, Training Loss Force: 3.1079106246010437, time: 3.1612589359283447
Validation Loss Energy: 1.5281326456602062, Validation Loss Force: 2.8250192638952054, time: 0.15644550323486328
Test Loss Energy: 7.4639957625986035, Test Loss Force: 6.918616364424302, time: 18.137430906295776


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8701350835501545, Training Loss Force: 3.126552724661275, time: 2.9272544384002686
Validation Loss Energy: 2.5006756005613084, Validation Loss Force: 2.757284423049702, time: 0.15391016006469727
Test Loss Energy: 7.553314817932893, Test Loss Force: 6.879271547067024, time: 18.255767583847046


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8687407623463765, Training Loss Force: 3.105594409149096, time: 2.952686071395874
Validation Loss Energy: 2.585588920676849, Validation Loss Force: 2.755796547816612, time: 0.15026545524597168
Test Loss Energy: 8.784119135263246, Test Loss Force: 6.888651880047821, time: 18.207103490829468

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–‚â–ˆâ–‚â–â–ƒâ–â–‚â–ƒâ–â–â–â–â–ƒâ–†â–‚â–â–â–…
wandb:   test_error_force â–†â–†â–…â–†â–…â–„â–†â–ˆâ–ƒâ–…â–‡â–„â–ƒâ–†â–‚â–â–ƒâ–ƒâ–â–
wandb:          test_loss â–„â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–â–„
wandb: train_error_energy â–ˆâ–‚â–â–‚â–„â–„â–„â–ƒâ–ƒâ–â–„â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–‚â–â–
wandb: valid_error_energy â–â–‚â–â–ˆâ–â–‚â–‚â–â–â–‚â–†â–ƒâ–ƒâ–‚â–‚â–…â–â–â–„â–„
wandb:  valid_error_force â–ƒâ–…â–‚â–‚â–‚â–‚â–„â–ˆâ–ƒâ–ƒâ–„â–„â–„â–†â–‚â–â–â–†â–‚â–‚
wandb:         valid_loss â–‚â–‚â–â–ˆâ–ƒâ–‚â–‚â–†â–‚â–ƒâ–†â–ƒâ–ƒâ–‚â–â–…â–â–„â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2562
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.78412
wandb:   test_error_force 6.88865
wandb:          test_loss 3.7917
wandb: train_error_energy 1.86874
wandb:  train_error_force 3.10559
wandb:         train_loss 1.40721
wandb: valid_error_energy 2.58559
wandb:  valid_error_force 2.7558
wandb:         valid_loss 1.41822
wandb: 
wandb: ğŸš€ View run al_54_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3zhyk7lh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_061030-3zhyk7lh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6913931369781494, Uncertainty Bias: 0.03035522997379303
2.2888184e-05 0.02421546
0.49033076 5.74005
Found uncertainty sample 2 after 2172 steps.
Found uncertainty sample 3 after 2471 steps.
Found uncertainty sample 4 after 72 steps.
Found uncertainty sample 5 after 1936 steps.
Found uncertainty sample 7 after 326 steps.
Found uncertainty sample 9 after 1059 steps.
Found uncertainty sample 11 after 1321 steps.
Found uncertainty sample 12 after 1753 steps.
Found uncertainty sample 14 after 888 steps.
Found uncertainty sample 17 after 548 steps.
Found uncertainty sample 18 after 1564 steps.
Found uncertainty sample 20 after 1456 steps.
Found uncertainty sample 25 after 1338 steps.
Found uncertainty sample 30 after 1237 steps.
Found uncertainty sample 32 after 2189 steps.
Found uncertainty sample 34 after 3052 steps.
Found uncertainty sample 35 after 1446 steps.
Found uncertainty sample 37 after 2379 steps.
Found uncertainty sample 39 after 1487 steps.
Found uncertainty sample 41 after 1889 steps.
Found uncertainty sample 43 after 3021 steps.
Found uncertainty sample 44 after 1541 steps.
Found uncertainty sample 45 after 2027 steps.
Found uncertainty sample 46 after 2447 steps.
Found uncertainty sample 47 after 1088 steps.
Found uncertainty sample 48 after 3885 steps.
Found uncertainty sample 49 after 305 steps.
Found uncertainty sample 50 after 267 steps.
Found uncertainty sample 51 after 1384 steps.
Found uncertainty sample 54 after 2131 steps.
Found uncertainty sample 57 after 691 steps.
Found uncertainty sample 58 after 14 steps.
Found uncertainty sample 63 after 1407 steps.
Found uncertainty sample 64 after 3043 steps.
Found uncertainty sample 65 after 723 steps.
Found uncertainty sample 67 after 2240 steps.
Found uncertainty sample 68 after 1350 steps.
Found uncertainty sample 70 after 3677 steps.
Found uncertainty sample 71 after 1506 steps.
Found uncertainty sample 72 after 1506 steps.
Found uncertainty sample 73 after 2249 steps.
Found uncertainty sample 74 after 3632 steps.
Found uncertainty sample 75 after 3263 steps.
Found uncertainty sample 77 after 779 steps.
Found uncertainty sample 78 after 1548 steps.
Found uncertainty sample 79 after 17 steps.
Found uncertainty sample 80 after 1496 steps.
Found uncertainty sample 82 after 1523 steps.
Found uncertainty sample 84 after 3108 steps.
Found uncertainty sample 88 after 3009 steps.
Found uncertainty sample 91 after 1890 steps.
Found uncertainty sample 92 after 906 steps.
Found uncertainty sample 95 after 2296 steps.
Found uncertainty sample 98 after 922 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_082601-yx2x7bj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/yx2x7bj0
Training model 31. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.9016780807183693, Training Loss Force: 3.2827478554639726, time: 3.026473045349121
Validation Loss Energy: 1.5864573770642285, Validation Loss Force: 2.781234382381976, time: 0.16477441787719727
Test Loss Energy: 7.4889058788658645, Test Loss Force: 6.905172930413217, time: 18.4235417842865


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0435137705347315, Training Loss Force: 3.113659721894658, time: 3.0547540187835693
Validation Loss Energy: 2.951855506125727, Validation Loss Force: 2.787718619245966, time: 0.16031837463378906
Test Loss Energy: 8.94445685458197, Test Loss Force: 6.865396605898884, time: 18.49839425086975


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9859674775663552, Training Loss Force: 3.1206820659045564, time: 3.0245308876037598
Validation Loss Energy: 1.395447608640886, Validation Loss Force: 2.7455548804496637, time: 0.1577587127685547
Test Loss Energy: 7.743472736684764, Test Loss Force: 6.822808196238051, time: 18.49944233894348


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.816899885904622, Training Loss Force: 3.103923453748463, time: 3.0237772464752197
Validation Loss Energy: 2.320650713446735, Validation Loss Force: 2.7549853641179975, time: 0.1598677635192871
Test Loss Energy: 7.426545129877958, Test Loss Force: 6.843841376870702, time: 18.783225297927856


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.245359061542865, Training Loss Force: 3.1068514498292727, time: 3.2906229496002197
Validation Loss Energy: 1.3651922714360882, Validation Loss Force: 2.7563573400606316, time: 0.16350960731506348
Test Loss Energy: 7.643060320821653, Test Loss Force: 6.8456240707162275, time: 18.3533935546875


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9051305262041085, Training Loss Force: 3.10885412255036, time: 3.0003857612609863
Validation Loss Energy: 2.196674322391937, Validation Loss Force: 2.782146657872842, time: 0.15814709663391113
Test Loss Energy: 7.418334413801334, Test Loss Force: 6.934975628750978, time: 18.567665576934814


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9034800454694667, Training Loss Force: 3.1059184769697445, time: 3.074216365814209
Validation Loss Energy: 1.6829532781434944, Validation Loss Force: 2.7508040828957654, time: 0.16254472732543945
Test Loss Energy: 7.940759651797186, Test Loss Force: 6.8528523308835805, time: 18.529487133026123


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.126409907096885, Training Loss Force: 3.1051490111502624, time: 3.064558267593384
Validation Loss Energy: 1.3266557573596631, Validation Loss Force: 2.7657606580931615, time: 0.15693020820617676
Test Loss Energy: 7.50346310860811, Test Loss Force: 6.842243983392028, time: 18.353146076202393


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9766560173452137, Training Loss Force: 3.112612848336033, time: 3.0572171211242676
Validation Loss Energy: 1.6120263637565433, Validation Loss Force: 2.750610694742527, time: 0.16123604774475098
Test Loss Energy: 7.382398691379191, Test Loss Force: 6.863900185300143, time: 18.56277084350586


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8447317729105932, Training Loss Force: 3.1003652279513108, time: 3.0751943588256836
Validation Loss Energy: 1.7447755294898908, Validation Loss Force: 2.7406954603435087, time: 0.164046049118042
Test Loss Energy: 8.02574348575195, Test Loss Force: 6.848608492455221, time: 18.574334144592285


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8540842422712696, Training Loss Force: 3.1000011123036484, time: 3.022913694381714
Validation Loss Energy: 1.3098906076917547, Validation Loss Force: 2.764985992134479, time: 0.1648416519165039
Test Loss Energy: 7.554998886833879, Test Loss Force: 6.858821197677707, time: 18.18948459625244


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.994444994315143, Training Loss Force: 3.1014872279073895, time: 3.246428966522217
Validation Loss Energy: 1.677695558602561, Validation Loss Force: 2.7666836217030326, time: 0.16133904457092285
Test Loss Energy: 7.359706623277765, Test Loss Force: 6.837910496733388, time: 18.020618200302124


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0319668743382486, Training Loss Force: 3.1078145264711385, time: 2.874654531478882
Validation Loss Energy: 1.6675985705131793, Validation Loss Force: 2.800696779081794, time: 0.14890098571777344
Test Loss Energy: 7.409587885811183, Test Loss Force: 6.884669070480455, time: 17.622984170913696


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9472992899913197, Training Loss Force: 3.1062606759993976, time: 2.9405837059020996
Validation Loss Energy: 1.5571821181052319, Validation Loss Force: 2.755446177915495, time: 0.1552724838256836
Test Loss Energy: 7.395745507965473, Test Loss Force: 6.800761453632507, time: 17.824047803878784


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9373347723931622, Training Loss Force: 3.104741670533516, time: 3.096858501434326
Validation Loss Energy: 1.8216827247963112, Validation Loss Force: 2.7524133128133856, time: 0.15166044235229492
Test Loss Energy: 7.421298023552928, Test Loss Force: 6.805559770876824, time: 17.48249626159668


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.750107327254006, Training Loss Force: 3.0868806913228686, time: 2.891493320465088
Validation Loss Energy: 2.0596246917759995, Validation Loss Force: 2.7280638850333174, time: 0.15659809112548828
Test Loss Energy: 7.31421271468339, Test Loss Force: 6.794522842403904, time: 17.713250637054443


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7779318424177353, Training Loss Force: 3.0873687332121493, time: 2.922960042953491
Validation Loss Energy: 1.2955602337999936, Validation Loss Force: 2.7399189016970853, time: 0.14815878868103027
Test Loss Energy: 7.554324581706427, Test Loss Force: 6.865298172146699, time: 18.133103370666504


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2584969253926555, Training Loss Force: 3.0997399784205006, time: 3.0544915199279785
Validation Loss Energy: 2.998061803266348, Validation Loss Force: 2.738776163640184, time: 0.16476225852966309
Test Loss Energy: 8.826137854657777, Test Loss Force: 6.84886864696093, time: 18.015430688858032


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.929264953346397, Training Loss Force: 3.096664768163981, time: 2.962341070175171
Validation Loss Energy: 1.3780455138810508, Validation Loss Force: 2.730542526631212, time: 0.1571638584136963
Test Loss Energy: 7.725387140620041, Test Loss Force: 6.799224782379668, time: 17.636471271514893


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7422071753077446, Training Loss Force: 3.0793110184058476, time: 2.9965596199035645
Validation Loss Energy: 1.4426430577950047, Validation Loss Force: 2.755468778833807, time: 0.15012311935424805
Test Loss Energy: 7.381123972306529, Test Loss Force: 6.83491591148856, time: 17.66793131828308

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–ƒâ–â–‚â–â–„â–‚â–â–„â–‚â–â–â–â–â–â–‚â–‡â–ƒâ–
wandb:   test_error_force â–‡â–…â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–„â–„â–„â–ƒâ–…â–â–‚â–â–…â–„â–â–ƒ
wandb:          test_loss â–„â–ˆâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–â–â–ƒâ–„â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–
wandb: valid_error_energy â–‚â–ˆâ–â–…â–â–…â–ƒâ–â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–„â–â–ˆâ–â–‚
wandb:  valid_error_force â–†â–‡â–ƒâ–„â–„â–†â–ƒâ–…â–ƒâ–‚â–…â–…â–ˆâ–„â–ƒâ–â–‚â–‚â–â–„
wandb:         valid_loss â–‚â–ˆâ–â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–‚â–†â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2610
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.38112
wandb:   test_error_force 6.83492
wandb:          test_loss 3.67742
wandb: train_error_energy 1.74221
wandb:  train_error_force 3.07931
wandb:         train_loss 1.38887
wandb: valid_error_energy 1.44264
wandb:  valid_error_force 2.75547
wandb:         valid_loss 1.34555
wandb: 
wandb: ğŸš€ View run al_54_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/yx2x7bj0
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_082601-yx2x7bj0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.671371340751648, Uncertainty Bias: 0.03774389624595642
6.6280365e-05 4.196167e-05
0.5887524 4.9326653
Found uncertainty sample 1 after 3437 steps.
Found uncertainty sample 5 after 2644 steps.
Found uncertainty sample 6 after 1843 steps.
Found uncertainty sample 8 after 3685 steps.
Found uncertainty sample 11 after 334 steps.
Found uncertainty sample 12 after 1455 steps.
Found uncertainty sample 15 after 296 steps.
Found uncertainty sample 16 after 2736 steps.
Found uncertainty sample 17 after 517 steps.
Found uncertainty sample 21 after 2623 steps.
Found uncertainty sample 23 after 1855 steps.
Found uncertainty sample 24 after 1869 steps.
Found uncertainty sample 28 after 2265 steps.
Found uncertainty sample 30 after 622 steps.
Found uncertainty sample 31 after 2734 steps.
Found uncertainty sample 35 after 2627 steps.
Found uncertainty sample 36 after 2066 steps.
Found uncertainty sample 37 after 468 steps.
Found uncertainty sample 39 after 995 steps.
Found uncertainty sample 42 after 3902 steps.
Found uncertainty sample 46 after 781 steps.
Found uncertainty sample 47 after 1781 steps.
Found uncertainty sample 49 after 53 steps.
Found uncertainty sample 51 after 291 steps.
Found uncertainty sample 52 after 1418 steps.
Found uncertainty sample 53 after 1828 steps.
Found uncertainty sample 56 after 3053 steps.
Found uncertainty sample 59 after 2523 steps.
Found uncertainty sample 61 after 1965 steps.
Found uncertainty sample 63 after 537 steps.
Found uncertainty sample 64 after 229 steps.
Found uncertainty sample 68 after 1168 steps.
Found uncertainty sample 69 after 3115 steps.
Found uncertainty sample 71 after 281 steps.
Found uncertainty sample 74 after 1816 steps.
Found uncertainty sample 75 after 276 steps.
Found uncertainty sample 78 after 3743 steps.
Found uncertainty sample 79 after 571 steps.
Found uncertainty sample 82 after 2795 steps.
Found uncertainty sample 85 after 1200 steps.
Found uncertainty sample 86 after 159 steps.
Found uncertainty sample 88 after 444 steps.
Found uncertainty sample 89 after 145 steps.
Found uncertainty sample 91 after 2069 steps.
Found uncertainty sample 93 after 1379 steps.
Found uncertainty sample 95 after 1580 steps.
Found uncertainty sample 97 after 2340 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_104659-gn644w6a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gn644w6a
Training model 32. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6347326235836164, Training Loss Force: 3.249685732926237, time: 2.981895685195923
Validation Loss Energy: 2.4286229823071195, Validation Loss Force: 2.7766191189943306, time: 0.16088414192199707
Test Loss Energy: 7.326860601965778, Test Loss Force: 6.825941932211977, time: 18.49826669692993


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7916629983755132, Training Loss Force: 3.0971242466009348, time: 2.9695870876312256
Validation Loss Energy: 2.0583147291905064, Validation Loss Force: 2.799275370588764, time: 0.15900325775146484
Test Loss Energy: 7.324195984415849, Test Loss Force: 6.798398684511504, time: 18.318570852279663


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8830390503445167, Training Loss Force: 3.098306482945011, time: 3.0144259929656982
Validation Loss Energy: 1.4291385080982033, Validation Loss Force: 2.781733049934281, time: 0.1597731113433838
Test Loss Energy: 7.742280269962476, Test Loss Force: 6.798476670008089, time: 18.35467505455017


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7429597980842697, Training Loss Force: 3.1157060270700208, time: 3.002148151397705
Validation Loss Energy: 1.324973992967757, Validation Loss Force: 2.7797089873977976, time: 0.16277074813842773
Test Loss Energy: 7.652628101585881, Test Loss Force: 6.80823954858159, time: 18.194650888442993


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8523572956890555, Training Loss Force: 3.106082435596952, time: 3.2146847248077393
Validation Loss Energy: 1.5127954732251325, Validation Loss Force: 2.75101461657324, time: 0.15673041343688965
Test Loss Energy: 7.769086769578462, Test Loss Force: 6.797468258570727, time: 18.219680786132812


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8544154601393756, Training Loss Force: 3.1013657289753915, time: 3.0945634841918945
Validation Loss Energy: 1.4687604785937398, Validation Loss Force: 2.7651886210572734, time: 0.1568741798400879
Test Loss Energy: 7.772579755988682, Test Loss Force: 6.755703134851462, time: 18.36207151412964


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.180913628546477, Training Loss Force: 3.1203580898874814, time: 2.9578003883361816
Validation Loss Energy: 1.3466223326731486, Validation Loss Force: 2.745415823568032, time: 0.16312146186828613
Test Loss Energy: 7.531266468845238, Test Loss Force: 6.768997420172215, time: 18.319477319717407


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9519240645184626, Training Loss Force: 3.0878883945454683, time: 3.085129976272583
Validation Loss Energy: 1.3551153792371262, Validation Loss Force: 2.7619698272183144, time: 0.1596086025238037
Test Loss Energy: 7.370174381434324, Test Loss Force: 6.7832310381995855, time: 18.21601152420044


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8996525147050438, Training Loss Force: 3.0976437390839062, time: 3.0333993434906006
Validation Loss Energy: 2.788096266117459, Validation Loss Force: 2.7874425095050155, time: 0.1601877212524414
Test Loss Energy: 8.701456915109123, Test Loss Force: 6.785995826554199, time: 18.663615942001343


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1611176546867337, Training Loss Force: 3.0989446124758278, time: 2.9971747398376465
Validation Loss Energy: 2.0436401644664275, Validation Loss Force: 2.7586234439587383, time: 0.16445040702819824
Test Loss Energy: 7.351449659635595, Test Loss Force: 6.758417893762473, time: 18.29669189453125


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1019519971565503, Training Loss Force: 3.0973663764936648, time: 2.9766812324523926
Validation Loss Energy: 1.6466500799334387, Validation Loss Force: 2.7561891135208834, time: 0.1587822437286377
Test Loss Energy: 7.353807250241695, Test Loss Force: 6.752611927518601, time: 18.20609164237976


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9977907295080457, Training Loss Force: 3.096713883461555, time: 2.981414318084717
Validation Loss Energy: 1.42344279834723, Validation Loss Force: 2.7577459048546373, time: 0.15770506858825684
Test Loss Energy: 7.345926818959483, Test Loss Force: 6.756242029158819, time: 18.344677448272705


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0736915226490606, Training Loss Force: 3.1069382175110114, time: 3.03572940826416
Validation Loss Energy: 1.9975723675345733, Validation Loss Force: 2.7374467175044224, time: 0.15744709968566895
Test Loss Energy: 7.203478837790013, Test Loss Force: 6.771678067569039, time: 18.335063219070435


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1168352846945684, Training Loss Force: 3.0915765548233365, time: 2.925621271133423
Validation Loss Energy: 1.49526311701493, Validation Loss Force: 2.750136075457982, time: 0.16208171844482422
Test Loss Energy: 7.298105770639068, Test Loss Force: 6.777924655249454, time: 18.175646781921387


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.883977875106893, Training Loss Force: 3.085071232800884, time: 3.2300848960876465
Validation Loss Energy: 1.3328903264437817, Validation Loss Force: 2.758031032695998, time: 0.16078591346740723
Test Loss Energy: 7.353900144078793, Test Loss Force: 6.799976916785559, time: 18.202101230621338


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8888335024599756, Training Loss Force: 3.0945220947202103, time: 3.0147104263305664
Validation Loss Energy: 2.137609327412278, Validation Loss Force: 2.8624719915711134, time: 0.16456317901611328
Test Loss Energy: 7.246943528649144, Test Loss Force: 6.760122767656014, time: 18.345947980880737


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3340748125128368, Training Loss Force: 3.094293405459061, time: 3.050224781036377
Validation Loss Energy: 1.306429995160318, Validation Loss Force: 2.772649484795303, time: 0.16382575035095215
Test Loss Energy: 7.462917966989048, Test Loss Force: 6.762252018630711, time: 18.35349130630493


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.815871567800076, Training Loss Force: 3.0920921519376345, time: 2.980140447616577
Validation Loss Energy: 1.7176008755862906, Validation Loss Force: 2.745606873695238, time: 0.1597762107849121
Test Loss Energy: 7.221702726549848, Test Loss Force: 6.782944685677921, time: 18.57019805908203


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8676252119835335, Training Loss Force: 3.0828566218134625, time: 3.0061609745025635
Validation Loss Energy: 1.287029667484927, Validation Loss Force: 2.735581640738131, time: 0.16647791862487793
Test Loss Energy: 7.44303344904471, Test Loss Force: 6.739975831208683, time: 18.350585460662842


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9650431229512086, Training Loss Force: 3.0864388505986073, time: 3.0412919521331787
Validation Loss Energy: 1.3075847573510995, Validation Loss Force: 2.7382096933329434, time: 0.16373038291931152
Test Loss Energy: 7.406271635749246, Test Loss Force: 6.745122969579456, time: 18.301122665405273

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–ƒâ–„â–„â–ƒâ–‚â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚
wandb:   test_error_force â–ˆâ–†â–†â–‡â–†â–‚â–ƒâ–…â–…â–ƒâ–‚â–‚â–„â–„â–†â–ƒâ–ƒâ–„â–â–
wandb:          test_loss â–ƒâ–ƒâ–„â–…â–†â–„â–„â–‚â–ˆâ–…â–â–‚â–â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–„â–ƒâ–‚â–„â–„â–ƒâ–„â–„â–‚â–‚â–†â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–â–‚
wandb: valid_error_energy â–†â–…â–‚â–â–‚â–‚â–â–â–ˆâ–…â–ƒâ–‚â–„â–‚â–â–…â–â–ƒâ–â–
wandb:  valid_error_force â–ƒâ–…â–„â–ƒâ–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–â–‚â–‚â–ˆâ–ƒâ–‚â–â–
wandb:         valid_loss â–†â–„â–ƒâ–‚â–‚â–‚â–â–‚â–ˆâ–…â–‚â–„â–„â–‚â–‚â–‡â–…â–ƒâ–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2652
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.40627
wandb:   test_error_force 6.74512
wandb:          test_loss 3.61896
wandb: train_error_energy 1.96504
wandb:  train_error_force 3.08644
wandb:         train_loss 1.41899
wandb: valid_error_energy 1.30758
wandb:  valid_error_force 2.73821
wandb:         valid_loss 1.43703
wandb: 
wandb: ğŸš€ View run al_54_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gn644w6a
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241126_104659-gn644w6a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6862601041793823, Uncertainty Bias: 0.03312203288078308
1.9073486e-05 0.0083966255
0.7230323 5.2508626
Found uncertainty sample 2 after 3883 steps.
Found uncertainty sample 3 after 3317 steps.
Found uncertainty sample 6 after 1690 steps.
Found uncertainty sample 9 after 2236 steps.
Found uncertainty sample 11 after 3727 steps.
Found uncertainty sample 14 after 2220 steps.
Found uncertainty sample 15 after 2908 steps.
Found uncertainty sample 17 after 2396 steps.
Found uncertainty sample 19 after 835 steps.
Found uncertainty sample 20 after 2115 steps.
Found uncertainty sample 22 after 477 steps.
Found uncertainty sample 24 after 168 steps.
Found uncertainty sample 25 after 1773 steps.
Found uncertainty sample 27 after 1145 steps.
Found uncertainty sample 28 after 1479 steps.
Found uncertainty sample 29 after 3329 steps.
Found uncertainty sample 31 after 1084 steps.
Found uncertainty sample 33 after 1632 steps.
Found uncertainty sample 34 after 3304 steps.
Found uncertainty sample 36 after 1957 steps.
Found uncertainty sample 37 after 2544 steps.
Found uncertainty sample 38 after 3822 steps.
Found uncertainty sample 39 after 304 steps.
Found uncertainty sample 42 after 3691 steps.
Found uncertainty sample 44 after 518 steps.
Found uncertainty sample 46 after 3736 steps.
Found uncertainty sample 47 after 2979 steps.
Found uncertainty sample 52 after 849 steps.
Found uncertainty sample 57 after 2077 steps.
Found uncertainty sample 58 after 1675 steps.
Found uncertainty sample 59 after 529 steps.
Found uncertainty sample 61 after 1978 steps.
Found uncertainty sample 62 after 1818 steps.
Found uncertainty sample 63 after 2009 steps.
Found uncertainty sample 68 after 1731 steps.
Found uncertainty sample 71 after 1227 steps.
Found uncertainty sample 73 after 2812 steps.
Found uncertainty sample 77 after 1007 steps.
Found uncertainty sample 78 after 1605 steps.
Found uncertainty sample 80 after 3439 steps.
Found uncertainty sample 82 after 1635 steps.
Found uncertainty sample 83 after 3132 steps.
Found uncertainty sample 88 after 1928 steps.
Found uncertainty sample 89 after 3821 steps.
Found uncertainty sample 93 after 437 steps.
Found uncertainty sample 95 after 1851 steps.
Found uncertainty sample 99 after 857 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241126_131631-83z2edtw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_54_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/83z2edtw
Training model 33. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.163309984699969, Training Loss Force: 3.2361922708115225, time: 3.0722272396087646
Validation Loss Energy: 1.4261000206001593, Validation Loss Force: 2.759950552068468, time: 0.16887927055358887
Test Loss Energy: 7.534495691411132, Test Loss Force: 6.785366155515342, time: 18.079433917999268


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7961725836650821, Training Loss Force: 3.099456927216513, time: 3.034587860107422
Validation Loss Energy: 1.319945121641551, Validation Loss Force: 2.7362603362949187, time: 0.16056227684020996
Test Loss Energy: 7.323809831816141, Test Loss Force: 6.7281636690290485, time: 18.228488445281982


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8516916406064037, Training Loss Force: 3.104129123175317, time: 3.0564017295837402
Validation Loss Energy: 1.3484535637292585, Validation Loss Force: 2.7431759946291443, time: 0.15771794319152832
Test Loss Energy: 7.296145494069339, Test Loss Force: 6.718184400346374, time: 18.184715032577515


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9858934664474117, Training Loss Force: 3.0992168689201067, time: 3.0295333862304688
Validation Loss Energy: 2.8408675176874696, Validation Loss Force: 2.7499228697507565, time: 0.15581297874450684
Test Loss Energy: 7.267873635617565, Test Loss Force: 6.773778576736805, time: 18.482290744781494


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.235609130663866, Training Loss Force: 3.09386512340285, time: 3.344379186630249
Validation Loss Energy: 1.7336258730131353, Validation Loss Force: 2.7587928951787895, time: 0.16422820091247559
Test Loss Energy: 7.1418873139393035, Test Loss Force: 6.739742009952547, time: 18.14927101135254


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7830768689282075, Training Loss Force: 3.0857988628614166, time: 3.0404231548309326
Validation Loss Energy: 1.51381991829826, Validation Loss Force: 2.743238453324577, time: 0.1639699935913086
Test Loss Energy: 7.6862746079852124, Test Loss Force: 6.697628918477583, time: 18.248104572296143


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.213565889847809, Training Loss Force: 3.090056925644439, time: 2.9979729652404785
Validation Loss Energy: 2.0213718025242002, Validation Loss Force: 2.758640366813829, time: 0.16309666633605957
Test Loss Energy: 7.259702134958377, Test Loss Force: 6.746337962025501, time: 18.24457883834839

slurmstepd: error: *** JOB 5122847 ON aimat01 CANCELLED AT 2024-11-26T13:19:20 ***
