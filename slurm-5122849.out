wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_165146-mp6em1kx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/mp6em1kx
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
55
Uncertainty Slope: 0.6569409370422363, Uncertainty Bias: 0.02670009434223175
0.0004348755 0.0067272186
0.44071528 2.8812573

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.429314460661287, Test Loss Force: 10.721971835464283, time: 15.381536960601807

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.047 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 8
wandb:  test_error_energy 12.42931
wandb:   test_error_force 10.72197
wandb:          test_loss 6.04434
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_56 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/mp6em1kx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_165146-mp6em1kx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 727 steps.
Found uncertainty sample 1 after 1157 steps.
Found uncertainty sample 2 after 2119 steps.
Found uncertainty sample 5 after 1436 steps.
Found uncertainty sample 7 after 3710 steps.
Found uncertainty sample 9 after 511 steps.
Found uncertainty sample 10 after 921 steps.
Found uncertainty sample 12 after 1366 steps.
Found uncertainty sample 16 after 1014 steps.
Found uncertainty sample 17 after 1313 steps.
Found uncertainty sample 18 after 1893 steps.
Found uncertainty sample 19 after 400 steps.
Found uncertainty sample 20 after 1622 steps.
Found uncertainty sample 21 after 1686 steps.
Found uncertainty sample 22 after 3215 steps.
Found uncertainty sample 23 after 1601 steps.
Found uncertainty sample 24 after 1421 steps.
Found uncertainty sample 25 after 1505 steps.
Found uncertainty sample 26 after 1340 steps.
Found uncertainty sample 27 after 2754 steps.
Found uncertainty sample 28 after 1666 steps.
Found uncertainty sample 29 after 185 steps.
Found uncertainty sample 31 after 687 steps.
Found uncertainty sample 33 after 1186 steps.
Found uncertainty sample 35 after 266 steps.
Found uncertainty sample 36 after 382 steps.
Found uncertainty sample 37 after 2003 steps.
Found uncertainty sample 38 after 738 steps.
Found uncertainty sample 39 after 977 steps.
Found uncertainty sample 40 after 1899 steps.
Found uncertainty sample 41 after 1221 steps.
Found uncertainty sample 45 after 666 steps.
Found uncertainty sample 47 after 700 steps.
Found uncertainty sample 53 after 3108 steps.
Found uncertainty sample 58 after 836 steps.
Found uncertainty sample 60 after 1446 steps.
Found uncertainty sample 61 after 918 steps.
Found uncertainty sample 62 after 377 steps.
Found uncertainty sample 63 after 1042 steps.
Found uncertainty sample 64 after 1587 steps.
Found uncertainty sample 67 after 539 steps.
Found uncertainty sample 68 after 207 steps.
Found uncertainty sample 74 after 434 steps.
Found uncertainty sample 75 after 783 steps.
Found uncertainty sample 79 after 13 steps.
Found uncertainty sample 83 after 405 steps.
Found uncertainty sample 85 after 1912 steps.
Found uncertainty sample 86 after 56 steps.
Found uncertainty sample 89 after 2460 steps.
Found uncertainty sample 90 after 622 steps.
Found uncertainty sample 91 after 2122 steps.
Found uncertainty sample 96 after 2134 steps.
Found uncertainty sample 98 after 783 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_185435-aj3ejuxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/aj3ejuxg
Training model 0. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.408625858725884, Training Loss Force: 3.1265351832807795, time: 1.0585031509399414
Validation Loss Energy: 2.0299777423451633, Validation Loss Force: 2.844179053225708, time: 0.07096028327941895
Test Loss Energy: 11.422913704702827, Test Loss Force: 10.272973954045048, time: 16.326465606689453


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6500248184593476, Training Loss Force: 2.7251185124115462, time: 1.021120548248291
Validation Loss Energy: 1.1276760478634138, Validation Loss Force: 2.72012005191777, time: 0.07636046409606934
Test Loss Energy: 11.54542457137724, Test Loss Force: 10.108809883459475, time: 16.56873917579651


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.577213234483015, Training Loss Force: 2.595945518311118, time: 1.0217278003692627
Validation Loss Energy: 1.743172088970065, Validation Loss Force: 2.6737823799810516, time: 0.06862354278564453
Test Loss Energy: 11.212039630223368, Test Loss Force: 10.128258674025252, time: 16.501843214035034


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4422473499816748, Training Loss Force: 2.548643565267451, time: 0.9973850250244141
Validation Loss Energy: 1.5412170743459284, Validation Loss Force: 2.6707614276782494, time: 0.07576942443847656
Test Loss Energy: 11.209268917237344, Test Loss Force: 10.081659710920952, time: 16.70640993118286


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7082150453287213, Training Loss Force: 2.5570104986247792, time: 1.0329980850219727
Validation Loss Energy: 1.1250341897815537, Validation Loss Force: 2.6616979027624046, time: 0.06823205947875977
Test Loss Energy: 11.587562391951277, Test Loss Force: 10.022802790348804, time: 16.61140537261963


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.341862567318553, Training Loss Force: 2.57229169657242, time: 1.1547541618347168
Validation Loss Energy: 1.7061885251846267, Validation Loss Force: 2.6547887018334113, time: 0.07216787338256836
Test Loss Energy: 11.790928319307602, Test Loss Force: 9.971145082695632, time: 16.670269012451172


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7328373562088755, Training Loss Force: 2.557518143042468, time: 0.9915361404418945
Validation Loss Energy: 1.9791348055788875, Validation Loss Force: 2.6994966582910846, time: 0.07453227043151855
Test Loss Energy: 11.898599091812782, Test Loss Force: 10.000411619377754, time: 16.803479194641113


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.418128069319685, Training Loss Force: 2.5460725530855197, time: 1.001617431640625
Validation Loss Energy: 1.2672003120326198, Validation Loss Force: 2.6638809510690806, time: 0.07125043869018555
Test Loss Energy: 11.356379128662947, Test Loss Force: 9.979747838697548, time: 16.69464921951294


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.45191353924973, Training Loss Force: 2.5534864542512725, time: 1.0354175567626953
Validation Loss Energy: 1.497376525546217, Validation Loss Force: 2.67510191733982, time: 0.07367873191833496
Test Loss Energy: 11.683588691962429, Test Loss Force: 9.851508877026763, time: 17.114962577819824


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.597799780489552, Training Loss Force: 2.5557663636364265, time: 1.0308003425598145
Validation Loss Energy: 1.4699562675746585, Validation Loss Force: 2.6514177136332107, time: 0.06907987594604492
Test Loss Energy: 11.521631512769252, Test Loss Force: 9.923686122385863, time: 16.74118137359619


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5546621919982806, Training Loss Force: 2.566511815822534, time: 0.9975955486297607
Validation Loss Energy: 1.0898851970894146, Validation Loss Force: 2.6645413877559028, time: 0.06927943229675293
Test Loss Energy: 10.98780829352649, Test Loss Force: 9.946450878556655, time: 16.812471628189087


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.22839126741559, Training Loss Force: 2.530841356731649, time: 1.0360949039459229
Validation Loss Energy: 1.1067718684437131, Validation Loss Force: 2.6606221881184275, time: 0.07352638244628906
Test Loss Energy: 11.044561352069804, Test Loss Force: 9.970740897392526, time: 16.806490659713745


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5755463435653556, Training Loss Force: 2.5424219749080885, time: 1.0596108436584473
Validation Loss Energy: 2.3061355798311407, Validation Loss Force: 2.6556802690937062, time: 0.07313179969787598
Test Loss Energy: 12.009592232535285, Test Loss Force: 9.862468619746734, time: 16.757762670516968


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7555433784809262, Training Loss Force: 2.533272821335126, time: 0.9752488136291504
Validation Loss Energy: 1.3003077626603199, Validation Loss Force: 2.665538500191367, time: 0.07261443138122559
Test Loss Energy: 11.19651661561262, Test Loss Force: 9.867031070909352, time: 16.856024026870728


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4296906925303314, Training Loss Force: 2.529935942749279, time: 1.0131843090057373
Validation Loss Energy: 2.3130372100091723, Validation Loss Force: 2.6491186547015064, time: 0.07045292854309082
Test Loss Energy: 11.811914156516083, Test Loss Force: 9.881961720306741, time: 16.802736520767212


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3573079961318228, Training Loss Force: 2.507435077107179, time: 0.9662051200866699
Validation Loss Energy: 2.000521063699522, Validation Loss Force: 2.6610664130645536, time: 0.07485175132751465
Test Loss Energy: 11.589725570242647, Test Loss Force: 9.911050210273457, time: 16.894532442092896


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.389833212301452, Training Loss Force: 2.516495146527759, time: 1.0249848365783691
Validation Loss Energy: 1.4070159387792722, Validation Loss Force: 2.6713477155394774, time: 0.07137250900268555
Test Loss Energy: 11.228281252960958, Test Loss Force: 9.857303091935604, time: 16.9187228679657


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6218463988486722, Training Loss Force: 2.5155592021313815, time: 1.0256218910217285
Validation Loss Energy: 1.1310804364355038, Validation Loss Force: 2.6491585124786274, time: 0.07350945472717285
Test Loss Energy: 10.936757458389566, Test Loss Force: 9.858272423189144, time: 16.75349259376526


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4206026843171913, Training Loss Force: 2.532371910217708, time: 1.0298335552215576
Validation Loss Energy: 1.2703191274250574, Validation Loss Force: 2.6463372943997223, time: 0.0728609561920166
Test Loss Energy: 10.587464916869916, Test Loss Force: 9.883610665773022, time: 16.898017644882202


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6086400711760627, Training Loss Force: 2.544078728194353, time: 1.019660234451294
Validation Loss Energy: 1.3778298031459333, Validation Loss Force: 2.6570968902000986, time: 0.06948089599609375
Test Loss Energy: 10.55992101864911, Test Loss Force: 9.85095371038465, time: 17.147730350494385

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–†â–„â–„â–†â–‡â–‡â–…â–†â–†â–ƒâ–ƒâ–ˆâ–„â–‡â–†â–„â–ƒâ–â–
wandb:   test_error_force â–ˆâ–…â–†â–…â–„â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–â–â–‚â–‚â–â–â–‚â–
wandb:          test_loss â–ˆâ–‡â–‡â–†â–…â–…â–†â–…â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–‚â–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–†â–â–…â–„â–â–…â–†â–‚â–ƒâ–ƒâ–â–â–ˆâ–‚â–ˆâ–†â–ƒâ–â–‚â–ƒ
wandb:  valid_error_force â–ˆâ–„â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–
wandb:         valid_loss â–ˆâ–‚â–ƒâ–‚â–â–ƒâ–„â–‚â–ƒâ–ƒâ–â–â–„â–‚â–„â–„â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 847
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.55992
wandb:   test_error_force 9.85095
wandb:          test_loss 5.47752
wandb: train_error_energy 1.60864
wandb:  train_error_force 2.54408
wandb:         train_loss 1.15447
wandb: valid_error_energy 1.37783
wandb:  valid_error_force 2.6571
wandb:         valid_loss 1.31729
wandb: 
wandb: ğŸš€ View run al_56_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/aj3ejuxg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_185435-aj3ejuxg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7529504299163818, Uncertainty Bias: 0.011041104793548584
8.010864e-05 0.007941484
0.23091875 5.9352136
Found uncertainty sample 6 after 1969 steps.
Found uncertainty sample 7 after 544 steps.
Found uncertainty sample 10 after 2800 steps.
Found uncertainty sample 11 after 2270 steps.
Found uncertainty sample 16 after 294 steps.
Found uncertainty sample 17 after 2683 steps.
Found uncertainty sample 18 after 3039 steps.
Found uncertainty sample 19 after 1202 steps.
Found uncertainty sample 21 after 1369 steps.
Found uncertainty sample 23 after 1840 steps.
Found uncertainty sample 27 after 1881 steps.
Found uncertainty sample 29 after 2225 steps.
Found uncertainty sample 31 after 206 steps.
Found uncertainty sample 32 after 1468 steps.
Found uncertainty sample 39 after 3150 steps.
Found uncertainty sample 40 after 3053 steps.
Found uncertainty sample 41 after 22 steps.
Found uncertainty sample 44 after 2153 steps.
Found uncertainty sample 49 after 1278 steps.
Found uncertainty sample 52 after 1647 steps.
Found uncertainty sample 53 after 2313 steps.
Found uncertainty sample 54 after 1156 steps.
Found uncertainty sample 58 after 1098 steps.
Found uncertainty sample 59 after 2583 steps.
Found uncertainty sample 60 after 907 steps.
Found uncertainty sample 61 after 974 steps.
Found uncertainty sample 63 after 3553 steps.
Found uncertainty sample 64 after 3987 steps.
Found uncertainty sample 70 after 1003 steps.
Found uncertainty sample 72 after 2840 steps.
Found uncertainty sample 77 after 3757 steps.
Found uncertainty sample 82 after 803 steps.
Found uncertainty sample 83 after 3090 steps.
Found uncertainty sample 88 after 3220 steps.
Found uncertainty sample 89 after 1202 steps.
Found uncertainty sample 97 after 1395 steps.
Found uncertainty sample 98 after 665 steps.
Found uncertainty sample 99 after 3323 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241123_213415-mpg4tfzq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/mpg4tfzq
Training model 1. Added 38 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.4601970417475565, Training Loss Force: 3.204177454501901, time: 1.034379005432129
Validation Loss Energy: 2.335878165660153, Validation Loss Force: 2.803786647485261, time: 0.07273125648498535
Test Loss Energy: 10.33171666749567, Test Loss Force: 9.649064193714917, time: 16.466997623443604


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9066277553839728, Training Loss Force: 2.7942377356411714, time: 1.054596185684204
Validation Loss Energy: 1.6060974080752106, Validation Loss Force: 2.7614100369854517, time: 0.07279443740844727
Test Loss Energy: 10.918058566211771, Test Loss Force: 9.581689345924797, time: 16.568207263946533


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4871621431021143, Training Loss Force: 2.716214244238929, time: 1.0262532234191895
Validation Loss Energy: 1.1922417500895, Validation Loss Force: 2.7441331379529146, time: 0.0711822509765625
Test Loss Energy: 10.617241242320665, Test Loss Force: 9.543635109610857, time: 16.51997423171997


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5942761218108157, Training Loss Force: 2.7161728834450725, time: 1.037484884262085
Validation Loss Energy: 1.2953374533194928, Validation Loss Force: 2.750727484709566, time: 0.07344865798950195
Test Loss Energy: 10.714151625110874, Test Loss Force: 9.494392548457682, time: 16.599040269851685


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5459354693342509, Training Loss Force: 2.7209285079193477, time: 1.0177290439605713
Validation Loss Energy: 1.2727702693834304, Validation Loss Force: 2.7663637574749074, time: 0.07571887969970703
Test Loss Energy: 10.326850421006355, Test Loss Force: 9.558964311131703, time: 16.476426124572754


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4948500061057126, Training Loss Force: 2.7225881326361727, time: 1.2486367225646973
Validation Loss Energy: 1.1340266832398473, Validation Loss Force: 2.751840830439205, time: 0.0739896297454834
Test Loss Energy: 10.35326090762663, Test Loss Force: 9.558151496469028, time: 16.526172637939453


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5043561734262532, Training Loss Force: 2.717374962829364, time: 1.0346331596374512
Validation Loss Energy: 1.1657304275716187, Validation Loss Force: 2.765187173707825, time: 0.07341170310974121
Test Loss Energy: 10.351877407098435, Test Loss Force: 9.523772830601745, time: 16.651161432266235


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6110524685557766, Training Loss Force: 2.7088579634272607, time: 1.1001965999603271
Validation Loss Energy: 1.289385729717989, Validation Loss Force: 2.767977886113738, time: 0.0717320442199707
Test Loss Energy: 10.563116309235104, Test Loss Force: 9.549365871973759, time: 16.85641360282898


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5238632073373604, Training Loss Force: 2.6830852185614815, time: 1.020787000656128
Validation Loss Energy: 1.2729255811127151, Validation Loss Force: 2.754015639987482, time: 0.07436776161193848
Test Loss Energy: 10.53504490197856, Test Loss Force: 9.458600709941253, time: 16.637298107147217


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5685895936430938, Training Loss Force: 2.6775211380856305, time: 1.0482735633850098
Validation Loss Energy: 1.2250362392325986, Validation Loss Force: 2.7427430144748874, time: 0.07438921928405762
Test Loss Energy: 10.422098474865384, Test Loss Force: 9.492723499814689, time: 16.52418541908264


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4337872692754892, Training Loss Force: 2.6741381337040186, time: 1.0763912200927734
Validation Loss Energy: 1.7257546857064474, Validation Loss Force: 2.738273154039533, time: 0.07446718215942383
Test Loss Energy: 10.044687035773332, Test Loss Force: 9.45473695958434, time: 16.61763072013855


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8024860519122796, Training Loss Force: 2.6831072787118684, time: 1.034510850906372
Validation Loss Energy: 1.2125575262910866, Validation Loss Force: 2.7498893580442942, time: 0.07416415214538574
Test Loss Energy: 10.184247569365569, Test Loss Force: 9.38843538640405, time: 16.652671575546265


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.831277482627053, Training Loss Force: 2.683989851729162, time: 1.0595464706420898
Validation Loss Energy: 1.412271041957741, Validation Loss Force: 2.758512888727785, time: 0.07388854026794434
Test Loss Energy: 10.416153884837199, Test Loss Force: 9.391475405481101, time: 16.511143922805786


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9965922415739554, Training Loss Force: 2.704639989510767, time: 1.0755181312561035
Validation Loss Energy: 1.2426643988428367, Validation Loss Force: 2.7511398679678245, time: 0.07100296020507812
Test Loss Energy: 10.43829517206262, Test Loss Force: 9.401520693816833, time: 16.680395364761353


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6610572667280754, Training Loss Force: 2.671173397408094, time: 1.096926212310791
Validation Loss Energy: 1.3666671761914275, Validation Loss Force: 2.7476738000423127, time: 0.07245230674743652
Test Loss Energy: 10.447957739934594, Test Loss Force: 9.365689175891758, time: 16.545536994934082


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5928251022976119, Training Loss Force: 2.6877521252860435, time: 1.0553007125854492
Validation Loss Energy: 1.1657646072855186, Validation Loss Force: 2.718994904723397, time: 0.07471799850463867
Test Loss Energy: 10.289710718351532, Test Loss Force: 9.381624242671563, time: 16.637194871902466


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9077308563447815, Training Loss Force: 2.6591247858268803, time: 1.0398218631744385
Validation Loss Energy: 1.7693240234864187, Validation Loss Force: 2.759451661847017, time: 0.07475423812866211
Test Loss Energy: 9.934399497434258, Test Loss Force: 9.315233028255836, time: 16.519660234451294


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8631201943751745, Training Loss Force: 2.663596920668511, time: 1.192000389099121
Validation Loss Energy: 1.7394171078277116, Validation Loss Force: 2.7257444518747604, time: 0.09892559051513672
Test Loss Energy: 9.843701010238368, Test Loss Force: 9.395764997172817, time: 16.574988842010498


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6947086205426996, Training Loss Force: 2.666899215437193, time: 1.0151078701019287
Validation Loss Energy: 1.1605747461668068, Validation Loss Force: 2.743080580900114, time: 0.07213854789733887
Test Loss Energy: 10.001192476937664, Test Loss Force: 9.35573461998686, time: 16.620925188064575


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.555560462454022, Training Loss Force: 2.668314572100936, time: 1.029482126235962
Validation Loss Energy: 1.3148889176776823, Validation Loss Force: 2.7249960608752968, time: 0.07176542282104492
Test Loss Energy: 9.810660602259407, Test Loss Force: 9.351087605844297, time: 16.864633798599243

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–†â–‡â–„â–„â–„â–†â–†â–…â–‚â–ƒâ–…â–…â–…â–„â–‚â–â–‚â–
wandb:   test_error_force â–ˆâ–‡â–†â–…â–†â–†â–…â–†â–„â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚
wandb:          test_loss â–ˆâ–ˆâ–†â–†â–†â–†â–†â–‡â–…â–…â–„â–„â–„â–„â–ƒâ–ƒâ–â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–â–‚â–‚â–â–â–‚â–‚â–‚â–„â–â–ƒâ–‚â–‚â–â–…â–…â–â–‚
wandb:  valid_error_force â–ˆâ–…â–ƒâ–„â–…â–„â–…â–…â–„â–ƒâ–ƒâ–„â–„â–„â–ƒâ–â–„â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–…â–â–‚â–â–ƒâ–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 881
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.81066
wandb:   test_error_force 9.35109
wandb:          test_loss 5.14342
wandb: train_error_energy 1.55556
wandb:  train_error_force 2.66831
wandb:         train_loss 1.20875
wandb: valid_error_energy 1.31489
wandb:  valid_error_force 2.725
wandb:         valid_loss 1.34723
wandb: 
wandb: ğŸš€ View run al_56_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/mpg4tfzq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241123_213415-mpg4tfzq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7757472395896912, Uncertainty Bias: 0.007552921772003174
1.5258789e-05 0.027606964
0.2593781 5.322116
Found uncertainty sample 1 after 1060 steps.
Found uncertainty sample 3 after 3621 steps.
Found uncertainty sample 4 after 3651 steps.
Found uncertainty sample 6 after 506 steps.
Found uncertainty sample 9 after 1764 steps.
Found uncertainty sample 10 after 3775 steps.
Found uncertainty sample 13 after 3542 steps.
Found uncertainty sample 14 after 178 steps.
Found uncertainty sample 16 after 1186 steps.
Found uncertainty sample 17 after 1316 steps.
Found uncertainty sample 18 after 136 steps.
Found uncertainty sample 20 after 1375 steps.
Found uncertainty sample 21 after 2738 steps.
Found uncertainty sample 25 after 3080 steps.
Found uncertainty sample 26 after 1698 steps.
Found uncertainty sample 28 after 1026 steps.
Found uncertainty sample 33 after 856 steps.
Found uncertainty sample 37 after 2402 steps.
Found uncertainty sample 38 after 2616 steps.
Found uncertainty sample 39 after 1155 steps.
Found uncertainty sample 41 after 340 steps.
Found uncertainty sample 42 after 2580 steps.
Found uncertainty sample 45 after 1651 steps.
Found uncertainty sample 47 after 2443 steps.
Found uncertainty sample 49 after 72 steps.
Found uncertainty sample 51 after 3744 steps.
Found uncertainty sample 53 after 615 steps.
Found uncertainty sample 60 after 3324 steps.
Found uncertainty sample 61 after 2638 steps.
Found uncertainty sample 66 after 1568 steps.
Found uncertainty sample 70 after 2021 steps.
Found uncertainty sample 72 after 1881 steps.
Found uncertainty sample 75 after 1762 steps.
Found uncertainty sample 76 after 3178 steps.
Found uncertainty sample 77 after 1899 steps.
Found uncertainty sample 78 after 301 steps.
Found uncertainty sample 80 after 3404 steps.
Found uncertainty sample 82 after 1271 steps.
Found uncertainty sample 86 after 1122 steps.
Found uncertainty sample 90 after 3061 steps.
Found uncertainty sample 92 after 940 steps.
Found uncertainty sample 93 after 368 steps.
Found uncertainty sample 98 after 845 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_000732-z116xu2p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/z116xu2p
Training model 2. Added 43 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4716810499640802, Training Loss Force: 3.1015590711054055, time: 1.0771949291229248
Validation Loss Energy: 3.0608978115668672, Validation Loss Force: 2.8798709132956186, time: 0.07687544822692871
Test Loss Energy: 11.007719923479504, Test Loss Force: 9.142506454654054, time: 16.60149312019348


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9055578404211553, Training Loss Force: 2.894318578159997, time: 1.0845239162445068
Validation Loss Energy: 1.5218576621261017, Validation Loss Force: 2.855109658930157, time: 0.07590055465698242
Test Loss Energy: 9.691916061778628, Test Loss Force: 9.142808972256228, time: 16.768242835998535


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7575266167054744, Training Loss Force: 2.8749258999375935, time: 1.1105148792266846
Validation Loss Energy: 1.4620869172884245, Validation Loss Force: 2.8407913648395624, time: 0.07605624198913574
Test Loss Energy: 9.743795762409642, Test Loss Force: 9.161685472805987, time: 16.613234996795654


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6059062216591309, Training Loss Force: 2.844578475604023, time: 1.0711209774017334
Validation Loss Energy: 1.536207909239137, Validation Loss Force: 2.841822322985208, time: 0.07238245010375977
Test Loss Energy: 9.763696867456641, Test Loss Force: 9.142575428462168, time: 16.77912187576294


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7313996076965332, Training Loss Force: 2.8385144730052474, time: 1.099358081817627
Validation Loss Energy: 1.6652410052633821, Validation Loss Force: 2.8741026690703593, time: 0.07487702369689941
Test Loss Energy: 9.62167714317418, Test Loss Force: 9.176528728643921, time: 16.805601358413696


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6760856491601335, Training Loss Force: 2.860298948019511, time: 1.085005760192871
Validation Loss Energy: 1.3359390567225387, Validation Loss Force: 2.8457974125783108, time: 0.07567930221557617
Test Loss Energy: 9.739682263540724, Test Loss Force: 9.120090806398252, time: 16.674829244613647


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7892667482469893, Training Loss Force: 2.826154362096928, time: 1.0755226612091064
Validation Loss Energy: 1.352554962395389, Validation Loss Force: 2.844267230207495, time: 0.07633018493652344
Test Loss Energy: 9.754895807676073, Test Loss Force: 9.07367840506403, time: 16.768851041793823


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6939408122863988, Training Loss Force: 2.830577830567465, time: 1.084543228149414
Validation Loss Energy: 1.5180906568498684, Validation Loss Force: 2.8407285721404105, time: 0.0759577751159668
Test Loss Energy: 9.662909318202027, Test Loss Force: 9.052039613318351, time: 16.738943338394165


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9231587768087424, Training Loss Force: 2.8248770397369287, time: 1.1224439144134521
Validation Loss Energy: 1.7472556184372348, Validation Loss Force: 2.8349480811121253, time: 0.08469533920288086
Test Loss Energy: 10.039857544848585, Test Loss Force: 9.06876077912655, time: 16.837811708450317


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9078424680887296, Training Loss Force: 2.8462764276589265, time: 1.0995521545410156
Validation Loss Energy: 2.0253310826079423, Validation Loss Force: 2.8534051266180795, time: 0.07369470596313477
Test Loss Energy: 9.530114918863815, Test Loss Force: 9.035769656806298, time: 16.673673152923584


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.651236064247956, Training Loss Force: 2.8205354981555995, time: 1.2765047550201416
Validation Loss Energy: 1.5114570089889607, Validation Loss Force: 2.8194667860723497, time: 0.07460546493530273
Test Loss Energy: 9.617582339187061, Test Loss Force: 9.020262459865558, time: 16.70994734764099


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5143942933601806, Training Loss Force: 2.8380172144111584, time: 1.0324935913085938
Validation Loss Energy: 1.4138152524847503, Validation Loss Force: 2.8313729053051087, time: 0.07553625106811523
Test Loss Energy: 9.89761462447541, Test Loss Force: 8.976146866289634, time: 17.203025579452515


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7014324274013053, Training Loss Force: 2.839458789818388, time: 1.0872344970703125
Validation Loss Energy: 1.5687634743886552, Validation Loss Force: 2.825331891376088, time: 0.07507491111755371
Test Loss Energy: 10.00389376844567, Test Loss Force: 9.017854657949956, time: 16.65438675880432


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5794340639566313, Training Loss Force: 2.816599498514978, time: 1.062523365020752
Validation Loss Energy: 1.4024337417597972, Validation Loss Force: 2.8209486492384994, time: 0.07667136192321777
Test Loss Energy: 9.643809836070053, Test Loss Force: 9.010387976251858, time: 16.8476083278656


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6361312297906039, Training Loss Force: 2.8156918530066966, time: 1.0608594417572021
Validation Loss Energy: 1.6673266358187149, Validation Loss Force: 2.810212879036737, time: 0.0744171142578125
Test Loss Energy: 9.881749398864159, Test Loss Force: 8.961467196496496, time: 16.76040816307068


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7431255280838271, Training Loss Force: 2.812728817716575, time: 1.101637840270996
Validation Loss Energy: 1.4515610127566991, Validation Loss Force: 2.8200724461492737, time: 0.07490229606628418
Test Loss Energy: 9.77252042731321, Test Loss Force: 9.002005366589417, time: 16.815632820129395


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5009227274904007, Training Loss Force: 2.8200544099484532, time: 1.0881199836730957
Validation Loss Energy: 1.4624777016395278, Validation Loss Force: 2.8299424787116685, time: 0.0769808292388916
Test Loss Energy: 9.466519109227361, Test Loss Force: 8.933988797978808, time: 16.805685997009277


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6685624610959835, Training Loss Force: 2.7921722555466526, time: 1.0558626651763916
Validation Loss Energy: 1.5094789276311111, Validation Loss Force: 2.8422300301914016, time: 0.07883071899414062
Test Loss Energy: 9.422549409408495, Test Loss Force: 8.930568571917986, time: 16.74515151977539


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8115714743642202, Training Loss Force: 2.794956218773971, time: 1.104628324508667
Validation Loss Energy: 1.5497426306052116, Validation Loss Force: 2.8352718420503042, time: 0.08044266700744629
Test Loss Energy: 9.848164209252257, Test Loss Force: 8.912249345789483, time: 16.819772958755493


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.867408676600126, Training Loss Force: 2.786163137053225, time: 1.086350917816162
Validation Loss Energy: 1.4184973166161738, Validation Loss Force: 2.818255243249357, time: 0.07384109497070312
Test Loss Energy: 9.50860628714329, Test Loss Force: 8.907476256609657, time: 16.73903512954712

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–„â–â–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–â–â–ƒâ–
wandb:   test_error_force â–‡â–‡â–ˆâ–‡â–ˆâ–‡â–…â–…â–…â–„â–„â–ƒâ–„â–„â–‚â–ƒâ–‚â–‚â–â–
wandb:          test_loss â–ˆâ–…â–†â–†â–…â–…â–…â–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–„â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–
wandb:  valid_error_force â–ˆâ–†â–„â–„â–‡â–…â–„â–„â–ƒâ–…â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–„â–„â–‚
wandb:         valid_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–…â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 919
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.50861
wandb:   test_error_force 8.90748
wandb:          test_loss 4.86993
wandb: train_error_energy 1.86741
wandb:  train_error_force 2.78616
wandb:         train_loss 1.27279
wandb: valid_error_energy 1.4185
wandb:  valid_error_force 2.81826
wandb:         valid_loss 1.39029
wandb: 
wandb: ğŸš€ View run al_56_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/z116xu2p
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_000732-z116xu2p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7952859401702881, Uncertainty Bias: 0.004765301942825317
0.00035095215 0.0019388199
0.11752032 5.9889774
Found uncertainty sample 1 after 2725 steps.
Found uncertainty sample 4 after 496 steps.
Found uncertainty sample 8 after 2546 steps.
Found uncertainty sample 13 after 2416 steps.
Found uncertainty sample 19 after 1288 steps.
Found uncertainty sample 22 after 1936 steps.
Found uncertainty sample 23 after 310 steps.
Found uncertainty sample 24 after 3204 steps.
Found uncertainty sample 25 after 441 steps.
Found uncertainty sample 26 after 1392 steps.
Found uncertainty sample 27 after 514 steps.
Found uncertainty sample 28 after 2712 steps.
Found uncertainty sample 30 after 2195 steps.
Found uncertainty sample 31 after 1461 steps.
Found uncertainty sample 34 after 2971 steps.
Found uncertainty sample 36 after 3610 steps.
Found uncertainty sample 37 after 3375 steps.
Found uncertainty sample 40 after 3904 steps.
Found uncertainty sample 43 after 763 steps.
Found uncertainty sample 44 after 1465 steps.
Found uncertainty sample 45 after 2485 steps.
Found uncertainty sample 46 after 411 steps.
Found uncertainty sample 48 after 2563 steps.
Found uncertainty sample 57 after 3818 steps.
Found uncertainty sample 60 after 2993 steps.
Found uncertainty sample 61 after 1157 steps.
Found uncertainty sample 62 after 3375 steps.
Found uncertainty sample 66 after 1009 steps.
Found uncertainty sample 73 after 1946 steps.
Found uncertainty sample 75 after 525 steps.
Found uncertainty sample 76 after 3825 steps.
Found uncertainty sample 77 after 930 steps.
Found uncertainty sample 81 after 2361 steps.
Found uncertainty sample 84 after 328 steps.
Found uncertainty sample 96 after 1522 steps.
Found uncertainty sample 97 after 1515 steps.
Found uncertainty sample 98 after 3334 steps.
Found uncertainty sample 99 after 2463 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_024849-89j9ef7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/89j9ef7q
Training model 3. Added 38 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1277868881953927, Training Loss Force: 3.3856100962495423, time: 1.0988271236419678
Validation Loss Energy: 2.2448971113180805, Validation Loss Force: 2.9184953260173985, time: 0.08146023750305176
Test Loss Energy: 9.99508108323723, Test Loss Force: 8.869563488649227, time: 16.79482078552246


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8067264205130422, Training Loss Force: 3.0475441647502617, time: 1.1171185970306396
Validation Loss Energy: 1.4070621426270522, Validation Loss Force: 2.90525608660797, time: 0.08057856559753418
Test Loss Energy: 9.461590366153883, Test Loss Force: 8.795143584937536, time: 17.16489005088806


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8485775652288334, Training Loss Force: 2.98118901904445, time: 1.1250011920928955
Validation Loss Energy: 1.4391943023955887, Validation Loss Force: 2.8721255897236664, time: 0.07518768310546875
Test Loss Energy: 9.533788157696375, Test Loss Force: 8.77844230313433, time: 16.743732929229736


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7965012139627061, Training Loss Force: 2.9590518686076135, time: 1.1765241622924805
Validation Loss Energy: 2.3601252769676675, Validation Loss Force: 2.9080185200323503, time: 0.08112955093383789
Test Loss Energy: 9.24295847065093, Test Loss Force: 8.828923394377824, time: 16.896029472351074


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0214493618988794, Training Loss Force: 2.96579685846379, time: 1.1227893829345703
Validation Loss Energy: 1.492073437166801, Validation Loss Force: 2.8650816739613867, time: 0.07695770263671875
Test Loss Energy: 9.4586113560912, Test Loss Force: 8.781471508185216, time: 16.838897705078125


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.186665344282483, Training Loss Force: 2.97389960312648, time: 1.1278047561645508
Validation Loss Energy: 1.4114613056085745, Validation Loss Force: 2.8668590190841825, time: 0.0779569149017334
Test Loss Energy: 9.362310872252337, Test Loss Force: 8.756452211756413, time: 16.788519144058228


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8699855224577389, Training Loss Force: 2.927442350436094, time: 1.123457908630371
Validation Loss Energy: 1.6355477406501928, Validation Loss Force: 2.8819682339811123, time: 0.07704877853393555
Test Loss Energy: 9.221725309809095, Test Loss Force: 8.727558015192106, time: 16.863463878631592


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.653978657787449, Training Loss Force: 2.950922670850387, time: 1.1283130645751953
Validation Loss Energy: 1.4088221195564654, Validation Loss Force: 2.861455506919953, time: 0.07581806182861328
Test Loss Energy: 9.28791398157175, Test Loss Force: 8.73813341930813, time: 16.747768878936768


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7390300234955836, Training Loss Force: 2.964564087848885, time: 1.0874824523925781
Validation Loss Energy: 1.5278008129654874, Validation Loss Force: 2.8749421317505073, time: 0.07597017288208008
Test Loss Energy: 9.467820746784735, Test Loss Force: 8.655117236818477, time: 16.88764190673828


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9165693254460612, Training Loss Force: 2.9468317190783533, time: 1.1299011707305908
Validation Loss Energy: 1.4175861544710373, Validation Loss Force: 2.862466647511611, time: 0.07710719108581543
Test Loss Energy: 9.364801012788039, Test Loss Force: 8.714545869166347, time: 16.879899501800537


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6877337026589798, Training Loss Force: 2.9638022921668368, time: 1.0935232639312744
Validation Loss Energy: 1.4727957445235296, Validation Loss Force: 2.8703992358352886, time: 0.0807197093963623
Test Loss Energy: 9.32386265377857, Test Loss Force: 8.675901683191247, time: 16.73889446258545


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9196215033854274, Training Loss Force: 2.9626064846301565, time: 1.123119831085205
Validation Loss Energy: 2.422689294906436, Validation Loss Force: 2.880295320687757, time: 0.08235716819763184
Test Loss Energy: 9.122180636773471, Test Loss Force: 8.714478774639195, time: 16.887596130371094


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9102865893145258, Training Loss Force: 2.9458685339984223, time: 1.0975642204284668
Validation Loss Energy: 2.296818212088938, Validation Loss Force: 2.868242685156978, time: 0.07646989822387695
Test Loss Energy: 9.811850942549642, Test Loss Force: 8.655990067227915, time: 16.817146062850952


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8592963309301518, Training Loss Force: 2.9465935595821735, time: 1.1043305397033691
Validation Loss Energy: 1.7145522009748204, Validation Loss Force: 2.8644247999809, time: 0.07824349403381348
Test Loss Energy: 9.520004601811015, Test Loss Force: 8.609123817210396, time: 16.867137908935547


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9852804072057508, Training Loss Force: 2.9597512501280585, time: 1.1640474796295166
Validation Loss Energy: 1.6753384943583425, Validation Loss Force: 2.868569340794054, time: 0.07734227180480957
Test Loss Energy: 9.102138068036192, Test Loss Force: 8.629930623762325, time: 17.181939125061035


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6472028653660855, Training Loss Force: 2.9325113838539205, time: 1.327901840209961
Validation Loss Energy: 1.5164462452071916, Validation Loss Force: 2.863897742112489, time: 0.07669615745544434
Test Loss Energy: 9.31282833438182, Test Loss Force: 8.65042971787588, time: 16.78231167793274


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8339845530794507, Training Loss Force: 2.938401695304978, time: 1.1466352939605713
Validation Loss Energy: 2.0039243389258825, Validation Loss Force: 2.895284516915032, time: 0.08363747596740723
Test Loss Energy: 9.044831614877472, Test Loss Force: 8.649418058500087, time: 16.917810440063477


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7901548352781125, Training Loss Force: 2.9236932700261073, time: 1.1109070777893066
Validation Loss Energy: 1.3734457816663341, Validation Loss Force: 2.8462621230858622, time: 0.07937955856323242
Test Loss Energy: 9.239904942201822, Test Loss Force: 8.598664009857897, time: 16.774988889694214


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5784468693840858, Training Loss Force: 2.9134881500883103, time: 1.146394968032837
Validation Loss Energy: 1.4296117357005864, Validation Loss Force: 2.854150177580354, time: 0.07573056221008301
Test Loss Energy: 9.088497607970977, Test Loss Force: 8.576847054816106, time: 16.916541814804077


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8214051120386259, Training Loss Force: 2.9378334956007044, time: 1.1492419242858887
Validation Loss Energy: 1.4345155783013541, Validation Loss Force: 2.8419877661606323, time: 0.07864952087402344
Test Loss Energy: 9.182104350068268, Test Loss Force: 8.557304444762437, time: 16.834851503372192

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–…â–‚â–„â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‡â–…â–â–ƒâ–â–‚â–â–‚
wandb:   test_error_force â–ˆâ–†â–†â–‡â–†â–…â–…â–…â–ƒâ–…â–„â–…â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–â–
wandb:          test_loss â–ˆâ–†â–…â–…â–…â–…â–ƒâ–„â–ƒâ–„â–„â–„â–„â–„â–‚â–‚â–‚â–â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–„â–‚â–â–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–‡â–â–â–ˆâ–‚â–â–ƒâ–â–‚â–â–‚â–ˆâ–‡â–ƒâ–ƒâ–‚â–…â–â–â–
wandb:  valid_error_force â–ˆâ–‡â–„â–‡â–ƒâ–ƒâ–…â–ƒâ–„â–ƒâ–„â–…â–ƒâ–ƒâ–ƒâ–ƒâ–†â–â–‚â–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–†â–‚â–…â–„â–ƒâ–‚â–â–‚â–‡â–†â–ƒâ–ƒâ–‚â–„â–‚â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 953
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.1821
wandb:   test_error_force 8.5573
wandb:          test_loss 4.65011
wandb: train_error_energy 1.82141
wandb:  train_error_force 2.93783
wandb:         train_loss 1.34217
wandb: valid_error_energy 1.43452
wandb:  valid_error_force 2.84199
wandb:         valid_loss 1.40254
wandb: 
wandb: ğŸš€ View run al_56_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/89j9ef7q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_024849-89j9ef7q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.779173731803894, Uncertainty Bias: 0.0087575763463974
4.196167e-05 0.002844043
0.20362228 5.888479
Found uncertainty sample 12 after 2555 steps.
Found uncertainty sample 13 after 2446 steps.
Found uncertainty sample 20 after 2230 steps.
Found uncertainty sample 25 after 1259 steps.
Found uncertainty sample 26 after 497 steps.
Found uncertainty sample 27 after 1138 steps.
Found uncertainty sample 29 after 3625 steps.
Found uncertainty sample 31 after 3836 steps.
Found uncertainty sample 33 after 2021 steps.
Found uncertainty sample 36 after 373 steps.
Found uncertainty sample 40 after 1213 steps.
Found uncertainty sample 45 after 3256 steps.
Found uncertainty sample 47 after 2556 steps.
Found uncertainty sample 51 after 3629 steps.
Found uncertainty sample 64 after 2126 steps.
Found uncertainty sample 65 after 1240 steps.
Found uncertainty sample 72 after 3931 steps.
Found uncertainty sample 74 after 3409 steps.
Found uncertainty sample 75 after 3698 steps.
Found uncertainty sample 76 after 2461 steps.
Found uncertainty sample 79 after 1843 steps.
Found uncertainty sample 80 after 501 steps.
Found uncertainty sample 89 after 3831 steps.
Found uncertainty sample 90 after 1278 steps.
Found uncertainty sample 98 after 1307 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_054544-jil3pv89
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jil3pv89
Training model 4. Added 25 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.111271006221182, Training Loss Force: 3.313632550059901, time: 1.1575992107391357
Validation Loss Energy: 2.200747386409248, Validation Loss Force: 2.997469392003607, time: 0.07927775382995605
Test Loss Energy: 9.508518417934564, Test Loss Force: 8.543768930647573, time: 17.17068910598755


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8651934449236176, Training Loss Force: 3.071852760036979, time: 1.1699793338775635
Validation Loss Energy: 1.5771622205693323, Validation Loss Force: 2.9182746608937844, time: 0.07980704307556152
Test Loss Energy: 9.114144756779645, Test Loss Force: 8.470766023432143, time: 16.999066591262817


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8811178048750967, Training Loss Force: 3.0280618844139986, time: 1.16066575050354
Validation Loss Energy: 2.1005774444221736, Validation Loss Force: 2.9090824332115934, time: 0.07716774940490723
Test Loss Energy: 9.370674759053609, Test Loss Force: 8.479507128087914, time: 16.853264093399048


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9349333531908812, Training Loss Force: 3.0532536085186686, time: 1.1977972984313965
Validation Loss Energy: 2.204136856148561, Validation Loss Force: 2.9130127663063647, time: 0.07686281204223633
Test Loss Energy: 8.852423401736852, Test Loss Force: 8.498993816709163, time: 16.919312953948975


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9801771485824786, Training Loss Force: 3.0389739798478344, time: 1.1653728485107422
Validation Loss Energy: 1.615392731571966, Validation Loss Force: 2.912623317970137, time: 0.0792090892791748
Test Loss Energy: 9.079142330515229, Test Loss Force: 8.52304698552219, time: 16.959327220916748


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0299921134836705, Training Loss Force: 3.0211741674661505, time: 1.1383264064788818
Validation Loss Energy: 1.5697366498909324, Validation Loss Force: 2.9078619836227633, time: 0.08117151260375977
Test Loss Energy: 8.944012873289514, Test Loss Force: 8.4644774923458, time: 16.897499084472656


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7527274612977617, Training Loss Force: 3.018103646138314, time: 1.1671535968780518
Validation Loss Energy: 1.5678616643476475, Validation Loss Force: 2.922916421909795, time: 0.08393263816833496
Test Loss Energy: 9.017279348493686, Test Loss Force: 8.446843222157925, time: 16.999528408050537


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9889432988539364, Training Loss Force: 3.0247179469235905, time: 1.1641011238098145
Validation Loss Energy: 2.329885693604944, Validation Loss Force: 2.913326729802123, time: 0.0808708667755127
Test Loss Energy: 9.390940099527835, Test Loss Force: 8.450482636264832, time: 16.898160457611084


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0702308362118917, Training Loss Force: 3.0196860049180327, time: 1.2060880661010742
Validation Loss Energy: 1.6600061649771929, Validation Loss Force: 2.906347388092162, time: 0.07840228080749512
Test Loss Energy: 8.969034666877011, Test Loss Force: 8.429719342295117, time: 17.36557650566101


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6704475432236927, Training Loss Force: 3.0265804019402602, time: 1.1565675735473633
Validation Loss Energy: 1.5687005703549306, Validation Loss Force: 2.903773110096091, time: 0.07662820816040039
Test Loss Energy: 8.848853567657725, Test Loss Force: 8.464065981111213, time: 16.999842405319214


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2448667564854774, Training Loss Force: 3.0145423763786034, time: 1.1700530052185059
Validation Loss Energy: 1.8349091050625623, Validation Loss Force: 2.897172528603354, time: 0.07851266860961914
Test Loss Energy: 8.872142351764413, Test Loss Force: 8.436464515338441, time: 16.87156081199646


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.6140773620472393, Training Loss Force: 3.0055645000723095, time: 1.1756706237792969
Validation Loss Energy: 2.297247072863995, Validation Loss Force: 2.9082411891782782, time: 0.07987523078918457
Test Loss Energy: 9.277167502266458, Test Loss Force: 8.412655331287386, time: 16.994864463806152


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3870421590119157, Training Loss Force: 3.0090401355882195, time: 1.1858530044555664
Validation Loss Energy: 2.078001019716555, Validation Loss Force: 2.8971827713840663, time: 0.08401656150817871
Test Loss Energy: 9.220904129315056, Test Loss Force: 8.389216542787992, time: 16.90824794769287


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1416761638763786, Training Loss Force: 2.9869883409390354, time: 1.1775622367858887
Validation Loss Energy: 1.8922876039309644, Validation Loss Force: 2.8954178957334427, time: 0.07709693908691406
Test Loss Energy: 8.73765114358581, Test Loss Force: 8.383034552476037, time: 16.992416620254517


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8258103086357154, Training Loss Force: 2.984715952024712, time: 1.1688814163208008
Validation Loss Energy: 1.7661332859598466, Validation Loss Force: 2.8890798411637544, time: 0.07673239707946777
Test Loss Energy: 8.77927073961143, Test Loss Force: 8.408706166911388, time: 16.959406852722168


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9238903211163658, Training Loss Force: 3.0019470314933177, time: 1.1782941818237305
Validation Loss Energy: 1.583731183043348, Validation Loss Force: 2.916841339601447, time: 0.07700085639953613
Test Loss Energy: 8.812771562098972, Test Loss Force: 8.366591650820213, time: 16.82661771774292


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9333455569742755, Training Loss Force: 3.006556735335191, time: 1.2272696495056152
Validation Loss Energy: 2.3689262749604634, Validation Loss Force: 2.8859562383846793, time: 0.0786137580871582
Test Loss Energy: 8.713570727530485, Test Loss Force: 8.363973084980243, time: 17.2792751789093


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9186155189013578, Training Loss Force: 2.965004108418449, time: 1.1918926239013672
Validation Loss Energy: 1.8937603376621308, Validation Loss Force: 2.8916009012339488, time: 0.07927322387695312
Test Loss Energy: 9.022498174671377, Test Loss Force: 8.346361051395979, time: 16.84944200515747


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8521378285479464, Training Loss Force: 2.978295919294944, time: 1.163386344909668
Validation Loss Energy: 2.790136583501596, Validation Loss Force: 2.890896153387087, time: 0.07955360412597656
Test Loss Energy: 8.66304381773844, Test Loss Force: 8.374254878259935, time: 16.9797203540802


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8813429592960083, Training Loss Force: 2.9860606725455976, time: 1.2165799140930176
Validation Loss Energy: 2.239634103384931, Validation Loss Force: 2.892133303161862, time: 0.07665753364562988
Test Loss Energy: 9.196259597882728, Test Loss Force: 8.31806236772406, time: 16.89423418045044

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–‡â–ƒâ–„â–ƒâ–„â–‡â–„â–ƒâ–ƒâ–†â–†â–‚â–‚â–‚â–â–„â–â–…
wandb:   test_error_force â–ˆâ–†â–†â–‡â–‡â–†â–…â–…â–„â–†â–…â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–
wandb:          test_loss â–ˆâ–…â–…â–„â–…â–„â–ƒâ–…â–„â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‚â–â–‚â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–„â–†â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–â–„â–…â–â–â–â–…â–‚â–â–ƒâ–…â–„â–ƒâ–‚â–â–†â–ƒâ–ˆâ–…
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–â–â–
wandb:         valid_loss â–ˆâ–‚â–„â–…â–‚â–â–„â–„â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 975
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.19626
wandb:   test_error_force 8.31806
wandb:          test_loss 4.53324
wandb: train_error_energy 1.88134
wandb:  train_error_force 2.98606
wandb:         train_loss 1.35566
wandb: valid_error_energy 2.23963
wandb:  valid_error_force 2.89213
wandb:         valid_loss 1.4538
wandb: 
wandb: ğŸš€ View run al_56_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/jil3pv89
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_054544-jil3pv89/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7763153314590454, Uncertainty Bias: 0.012481063604354858
0.00016784668 0.01521492
0.23933092 6.0237794
Found uncertainty sample 1 after 1988 steps.
Found uncertainty sample 2 after 3336 steps.
Found uncertainty sample 7 after 908 steps.
Found uncertainty sample 11 after 2332 steps.
Found uncertainty sample 12 after 1863 steps.
Found uncertainty sample 16 after 542 steps.
Found uncertainty sample 19 after 3321 steps.
Found uncertainty sample 24 after 900 steps.
Found uncertainty sample 31 after 1041 steps.
Found uncertainty sample 35 after 1662 steps.
Found uncertainty sample 38 after 844 steps.
Found uncertainty sample 49 after 1284 steps.
Found uncertainty sample 51 after 2692 steps.
Found uncertainty sample 53 after 3504 steps.
Found uncertainty sample 55 after 745 steps.
Found uncertainty sample 59 after 3671 steps.
Found uncertainty sample 60 after 538 steps.
Found uncertainty sample 61 after 2318 steps.
Found uncertainty sample 62 after 1274 steps.
Found uncertainty sample 65 after 1169 steps.
Found uncertainty sample 68 after 1614 steps.
Found uncertainty sample 70 after 1441 steps.
Found uncertainty sample 71 after 2014 steps.
Found uncertainty sample 73 after 2445 steps.
Found uncertainty sample 75 after 512 steps.
Found uncertainty sample 78 after 2101 steps.
Found uncertainty sample 80 after 262 steps.
Found uncertainty sample 92 after 2393 steps.
Found uncertainty sample 94 after 1122 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_083224-fj0uocgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fj0uocgz
Training model 5. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.527832497604569, Training Loss Force: 3.5619659251423412, time: 1.2056398391723633
Validation Loss Energy: 2.728149501319926, Validation Loss Force: 3.095924558897892, time: 0.08766436576843262
Test Loss Energy: 8.755030535710667, Test Loss Force: 8.411139847411816, time: 16.90876030921936


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.257884825051951, Training Loss Force: 3.17071761503989, time: 1.195073127746582
Validation Loss Energy: 2.3748365821008246, Validation Loss Force: 2.974851550836846, time: 0.07959747314453125
Test Loss Energy: 9.333129411505256, Test Loss Force: 8.243824828877077, time: 17.031982898712158


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.037511373664241, Training Loss Force: 3.0862858865365266, time: 1.1909801959991455
Validation Loss Energy: 1.6445427948036646, Validation Loss Force: 2.9562994256055806, time: 0.07712960243225098
Test Loss Energy: 8.727640782829194, Test Loss Force: 8.275810409976915, time: 16.8617262840271


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0695986099325863, Training Loss Force: 3.0858553487844644, time: 1.1704564094543457
Validation Loss Energy: 2.1363136156521243, Validation Loss Force: 2.9616256715761735, time: 0.07920002937316895
Test Loss Energy: 9.148151740044286, Test Loss Force: 8.26965075419636, time: 16.952788829803467


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2920109035213407, Training Loss Force: 3.085350884875954, time: 1.2013607025146484
Validation Loss Energy: 1.707239746222552, Validation Loss Force: 2.9615063209139563, time: 0.08208203315734863
Test Loss Energy: 8.653795458778564, Test Loss Force: 8.243620005905422, time: 16.9780170917511


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8978910521130046, Training Loss Force: 3.06969431442628, time: 1.1832633018493652
Validation Loss Energy: 1.8025349039324023, Validation Loss Force: 2.947812613777689, time: 0.08101844787597656
Test Loss Energy: 8.650266679760392, Test Loss Force: 8.241316557710187, time: 16.910423278808594


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8135815515747287, Training Loss Force: 3.0962180785826896, time: 1.2255702018737793
Validation Loss Energy: 1.696869710092976, Validation Loss Force: 2.9539587275435877, time: 0.08081841468811035
Test Loss Energy: 8.674593269963319, Test Loss Force: 8.212018658486889, time: 17.28607749938965


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7736388540081265, Training Loss Force: 3.080594115246072, time: 1.204892873764038
Validation Loss Energy: 1.7288187244889868, Validation Loss Force: 2.966128264375979, time: 0.07939720153808594
Test Loss Energy: 8.599079806599189, Test Loss Force: 8.243557112946863, time: 16.95724582672119


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.13763047402273, Training Loss Force: 3.1292405113471107, time: 1.1823768615722656
Validation Loss Energy: 2.438247633470702, Validation Loss Force: 2.9643039360633927, time: 0.0792994499206543
Test Loss Energy: 9.201027352329508, Test Loss Force: 8.190300123207601, time: 17.008366107940674


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9666370683422203, Training Loss Force: 3.0844638544995076, time: 1.1799867153167725
Validation Loss Energy: 1.8576674504604038, Validation Loss Force: 2.9512568601269002, time: 0.08205771446228027
Test Loss Energy: 8.539149361934504, Test Loss Force: 8.2113490119244, time: 17.02622652053833


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8168322584252663, Training Loss Force: 3.0520512707753182, time: 1.2086350917816162
Validation Loss Energy: 1.6464118796145826, Validation Loss Force: 2.94905488494282, time: 0.0806114673614502
Test Loss Energy: 8.579702223527827, Test Loss Force: 8.229826379778793, time: 16.88947558403015


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.952268277064376, Training Loss Force: 3.1252616224617054, time: 1.19804048538208
Validation Loss Energy: 1.7715920200722663, Validation Loss Force: 2.9546962077549006, time: 0.08133482933044434
Test Loss Energy: 8.811391074016187, Test Loss Force: 8.156783508697801, time: 17.032146453857422


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0360513007615437, Training Loss Force: 3.1090210047590836, time: 1.2306411266326904
Validation Loss Energy: 2.0374859232767024, Validation Loss Force: 2.940297975440918, time: 0.08064103126525879
Test Loss Energy: 8.97463887155853, Test Loss Force: 8.159674847738955, time: 16.865850687026978


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0729498884341666, Training Loss Force: 3.100472757122148, time: 1.1954562664031982
Validation Loss Energy: 2.1675184697624443, Validation Loss Force: 2.947858706290896, time: 0.07920408248901367
Test Loss Energy: 8.57764365310276, Test Loss Force: 8.157684805783708, time: 17.034096717834473


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.105878596623782, Training Loss Force: 3.071318727596288, time: 1.183905839920044
Validation Loss Energy: 2.572115878664196, Validation Loss Force: 2.9376388605002486, time: 0.07823848724365234
Test Loss Energy: 9.199339133155435, Test Loss Force: 8.166236844515865, time: 16.99503231048584


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.014400657822174, Training Loss Force: 3.0631854308712, time: 1.1815366744995117
Validation Loss Energy: 1.9903493144443947, Validation Loss Force: 2.966390791299028, time: 0.07874488830566406
Test Loss Energy: 8.494492493473233, Test Loss Force: 8.176087893076312, time: 16.911794424057007


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8419509367808042, Training Loss Force: 3.0603680260014183, time: 1.278456449508667
Validation Loss Energy: 1.5934266429953359, Validation Loss Force: 2.94052754733037, time: 0.0802607536315918
Test Loss Energy: 8.60336828611098, Test Loss Force: 8.132060171040727, time: 17.238544940948486


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0447577791810985, Training Loss Force: 3.057594452161331, time: 1.207056999206543
Validation Loss Energy: 3.26330495589181, Validation Loss Force: 2.955402291616638, time: 0.08059859275817871
Test Loss Energy: 8.592179320077868, Test Loss Force: 8.174391744082708, time: 16.918296575546265


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2588402078977863, Training Loss Force: 3.1125185247014575, time: 1.1843845844268799
Validation Loss Energy: 1.7922174177212655, Validation Loss Force: 2.9727484407535583, time: 0.0823373794555664
Test Loss Energy: 8.492244710232864, Test Loss Force: 8.146899868835556, time: 17.004619598388672


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9698193618372744, Training Loss Force: 3.110077521147635, time: 1.1951868534088135
Validation Loss Energy: 1.5953582978362593, Validation Loss Force: 2.99112087198406, time: 0.0784604549407959
Test Loss Energy: 8.610066206663088, Test Loss Force: 8.149374068125699, time: 17.080955028533936

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–†â–‚â–‚â–ƒâ–‚â–‡â–â–‚â–„â–…â–‚â–‡â–â–‚â–‚â–â–‚
wandb:   test_error_force â–ˆâ–„â–…â–„â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–
wandb:          test_loss â–ˆâ–…â–„â–†â–„â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–â–„â–â–â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–‚â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–‚â–
wandb: valid_error_energy â–†â–„â–â–ƒâ–â–‚â–â–‚â–…â–‚â–â–‚â–ƒâ–ƒâ–…â–ƒâ–â–ˆâ–‚â–
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–ƒâ–ƒ
wandb:         valid_loss â–ˆâ–„â–‚â–„â–‚â–‚â–‚â–„â–ƒâ–‚â–â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1001
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.61007
wandb:   test_error_force 8.14937
wandb:          test_loss 4.41592
wandb: train_error_energy 1.96982
wandb:  train_error_force 3.11008
wandb:         train_loss 1.41289
wandb: valid_error_energy 1.59536
wandb:  valid_error_force 2.99112
wandb:         valid_loss 1.4609
wandb: 
wandb: ğŸš€ View run al_56_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fj0uocgz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_083224-fj0uocgz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7701846361160278, Uncertainty Bias: 0.018689200282096863
5.9127808e-05 0.011683464
0.39378533 5.2329473
Found uncertainty sample 10 after 2494 steps.
Found uncertainty sample 14 after 350 steps.
Found uncertainty sample 18 after 3005 steps.
Found uncertainty sample 24 after 3444 steps.
Found uncertainty sample 27 after 3695 steps.
Found uncertainty sample 43 after 538 steps.
Found uncertainty sample 45 after 3944 steps.
Found uncertainty sample 49 after 1517 steps.
Found uncertainty sample 51 after 1472 steps.
Found uncertainty sample 53 after 1707 steps.
Found uncertainty sample 55 after 2761 steps.
Found uncertainty sample 56 after 2996 steps.
Found uncertainty sample 61 after 2363 steps.
Found uncertainty sample 63 after 2103 steps.
Found uncertainty sample 65 after 1900 steps.
Found uncertainty sample 76 after 1590 steps.
Found uncertainty sample 80 after 1360 steps.
Found uncertainty sample 83 after 1212 steps.
Found uncertainty sample 84 after 2946 steps.
Found uncertainty sample 89 after 3810 steps.
Found uncertainty sample 93 after 3265 steps.
Found uncertainty sample 95 after 1131 steps.
Found uncertainty sample 97 after 2454 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_113050-suslef49
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/suslef49
Training model 6. Added 23 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.817068674664785, Training Loss Force: 3.5667062311722466, time: 1.1744349002838135
Validation Loss Energy: 1.7166839240433602, Validation Loss Force: 3.188840162779785, time: 0.0867466926574707
Test Loss Energy: 8.623555617772482, Test Loss Force: 8.163035342509925, time: 17.225974082946777


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0622739222941133, Training Loss Force: 3.2397507770496015, time: 1.241030216217041
Validation Loss Energy: 2.5291055517750767, Validation Loss Force: 3.011426962077799, time: 0.0831155776977539
Test Loss Energy: 8.506574253195652, Test Loss Force: 8.091028519488148, time: 17.48314595222473


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.056124092736842, Training Loss Force: 3.1597465322597578, time: 1.2287652492523193
Validation Loss Energy: 1.7448250733748598, Validation Loss Force: 2.990588247387001, time: 0.0843954086303711
Test Loss Energy: 8.420354591491307, Test Loss Force: 8.10031422391096, time: 17.301753282546997


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9552092111220658, Training Loss Force: 3.158086234565201, time: 1.2532861232757568
Validation Loss Energy: 1.6825481872997654, Validation Loss Force: 2.9918806191099656, time: 0.07808160781860352
Test Loss Energy: 8.470651091178633, Test Loss Force: 8.111115246664745, time: 17.527372121810913


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8465363798989225, Training Loss Force: 3.164723681718411, time: 1.246603012084961
Validation Loss Energy: 1.7103330659977807, Validation Loss Force: 2.9770406112104624, time: 0.08244681358337402
Test Loss Energy: 8.678982225721246, Test Loss Force: 8.060556111634313, time: 17.72106695175171


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9645645752664975, Training Loss Force: 3.1473426361512775, time: 1.233351469039917
Validation Loss Energy: 2.3409641516222894, Validation Loss Force: 3.020676638399639, time: 0.08350515365600586
Test Loss Energy: 8.837786799187638, Test Loss Force: 8.068698434474735, time: 17.38731336593628


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.395676013507936, Training Loss Force: 3.1621843975703046, time: 1.2114946842193604
Validation Loss Energy: 1.9849961255071449, Validation Loss Force: 3.0076627401658893, time: 0.08366894721984863
Test Loss Energy: 8.391388499606425, Test Loss Force: 8.059383825032006, time: 17.443187713623047


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.010836782474313, Training Loss Force: 3.140530470261033, time: 1.2126338481903076
Validation Loss Energy: 1.6423110932886034, Validation Loss Force: 2.9872965294027503, time: 0.08405828475952148
Test Loss Energy: 8.509983278182368, Test Loss Force: 8.054563038022668, time: 17.395564794540405


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0832564499403317, Training Loss Force: 3.138917886389402, time: 1.2504260540008545
Validation Loss Energy: 1.729718419173108, Validation Loss Force: 2.9856336362209617, time: 0.07950258255004883
Test Loss Energy: 8.420672001112695, Test Loss Force: 8.03456656762763, time: 17.32302212715149


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8688909600302939, Training Loss Force: 3.1240933887875952, time: 1.2086570262908936
Validation Loss Energy: 1.792786114719965, Validation Loss Force: 2.9654299739343495, time: 0.08513569831848145
Test Loss Energy: 8.628157508187495, Test Loss Force: 8.047113421408122, time: 17.472044229507446


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0668277985815906, Training Loss Force: 3.150297560093901, time: 1.2819936275482178
Validation Loss Energy: 1.6695269409842002, Validation Loss Force: 2.9832045385080352, time: 0.08081483840942383
Test Loss Energy: 8.435578693175271, Test Loss Force: 8.053622537177393, time: 17.29783606529236


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2816523939992726, Training Loss Force: 3.131521074822881, time: 1.213958978652954
Validation Loss Energy: 2.2175301826069713, Validation Loss Force: 2.968781812588001, time: 0.08942365646362305
Test Loss Energy: 8.353834557728527, Test Loss Force: 8.00568526488926, time: 17.412262678146362


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0792783334385265, Training Loss Force: 3.113865123319867, time: 1.2277915477752686
Validation Loss Energy: 1.6504489825648263, Validation Loss Force: 2.9887737165168353, time: 0.08402085304260254
Test Loss Energy: 8.463416589280351, Test Loss Force: 8.042655128110285, time: 17.74712872505188


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.058358121840319, Training Loss Force: 3.1187178772684656, time: 1.2615489959716797
Validation Loss Energy: 1.7279903952661355, Validation Loss Force: 2.9614335081032377, time: 0.08128690719604492
Test Loss Energy: 8.585120391052442, Test Loss Force: 8.050896992219586, time: 17.398515224456787


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7180328154581312, Training Loss Force: 3.124962591715546, time: 1.2250874042510986
Validation Loss Energy: 1.7597041597094736, Validation Loss Force: 2.9662536271051367, time: 0.07864165306091309
Test Loss Energy: 8.40597482322933, Test Loss Force: 7.992201389031723, time: 17.44688892364502


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0271559014884906, Training Loss Force: 3.1135638241317833, time: 1.2342371940612793
Validation Loss Energy: 1.8030506056743711, Validation Loss Force: 2.972578989533507, time: 0.0811917781829834
Test Loss Energy: 8.678826315350042, Test Loss Force: 8.01073541044536, time: 17.36519956588745


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.967475542928033, Training Loss Force: 3.1098239218656554, time: 1.2017316818237305
Validation Loss Energy: 2.2875529489268827, Validation Loss Force: 2.967455595154855, time: 0.08321404457092285
Test Loss Energy: 8.945964126512703, Test Loss Force: 7.97635022538507, time: 17.424702405929565


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9226320122733387, Training Loss Force: 3.121205669176576, time: 1.2688567638397217
Validation Loss Energy: 2.185323762678268, Validation Loss Force: 2.9717217133216853, time: 0.0827493667602539
Test Loss Energy: 8.93071777190383, Test Loss Force: 7.968825442195377, time: 17.47461199760437


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4414124439585954, Training Loss Force: 3.121324964171507, time: 1.2282915115356445
Validation Loss Energy: 1.7352432860218683, Validation Loss Force: 2.967143858350556, time: 0.08339619636535645
Test Loss Energy: 8.59221761450774, Test Loss Force: 8.011784245076258, time: 17.33422064781189


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9292803980483424, Training Loss Force: 3.1033597043495664, time: 1.2243623733520508
Validation Loss Energy: 1.7082189337917693, Validation Loss Force: 2.965453131525526, time: 0.08238959312438965
Test Loss Energy: 8.552719043522295, Test Loss Force: 7.990400669477641, time: 17.497886896133423

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‚â–‚â–…â–‡â–â–ƒâ–‚â–„â–‚â–â–‚â–„â–‚â–…â–ˆâ–ˆâ–„â–ƒ
wandb:   test_error_force â–ˆâ–…â–†â–†â–„â–…â–„â–„â–ƒâ–„â–„â–‚â–„â–„â–‚â–ƒâ–â–â–ƒâ–‚
wandb:          test_loss â–ˆâ–†â–‡â–„â–…â–‡â–‚â–‚â–ƒâ–„â–„â–â–…â–„â–â–‚â–‚â–‚â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–â–‚â–‚â–â–â–â–â–â–â–‚â–
wandb: valid_error_energy â–‚â–ˆâ–‚â–â–‚â–‡â–„â–â–‚â–‚â–â–†â–â–‚â–‚â–‚â–†â–…â–‚â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–
wandb:         valid_loss â–‡â–…â–ƒâ–ƒâ–â–ˆâ–ƒâ–â–ƒâ–â–‚â–ƒâ–„â–‚â–â–â–ƒâ–ƒâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1021
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.55272
wandb:   test_error_force 7.9904
wandb:          test_loss 4.34147
wandb: train_error_energy 1.92928
wandb:  train_error_force 3.10336
wandb:         train_loss 1.41736
wandb: valid_error_energy 1.70822
wandb:  valid_error_force 2.96545
wandb:         valid_loss 1.50766
wandb: 
wandb: ğŸš€ View run al_56_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/suslef49
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_113050-suslef49/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.775664210319519, Uncertainty Bias: 0.014184817671775818
6.866455e-05 0.008141875
0.50504637 5.954829
Found uncertainty sample 4 after 3063 steps.
Found uncertainty sample 10 after 2422 steps.
Found uncertainty sample 13 after 3291 steps.
Found uncertainty sample 14 after 922 steps.
Found uncertainty sample 21 after 2974 steps.
Found uncertainty sample 23 after 2432 steps.
Found uncertainty sample 24 after 1821 steps.
Found uncertainty sample 31 after 818 steps.
Found uncertainty sample 32 after 3192 steps.
Found uncertainty sample 39 after 679 steps.
Found uncertainty sample 42 after 1567 steps.
Found uncertainty sample 43 after 3270 steps.
Found uncertainty sample 45 after 963 steps.
Found uncertainty sample 47 after 222 steps.
Found uncertainty sample 49 after 2181 steps.
Found uncertainty sample 52 after 3215 steps.
Found uncertainty sample 53 after 1978 steps.
Found uncertainty sample 56 after 409 steps.
Found uncertainty sample 62 after 1497 steps.
Found uncertainty sample 63 after 1824 steps.
Found uncertainty sample 64 after 2166 steps.
Found uncertainty sample 67 after 2883 steps.
Found uncertainty sample 74 after 2722 steps.
Found uncertainty sample 75 after 2231 steps.
Found uncertainty sample 76 after 452 steps.
Found uncertainty sample 77 after 2048 steps.
Found uncertainty sample 81 after 2990 steps.
Found uncertainty sample 82 after 2081 steps.
Found uncertainty sample 91 after 2400 steps.
Found uncertainty sample 92 after 3183 steps.
Found uncertainty sample 95 after 3671 steps.
Found uncertainty sample 96 after 1686 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_142037-q5rpcp4r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q5rpcp4r
Training model 7. Added 32 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.169030930722685, Training Loss Force: 3.468448906446702, time: 1.2065355777740479
Validation Loss Energy: 1.6896532257426022, Validation Loss Force: 3.0781453182721417, time: 0.08024048805236816
Test Loss Energy: 8.411119347860705, Test Loss Force: 7.948337842939304, time: 16.404299020767212


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0037092101669414, Training Loss Force: 3.2734303967121336, time: 1.2086782455444336
Validation Loss Energy: 1.6862100927391208, Validation Loss Force: 3.0371356736591832, time: 0.07966756820678711
Test Loss Energy: 8.482436976067431, Test Loss Force: 7.949595671799473, time: 16.515042543411255


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0141400214782563, Training Loss Force: 3.225285076406124, time: 1.1924097537994385
Validation Loss Energy: 2.637232130353589, Validation Loss Force: 3.0318679896739695, time: 0.07685184478759766
Test Loss Energy: 8.459955336137943, Test Loss Force: 7.931185661944626, time: 16.48640513420105


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.402347675588822, Training Loss Force: 3.2498624128045996, time: 1.2092761993408203
Validation Loss Energy: 1.900448205460072, Validation Loss Force: 3.031623053613449, time: 0.07879495620727539
Test Loss Energy: 8.353567133250074, Test Loss Force: 7.951750344362632, time: 16.604309558868408


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1861548516490186, Training Loss Force: 3.212390252185047, time: 1.2138967514038086
Validation Loss Energy: 2.7815978897627027, Validation Loss Force: 3.0245076610553268, time: 0.08048510551452637
Test Loss Energy: 8.407153719957591, Test Loss Force: 7.914482724695413, time: 17.28212881088257


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1515179406383393, Training Loss Force: 3.2266188983279807, time: 1.2522029876708984
Validation Loss Energy: 2.854695271649585, Validation Loss Force: 3.040389983226918, time: 0.0865168571472168
Test Loss Energy: 8.314203544067729, Test Loss Force: 7.893494117529387, time: 17.024691104888916


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.086027743108561, Training Loss Force: 3.2293819795171497, time: 1.2185981273651123
Validation Loss Energy: 1.7728887338435768, Validation Loss Force: 3.028358946603294, time: 0.08307623863220215
Test Loss Energy: 8.448391523501863, Test Loss Force: 7.909633872047232, time: 17.193529844284058


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0311489314461193, Training Loss Force: 3.2055552810522463, time: 1.2217695713043213
Validation Loss Energy: 2.1392080918800396, Validation Loss Force: 3.0227156197688996, time: 0.08165454864501953
Test Loss Energy: 8.684618499423005, Test Loss Force: 7.9055089739170095, time: 17.026269912719727


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9756420038607645, Training Loss Force: 3.2179069342558067, time: 1.2345061302185059
Validation Loss Energy: 1.6540104642193683, Validation Loss Force: 3.006043490136703, time: 0.0795292854309082
Test Loss Energy: 8.345483308275643, Test Loss Force: 7.9244546930943605, time: 17.19945788383484


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.873274516456104, Training Loss Force: 3.2193574415576807, time: 1.2488925457000732
Validation Loss Energy: 1.9623845190764697, Validation Loss Force: 3.047469748721692, time: 0.07908511161804199
Test Loss Energy: 8.226904951257762, Test Loss Force: 7.866349624802796, time: 17.14474058151245


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1157039195516876, Training Loss Force: 3.196437607048642, time: 1.2525665760040283
Validation Loss Energy: 1.6694117097011827, Validation Loss Force: 3.0149562680407542, time: 0.08275842666625977
Test Loss Energy: 8.282545253969806, Test Loss Force: 7.894585851527993, time: 17.083428859710693


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9024122316715288, Training Loss Force: 3.1981474226922724, time: 1.2576913833618164
Validation Loss Energy: 1.6822360051571748, Validation Loss Force: 3.0060125391254187, time: 0.08318376541137695
Test Loss Energy: 8.376766931304886, Test Loss Force: 7.881162210588946, time: 17.147615432739258


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9760659422981866, Training Loss Force: 3.1925032321714943, time: 1.2218081951141357
Validation Loss Energy: 2.6930757707991106, Validation Loss Force: 3.013488433030798, time: 0.08288145065307617
Test Loss Energy: 8.871881868501118, Test Loss Force: 7.865867687164515, time: 17.089706420898438


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.261021913442037, Training Loss Force: 3.202389141718749, time: 1.2131376266479492
Validation Loss Energy: 1.647640901965531, Validation Loss Force: 3.0065433823693106, time: 0.08372020721435547
Test Loss Energy: 8.330129669107487, Test Loss Force: 7.889035637702422, time: 17.54596757888794


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.605229918274351, Training Loss Force: 3.2158704629751003, time: 1.2301831245422363
Validation Loss Energy: 2.5282153205296574, Validation Loss Force: 3.0269783978985414, time: 0.0794992446899414
Test Loss Energy: 8.837330532620525, Test Loss Force: 7.849669791517633, time: 17.172550678253174


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.229592868613292, Training Loss Force: 3.1885394717146345, time: 1.2284648418426514
Validation Loss Energy: 1.639160658877444, Validation Loss Force: 2.989387392683012, time: 0.07944035530090332
Test Loss Energy: 8.291741177260336, Test Loss Force: 7.863467940975603, time: 17.08316922187805


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.057086428827395, Training Loss Force: 3.2102120958520315, time: 1.2787315845489502
Validation Loss Energy: 1.7565030680676157, Validation Loss Force: 3.0164111882402462, time: 0.08220219612121582
Test Loss Energy: 8.195562517926243, Test Loss Force: 7.875963086550343, time: 17.182848691940308


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8711922158166356, Training Loss Force: 3.204671729881205, time: 1.276857614517212
Validation Loss Energy: 1.7163960128376754, Validation Loss Force: 2.996569585984913, time: 0.08286285400390625
Test Loss Energy: 8.137564570980976, Test Loss Force: 7.84235238908026, time: 17.085957288742065


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9712586301459534, Training Loss Force: 3.1892702583564696, time: 1.2474656105041504
Validation Loss Energy: 1.684258063671345, Validation Loss Force: 2.990582012650915, time: 0.0832984447479248
Test Loss Energy: 8.299632923865744, Test Loss Force: 7.8298549538604805, time: 17.21526551246643


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9786185977706783, Training Loss Force: 3.1836747783982506, time: 1.236469030380249
Validation Loss Energy: 1.7943597175742367, Validation Loss Force: 3.005141012088257, time: 0.08178448677062988
Test Loss Energy: 8.364942253020796, Test Loss Force: 7.798480276637663, time: 17.210335969924927

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–„â–ƒâ–„â–ƒâ–„â–†â–ƒâ–‚â–‚â–ƒâ–ˆâ–ƒâ–ˆâ–‚â–‚â–â–ƒâ–ƒ
wandb:   test_error_force â–ˆâ–ˆâ–‡â–ˆâ–†â–…â–†â–†â–‡â–„â–…â–…â–„â–…â–ƒâ–„â–…â–ƒâ–‚â–
wandb:          test_loss â–ˆâ–ˆâ–†â–†â–…â–ƒâ–…â–„â–‡â–â–ƒâ–„â–„â–‡â–†â–ƒâ–â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–ƒâ–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–ƒâ–â–â–â–â–
wandb: valid_error_energy â–â–â–‡â–ƒâ–ˆâ–ˆâ–‚â–„â–â–ƒâ–â–â–‡â–â–†â–â–‚â–â–â–‚
wandb:  valid_error_force â–ˆâ–…â–„â–„â–„â–…â–„â–„â–‚â–†â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–â–‚
wandb:         valid_loss â–‡â–ƒâ–†â–ƒâ–†â–†â–ƒâ–…â–ƒâ–‡â–ƒâ–ƒâ–…â–ƒâ–ˆâ–â–‚â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1049
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.36494
wandb:   test_error_force 7.79848
wandb:          test_loss 4.20575
wandb: train_error_energy 1.97862
wandb:  train_error_force 3.18367
wandb:         train_loss 1.44746
wandb: valid_error_energy 1.79436
wandb:  valid_error_force 3.00514
wandb:         valid_loss 1.49608
wandb: 
wandb: ğŸš€ View run al_56_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q5rpcp4r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_142037-q5rpcp4r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7512613534927368, Uncertainty Bias: 0.019296899437904358
0.0009799004 0.017559528
0.3542695 5.69893
Found uncertainty sample 0 after 2313 steps.
Found uncertainty sample 5 after 2924 steps.
Found uncertainty sample 7 after 511 steps.
Found uncertainty sample 8 after 1310 steps.
Found uncertainty sample 15 after 2433 steps.
Found uncertainty sample 16 after 380 steps.
Found uncertainty sample 17 after 2352 steps.
Found uncertainty sample 21 after 1667 steps.
Found uncertainty sample 33 after 2166 steps.
Found uncertainty sample 44 after 16 steps.
Found uncertainty sample 48 after 3660 steps.
Found uncertainty sample 55 after 1910 steps.
Found uncertainty sample 56 after 1686 steps.
Found uncertainty sample 62 after 719 steps.
Found uncertainty sample 63 after 444 steps.
Found uncertainty sample 65 after 1725 steps.
Found uncertainty sample 71 after 2451 steps.
Found uncertainty sample 74 after 300 steps.
Found uncertainty sample 76 after 2274 steps.
Found uncertainty sample 77 after 2984 steps.
Found uncertainty sample 79 after 1145 steps.
Found uncertainty sample 82 after 2039 steps.
Found uncertainty sample 84 after 3865 steps.
Found uncertainty sample 85 after 2062 steps.
Found uncertainty sample 88 after 1938 steps.
Found uncertainty sample 98 after 830 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_171051-9c1t77xh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9c1t77xh
Training model 8. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.068864320040676, Training Loss Force: 3.4691170454617075, time: 1.25166916847229
Validation Loss Energy: 3.1988609423539733, Validation Loss Force: 3.145357554632153, time: 0.09493875503540039
Test Loss Energy: 8.236944203044606, Test Loss Force: 7.8573297803453785, time: 16.879355430603027


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0143414401089053, Training Loss Force: 3.3015890450204095, time: 1.2353224754333496
Validation Loss Energy: 1.7433865193575935, Validation Loss Force: 3.0677241795735752, time: 0.08445119857788086
Test Loss Energy: 8.131816419440165, Test Loss Force: 7.756294089060867, time: 17.34685754776001


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9942155024524075, Training Loss Force: 3.275258019019805, time: 1.2509434223175049
Validation Loss Energy: 2.189726822369844, Validation Loss Force: 3.0710998438258406, time: 0.08675312995910645
Test Loss Energy: 8.474292086119894, Test Loss Force: 7.795307528096723, time: 16.983447790145874


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9911881058425587, Training Loss Force: 3.270341995106936, time: 1.2712044715881348
Validation Loss Energy: 1.7728043422372701, Validation Loss Force: 3.0548434374890907, time: 0.0805976390838623
Test Loss Energy: 8.116265152661448, Test Loss Force: 7.782173946945749, time: 17.104931592941284


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8428433863266582, Training Loss Force: 3.260814637261939, time: 1.2518410682678223
Validation Loss Energy: 1.7972995069733484, Validation Loss Force: 3.064929013784744, time: 0.0858466625213623
Test Loss Energy: 8.354978002264499, Test Loss Force: 7.760527206727624, time: 17.073135375976562


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0486741178884347, Training Loss Force: 3.280603997406182, time: 1.2627253532409668
Validation Loss Energy: 1.7377951857687737, Validation Loss Force: 3.078304972049772, time: 0.08452844619750977
Test Loss Energy: 8.116986323232176, Test Loss Force: 7.739849492321596, time: 16.986135721206665


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3429590674224805, Training Loss Force: 3.293222101233045, time: 1.222839117050171
Validation Loss Energy: 1.7449024509030697, Validation Loss Force: 3.068422470015205, time: 0.09139013290405273
Test Loss Energy: 8.1108785785078, Test Loss Force: 7.6899947122610515, time: 17.08114194869995


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.074993856528069, Training Loss Force: 3.2686013772950337, time: 1.3064515590667725
Validation Loss Energy: 1.9646590844021221, Validation Loss Force: 3.0709248258771416, time: 0.08365201950073242
Test Loss Energy: 8.380555524413108, Test Loss Force: 7.705828507714321, time: 17.02454137802124


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0181335873513517, Training Loss Force: 3.270077771968923, time: 1.2825665473937988
Validation Loss Energy: 2.084374924018738, Validation Loss Force: 3.0564789423659304, time: 0.08028841018676758
Test Loss Energy: 8.487142581340551, Test Loss Force: 7.751928454107106, time: 17.12943410873413


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.043152781000547, Training Loss Force: 3.2736337458366496, time: 1.2890498638153076
Validation Loss Energy: 2.2456214540497834, Validation Loss Force: 3.068616414841308, time: 0.08440685272216797
Test Loss Energy: 8.122621564028892, Test Loss Force: 7.731012012728887, time: 17.382738828659058


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.080162747452509, Training Loss Force: 3.301177349416867, time: 1.2640762329101562
Validation Loss Energy: 1.918172224137632, Validation Loss Force: 3.050065848294064, time: 0.08223080635070801
Test Loss Energy: 8.340282978792557, Test Loss Force: 7.725271898261857, time: 17.01259207725525


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.098157297681459, Training Loss Force: 3.270751254448059, time: 1.2483716011047363
Validation Loss Energy: 2.3116297183377625, Validation Loss Force: 3.0549278290953974, time: 0.08700108528137207
Test Loss Energy: 8.093633629583184, Test Loss Force: 7.695271777495571, time: 17.11376142501831


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.166122072253776, Training Loss Force: 3.2420637077779153, time: 1.257552146911621
Validation Loss Energy: 1.9497369115877714, Validation Loss Force: 3.047553249651415, time: 0.08423280715942383
Test Loss Energy: 8.055251855116236, Test Loss Force: 7.653867785825174, time: 17.03089451789856


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.01603413493624, Training Loss Force: 3.248487627499729, time: 1.3075709342956543
Validation Loss Energy: 2.2787853513059764, Validation Loss Force: 3.0509424967215817, time: 0.10720300674438477
Test Loss Energy: 8.469638352265514, Test Loss Force: 7.693847021387606, time: 17.12426781654358


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0469349441514346, Training Loss Force: 3.2237445141205674, time: 1.2632133960723877
Validation Loss Energy: 2.524630569949366, Validation Loss Force: 3.0446351704940313, time: 0.08181452751159668
Test Loss Energy: 8.646395029894933, Test Loss Force: 7.693182511370963, time: 17.22130036354065


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3590176322230736, Training Loss Force: 3.2677761457929475, time: 1.269895315170288
Validation Loss Energy: 2.134353459160522, Validation Loss Force: 3.048182735326953, time: 0.08582139015197754
Test Loss Energy: 8.055603975476634, Test Loss Force: 7.662310126777461, time: 17.11073613166809


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.29731276353659, Training Loss Force: 3.262715747135315, time: 1.2800381183624268
Validation Loss Energy: 2.425901965343882, Validation Loss Force: 3.069470796354233, time: 0.08474588394165039
Test Loss Energy: 7.995103971116033, Test Loss Force: 7.64818829565619, time: 17.201184272766113


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.430261598002909, Training Loss Force: 3.2447014333823905, time: 1.2674264907836914
Validation Loss Energy: 2.1753192379517325, Validation Loss Force: 3.032440249379004, time: 0.0851430892944336
Test Loss Energy: 8.40908572803805, Test Loss Force: 7.654133603821514, time: 17.00884985923767


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2625588350275208, Training Loss Force: 3.2222779299872837, time: 1.4853079319000244
Validation Loss Energy: 1.7608571405470876, Validation Loss Force: 3.081604706123276, time: 0.08366823196411133
Test Loss Energy: 8.092304367062033, Test Loss Force: 7.669963591748973, time: 17.015620708465576


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.006727054181124, Training Loss Force: 3.251228186955067, time: 1.28212571144104
Validation Loss Energy: 2.5661982234420195, Validation Loss Force: 3.0519543053206775, time: 0.09029221534729004
Test Loss Energy: 8.048016576790463, Test Loss Force: 7.615999658948178, time: 17.14772915840149

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–†â–‚â–…â–‚â–‚â–…â–†â–‚â–…â–‚â–‚â–†â–ˆâ–‚â–â–…â–‚â–‚
wandb:   test_error_force â–ˆâ–…â–†â–†â–…â–…â–ƒâ–„â–…â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–
wandb:          test_loss â–‡â–‡â–ˆâ–‡â–ˆâ–„â–†â–†â–†â–…â–„â–…â–ƒâ–„â–…â–â–‚â–…â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–â–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–ˆâ–â–ƒâ–â–â–â–â–‚â–ƒâ–ƒâ–‚â–„â–‚â–„â–…â–ƒâ–„â–ƒâ–â–…
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–„â–‚
wandb:         valid_loss â–ˆâ–‚â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–…â–…â–„â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1072
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.04802
wandb:   test_error_force 7.616
wandb:          test_loss 4.12032
wandb: train_error_energy 2.00673
wandb:  train_error_force 3.25123
wandb:         train_loss 1.48794
wandb: valid_error_energy 2.5662
wandb:  valid_error_force 3.05195
wandb:         valid_loss 1.56449
wandb: 
wandb: ğŸš€ View run al_56_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9c1t77xh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_171051-9c1t77xh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.8103487491607666, Uncertainty Bias: 0.0072876811027526855
0.00018310547 0.042812347
0.38279995 5.0973096
Found uncertainty sample 2 after 2316 steps.
Found uncertainty sample 14 after 3240 steps.
Found uncertainty sample 17 after 3476 steps.
Found uncertainty sample 18 after 1201 steps.
Found uncertainty sample 35 after 2388 steps.
Found uncertainty sample 38 after 3945 steps.
Found uncertainty sample 39 after 3709 steps.
Found uncertainty sample 44 after 2517 steps.
Found uncertainty sample 46 after 1023 steps.
Found uncertainty sample 47 after 1356 steps.
Found uncertainty sample 48 after 213 steps.
Found uncertainty sample 56 after 1939 steps.
Found uncertainty sample 61 after 2781 steps.
Found uncertainty sample 67 after 1486 steps.
Found uncertainty sample 71 after 1637 steps.
Found uncertainty sample 87 after 2054 steps.
Found uncertainty sample 89 after 764 steps.
Found uncertainty sample 90 after 3902 steps.
Found uncertainty sample 96 after 513 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_201145-l7tl0wzh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/l7tl0wzh
Training model 9. Added 19 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.054050184424762, Training Loss Force: 3.822148043275151, time: 1.327430248260498
Validation Loss Energy: 1.998409046850397, Validation Loss Force: 3.1668938917571423, time: 0.08503127098083496
Test Loss Energy: 8.109703885679746, Test Loss Force: 7.610202140142169, time: 17.085071325302124


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.098520255078751, Training Loss Force: 3.366316353402167, time: 1.2938950061798096
Validation Loss Energy: 2.0845303470825955, Validation Loss Force: 3.0902344715428534, time: 0.08287453651428223
Test Loss Energy: 8.482335543859524, Test Loss Force: 7.627572623169575, time: 17.61159896850586


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.465490497295676, Training Loss Force: 3.2813588811759775, time: 1.286827564239502
Validation Loss Energy: 1.8274007014618774, Validation Loss Force: 3.0630648276950363, time: 0.08186197280883789
Test Loss Energy: 8.111124032186648, Test Loss Force: 7.587300140502607, time: 17.15212368965149


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8065155284442755, Training Loss Force: 3.315172749669133, time: 1.2919988632202148
Validation Loss Energy: 1.9294103359326074, Validation Loss Force: 3.0810077301430434, time: 0.08091282844543457
Test Loss Energy: 8.054724094266176, Test Loss Force: 7.635362098186001, time: 17.17017698287964


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.117773155103117, Training Loss Force: 3.3284791715408755, time: 1.3041763305664062
Validation Loss Energy: 1.781864193112207, Validation Loss Force: 3.0790034851605474, time: 0.08532047271728516
Test Loss Energy: 8.055820589420762, Test Loss Force: 7.590608411781114, time: 17.12821078300476


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.149100238669613, Training Loss Force: 3.3175041465228015, time: 1.2873823642730713
Validation Loss Energy: 4.496001793086336, Validation Loss Force: 3.145300551330795, time: 0.0862123966217041
Test Loss Energy: 9.672115043598206, Test Loss Force: 7.60831059022946, time: 17.08132839202881


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2738857712288594, Training Loss Force: 3.323869054991489, time: 1.284363031387329
Validation Loss Energy: 1.786850200627822, Validation Loss Force: 3.080257557790413, time: 0.0848703384399414
Test Loss Energy: 8.158309976807367, Test Loss Force: 7.567393162119705, time: 17.193978309631348


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.093797251634355, Training Loss Force: 3.3571526210086793, time: 1.3011274337768555
Validation Loss Energy: 2.7484874331015328, Validation Loss Force: 3.0791266211982458, time: 0.08441400527954102
Test Loss Energy: 8.821621916864707, Test Loss Force: 7.5931301806619915, time: 17.03087306022644


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.063117829907681, Training Loss Force: 3.2846381169641043, time: 1.5193583965301514
Validation Loss Energy: 3.2465974218654106, Validation Loss Force: 3.105529615176633, time: 0.08314681053161621
Test Loss Energy: 8.118270594927779, Test Loss Force: 7.670914281747836, time: 17.076241970062256


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.180119520313717, Training Loss Force: 3.2637610268364994, time: 1.3040697574615479
Validation Loss Energy: 1.8623420551754388, Validation Loss Force: 3.084409669354528, time: 0.08070921897888184
Test Loss Energy: 8.23934655364646, Test Loss Force: 7.538115265813717, time: 17.538580179214478


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3423877613588764, Training Loss Force: 3.2778133330893198, time: 1.313605785369873
Validation Loss Energy: 2.5316199317708934, Validation Loss Force: 3.1681568711528447, time: 0.08740687370300293
Test Loss Energy: 7.888922426180113, Test Loss Force: 7.622578056298624, time: 17.072970390319824


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0232337555604727, Training Loss Force: 3.338105928518381, time: 1.3033123016357422
Validation Loss Energy: 2.012371292976653, Validation Loss Force: 3.0741016465820934, time: 0.08500933647155762
Test Loss Energy: 7.972097948845305, Test Loss Force: 7.569563757275509, time: 17.17793345451355


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.021395058725998, Training Loss Force: 3.2731181473832254, time: 1.28859281539917
Validation Loss Energy: 1.928631216591006, Validation Loss Force: 3.071491296184382, time: 0.09573936462402344
Test Loss Energy: 7.877547080242823, Test Loss Force: 7.551414839235236, time: 17.198291063308716


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0302620558536475, Training Loss Force: 3.241285948402156, time: 1.303229570388794
Validation Loss Energy: 3.1296317688701487, Validation Loss Force: 3.084849440917736, time: 0.08548331260681152
Test Loss Energy: 8.923518736187523, Test Loss Force: 7.6394744499007885, time: 17.13896870613098


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4088082880275774, Training Loss Force: 3.3031538389709976, time: 1.3249220848083496
Validation Loss Energy: 1.9448640199982878, Validation Loss Force: 3.075094973642077, time: 0.08224868774414062
Test Loss Energy: 8.189260360887138, Test Loss Force: 7.502227961689841, time: 17.231746435165405


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1415718234746848, Training Loss Force: 3.297756574266806, time: 1.3262484073638916
Validation Loss Energy: 2.060847702060008, Validation Loss Force: 3.063649111533951, time: 0.08179974555969238
Test Loss Energy: 7.932717075407683, Test Loss Force: 7.586452132456806, time: 17.169841289520264


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3102395948597354, Training Loss Force: 3.270205695393258, time: 1.3341524600982666
Validation Loss Energy: 2.286167056162628, Validation Loss Force: 3.061485435442971, time: 0.08347082138061523
Test Loss Energy: 7.921660139354229, Test Loss Force: 7.53547789317447, time: 17.244155406951904


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8091653352207073, Training Loss Force: 3.361100061455833, time: 1.3128235340118408
Validation Loss Energy: 3.6742252778613276, Validation Loss Force: 3.0913413598672603, time: 0.08541750907897949
Test Loss Energy: 8.071914292228646, Test Loss Force: 7.510521797477286, time: 17.20357656478882


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9205665403360266, Training Loss Force: 3.311897114759194, time: 1.278775930404663
Validation Loss Energy: 1.8064323933281494, Validation Loss Force: 3.1388366886936576, time: 0.08804178237915039
Test Loss Energy: 8.069014179323661, Test Loss Force: 7.6240013598110075, time: 17.070399284362793


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.27225098843625, Training Loss Force: 3.4085656607702615, time: 1.3344063758850098
Validation Loss Energy: 2.2944332028669057, Validation Loss Force: 3.098246330082481, time: 0.08436918258666992
Test Loss Energy: 8.401933140406102, Test Loss Force: 7.547037576521991, time: 17.252208948135376

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–‚â–‚â–ˆâ–‚â–…â–‚â–‚â–â–â–â–…â–‚â–â–â–‚â–‚â–ƒ
wandb:   test_error_force â–…â–†â–…â–‡â–…â–…â–„â–…â–ˆâ–‚â–†â–„â–ƒâ–‡â–â–„â–‚â–â–†â–ƒ
wandb:          test_loss â–ˆâ–‡â–ƒâ–†â–„â–‡â–ƒâ–†â–„â–…â–…â–…â–ƒâ–‡â–â–‚â–‚â–ƒâ–‚â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–„â–„â–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–ƒ
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–‚â–‚â–â–â–â–ˆâ–â–ƒâ–…â–â–ƒâ–‚â–â–„â–â–‚â–‚â–†â–â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–â–‚â–‚â–‡â–‚â–‚â–„â–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–â–â–ƒâ–†â–ƒ
wandb:         valid_loss â–…â–‚â–â–‚â–â–†â–â–„â–„â–‚â–„â–ƒâ–â–„â–‚â–„â–ˆâ–†â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1089
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.40193
wandb:   test_error_force 7.54704
wandb:          test_loss 4.08633
wandb: train_error_energy 2.27225
wandb:  train_error_force 3.40857
wandb:         train_loss 1.586
wandb: valid_error_energy 2.29443
wandb:  valid_error_force 3.09825
wandb:         valid_loss 1.54201
wandb: 
wandb: ğŸš€ View run al_56_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/l7tl0wzh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_201145-l7tl0wzh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7986037731170654, Uncertainty Bias: 0.014115437865257263
6.866455e-05 0.024233282
0.5152673 6.111126
Found uncertainty sample 1 after 2298 steps.
Found uncertainty sample 2 after 2136 steps.
Found uncertainty sample 3 after 1751 steps.
Found uncertainty sample 6 after 2317 steps.
Found uncertainty sample 7 after 3406 steps.
Found uncertainty sample 14 after 1991 steps.
Found uncertainty sample 22 after 819 steps.
Found uncertainty sample 23 after 3654 steps.
Found uncertainty sample 24 after 2945 steps.
Found uncertainty sample 28 after 3441 steps.
Found uncertainty sample 30 after 552 steps.
Found uncertainty sample 31 after 1641 steps.
Found uncertainty sample 39 after 2262 steps.
Found uncertainty sample 40 after 1450 steps.
Found uncertainty sample 45 after 384 steps.
Found uncertainty sample 55 after 1569 steps.
Found uncertainty sample 56 after 537 steps.
Found uncertainty sample 61 after 1284 steps.
Found uncertainty sample 62 after 1433 steps.
Found uncertainty sample 64 after 1041 steps.
Found uncertainty sample 65 after 3513 steps.
Found uncertainty sample 66 after 1820 steps.
Found uncertainty sample 68 after 930 steps.
Found uncertainty sample 71 after 2976 steps.
Found uncertainty sample 72 after 2541 steps.
Found uncertainty sample 73 after 3439 steps.
Found uncertainty sample 74 after 1627 steps.
Found uncertainty sample 76 after 683 steps.
Found uncertainty sample 79 after 269 steps.
Found uncertainty sample 90 after 301 steps.
Found uncertainty sample 92 after 1250 steps.
Found uncertainty sample 94 after 1790 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241124_225612-tpbyof0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/tpbyof0k
Training model 10. Added 32 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.750623154077798, Training Loss Force: 3.7350093168194025, time: 1.3199436664581299
Validation Loss Energy: 3.528362959122433, Validation Loss Force: 3.245287459279917, time: 0.08844614028930664
Test Loss Energy: 7.976929731746709, Test Loss Force: 7.657346656643674, time: 17.2529776096344


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.366007928600105, Training Loss Force: 3.4349427742319163, time: 1.2754554748535156
Validation Loss Energy: 1.8984802555483622, Validation Loss Force: 3.106817533516679, time: 0.08505010604858398
Test Loss Energy: 8.032519918745423, Test Loss Force: 7.52562300910884, time: 17.085260152816772


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.950445489343943, Training Loss Force: 3.3828364763514025, time: 1.3105101585388184
Validation Loss Energy: 2.008176651605665, Validation Loss Force: 3.108144418957263, time: 0.08362579345703125
Test Loss Energy: 8.249379768884415, Test Loss Force: 7.483559154328688, time: 17.01110553741455


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.004222254338195, Training Loss Force: 3.3682436820996835, time: 1.324753999710083
Validation Loss Energy: 1.8583694149429413, Validation Loss Force: 3.096907643177163, time: 0.08613467216491699
Test Loss Energy: 7.882473591961615, Test Loss Force: 7.473882449880469, time: 17.161046743392944


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.262335111477696, Training Loss Force: 3.358593576671734, time: 1.3234333992004395
Validation Loss Energy: 1.8304739810139727, Validation Loss Force: 3.0930527949228614, time: 0.08437585830688477
Test Loss Energy: 8.008194687873516, Test Loss Force: 7.474404983251731, time: 17.131566286087036


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2772954052498293, Training Loss Force: 3.370799109562058, time: 1.327498197555542
Validation Loss Energy: 3.1519536827419716, Validation Loss Force: 3.099230305038336, time: 0.08580422401428223
Test Loss Energy: 8.908184768847471, Test Loss Force: 7.467457071699751, time: 16.93597149848938


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.118520248259559, Training Loss Force: 3.370457967706545, time: 1.2941105365753174
Validation Loss Energy: 1.830103348220576, Validation Loss Force: 3.0849547634237595, time: 0.08620810508728027
Test Loss Energy: 8.025017470087134, Test Loss Force: 7.40415029594117, time: 17.152490377426147


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3523643633745124, Training Loss Force: 3.3611715509756275, time: 1.3312740325927734
Validation Loss Energy: 1.8148369289066208, Validation Loss Force: 3.07979730066578, time: 0.08612799644470215
Test Loss Energy: 7.923597486830962, Test Loss Force: 7.44111260939576, time: 17.00690770149231


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1627580038247403, Training Loss Force: 3.3544310123817107, time: 1.2962756156921387
Validation Loss Energy: 1.8013052135740162, Validation Loss Force: 3.0843488806776898, time: 0.1023092269897461
Test Loss Energy: 7.870525921034096, Test Loss Force: 7.3987254017098945, time: 17.50571608543396


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0599859215694623, Training Loss Force: 3.3395972137703915, time: 1.2922823429107666
Validation Loss Energy: 1.8290048099891412, Validation Loss Force: 3.078564381604778, time: 0.08350205421447754
Test Loss Energy: 7.9328943223794575, Test Loss Force: 7.39937170881531, time: 17.125088930130005


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3119603279426735, Training Loss Force: 3.359843119574973, time: 1.3192660808563232
Validation Loss Energy: 2.112715362235843, Validation Loss Force: 3.0957782652690176, time: 0.0838770866394043
Test Loss Energy: 8.270032231909811, Test Loss Force: 7.413021709845395, time: 16.97618842124939


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.141410426515741, Training Loss Force: 3.365316467145341, time: 1.3320252895355225
Validation Loss Energy: 2.111105686979931, Validation Loss Force: 3.0760711551778246, time: 0.08893179893493652
Test Loss Energy: 8.263072193632931, Test Loss Force: 7.3737859607321825, time: 17.079070806503296


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.056353911053442, Training Loss Force: 3.344621533103057, time: 1.3292529582977295
Validation Loss Energy: 1.8507951012750616, Validation Loss Force: 3.078530090556305, time: 0.08614897727966309
Test Loss Energy: 8.020611174115198, Test Loss Force: 7.436518632478982, time: 17.075897216796875


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1017723061451483, Training Loss Force: 3.3489532941341067, time: 1.5482115745544434
Validation Loss Energy: 2.237855199578114, Validation Loss Force: 3.072865387483902, time: 0.08450484275817871
Test Loss Energy: 7.7959268024683395, Test Loss Force: 7.397812218055341, time: 17.028138875961304


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2039208161812063, Training Loss Force: 3.347134634341778, time: 1.2974562644958496
Validation Loss Energy: 1.776733673320885, Validation Loss Force: 3.0884263980779196, time: 0.08591914176940918
Test Loss Energy: 7.926829297488501, Test Loss Force: 7.408799152058867, time: 17.14457893371582


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9752319530377114, Training Loss Force: 3.343717369131078, time: 1.3380115032196045
Validation Loss Energy: 1.9173721738963134, Validation Loss Force: 3.0848941974160673, time: 0.08706474304199219
Test Loss Energy: 7.852099496616032, Test Loss Force: 7.352610805785764, time: 17.056072235107422


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0142899980162468, Training Loss Force: 3.3646825344488605, time: 1.311286449432373
Validation Loss Energy: 1.8325065049780016, Validation Loss Force: 3.1461155204048907, time: 0.08410906791687012
Test Loss Energy: 7.873518137359004, Test Loss Force: 7.404984517152835, time: 17.40979552268982


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1969603918056864, Training Loss Force: 3.3573492633124355, time: 1.3054678440093994
Validation Loss Energy: 2.2749015560627037, Validation Loss Force: 3.0784116305706712, time: 0.08860158920288086
Test Loss Energy: 7.721348034230388, Test Loss Force: 7.346321593868106, time: 17.16367793083191


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.129942319759936, Training Loss Force: 3.3144345251066745, time: 1.3312959671020508
Validation Loss Energy: 2.007884064347916, Validation Loss Force: 3.1034964232051663, time: 0.08663249015808105
Test Loss Energy: 7.828319054371907, Test Loss Force: 7.416074830262039, time: 17.021130561828613


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.923889270364267, Training Loss Force: 3.318288406340686, time: 1.2887139320373535
Validation Loss Energy: 3.2173119757929878, Validation Loss Force: 3.105258404156893, time: 0.08458256721496582
Test Loss Energy: 8.783443689976504, Test Loss Force: 7.337549837813464, time: 17.13568902015686

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–‚â–ƒâ–ˆâ–ƒâ–‚â–‚â–‚â–„â–„â–ƒâ–â–‚â–‚â–‚â–â–‚â–‡
wandb:   test_error_force â–ˆâ–…â–„â–„â–„â–„â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–‚â–â–ƒâ–
wandb:          test_loss â–ˆâ–†â–…â–„â–†â–†â–ƒâ–ƒâ–ƒâ–ƒâ–…â–†â–„â–…â–ƒâ–„â–…â–â–‚â–„
wandb: train_error_energy â–ˆâ–ƒâ–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–
wandb: valid_error_energy â–ˆâ–â–‚â–â–â–†â–â–â–â–â–‚â–‚â–â–ƒâ–â–‚â–â–ƒâ–‚â–‡
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–‚â–â–„â–â–‚â–‚
wandb:         valid_loss â–ˆâ–‚â–„â–ƒâ–‚â–†â–ƒâ–ƒâ–â–â–‚â–„â–‚â–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1117
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.78344
wandb:   test_error_force 7.33755
wandb:          test_loss 3.95664
wandb: train_error_energy 1.92389
wandb:  train_error_force 3.31829
wandb:         train_loss 1.50685
wandb: valid_error_energy 3.21731
wandb:  valid_error_force 3.10526
wandb:         valid_loss 1.59432
wandb: 
wandb: ğŸš€ View run al_56_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/tpbyof0k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241124_225612-tpbyof0k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7698941230773926, Uncertainty Bias: 0.020346537232398987
0.00013160706 0.05764389
0.32627147 6.2723646
Found uncertainty sample 11 after 1647 steps.
Found uncertainty sample 21 after 533 steps.
Found uncertainty sample 23 after 2839 steps.
Found uncertainty sample 24 after 900 steps.
Found uncertainty sample 25 after 3456 steps.
Found uncertainty sample 33 after 3996 steps.
Found uncertainty sample 39 after 1099 steps.
Found uncertainty sample 40 after 3124 steps.
Found uncertainty sample 41 after 3193 steps.
Found uncertainty sample 44 after 2947 steps.
Found uncertainty sample 45 after 2241 steps.
Found uncertainty sample 47 after 2883 steps.
Found uncertainty sample 48 after 1298 steps.
Found uncertainty sample 59 after 3460 steps.
Found uncertainty sample 66 after 1528 steps.
Found uncertainty sample 67 after 946 steps.
Found uncertainty sample 72 after 3032 steps.
Found uncertainty sample 73 after 1634 steps.
Found uncertainty sample 74 after 1506 steps.
Found uncertainty sample 76 after 3882 steps.
Found uncertainty sample 89 after 1887 steps.
Found uncertainty sample 99 after 922 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_015534-j8bq4kty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/j8bq4kty
Training model 11. Added 22 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.378782472886745, Training Loss Force: 3.7373939105690845, time: 1.3137762546539307
Validation Loss Energy: 3.067882942674622, Validation Loss Force: 3.231427863629934, time: 0.08784317970275879
Test Loss Energy: 7.765880828179288, Test Loss Force: 7.382119443285672, time: 17.149625301361084


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.316398747141179, Training Loss Force: 3.44495115272517, time: 1.3627700805664062
Validation Loss Energy: 2.0113240799833547, Validation Loss Force: 3.1435946830038426, time: 0.08641815185546875
Test Loss Energy: 8.197532680539728, Test Loss Force: 7.3487417113693505, time: 17.230213403701782


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.046036579296935, Training Loss Force: 3.4207845239434, time: 1.3320116996765137
Validation Loss Energy: 2.07395222663615, Validation Loss Force: 3.1564878945604993, time: 0.0848078727722168
Test Loss Energy: 7.724640790948719, Test Loss Force: 7.311763843717143, time: 17.160555601119995


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.142618572927372, Training Loss Force: 3.42801858060054, time: 1.3394641876220703
Validation Loss Energy: 2.584378045861294, Validation Loss Force: 3.178153157120981, time: 0.0840446949005127
Test Loss Energy: 8.448012519630968, Test Loss Force: 7.355929578654149, time: 17.280847311019897


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9549084504376633, Training Loss Force: 3.4266141382593793, time: 1.3433544635772705
Validation Loss Energy: 1.7911645266647458, Validation Loss Force: 3.123456930784425, time: 0.0851593017578125
Test Loss Energy: 7.849753118742108, Test Loss Force: 7.281100255165712, time: 17.248298406600952


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2295631057330816, Training Loss Force: 3.4011417281238563, time: 1.3108434677124023
Validation Loss Energy: 2.996625253271395, Validation Loss Force: 3.1571970957902793, time: 0.09201431274414062
Test Loss Energy: 7.792724605641399, Test Loss Force: 7.341918149460204, time: 17.140688180923462


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.148991410273231, Training Loss Force: 3.407795249206038, time: 1.3445067405700684
Validation Loss Energy: 1.8434693977086103, Validation Loss Force: 3.1208414589963573, time: 0.08785176277160645
Test Loss Energy: 7.772429809886329, Test Loss Force: 7.280645567101342, time: 17.590758323669434


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9249144108366711, Training Loss Force: 3.4050436399762516, time: 1.3066723346710205
Validation Loss Energy: 2.1271432095462344, Validation Loss Force: 3.142600242598129, time: 0.08672904968261719
Test Loss Energy: 8.230197181031308, Test Loss Force: 7.300550810763357, time: 17.24679160118103


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3198825358195547, Training Loss Force: 3.424237652317432, time: 1.4384799003601074
Validation Loss Energy: 1.855798476984059, Validation Loss Force: 3.1446614908819823, time: 0.08479928970336914
Test Loss Energy: 7.849564512146471, Test Loss Force: 7.29273677452407, time: 17.18924331665039


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.315500784328193, Training Loss Force: 3.383054152583537, time: 1.3604209423065186
Validation Loss Energy: 2.691034117400099, Validation Loss Force: 3.14514935898071, time: 0.08954286575317383
Test Loss Energy: 7.67442644801559, Test Loss Force: 7.3015601828257255, time: 17.29901432991028


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1805992305925126, Training Loss Force: 3.406601031279649, time: 1.3486270904541016
Validation Loss Energy: 2.0182593332024217, Validation Loss Force: 3.1323082520042007, time: 0.08448338508605957
Test Loss Energy: 8.089791381371443, Test Loss Force: 7.2659359150825775, time: 17.157282829284668


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.002396519322115, Training Loss Force: 3.375184406441043, time: 1.3601107597351074
Validation Loss Energy: 1.8646034830214815, Validation Loss Force: 3.1130945767403837, time: 0.08745694160461426
Test Loss Energy: 7.840346802253852, Test Loss Force: 7.269881582037434, time: 17.258939027786255


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.414298413276288, Training Loss Force: 3.3975639359543752, time: 1.353132724761963
Validation Loss Energy: 2.1775521641470963, Validation Loss Force: 3.1302465583820553, time: 0.09561538696289062
Test Loss Energy: 7.600780801064309, Test Loss Force: 7.252857320386769, time: 17.343268871307373


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.047388712944565, Training Loss Force: 3.3781811929562586, time: 1.3514211177825928
Validation Loss Energy: 2.047654332494641, Validation Loss Force: 3.12862285496995, time: 0.08742547035217285
Test Loss Energy: 7.981124111976915, Test Loss Force: 7.257985379159415, time: 17.216285467147827


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1644558690514724, Training Loss Force: 3.392873292875579, time: 1.3341407775878906
Validation Loss Energy: 2.3493541023717026, Validation Loss Force: 3.1129487284498008, time: 0.08810091018676758
Test Loss Energy: 7.52530260802657, Test Loss Force: 7.245313336355017, time: 17.304836988449097


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4277122036477348, Training Loss Force: 3.401880810315969, time: 1.3536922931671143
Validation Loss Energy: 2.0383095764474892, Validation Loss Force: 3.1503170645194025, time: 0.08700394630432129
Test Loss Energy: 7.63441852893658, Test Loss Force: 7.250536053996631, time: 17.214805603027344


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3868923752037983, Training Loss Force: 3.401161001375488, time: 1.3360075950622559
Validation Loss Energy: 1.9192156517554495, Validation Loss Force: 3.1233805552673717, time: 0.08436012268066406
Test Loss Energy: 7.939764458280122, Test Loss Force: 7.218788446757628, time: 17.299081087112427


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.129199042640164, Training Loss Force: 3.3700036994983305, time: 1.3282647132873535
Validation Loss Energy: 1.8168843717034269, Validation Loss Force: 3.1331561761118936, time: 0.08897900581359863
Test Loss Energy: 7.8538927689947, Test Loss Force: 7.195562084623452, time: 17.33537769317627


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0644247117948513, Training Loss Force: 3.3770851535674615, time: 1.3610992431640625
Validation Loss Energy: 2.173946705336234, Validation Loss Force: 3.119050976393952, time: 0.0897982120513916
Test Loss Energy: 7.591444342065909, Test Loss Force: 7.20361264445961, time: 17.175363540649414


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.265530531241587, Training Loss Force: 3.377763007929698, time: 1.334798812866211
Validation Loss Energy: 1.817716486301759, Validation Loss Force: 3.1175666638671973, time: 0.08804011344909668
Test Loss Energy: 7.615291848526204, Test Loss Force: 7.21372889080705, time: 17.59308648109436

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–†â–ƒâ–‚â–…â–ƒâ–‚â–„â–â–‚â–„â–ƒâ–‚â–‚
wandb:   test_error_force â–ˆâ–‡â–…â–‡â–„â–†â–„â–…â–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–‚
wandb:          test_loss â–„â–‡â–†â–ˆâ–„â–†â–…â–†â–ˆâ–„â–‡â–…â–‚â–…â–â–‚â–‚â–†â–‚â–ƒ
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–ƒâ–…â–â–ˆâ–â–ƒâ–â–†â–‚â–â–ƒâ–‚â–„â–‚â–‚â–â–ƒâ–
wandb:  valid_error_force â–ˆâ–ƒâ–„â–…â–‚â–„â–â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–â–
wandb:         valid_loss â–ˆâ–ƒâ–ƒâ–…â–â–…â–‚â–ƒâ–†â–„â–…â–ƒâ–ƒâ–…â–„â–‚â–ƒâ–…â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1136
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.61529
wandb:   test_error_force 7.21373
wandb:          test_loss 3.87185
wandb: train_error_energy 2.26553
wandb:  train_error_force 3.37776
wandb:         train_loss 1.53912
wandb: valid_error_energy 1.81772
wandb:  valid_error_force 3.11757
wandb:         valid_loss 1.53622
wandb: 
wandb: ğŸš€ View run al_56_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/j8bq4kty
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_015534-j8bq4kty/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7919070720672607, Uncertainty Bias: 0.013358280062675476
2.2888184e-05 0.0027618408
0.23476402 6.4847803
Found uncertainty sample 0 after 1948 steps.
Found uncertainty sample 1 after 2247 steps.
Found uncertainty sample 6 after 820 steps.
Found uncertainty sample 15 after 1936 steps.
Found uncertainty sample 24 after 342 steps.
Found uncertainty sample 29 after 483 steps.
Found uncertainty sample 30 after 2026 steps.
Found uncertainty sample 33 after 2581 steps.
Found uncertainty sample 34 after 1749 steps.
Found uncertainty sample 35 after 2669 steps.
Found uncertainty sample 36 after 3569 steps.
Found uncertainty sample 43 after 2115 steps.
Found uncertainty sample 44 after 2775 steps.
Found uncertainty sample 49 after 3250 steps.
Found uncertainty sample 55 after 1217 steps.
Found uncertainty sample 67 after 2541 steps.
Found uncertainty sample 69 after 2057 steps.
Found uncertainty sample 86 after 2362 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_045613-amgs0mcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/amgs0mcb
Training model 12. Added 18 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.497258182093844, Training Loss Force: 3.7103111324291955, time: 1.3180320262908936
Validation Loss Energy: 1.8929783236216324, Validation Loss Force: 3.17853815207429, time: 0.08998918533325195
Test Loss Energy: 7.724544089585805, Test Loss Force: 7.199449398272392, time: 16.93685007095337


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3016167878509686, Training Loss Force: 3.438301274757626, time: 1.3421683311462402
Validation Loss Energy: 1.8692769743907869, Validation Loss Force: 3.141151111796431, time: 0.08685994148254395
Test Loss Energy: 7.8586915035979406, Test Loss Force: 7.186370320932465, time: 17.439253091812134


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1289221442793216, Training Loss Force: 3.4409146188182995, time: 1.401496171951294
Validation Loss Energy: 1.9381754841929089, Validation Loss Force: 3.154114018795763, time: 0.08743715286254883
Test Loss Energy: 7.897921785076103, Test Loss Force: 7.191785268498017, time: 17.03850769996643


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8903026136443368, Training Loss Force: 3.4234060325394244, time: 1.3546323776245117
Validation Loss Energy: 2.035682525863833, Validation Loss Force: 3.1539461262597333, time: 0.08479666709899902
Test Loss Energy: 7.631257597015869, Test Loss Force: 7.194031869610039, time: 17.138842344284058


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1163775614747657, Training Loss Force: 3.4339763100837297, time: 1.3037171363830566
Validation Loss Energy: 2.630078438702367, Validation Loss Force: 3.146025784739082, time: 0.08909916877746582
Test Loss Energy: 8.273356528371982, Test Loss Force: 7.200564289862174, time: 17.177558660507202


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.34964438252969, Training Loss Force: 3.4247312727024304, time: 1.344045877456665
Validation Loss Energy: 2.0699441820094497, Validation Loss Force: 3.1505613325724853, time: 0.08821702003479004
Test Loss Energy: 7.939374563439794, Test Loss Force: 7.167933042850797, time: 17.076082468032837


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2762519145424207, Training Loss Force: 3.444919391445605, time: 1.340881586074829
Validation Loss Energy: 2.6855673671984257, Validation Loss Force: 3.136109214325188, time: 0.08917856216430664
Test Loss Energy: 8.297671700660693, Test Loss Force: 7.180497257829827, time: 17.128411769866943


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0746994238815812, Training Loss Force: 3.4234168443635102, time: 1.3669278621673584
Validation Loss Energy: 2.098877365493015, Validation Loss Force: 3.1383552780001613, time: 0.0858299732208252
Test Loss Energy: 7.561705583581432, Test Loss Force: 7.138833202586671, time: 17.07059335708618


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8711104599719997, Training Loss Force: 3.397450987030103, time: 1.560655117034912
Validation Loss Energy: 1.9231172605303963, Validation Loss Force: 3.14923778716909, time: 0.08571505546569824
Test Loss Energy: 7.564210781680948, Test Loss Force: 7.178189092779281, time: 17.014384269714355


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.205989522202594, Training Loss Force: 3.4276526671559866, time: 1.3735854625701904
Validation Loss Energy: 2.1171264380166726, Validation Loss Force: 3.1437142563352056, time: 0.08437323570251465
Test Loss Energy: 8.05649920570267, Test Loss Force: 7.153622232075634, time: 17.583091020584106


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2840217069794084, Training Loss Force: 3.420755719215273, time: 1.3478786945343018
Validation Loss Energy: 2.069342529977153, Validation Loss Force: 3.1242358274568804, time: 0.08925437927246094
Test Loss Energy: 7.403703535364716, Test Loss Force: 7.139197841383137, time: 17.068340301513672


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.056263494832965, Training Loss Force: 3.405913837183791, time: 1.362607717514038
Validation Loss Energy: 1.8568366718769473, Validation Loss Force: 3.168970504212065, time: 0.08919978141784668
Test Loss Energy: 7.694427038372729, Test Loss Force: 7.150017384147664, time: 17.15617275238037


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.241821320552839, Training Loss Force: 3.41115900684425, time: 1.3755226135253906
Validation Loss Energy: 2.2873071221897785, Validation Loss Force: 3.1411019019151807, time: 0.08754920959472656
Test Loss Energy: 7.441393788065748, Test Loss Force: 7.162064897122281, time: 17.187654495239258


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.443700460665501, Training Loss Force: 3.4014693548458186, time: 1.3804540634155273
Validation Loss Energy: 1.827993892066629, Validation Loss Force: 3.1228514933766474, time: 0.08858013153076172
Test Loss Energy: 7.6037860930810535, Test Loss Force: 7.094571663958178, time: 17.07971453666687


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.249056199848768, Training Loss Force: 3.406121234937461, time: 1.36655855178833
Validation Loss Energy: 2.4670078030278813, Validation Loss Force: 3.162797892817801, time: 0.08744263648986816
Test Loss Energy: 8.32297125010869, Test Loss Force: 7.1030161779748004, time: 17.202014923095703


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.216199644773869, Training Loss Force: 3.4132761698247474, time: 1.3510873317718506
Validation Loss Energy: 3.138515154446938, Validation Loss Force: 3.1613532153990214, time: 0.08432292938232422
Test Loss Energy: 8.63741041612647, Test Loss Force: 7.198386650900196, time: 17.06995987892151


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1302260360379615, Training Loss Force: 3.3951815616505696, time: 1.3693253993988037
Validation Loss Energy: 1.8855652224154045, Validation Loss Force: 3.1207396991966685, time: 0.08574748039245605
Test Loss Energy: 7.812439452028156, Test Loss Force: 7.092278836265138, time: 17.161563873291016


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9914000963292824, Training Loss Force: 3.404655385394056, time: 1.362548828125
Validation Loss Energy: 1.8402637413492609, Validation Loss Force: 3.137709760146117, time: 0.08883261680603027
Test Loss Energy: 7.56701571343541, Test Loss Force: 7.072933340866935, time: 17.17486596107483


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9261506266380843, Training Loss Force: 3.3792188373615364, time: 1.363771915435791
Validation Loss Energy: 2.10455453803759, Validation Loss Force: 3.1434811217394194, time: 0.08915996551513672
Test Loss Energy: 7.916951990290135, Test Loss Force: 7.101934383647074, time: 17.08701729774475


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1615137663673445, Training Loss Force: 3.389917415630675, time: 1.3559842109680176
Validation Loss Energy: 1.8178627799306335, Validation Loss Force: 3.1153517738726535, time: 0.08735156059265137
Test Loss Energy: 7.5275047709055825, Test Loss Force: 7.088580495275249, time: 17.1896231174469

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–„â–‚â–†â–„â–†â–‚â–‚â–…â–â–ƒâ–â–‚â–†â–ˆâ–ƒâ–‚â–„â–‚
wandb:   test_error_force â–ˆâ–‡â–ˆâ–ˆâ–ˆâ–†â–‡â–…â–‡â–…â–…â–…â–†â–‚â–ƒâ–ˆâ–‚â–â–ƒâ–‚
wandb:          test_loss â–‡â–„â–„â–„â–ˆâ–†â–†â–ƒâ–„â–…â–„â–‚â–‚â–„â–…â–†â–ƒâ–â–ƒâ–†
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–â–â–‚â–‚â–…â–‚â–†â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–„â–ˆâ–â–â–ƒâ–
wandb:  valid_error_force â–ˆâ–„â–…â–…â–„â–…â–ƒâ–„â–…â–„â–‚â–‡â–„â–‚â–†â–†â–‚â–ƒâ–„â–
wandb:         valid_loss â–…â–„â–‚â–â–ˆâ–†â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–†â–â–â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1152
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.5275
wandb:   test_error_force 7.08858
wandb:          test_loss 3.86974
wandb: train_error_energy 2.16151
wandb:  train_error_force 3.38992
wandb:         train_loss 1.53275
wandb: valid_error_energy 1.81786
wandb:  valid_error_force 3.11535
wandb:         valid_loss 1.58943
wandb: 
wandb: ğŸš€ View run al_56_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/amgs0mcb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_045613-amgs0mcb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.8082661628723145, Uncertainty Bias: 0.00945843756198883
0.00024032593 0.005396843
0.43545115 9.815563
Found uncertainty sample 5 after 1156 steps.
Found uncertainty sample 7 after 2765 steps.
Found uncertainty sample 17 after 2943 steps.
Found uncertainty sample 22 after 329 steps.
Found uncertainty sample 31 after 2752 steps.
Found uncertainty sample 34 after 1591 steps.
Found uncertainty sample 42 after 1796 steps.
Found uncertainty sample 46 after 3493 steps.
Found uncertainty sample 54 after 1254 steps.
Found uncertainty sample 56 after 2999 steps.
Found uncertainty sample 58 after 3300 steps.
Found uncertainty sample 62 after 2330 steps.
Found uncertainty sample 63 after 1608 steps.
Found uncertainty sample 75 after 2504 steps.
Found uncertainty sample 77 after 600 steps.
Found uncertainty sample 92 after 1406 steps.
Found uncertainty sample 98 after 1668 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_075735-w1w9a7t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/w1w9a7t6
Training model 13. Added 17 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.489111482926236, Training Loss Force: 3.626788968394772, time: 1.3650858402252197
Validation Loss Energy: 2.137300039968584, Validation Loss Force: 3.2067973160531316, time: 0.09220337867736816
Test Loss Energy: 7.363169907256049, Test Loss Force: 7.111243931155608, time: 17.50881576538086


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0167557026227363, Training Loss Force: 3.4265535222681476, time: 1.362173080444336
Validation Loss Energy: 2.0320303065323255, Validation Loss Force: 3.1522162096650206, time: 0.08779215812683105
Test Loss Energy: 7.870838660432456, Test Loss Force: 7.079123207371298, time: 17.389909505844116


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9958721968296183, Training Loss Force: 3.4482207407062617, time: 1.3569738864898682
Validation Loss Energy: 2.228449654854124, Validation Loss Force: 3.1554687378795876, time: 0.08660006523132324
Test Loss Energy: 7.382153295990694, Test Loss Force: 7.066441679560767, time: 17.274412393569946


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1715747583677483, Training Loss Force: 3.455001918912517, time: 1.565126895904541
Validation Loss Energy: 2.1640483937923056, Validation Loss Force: 3.1877820389983365, time: 0.11021780967712402
Test Loss Energy: 7.363725771050777, Test Loss Force: 7.117621114873012, time: 17.3142032623291


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9929783570141943, Training Loss Force: 3.4452301616785808, time: 1.3753783702850342
Validation Loss Energy: 1.849535795920267, Validation Loss Force: 3.1501409332249732, time: 0.08794784545898438
Test Loss Energy: 7.550693710633561, Test Loss Force: 7.048781675348142, time: 17.41435670852661


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.08427984730247, Training Loss Force: 3.455887257454811, time: 1.3695776462554932
Validation Loss Energy: 2.0376729653592816, Validation Loss Force: 3.1770322406403806, time: 0.08989500999450684
Test Loss Energy: 7.898603525720899, Test Loss Force: 7.072999714925332, time: 17.260639429092407


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.65405812135658, Training Loss Force: 3.4670071921141496, time: 1.3802740573883057
Validation Loss Energy: 2.9178881072564535, Validation Loss Force: 3.268017748365372, time: 0.08962512016296387
Test Loss Energy: 8.436340977097313, Test Loss Force: 7.124867612925804, time: 17.340667724609375


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1069952416274864, Training Loss Force: 3.4485655167973492, time: 1.3598966598510742
Validation Loss Energy: 1.9167393481835866, Validation Loss Force: 3.169192282681409, time: 0.09070849418640137
Test Loss Energy: 7.454433442474581, Test Loss Force: 7.0483574404954465, time: 17.38087821006775


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0408755284229283, Training Loss Force: 3.4376922453889334, time: 1.3745548725128174
Validation Loss Energy: 2.6813802965783995, Validation Loss Force: 3.1377879170163374, time: 0.08744621276855469
Test Loss Energy: 7.362216976576042, Test Loss Force: 7.03001840730522, time: 17.61182141304016


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2625273381405244, Training Loss Force: 3.4142705746234583, time: 1.3567497730255127
Validation Loss Energy: 1.8992600428974011, Validation Loss Force: 3.1553402577823872, time: 0.08689570426940918
Test Loss Energy: 7.79485562864281, Test Loss Force: 6.999804908875169, time: 17.400659322738647


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.033707271501424, Training Loss Force: 3.431514073284106, time: 1.3519721031188965
Validation Loss Energy: 2.0482542031737703, Validation Loss Force: 3.142810219602739, time: 0.08872342109680176
Test Loss Energy: 7.361720865055688, Test Loss Force: 7.04786046161465, time: 17.28511667251587


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.230260120507855, Training Loss Force: 3.421709036039982, time: 1.3586170673370361
Validation Loss Energy: 1.8397500436296055, Validation Loss Force: 3.15421043453595, time: 0.09198451042175293
Test Loss Energy: 7.517172927197763, Test Loss Force: 6.999176107528368, time: 17.427111387252808


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.058850504255076, Training Loss Force: 3.4342503039662877, time: 1.4171626567840576
Validation Loss Energy: 2.3565104660526757, Validation Loss Force: 3.1392056514684596, time: 0.09635806083679199
Test Loss Energy: 7.27908161596361, Test Loss Force: 6.983109229940626, time: 17.412776470184326


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.247547527116846, Training Loss Force: 3.417380179336765, time: 1.4023892879486084
Validation Loss Energy: 2.015750965273545, Validation Loss Force: 3.137168896790658, time: 0.08960771560668945
Test Loss Energy: 7.300309581969246, Test Loss Force: 6.982279117032994, time: 17.31630516052246


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4670303768648103, Training Loss Force: 3.4190649302033647, time: 1.3955588340759277
Validation Loss Energy: 1.9347568447954795, Validation Loss Force: 3.154102440000175, time: 0.08808755874633789
Test Loss Energy: 7.320314718973869, Test Loss Force: 7.053824033313169, time: 17.41466522216797


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0595641378044776, Training Loss Force: 3.422738489664371, time: 1.358360767364502
Validation Loss Energy: 1.8325896719040056, Validation Loss Force: 3.144654142800167, time: 0.0865943431854248
Test Loss Energy: 7.544931536765594, Test Loss Force: 6.987302276487575, time: 17.297983646392822


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.6755236707564616, Training Loss Force: 3.402539328905358, time: 1.6346487998962402
Validation Loss Energy: 2.294092073735344, Validation Loss Force: 3.1462858623015255, time: 0.08614444732666016
Test Loss Energy: 7.209318300001951, Test Loss Force: 6.995734796681298, time: 17.312400817871094


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.20797409548608, Training Loss Force: 3.38864255352609, time: 1.3702175617218018
Validation Loss Energy: 2.0735785878092834, Validation Loss Force: 3.1406590129839302, time: 0.08920907974243164
Test Loss Energy: 7.756537276410818, Test Loss Force: 7.013564400171467, time: 17.404428243637085


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9627900326906722, Training Loss Force: 3.38458169418521, time: 1.3671000003814697
Validation Loss Energy: 1.8275138173880088, Validation Loss Force: 3.1381900574938832, time: 0.09325742721557617
Test Loss Energy: 7.587632833854377, Test Loss Force: 6.980736647055905, time: 17.26727271080017


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.202474301484055, Training Loss Force: 3.394126810337102, time: 1.3801517486572266
Validation Loss Energy: 3.027014470300182, Validation Loss Force: 3.1736158279344107, time: 0.09233307838439941
Test Loss Energy: 8.39176046200276, Test Loss Force: 7.018823614568486, time: 17.381102800369263

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‚â–‚â–ƒâ–…â–ˆâ–‚â–‚â–„â–‚â–ƒâ–â–‚â–‚â–ƒâ–â–„â–ƒâ–ˆ
wandb:   test_error_force â–‡â–†â–…â–ˆâ–„â–…â–ˆâ–„â–ƒâ–‚â–„â–‚â–â–â–…â–â–‚â–ƒâ–â–ƒ
wandb:          test_loss â–†â–†â–„â–…â–…â–‡â–ˆâ–ƒâ–„â–„â–†â–„â–„â–â–ƒâ–„â–â–„â–…â–†
wandb: train_error_energy â–ˆâ–â–â–‚â–â–â–ƒâ–â–â–‚â–â–‚â–â–‚â–‚â–â–ƒâ–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–
wandb: valid_error_energy â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‡â–‚â–†â–â–‚â–â–„â–‚â–‚â–â–„â–‚â–â–ˆ
wandb:  valid_error_force â–…â–‚â–‚â–„â–‚â–ƒâ–ˆâ–ƒâ–â–‚â–â–‚â–â–â–‚â–â–â–â–â–ƒ
wandb:         valid_loss â–‡â–‚â–„â–‚â–â–ƒâ–ˆâ–ƒâ–„â–‚â–„â–‚â–ƒâ–†â–‚â–ƒâ–ˆâ–â–‚â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1167
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.39176
wandb:   test_error_force 7.01882
wandb:          test_loss 3.79819
wandb: train_error_energy 2.20247
wandb:  train_error_force 3.39413
wandb:         train_loss 1.53827
wandb: valid_error_energy 3.02701
wandb:  valid_error_force 3.17362
wandb:         valid_loss 1.62467
wandb: 
wandb: ğŸš€ View run al_56_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/w1w9a7t6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_075735-w1w9a7t6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.8237390518188477, Uncertainty Bias: 0.008609950542449951
1.9073486e-05 0.016131401
0.48928627 7.8100142
Found uncertainty sample 0 after 2983 steps.
Found uncertainty sample 1 after 1633 steps.
Found uncertainty sample 2 after 1602 steps.
Found uncertainty sample 4 after 2110 steps.
Found uncertainty sample 5 after 1548 steps.
Found uncertainty sample 8 after 67 steps.
Found uncertainty sample 9 after 2525 steps.
Found uncertainty sample 13 after 3252 steps.
Found uncertainty sample 18 after 2297 steps.
Found uncertainty sample 21 after 555 steps.
Found uncertainty sample 22 after 1553 steps.
Found uncertainty sample 24 after 2641 steps.
Found uncertainty sample 27 after 3103 steps.
Found uncertainty sample 28 after 3283 steps.
Found uncertainty sample 35 after 3338 steps.
Found uncertainty sample 42 after 753 steps.
Found uncertainty sample 60 after 3226 steps.
Found uncertainty sample 65 after 3622 steps.
Found uncertainty sample 68 after 1736 steps.
Found uncertainty sample 72 after 3797 steps.
Found uncertainty sample 77 after 3270 steps.
Found uncertainty sample 81 after 1754 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241125_105740-6w3uupxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_56_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6w3uupxi
Training model 14. Added 22 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.24393492016929, Training Loss Force: 3.754825361846816, time: 1.4190163612365723
Validation Loss Energy: 2.311780020011264, Validation Loss Force: 3.2399703427443076, time: 0.09062051773071289
Test Loss Energy: 7.3253115241943485, Test Loss Force: 6.964839331439887, time: 17.108731985092163


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.308225669629106, Training Loss Force: 3.4979114533299307, time: 1.4242498874664307
Validation Loss Energy: 3.041194709520301, Validation Loss Force: 3.1883554120491002, time: 0.08851885795593262
Test Loss Energy: 8.49268108346853, Test Loss Force: 6.942113921256921, time: 17.269298791885376


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4517611045826264, Training Loss Force: 3.495876491724725, time: 1.344313383102417
Validation Loss Energy: 4.05734535696176, Validation Loss Force: 3.1878125446713286, time: 0.08899092674255371
Test Loss Energy: 9.143261946584241, Test Loss Force: 6.948418195401624, time: 17.22746753692627


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7976939596650987, Training Loss Force: 3.518965881685703, time: 1.4467096328735352
Validation Loss Energy: 1.99819617514689, Validation Loss Force: 3.2619228485030365, time: 0.09520983695983887
Test Loss Energy: 7.372724118026253, Test Loss Force: 7.019459790810666, time: 17.357304573059082


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9701210237783, Training Loss Force: 3.473704229098109, time: 1.3490321636199951
Validation Loss Energy: 1.930679104726104, Validation Loss Force: 3.2039743166210592, time: 0.09300827980041504
Test Loss Energy: 7.45452245650583, Test Loss Force: 6.95975387358834, time: 17.318559646606445


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0844058515911645, Training Loss Force: 3.528045930996061, time: 1.3889548778533936
Validation Loss Energy: 4.233451267108006, Validation Loss Force: 3.1940383739914693, time: 0.09042525291442871
Test Loss Energy: 7.416051262306781, Test Loss Force: 6.976274177837226, time: 17.1655216217041


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9343101911572025, Training Loss Force: 3.5005193074893213, time: 1.4167895317077637
Validation Loss Energy: 2.1365569930286235, Validation Loss Force: 3.1723363710219092, time: 0.09165406227111816
Test Loss Energy: 7.312642505493431, Test Loss Force: 6.957326217978732, time: 17.329306840896606


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2403889224910545, Training Loss Force: 3.4421838410885797, time: 1.4498119354248047
Validation Loss Energy: 1.864043470119473, Validation Loss Force: 3.1697796838883665, time: 0.08953595161437988
Test Loss Energy: 7.4785320334617635, Test Loss Force: 6.93689811918271, time: 17.377527713775635


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3446975192082022, Training Loss Force: 3.43376972487712, time: 1.4194269180297852
Validation Loss Energy: 2.559160542415826, Validation Loss Force: 3.1635912629847414, time: 0.08761334419250488
Test Loss Energy: 8.131040724073861, Test Loss Force: 6.9249138069397125, time: 17.18667244911194


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4461388404915234, Training Loss Force: 3.4333740828228057, time: 1.4427454471588135
Validation Loss Energy: 2.58166883036279, Validation Loss Force: 3.1769676665880615, time: 0.0902700424194336
Test Loss Energy: 7.95508792169868, Test Loss Force: 6.949300660040497, time: 17.26491117477417


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.351956559734162, Training Loss Force: 3.5381629153607186, time: 1.3995671272277832
Validation Loss Energy: 1.8748091893213628, Validation Loss Force: 3.180397439442787, time: 0.08835935592651367
Test Loss Energy: 7.372253010735437, Test Loss Force: 6.89935306774935, time: 17.2144296169281


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.08893212935644, Training Loss Force: 3.501239747651256, time: 1.442382574081421
Validation Loss Energy: 2.1347805385824112, Validation Loss Force: 3.164480603553577, time: 0.09087800979614258
Test Loss Energy: 7.280467576344674, Test Loss Force: 6.913588264279459, time: 17.37534737586975


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.391782694397657, Training Loss Force: 3.5237822211718357, time: 1.4102764129638672
Validation Loss Energy: 2.0517623555678624, Validation Loss Force: 3.2057057918997938, time: 0.0955495834350586
Test Loss Energy: 7.289596022723337, Test Loss Force: 6.917572624370197, time: 17.664584159851074


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1233696501794825, Training Loss Force: 3.4625200676933057, time: 1.4479126930236816
Validation Loss Energy: 3.7488630848997384, Validation Loss Force: 3.1579410334068236, time: 0.09221363067626953
Test Loss Energy: 8.841668985617185, Test Loss Force: 6.9312955419678275, time: 17.255019664764404


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4547202486182913, Training Loss Force: 3.527826613606751, time: 1.450096607208252
Validation Loss Energy: 2.4081888574544723, Validation Loss Force: 3.175180301353699, time: 0.08830642700195312
Test Loss Energy: 8.109192527734832, Test Loss Force: 6.987017882521751, time: 17.320199966430664


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2050845565426296, Training Loss Force: 3.509234214558645, time: 1.4712975025177002
Validation Loss Energy: 3.0619888903819135, Validation Loss Force: 3.259962469342288, time: 0.0884559154510498
Test Loss Energy: 7.174931818564227, Test Loss Force: 6.884080023153948, time: 17.206924438476562


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.661707585940395, Training Loss Force: 3.4465908502276386, time: 1.6723222732543945
Validation Loss Energy: 1.8460040405967062, Validation Loss Force: 3.170962947729827, time: 0.08851218223571777
Test Loss Energy: 7.40758820263166, Test Loss Force: 6.887069098794671, time: 17.22149682044983


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.143143118606019, Training Loss Force: 3.46024247875504, time: 1.453366994857788
Validation Loss Energy: 2.7433691601132364, Validation Loss Force: 3.1395151615812993, time: 0.09344840049743652
Test Loss Energy: 8.036578004473798, Test Loss Force: 6.885127747936538, time: 17.34796714782715


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1719757523209116, Training Loss Force: 3.4134938357512254, time: 1.4549951553344727
Validation Loss Energy: 2.151060325179484, Validation Loss Force: 3.151073694277265, time: 0.09080362319946289
Test Loss Energy: 7.713550118770945, Test Loss Force: 6.9223268997559035, time: 17.204742670059204


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.042887698035622, Training Loss Force: 3.4338634920264126, time: 1.4247760772705078
Validation Loss Energy: 2.98816048568895, Validation Loss Force: 3.238337509897219, time: 0.09204936027526855
Test Loss Energy: 8.193914603033392, Test Loss Force: 6.891756442866209, time: 17.33664608001709

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–ˆâ–‚â–‚â–‚â–â–‚â–„â–„â–‚â–â–â–‡â–„â–â–‚â–„â–ƒâ–…
wandb:   test_error_force â–…â–„â–„â–ˆâ–…â–†â–…â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–†â–â–â–â–ƒâ–
wandb:          test_loss â–ƒâ–†â–ˆâ–ƒâ–‚â–†â–…â–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–…â–â–‚â–ƒâ–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–„â–â–â–„â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–â–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–â–â–
wandb: valid_error_energy â–‚â–…â–‡â–â–â–ˆâ–‚â–â–ƒâ–ƒâ–â–‚â–‚â–‡â–ƒâ–…â–â–„â–‚â–„
wandb:  valid_error_force â–‡â–„â–„â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–‚â–ƒâ–ˆâ–ƒâ–â–‚â–‡
wandb:         valid_loss â–„â–…â–‡â–‚â–‚â–ˆâ–ƒâ–â–ƒâ–ƒâ–„â–„â–ƒâ–†â–ƒâ–†â–â–„â–â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1186
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.19391
wandb:   test_error_force 6.89176
wandb:          test_loss 3.69538
wandb: train_error_energy 2.04289
wandb:  train_error_force 3.43386
wandb:         train_loss 1.55372
wandb: valid_error_energy 2.98816
wandb:  valid_error_force 3.23834
wandb:         valid_loss 1.65321
wandb: 
wandb: ğŸš€ View run al_56_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6w3uupxi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241125_105740-6w3uupxi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.8075602054595947, Uncertainty Bias: 0.015056222677230835
4.5776367e-05 0.031941414
0.67257345 8.832586
Found uncertainty sample 4 after 2104 steps.
