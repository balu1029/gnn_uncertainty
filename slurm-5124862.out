wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_213558-vnwc3dk5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/vnwc3dk5
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/autograd/graph.py:744: UserWarning: Attempting to run cuBLAS, but there was no current CUDA context! Attempting to set the primary context... (Triggered internally at ../aten/src/ATen/cuda/CublasHandlePool.cpp:135.)
  return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
73
Uncertainty Slope: 1.6197417974472046, Uncertainty Bias: 0.004416286945343018
2.2888184e-05 0.002187252
0.7288603 3.4580226
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 14.464109733916708, Test Loss Force: 12.648549456128888, time: 6.37402606010437

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.051 MB uploadedwandb: | 0.039 MB of 0.051 MB uploadedwandb: / 0.051 MB of 0.051 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.46411
wandb:   test_error_force 12.64855
wandb:          test_loss 5.20019
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_74 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/vnwc3dk5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_213558-vnwc3dk5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 439 steps.
Found uncertainty sample 2 after 1322 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1228 steps.
Found uncertainty sample 5 after 824 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2203 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2356 steps.
Found uncertainty sample 12 after 795 steps.
Found uncertainty sample 13 after 2159 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2870 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 243 steps.
Found uncertainty sample 22 after 19 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3116 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1065 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3478 steps.
Found uncertainty sample 31 after 3453 steps.
Found uncertainty sample 32 after 1564 steps.
Found uncertainty sample 33 after 698 steps.
Found uncertainty sample 34 after 2459 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3781 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2251 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3106 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1822 steps.
Found uncertainty sample 45 after 3565 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1489 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1330 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1671 steps.
Found uncertainty sample 56 after 841 steps.
Found uncertainty sample 57 after 3367 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1810 steps.
Found uncertainty sample 60 after 2355 steps.
Found uncertainty sample 61 after 1595 steps.
Found uncertainty sample 62 after 2749 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2875 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 443 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2352 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2246 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3106 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1572 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 408 steps.
Found uncertainty sample 81 after 2149 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1282 steps.
Found uncertainty sample 86 after 1618 steps.
Found uncertainty sample 87 after 646 steps.
Found uncertainty sample 88 after 3108 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2917 steps.
Found uncertainty sample 92 after 301 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2913 steps.
Found uncertainty sample 97 after 805 steps.
Found uncertainty sample 98 after 2173 steps.
Found uncertainty sample 99 after 940 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_231126-jqq3oxj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jqq3oxj9
Training model 0. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 30.05230426120855, Training Loss Force: 28.777114250339828, time: 0.8595304489135742
Validation Loss Energy: 7.079501409166944, Validation Loss Force: 15.682180017818759, time: 0.0392913818359375
Test Loss Energy: 24.776543132131096, Test Loss Force: 20.88004379102367, time: 7.777220726013184


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.013729556343977, Training Loss Force: 10.442284680184567, time: 0.37171459197998047
Validation Loss Energy: 15.790892438920206, Validation Loss Force: 8.061335623852889, time: 0.0393061637878418
Test Loss Energy: 12.930720381801889, Test Loss Force: 13.661136730393874, time: 7.860488414764404


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.779626094115631, Training Loss Force: 6.2709104370991735, time: 0.36421751976013184
Validation Loss Energy: 11.750639165599862, Validation Loss Force: 5.218486573435808, time: 0.03712725639343262
Test Loss Energy: 14.537293299255326, Test Loss Force: 12.096025414131857, time: 7.82950758934021


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.869777222737284, Training Loss Force: 4.911910184322819, time: 0.37091851234436035
Validation Loss Energy: 4.559087970172304, Validation Loss Force: 4.126102917194511, time: 0.03458833694458008
Test Loss Energy: 23.839538206437016, Test Loss Force: 12.14597314398824, time: 8.112908601760864


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 9.560429810943788, Training Loss Force: 4.509833637563132, time: 0.3823235034942627
Validation Loss Energy: 17.586131254282567, Validation Loss Force: 5.05286303600326, time: 0.03403520584106445
Test Loss Energy: 32.849592169643536, Test Loss Force: 12.9615054987431, time: 7.804717779159546


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 9.84201823551274, Training Loss Force: 4.463056424979357, time: 0.3702213764190674
Validation Loss Energy: 12.266739930678122, Validation Loss Force: 4.241432619974641, time: 0.036545515060424805
Test Loss Energy: 14.307156669554193, Test Loss Force: 11.34048707549994, time: 7.983965873718262


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.535365021420901, Training Loss Force: 4.354743546548753, time: 0.394634485244751
Validation Loss Energy: 11.749994315753256, Validation Loss Force: 3.9267000249864252, time: 0.03740954399108887
Test Loss Energy: 14.849465024194313, Test Loss Force: 11.649246525182164, time: 8.099996089935303


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 12.183010278507307, Training Loss Force: 4.809705491680257, time: 0.3815028667449951
Validation Loss Energy: 3.8562809075867626, Validation Loss Force: 4.239914016399413, time: 0.03510236740112305
Test Loss Energy: 15.952060753790676, Test Loss Force: 11.48245565815887, time: 7.875581502914429


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 15.607913420864122, Training Loss Force: 5.214137242984443, time: 0.41660308837890625
Validation Loss Energy: 7.6131845753459535, Validation Loss Force: 7.3224797625565134, time: 0.03555893898010254
Test Loss Energy: 13.761430369171837, Test Loss Force: 12.549999454328772, time: 7.902991533279419


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.861648491760562, Training Loss Force: 6.077851850690875, time: 0.3870851993560791
Validation Loss Energy: 2.518043793943676, Validation Loss Force: 4.15446116894329, time: 0.03474879264831543
Test Loss Energy: 16.06751545673397, Test Loss Force: 11.1785708161341, time: 7.91245436668396


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 23.55901768603662, Training Loss Force: 5.587706291938542, time: 0.4019761085510254
Validation Loss Energy: 7.318256174196556, Validation Loss Force: 8.36155687060099, time: 0.036829471588134766
Test Loss Energy: 11.805544648472273, Test Loss Force: 13.72774187506591, time: 8.4919912815094


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 20.875050155416652, Training Loss Force: 8.63335727082929, time: 0.35745668411254883
Validation Loss Energy: 12.762250925170731, Validation Loss Force: 8.164056463575712, time: 0.03781414031982422
Test Loss Energy: 24.129299519925457, Test Loss Force: 13.0161747984343, time: 7.866669654846191


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 16.974203873848662, Training Loss Force: 9.699603692841368, time: 0.37410926818847656
Validation Loss Energy: 7.175509219478337, Validation Loss Force: 6.740964591802465, time: 0.036527395248413086
Test Loss Energy: 14.057623011120162, Test Loss Force: 11.839394266438516, time: 7.95510458946228


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.296205845969817, Training Loss Force: 6.993930118219197, time: 0.3758511543273926
Validation Loss Energy: 4.602952901243495, Validation Loss Force: 4.719834607970742, time: 0.036972999572753906
Test Loss Energy: 15.226769153079328, Test Loss Force: 11.084910502871397, time: 7.943158864974976


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 16.189506859822963, Training Loss Force: 5.547249798719093, time: 0.4217538833618164
Validation Loss Energy: 2.1161518151649465, Validation Loss Force: 6.472616206602466, time: 0.0358278751373291
Test Loss Energy: 14.058783268925358, Test Loss Force: 11.872359992818062, time: 8.1262366771698


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.374048461943461, Training Loss Force: 6.83289800208167, time: 0.3731424808502197
Validation Loss Energy: 10.912282705769071, Validation Loss Force: 5.434726370444077, time: 0.039148807525634766
Test Loss Energy: 12.738239893287602, Test Loss Force: 11.549174664873547, time: 7.970738410949707


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 18.430891884925376, Training Loss Force: 6.494792816486063, time: 0.39340829849243164
Validation Loss Energy: 5.590982662245734, Validation Loss Force: 10.178788272168346, time: 0.03622126579284668
Test Loss Energy: 18.849086783583115, Test Loss Force: 15.086967330071014, time: 8.046707391738892


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 12.880515918608525, Training Loss Force: 7.682592708847061, time: 0.3703594207763672
Validation Loss Energy: 14.51930554471281, Validation Loss Force: 4.751487472402669, time: 0.03756403923034668
Test Loss Energy: 24.708384241796217, Test Loss Force: 11.293530144347095, time: 8.184783458709717


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 14.64325465467373, Training Loss Force: 6.589264506582749, time: 0.3884298801422119
Validation Loss Energy: 4.796943151852368, Validation Loss Force: 5.526731480188271, time: 0.03597688674926758
Test Loss Energy: 12.079852998363789, Test Loss Force: 11.73549813466282, time: 7.93841814994812


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 14.791342238139968, Training Loss Force: 6.353102732004472, time: 0.37401342391967773
Validation Loss Energy: 17.9289793916505, Validation Loss Force: 5.211536624053109, time: 0.03814196586608887
Test Loss Energy: 29.516442438188477, Test Loss Force: 11.37340482192467, time: 8.069876909255981

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.045 MB of 0.061 MB uploadedwandb: - 0.045 MB of 0.061 MB uploadedwandb: \ 0.064 MB of 0.064 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‚â–…â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–…â–‚â–‚â–‚â–â–ƒâ–…â–â–‡
wandb:   test_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–â–ƒâ–‚â–‚â–â–‚â–â–„â–â–â–
wandb:          test_loss â–ˆâ–‚â–‚â–ƒâ–„â–â–â–â–‚â–â–‚â–ƒâ–â–â–â–â–„â–‚â–â–ƒ
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–‚â–ƒâ–â–†â–…â–„â–‚â–ƒâ–â–„â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–‡â–…â–‚â–ˆâ–…â–…â–‚â–ƒâ–â–ƒâ–†â–ƒâ–‚â–â–…â–ƒâ–†â–‚â–ˆ
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–ƒâ–â–„â–„â–ƒâ–â–ƒâ–‚â–…â–â–‚â–‚
wandb:         valid_loss â–ˆâ–…â–ƒâ–â–ƒâ–‚â–‚â–â–ƒâ–â–„â–„â–ƒâ–‚â–‚â–ƒâ–…â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 845
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 29.51644
wandb:   test_error_force 11.3734
wandb:          test_loss 5.78084
wandb: train_error_energy 14.79134
wandb:  train_error_force 6.3531
wandb:         train_loss 3.11561
wandb: valid_error_energy 17.92898
wandb:  valid_error_force 5.21154
wandb:         valid_loss 2.94362
wandb: 
wandb: ğŸš€ View run al_74_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jqq3oxj9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_231126-jqq3oxj9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.7853765487670898, Uncertainty Bias: 0.03545279800891876
0.00018692017 0.6136799
1.9193555 5.6344833
(48745, 22, 3)
Found uncertainty sample 0 after 14 steps.
Found uncertainty sample 1 after 119 steps.
Found uncertainty sample 2 after 48 steps.
Found uncertainty sample 3 after 102 steps.
Found uncertainty sample 4 after 53 steps.
Found uncertainty sample 5 after 5 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 23 steps.
Found uncertainty sample 8 after 20 steps.
Found uncertainty sample 9 after 4 steps.
Found uncertainty sample 10 after 38 steps.
Found uncertainty sample 11 after 5 steps.
Found uncertainty sample 12 after 29 steps.
Found uncertainty sample 13 after 3 steps.
Found uncertainty sample 14 after 11 steps.
Found uncertainty sample 15 after 53 steps.
Found uncertainty sample 16 after 2 steps.
Found uncertainty sample 17 after 13 steps.
Found uncertainty sample 18 after 63 steps.
Found uncertainty sample 19 after 26 steps.
Found uncertainty sample 20 after 30 steps.
Found uncertainty sample 21 after 24 steps.
Found uncertainty sample 22 after 25 steps.
Found uncertainty sample 23 after 64 steps.
Found uncertainty sample 24 after 6 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 37 steps.
Found uncertainty sample 27 after 41 steps.
Found uncertainty sample 28 after 16 steps.
Found uncertainty sample 29 after 17 steps.
Found uncertainty sample 30 after 64 steps.
Found uncertainty sample 31 after 7 steps.
Found uncertainty sample 32 after 38 steps.
Found uncertainty sample 33 after 17 steps.
Found uncertainty sample 34 after 12 steps.
Found uncertainty sample 35 after 16 steps.
Found uncertainty sample 36 after 36 steps.
Found uncertainty sample 37 after 28 steps.
Found uncertainty sample 38 after 2 steps.
Found uncertainty sample 39 after 9 steps.
Found uncertainty sample 40 after 45 steps.
Found uncertainty sample 41 after 8 steps.
Found uncertainty sample 42 after 3 steps.
Found uncertainty sample 43 after 112 steps.
Found uncertainty sample 44 after 21 steps.
Found uncertainty sample 45 after 37 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 45 steps.
Found uncertainty sample 48 after 4 steps.
Found uncertainty sample 49 after 14 steps.
Found uncertainty sample 50 after 110 steps.
Found uncertainty sample 51 after 6 steps.
Found uncertainty sample 52 after 22 steps.
Found uncertainty sample 53 after 4 steps.
Found uncertainty sample 54 after 57 steps.
Found uncertainty sample 55 after 57 steps.
Found uncertainty sample 56 after 4 steps.
Found uncertainty sample 57 after 23 steps.
Found uncertainty sample 58 after 14 steps.
Found uncertainty sample 59 after 3 steps.
Found uncertainty sample 60 after 20 steps.
Found uncertainty sample 61 after 9 steps.
Found uncertainty sample 62 after 3 steps.
Found uncertainty sample 63 after 4 steps.
Found uncertainty sample 64 after 5 steps.
Found uncertainty sample 65 after 9 steps.
Found uncertainty sample 66 after 24 steps.
Found uncertainty sample 67 after 62 steps.
Found uncertainty sample 68 after 31 steps.
Found uncertainty sample 69 after 2 steps.
Found uncertainty sample 70 after 29 steps.
Found uncertainty sample 71 after 7 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 7 steps.
Found uncertainty sample 74 after 320 steps.
Found uncertainty sample 75 after 8 steps.
Found uncertainty sample 76 after 3 steps.
Found uncertainty sample 77 after 4 steps.
Found uncertainty sample 78 after 4 steps.
Found uncertainty sample 79 after 23 steps.
Found uncertainty sample 80 after 18 steps.
Found uncertainty sample 81 after 26 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 34 steps.
Found uncertainty sample 84 after 34 steps.
Found uncertainty sample 85 after 11 steps.
Found uncertainty sample 86 after 5 steps.
Found uncertainty sample 87 after 27 steps.
Found uncertainty sample 88 after 8 steps.
Found uncertainty sample 89 after 7 steps.
Found uncertainty sample 90 after 30 steps.
Found uncertainty sample 91 after 3 steps.
Found uncertainty sample 92 after 35 steps.
Found uncertainty sample 93 after 71 steps.
Found uncertainty sample 94 after 33 steps.
Found uncertainty sample 95 after 97 steps.
Found uncertainty sample 96 after 8 steps.
Found uncertainty sample 97 after 34 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 14 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_231745-fde2u0rm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/fde2u0rm
Training model 1. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 39.97630165107069, Training Loss Force: 18.35311123814308, time: 0.4942746162414551
Validation Loss Energy: 20.767521130108754, Validation Loss Force: 9.51237870817616, time: 0.04379892349243164
Test Loss Energy: 22.127542808010645, Test Loss Force: 14.620284407567024, time: 8.387044668197632


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.392147567622038, Training Loss Force: 8.23420025799874, time: 0.4290022850036621
Validation Loss Energy: 3.0046970098112773, Validation Loss Force: 8.565143270722766, time: 0.038713693618774414
Test Loss Energy: 10.52663421035598, Test Loss Force: 13.35369519759862, time: 8.338496208190918


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 9.279646408735715, Training Loss Force: 6.757479427949978, time: 0.4395613670349121
Validation Loss Energy: 9.516187241248108, Validation Loss Force: 5.317826850185155, time: 0.03784370422363281
Test Loss Energy: 10.487373582920387, Test Loss Force: 11.37684795842557, time: 8.388736009597778


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.036571388774313, Training Loss Force: 5.5265764876180965, time: 0.42134523391723633
Validation Loss Energy: 9.149481440908888, Validation Loss Force: 4.572183587982609, time: 0.06254291534423828
Test Loss Energy: 20.29294995608888, Test Loss Force: 12.841104794118804, time: 8.49623441696167


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 11.436513941529844, Training Loss Force: 5.187342893962178, time: 0.41489696502685547
Validation Loss Energy: 9.469172877776916, Validation Loss Force: 6.80357247556298, time: 0.0404207706451416
Test Loss Energy: 21.758449807897954, Test Loss Force: 13.446031914162416, time: 8.403485774993896


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.234198846445393, Training Loss Force: 6.602962107954968, time: 0.4565720558166504
Validation Loss Energy: 37.19602221501026, Validation Loss Force: 8.456177006794961, time: 0.04317522048950195
Test Loss Energy: 23.20120398080274, Test Loss Force: 13.684801899968829, time: 8.42418646812439


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 18.896446169165344, Training Loss Force: 9.504556964553327, time: 0.45571303367614746
Validation Loss Energy: 29.072061339203476, Validation Loss Force: 9.535627148364188, time: 0.041260480880737305
Test Loss Energy: 38.84758421862747, Test Loss Force: 15.95317002852211, time: 8.927706718444824


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 21.05941351909878, Training Loss Force: 7.8757118101316195, time: 0.4321901798248291
Validation Loss Energy: 18.406736529799993, Validation Loss Force: 7.168265792161305, time: 0.03940606117248535
Test Loss Energy: 13.221700332049204, Test Loss Force: 12.666351931289082, time: 8.41487193107605


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.29446039643009, Training Loss Force: 7.80536693062521, time: 0.43215012550354004
Validation Loss Energy: 9.101563931381811, Validation Loss Force: 7.481243308941318, time: 0.03849339485168457
Test Loss Energy: 19.42809373213417, Test Loss Force: 12.46970160278292, time: 8.400165796279907


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 27.698501896071605, Training Loss Force: 7.1667941569312585, time: 0.4082353115081787
Validation Loss Energy: 10.904337870642369, Validation Loss Force: 11.840176210530593, time: 0.0398101806640625
Test Loss Energy: 15.02463920969073, Test Loss Force: 17.081984721293882, time: 8.599876642227173


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.416028079501139, Training Loss Force: 8.89553192634109, time: 0.4310617446899414
Validation Loss Energy: 2.0792299307329305, Validation Loss Force: 6.256200946307207, time: 0.04423880577087402
Test Loss Energy: 14.074786498111578, Test Loss Force: 12.238466610304311, time: 8.349350214004517


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 9.975565891566331, Training Loss Force: 7.490307249506234, time: 0.455294132232666
Validation Loss Energy: 14.508539936845493, Validation Loss Force: 11.07501911505552, time: 0.04164743423461914
Test Loss Energy: 23.821258361270562, Test Loss Force: 15.301146434885391, time: 8.45639419555664


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 13.931982372157497, Training Loss Force: 7.456587109878906, time: 0.4474458694458008
Validation Loss Energy: 16.31178504401883, Validation Loss Force: 7.4926243743279795, time: 0.04352617263793945
Test Loss Energy: 12.43888901010123, Test Loss Force: 12.691971450470739, time: 8.386719703674316


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.068045383292617, Training Loss Force: 7.656936286578743, time: 0.4316110610961914
Validation Loss Energy: 15.773037936123133, Validation Loss Force: 5.6278161470268175, time: 0.04027247428894043
Test Loss Energy: 25.763768031606336, Test Loss Force: 12.405440019394986, time: 8.628433227539062


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 15.177392448571482, Training Loss Force: 6.2873563827117405, time: 0.43424296379089355
Validation Loss Energy: 8.714629975149927, Validation Loss Force: 9.050752613634259, time: 0.04316067695617676
Test Loss Energy: 11.88450517943867, Test Loss Force: 13.777680119916155, time: 8.479668855667114


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 15.332325566084988, Training Loss Force: 7.3501296295290475, time: 0.41182661056518555
Validation Loss Energy: 3.657120056740301, Validation Loss Force: 5.0069709250275425, time: 0.03894996643066406
Test Loss Energy: 13.46267657038575, Test Loss Force: 10.864552541434408, time: 8.531281471252441


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 19.11539139629663, Training Loss Force: 7.463706317501729, time: 0.42193174362182617
Validation Loss Energy: 20.882021167651157, Validation Loss Force: 10.96671907721233, time: 0.03937482833862305
Test Loss Energy: 14.021463220583637, Test Loss Force: 14.97589240098934, time: 8.766351461410522


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.69431757172819, Training Loss Force: 7.501591661638954, time: 0.42980384826660156
Validation Loss Energy: 4.321393555615601, Validation Loss Force: 7.241028279652713, time: 0.04078555107116699
Test Loss Energy: 12.393453974762712, Test Loss Force: 12.111494186072335, time: 8.345700979232788


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.937200825967678, Training Loss Force: 6.4603279128922475, time: 0.4464566707611084
Validation Loss Energy: 4.044864305994216, Validation Loss Force: 4.427864143755849, time: 0.04189491271972656
Test Loss Energy: 13.505550588783349, Test Loss Force: 10.441154197264053, time: 8.332550764083862


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 9.649546253238324, Training Loss Force: 5.805694340283939, time: 0.41687917709350586
Validation Loss Energy: 2.429250018622052, Validation Loss Force: 5.039623128586394, time: 0.042859554290771484
Test Loss Energy: 11.927230874537328, Test Loss Force: 11.054671599174181, time: 8.33588171005249

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–â–ƒâ–„â–„â–ˆâ–‚â–ƒâ–‚â–‚â–„â–â–…â–â–‚â–‚â–â–‚â–
wandb:   test_error_force â–…â–„â–‚â–„â–„â–„â–‡â–ƒâ–ƒâ–ˆâ–ƒâ–†â–ƒâ–ƒâ–…â–â–†â–ƒâ–â–‚
wandb:          test_loss â–…â–ƒâ–â–ƒâ–„â–„â–ˆâ–‚â–ƒâ–†â–‚â–†â–‚â–„â–ƒâ–â–„â–‚â–â–
wandb: train_error_energy â–ˆâ–â–â–â–‚â–‚â–ƒâ–„â–‚â–…â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–…â–â–‚â–‚â–‚â–ˆâ–†â–„â–‚â–ƒâ–â–ƒâ–„â–„â–‚â–â–…â–â–â–
wandb:  valid_error_force â–†â–…â–‚â–â–ƒâ–…â–†â–„â–„â–ˆâ–ƒâ–‡â–„â–‚â–…â–‚â–‡â–„â–â–‚
wandb:         valid_loss â–‡â–„â–‚â–‚â–ƒâ–ˆâ–ˆâ–…â–„â–‡â–‚â–‡â–…â–ƒâ–…â–â–ˆâ–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 935
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.92723
wandb:   test_error_force 11.05467
wandb:          test_loss 4.49711
wandb: train_error_energy 9.64955
wandb:  train_error_force 5.80569
wandb:         train_loss 2.58836
wandb: valid_error_energy 2.42925
wandb:  valid_error_force 5.03962
wandb:         valid_loss 1.84884
wandb: 
wandb: ğŸš€ View run al_74_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/fde2u0rm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_231745-fde2u0rm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.635586977005005, Uncertainty Bias: 0.06502822041511536
0.0007133484 0.115550995
2.3605306 6.3842525
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 2 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 5 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 9 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 12 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 19 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 35 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 36 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 45 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 53 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 60 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 70 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 73 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 74 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 77 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 82 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 86 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 90 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 91 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 94 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 98 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_232325-zmk1vpam
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/zmk1vpam
Training model 2. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 40.80789210242746, Training Loss Force: 14.893160320165888, time: 0.46739912033081055
Validation Loss Energy: 10.560843992751243, Validation Loss Force: 10.21991793545096, time: 0.04669189453125
Test Loss Energy: 11.768051822862994, Test Loss Force: 14.586559680178079, time: 8.640612125396729


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 13.028332315796035, Training Loss Force: 8.535389261291813, time: 0.4792506694793701
Validation Loss Energy: 8.450442830949028, Validation Loss Force: 7.058648443650807, time: 0.047182559967041016
Test Loss Energy: 18.30819385393136, Test Loss Force: 11.806996642496077, time: 8.64190936088562


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.545550383012761, Training Loss Force: 7.692256534785772, time: 0.46027612686157227
Validation Loss Energy: 21.02316846722503, Validation Loss Force: 7.649161674591798, time: 0.04193282127380371
Test Loss Energy: 14.597967754982403, Test Loss Force: 12.88827982911718, time: 8.825822353363037


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 19.03902924681446, Training Loss Force: 8.527715421263252, time: 0.4790487289428711
Validation Loss Energy: 20.15789932374082, Validation Loss Force: 8.362337103288322, time: 0.044170379638671875
Test Loss Energy: 13.836920045408988, Test Loss Force: 12.809941685227214, time: 8.998605251312256


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 13.929991346637339, Training Loss Force: 7.069411258032474, time: 0.4768824577331543
Validation Loss Energy: 13.691940033925015, Validation Loss Force: 5.903151444687738, time: 0.04355764389038086
Test Loss Energy: 23.56398579586656, Test Loss Force: 11.363629310666008, time: 8.631981611251831


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.787394041568005, Training Loss Force: 4.877035880637518, time: 0.45610499382019043
Validation Loss Energy: 11.477848976276897, Validation Loss Force: 5.058084627475266, time: 0.044708251953125
Test Loss Energy: 11.383841532307954, Test Loss Force: 10.65897479831672, time: 8.70103907585144


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.131505725125832, Training Loss Force: 4.406849176314725, time: 0.46601271629333496
Validation Loss Energy: 2.669317195597762, Validation Loss Force: 5.156126743103855, time: 0.04408979415893555
Test Loss Energy: 12.77004573958343, Test Loss Force: 11.226787569677164, time: 8.846922874450684


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.001996154240826, Training Loss Force: 4.4155053583920685, time: 0.4672212600708008
Validation Loss Energy: 8.789292721132682, Validation Loss Force: 4.562428898037805, time: 0.04466724395751953
Test Loss Energy: 20.793356207013357, Test Loss Force: 11.164485013113802, time: 8.749206781387329


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.279701299379205, Training Loss Force: 4.249470861434286, time: 0.4547560214996338
Validation Loss Energy: 15.392510616557882, Validation Loss Force: 4.094356977059586, time: 0.043068647384643555
Test Loss Energy: 28.587304285181258, Test Loss Force: 10.86460189704154, time: 8.705408334732056


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.168350641285581, Training Loss Force: 6.014007380201134, time: 0.4561169147491455
Validation Loss Energy: 5.568768297571395, Validation Loss Force: 7.6204596216817055, time: 0.04290318489074707
Test Loss Energy: 20.355404711093804, Test Loss Force: 12.931279731359687, time: 9.002556085586548


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 31.010307807621082, Training Loss Force: 8.40221377354905, time: 0.4832923412322998
Validation Loss Energy: 58.47497340219229, Validation Loss Force: 11.833631518993483, time: 0.0460352897644043
Test Loss Energy: 63.0454342561174, Test Loss Force: 16.015218681637144, time: 8.724500179290771


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.422434545134427, Training Loss Force: 9.675751033553178, time: 0.4677886962890625
Validation Loss Energy: 13.378858307984707, Validation Loss Force: 11.21948240355055, time: 0.0434415340423584
Test Loss Energy: 21.97313925640511, Test Loss Force: 15.745153193227685, time: 8.773607015609741


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.386766171084162, Training Loss Force: 8.39062589575867, time: 0.45110368728637695
Validation Loss Energy: 24.808743459552176, Validation Loss Force: 6.660185569719365, time: 0.043849945068359375
Test Loss Energy: 32.092693502064286, Test Loss Force: 11.876111191499454, time: 8.988864183425903


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.540203382751047, Training Loss Force: 7.186417767442239, time: 0.45418524742126465
Validation Loss Energy: 19.11024989891642, Validation Loss Force: 7.031137225333136, time: 0.04435539245605469
Test Loss Energy: 13.47778888050039, Test Loss Force: 11.732219563484636, time: 8.85059404373169


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 23.852480016285487, Training Loss Force: 7.787463653838606, time: 0.45177531242370605
Validation Loss Energy: 32.35110855837409, Validation Loss Force: 8.073944041571904, time: 0.044733285903930664
Test Loss Energy: 39.89699707117014, Test Loss Force: 14.442742635834882, time: 9.079510688781738


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 19.63200830238236, Training Loss Force: 7.720502628760502, time: 0.4699232578277588
Validation Loss Energy: 13.808306038910292, Validation Loss Force: 10.099050451011605, time: 0.04466366767883301
Test Loss Energy: 11.366890865724537, Test Loss Force: 14.2903582107388, time: 8.741079330444336


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 14.445203256970355, Training Loss Force: 8.079659742626275, time: 0.6715905666351318
Validation Loss Energy: 12.113051014129011, Validation Loss Force: 6.0834266119223335, time: 0.04397869110107422
Test Loss Energy: 22.375916143354278, Test Loss Force: 11.304776255910024, time: 8.705293416976929


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 14.54656190807164, Training Loss Force: 7.226783567593522, time: 0.4840679168701172
Validation Loss Energy: 5.777483658800471, Validation Loss Force: 6.62607310190152, time: 0.044705867767333984
Test Loss Energy: 11.122897411496771, Test Loss Force: 11.778712251618554, time: 8.697993755340576


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 15.73570680604355, Training Loss Force: 6.311955060260965, time: 0.46658778190612793
Validation Loss Energy: 11.351868117570456, Validation Loss Force: 6.248191091789892, time: 0.04427146911621094
Test Loss Energy: 10.703041703127145, Test Loss Force: 11.329301903002955, time: 8.68556833267212


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 20.239939638332153, Training Loss Force: 9.893320232838136, time: 0.4901702404022217
Validation Loss Energy: 17.46954703353428, Validation Loss Force: 9.11769141228307, time: 0.04549407958984375
Test Loss Energy: 14.465516084263015, Test Loss Force: 13.275386595259217, time: 8.862528085708618

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‚â–â–ƒâ–â–â–‚â–ƒâ–‚â–ˆâ–ƒâ–„â–â–…â–â–ƒâ–â–â–‚
wandb:   test_error_force â–†â–ƒâ–„â–„â–‚â–â–‚â–‚â–â–„â–ˆâ–ˆâ–ƒâ–‚â–†â–†â–‚â–‚â–‚â–„
wandb:          test_loss â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–ƒâ–ˆâ–„â–ƒâ–‚â–…â–ƒâ–‚â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–‚â–â–â–â–â–‚â–†â–‚â–‚â–â–„â–ƒâ–‚â–‚â–ƒâ–„
wandb:  train_error_force â–ˆâ–„â–ƒâ–„â–ƒâ–â–â–â–â–‚â–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–…
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–„â–ƒâ–â–â–â–â–‚â–…â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–„
wandb: valid_error_energy â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–â–ˆâ–‚â–„â–ƒâ–…â–‚â–‚â–â–‚â–ƒ
wandb:  valid_error_force â–‡â–„â–„â–…â–ƒâ–‚â–‚â–â–â–„â–ˆâ–‡â–ƒâ–„â–…â–†â–ƒâ–ƒâ–ƒâ–†
wandb:         valid_loss â–„â–‚â–ƒâ–„â–‚â–‚â–â–â–‚â–‚â–ˆâ–„â–ƒâ–ƒâ–„â–„â–‚â–‚â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1025
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.46552
wandb:   test_error_force 13.27539
wandb:          test_loss 5.41003
wandb: train_error_energy 20.23994
wandb:  train_error_force 9.89332
wandb:         train_loss 4.66481
wandb: valid_error_energy 17.46955
wandb:  valid_error_force 9.11769
wandb:         valid_loss 4.21988
wandb: 
wandb: ğŸš€ View run al_74_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/zmk1vpam
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_232325-zmk1vpam/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.8894031047821045, Uncertainty Bias: 0.18358734250068665
0.0008735657 0.015209198
3.3877635 5.1886005
(48745, 22, 3)
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 4 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 5 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 13 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 19 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 35 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 36 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 41 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 47 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 52 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 59 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 74 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 77 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 78 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 81 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 82 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 83 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_232911-hvkep9oi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hvkep9oi
Training model 3. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 18.59350360962214, Training Loss Force: 17.62478182108603, time: 0.5022084712982178
Validation Loss Energy: 15.810054454942168, Validation Loss Force: 7.008013034528536, time: 0.046811819076538086
Test Loss Energy: 22.554582918886524, Test Loss Force: 12.464869215993463, time: 9.04550313949585


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.374210370678266, Training Loss Force: 6.786351969082143, time: 0.5031905174255371
Validation Loss Energy: 11.978451078122, Validation Loss Force: 8.59231425058546, time: 0.04570722579956055
Test Loss Energy: 20.32646116358559, Test Loss Force: 13.297333183381378, time: 8.705241680145264


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 18.856433614720935, Training Loss Force: 7.08542863280042, time: 0.5079917907714844
Validation Loss Energy: 23.79281993463956, Validation Loss Force: 7.850700409247622, time: 0.05065655708312988
Test Loss Energy: 17.305320438385174, Test Loss Force: 12.80149494218752, time: 9.023424863815308


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 15.344394136243984, Training Loss Force: 7.647232570903088, time: 0.5100641250610352
Validation Loss Energy: 4.880842659346499, Validation Loss Force: 8.434647572413494, time: 0.04952669143676758
Test Loss Energy: 11.994634121387103, Test Loss Force: 12.75929801519621, time: 8.743457794189453


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.566805670851448, Training Loss Force: 6.776232750659529, time: 0.5111253261566162
Validation Loss Energy: 11.33715235905438, Validation Loss Force: 6.567341887971606, time: 0.04659318923950195
Test Loss Energy: 22.594817121113305, Test Loss Force: 11.88385655704046, time: 8.778910636901855


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.503640615616263, Training Loss Force: 6.277744504274501, time: 0.5178942680358887
Validation Loss Energy: 8.467121640655604, Validation Loss Force: 5.030001149452562, time: 0.04868292808532715
Test Loss Energy: 18.194944363618312, Test Loss Force: 10.557585030447585, time: 8.753071546554565


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.31585677957112, Training Loss Force: 5.207047741310717, time: 0.48703694343566895
Validation Loss Energy: 33.738711421669365, Validation Loss Force: 5.785015665330625, time: 0.04808330535888672
Test Loss Energy: 24.39400503789808, Test Loss Force: 11.249201236060985, time: 9.047439813613892


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 14.724088657892457, Training Loss Force: 7.097747071671681, time: 0.5291445255279541
Validation Loss Energy: 9.573837173805396, Validation Loss Force: 5.446722002673498, time: 0.050368309020996094
Test Loss Energy: 10.095281783877427, Test Loss Force: 11.236959576575646, time: 8.755363702774048


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.298081027683747, Training Loss Force: 5.604071472742149, time: 0.5075891017913818
Validation Loss Energy: 29.796095896808605, Validation Loss Force: 4.614541048935869, time: 0.04650092124938965
Test Loss Energy: 18.7818805348081, Test Loss Force: 10.668697409914827, time: 8.835554599761963


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 27.809485101894705, Training Loss Force: 6.341205859785432, time: 0.5056014060974121
Validation Loss Energy: 27.528411938442005, Validation Loss Force: 9.300301488181866, time: 0.04732227325439453
Test Loss Energy: 19.74906383083429, Test Loss Force: 13.421884949177638, time: 8.978454113006592


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 14.661285582358625, Training Loss Force: 10.095459192130278, time: 0.5085403919219971
Validation Loss Energy: 18.254224197017965, Validation Loss Force: 8.053253624532294, time: 0.046465158462524414
Test Loss Energy: 27.599123927556334, Test Loss Force: 12.903460656043569, time: 8.798155546188354


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 14.444177458386918, Training Loss Force: 7.3075532190649275, time: 0.5034961700439453
Validation Loss Energy: 11.397746868397418, Validation Loss Force: 5.71210488018803, time: 0.046274423599243164
Test Loss Energy: 11.058575970911832, Test Loss Force: 10.755526625491633, time: 9.154532194137573


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 13.711859901204155, Training Loss Force: 6.447147042488271, time: 0.5142624378204346
Validation Loss Energy: 11.362994449454176, Validation Loss Force: 7.037208967604296, time: 0.04583406448364258
Test Loss Energy: 10.827661789879572, Test Loss Force: 11.879705565816915, time: 8.971520185470581


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 13.837763780005858, Training Loss Force: 6.1506985108895025, time: 0.4889562129974365
Validation Loss Energy: 16.58063220810571, Validation Loss Force: 6.410393985802697, time: 0.04859280586242676
Test Loss Energy: 12.195678651782902, Test Loss Force: 12.00062996495629, time: 8.782995223999023


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 14.486495589607033, Training Loss Force: 6.1011799593074, time: 0.5051240921020508
Validation Loss Energy: 18.666450696197497, Validation Loss Force: 5.997827693506482, time: 0.04558134078979492
Test Loss Energy: 28.71166476535729, Test Loss Force: 11.504511109343056, time: 8.80320119857788


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.01961602470998, Training Loss Force: 6.473761743928631, time: 0.49417734146118164
Validation Loss Energy: 15.918200405736377, Validation Loss Force: 6.1476630978161655, time: 0.045290231704711914
Test Loss Energy: 11.70820081395886, Test Loss Force: 11.632224632451416, time: 8.944867372512817


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 19.678726970481538, Training Loss Force: 7.419338601619692, time: 0.5357038974761963
Validation Loss Energy: 6.428916496037554, Validation Loss Force: 8.831237353489392, time: 0.04709124565124512
Test Loss Energy: 16.071326815722202, Test Loss Force: 13.728592475866579, time: 8.8073410987854


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.179968165350616, Training Loss Force: 6.586868903257573, time: 0.482590913772583
Validation Loss Energy: 13.08153977622292, Validation Loss Force: 5.301889974072812, time: 0.04637575149536133
Test Loss Energy: 10.817134692144336, Test Loss Force: 10.975350479425002, time: 8.832987308502197


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.220319537747631, Training Loss Force: 4.779903980761999, time: 0.4897439479827881
Validation Loss Energy: 24.487096987582902, Validation Loss Force: 5.9603106144474, time: 0.046323299407958984
Test Loss Energy: 33.86507003916478, Test Loss Force: 11.390696673598384, time: 8.719658136367798


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 23.604741772524218, Training Loss Force: 8.247142732453113, time: 0.5536837577819824
Validation Loss Energy: 19.99324172506331, Validation Loss Force: 10.734656856032725, time: 0.06909394264221191
Test Loss Energy: 27.538360497435455, Test Loss Force: 14.512191612910915, time: 8.897404193878174

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–ƒâ–‚â–…â–ƒâ–…â–â–„â–„â–†â–â–â–‚â–†â–â–ƒâ–â–ˆâ–†
wandb:   test_error_force â–„â–†â–…â–…â–ƒâ–â–‚â–‚â–â–†â–…â–â–ƒâ–„â–ƒâ–ƒâ–‡â–‚â–‚â–ˆ
wandb:          test_loss â–…â–…â–„â–ƒâ–„â–‚â–„â–â–‚â–…â–†â–â–‚â–‚â–…â–‚â–…â–â–†â–ˆ
wandb: train_error_energy â–…â–‚â–…â–„â–‚â–ƒâ–ƒâ–„â–‚â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–â–…â–â–‚â–‡
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒ
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–â–„
wandb: valid_error_energy â–„â–ƒâ–†â–â–ƒâ–‚â–ˆâ–‚â–‡â–†â–„â–ƒâ–ƒâ–„â–„â–„â–â–ƒâ–†â–…
wandb:  valid_error_force â–„â–†â–…â–…â–ƒâ–â–‚â–‚â–â–†â–…â–‚â–„â–ƒâ–ƒâ–ƒâ–†â–‚â–ƒâ–ˆ
wandb:         valid_loss â–„â–…â–†â–ƒâ–ƒâ–â–†â–‚â–„â–ˆâ–…â–‚â–ƒâ–„â–„â–ƒâ–„â–‚â–…â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1115
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 27.53836
wandb:   test_error_force 14.51219
wandb:          test_loss 6.69871
wandb: train_error_energy 23.60474
wandb:  train_error_force 8.24714
wandb:         train_loss 4.33916
wandb: valid_error_energy 19.99324
wandb:  valid_error_force 10.73466
wandb:         valid_loss 4.92981
wandb: 
wandb: ğŸš€ View run al_74_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hvkep9oi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_232911-hvkep9oi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6914927363395691, Uncertainty Bias: 0.20489835739135742
3.2424927e-05 0.5157738
3.091843 4.02007
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 3 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 5 steps.
Found uncertainty sample 20 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 3 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 2 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 2 steps.
Found uncertainty sample 34 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 48 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 49 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 3 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 3 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 4 steps.
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 2 steps.
Found uncertainty sample 77 after 3 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 94 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_233505-yes5oqpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/yes5oqpb
Training model 4. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 36.79433575985323, Training Loss Force: 13.864421505645561, time: 0.5993311405181885
Validation Loss Energy: 5.731997696346927, Validation Loss Force: 14.233464271408724, time: 0.05166029930114746
Test Loss Energy: 10.362527693332687, Test Loss Force: 18.21278228397595, time: 8.822328090667725


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 15.653784527585177, Training Loss Force: 10.836082417614255, time: 0.5451290607452393
Validation Loss Energy: 25.181735655219228, Validation Loss Force: 9.421549291522464, time: 0.04979872703552246
Test Loss Energy: 29.64414351514081, Test Loss Force: 13.411543727717932, time: 8.940562725067139


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 22.534085169531398, Training Loss Force: 8.59409756089748, time: 0.564769983291626
Validation Loss Energy: 6.34514836333952, Validation Loss Force: 10.088279499084786, time: 0.04861783981323242
Test Loss Energy: 9.357162710302978, Test Loss Force: 14.097834713270942, time: 9.079919815063477


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 15.253830854423178, Training Loss Force: 9.861203543248228, time: 0.5408661365509033
Validation Loss Energy: 18.09985213152915, Validation Loss Force: 8.101325221108352, time: 0.04976630210876465
Test Loss Energy: 13.93500068396563, Test Loss Force: 13.000417610493683, time: 9.00810432434082


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 9.388844163023455, Training Loss Force: 7.125798637355105, time: 0.544856071472168
Validation Loss Energy: 20.95117329761049, Validation Loss Force: 6.261163350893353, time: 0.04997110366821289
Test Loss Energy: 27.718869928932868, Test Loss Force: 11.740178113165436, time: 8.940145492553711


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 16.817408985532904, Training Loss Force: 7.658654060282699, time: 0.5413403511047363
Validation Loss Energy: 13.46114079214111, Validation Loss Force: 6.799833415264561, time: 0.04921317100524902
Test Loss Energy: 20.51061147577518, Test Loss Force: 11.577026802477508, time: 8.942667007446289


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.17921135590285, Training Loss Force: 6.086568778276522, time: 0.7139770984649658
Validation Loss Energy: 17.711123461981085, Validation Loss Force: 6.130118105131931, time: 0.07212996482849121
Test Loss Energy: 12.481198512084202, Test Loss Force: 11.694365001938435, time: 9.027885913848877


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 14.074725212770257, Training Loss Force: 6.18194577861693, time: 0.5828948020935059
Validation Loss Energy: 10.38187500272666, Validation Loss Force: 7.791911301339768, time: 0.05102944374084473
Test Loss Energy: 18.26330193545332, Test Loss Force: 11.903689695536631, time: 9.021748542785645


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 20.438347503452825, Training Loss Force: 7.25606804521497, time: 0.5304465293884277
Validation Loss Energy: 15.967255309260851, Validation Loss Force: 5.666850048307959, time: 0.04825949668884277
Test Loss Energy: 12.08140410463948, Test Loss Force: 11.239571721150403, time: 8.941598415374756


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 28.711810377541262, Training Loss Force: 8.880081108066383, time: 0.5567519664764404
Validation Loss Energy: 19.52419540390251, Validation Loss Force: 11.710324471391345, time: 0.04906797409057617
Test Loss Energy: 13.250217091587286, Test Loss Force: 15.734311681995168, time: 9.575916290283203


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 14.037191978478667, Training Loss Force: 9.106036065386343, time: 0.5359680652618408
Validation Loss Energy: 12.62678525152435, Validation Loss Force: 6.280805441593935, time: 0.04976344108581543
Test Loss Energy: 21.72646303767493, Test Loss Force: 11.78406358575679, time: 8.950239419937134


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.671023578084807, Training Loss Force: 8.012187597747701, time: 0.5329830646514893
Validation Loss Energy: 12.309892320482342, Validation Loss Force: 7.090265681019385, time: 0.04929757118225098
Test Loss Energy: 10.713082104399737, Test Loss Force: 12.39879703633415, time: 9.002452611923218


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 13.911197431479465, Training Loss Force: 6.401755090948137, time: 0.5656702518463135
Validation Loss Energy: 18.423682542481682, Validation Loss Force: 7.2477773814657835, time: 0.04983830451965332
Test Loss Energy: 27.26130742272859, Test Loss Force: 12.014508753287688, time: 9.19544529914856


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 14.589068672948853, Training Loss Force: 5.865242327298678, time: 0.5472424030303955
Validation Loss Energy: 5.026943456740682, Validation Loss Force: 5.519198582981534, time: 0.05016326904296875
Test Loss Energy: 11.25933036923952, Test Loss Force: 11.221463039774543, time: 8.988975763320923


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 22.669006364378554, Training Loss Force: 8.243865738089438, time: 0.5393598079681396
Validation Loss Energy: 4.0652656984824125, Validation Loss Force: 9.297957227413537, time: 0.04982757568359375
Test Loss Energy: 12.107389174278717, Test Loss Force: 13.618073142444016, time: 9.024179220199585


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.717384996035634, Training Loss Force: 6.234466984455492, time: 0.5733828544616699
Validation Loss Energy: 3.1381210300586457, Validation Loss Force: 5.125325810824248, time: 0.04901289939880371
Test Loss Energy: 9.97119994557525, Test Loss Force: 10.786679069580359, time: 9.18434476852417


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.535651902568079, Training Loss Force: 4.446256884756345, time: 0.5667510032653809
Validation Loss Energy: 6.850607324595599, Validation Loss Force: 4.088115115560938, time: 0.0493011474609375
Test Loss Energy: 16.5774818150807, Test Loss Force: 10.0993949936262, time: 9.030123949050903


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.45634583688529, Training Loss Force: 4.277330384547677, time: 0.5260515213012695
Validation Loss Energy: 7.348987188364341, Validation Loss Force: 4.476218530147235, time: 0.04940342903137207
Test Loss Energy: 10.641250157098197, Test Loss Force: 10.580413919995632, time: 8.8978590965271


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.540197775218193, Training Loss Force: 4.147582901446438, time: 0.5422866344451904
Validation Loss Energy: 7.00807404587452, Validation Loss Force: 4.071093840707926, time: 0.04987597465515137
Test Loss Energy: 17.58085177116423, Test Loss Force: 10.254147308067836, time: 9.151589155197144


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.647526776354848, Training Loss Force: 4.064268175866942, time: 0.527446985244751
Validation Loss Energy: 5.476637602428897, Validation Loss Force: 4.075409614094299, time: 0.05454897880554199
Test Loss Energy: 10.766937349009565, Test Loss Force: 10.295374973754027, time: 9.292038917541504

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–â–ƒâ–‡â–…â–‚â–„â–‚â–‚â–…â–â–‡â–‚â–‚â–â–ƒâ–â–„â–
wandb:   test_error_force â–ˆâ–„â–„â–„â–‚â–‚â–‚â–ƒâ–‚â–†â–‚â–ƒâ–ƒâ–‚â–„â–‚â–â–â–â–
wandb:          test_loss â–ˆâ–‡â–„â–„â–…â–„â–ƒâ–„â–‚â–†â–„â–ƒâ–…â–‚â–„â–â–‚â–â–‚â–
wandb: train_error_energy â–ˆâ–ƒâ–„â–ƒâ–â–ƒâ–‚â–‚â–„â–†â–‚â–‚â–‚â–ƒâ–…â–â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–„â–…â–ƒâ–„â–‚â–ƒâ–ƒâ–„â–…â–„â–ƒâ–‚â–„â–ƒâ–â–â–â–
wandb:         train_loss â–ˆâ–…â–„â–„â–‚â–ƒâ–‚â–‚â–„â–…â–„â–ƒâ–ƒâ–‚â–„â–‚â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–‚â–†â–‡â–„â–†â–ƒâ–…â–†â–„â–„â–†â–‚â–â–â–‚â–‚â–‚â–‚
wandb:  valid_error_force â–ˆâ–…â–…â–„â–ƒâ–ƒâ–‚â–„â–‚â–†â–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–â–â–â–
wandb:         valid_loss â–ˆâ–‡â–…â–…â–…â–„â–„â–„â–ƒâ–ˆâ–ƒâ–„â–…â–‚â–„â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1205
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.76694
wandb:   test_error_force 10.29537
wandb:          test_loss 4.1654
wandb: train_error_energy 8.64753
wandb:  train_error_force 4.06427
wandb:         train_loss 1.93862
wandb: valid_error_energy 5.47664
wandb:  valid_error_force 4.07541
wandb:         valid_loss 1.73015
wandb: 
wandb: ğŸš€ View run al_74_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/yes5oqpb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_233505-yes5oqpb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.8696129322052, Uncertainty Bias: -0.0028763413429260254
0.00035953522 0.019571304
6.0128927 11.865223
(48745, 22, 3)
Found uncertainty sample 0 after 5 steps.
Found uncertainty sample 1 after 2 steps.
Found uncertainty sample 2 after 2 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 2 steps.
Found uncertainty sample 5 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 4 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 4 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 2 steps.
Found uncertainty sample 17 after 3 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 2 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 3 steps.
Found uncertainty sample 23 after 7 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 3 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 3 steps.
Found uncertainty sample 39 after 3 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 6 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 2 steps.
Found uncertainty sample 53 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 3 steps.
Found uncertainty sample 56 after 3 steps.
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 2 steps.
Found uncertainty sample 61 after 8 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 4 steps.
Found uncertainty sample 64 after 2 steps.
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 19 steps.
Found uncertainty sample 68 after 2 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 3 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 2 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 2 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 8 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 2 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 86 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 2 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 6 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 2 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_234103-qro6kzzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/qro6kzzv
Training model 5. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 29.332781198944993, Training Loss Force: 16.083725610301702, time: 0.6075830459594727
Validation Loss Energy: 5.613500747635119, Validation Loss Force: 8.24461905124897, time: 0.05571699142456055
Test Loss Energy: 12.936956321000737, Test Loss Force: 13.388150526937297, time: 10.10494089126587


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 10.039771036506327, Training Loss Force: 7.281393818459869, time: 0.6953701972961426
Validation Loss Energy: 4.406028316629586, Validation Loss Force: 6.227034405558709, time: 0.05556488037109375
Test Loss Energy: 9.769308036669457, Test Loss Force: 11.079164524394924, time: 9.405307292938232


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.721697534573837, Training Loss Force: 6.019620040408785, time: 0.5931575298309326
Validation Loss Energy: 5.961254286287843, Validation Loss Force: 9.117080408146643, time: 0.049402475357055664
Test Loss Energy: 14.429167078579576, Test Loss Force: 13.49738668452288, time: 8.449698448181152


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.580668248229317, Training Loss Force: 7.57372268224252, time: 0.5944421291351318
Validation Loss Energy: 6.304208414169238, Validation Loss Force: 6.904996935518212, time: 0.050862789154052734
Test Loss Energy: 9.66466971015875, Test Loss Force: 11.930119184811772, time: 8.295637369155884


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 13.72352654838241, Training Loss Force: 6.487193236809674, time: 0.5560050010681152
Validation Loss Energy: 9.818848051158994, Validation Loss Force: 5.275697847775618, time: 0.050103187561035156
Test Loss Energy: 18.785185551153333, Test Loss Force: 10.799816759035368, time: 8.383195877075195


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 13.845840040824463, Training Loss Force: 5.9038457270847395, time: 0.5869393348693848
Validation Loss Energy: 22.73009669931243, Validation Loss Force: 6.449940026119473, time: 0.050513505935668945
Test Loss Energy: 30.338647853825986, Test Loss Force: 11.540618252033351, time: 8.401687860488892


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 13.771885871511689, Training Loss Force: 6.436244678834863, time: 0.5884618759155273
Validation Loss Energy: 8.467768271855377, Validation Loss Force: 11.279357246213948, time: 0.07437515258789062
Test Loss Energy: 16.03895765146139, Test Loss Force: 14.496741610463891, time: 8.477002143859863


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 20.586121733511145, Training Loss Force: 8.288178556285313, time: 0.6058101654052734
Validation Loss Energy: 2.7803676427314516, Validation Loss Force: 6.974779219160522, time: 0.05068540573120117
Test Loss Energy: 11.800585053481111, Test Loss Force: 12.271390432915366, time: 8.346730470657349


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 15.886747547076084, Training Loss Force: 6.921300813830683, time: 0.5680797100067139
Validation Loss Energy: 11.991573416229814, Validation Loss Force: 8.540952494709172, time: 0.05637812614440918
Test Loss Energy: 10.392909884042407, Test Loss Force: 13.41274373021697, time: 8.818950176239014


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 8.426335273455509, Training Loss Force: 5.362816825262579, time: 0.5911266803741455
Validation Loss Energy: 4.543858291267427, Validation Loss Force: 4.839201747704835, time: 0.05131244659423828
Test Loss Energy: 9.208852361144718, Test Loss Force: 10.78233507200539, time: 8.56357479095459


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.445636235024528, Training Loss Force: 4.386334914268255, time: 0.5990872383117676
Validation Loss Energy: 1.7441933610078628, Validation Loss Force: 5.075596219787611, time: 0.05106019973754883
Test Loss Energy: 11.473057369417942, Test Loss Force: 10.668027509206398, time: 8.343377590179443


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.38409522431361, Training Loss Force: 4.628955449202228, time: 0.5833442211151123
Validation Loss Energy: 13.348295631691242, Validation Loss Force: 4.26109074285373, time: 0.0498046875
Test Loss Energy: 20.92137386120084, Test Loss Force: 10.183180422237578, time: 8.29099988937378


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.508122302469358, Training Loss Force: 4.171317712075953, time: 0.6114346981048584
Validation Loss Energy: 10.196883257643021, Validation Loss Force: 4.326872997958592, time: 0.049698591232299805
Test Loss Energy: 18.88785421401597, Test Loss Force: 10.35656827423887, time: 9.399773359298706


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.476395397830933, Training Loss Force: 4.1346615859850795, time: 0.6119451522827148
Validation Loss Energy: 6.8086381986328375, Validation Loss Force: 4.128142566571209, time: 0.0579221248626709
Test Loss Energy: 9.786561827074713, Test Loss Force: 10.323779083688798, time: 10.311132669448853


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.568644292273234, Training Loss Force: 4.093462232690745, time: 0.6390655040740967
Validation Loss Energy: 9.984007100753137, Validation Loss Force: 3.895274283083345, time: 0.06113028526306152
Test Loss Energy: 10.327744147341297, Test Loss Force: 10.39090536276364, time: 10.288371801376343


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.598829528071487, Training Loss Force: 4.09684050923226, time: 0.6436831951141357
Validation Loss Energy: 11.012593374656372, Validation Loss Force: 4.625531552640573, time: 0.053977251052856445
Test Loss Energy: 21.860229603509417, Test Loss Force: 10.516174057924594, time: 10.008163928985596


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.856296115557631, Training Loss Force: 4.035394295837003, time: 0.588794469833374
Validation Loss Energy: 4.48341029822241, Validation Loss Force: 4.334365814719062, time: 0.05589175224304199
Test Loss Energy: 17.41841187324205, Test Loss Force: 10.381507405111911, time: 9.85777473449707


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.973386218881648, Training Loss Force: 3.9223262164172876, time: 0.6257569789886475
Validation Loss Energy: 6.848923500514093, Validation Loss Force: 3.999096889740219, time: 0.059859275817871094
Test Loss Energy: 11.75716817470058, Test Loss Force: 10.276517625082434, time: 9.94732928276062


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 13.666027319389276, Training Loss Force: 4.358752534150119, time: 0.6081905364990234
Validation Loss Energy: 27.51723216596326, Validation Loss Force: 5.272703838439473, time: 0.06010580062866211
Test Loss Energy: 37.79586396347205, Test Loss Force: 11.372537032464898, time: 9.934889316558838


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 19.175375562450444, Training Loss Force: 6.844034609331832, time: 0.6314802169799805
Validation Loss Energy: 4.383491972370234, Validation Loss Force: 7.350585952832103, time: 0.05487966537475586
Test Loss Energy: 18.491495262735327, Test Loss Force: 12.268258688139879, time: 10.172661781311035

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–â–ƒâ–†â–ƒâ–‚â–â–â–‚â–„â–ƒâ–â–â–„â–ƒâ–‚â–ˆâ–ƒ
wandb:   test_error_force â–†â–‚â–†â–„â–‚â–ƒâ–ˆâ–„â–†â–‚â–‚â–â–â–â–â–‚â–â–â–ƒâ–„
wandb:          test_loss â–…â–‚â–…â–ƒâ–ƒâ–‡â–‡â–ƒâ–„â–â–‚â–ƒâ–ƒâ–â–â–„â–ƒâ–â–ˆâ–…
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–â–â–â–â–â–â–â–â–â–ƒâ–…
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–ƒ
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–‚â–ƒ
wandb: valid_error_energy â–‚â–‚â–‚â–‚â–ƒâ–‡â–ƒâ–â–„â–‚â–â–„â–ƒâ–‚â–ƒâ–„â–‚â–‚â–ˆâ–‚
wandb:  valid_error_force â–…â–ƒâ–†â–„â–‚â–ƒâ–ˆâ–„â–…â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–„
wandb:         valid_loss â–…â–ƒâ–†â–„â–ƒâ–†â–ˆâ–ƒâ–†â–â–â–ƒâ–‚â–â–‚â–‚â–â–â–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1295
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 18.4915
wandb:   test_error_force 12.26826
wandb:          test_loss 5.34246
wandb: train_error_energy 19.17538
wandb:  train_error_force 6.84403
wandb:         train_loss 3.57326
wandb: valid_error_energy 4.38349
wandb:  valid_error_force 7.35059
wandb:         valid_loss 2.75288
wandb: 
wandb: ğŸš€ View run al_74_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/qro6kzzv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_234103-qro6kzzv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6199610233306885, Uncertainty Bias: 0.08596910536289215
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:974: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.0002593994 0.18837798
1.8575648 6.2322946
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 2 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 4 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 5 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 12 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 13 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 14 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 36 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 46 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 52 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 61 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 70 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 73 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 74 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 77 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 78 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 81 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 82 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 86 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 87 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 91 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_234702-amfb01pg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/amfb01pg
Training model 6. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.51661073883541, Training Loss Force: 16.720879398021143, time: 0.6348166465759277
Validation Loss Energy: 16.41917748242322, Validation Loss Force: 7.899304185082448, time: 0.05981636047363281
Test Loss Energy: 13.43150875629692, Test Loss Force: 12.651809621545418, time: 8.549737215042114


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.705303828702215, Training Loss Force: 5.915208634814683, time: 0.6393051147460938
Validation Loss Energy: 9.679768902612498, Validation Loss Force: 4.779569391741352, time: 0.05986952781677246
Test Loss Energy: 16.477543351077596, Test Loss Force: 10.636393754683583, time: 8.53162932395935


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.926805645270697, Training Loss Force: 4.531754421590435, time: 0.6464698314666748
Validation Loss Energy: 13.184375958563333, Validation Loss Force: 4.476666317799696, time: 0.057198286056518555
Test Loss Energy: 19.108840419543995, Test Loss Force: 10.491091971128256, time: 8.748320817947388


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.154193421146134, Training Loss Force: 4.998019200265603, time: 0.635054349899292
Validation Loss Energy: 7.358708700606402, Validation Loss Force: 5.004473467886816, time: 0.06946873664855957
Test Loss Energy: 9.49122737299932, Test Loss Force: 10.731808630867775, time: 8.635649681091309


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.841200947578377, Training Loss Force: 4.273566333366537, time: 0.6450738906860352
Validation Loss Energy: 5.100275309238226, Validation Loss Force: 4.257714855932319, time: 0.05954098701477051
Test Loss Energy: 10.296430971103423, Test Loss Force: 10.464297248495056, time: 8.714632987976074


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 9.470798600393321, Training Loss Force: 4.171111289754677, time: 0.667733907699585
Validation Loss Energy: 2.6900675106376264, Validation Loss Force: 3.790309606377007, time: 0.05585312843322754
Test Loss Energy: 10.351233182124405, Test Loss Force: 10.232686222621908, time: 8.624791145324707


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.171042360201524, Training Loss Force: 5.986969050421465, time: 0.6754724979400635
Validation Loss Energy: 1.995531604812145, Validation Loss Force: 6.847196923956569, time: 0.061187028884887695
Test Loss Energy: 12.058746952459105, Test Loss Force: 11.692638040664587, time: 8.839930772781372


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 20.389814598466103, Training Loss Force: 6.599140003535951, time: 0.6649975776672363
Validation Loss Energy: 55.28126190650704, Validation Loss Force: 7.431727925623064, time: 0.06216001510620117
Test Loss Energy: 43.48989864790645, Test Loss Force: 11.642378424780606, time: 11.045633554458618


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 20.345225815547465, Training Loss Force: 7.354707396782032, time: 0.7122032642364502
Validation Loss Energy: 38.63158088692572, Validation Loss Force: 8.510392045107167, time: 0.06312751770019531
Test Loss Energy: 28.630989043104986, Test Loss Force: 12.448123703470904, time: 10.936023473739624


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 16.063292279109035, Training Loss Force: 8.711299826495356, time: 0.650254487991333
Validation Loss Energy: 6.2577794478826885, Validation Loss Force: 7.011962071831565, time: 0.06854009628295898
Test Loss Energy: 13.666315026123778, Test Loss Force: 12.108113658073071, time: 9.302205562591553


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.229907283250935, Training Loss Force: 5.763792350418185, time: 0.6208181381225586
Validation Loss Energy: 27.70441764747258, Validation Loss Force: 5.266312120605615, time: 0.05902576446533203
Test Loss Energy: 20.279740364318453, Test Loss Force: 10.793564363304245, time: 9.246938228607178


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 16.835752214077807, Training Loss Force: 6.635086111285212, time: 0.6209361553192139
Validation Loss Energy: 14.852811375394197, Validation Loss Force: 5.985627205662807, time: 0.058114051818847656
Test Loss Energy: 11.441841729260824, Test Loss Force: 11.006581736733315, time: 9.417319536209106


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 16.991488077478806, Training Loss Force: 8.002232734633122, time: 0.6089606285095215
Validation Loss Energy: 2.395596360579391, Validation Loss Force: 7.852095208777714, time: 0.05947232246398926
Test Loss Energy: 9.335963278590619, Test Loss Force: 12.67258172435318, time: 9.200589895248413


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.431363699628275, Training Loss Force: 6.088108099138243, time: 0.6055803298950195
Validation Loss Energy: 12.01958029606632, Validation Loss Force: 4.726582819107229, time: 0.05762314796447754
Test Loss Energy: 20.66874619749704, Test Loss Force: 10.641313581664768, time: 9.237030029296875


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.157722715629733, Training Loss Force: 4.331826025137297, time: 0.6146230697631836
Validation Loss Energy: 9.931954625186183, Validation Loss Force: 4.3251764817357685, time: 0.05831432342529297
Test Loss Energy: 17.856622495425498, Test Loss Force: 10.387338403564687, time: 9.165396451950073


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.10100654107523, Training Loss Force: 4.1777243255376, time: 0.834507942199707
Validation Loss Energy: 6.879618219611093, Validation Loss Force: 4.169189174262391, time: 0.05862879753112793
Test Loss Energy: 18.031822310024026, Test Loss Force: 10.27170263213412, time: 9.180989027023315


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.078868450704695, Training Loss Force: 4.0845789625217455, time: 0.650515079498291
Validation Loss Energy: 8.617940351913704, Validation Loss Force: 4.1107371874414715, time: 0.061940670013427734
Test Loss Energy: 21.861715597129926, Test Loss Force: 10.44261343794446, time: 9.22338581085205


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.133129723228656, Training Loss Force: 3.9986368451634076, time: 0.6274843215942383
Validation Loss Energy: 15.42665025001153, Validation Loss Force: 4.212034503314379, time: 0.06445050239562988
Test Loss Energy: 24.762805205933546, Test Loss Force: 10.409667143236769, time: 9.166126489639282


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.698726205891054, Training Loss Force: 4.018197970326133, time: 0.6292834281921387
Validation Loss Energy: 8.911412051510442, Validation Loss Force: 4.621888462744048, time: 0.057634830474853516
Test Loss Energy: 19.58050148736088, Test Loss Force: 10.610458544280123, time: 9.301172494888306


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.435151715602524, Training Loss Force: 3.954473233796929, time: 0.6201267242431641
Validation Loss Energy: 8.736794461935581, Validation Loss Force: 4.27528679158321, time: 0.058165788650512695
Test Loss Energy: 19.37151710682931, Test Loss Force: 10.473241516013246, time: 9.530822038650513

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–â–â–â–‚â–ˆâ–…â–‚â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒ
wandb:   test_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–…â–…â–‡â–†â–ƒâ–ƒâ–ˆâ–‚â–â–â–‚â–‚â–‚â–‚
wandb:          test_loss â–„â–‚â–ƒâ–â–â–â–ƒâ–ˆâ–†â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‡â–‡â–…â–‚â–†â–†â–â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–‚â–ƒâ–„â–„â–‚â–ƒâ–„â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–‚â–‚â–‚â–â–â–â–ˆâ–†â–‚â–„â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb:  valid_error_force â–‡â–‚â–‚â–ƒâ–‚â–â–†â–†â–ˆâ–†â–ƒâ–„â–‡â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:         valid_loss â–„â–‚â–‚â–‚â–â–â–‚â–ˆâ–‡â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1385
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 19.37152
wandb:   test_error_force 10.47324
wandb:          test_loss 4.80073
wandb: train_error_energy 8.43515
wandb:  train_error_force 3.95447
wandb:         train_loss 1.88767
wandb: valid_error_energy 8.73679
wandb:  valid_error_force 4.27529
wandb:         valid_loss 2.0152
wandb: 
wandb: ğŸš€ View run al_74_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/amfb01pg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_234702-amfb01pg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.093198537826538, Uncertainty Bias: 0.1789204329252243
1.9073486e-05 0.5385113
2.7864077 4.820129
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 2 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 3 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 2 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 2 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 4 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 2 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 2 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 49 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 61 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 68 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 5 steps.
Found uncertainty sample 93 after 3 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_235303-ko0knswc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/ko0knswc
Training model 7. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 26.36558529182602, Training Loss Force: 12.93274055093971, time: 0.689096212387085
Validation Loss Energy: 17.77828582045241, Validation Loss Force: 7.273773113576269, time: 0.06024956703186035
Test Loss Energy: 14.135190845672376, Test Loss Force: 12.489666449496005, time: 9.395592212677002


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 13.127768529783792, Training Loss Force: 7.23375022965231, time: 0.6825294494628906
Validation Loss Energy: 13.886920271556681, Validation Loss Force: 5.384715102937841, time: 0.06205248832702637
Test Loss Energy: 21.562042396274503, Test Loss Force: 10.323842568877335, time: 9.272897005081177


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 12.696248762964876, Training Loss Force: 6.42826794135537, time: 0.67905592918396
Validation Loss Energy: 2.025023576517416, Validation Loss Force: 6.484334393076063, time: 0.06086874008178711
Test Loss Energy: 10.430032458660097, Test Loss Force: 11.72033885651388, time: 9.433568954467773


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 17.486000952141108, Training Loss Force: 8.269111946654817, time: 0.6853542327880859
Validation Loss Energy: 4.754924370670064, Validation Loss Force: 5.976636493557679, time: 0.0613250732421875
Test Loss Energy: 14.554577727069768, Test Loss Force: 11.157843065289624, time: 9.287303686141968


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.136475066575944, Training Loss Force: 4.907838630735774, time: 0.6656637191772461
Validation Loss Energy: 5.581143135356331, Validation Loss Force: 4.974631794287866, time: 0.06170773506164551
Test Loss Energy: 15.412007135264151, Test Loss Force: 10.52423817842832, time: 9.212526082992554


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.023317690819994, Training Loss Force: 4.270511405391436, time: 0.6938314437866211
Validation Loss Energy: 11.315298273058152, Validation Loss Force: 4.187339381685257, time: 0.0628061294555664
Test Loss Energy: 10.484618780868933, Test Loss Force: 10.34988676824998, time: 9.544774293899536


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.287617676163826, Training Loss Force: 4.174350341855949, time: 0.6659777164459229
Validation Loss Energy: 5.398442210445998, Validation Loss Force: 4.937619951520896, time: 0.06382107734680176
Test Loss Energy: 10.85702156314607, Test Loss Force: 10.912525874466107, time: 9.36950945854187


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.343880218862175, Training Loss Force: 4.158358727034837, time: 0.7310400009155273
Validation Loss Energy: 10.636617412433885, Validation Loss Force: 4.093036994362526, time: 0.05934906005859375
Test Loss Energy: 20.94951239562714, Test Loss Force: 10.416500819687855, time: 9.265403509140015


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 8.74809494004198, Training Loss Force: 4.056910820492304, time: 0.6762831211090088
Validation Loss Energy: 4.3133643288825905, Validation Loss Force: 4.618031387798287, time: 0.060211896896362305
Test Loss Energy: 15.329489624407122, Test Loss Force: 10.390368475976016, time: 9.892941951751709


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 17.92856443585296, Training Loss Force: 4.770629784574037, time: 0.7261145114898682
Validation Loss Energy: 14.525670319580009, Validation Loss Force: 5.864231550009311, time: 0.05914616584777832
Test Loss Energy: 23.52003459041068, Test Loss Force: 11.476211735513367, time: 9.270876407623291


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.535656093774385, Training Loss Force: 6.37751665899967, time: 0.6825597286224365
Validation Loss Energy: 8.327793102665668, Validation Loss Force: 5.486398304440641, time: 0.05963778495788574
Test Loss Energy: 18.248053860113252, Test Loss Force: 11.02840739802213, time: 9.297065496444702


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 19.309466961878123, Training Loss Force: 6.912973238059111, time: 0.674813985824585
Validation Loss Energy: 32.26334485052152, Validation Loss Force: 9.309203355297766, time: 0.06293845176696777
Test Loss Energy: 26.630414981817125, Test Loss Force: 13.93073061721033, time: 9.526469707489014


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.232497897843194, Training Loss Force: 8.373567180043478, time: 0.6881203651428223
Validation Loss Energy: 16.755258259108118, Validation Loss Force: 8.336786709469692, time: 0.06067848205566406
Test Loss Energy: 22.785033444466603, Test Loss Force: 13.391917179556899, time: 9.328121423721313


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.39254808814251, Training Loss Force: 7.210036922614564, time: 0.6727163791656494
Validation Loss Energy: 8.912384225001563, Validation Loss Force: 8.790656792320636, time: 0.06221413612365723
Test Loss Energy: 17.39736266742574, Test Loss Force: 12.685971563882715, time: 9.406062841415405


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.547614133345537, Training Loss Force: 7.270776337457544, time: 0.6778688430786133
Validation Loss Energy: 13.473898398187897, Validation Loss Force: 6.386407620065064, time: 0.060254812240600586
Test Loss Energy: 23.713147897642852, Test Loss Force: 11.469239542532215, time: 9.472833156585693


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 13.385634139570575, Training Loss Force: 6.49418552244926, time: 0.7023837566375732
Validation Loss Energy: 8.153911211948952, Validation Loss Force: 4.84002874091281, time: 0.06084585189819336
Test Loss Energy: 9.990481666664772, Test Loss Force: 10.906813615792656, time: 9.346997261047363


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 13.03077230534655, Training Loss Force: 5.911054948630845, time: 0.6969771385192871
Validation Loss Energy: 6.167091871474948, Validation Loss Force: 7.319248833249102, time: 0.06168508529663086
Test Loss Energy: 9.753637962494604, Test Loss Force: 12.905681238673923, time: 9.28553318977356


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.734547200163587, Training Loss Force: 5.295840143393141, time: 0.640972375869751
Validation Loss Energy: 5.833249142375773, Validation Loss Force: 5.123961739636295, time: 0.05975604057312012
Test Loss Energy: 17.39880137124921, Test Loss Force: 10.664964658964145, time: 9.605133533477783


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.237707543088613, Training Loss Force: 4.18610604097417, time: 0.6443345546722412
Validation Loss Energy: 2.3168360569732735, Validation Loss Force: 4.560895152960654, time: 0.06401252746582031
Test Loss Energy: 12.170223618649079, Test Loss Force: 10.691051139826762, time: 9.381160974502563


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.527102755722128, Training Loss Force: 4.04258195672374, time: 0.6481034755706787
Validation Loss Energy: 3.644569421664654, Validation Loss Force: 4.601398670604919, time: 0.0649867057800293
Test Loss Energy: 11.932389836523168, Test Loss Force: 10.858552253808758, time: 9.305951595306396

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–â–ƒâ–ƒâ–â–â–†â–ƒâ–‡â–…â–ˆâ–†â–„â–‡â–â–â–„â–‚â–‚
wandb:   test_error_force â–…â–â–„â–ƒâ–â–â–‚â–â–â–ƒâ–‚â–ˆâ–‡â–†â–ƒâ–‚â–†â–‚â–‚â–‚
wandb:          test_loss â–„â–ƒâ–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–…â–ƒâ–ˆâ–‡â–…â–…â–â–ƒâ–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–…â–â–â–â–â–â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–„â–ƒâ–„â–‚â–â–â–â–â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–„â–â–â–â–â–â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–
wandb: valid_error_energy â–…â–„â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–„â–‚â–ˆâ–„â–ƒâ–„â–‚â–‚â–‚â–â–
wandb:  valid_error_force â–…â–ƒâ–„â–„â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–ˆâ–‡â–‡â–„â–‚â–…â–‚â–‚â–‚
wandb:         valid_loss â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ˆâ–…â–…â–„â–‚â–ƒâ–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1475
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.93239
wandb:   test_error_force 10.85855
wandb:          test_loss 4.43183
wandb: train_error_energy 8.5271
wandb:  train_error_force 4.04258
wandb:         train_loss 1.9233
wandb: valid_error_energy 3.64457
wandb:  valid_error_force 4.6014
wandb:         valid_loss 1.78354
wandb: 
wandb: ğŸš€ View run al_74_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/ko0knswc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_235303-ko0knswc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.592167377471924, Uncertainty Bias: 0.0545809268951416
0.00034713745 0.007281542
0.89369607 5.762628
(48745, 22, 3)
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 2 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 2 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 2 steps.
Found uncertainty sample 16 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 2 steps.
Found uncertainty sample 31 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 4 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 5 steps.
Found uncertainty sample 49 after 7 steps.
Found uncertainty sample 50 after 2 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 2 steps.
Found uncertainty sample 55 after 2 steps.
Found uncertainty sample 56 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 9 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 3 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 7 steps.
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 2 steps.
Found uncertainty sample 71 after 2 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 4 steps.
Found uncertainty sample 78 after 2 steps.
Found uncertainty sample 79 after 2 steps.
Found uncertainty sample 80 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 4 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 2 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 7 steps.
Found uncertainty sample 95 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 2 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_235908-wyax7ed5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/wyax7ed5
Training model 8. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.13019912507064, Training Loss Force: 15.850890812972645, time: 0.708702802658081
Validation Loss Energy: 10.165857429526028, Validation Loss Force: 7.474682585225702, time: 0.06266331672668457
Test Loss Energy: 10.617071878536144, Test Loss Force: 12.106201389437528, time: 9.399266719818115


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.4988942870367, Training Loss Force: 6.718138086924626, time: 0.7074458599090576
Validation Loss Energy: 38.625146639284985, Validation Loss Force: 8.44603220050649, time: 0.06184029579162598
Test Loss Energy: 27.856420303403457, Test Loss Force: 12.616198921464685, time: 9.369034051895142


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 17.40496930035791, Training Loss Force: 8.051669610759383, time: 0.6962120532989502
Validation Loss Energy: 21.891995863661165, Validation Loss Force: 7.212321773359702, time: 0.06305932998657227
Test Loss Energy: 32.83889147857581, Test Loss Force: 12.565000154739986, time: 9.616500616073608


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 12.965709685884939, Training Loss Force: 6.192845557679543, time: 0.6877989768981934
Validation Loss Energy: 14.387921396511285, Validation Loss Force: 4.684906503071363, time: 0.0658273696899414
Test Loss Energy: 24.315321642582838, Test Loss Force: 10.421206865636037, time: 9.420132875442505


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.251022134018784, Training Loss Force: 5.072456548475883, time: 0.7232160568237305
Validation Loss Energy: 6.35605380743048, Validation Loss Force: 4.236923569769603, time: 0.06387042999267578
Test Loss Energy: 18.071438662495407, Test Loss Force: 10.42748237698928, time: 9.483672618865967


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.091093728358091, Training Loss Force: 4.153249953307614, time: 0.7036070823669434
Validation Loss Energy: 3.3753540741449863, Validation Loss Force: 3.961579588011992, time: 0.061547279357910156
Test Loss Energy: 15.312236015867768, Test Loss Force: 10.245419069258636, time: 9.67805290222168


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.257454575591892, Training Loss Force: 4.107587027958544, time: 0.7188549041748047
Validation Loss Energy: 3.990547285213175, Validation Loss Force: 4.464990883802118, time: 0.0672149658203125
Test Loss Energy: 10.39344665891255, Test Loss Force: 10.472310903543343, time: 9.558062314987183


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.607759398103656, Training Loss Force: 4.493918555088254, time: 0.7168838977813721
Validation Loss Energy: 43.336530062491185, Validation Loss Force: 6.936462089860122, time: 0.06439089775085449
Test Loss Energy: 30.141002728177153, Test Loss Force: 11.675367896318079, time: 9.426651000976562


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 20.063471105629304, Training Loss Force: 6.972435540058535, time: 0.7272396087646484
Validation Loss Energy: 5.991308163582862, Validation Loss Force: 8.556284601421176, time: 0.06156730651855469
Test Loss Energy: 10.200107721384551, Test Loss Force: 12.299739255616755, time: 9.677329778671265


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.337849414013082, Training Loss Force: 5.634297727765996, time: 0.7217164039611816
Validation Loss Energy: 3.471995823514835, Validation Loss Force: 4.531151231116766, time: 0.06294035911560059
Test Loss Energy: 9.585944252525259, Test Loss Force: 10.514606042783496, time: 9.488209962844849


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.929058558743389, Training Loss Force: 4.148687357989383, time: 0.6917393207550049
Validation Loss Energy: 7.417407627510157, Validation Loss Force: 3.871637285235672, time: 0.06275534629821777
Test Loss Energy: 17.568111719839955, Test Loss Force: 10.207437887077473, time: 9.85664439201355


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.821994766365586, Training Loss Force: 3.974497943005065, time: 0.7402529716491699
Validation Loss Energy: 4.443187789040307, Validation Loss Force: 4.133653627932922, time: 0.06115221977233887
Test Loss Energy: 16.850325099919804, Test Loss Force: 10.256778250115413, time: 9.748583555221558


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.055421085998754, Training Loss Force: 3.8428018535071695, time: 0.6886789798736572
Validation Loss Energy: 11.002155981110153, Validation Loss Force: 4.312291063599219, time: 0.06559062004089355
Test Loss Energy: 10.89230007350368, Test Loss Force: 10.535988426927315, time: 9.454379558563232


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.457693310970436, Training Loss Force: 3.811349723038162, time: 0.7014977931976318
Validation Loss Energy: 8.832270983664788, Validation Loss Force: 3.8692168716194377, time: 0.06501460075378418
Test Loss Energy: 12.029911106869097, Test Loss Force: 10.52734864489359, time: 9.491772174835205


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.144020684736592, Training Loss Force: 4.533184423088233, time: 0.6839132308959961
Validation Loss Energy: 11.136267381011, Validation Loss Force: 6.517712943388929, time: 0.06226634979248047
Test Loss Energy: 10.598290102140547, Test Loss Force: 11.319200725877403, time: 9.669913291931152


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.45794238644083, Training Loss Force: 5.951898410416199, time: 0.6953892707824707
Validation Loss Energy: 8.664798846982748, Validation Loss Force: 4.794775245047614, time: 0.06162118911743164
Test Loss Energy: 18.931719084465197, Test Loss Force: 10.484194739540209, time: 9.430461406707764


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.545265459598236, Training Loss Force: 4.289804815353433, time: 0.7368569374084473
Validation Loss Energy: 11.839363468147958, Validation Loss Force: 5.204062734170044, time: 0.06135082244873047
Test Loss Energy: 21.19650243096139, Test Loss Force: 11.02935998828648, time: 9.477351665496826


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.951860358706699, Training Loss Force: 4.597134674611377, time: 0.770195484161377
Validation Loss Energy: 4.834622111380538, Validation Loss Force: 4.044912847868028, time: 0.06322789192199707
Test Loss Energy: 11.24616078796694, Test Loss Force: 10.525156848370838, time: 9.671981811523438


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 14.118386961833368, Training Loss Force: 4.487615518649964, time: 0.741997241973877
Validation Loss Energy: 34.709463392962476, Validation Loss Force: 6.054312843761421, time: 0.061954498291015625
Test Loss Energy: 44.505163202717505, Test Loss Force: 11.61478200462073, time: 9.462974786758423


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 18.54764792504656, Training Loss Force: 8.608531508050941, time: 0.7758581638336182
Validation Loss Energy: 2.893098462574886, Validation Loss Force: 6.0322347526043885, time: 0.06273055076599121
Test Loss Energy: 11.517397157015413, Test Loss Force: 11.087373895130217, time: 9.488616228103638

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–†â–„â–ƒâ–‚â–â–…â–â–â–ƒâ–‚â–â–â–â–ƒâ–ƒâ–â–ˆâ–
wandb:   test_error_force â–‡â–ˆâ–ˆâ–‚â–‚â–â–‚â–…â–‡â–‚â–â–â–‚â–‚â–„â–‚â–ƒâ–‚â–…â–„
wandb:          test_loss â–ƒâ–†â–‡â–ƒâ–‚â–‚â–â–†â–ƒâ–â–‚â–‚â–â–â–‚â–ƒâ–ƒâ–â–ˆâ–‚
wandb: train_error_energy â–ˆâ–ƒâ–†â–„â–‚â–â–â–‚â–‡â–â–â–â–â–‚â–â–ƒâ–‚â–â–„â–‡
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–â–â–ƒâ–‚â–â–â–â–â–â–‚â–â–â–â–„
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–‚â–â–â–â–„â–‚â–â–â–â–â–â–‚â–â–â–‚â–„
wandb: valid_error_energy â–‚â–‡â–„â–ƒâ–‚â–â–â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–â–‡â–
wandb:  valid_error_force â–†â–ˆâ–†â–‚â–‚â–â–‚â–†â–ˆâ–‚â–â–â–‚â–â–…â–‚â–ƒâ–â–„â–„
wandb:         valid_loss â–„â–ˆâ–…â–ƒâ–‚â–â–â–ˆâ–„â–â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–â–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1565
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.5174
wandb:   test_error_force 11.08737
wandb:          test_loss 4.48062
wandb: train_error_energy 18.54765
wandb:  train_error_force 8.60853
wandb:         train_loss 4.12166
wandb: valid_error_energy 2.8931
wandb:  valid_error_force 6.03223
wandb:         valid_loss 2.21201
wandb: 
wandb: ğŸš€ View run al_74_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/wyax7ed5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_235908-wyax7ed5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.566739082336426, Uncertainty Bias: -0.08676247298717499
6.1035156e-05 0.0060300827
-1.0020765 7.119036
(48745, 22, 3)
Found uncertainty sample 0 after 31 steps.
Found uncertainty sample 1 after 7 steps.
Found uncertainty sample 2 after 3 steps.
Found uncertainty sample 3 after 20 steps.
Found uncertainty sample 4 after 10 steps.
Found uncertainty sample 5 after 9 steps.
Found uncertainty sample 6 after 17 steps.
Found uncertainty sample 7 after 6 steps.
Found uncertainty sample 8 after 6 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 13 steps.
Found uncertainty sample 11 after 3 steps.
Found uncertainty sample 12 after 2 steps.
Found uncertainty sample 13 after 20 steps.
Found uncertainty sample 14 after 43 steps.
Found uncertainty sample 15 after 14 steps.
Found uncertainty sample 16 after 10 steps.
Found uncertainty sample 17 after 3 steps.
Found uncertainty sample 18 after 10 steps.
Found uncertainty sample 19 after 20 steps.
Found uncertainty sample 20 after 4 steps.
Found uncertainty sample 21 after 3 steps.
Found uncertainty sample 22 after 2 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 26 steps.
Found uncertainty sample 25 after 3 steps.
Found uncertainty sample 26 after 8 steps.
Found uncertainty sample 27 after 3 steps.
Found uncertainty sample 28 after 14 steps.
Found uncertainty sample 29 after 7 steps.
Found uncertainty sample 30 after 3 steps.
Found uncertainty sample 31 after 2 steps.
Found uncertainty sample 32 after 11 steps.
Found uncertainty sample 33 after 4 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 3 steps.
Found uncertainty sample 36 after 2 steps.
Found uncertainty sample 37 after 2 steps.
Found uncertainty sample 38 after 2 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 14 steps.
Found uncertainty sample 41 after 3 steps.
Found uncertainty sample 42 after 8 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 14 steps.
Found uncertainty sample 46 after 4 steps.
Found uncertainty sample 47 after 6 steps.
Found uncertainty sample 48 after 9 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 36 steps.
Found uncertainty sample 53 after 2 steps.
Found uncertainty sample 54 after 10 steps.
Found uncertainty sample 55 after 26 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 18 steps.
Found uncertainty sample 58 after 20 steps.
Found uncertainty sample 59 after 24 steps.
Found uncertainty sample 60 after 6 steps.
Found uncertainty sample 61 after 2 steps.
Found uncertainty sample 62 after 4 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 16 steps.
Found uncertainty sample 67 after 9 steps.
Found uncertainty sample 68 after 19 steps.
Found uncertainty sample 69 after 9 steps.
Found uncertainty sample 70 after 7 steps.
Found uncertainty sample 71 after 18 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 12 steps.
Found uncertainty sample 75 after 61 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 42 steps.
Found uncertainty sample 78 after 6 steps.
Found uncertainty sample 79 after 6 steps.
Found uncertainty sample 80 after 11 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 48 steps.
Found uncertainty sample 83 after 39 steps.
Found uncertainty sample 84 after 13 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 14 steps.
Found uncertainty sample 87 after 29 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 5 steps.
Found uncertainty sample 90 after 62 steps.
Found uncertainty sample 91 after 24 steps.
Found uncertainty sample 92 after 11 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 9 steps.
Found uncertainty sample 97 after 6 steps.
Found uncertainty sample 98 after 15 steps.
Found uncertainty sample 99 after 24 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_000535-islju9y4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/islju9y4
Training model 9. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 20.363892948614037, Training Loss Force: 9.797253665900502, time: 0.8013441562652588
Validation Loss Energy: 4.241776866474245, Validation Loss Force: 6.956598283395518, time: 0.06519722938537598
Test Loss Energy: 11.353207298777964, Test Loss Force: 12.207333196849818, time: 9.908063650131226


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.542242701229375, Training Loss Force: 7.013847402925938, time: 0.7351353168487549
Validation Loss Energy: 15.491170861735567, Validation Loss Force: 5.223019671908606, time: 0.06714153289794922
Test Loss Energy: 23.686082670468988, Test Loss Force: 10.852039985697234, time: 9.525305271148682


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.264479281404432, Training Loss Force: 6.238589341291549, time: 0.7483632564544678
Validation Loss Energy: 2.5377883124513847, Validation Loss Force: 4.850816170356428, time: 0.062433719635009766
Test Loss Energy: 10.540647057171293, Test Loss Force: 10.947605325602103, time: 9.76451563835144


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.783336674535368, Training Loss Force: 5.792641586855172, time: 0.7445998191833496
Validation Loss Energy: 7.4035438011464, Validation Loss Force: 5.524661325138581, time: 0.062345266342163086
Test Loss Energy: 18.514066238458813, Test Loss Force: 11.202440286399156, time: 9.661863088607788


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 7.78240205702526, Training Loss Force: 4.438286806881646, time: 0.7516746520996094
Validation Loss Energy: 6.9592313460461135, Validation Loss Force: 4.368314843383796, time: 0.06367635726928711
Test Loss Energy: 16.811402388651548, Test Loss Force: 10.453982271683584, time: 9.5240797996521


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.883354685342369, Training Loss Force: 3.960340053108096, time: 0.7691643238067627
Validation Loss Energy: 8.891721864274341, Validation Loss Force: 3.89111883148204, time: 0.06466388702392578
Test Loss Energy: 21.562830323288342, Test Loss Force: 10.149324979899328, time: 9.743244409561157


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.086716575015666, Training Loss Force: 3.929793760125254, time: 0.7610998153686523
Validation Loss Energy: 4.965935005455365, Validation Loss Force: 3.956635887634103, time: 0.06249594688415527
Test Loss Energy: 16.680289479449133, Test Loss Force: 10.519409410303941, time: 9.608890295028687


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.15150654789269, Training Loss Force: 3.9156880936585248, time: 0.7913763523101807
Validation Loss Energy: 3.6153864033993584, Validation Loss Force: 4.027265427376667, time: 0.06798386573791504
Test Loss Energy: 17.594176022389316, Test Loss Force: 10.343505578819562, time: 9.592387437820435


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 8.472423155363654, Training Loss Force: 3.80419444928246, time: 0.762047290802002
Validation Loss Energy: 1.885571735487923, Validation Loss Force: 4.340406605978938, time: 0.06374168395996094
Test Loss Energy: 14.963250254140851, Test Loss Force: 10.651705189305035, time: 9.781139135360718


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 16.38046559498388, Training Loss Force: 5.443616281939681, time: 0.7460360527038574
Validation Loss Energy: 8.770792032474127, Validation Loss Force: 7.351819317231397, time: 0.06745195388793945
Test Loss Energy: 19.06770126192879, Test Loss Force: 12.544436516885094, time: 9.638994216918945


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 9.917396041112438, Training Loss Force: 6.351674333539975, time: 0.7704305648803711
Validation Loss Energy: 9.821198101325116, Validation Loss Force: 5.372752648411163, time: 0.07040548324584961
Test Loss Energy: 18.84368826690208, Test Loss Force: 11.097127643102928, time: 9.607846975326538


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 12.697619330005844, Training Loss Force: 5.3263157688057365, time: 0.7354443073272705
Validation Loss Energy: 13.292256042397305, Validation Loss Force: 5.415064239520362, time: 0.07372498512268066
Test Loss Energy: 10.79190643646048, Test Loss Force: 11.038151320573053, time: 9.814618587493896


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.388177923059207, Training Loss Force: 7.094485158564343, time: 0.7408959865570068
Validation Loss Energy: 1.970215904273323, Validation Loss Force: 5.89104893126827, time: 0.06869888305664062
Test Loss Energy: 10.66629717641857, Test Loss Force: 11.407985372929847, time: 10.070479393005371


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.040197839191343, Training Loss Force: 6.449411923418915, time: 0.7397463321685791
Validation Loss Energy: 9.09345877447004, Validation Loss Force: 4.52024667770239, time: 0.06981325149536133
Test Loss Energy: 19.742842217072432, Test Loss Force: 10.687219509785603, time: 9.592327356338501


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.784787216120757, Training Loss Force: 4.282093616090264, time: 0.7387096881866455
Validation Loss Energy: 4.012679484972669, Validation Loss Force: 3.9475601159152323, time: 0.06244015693664551
Test Loss Energy: 15.911158357596985, Test Loss Force: 10.264148799364436, time: 9.744115829467773


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.695794896998747, Training Loss Force: 4.0018229938370204, time: 0.7076168060302734
Validation Loss Energy: 12.051654895860635, Validation Loss Force: 4.45731970905576, time: 0.06214618682861328
Test Loss Energy: 24.154081406744037, Test Loss Force: 10.572715559794752, time: 9.642139911651611


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.98641709097085, Training Loss Force: 3.927385285000919, time: 0.7716670036315918
Validation Loss Energy: 8.737681130474664, Validation Loss Force: 4.055675561036448, time: 0.06612443923950195
Test Loss Energy: 19.85990468917712, Test Loss Force: 10.46929747419341, time: 9.647348642349243


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.081874386075727, Training Loss Force: 3.8109775595254716, time: 0.8494553565979004
Validation Loss Energy: 6.288634934103047, Validation Loss Force: 4.158671842492785, time: 0.09276056289672852
Test Loss Energy: 19.04528409812383, Test Loss Force: 10.451891312807149, time: 9.7328200340271


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.06053619023382, Training Loss Force: 3.8222355873627114, time: 0.7423171997070312
Validation Loss Energy: 7.619022515013889, Validation Loss Force: 4.406497035181764, time: 0.06729340553283691
Test Loss Energy: 20.09731034498642, Test Loss Force: 10.845148634439928, time: 9.60660171508789


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.12036263661477, Training Loss Force: 3.79269753599053, time: 0.7347023487091064
Validation Loss Energy: 10.984713416233046, Validation Loss Force: 4.177664184625549, time: 0.06609368324279785
Test Loss Energy: 23.41180956059288, Test Loss Force: 10.544882667333516, time: 9.796712160110474

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–â–…â–„â–‡â–„â–…â–ƒâ–…â–…â–â–â–†â–„â–ˆâ–†â–…â–†â–ˆ
wandb:   test_error_force â–‡â–ƒâ–ƒâ–„â–‚â–â–‚â–‚â–‚â–ˆâ–„â–„â–…â–ƒâ–â–‚â–‚â–‚â–ƒâ–‚
wandb:          test_loss â–„â–†â–â–…â–ƒâ–„â–ƒâ–ƒâ–‚â–ˆâ–…â–â–‚â–„â–‚â–†â–„â–„â–…â–†
wandb: train_error_energy â–ˆâ–„â–‚â–„â–â–â–â–â–â–†â–‚â–„â–ƒâ–‚â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–„â–ƒâ–‚â–â–â–â–â–ƒâ–„â–ƒâ–…â–„â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–ƒâ–„â–â–â–â–â–â–„â–ƒâ–ƒâ–„â–ƒâ–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–â–„â–„â–…â–ƒâ–‚â–â–…â–…â–‡â–â–…â–‚â–†â–…â–ƒâ–„â–†
wandb:  valid_error_force â–‡â–„â–ƒâ–„â–‚â–â–â–â–‚â–ˆâ–„â–„â–…â–‚â–â–‚â–â–‚â–‚â–‚
wandb:         valid_loss â–†â–‡â–‚â–…â–ƒâ–ƒâ–â–â–â–ˆâ–…â–†â–„â–„â–â–„â–ƒâ–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1655
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 23.41181
wandb:   test_error_force 10.54488
wandb:          test_loss 5.09508
wandb: train_error_energy 8.12036
wandb:  train_error_force 3.7927
wandb:         train_loss 1.81247
wandb: valid_error_energy 10.98471
wandb:  valid_error_force 4.17766
wandb:         valid_loss 2.13296
wandb: 
wandb: ğŸš€ View run al_74_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/islju9y4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_000535-islju9y4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0203168392181396, Uncertainty Bias: 0.13136081397533417
0.0001296997 0.10962057
2.2777781 5.8156343
(48745, 22, 3)
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 0 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 2 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 2 steps.
Found uncertainty sample 18 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 19 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 22 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 2 steps.
Found uncertainty sample 35 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 41 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 61 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 67 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 3 steps.
Found uncertainty sample 70 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 86 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 5 steps.
Found uncertainty sample 92 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_001150-jt8e24de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jt8e24de
Training model 10. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.233457188396585, Training Loss Force: 13.83204617710636, time: 0.8142740726470947
Validation Loss Energy: 5.398491865665539, Validation Loss Force: 7.553725233308857, time: 0.06486296653747559
Test Loss Energy: 11.25175379390597, Test Loss Force: 12.078934398369691, time: 9.50395655632019


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 15.145501554871089, Training Loss Force: 7.388084230518209, time: 0.7860612869262695
Validation Loss Energy: 5.8063418027818585, Validation Loss Force: 7.991813417773023, time: 0.07186269760131836
Test Loss Energy: 10.647753490464519, Test Loss Force: 12.065129657438682, time: 9.563390016555786


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.353762620224552, Training Loss Force: 6.9003376686588025, time: 0.812572717666626
Validation Loss Energy: 9.498339863863706, Validation Loss Force: 10.105586681121169, time: 0.06928443908691406
Test Loss Energy: 20.346440102574263, Test Loss Force: 14.705685868580137, time: 10.082625389099121


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.194662305506546, Training Loss Force: 7.301833741696071, time: 0.7546560764312744
Validation Loss Energy: 12.287493585755175, Validation Loss Force: 5.797108381307671, time: 0.06487131118774414
Test Loss Energy: 22.027927179294927, Test Loss Force: 11.441082355193172, time: 9.52778935432434


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 13.414325737798173, Training Loss Force: 5.444752732941033, time: 0.767470121383667
Validation Loss Energy: 12.407927310698263, Validation Loss Force: 6.84096441456205, time: 0.06687736511230469
Test Loss Energy: 19.94458728092262, Test Loss Force: 12.086892248566269, time: 9.542637348175049


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.218262748966218, Training Loss Force: 6.025983915514897, time: 0.7922215461730957
Validation Loss Energy: 14.200702514630077, Validation Loss Force: 5.370907611868005, time: 0.070037841796875
Test Loss Energy: 10.85423285476247, Test Loss Force: 10.968438796492807, time: 9.691554307937622


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.318584081681344, Training Loss Force: 4.206095062952669, time: 0.7932462692260742
Validation Loss Energy: 6.951567742050717, Validation Loss Force: 3.7914187213928736, time: 0.06360793113708496
Test Loss Energy: 19.10211206210151, Test Loss Force: 10.434957853535737, time: 9.613531112670898


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.091500277023743, Training Loss Force: 3.825834140705078, time: 0.786306619644165
Validation Loss Energy: 10.391761958144144, Validation Loss Force: 4.062259665012387, time: 0.06739568710327148
Test Loss Energy: 21.374701410094833, Test Loss Force: 10.470489190135963, time: 9.496561765670776


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.926763642945012, Training Loss Force: 4.253267019499761, time: 0.831960916519165
Validation Loss Energy: 10.824289203357912, Validation Loss Force: 5.1036440707469675, time: 0.06824779510498047
Test Loss Energy: 11.325502136799999, Test Loss Force: 11.014757415644958, time: 9.744243383407593


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 19.943644322577285, Training Loss Force: 6.648347364576114, time: 0.8190410137176514
Validation Loss Energy: 7.601297828328891, Validation Loss Force: 8.708119574661291, time: 0.06338238716125488
Test Loss Energy: 10.324738766723222, Test Loss Force: 13.774137731266524, time: 9.55508542060852


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.839611237968128, Training Loss Force: 7.949561129530182, time: 0.8432238101959229
Validation Loss Energy: 21.156738781101275, Validation Loss Force: 7.8071200493449275, time: 0.06409645080566406
Test Loss Energy: 14.41140337349853, Test Loss Force: 13.069226498879088, time: 9.530888557434082


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 14.28808998045103, Training Loss Force: 6.432418935955922, time: 0.8112456798553467
Validation Loss Energy: 11.182497949088528, Validation Loss Force: 7.115517475513325, time: 0.06406521797180176
Test Loss Energy: 10.64389409556273, Test Loss Force: 12.582644206048979, time: 9.807509899139404


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 13.272359894298276, Training Loss Force: 5.652271194879859, time: 0.7969644069671631
Validation Loss Energy: 7.2324555175344925, Validation Loss Force: 6.014209239903243, time: 0.06404709815979004
Test Loss Energy: 9.810793513589193, Test Loss Force: 11.560816026994376, time: 9.532353401184082


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.898970690196991, Training Loss Force: 6.533190311354676, time: 0.8120322227478027
Validation Loss Energy: 11.055556050348263, Validation Loss Force: 6.442830200289999, time: 0.06651163101196289
Test Loss Energy: 10.51666703109238, Test Loss Force: 11.616202372630969, time: 9.540550231933594


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.049432375027848, Training Loss Force: 4.468727077741351, time: 0.7918121814727783
Validation Loss Energy: 7.846813941974599, Validation Loss Force: 4.2675018329032826, time: 0.06392645835876465
Test Loss Energy: 10.943995716518153, Test Loss Force: 10.56441994265414, time: 10.148927450180054


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.074295251542981, Training Loss Force: 3.931840378656938, time: 0.80940842628479
Validation Loss Energy: 10.991523974730393, Validation Loss Force: 4.188388821370015, time: 0.06380558013916016
Test Loss Energy: 22.828679777390064, Test Loss Force: 10.498963183208343, time: 9.571044445037842


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.048561584823133, Training Loss Force: 3.9481802575837017, time: 0.805063009262085
Validation Loss Energy: 6.646035168164801, Validation Loss Force: 3.971636662656967, time: 0.06413865089416504
Test Loss Energy: 15.805785857103752, Test Loss Force: 10.451757170385122, time: 9.499939203262329


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.974093514957762, Training Loss Force: 4.1318907158193126, time: 0.8416647911071777
Validation Loss Energy: 18.961580835593104, Validation Loss Force: 5.2389491999391335, time: 0.09543919563293457
Test Loss Energy: 27.638853801654697, Test Loss Force: 11.53933213836261, time: 9.675483703613281


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 18.17854733072553, Training Loss Force: 5.927126239726843, time: 0.7695214748382568
Validation Loss Energy: 9.40195707871057, Validation Loss Force: 9.48012953577144, time: 0.0638127326965332
Test Loss Energy: 10.911827406821807, Test Loss Force: 14.120181550931617, time: 9.508887767791748


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 13.424802025571388, Training Loss Force: 7.292694233970576, time: 0.8015294075012207
Validation Loss Energy: 4.577714912236601, Validation Loss Force: 8.942328771745933, time: 0.06531715393066406
Test Loss Energy: 16.21514058647921, Test Loss Force: 13.537308063413196, time: 9.704606056213379

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–…â–†â–…â–â–…â–†â–‚â–â–ƒâ–â–â–â–â–†â–ƒâ–ˆâ–â–„
wandb:   test_error_force â–„â–„â–ˆâ–ƒâ–„â–‚â–â–â–‚â–†â–…â–…â–ƒâ–ƒâ–â–â–â–ƒâ–‡â–†
wandb:          test_loss â–ƒâ–ƒâ–ˆâ–…â–…â–â–ƒâ–ƒâ–‚â–…â–…â–ƒâ–‚â–‚â–â–„â–‚â–†â–…â–†
wandb: train_error_energy â–ˆâ–…â–ƒâ–„â–„â–‚â–‚â–‚â–‚â–‡â–â–…â–„â–…â–‚â–‚â–‚â–ƒâ–‡â–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–â–â–ƒâ–„â–ƒâ–‚â–ƒâ–â–â–â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–â–â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–â–â–ƒâ–„
wandb: valid_error_energy â–â–‚â–ƒâ–„â–„â–…â–‚â–ƒâ–„â–‚â–ˆâ–„â–‚â–„â–‚â–„â–‚â–‡â–ƒâ–
wandb:  valid_error_force â–…â–†â–ˆâ–ƒâ–„â–ƒâ–â–â–‚â–†â–…â–…â–ƒâ–„â–‚â–â–â–ƒâ–‡â–‡
wandb:         valid_loss â–…â–…â–ˆâ–„â–…â–„â–â–‚â–ƒâ–†â–ˆâ–…â–ƒâ–…â–‚â–‚â–â–…â–‡â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1745
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 16.21514
wandb:   test_error_force 13.53731
wandb:          test_loss 5.61475
wandb: train_error_energy 13.4248
wandb:  train_error_force 7.29269
wandb:         train_loss 3.33856
wandb: valid_error_energy 4.57771
wandb:  valid_error_force 8.94233
wandb:         valid_loss 3.29848
wandb: 
wandb: ğŸš€ View run al_74_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/jt8e24de
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_001150-jt8e24de/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.086484670639038, Uncertainty Bias: 0.0889582484960556
2.2888184e-05 0.79465675
2.1121297 6.646202
(48745, 22, 3)
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 0 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 2 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 14 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 5 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 22 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 27 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 3 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 3 steps.
Found uncertainty sample 42 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 2 steps.
Found uncertainty sample 60 after 2 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 74 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 78 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 2 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 89 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 90 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 91 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 94 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 98 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_001804-9k2z1es1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/9k2z1es1
Training model 11. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 19.670066882789374, Training Loss Force: 9.349414792448545, time: 0.8393189907073975
Validation Loss Energy: 5.54209119787437, Validation Loss Force: 4.762570829141224, time: 0.07555055618286133
Test Loss Energy: 13.899622235964742, Test Loss Force: 10.855985090733093, time: 9.543058156967163


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 7.439853744695928, Training Loss Force: 4.243389217599032, time: 0.8112320899963379
Validation Loss Energy: 5.459173438644635, Validation Loss Force: 3.9751192080992768, time: 0.06823897361755371
Test Loss Energy: 10.158533992871378, Test Loss Force: 10.487677942497696, time: 9.5410635471344


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.612393262300268, Training Loss Force: 4.396214830512887, time: 0.8169615268707275
Validation Loss Energy: 2.280398811937369, Validation Loss Force: 6.400163451893045, time: 0.06966948509216309
Test Loss Energy: 12.828712722208296, Test Loss Force: 11.743205000591914, time: 9.90576171875


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.777773707100217, Training Loss Force: 4.778331382002978, time: 0.8309457302093506
Validation Loss Energy: 6.153758665685939, Validation Loss Force: 3.9655553456125325, time: 0.06898903846740723
Test Loss Energy: 16.748781473499868, Test Loss Force: 10.449837020893941, time: 9.67013692855835


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 16.149957704555373, Training Loss Force: 4.594792192218938, time: 0.8508193492889404
Validation Loss Energy: 9.689079144942031, Validation Loss Force: 7.96334605814274, time: 0.07735848426818848
Test Loss Energy: 9.734576858730607, Test Loss Force: 13.139109240114612, time: 9.567319393157959


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 16.313705580758953, Training Loss Force: 8.581536441984595, time: 0.8131837844848633
Validation Loss Energy: 14.749152653228725, Validation Loss Force: 7.434193541075922, time: 0.06624484062194824
Test Loss Energy: 22.29163021512482, Test Loss Force: 12.27595877373519, time: 10.159554481506348


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 20.357426488367075, Training Loss Force: 7.228882637523153, time: 0.8245010375976562
Validation Loss Energy: 26.163258578439166, Validation Loss Force: 10.705461368295257, time: 0.0664968490600586
Test Loss Energy: 35.601240815625275, Test Loss Force: 14.910387512365427, time: 9.665158987045288


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.711681980246963, Training Loss Force: 8.062052664572255, time: 0.8158688545227051
Validation Loss Energy: 2.6110852058930183, Validation Loss Force: 7.81324077882819, time: 0.06863570213317871
Test Loss Energy: 10.281257801197716, Test Loss Force: 12.658320350791646, time: 9.736756563186646


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.840400441550882, Training Loss Force: 6.674553257969124, time: 0.8159754276275635
Validation Loss Energy: 30.692025691010485, Validation Loss Force: 8.686822606868173, time: 0.06628918647766113
Test Loss Energy: 39.114240327644865, Test Loss Force: 13.061539922655832, time: 9.861802577972412


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.602828059283958, Training Loss Force: 7.575792674738116, time: 0.8114848136901855
Validation Loss Energy: 2.6828668357966134, Validation Loss Force: 10.430574526294235, time: 0.06892538070678711
Test Loss Energy: 13.399067493865104, Test Loss Force: 14.52204532184304, time: 9.68474817276001


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.030962312311543, Training Loss Force: 6.3807521308883555, time: 0.8651676177978516
Validation Loss Energy: 8.360288101807495, Validation Loss Force: 7.1858245903325875, time: 0.0715487003326416
Test Loss Energy: 18.850828284802457, Test Loss Force: 11.789570014201301, time: 9.713491678237915


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 12.906541201658936, Training Loss Force: 6.87531357200377, time: 0.8326327800750732
Validation Loss Energy: 1.8625409543900389, Validation Loss Force: 5.092847957206659, time: 0.07069802284240723
Test Loss Energy: 12.798047688056128, Test Loss Force: 11.088037383899888, time: 9.828611850738525


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.543982747936723, Training Loss Force: 4.266581176606459, time: 0.833552360534668
Validation Loss Energy: 9.47875700315594, Validation Loss Force: 3.8879288732974793, time: 0.0658717155456543
Test Loss Energy: 19.968532883051054, Test Loss Force: 10.448701790634422, time: 9.650893449783325


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.531055825039197, Training Loss Force: 4.006885533978424, time: 0.8563029766082764
Validation Loss Energy: 8.725336798362719, Validation Loss Force: 4.079908866856915, time: 0.06875014305114746
Test Loss Energy: 10.435875157152397, Test Loss Force: 10.703783324285089, time: 9.678435564041138


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.760910980357353, Training Loss Force: 3.8957544690965387, time: 1.042473554611206
Validation Loss Energy: 12.406693723629822, Validation Loss Force: 3.8999089186866858, time: 0.06882643699645996
Test Loss Energy: 23.544858250427357, Test Loss Force: 10.460707980412456, time: 9.669376134872437


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.758332287369594, Training Loss Force: 3.817577946404195, time: 0.8365688323974609
Validation Loss Energy: 9.709665352821347, Validation Loss Force: 4.424034457115036, time: 0.07235312461853027
Test Loss Energy: 10.819366144759595, Test Loss Force: 10.690769392242935, time: 9.710837602615356


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.879101298298724, Training Loss Force: 3.811596492632586, time: 0.7963583469390869
Validation Loss Energy: 12.023056161434253, Validation Loss Force: 3.91230958609255, time: 0.07133984565734863
Test Loss Energy: 21.460470011726336, Test Loss Force: 10.382264540830032, time: 10.37764310836792


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.985680829238176, Training Loss Force: 3.7294596187411266, time: 0.8698470592498779
Validation Loss Energy: 7.069927749237779, Validation Loss Force: 3.834598276832898, time: 0.07045769691467285
Test Loss Energy: 10.444612475266878, Test Loss Force: 10.529941656243096, time: 9.623567819595337


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.240028511814769, Training Loss Force: 3.7712676397376863, time: 0.8359560966491699
Validation Loss Energy: 8.491258530735884, Validation Loss Force: 3.681100744414713, time: 0.06702947616577148
Test Loss Energy: 19.764458611333133, Test Loss Force: 10.341099758775941, time: 9.686380863189697


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.247325560165613, Training Loss Force: 3.7403770869659665, time: 0.8112728595733643
Validation Loss Energy: 5.7017863919657366, Validation Loss Force: 4.258541403802003, time: 0.0696554183959961
Test Loss Energy: 14.086625231365417, Test Loss Force: 10.347382069115882, time: 9.806718111038208

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–ƒâ–â–„â–‡â–â–ˆâ–‚â–ƒâ–‚â–ƒâ–â–„â–â–„â–â–ƒâ–‚
wandb:   test_error_force â–‚â–â–ƒâ–â–…â–„â–ˆâ–…â–…â–‡â–ƒâ–‚â–â–‚â–â–‚â–â–â–â–
wandb:          test_loss â–‚â–â–‚â–‚â–ƒâ–„â–ˆâ–ƒâ–‡â–„â–ƒâ–‚â–‚â–â–ƒâ–â–ƒâ–â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–â–†â–†â–ˆâ–ƒâ–„â–„â–â–„â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‡â–…â–†â–…â–†â–„â–…â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‡â–†â–…â–„â–…â–ƒâ–…â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–â–‚â–ƒâ–„â–‡â–â–ˆâ–â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚
wandb:  valid_error_force â–‚â–â–„â–â–…â–…â–ˆâ–…â–†â–ˆâ–„â–‚â–â–â–â–‚â–â–â–â–‚
wandb:         valid_loss â–‚â–â–‚â–â–„â–„â–ˆâ–ƒâ–‡â–…â–ƒâ–â–â–â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1835
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.08663
wandb:   test_error_force 10.34738
wandb:          test_loss 4.40495
wandb: train_error_energy 8.24733
wandb:  train_error_force 3.74038
wandb:         train_loss 1.80346
wandb: valid_error_energy 5.70179
wandb:  valid_error_force 4.25854
wandb:         valid_loss 1.80649
wandb: 
wandb: ğŸš€ View run al_74_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/9k2z1es1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_001804-9k2z1es1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0421369075775146, Uncertainty Bias: 0.051063910126686096
0.00012588501 0.057343483
0.849264 3.609984
(48745, 22, 3)
Found uncertainty sample 0 after 4 steps.
Found uncertainty sample 1 after 12 steps.
Found uncertainty sample 2 after 65 steps.
Found uncertainty sample 3 after 16 steps.
Found uncertainty sample 4 after 23 steps.
Found uncertainty sample 5 after 35 steps.
Found uncertainty sample 6 after 6 steps.
Found uncertainty sample 7 after 2 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 4 steps.
Found uncertainty sample 10 after 13 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 22 steps.
Found uncertainty sample 13 after 23 steps.
Found uncertainty sample 14 after 30 steps.
Found uncertainty sample 15 after 12 steps.
Found uncertainty sample 16 after 37 steps.
Found uncertainty sample 17 after 28 steps.
Found uncertainty sample 18 after 15 steps.
Found uncertainty sample 19 after 16 steps.
Found uncertainty sample 20 after 10 steps.
Found uncertainty sample 21 after 18 steps.
Found uncertainty sample 22 after 13 steps.
Found uncertainty sample 23 after 10 steps.
Found uncertainty sample 24 after 7 steps.
Found uncertainty sample 25 after 67 steps.
Found uncertainty sample 26 after 2 steps.
Found uncertainty sample 27 after 20 steps.
Found uncertainty sample 28 after 10 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 3 steps.
Found uncertainty sample 31 after 12 steps.
Found uncertainty sample 32 after 114 steps.
Found uncertainty sample 33 after 8 steps.
Found uncertainty sample 34 after 29 steps.
Found uncertainty sample 35 after 23 steps.
Found uncertainty sample 36 after 15 steps.
Found uncertainty sample 37 after 68 steps.
Found uncertainty sample 38 after 27 steps.
Found uncertainty sample 39 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 12 steps.
Found uncertainty sample 42 after 51 steps.
Found uncertainty sample 43 after 140 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 13 steps.
Found uncertainty sample 46 after 11 steps.
Found uncertainty sample 47 after 8 steps.
Found uncertainty sample 48 after 19 steps.
Found uncertainty sample 49 after 4 steps.
Found uncertainty sample 50 after 19 steps.
Found uncertainty sample 51 after 4 steps.
Found uncertainty sample 52 after 20 steps.
Found uncertainty sample 53 after 6 steps.
Found uncertainty sample 54 after 22 steps.
Found uncertainty sample 55 after 7 steps.
Found uncertainty sample 56 after 20 steps.
Found uncertainty sample 57 after 13 steps.
Found uncertainty sample 58 after 12 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 5 steps.
Found uncertainty sample 62 after 9 steps.
Found uncertainty sample 63 after 11 steps.
Found uncertainty sample 64 after 8 steps.
Found uncertainty sample 65 after 40 steps.
Found uncertainty sample 66 after 4 steps.
Found uncertainty sample 67 after 25 steps.
Found uncertainty sample 68 after 5 steps.
Found uncertainty sample 69 after 8 steps.
Found uncertainty sample 70 after 7 steps.
Found uncertainty sample 71 after 24 steps.
Found uncertainty sample 72 after 50 steps.
Found uncertainty sample 73 after 9 steps.
Found uncertainty sample 74 after 17 steps.
Found uncertainty sample 75 after 33 steps.
Found uncertainty sample 76 after 21 steps.
Found uncertainty sample 77 after 18 steps.
Found uncertainty sample 78 after 33 steps.
Found uncertainty sample 79 after 15 steps.
Found uncertainty sample 80 after 4 steps.
Found uncertainty sample 81 after 6 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 10 steps.
Found uncertainty sample 84 after 16 steps.
Found uncertainty sample 85 after 4 steps.
Found uncertainty sample 86 after 119 steps.
Found uncertainty sample 87 after 31 steps.
Found uncertainty sample 88 after 88 steps.
Found uncertainty sample 89 after 2 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 11 steps.
Found uncertainty sample 92 after 2 steps.
Found uncertainty sample 93 after 9 steps.
Found uncertainty sample 94 after 44 steps.
Found uncertainty sample 95 after 3 steps.
Found uncertainty sample 96 after 7 steps.
Found uncertainty sample 97 after 9 steps.
Found uncertainty sample 98 after 19 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_002456-vmw23i47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/vmw23i47
Training model 12. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.21803317242279, Training Loss Force: 9.800333776032224, time: 0.8908271789550781
Validation Loss Energy: 3.7390015137648884, Validation Loss Force: 5.292319654180835, time: 0.07166242599487305
Test Loss Energy: 14.362963302620825, Test Loss Force: 10.918740064368697, time: 9.552783012390137


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.998992688821914, Training Loss Force: 5.621535139562253, time: 0.8537123203277588
Validation Loss Energy: 12.523129646726922, Validation Loss Force: 5.026018934446789, time: 0.07248997688293457
Test Loss Energy: 10.490022147307283, Test Loss Force: 10.972950581681175, time: 9.75048565864563


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.24269264373423, Training Loss Force: 5.832382452004485, time: 0.8320684432983398
Validation Loss Energy: 6.59602256464369, Validation Loss Force: 5.823421194281958, time: 0.0743703842163086
Test Loss Energy: 17.94250447878714, Test Loss Force: 11.396645073483999, time: 9.830713510513306


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.8534638045297065, Training Loss Force: 4.773123930336421, time: 0.8423919677734375
Validation Loss Energy: 7.008351046292054, Validation Loss Force: 3.9181936182736923, time: 0.06653928756713867
Test Loss Energy: 10.850431614979405, Test Loss Force: 10.395419167129814, time: 9.720794916152954


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 7.864264128707061, Training Loss Force: 3.8625122488808437, time: 0.8741769790649414
Validation Loss Energy: 8.307363208526795, Validation Loss Force: 4.1766566067402255, time: 0.06983351707458496
Test Loss Energy: 11.010711915969459, Test Loss Force: 10.742889542908953, time: 9.635466814041138


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.90024363716006, Training Loss Force: 3.867102675532933, time: 0.8868725299835205
Validation Loss Energy: 9.721105648200826, Validation Loss Force: 4.912695480671468, time: 0.07136821746826172
Test Loss Energy: 20.09237809516534, Test Loss Force: 10.737942118943359, time: 9.762641429901123


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 17.75340328258354, Training Loss Force: 4.841179940397257, time: 0.8520326614379883
Validation Loss Energy: 12.3498658855593, Validation Loss Force: 8.8629458852078, time: 0.06785464286804199
Test Loss Energy: 19.1213071870436, Test Loss Force: 13.616871778282347, time: 9.711575746536255


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 17.91495294380394, Training Loss Force: 10.152714970888171, time: 0.8498673439025879
Validation Loss Energy: 17.487529793759407, Validation Loss Force: 6.959826763342325, time: 0.06877326965332031
Test Loss Energy: 12.400889128375038, Test Loss Force: 11.859426571410559, time: 9.744954347610474


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.10656616436581, Training Loss Force: 7.790350259215514, time: 0.866166353225708
Validation Loss Energy: 7.698507384020855, Validation Loss Force: 5.220046370803032, time: 0.07541012763977051
Test Loss Energy: 10.050957534156277, Test Loss Force: 10.841554600538126, time: 9.88120436668396


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.893809009886688, Training Loss Force: 4.447288033294678, time: 0.8958961963653564
Validation Loss Energy: 6.642132891382415, Validation Loss Force: 4.4466355980958525, time: 0.06926608085632324
Test Loss Energy: 18.486006260774555, Test Loss Force: 10.415014238500586, time: 10.132243156433105


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.687038462880027, Training Loss Force: 3.95542202321149, time: 0.8553187847137451
Validation Loss Energy: 10.026057723623309, Validation Loss Force: 4.021576453367358, time: 0.0748744010925293
Test Loss Energy: 21.093224144277873, Test Loss Force: 10.210019818596809, time: 9.722641944885254


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.8837232985294206, Training Loss Force: 4.031806169606705, time: 1.0068187713623047
Validation Loss Energy: 6.134075158524214, Validation Loss Force: 3.9792285671873744, time: 0.09987092018127441
Test Loss Energy: 10.81319816278511, Test Loss Force: 10.39554767637219, time: 9.790975570678711


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.09339481932268, Training Loss Force: 3.850678898655037, time: 0.862011194229126
Validation Loss Energy: 4.322484189092355, Validation Loss Force: 3.9146937046379993, time: 0.06747674942016602
Test Loss Energy: 11.046011485465563, Test Loss Force: 10.33321666945366, time: 9.699501752853394


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.705716403479369, Training Loss Force: 3.8466739531448106, time: 0.8525474071502686
Validation Loss Energy: 9.532270188320181, Validation Loss Force: 3.8318135764939254, time: 0.0699012279510498
Test Loss Energy: 20.8308723534268, Test Loss Force: 10.134788415252793, time: 9.915231943130493


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.934249977400913, Training Loss Force: 3.6276170884645036, time: 0.8873019218444824
Validation Loss Energy: 13.327541531275898, Validation Loss Force: 3.9887283009600916, time: 0.07810831069946289
Test Loss Energy: 26.200835836457998, Test Loss Force: 10.53516609927914, time: 9.682876586914062


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.988726666207322, Training Loss Force: 4.690012149623991, time: 0.8417773246765137
Validation Loss Energy: 41.14480656588981, Validation Loss Force: 5.704964326016418, time: 0.07940363883972168
Test Loss Energy: 53.380403845258385, Test Loss Force: 11.576433308762926, time: 9.699541807174683


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 22.399834307564078, Training Loss Force: 7.94332372154719, time: 0.899177074432373
Validation Loss Energy: 20.85615948236652, Validation Loss Force: 7.253915479142429, time: 0.07141780853271484
Test Loss Energy: 29.113228243026395, Test Loss Force: 11.742571673582155, time: 9.741227865219116


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.396689608445477, Training Loss Force: 5.97269442105351, time: 0.882620096206665
Validation Loss Energy: 13.285249089713247, Validation Loss Force: 4.549083445445769, time: 0.07407450675964355
Test Loss Energy: 10.416091742658379, Test Loss Force: 10.42718142156855, time: 9.74915337562561


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.502919586323895, Training Loss Force: 4.086307053046946, time: 0.8507988452911377
Validation Loss Energy: 5.7924868831839404, Validation Loss Force: 4.463687601291003, time: 0.08465981483459473
Test Loss Energy: 10.583671310791392, Test Loss Force: 10.423108404183521, time: 9.722798109054565


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.765702055070533, Training Loss Force: 3.786499682535475, time: 0.9009180068969727
Validation Loss Energy: 7.792210568671894, Validation Loss Force: 3.7278031484124607, time: 0.06784319877624512
Test Loss Energy: 19.799447026928455, Test Loss Force: 10.107457043656611, time: 9.791514873504639

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–â–â–ƒâ–‚â–â–â–‚â–ƒâ–â–â–ƒâ–„â–ˆâ–„â–â–â–ƒ
wandb:   test_error_force â–ƒâ–ƒâ–„â–‚â–‚â–‚â–ˆâ–„â–‚â–‚â–â–‚â–â–â–‚â–„â–„â–‚â–‚â–
wandb:          test_loss â–‚â–â–ƒâ–â–â–ƒâ–…â–‚â–â–‚â–‚â–â–â–‚â–ƒâ–ˆâ–…â–â–â–‚
wandb: train_error_energy â–‡â–‚â–â–â–â–â–†â–†â–‚â–â–â–â–â–â–‚â–ƒâ–ˆâ–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–â–â–‚â–ˆâ–…â–‚â–â–â–â–â–â–‚â–†â–„â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–â–â–ƒâ–ˆâ–…â–‚â–â–â–â–â–â–‚â–‡â–ƒâ–â–
wandb: valid_error_energy â–â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–‚â–‚â–â–â–‚â–ƒâ–ˆâ–„â–ƒâ–â–‚
wandb:  valid_error_force â–ƒâ–ƒâ–„â–â–‚â–ƒâ–ˆâ–…â–ƒâ–‚â–â–â–â–â–â–„â–†â–‚â–‚â–
wandb:         valid_loss â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–†â–…â–ƒâ–‚â–‚â–â–â–‚â–‚â–ˆâ–†â–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1925
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 19.79945
wandb:   test_error_force 10.10746
wandb:          test_loss 4.70698
wandb: train_error_energy 7.7657
wandb:  train_error_force 3.7865
wandb:         train_loss 1.78666
wandb: valid_error_energy 7.79221
wandb:  valid_error_force 3.7278
wandb:         valid_loss 1.76879
wandb: 
wandb: ğŸš€ View run al_74_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/vmw23i47
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_002456-vmw23i47/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.44753900170326233, Uncertainty Bias: 0.18510527908802032
0.0 0.038510084
2.768292 3.8587031
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2520 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1637 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 693 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3435 steps.
Found uncertainty sample 16 after 3614 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2842 steps.
Found uncertainty sample 37 after 1500 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1147 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 704 steps.
Distance between 20 and 21 is 0.3017659078802479 which is too small.
Atomic distances for sample 56 are too large or too small. Resetting this trajectory.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1514 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1764 steps.
Found uncertainty sample 63 after 749 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1787 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2744 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3076 steps.
Found uncertainty sample 88 after 3004 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3571 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 628 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_022759-3debxad3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/3debxad3
Training model 13. Added 18 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 24.762692731487967, Training Loss Force: 11.391432343750923, time: 0.8704040050506592
Validation Loss Energy: 4.479380209350264, Validation Loss Force: 7.1501024472588295, time: 0.07362055778503418
Test Loss Energy: 10.921944737369799, Test Loss Force: 11.545785099538056, time: 9.592329502105713


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 13.964572934873733, Training Loss Force: 7.4814370164970185, time: 0.8898153305053711
Validation Loss Energy: 23.269990107971367, Validation Loss Force: 6.279660254176429, time: 0.07189297676086426
Test Loss Energy: 31.204699421714775, Test Loss Force: 11.443605250243658, time: 9.490256547927856


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.90960709123296, Training Loss Force: 6.614717216379918, time: 0.8734636306762695
Validation Loss Energy: 20.8408665654242, Validation Loss Force: 5.7538402035475675, time: 0.06853485107421875
Test Loss Energy: 14.093866944946091, Test Loss Force: 11.107722166454522, time: 9.732202053070068


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 12.48460803049397, Training Loss Force: 6.13286755073957, time: 0.8844757080078125
Validation Loss Energy: 9.59249773891073, Validation Loss Force: 7.571282695465262, time: 0.06805586814880371
Test Loss Energy: 17.02488012529369, Test Loss Force: 12.398163336266139, time: 9.585835933685303


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 15.445348840436424, Training Loss Force: 6.702650547017282, time: 0.8900234699249268
Validation Loss Energy: 10.056468539559251, Validation Loss Force: 7.660420271948199, time: 0.0717318058013916
Test Loss Energy: 9.934640880114902, Test Loss Force: 12.261736990980957, time: 9.98118257522583


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.191949165244752, Training Loss Force: 6.146063588684375, time: 0.8799178600311279
Validation Loss Energy: 11.716613093410636, Validation Loss Force: 4.680108428314911, time: 0.06772160530090332
Test Loss Energy: 10.312653600512608, Test Loss Force: 10.577623099169665, time: 9.829807043075562


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.352133861714902, Training Loss Force: 5.75899176009771, time: 0.8673362731933594
Validation Loss Energy: 4.547927792578403, Validation Loss Force: 7.454690458627722, time: 0.06820321083068848
Test Loss Energy: 14.87450105694908, Test Loss Force: 12.10880793813846, time: 9.708816051483154


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 15.790574325017584, Training Loss Force: 8.023680971764763, time: 0.8648338317871094
Validation Loss Energy: 24.408262312482044, Validation Loss Force: 7.619934122497316, time: 0.06759357452392578
Test Loss Energy: 17.199015996402, Test Loss Force: 12.45056267440371, time: 9.609347343444824


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.004695151859085, Training Loss Force: 6.362637214196469, time: 0.8711986541748047
Validation Loss Energy: 8.739537745813411, Validation Loss Force: 5.0858717328647405, time: 0.06870198249816895
Test Loss Energy: 16.93322224418353, Test Loss Force: 10.382127768347306, time: 9.854250431060791


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.285754861306621, Training Loss Force: 6.0028701020216655, time: 0.8922297954559326
Validation Loss Energy: 13.777169321558626, Validation Loss Force: 5.983290292976294, time: 0.06746602058410645
Test Loss Energy: 10.813855472777433, Test Loss Force: 11.356378200680538, time: 9.617597579956055


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 9.546103751756817, Training Loss Force: 6.959379888268331, time: 0.844050407409668
Validation Loss Energy: 13.475582222269402, Validation Loss Force: 7.791348393738863, time: 0.06904435157775879
Test Loss Energy: 20.76737247572061, Test Loss Force: 12.39373462648792, time: 9.61917781829834


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.337410069388282, Training Loss Force: 7.401662736005369, time: 0.8699486255645752
Validation Loss Energy: 11.042414562693898, Validation Loss Force: 5.76080796646194, time: 0.07111597061157227
Test Loss Energy: 10.023565843703494, Test Loss Force: 11.209995182384866, time: 9.841274738311768


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 9.312942112620135, Training Loss Force: 6.216381519383625, time: 0.8793330192565918
Validation Loss Energy: 5.462848370229027, Validation Loss Force: 9.565088057723603, time: 0.0676720142364502
Test Loss Energy: 15.21819558422263, Test Loss Force: 13.031629058408658, time: 9.669777393341064


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.238383849394454, Training Loss Force: 6.256713771601848, time: 0.833946704864502
Validation Loss Energy: 5.782050825652597, Validation Loss Force: 7.920847424950962, time: 0.07034635543823242
Test Loss Energy: 17.586364742117887, Test Loss Force: 12.875807092685493, time: 9.611895322799683


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 16.754478139580513, Training Loss Force: 8.569223146225756, time: 1.049231767654419
Validation Loss Energy: 13.309609094277748, Validation Loss Force: 5.653969974230911, time: 0.0789177417755127
Test Loss Energy: 24.39957593547227, Test Loss Force: 10.967961020785678, time: 9.683609962463379


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.394969747758434, Training Loss Force: 5.543786221118822, time: 0.8615343570709229
Validation Loss Energy: 4.261523166335121, Validation Loss Force: 5.986363127190097, time: 0.06942510604858398
Test Loss Energy: 10.147989118910292, Test Loss Force: 11.570009502090105, time: 9.630791425704956


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.763590072545878, Training Loss Force: 5.702131529141925, time: 0.8589699268341064
Validation Loss Energy: 9.606128653347845, Validation Loss Force: 5.302779091972502, time: 0.07551980018615723
Test Loss Energy: 10.524941351269863, Test Loss Force: 11.010497197627592, time: 10.204445123672485


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.33992764906096, Training Loss Force: 6.238479745671951, time: 0.8626720905303955
Validation Loss Energy: 15.214930191327305, Validation Loss Force: 6.737538158984927, time: 0.06902909278869629
Test Loss Energy: 23.02289433393797, Test Loss Force: 11.842819519459322, time: 9.619527816772461


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.650050221217366, Training Loss Force: 4.812377967445666, time: 0.8801302909851074
Validation Loss Energy: 10.397550910599975, Validation Loss Force: 3.78619423522197, time: 0.07077622413635254
Test Loss Energy: 22.081035537962183, Test Loss Force: 10.213429188662408, time: 9.600232362747192


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.565306127827575, Training Loss Force: 3.937404176169466, time: 0.8770754337310791
Validation Loss Energy: 5.77415096969337, Validation Loss Force: 4.38369727332278, time: 0.06668877601623535
Test Loss Energy: 10.92450659369179, Test Loss Force: 10.428006453889074, time: 9.774788618087769

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–‚â–ƒâ–â–â–ƒâ–ƒâ–ƒâ–â–…â–â–ƒâ–„â–†â–â–â–…â–…â–
wandb:   test_error_force â–„â–„â–ƒâ–†â–†â–‚â–†â–‡â–â–„â–†â–ƒâ–ˆâ–ˆâ–ƒâ–„â–ƒâ–…â–â–‚
wandb:          test_loss â–ƒâ–ˆâ–ƒâ–…â–ƒâ–â–„â–†â–ƒâ–‚â–†â–‚â–†â–†â–…â–‚â–‚â–†â–„â–
wandb: train_error_energy â–ˆâ–„â–ƒâ–ƒâ–„â–â–„â–„â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–…â–ƒâ–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–
wandb: valid_error_energy â–â–ˆâ–‡â–ƒâ–ƒâ–„â–â–ˆâ–ƒâ–„â–„â–ƒâ–â–‚â–„â–â–ƒâ–…â–ƒâ–‚
wandb:  valid_error_force â–…â–„â–ƒâ–†â–†â–‚â–…â–†â–ƒâ–„â–†â–ƒâ–ˆâ–†â–ƒâ–„â–ƒâ–…â–â–‚
wandb:         valid_loss â–„â–†â–…â–…â–…â–‚â–„â–ˆâ–‚â–„â–†â–ƒâ–†â–…â–„â–‚â–ƒâ–…â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1941
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.92451
wandb:   test_error_force 10.42801
wandb:          test_loss 4.22032
wandb: train_error_energy 7.56531
wandb:  train_error_force 3.9374
wandb:         train_loss 1.82374
wandb: valid_error_energy 5.77415
wandb:  valid_error_force 4.3837
wandb:         valid_loss 1.85321
wandb: 
wandb: ğŸš€ View run al_74_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/3debxad3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_022759-3debxad3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.298548936843872, Uncertainty Bias: 0.010648965835571289
4.9591064e-05 0.0057029724
0.22388324 5.130485
(48745, 22, 3)
Found uncertainty sample 0 after 2 steps.
Found uncertainty sample 1 after 3 steps.
Found uncertainty sample 2 after 2 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 5 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 7 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 2 steps.
Found uncertainty sample 26 after 2 steps.
Found uncertainty sample 27 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 4 steps.
Found uncertainty sample 40 after 6 steps.
Found uncertainty sample 41 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 3 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 5 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 6 steps.
Found uncertainty sample 55 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 2 steps.
Found uncertainty sample 60 after 3 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 4 steps.
Found uncertainty sample 63 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 64 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 5 steps.
Found uncertainty sample 70 after 2 steps.
Found uncertainty sample 71 after 5 steps.
Found uncertainty sample 72 after 6 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 2 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 9 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 2 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 11 steps.
Found uncertainty sample 91 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 2 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 15 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_023417-vmmhocvn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/vmmhocvn
Training model 14. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 23.9809723777903, Training Loss Force: 10.987631871144615, time: 0.9315712451934814
Validation Loss Energy: 7.77800383182341, Validation Loss Force: 7.34689632508408, time: 0.07447504997253418
Test Loss Energy: 15.229324420259884, Test Loss Force: 12.148193022471135, time: 9.693510293960571


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.097510468221188, Training Loss Force: 6.2930011072589185, time: 0.9278786182403564
Validation Loss Energy: 18.93612708018381, Validation Loss Force: 5.676196140369985, time: 0.06971454620361328
Test Loss Energy: 13.159005733228936, Test Loss Force: 11.195277553914288, time: 9.713510036468506


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.278082341590707, Training Loss Force: 6.262453308047768, time: 0.917471170425415
Validation Loss Energy: 3.790587497471125, Validation Loss Force: 8.252211623786815, time: 0.07158923149108887
Test Loss Energy: 13.139292388401655, Test Loss Force: 12.686098291771925, time: 9.814333438873291


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.10667660037425, Training Loss Force: 7.032475411232876, time: 0.9306511878967285
Validation Loss Energy: 13.181587250179735, Validation Loss Force: 5.381707288114649, time: 0.07064485549926758
Test Loss Energy: 21.629318434922574, Test Loss Force: 10.921855072818222, time: 9.664530992507935


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.591790267097046, Training Loss Force: 5.998624960383476, time: 0.9708907604217529
Validation Loss Energy: 14.877924001671932, Validation Loss Force: 8.314918372648123, time: 0.07867908477783203
Test Loss Energy: 23.40417836486758, Test Loss Force: 12.596369089197294, time: 9.669290542602539


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 11.836552868603949, Training Loss Force: 6.349817505702069, time: 0.9507286548614502
Validation Loss Energy: 14.125092088762255, Validation Loss Force: 5.976522264285819, time: 0.06946992874145508
Test Loss Energy: 11.061920163037058, Test Loss Force: 11.407774860819805, time: 9.873157739639282


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.405918320079593, Training Loss Force: 5.630870179614611, time: 0.9175910949707031
Validation Loss Energy: 15.479110210115534, Validation Loss Force: 5.2836653951552055, time: 0.07074260711669922
Test Loss Energy: 23.931634379701258, Test Loss Force: 10.893039614861852, time: 9.659748554229736


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.8059688960942, Training Loss Force: 5.424849080259206, time: 0.9153180122375488
Validation Loss Energy: 3.7320615844937572, Validation Loss Force: 7.851825333772849, time: 0.07111191749572754
Test Loss Energy: 12.19280005501277, Test Loss Force: 12.606670076324198, time: 9.735243082046509


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.35991680821608, Training Loss Force: 5.648409751696825, time: 0.975165605545044
Validation Loss Energy: 2.858627163428378, Validation Loss Force: 5.765694886207617, time: 0.08031392097473145
Test Loss Energy: 13.335450121461518, Test Loss Force: 11.14164425098679, time: 9.918230295181274


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 20.221256687492094, Training Loss Force: 7.179728096994176, time: 0.9170069694519043
Validation Loss Energy: 14.862171050274124, Validation Loss Force: 6.629629350831133, time: 0.0744621753692627
Test Loss Energy: 11.91934820956881, Test Loss Force: 11.517068049686113, time: 10.198189496994019


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.843044913791434, Training Loss Force: 6.570134465231616, time: 0.8999128341674805
Validation Loss Energy: 13.109818757755749, Validation Loss Force: 6.3453449801953745, time: 0.0718998908996582
Test Loss Energy: 22.15844583467656, Test Loss Force: 11.216429038314427, time: 9.836995124816895


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.968146141404757, Training Loss Force: 5.59791953677452, time: 0.9348456859588623
Validation Loss Energy: 17.043556909106663, Validation Loss Force: 6.656124307166788, time: 0.07589221000671387
Test Loss Energy: 11.82664092491391, Test Loss Force: 12.01608214513088, time: 9.783211469650269


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.768551266391405, Training Loss Force: 6.211579399394975, time: 0.8937256336212158
Validation Loss Energy: 6.76523953675322, Validation Loss Force: 9.187868265651964, time: 0.06901240348815918
Test Loss Energy: 15.32561210353738, Test Loss Force: 13.335672613404773, time: 9.715741157531738


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.503074954062684, Training Loss Force: 5.26003360915723, time: 0.9260852336883545
Validation Loss Energy: 1.6820610985430484, Validation Loss Force: 4.958907121871592, time: 0.0703732967376709
Test Loss Energy: 12.770875183317816, Test Loss Force: 10.535552093329086, time: 9.875087261199951


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.74153264988243, Training Loss Force: 6.1407967328641195, time: 0.9214951992034912
Validation Loss Energy: 12.073817155954828, Validation Loss Force: 7.914188726811137, time: 0.07230210304260254
Test Loss Energy: 10.20790002231726, Test Loss Force: 12.596674693856523, time: 9.744342803955078


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.25573639386997, Training Loss Force: 5.716621570728137, time: 0.9903140068054199
Validation Loss Energy: 18.392909666514463, Validation Loss Force: 6.05015449746122, time: 0.07581257820129395
Test Loss Energy: 27.466387720642665, Test Loss Force: 11.376245338773423, time: 9.660161256790161


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.521918347448306, Training Loss Force: 5.363263421838769, time: 0.8991444110870361
Validation Loss Energy: 3.0688518874631265, Validation Loss Force: 4.823386671615314, time: 0.07235527038574219
Test Loss Energy: 10.305411443925259, Test Loss Force: 10.657460410299773, time: 9.911870241165161


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.702188312768799, Training Loss Force: 6.0041326608327665, time: 0.9281086921691895
Validation Loss Energy: 16.582756471757857, Validation Loss Force: 5.928333321069857, time: 0.06956362724304199
Test Loss Energy: 11.549068902858266, Test Loss Force: 11.106307501572353, time: 9.711929559707642


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 14.13182036405177, Training Loss Force: 6.457433803140634, time: 0.9462411403656006
Validation Loss Energy: 5.880030593920326, Validation Loss Force: 7.360006193719723, time: 0.07231426239013672
Test Loss Energy: 10.403723980156409, Test Loss Force: 12.56640422476771, time: 9.626246452331543


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 15.904798308201137, Training Loss Force: 6.428865323884456, time: 0.9065649509429932
Validation Loss Energy: 13.158961838262012, Validation Loss Force: 6.6805088053373405, time: 0.07066059112548828
Test Loss Energy: 22.989383909863587, Test Loss Force: 12.268032288411403, time: 9.897766828536987

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‚â–†â–†â–â–‡â–‚â–‚â–‚â–†â–‚â–ƒâ–‚â–â–ˆâ–â–‚â–â–†
wandb:   test_error_force â–…â–ƒâ–†â–‚â–†â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–…â–ˆâ–â–†â–ƒâ–â–‚â–†â–…
wandb:          test_loss â–…â–ƒâ–…â–…â–ˆâ–‚â–†â–…â–ƒâ–ƒâ–…â–„â–‡â–‚â–„â–‡â–â–‚â–„â–‡
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–„â–…
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–ƒ
wandb: valid_error_energy â–ƒâ–ˆâ–‚â–†â–†â–†â–‡â–‚â–â–†â–†â–‡â–ƒâ–â–…â–ˆâ–‚â–‡â–ƒâ–†
wandb:  valid_error_force â–…â–‚â–†â–‚â–‡â–ƒâ–‚â–†â–ƒâ–„â–ƒâ–„â–ˆâ–â–†â–ƒâ–â–ƒâ–…â–„
wandb:         valid_loss â–…â–†â–…â–„â–ˆâ–…â–…â–…â–‚â–†â–…â–‡â–‡â–â–‡â–†â–â–†â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2031
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 22.98938
wandb:   test_error_force 12.26803
wandb:          test_loss 5.64339
wandb: train_error_energy 15.9048
wandb:  train_error_force 6.42887
wandb:         train_loss 3.21548
wandb: valid_error_energy 13.15896
wandb:  valid_error_force 6.68051
wandb:         valid_loss 3.11593
wandb: 
wandb: ğŸš€ View run al_74_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/vmmhocvn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_023417-vmmhocvn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1262497901916504, Uncertainty Bias: 0.09661896526813507
0.00021743774 0.048591614
1.7241026 4.7120414
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 4 steps.
Found uncertainty sample 4 after 2 steps.
Found uncertainty sample 5 after 2 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 9 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 5 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 8 steps.
Found uncertainty sample 16 after 8 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 20 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 8 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 2 steps.
Found uncertainty sample 25 after 15 steps.
Found uncertainty sample 26 after 6 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 2 steps.
Found uncertainty sample 30 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 3 steps.
Found uncertainty sample 37 after 3 steps.
Found uncertainty sample 38 after 7 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 6 steps.
Found uncertainty sample 41 after 7 steps.
Found uncertainty sample 42 after 3 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 6 steps.
Found uncertainty sample 49 after 7 steps.
Found uncertainty sample 50 after 2 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 8 steps.
Found uncertainty sample 54 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 3 steps.
Found uncertainty sample 62 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 7 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 2 steps.
Found uncertainty sample 71 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 10 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 5 steps.
Found uncertainty sample 77 after 2 steps.
Found uncertainty sample 78 after 3 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 6 steps.
Found uncertainty sample 82 after 6 steps.
Found uncertainty sample 83 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 2 steps.
Found uncertainty sample 86 after 2 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 2 steps.
Found uncertainty sample 90 after 4 steps.
Found uncertainty sample 91 after 30 steps.
Found uncertainty sample 92 after 6 steps.
Found uncertainty sample 93 after 2 steps.
Found uncertainty sample 94 after 2 steps.
Found uncertainty sample 95 after 7 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 2 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 2 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_024039-75vpptq3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/75vpptq3
Training model 15. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 20.084895306694488, Training Loss Force: 9.442035284992432, time: 0.9930906295776367
Validation Loss Energy: 11.770154780225557, Validation Loss Force: 7.284901672151449, time: 0.07466244697570801
Test Loss Energy: 19.704079664376266, Test Loss Force: 12.483965275315951, time: 9.672513961791992


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 15.198062435218436, Training Loss Force: 7.440929870985594, time: 0.9490466117858887
Validation Loss Energy: 14.723230847274689, Validation Loss Force: 6.345140124581121, time: 0.0718698501586914
Test Loss Energy: 20.550813315198344, Test Loss Force: 11.529673151849888, time: 9.64543104171753


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.740688530130063, Training Loss Force: 6.189268475450243, time: 1.005157470703125
Validation Loss Energy: 6.808873114581791, Validation Loss Force: 5.515614277739535, time: 0.0738368034362793
Test Loss Energy: 9.978931587235701, Test Loss Force: 11.243371244865495, time: 9.864733219146729


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.631288687451622, Training Loss Force: 6.409415796921216, time: 0.9697747230529785
Validation Loss Energy: 29.33444040993944, Validation Loss Force: 6.268613192508659, time: 0.07124638557434082
Test Loss Energy: 19.732796271221527, Test Loss Force: 11.969980547955325, time: 10.264518737792969


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 12.211905978489678, Training Loss Force: 6.016318651191018, time: 0.9867310523986816
Validation Loss Energy: 7.8620730132067385, Validation Loss Force: 4.970325373005624, time: 0.07438397407531738
Test Loss Energy: 10.240756652473369, Test Loss Force: 10.893279388728768, time: 9.751569747924805


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.253397947736659, Training Loss Force: 5.366858011196519, time: 0.9208331108093262
Validation Loss Energy: 8.03031603047198, Validation Loss Force: 4.555261178230389, time: 0.06971096992492676
Test Loss Energy: 20.423402039224918, Test Loss Force: 10.392207653172957, time: 9.895323276519775


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.61886576041848, Training Loss Force: 6.7531447536088764, time: 0.9830636978149414
Validation Loss Energy: 2.0834644298810394, Validation Loss Force: 7.636246418789694, time: 0.0706934928894043
Test Loss Energy: 11.306258075941312, Test Loss Force: 12.67567015706527, time: 9.81813097000122


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.202020341829494, Training Loss Force: 7.017834957261729, time: 0.939338207244873
Validation Loss Energy: 8.021387888396859, Validation Loss Force: 5.9398003367468455, time: 0.07435202598571777
Test Loss Energy: 17.19599290018004, Test Loss Force: 11.521622316883267, time: 9.736860990524292


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 8.348300060269553, Training Loss Force: 5.672101676850724, time: 1.002974271774292
Validation Loss Energy: 20.114166212804022, Validation Loss Force: 8.296143355601785, time: 0.10647773742675781
Test Loss Energy: 28.303002669927665, Test Loss Force: 12.518635010560208, time: 9.82181715965271


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.974263986280503, Training Loss Force: 7.408832698522039, time: 0.9762711524963379
Validation Loss Energy: 9.842444300552962, Validation Loss Force: 7.262313223311949, time: 0.07090902328491211
Test Loss Energy: 18.32876872550295, Test Loss Force: 12.355833465302442, time: 9.757651567459106


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.297735926495452, Training Loss Force: 7.1777517570045966, time: 0.9673914909362793
Validation Loss Energy: 7.776632189884495, Validation Loss Force: 4.954347971108721, time: 0.07371068000793457
Test Loss Energy: 16.457437534976417, Test Loss Force: 10.876579044234425, time: 9.897762537002563


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.496290543715309, Training Loss Force: 5.71014104467039, time: 0.968902587890625
Validation Loss Energy: 28.00403590617351, Validation Loss Force: 4.445193592706825, time: 0.07082891464233398
Test Loss Energy: 35.505636281287494, Test Loss Force: 10.684390235980006, time: 9.85214877128601


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.04674649122532, Training Loss Force: 5.9266843297542975, time: 1.0101854801177979
Validation Loss Energy: 8.390569324300506, Validation Loss Force: 5.684338260359981, time: 0.0713036060333252
Test Loss Energy: 9.468990163170096, Test Loss Force: 11.316563469818854, time: 9.873637914657593


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.90746665999925, Training Loss Force: 5.852351719029452, time: 0.9734044075012207
Validation Loss Energy: 3.6758604487344484, Validation Loss Force: 4.950870324387621, time: 0.0722496509552002
Test Loss Energy: 10.278377418411191, Test Loss Force: 11.11765560726219, time: 9.977793216705322


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.22229738523166, Training Loss Force: 6.423345872341017, time: 0.9571151733398438
Validation Loss Energy: 12.197733426340225, Validation Loss Force: 4.968112709702538, time: 0.07402276992797852
Test Loss Energy: 22.25617580313677, Test Loss Force: 10.619263017543725, time: 9.809282779693604


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.191588362775075, Training Loss Force: 5.416934680286675, time: 0.9840481281280518
Validation Loss Energy: 6.782076886891696, Validation Loss Force: 5.544939136250786, time: 0.07523941993713379
Test Loss Energy: 10.873539822569395, Test Loss Force: 11.246357450289269, time: 9.760815620422363


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.418890289837796, Training Loss Force: 5.103761693230738, time: 0.9656529426574707
Validation Loss Energy: 13.196237098628615, Validation Loss Force: 4.541219216549891, time: 0.07512497901916504
Test Loss Energy: 10.618318984303098, Test Loss Force: 10.473894433244615, time: 10.025214195251465


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 15.448835408470131, Training Loss Force: 5.906257187407257, time: 0.9703783988952637
Validation Loss Energy: 5.117052538707301, Validation Loss Force: 5.907365235605274, time: 0.07814502716064453
Test Loss Energy: 9.28451253433084, Test Loss Force: 11.189290537836056, time: 9.807461500167847


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.14095717541755, Training Loss Force: 7.65629164699385, time: 0.9412033557891846
Validation Loss Energy: 10.364167906904191, Validation Loss Force: 6.937403757678251, time: 0.07699966430664062
Test Loss Energy: 19.010816816931307, Test Loss Force: 12.334227395428956, time: 9.747193098068237


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.100935773793358, Training Loss Force: 5.411317867697748, time: 0.9496829509735107
Validation Loss Energy: 8.136909086642488, Validation Loss Force: 4.737538586425169, time: 0.07108283042907715
Test Loss Energy: 17.014196482988222, Test Loss Force: 10.442521371830363, time: 10.310842037200928

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–â–„â–â–„â–‚â–ƒâ–†â–ƒâ–ƒâ–ˆâ–â–â–„â–â–â–â–„â–ƒ
wandb:   test_error_force â–‡â–„â–„â–†â–ƒâ–â–ˆâ–„â–ˆâ–‡â–‚â–‚â–„â–ƒâ–‚â–„â–â–ƒâ–‡â–
wandb:          test_loss â–†â–…â–‚â–…â–â–ƒâ–„â–„â–ˆâ–…â–ƒâ–ˆâ–‚â–‚â–„â–‚â–â–‚â–…â–ƒ
wandb: train_error_energy â–ˆâ–…â–„â–…â–„â–„â–…â–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–„â–„â–†â–ƒâ–
wandb:  train_error_force â–ˆâ–…â–ƒâ–ƒâ–‚â–â–„â–„â–‚â–…â–„â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–…â–
wandb:         train_loss â–ˆâ–…â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–‚â–„â–„â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–„â–
wandb: valid_error_energy â–ƒâ–„â–‚â–ˆâ–‚â–ƒâ–â–ƒâ–†â–ƒâ–‚â–ˆâ–ƒâ–â–„â–‚â–„â–‚â–ƒâ–ƒ
wandb:  valid_error_force â–†â–„â–ƒâ–„â–‚â–â–‡â–„â–ˆâ–†â–‚â–â–ƒâ–‚â–‚â–ƒâ–â–„â–†â–‚
wandb:         valid_loss â–…â–…â–‚â–ˆâ–‚â–‚â–ƒâ–ƒâ–ˆâ–…â–‚â–†â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2121
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 17.0142
wandb:   test_error_force 10.44252
wandb:          test_loss 4.6327
wandb: train_error_energy 7.10094
wandb:  train_error_force 5.41132
wandb:         train_loss 2.28584
wandb: valid_error_energy 8.13691
wandb:  valid_error_force 4.73754
wandb:         valid_loss 2.12972
wandb: 
wandb: ğŸš€ View run al_74_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/75vpptq3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_024039-75vpptq3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5407770872116089, Uncertainty Bias: 0.1353696882724762
0.00010585785 0.073393345
2.0371976 4.348622
(48745, 22, 3)
Found uncertainty sample 0 after 3 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 2 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 4 steps.
Found uncertainty sample 5 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 3 steps.
Found uncertainty sample 9 after 4 steps.
Found uncertainty sample 10 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 6 steps.
Found uncertainty sample 14 after 5 steps.
Found uncertainty sample 15 after 3 steps.
Found uncertainty sample 16 after 4 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 4 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 22 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 11 steps.
Found uncertainty sample 29 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 2 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 2 steps.
Found uncertainty sample 34 after 5 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 7 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 3 steps.
Found uncertainty sample 42 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 2 steps.
Found uncertainty sample 45 after 3 steps.
Found uncertainty sample 46 after 3 steps.
Found uncertainty sample 47 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 48 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 52 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 2 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 2 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 4 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 12 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 2 steps.
Found uncertainty sample 72 after 4 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 2 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 8 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 2 steps.
Found uncertainty sample 90 after 4 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 8 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_024704-o03dgjl9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/o03dgjl9
Training model 16. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 20.248626051746392, Training Loss Force: 10.142363779712527, time: 1.0030732154846191
Validation Loss Energy: 9.5950637781484, Validation Loss Force: 6.095905213529273, time: 0.07475161552429199
Test Loss Energy: 19.188069160742792, Test Loss Force: 11.242874121424622, time: 9.792571783065796


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 10.697831217158047, Training Loss Force: 6.680457114285607, time: 1.0323309898376465
Validation Loss Energy: 9.151424451876254, Validation Loss Force: 4.635350371299404, time: 0.07958292961120605
Test Loss Energy: 9.476156285821855, Test Loss Force: 10.612876987682448, time: 9.765827894210815


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.949865197262076, Training Loss Force: 5.653723918462686, time: 0.980273962020874
Validation Loss Energy: 50.76207758329987, Validation Loss Force: 5.035484154501887, time: 0.07421994209289551
Test Loss Energy: 57.50800674109476, Test Loss Force: 12.03246310046347, time: 9.985348463058472


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 19.441751401909624, Training Loss Force: 7.016753600115125, time: 1.0313725471496582
Validation Loss Energy: 2.6605263290511054, Validation Loss Force: 8.674965029509227, time: 0.07511544227600098
Test Loss Energy: 10.728258370688959, Test Loss Force: 13.234523398161661, time: 9.780271291732788


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 11.525662267100715, Training Loss Force: 6.101287858413541, time: 1.0015299320220947
Validation Loss Energy: 10.468186907747771, Validation Loss Force: 6.931307744470185, time: 0.07922720909118652
Test Loss Energy: 9.625519936983618, Test Loss Force: 12.105844559216662, time: 9.764471292495728


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.054181614908122, Training Loss Force: 5.453805458114119, time: 0.981839656829834
Validation Loss Energy: 16.653225021707918, Validation Loss Force: 4.81770014696661, time: 0.07799887657165527
Test Loss Energy: 23.491481849403907, Test Loss Force: 10.64329290752164, time: 10.030163526535034


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.845698999197765, Training Loss Force: 4.959879238104932, time: 1.001692533493042
Validation Loss Energy: 50.25605749579606, Validation Loss Force: 5.760594872089287, time: 0.07211542129516602
Test Loss Energy: 57.71646706804266, Test Loss Force: 11.550432286220062, time: 9.83864974975586


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 15.72490565584283, Training Loss Force: 7.344139127565617, time: 1.0323834419250488
Validation Loss Energy: 12.389160309741175, Validation Loss Force: 6.528524866438599, time: 0.07498359680175781
Test Loss Energy: 19.475534459221723, Test Loss Force: 11.444905708004299, time: 9.809277296066284


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.212944531246046, Training Loss Force: 5.418365869462593, time: 1.2238502502441406
Validation Loss Energy: 6.0216530694516095, Validation Loss Force: 4.328574858240918, time: 0.0747988224029541
Test Loss Energy: 9.258322161407445, Test Loss Force: 10.435996023363774, time: 9.76106333732605


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.108164310690507, Training Loss Force: 5.823399512669121, time: 1.0262022018432617
Validation Loss Energy: 29.453080312242932, Validation Loss Force: 7.52574084305609, time: 0.07289290428161621
Test Loss Energy: 36.48522380159685, Test Loss Force: 12.801558828413683, time: 9.798544883728027


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.820228989132134, Training Loss Force: 4.995015131489315, time: 0.9908747673034668
Validation Loss Energy: 9.330669996980081, Validation Loss Force: 4.094718814421719, time: 0.07464218139648438
Test Loss Energy: 16.709574440545826, Test Loss Force: 10.334412498363472, time: 10.465601444244385


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.218076037143585, Training Loss Force: 3.937722373559985, time: 0.9805302619934082
Validation Loss Energy: 3.1190047725461723, Validation Loss Force: 4.489873938190403, time: 0.0741734504699707
Test Loss Energy: 9.557598554186757, Test Loss Force: 10.65689620632143, time: 9.6957528591156


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.412353836325534, Training Loss Force: 3.922686773082696, time: 0.9576468467712402
Validation Loss Energy: 9.95389020808982, Validation Loss Force: 4.20892804605954, time: 0.07356548309326172
Test Loss Energy: 19.43242190737591, Test Loss Force: 10.349308075621664, time: 9.849305868148804


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.503344843978429, Training Loss Force: 3.8232582652747698, time: 0.9812662601470947
Validation Loss Energy: 11.555392170331373, Validation Loss Force: 4.019634555745723, time: 0.07480478286743164
Test Loss Energy: 10.126793291873321, Test Loss Force: 10.193554463497263, time: 10.011943340301514


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 15.641043098702978, Training Loss Force: 5.532948953053464, time: 0.995222806930542
Validation Loss Energy: 2.3117871454239336, Validation Loss Force: 7.335267874276292, time: 0.07950901985168457
Test Loss Energy: 11.11913284334017, Test Loss Force: 12.450430784320897, time: 9.79474139213562


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.399473259058475, Training Loss Force: 5.485787421181752, time: 1.0308287143707275
Validation Loss Energy: 10.26628611306067, Validation Loss Force: 4.173854315538724, time: 0.07247018814086914
Test Loss Energy: 9.502365167097926, Test Loss Force: 10.286783540070147, time: 9.802159309387207


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.974035845786673, Training Loss Force: 6.651668691194798, time: 1.011610746383667
Validation Loss Energy: 9.152941719436607, Validation Loss Force: 5.235766144498096, time: 0.0840909481048584
Test Loss Energy: 16.30414054876674, Test Loss Force: 10.602216283796425, time: 9.887757301330566


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.233138803256675, Training Loss Force: 4.145878765251052, time: 1.045710563659668
Validation Loss Energy: 3.1096130333092296, Validation Loss Force: 4.516950729004368, time: 0.07625222206115723
Test Loss Energy: 10.218630651309946, Test Loss Force: 10.614049682317225, time: 9.771368741989136


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.266455616958339, Training Loss Force: 3.866091789681035, time: 1.0176897048950195
Validation Loss Energy: 7.318797037552014, Validation Loss Force: 3.7560722211682966, time: 0.07885289192199707
Test Loss Energy: 16.34242148325576, Test Loss Force: 10.15779760851869, time: 9.828256607055664


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 9.499662329321744, Training Loss Force: 3.9313560622756776, time: 1.0004241466522217
Validation Loss Energy: 51.426039568040025, Validation Loss Force: 7.753491076224803, time: 0.07906436920166016
Test Loss Energy: 40.899969916067725, Test Loss Force: 12.701561542450229, time: 9.891387224197388

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–â–â–ƒâ–ˆâ–‚â–â–…â–‚â–â–‚â–â–â–â–‚â–â–‚â–†
wandb:   test_error_force â–ƒâ–‚â–…â–ˆâ–…â–‚â–„â–„â–‚â–‡â–â–‚â–â–â–†â–â–‚â–‚â–â–‡
wandb:          test_loss â–ƒâ–â–ˆâ–ƒâ–‚â–ƒâ–ˆâ–ƒâ–â–†â–‚â–â–‚â–â–ƒâ–â–‚â–â–‚â–†
wandb: train_error_energy â–ˆâ–ƒâ–â–ˆâ–ƒâ–„â–ƒâ–†â–â–„â–â–â–â–â–†â–‚â–„â–â–â–‚
wandb:  train_error_force â–ˆâ–„â–ƒâ–…â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–‚â–â–â–â–ƒâ–ƒâ–„â–â–â–
wandb:         train_loss â–ˆâ–„â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–‚â–ƒâ–‚â–â–â–â–„â–‚â–„â–â–â–
wandb: valid_error_energy â–‚â–‚â–ˆâ–â–‚â–ƒâ–ˆâ–‚â–‚â–…â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–ˆ
wandb:  valid_error_force â–„â–‚â–ƒâ–ˆâ–†â–ƒâ–„â–…â–‚â–†â–â–‚â–‚â–â–†â–‚â–ƒâ–‚â–â–‡
wandb:         valid_loss â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–‡â–ƒâ–â–…â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2211
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 40.89997
wandb:   test_error_force 12.70156
wandb:          test_loss 6.98704
wandb: train_error_energy 9.49966
wandb:  train_error_force 3.93136
wandb:         train_loss 1.95117
wandb: valid_error_energy 51.42604
wandb:  valid_error_force 7.75349
wandb:         valid_loss 6.03581
wandb: 
wandb: ğŸš€ View run al_74_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/o03dgjl9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_024704-o03dgjl9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3247249126434326, Uncertainty Bias: 0.05193553864955902
0.000207901 0.53809357
0.8079383 4.8611746
(48745, 22, 3)
Found uncertainty sample 0 after 7 steps.
Found uncertainty sample 1 after 2 steps.
Found uncertainty sample 2 after 9 steps.
Found uncertainty sample 3 after 3 steps.
Found uncertainty sample 4 after 5 steps.
Found uncertainty sample 5 after 41 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 27 steps.
Found uncertainty sample 8 after 4 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 9 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 4 steps.
Found uncertainty sample 14 after 5 steps.
Found uncertainty sample 15 after 3 steps.
Found uncertainty sample 16 after 6 steps.
Found uncertainty sample 17 after 43 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 2 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 2 steps.
Found uncertainty sample 22 after 9 steps.
Found uncertainty sample 23 after 22 steps.
Found uncertainty sample 24 after 2 steps.
Found uncertainty sample 25 after 21 steps.
Found uncertainty sample 26 after 8 steps.
Found uncertainty sample 27 after 18 steps.
Found uncertainty sample 28 after 4 steps.
Found uncertainty sample 29 after 10 steps.
Found uncertainty sample 30 after 9 steps.
Found uncertainty sample 31 after 5 steps.
Found uncertainty sample 32 after 14 steps.
Found uncertainty sample 33 after 25 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 46 steps.
Found uncertainty sample 36 after 3 steps.
Found uncertainty sample 37 after 10 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 13 steps.
Found uncertainty sample 40 after 5 steps.
Found uncertainty sample 41 after 6 steps.
Found uncertainty sample 42 after 12 steps.
Found uncertainty sample 43 after 8 steps.
Found uncertainty sample 44 after 12 steps.
Found uncertainty sample 45 after 4 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 2 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 2 steps.
Found uncertainty sample 50 after 4 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 4 steps.
Found uncertainty sample 53 after 7 steps.
Found uncertainty sample 54 after 5 steps.
Found uncertainty sample 55 after 7 steps.
Found uncertainty sample 56 after 26 steps.
Found uncertainty sample 57 after 19 steps.
Found uncertainty sample 58 after 11 steps.
Found uncertainty sample 59 after 5 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 19 steps.
Found uncertainty sample 62 after 2 steps.
Found uncertainty sample 63 after 8 steps.
Found uncertainty sample 64 after 2 steps.
Found uncertainty sample 65 after 2 steps.
Found uncertainty sample 66 after 9 steps.
Found uncertainty sample 67 after 7 steps.
Found uncertainty sample 68 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 3 steps.
Found uncertainty sample 71 after 9 steps.
Found uncertainty sample 72 after 3 steps.
Found uncertainty sample 73 after 11 steps.
Found uncertainty sample 74 after 78 steps.
Found uncertainty sample 75 after 21 steps.
Found uncertainty sample 76 after 6 steps.
Found uncertainty sample 77 after 8 steps.
Found uncertainty sample 78 after 8 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 21 steps.
Found uncertainty sample 81 after 23 steps.
Found uncertainty sample 82 after 22 steps.
Found uncertainty sample 83 after 2 steps.
Found uncertainty sample 84 after 4 steps.
Found uncertainty sample 85 after 12 steps.
Found uncertainty sample 86 after 2 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 7 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 36 steps.
Found uncertainty sample 92 after 3 steps.
Found uncertainty sample 93 after 8 steps.
Found uncertainty sample 94 after 12 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 3 steps.
Found uncertainty sample 97 after 4 steps.
Found uncertainty sample 98 after 11 steps.
Found uncertainty sample 99 after 6 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_025344-divz3v7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/divz3v7t
Training model 17. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 22.88102388446349, Training Loss Force: 10.312151896502508, time: 1.1006605625152588
Validation Loss Energy: 2.650305481249301, Validation Loss Force: 7.277980669757721, time: 0.0781550407409668
Test Loss Energy: 11.698990028960095, Test Loss Force: 11.811999069238139, time: 9.75984501838684


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.868074491880451, Training Loss Force: 6.6936256633100655, time: 1.0411665439605713
Validation Loss Energy: 11.306546930284899, Validation Loss Force: 6.61529836459922, time: 0.0793919563293457
Test Loss Energy: 20.42532483742971, Test Loss Force: 11.780437189051367, time: 10.26427960395813


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.159523993235057, Training Loss Force: 5.060852779167019, time: 1.0873923301696777
Validation Loss Energy: 2.8831828941721485, Validation Loss Force: 4.328697771609471, time: 0.07829785346984863
Test Loss Energy: 11.819554538800913, Test Loss Force: 10.364474395245164, time: 9.937250852584839


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.150749752651295, Training Loss Force: 4.028329711671154, time: 1.0275473594665527
Validation Loss Energy: 8.768533276657834, Validation Loss Force: 3.9687094540645997, time: 0.0749053955078125
Test Loss Energy: 18.819186369630312, Test Loss Force: 10.174274892155935, time: 9.822135210037231


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 7.282068417568155, Training Loss Force: 3.93414041244091, time: 1.0201787948608398
Validation Loss Energy: 9.497297326922471, Validation Loss Force: 4.02101866715681, time: 0.07442688941955566
Test Loss Energy: 18.880994558720655, Test Loss Force: 10.227654813916665, time: 9.792251586914062


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.776909883050482, Training Loss Force: 3.848099780292079, time: 1.0046842098236084
Validation Loss Energy: 7.247301092162644, Validation Loss Force: 4.666565913528729, time: 0.07636427879333496
Test Loss Energy: 15.713118191235523, Test Loss Force: 10.709954766374883, time: 9.94343614578247


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.628590700993216, Training Loss Force: 4.285763900645707, time: 1.0352575778961182
Validation Loss Energy: 4.14613445623132, Validation Loss Force: 3.908086443070884, time: 0.07975506782531738
Test Loss Energy: 14.81159300818501, Test Loss Force: 10.18198333425616, time: 9.890848159790039


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.485952415003464, Training Loss Force: 3.859753640123517, time: 1.0068926811218262
Validation Loss Energy: 10.911174258760642, Validation Loss Force: 3.750553700390195, time: 0.07805156707763672
Test Loss Energy: 20.57095059876333, Test Loss Force: 10.246278404285702, time: 10.060123920440674


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.255750968088243, Training Loss Force: 4.244440011107931, time: 1.0050508975982666
Validation Loss Energy: 5.540790810062152, Validation Loss Force: 5.130023239126741, time: 0.07628536224365234
Test Loss Energy: 10.371648888391524, Test Loss Force: 10.818991692199408, time: 9.835007429122925


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 8.500248178977314, Training Loss Force: 5.440749397654311, time: 1.0528016090393066
Validation Loss Energy: 23.34972881980469, Validation Loss Force: 6.2002001014446595, time: 0.08257603645324707
Test Loss Energy: 16.804922814432842, Test Loss Force: 11.181827423507524, time: 9.796533584594727


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 14.4105899815023, Training Loss Force: 7.172454347242304, time: 1.0082054138183594
Validation Loss Energy: 20.859614416834734, Validation Loss Force: 6.502331849464822, time: 0.07541775703430176
Test Loss Energy: 14.662944682237441, Test Loss Force: 12.24891847617921, time: 9.978605270385742


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.388462348335471, Training Loss Force: 6.268170297392156, time: 1.0777065753936768
Validation Loss Energy: 13.10132749254494, Validation Loss Force: 9.508890373336055, time: 0.0877985954284668
Test Loss Energy: 10.957048152835448, Test Loss Force: 13.369566695251782, time: 10.445965766906738


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 17.366461931829733, Training Loss Force: 7.779129919176398, time: 1.0634593963623047
Validation Loss Energy: 3.581656147170498, Validation Loss Force: 6.32214174184397, time: 0.07557892799377441
Test Loss Energy: 8.962640837766592, Test Loss Force: 11.416806713089805, time: 9.850302934646606


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.030523301756798, Training Loss Force: 4.924227311625685, time: 1.0814518928527832
Validation Loss Energy: 4.563170386293745, Validation Loss Force: 4.48898058957694, time: 0.07431411743164062
Test Loss Energy: 9.145929142899357, Test Loss Force: 10.58728365252706, time: 10.103107929229736


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.009578644488256, Training Loss Force: 4.068872227342226, time: 1.0370776653289795
Validation Loss Energy: 6.332840103629216, Validation Loss Force: 3.7999404922766757, time: 0.07542157173156738
Test Loss Energy: 8.906757900297139, Test Loss Force: 10.157796983646111, time: 9.85847520828247


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.175611798824188, Training Loss Force: 3.8963416414490957, time: 1.0180885791778564
Validation Loss Energy: 7.441811275227257, Validation Loss Force: 3.858293391327658, time: 0.07868695259094238
Test Loss Energy: 9.564245640888398, Test Loss Force: 10.175817296847828, time: 9.74390172958374


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.331337785499056, Training Loss Force: 3.7693473381438625, time: 0.9778938293457031
Validation Loss Energy: 6.4863909653078515, Validation Loss Force: 3.895131774829951, time: 0.08025312423706055
Test Loss Energy: 10.783805457801162, Test Loss Force: 10.217527107685955, time: 10.022905826568604


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.336102976352332, Training Loss Force: 3.8006400599732677, time: 1.0663137435913086
Validation Loss Energy: 3.8368147255114637, Validation Loss Force: 3.962001546043525, time: 0.07809042930603027
Test Loss Energy: 10.756235921151786, Test Loss Force: 10.179543052956232, time: 9.8241708278656


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.238078782497364, Training Loss Force: 3.7725449010982834, time: 1.072697401046753
Validation Loss Energy: 7.0262701231414475, Validation Loss Force: 3.8364780497628206, time: 0.08215594291687012
Test Loss Energy: 9.904965816664227, Test Loss Force: 10.14830273499555, time: 9.813271760940552


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.414379849779506, Training Loss Force: 3.6505874573748653, time: 1.2005615234375
Validation Loss Energy: 8.458752843475054, Validation Loss Force: 4.24524003970086, time: 0.08014369010925293
Test Loss Energy: 9.899958237055019, Test Loss Force: 10.365946688301268, time: 9.865652799606323

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–‡â–‡â–…â–…â–ˆâ–‚â–†â–„â–‚â–â–â–â–â–‚â–‚â–‚â–‚
wandb:   test_error_force â–…â–…â–â–â–â–‚â–â–â–‚â–ƒâ–†â–ˆâ–„â–‚â–â–â–â–â–â–
wandb:          test_loss â–…â–ˆâ–‚â–…â–…â–„â–ƒâ–…â–ƒâ–†â–‡â–‡â–ƒâ–‚â–â–â–‚â–‚â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–‚â–‚â–„â–„â–†â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–â–â–‚â–â–‚â–ƒâ–…â–„â–…â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–‚â–â–â–â–â–â–‚â–‚â–…â–„â–…â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–„â–â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ˆâ–‡â–…â–â–‚â–‚â–ƒâ–‚â–â–‚â–ƒ
wandb:  valid_error_force â–…â–„â–‚â–â–â–‚â–â–â–ƒâ–„â–„â–ˆâ–„â–‚â–â–â–â–â–â–‚
wandb:         valid_loss â–„â–…â–â–‚â–‚â–‚â–â–‚â–‚â–‡â–‡â–ˆâ–ƒâ–‚â–â–‚â–â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2301
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.89996
wandb:   test_error_force 10.36595
wandb:          test_loss 4.13099
wandb: train_error_energy 7.41438
wandb:  train_error_force 3.65059
wandb:         train_loss 1.71767
wandb: valid_error_energy 8.45875
wandb:  valid_error_force 4.24524
wandb:         valid_loss 1.98654
wandb: 
wandb: ğŸš€ View run al_74_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/divz3v7t
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_025344-divz3v7t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2760093212127686, Uncertainty Bias: 0.04473920166492462
0.00033569336 2.155613
0.8378619 5.865179
(48745, 22, 3)
Found uncertainty sample 0 after 6 steps.
Found uncertainty sample 1 after 4 steps.
Found uncertainty sample 2 after 5 steps.
Found uncertainty sample 3 after 2 steps.
Found uncertainty sample 4 after 10 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 10 steps.
Found uncertainty sample 7 after 17 steps.
Found uncertainty sample 8 after 9 steps.
Found uncertainty sample 9 after 6 steps.
Found uncertainty sample 10 after 11 steps.
Found uncertainty sample 11 after 14 steps.
Found uncertainty sample 12 after 2 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 2 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 4 steps.
Found uncertainty sample 17 after 3 steps.
Found uncertainty sample 18 after 9 steps.
Found uncertainty sample 19 after 5 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 4 steps.
Found uncertainty sample 23 after 5 steps.
Found uncertainty sample 24 after 12 steps.
Found uncertainty sample 25 after 21 steps.
Found uncertainty sample 26 after 3 steps.
Found uncertainty sample 27 after 6 steps.
Found uncertainty sample 28 after 3 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 2 steps.
Found uncertainty sample 32 after 13 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 5 steps.
Found uncertainty sample 35 after 5 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 8 steps.
Found uncertainty sample 38 after 14 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 3 steps.
Found uncertainty sample 41 after 6 steps.
Found uncertainty sample 42 after 5 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 14 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 9 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 6 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 9 steps.
Found uncertainty sample 51 after 4 steps.
Found uncertainty sample 52 after 3 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 4 steps.
Found uncertainty sample 57 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 2 steps.
Found uncertainty sample 61 after 2 steps.
Found uncertainty sample 62 after 10 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 14 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 4 steps.
Found uncertainty sample 67 after 2 steps.
Found uncertainty sample 68 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 6 steps.
Found uncertainty sample 71 after 10 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 8 steps.
Found uncertainty sample 74 after 29 steps.
Found uncertainty sample 75 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 2 steps.
Found uncertainty sample 79 after 3 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 7 steps.
Found uncertainty sample 82 after 18 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 4 steps.
Found uncertainty sample 85 after 3 steps.
Found uncertainty sample 86 after 5 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 19 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 4 steps.
Found uncertainty sample 92 after 9 steps.
Found uncertainty sample 93 after 3 steps.
Found uncertainty sample 94 after 7 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 9 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 14 steps.
Found uncertainty sample 99 after 9 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_030020-htpjtdzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/htpjtdzw
Training model 18. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 17.897241437915607, Training Loss Force: 8.471525528676402, time: 1.0631413459777832
Validation Loss Energy: 16.23101671005474, Validation Loss Force: 6.131451670646893, time: 0.07840967178344727
Test Loss Energy: 24.924878257020715, Test Loss Force: 11.176432222381731, time: 9.755448579788208


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.869917418779822, Training Loss Force: 5.977103110113121, time: 1.0940256118774414
Validation Loss Energy: 5.699300290951452, Validation Loss Force: 6.0432317137143245, time: 0.08121323585510254
Test Loss Energy: 10.071878118812739, Test Loss Force: 11.345219058323295, time: 9.67713713645935


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 12.066174272065691, Training Loss Force: 5.732000311967162, time: 1.087451696395874
Validation Loss Energy: 5.774519709799026, Validation Loss Force: 5.438955748201829, time: 0.08043742179870605
Test Loss Energy: 17.116359008389903, Test Loss Force: 11.19816108437984, time: 9.9117112159729


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.911709294080062, Training Loss Force: 5.260619910471386, time: 1.0560252666473389
Validation Loss Energy: 25.60559795328836, Validation Loss Force: 6.334789572001814, time: 0.07506465911865234
Test Loss Energy: 17.67182771577402, Test Loss Force: 11.65751098729526, time: 9.7867431640625


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 16.879435690712466, Training Loss Force: 7.136019909322099, time: 1.0833513736724854
Validation Loss Energy: 5.150580945355378, Validation Loss Force: 4.760240596529091, time: 0.0803518295288086
Test Loss Energy: 14.91012230058875, Test Loss Force: 10.74810155377865, time: 9.747318983078003


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.9407408170384555, Training Loss Force: 4.206649496440637, time: 1.0545835494995117
Validation Loss Energy: 4.442349662375035, Validation Loss Force: 4.126174393990354, time: 0.07695221900939941
Test Loss Energy: 14.345884028867234, Test Loss Force: 10.286073451661204, time: 10.462220907211304


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.05516718672062, Training Loss Force: 3.8745306154597166, time: 1.0792341232299805
Validation Loss Energy: 7.643117988633026, Validation Loss Force: 4.043247059987342, time: 0.07492184638977051
Test Loss Energy: 9.611626669328704, Test Loss Force: 10.449601094190276, time: 9.668368101119995


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.2161139684541835, Training Loss Force: 3.7886481293709857, time: 1.1133840084075928
Validation Loss Energy: 5.489673544908094, Validation Loss Force: 3.723422578304624, time: 0.07850074768066406
Test Loss Energy: 9.618207682750162, Test Loss Force: 10.070618730102739, time: 9.814899921417236


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.331354238398544, Training Loss Force: 3.848163536530107, time: 1.2799403667449951
Validation Loss Energy: 5.036901220946572, Validation Loss Force: 3.80996639324122, time: 0.0762944221496582
Test Loss Energy: 16.27801891182682, Test Loss Force: 10.153990353171263, time: 9.730905294418335


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.400891915530668, Training Loss Force: 3.8654686878238786, time: 1.0926649570465088
Validation Loss Energy: 10.164451051200347, Validation Loss Force: 3.926257136055175, time: 0.07891321182250977
Test Loss Energy: 19.88176026041153, Test Loss Force: 10.176012835332166, time: 9.795512437820435


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.461757790277387, Training Loss Force: 3.736980595316746, time: 1.056494951248169
Validation Loss Energy: 8.34461263927247, Validation Loss Force: 3.7608771986682723, time: 0.07835841178894043
Test Loss Energy: 10.136574869991852, Test Loss Force: 10.06269307483357, time: 10.00831913948059


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.570395302509223, Training Loss Force: 3.6725806673008803, time: 1.0689122676849365
Validation Loss Energy: 7.14116717977104, Validation Loss Force: 4.3186812227490545, time: 0.07975435256958008
Test Loss Energy: 11.368191048354717, Test Loss Force: 10.499575530354484, time: 9.714502811431885


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 9.01091178311965, Training Loss Force: 4.786461791541055, time: 1.0846078395843506
Validation Loss Energy: 8.444278012974872, Validation Loss Force: 4.3374626972006265, time: 0.07993435859680176
Test Loss Energy: 17.810886719174746, Test Loss Force: 10.455548160392631, time: 9.848830938339233


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.275282527022652, Training Loss Force: 4.366265901281408, time: 1.0916736125946045
Validation Loss Energy: 55.11282427640826, Validation Loss Force: 5.7697445699646055, time: 0.0812833309173584
Test Loss Energy: 44.20789369081042, Test Loss Force: 11.09911121716068, time: 9.884306907653809


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 16.483059657172053, Training Loss Force: 7.549569520442421, time: 1.0757672786712646
Validation Loss Energy: 23.12889624899251, Validation Loss Force: 5.925768172508769, time: 0.08057045936584473
Test Loss Energy: 16.10335101301466, Test Loss Force: 11.291141960632473, time: 9.776307582855225


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.15500568585302, Training Loss Force: 6.337970323559422, time: 1.0809721946716309
Validation Loss Energy: 11.155320289151458, Validation Loss Force: 5.298443723701288, time: 0.0791161060333252
Test Loss Energy: 9.765355297929055, Test Loss Force: 10.986457771348032, time: 9.787275075912476


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 13.802873483267128, Training Loss Force: 6.908645716838106, time: 1.0535001754760742
Validation Loss Energy: 37.941450824156135, Validation Loss Force: 6.815815047875236, time: 0.07990407943725586
Test Loss Energy: 44.88443515327544, Test Loss Force: 12.104485190894334, time: 9.94294786453247


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 12.617337842032004, Training Loss Force: 7.12432675679835, time: 1.0711960792541504
Validation Loss Energy: 11.671247372295895, Validation Loss Force: 6.927781333206127, time: 0.07692170143127441
Test Loss Energy: 22.884746031022786, Test Loss Force: 11.492943692031586, time: 9.719592332839966


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.443623080669337, Training Loss Force: 5.421362382872334, time: 1.0695252418518066
Validation Loss Energy: 5.158431368764209, Validation Loss Force: 4.066486148071243, time: 0.07544422149658203
Test Loss Energy: 9.235721257085459, Test Loss Force: 10.360092331738501, time: 9.688858032226562


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.063698478937102, Training Loss Force: 3.7760185758966394, time: 1.0478966236114502
Validation Loss Energy: 9.981506526244369, Validation Loss Force: 3.6878149985064463, time: 0.07897233963012695
Test Loss Energy: 19.401028719468798, Test Loss Force: 10.099752635248771, time: 9.867607593536377

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–ƒâ–â–â–ƒâ–ˆâ–‚â–â–ˆâ–„â–â–ƒ
wandb:   test_error_force â–…â–…â–…â–†â–ƒâ–‚â–‚â–â–â–â–â–‚â–‚â–…â–…â–„â–ˆâ–†â–‚â–
wandb:          test_loss â–„â–‚â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–ƒâ–â–‚â–ƒâ–‡â–ƒâ–‚â–ˆâ–„â–â–ƒ
wandb: train_error_energy â–ˆâ–„â–„â–ƒâ–‡â–â–â–â–â–â–â–â–‚â–„â–‡â–„â–…â–…â–‚â–
wandb:  train_error_force â–ˆâ–„â–„â–ƒâ–†â–‚â–â–â–â–â–â–â–ƒâ–‚â–‡â–…â–†â–†â–„â–
wandb:         train_loss â–ˆâ–„â–„â–ƒâ–†â–â–â–â–â–â–â–â–‚â–‚â–‡â–„â–†â–†â–ƒâ–
wandb: valid_error_energy â–ƒâ–â–â–„â–â–â–â–â–â–‚â–‚â–â–‚â–ˆâ–„â–‚â–†â–‚â–â–‚
wandb:  valid_error_force â–†â–†â–…â–‡â–ƒâ–‚â–‚â–â–â–‚â–â–‚â–‚â–…â–†â–„â–ˆâ–ˆâ–‚â–
wandb:         valid_loss â–„â–‚â–‚â–…â–‚â–â–â–â–â–‚â–â–‚â–‚â–ˆâ–„â–ƒâ–‡â–„â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2391
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 19.40103
wandb:   test_error_force 10.09975
wandb:          test_loss 4.67774
wandb: train_error_energy 7.0637
wandb:  train_error_force 3.77602
wandb:         train_loss 1.73618
wandb: valid_error_energy 9.98151
wandb:  valid_error_force 3.68781
wandb:         valid_loss 1.90192
wandb: 
wandb: ğŸš€ View run al_74_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/htpjtdzw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_030020-htpjtdzw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.987962245941162, Uncertainty Bias: 0.03679083287715912
6.866455e-05 0.43428344
0.6500498 3.283008
(48745, 22, 3)
Found uncertainty sample 0 after 22 steps.
Found uncertainty sample 1 after 4 steps.
Found uncertainty sample 2 after 4 steps.
Found uncertainty sample 3 after 189 steps.
Found uncertainty sample 4 after 20 steps.
Found uncertainty sample 5 after 35 steps.
Found uncertainty sample 6 after 35 steps.
Found uncertainty sample 7 after 149 steps.
Found uncertainty sample 8 after 28 steps.
Found uncertainty sample 9 after 125 steps.
Found uncertainty sample 10 after 36 steps.
Found uncertainty sample 11 after 7 steps.
Found uncertainty sample 12 after 48 steps.
Found uncertainty sample 13 after 53 steps.
Found uncertainty sample 14 after 166 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 35 steps.
Found uncertainty sample 17 after 14 steps.
Found uncertainty sample 18 after 59 steps.
Found uncertainty sample 19 after 147 steps.
Found uncertainty sample 20 after 25 steps.
Found uncertainty sample 21 after 20 steps.
Found uncertainty sample 22 after 113 steps.
Found uncertainty sample 23 after 42 steps.
Found uncertainty sample 24 after 12 steps.
Found uncertainty sample 25 after 30 steps.
Found uncertainty sample 26 after 4 steps.
Found uncertainty sample 27 after 36 steps.
Found uncertainty sample 28 after 23 steps.
Found uncertainty sample 29 after 3 steps.
Found uncertainty sample 30 after 94 steps.
Found uncertainty sample 31 after 15 steps.
Found uncertainty sample 32 after 117 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 44 steps.
Found uncertainty sample 35 after 81 steps.
Found uncertainty sample 36 after 45 steps.
Found uncertainty sample 37 after 14 steps.
Found uncertainty sample 38 after 34 steps.
Found uncertainty sample 39 after 3 steps.
Found uncertainty sample 40 after 13 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 134 steps.
Found uncertainty sample 43 after 11 steps.
Found uncertainty sample 44 after 9 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 32 steps.
Found uncertainty sample 47 after 67 steps.
Found uncertainty sample 48 after 19 steps.
Found uncertainty sample 49 after 20 steps.
Found uncertainty sample 50 after 21 steps.
Found uncertainty sample 51 after 2 steps.
Found uncertainty sample 52 after 161 steps.
Found uncertainty sample 53 after 7 steps.
Found uncertainty sample 54 after 22 steps.
Found uncertainty sample 55 after 110 steps.
Found uncertainty sample 56 after 7 steps.
Found uncertainty sample 57 after 205 steps.
Found uncertainty sample 58 after 62 steps.
Found uncertainty sample 59 after 42 steps.
Found uncertainty sample 60 after 20 steps.
Found uncertainty sample 61 after 232 steps.
Found uncertainty sample 62 after 33 steps.
Found uncertainty sample 63 after 174 steps.
Found uncertainty sample 64 after 9 steps.
Found uncertainty sample 65 after 165 steps.
Found uncertainty sample 66 after 144 steps.
Found uncertainty sample 67 after 7 steps.
Found uncertainty sample 68 after 129 steps.
Found uncertainty sample 69 after 11 steps.
Found uncertainty sample 70 after 73 steps.
Found uncertainty sample 71 after 54 steps.
Found uncertainty sample 72 after 116 steps.
Found uncertainty sample 73 after 69 steps.
Found uncertainty sample 74 after 130 steps.
Found uncertainty sample 75 after 26 steps.
Found uncertainty sample 76 after 63 steps.
Found uncertainty sample 77 after 27 steps.
Found uncertainty sample 78 after 54 steps.
Found uncertainty sample 79 after 43 steps.
Found uncertainty sample 80 after 69 steps.
Found uncertainty sample 81 after 5 steps.
Found uncertainty sample 82 after 11 steps.
Found uncertainty sample 83 after 441 steps.
Found uncertainty sample 84 after 39 steps.
Found uncertainty sample 85 after 3 steps.
Found uncertainty sample 86 after 24 steps.
Found uncertainty sample 87 after 2 steps.
Found uncertainty sample 88 after 13 steps.
Found uncertainty sample 89 after 204 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 96 steps.
Found uncertainty sample 92 after 32 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 32 steps.
Found uncertainty sample 95 after 224 steps.
Found uncertainty sample 96 after 25 steps.
Found uncertainty sample 97 after 87 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 14 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_030836-as2q19v4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/as2q19v4
Training model 19. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.495869988988808, Training Loss Force: 8.523306598645043, time: 1.145857334136963
Validation Loss Energy: 6.428732125984727, Validation Loss Force: 7.443475727093068, time: 0.08072471618652344
Test Loss Energy: 9.14555916703823, Test Loss Force: 12.552345701632309, time: 9.737825870513916


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 15.433067513420418, Training Loss Force: 6.522483064603369, time: 1.14729642868042
Validation Loss Energy: 2.5895989693258628, Validation Loss Force: 5.322654539938016, time: 0.07853388786315918
Test Loss Energy: 12.422384003572413, Test Loss Force: 11.26046395337949, time: 9.742005348205566


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.1648342665007405, Training Loss Force: 5.586545194461648, time: 1.1393656730651855
Validation Loss Energy: 3.820528258840013, Validation Loss Force: 4.073965159344665, time: 0.08224320411682129
Test Loss Energy: 13.854814381501232, Test Loss Force: 10.087354160725962, time: 9.888737440109253


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.9532953691498545, Training Loss Force: 3.913168991934921, time: 1.0835211277008057
Validation Loss Energy: 8.299390317087703, Validation Loss Force: 3.9340783898058884, time: 0.07711911201477051
Test Loss Energy: 9.734424930756276, Test Loss Force: 10.241010066282735, time: 9.683800458908081


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.500337840238151, Training Loss Force: 4.8673783585251895, time: 1.1219518184661865
Validation Loss Energy: 9.683355211876812, Validation Loss Force: 6.826451952976207, time: 0.08805727958679199
Test Loss Energy: 9.996080986614766, Test Loss Force: 11.548527348179226, time: 9.84559416770935


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 10.257176036019663, Training Loss Force: 6.47849619648219, time: 1.136150598526001
Validation Loss Energy: 25.539681651357647, Validation Loss Force: 6.592001827875672, time: 0.07508587837219238
Test Loss Energy: 18.203407367334695, Test Loss Force: 11.910854074141053, time: 10.458130598068237


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.179531510375393, Training Loss Force: 6.611556255446342, time: 1.1268386840820312
Validation Loss Energy: 4.114241331790938, Validation Loss Force: 5.817762503276495, time: 0.0845954418182373
Test Loss Energy: 9.545486798249025, Test Loss Force: 11.268267068338362, time: 9.842411994934082


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.957496741322696, Training Loss Force: 5.940816084876984, time: 1.0940444469451904
Validation Loss Energy: 3.981565479873886, Validation Loss Force: 5.143787977720558, time: 0.07735204696655273
Test Loss Energy: 9.52173517708671, Test Loss Force: 10.864138908430995, time: 9.874957799911499


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.78526233081336, Training Loss Force: 5.90884896576657, time: 1.1247708797454834
Validation Loss Energy: 11.620067314442682, Validation Loss Force: 5.191474134005016, time: 0.08237075805664062
Test Loss Energy: 10.237020152287228, Test Loss Force: 11.058400148556268, time: 9.71553897857666


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.050722448444107, Training Loss Force: 5.842105345188362, time: 1.159257173538208
Validation Loss Energy: 3.7905543197683818, Validation Loss Force: 5.764014847501592, time: 0.0825505256652832
Test Loss Energy: 13.075548591218691, Test Loss Force: 10.960646602814345, time: 9.803747415542603


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.08268871673225, Training Loss Force: 4.42889175615484, time: 1.1347527503967285
Validation Loss Energy: 2.8414161744630357, Validation Loss Force: 4.394683991652004, time: 0.07948160171508789
Test Loss Energy: 12.380354943469378, Test Loss Force: 10.263439298522247, time: 9.915050506591797


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.251343486471779, Training Loss Force: 4.55051437161742, time: 1.1393256187438965
Validation Loss Energy: 7.0090557941389156, Validation Loss Force: 4.275012463195427, time: 0.08116888999938965
Test Loss Energy: 8.910166720101815, Test Loss Force: 10.2584065328176, time: 9.738893985748291


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 19.128879413094825, Training Loss Force: 6.788720968800403, time: 1.1032404899597168
Validation Loss Energy: 2.76609377113547, Validation Loss Force: 8.944635624097744, time: 0.07981252670288086
Test Loss Energy: 9.265531908558895, Test Loss Force: 13.437377857987213, time: 9.7066171169281


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 6.787033955982539, Training Loss Force: 6.258178042782295, time: 1.1571316719055176
Validation Loss Energy: 3.1754448322990614, Validation Loss Force: 4.261718892514391, time: 0.08991360664367676
Test Loss Energy: 12.88010558181659, Test Loss Force: 10.087190714578007, time: 9.931018829345703


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.80154594082803, Training Loss Force: 4.016805983875536, time: 1.082228183746338
Validation Loss Energy: 5.619807405855233, Validation Loss Force: 3.78810173046056, time: 0.07920169830322266
Test Loss Energy: 10.063743079934746, Test Loss Force: 10.069325579620667, time: 9.77472710609436


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.923788589946377, Training Loss Force: 3.810268660897352, time: 1.1396987438201904
Validation Loss Energy: 7.201385600926605, Validation Loss Force: 3.7359793367817837, time: 0.08314085006713867
Test Loss Energy: 15.922883844354308, Test Loss Force: 9.943705412288033, time: 9.695004224777222


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.067015114055539, Training Loss Force: 3.7435900540002898, time: 1.1089587211608887
Validation Loss Energy: 3.1883388231977285, Validation Loss Force: 3.796763448902578, time: 0.07916474342346191
Test Loss Energy: 10.47995343091314, Test Loss Force: 10.137640622814615, time: 9.89896297454834


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.111044514838323, Training Loss Force: 3.8035661369020373, time: 1.1219744682312012
Validation Loss Energy: 5.541111230963142, Validation Loss Force: 3.9088704611336955, time: 0.08581328392028809
Test Loss Energy: 15.00920418086941, Test Loss Force: 10.07034464886605, time: 9.713249921798706


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.1561947978449165, Training Loss Force: 3.651086513646599, time: 1.1049716472625732
Validation Loss Energy: 2.9896117318475346, Validation Loss Force: 3.886017481348835, time: 0.07761502265930176
Test Loss Energy: 11.23829153910592, Test Loss Force: 10.129113718882385, time: 9.696901321411133


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.190196580541474, Training Loss Force: 3.631431622324859, time: 1.335252046585083
Validation Loss Energy: 8.45467220870678, Validation Loss Force: 3.7139390993795596, time: 0.0776369571685791
Test Loss Energy: 17.59939074259459, Test Loss Force: 10.050940462077884, time: 9.63454294204712

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–…â–‚â–‚â–ˆâ–â–â–‚â–„â–„â–â–â–„â–‚â–†â–‚â–†â–ƒâ–ˆ
wandb:   test_error_force â–†â–„â–â–‚â–„â–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–ˆâ–â–â–â–â–â–â–
wandb:          test_loss â–†â–„â–ƒâ–â–„â–ˆâ–ƒâ–‚â–ƒâ–„â–‚â–â–‡â–‚â–â–ƒâ–â–ƒâ–‚â–„
wandb: train_error_energy â–‡â–†â–â–â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–â–„â–ˆâ–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–„â–â–ƒâ–…â–…â–„â–„â–„â–‚â–‚â–†â–…â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–†â–ƒâ–â–ƒâ–…â–…â–„â–„â–„â–‚â–ƒâ–‡â–„â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–â–â–ƒâ–ƒâ–ˆâ–â–â–„â–â–â–‚â–â–â–‚â–‚â–â–‚â–â–ƒ
wandb:  valid_error_force â–†â–ƒâ–â–â–…â–…â–„â–ƒâ–ƒâ–„â–‚â–‚â–ˆâ–‚â–â–â–â–â–â–
wandb:         valid_loss â–…â–‚â–â–‚â–…â–ˆâ–ƒâ–‚â–„â–ƒâ–‚â–‚â–†â–â–â–‚â–â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2481
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 17.59939
wandb:   test_error_force 10.05094
wandb:          test_loss 4.54084
wandb: train_error_energy 7.1902
wandb:  train_error_force 3.63143
wandb:         train_loss 1.69626
wandb: valid_error_energy 8.45467
wandb:  valid_error_force 3.71394
wandb:         valid_loss 1.80849
wandb: 
wandb: ğŸš€ View run al_74_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/as2q19v4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_030836-as2q19v4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4487674236297607, Uncertainty Bias: 0.0049176812171936035
0.00012207031 0.22046852
0.2764369 4.272249
(48745, 22, 3)
Found uncertainty sample 0 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 15 steps.
Found uncertainty sample 3 after 14 steps.
Found uncertainty sample 4 after 3 steps.
Found uncertainty sample 5 after 3 steps.
Found uncertainty sample 6 after 9 steps.
Found uncertainty sample 7 after 58 steps.
Found uncertainty sample 8 after 8 steps.
Found uncertainty sample 9 after 29 steps.
Found uncertainty sample 10 after 5 steps.
Found uncertainty sample 11 after 2 steps.
Found uncertainty sample 12 after 5 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 14 steps.
Found uncertainty sample 15 after 47 steps.
Found uncertainty sample 16 after 23 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 21 steps.
Found uncertainty sample 20 after 2 steps.
Found uncertainty sample 21 after 8 steps.
Found uncertainty sample 22 after 12 steps.
Found uncertainty sample 23 after 9 steps.
Found uncertainty sample 24 after 6 steps.
Found uncertainty sample 25 after 10 steps.
Found uncertainty sample 26 after 11 steps.
Found uncertainty sample 27 after 9 steps.
Found uncertainty sample 28 after 4 steps.
Found uncertainty sample 29 after 46 steps.
Found uncertainty sample 30 after 6 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 2 steps.
Found uncertainty sample 34 after 63 steps.
Found uncertainty sample 35 after 40 steps.
Found uncertainty sample 36 after 3 steps.
Found uncertainty sample 37 after 7 steps.
Found uncertainty sample 38 after 5 steps.
Found uncertainty sample 39 after 2 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 26 steps.
Found uncertainty sample 42 after 22 steps.
Found uncertainty sample 43 after 2 steps.
Found uncertainty sample 44 after 27 steps.
Found uncertainty sample 45 after 4 steps.
Found uncertainty sample 46 after 19 steps.
Found uncertainty sample 47 after 16 steps.
Found uncertainty sample 48 after 57 steps.
Found uncertainty sample 49 after 34 steps.
Found uncertainty sample 50 after 11 steps.
Found uncertainty sample 51 after 7 steps.
Found uncertainty sample 52 after 9 steps.
Found uncertainty sample 53 after 24 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 15 steps.
Found uncertainty sample 56 after 68 steps.
Found uncertainty sample 57 after 56 steps.
Found uncertainty sample 58 after 17 steps.
Found uncertainty sample 59 after 18 steps.
Found uncertainty sample 60 after 21 steps.
Found uncertainty sample 61 after 10 steps.
Found uncertainty sample 62 after 7 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 2 steps.
Found uncertainty sample 65 after 25 steps.
Found uncertainty sample 66 after 10 steps.
Found uncertainty sample 67 after 11 steps.
Found uncertainty sample 68 after 22 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 8 steps.
Found uncertainty sample 74 after 5 steps.
Found uncertainty sample 75 after 8 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 19 steps.
Found uncertainty sample 79 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 27 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 4 steps.
Found uncertainty sample 84 after 60 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 18 steps.
Found uncertainty sample 87 after 12 steps.
Found uncertainty sample 88 after 7 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 56 steps.
Found uncertainty sample 91 after 2 steps.
Found uncertainty sample 92 after 2 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 17 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 30 steps.
Found uncertainty sample 97 after 6 steps.
Found uncertainty sample 98 after 3 steps.
Found uncertainty sample 99 after 4 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_031528-84tzvnan
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/84tzvnan
Training model 20. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 19.603906194124537, Training Loss Force: 9.045959668515168, time: 1.1791670322418213
Validation Loss Energy: 4.829398070547926, Validation Loss Force: 4.795408293429487, time: 0.08320951461791992
Test Loss Energy: 10.437843426495236, Test Loss Force: 10.526177018138071, time: 9.717890739440918


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.725778656388756, Training Loss Force: 4.109180059354997, time: 1.1734638214111328
Validation Loss Energy: 5.9526421117307935, Validation Loss Force: 4.227383310212327, time: 0.08330678939819336
Test Loss Energy: 9.048238177679703, Test Loss Force: 10.293135458417238, time: 9.746480226516724


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.148316478517383, Training Loss Force: 3.845016284418412, time: 1.1420879364013672
Validation Loss Energy: 9.19509165274586, Validation Loss Force: 4.4364794356809405, time: 0.08112788200378418
Test Loss Energy: 17.426024462686893, Test Loss Force: 10.235953154382537, time: 9.947014570236206


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.34838307322643, Training Loss Force: 3.872255598967889, time: 1.1826081275939941
Validation Loss Energy: 8.714404633974247, Validation Loss Force: 3.5963385053146846, time: 0.08504962921142578
Test Loss Energy: 19.03134578368463, Test Loss Force: 9.97661642967449, time: 9.78736925125122


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 12.684650458412719, Training Loss Force: 4.569307868193987, time: 1.179246187210083
Validation Loss Energy: 27.149999975763066, Validation Loss Force: 10.818956277312942, time: 0.08648252487182617
Test Loss Energy: 17.30796513229268, Test Loss Force: 14.469572444596963, time: 10.305952787399292


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.5471499206406785, Training Loss Force: 6.863612890604887, time: 1.170074224472046
Validation Loss Energy: 1.95497097253195, Validation Loss Force: 4.625814119786755, time: 0.08386445045471191
Test Loss Energy: 9.71048290066063, Test Loss Force: 10.60586937281999, time: 9.99998688697815


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.887101146837582, Training Loss Force: 4.293272724156417, time: 1.1566658020019531
Validation Loss Energy: 3.806408585627586, Validation Loss Force: 4.156208899069677, time: 0.08527302742004395
Test Loss Energy: 8.87585209901045, Test Loss Force: 10.495500223324417, time: 9.892449140548706


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.093777926677161, Training Loss Force: 3.757171035674412, time: 1.2177619934082031
Validation Loss Energy: 3.035444946834154, Validation Loss Force: 4.067554959971696, time: 0.08209896087646484
Test Loss Energy: 9.845626802235653, Test Loss Force: 10.388792780498097, time: 10.036185503005981


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.302422583579901, Training Loss Force: 3.668106700846475, time: 1.1567389965057373
Validation Loss Energy: 6.389038010685908, Validation Loss Force: 4.049554608884039, time: 0.08204460144042969
Test Loss Energy: 17.582369530695157, Test Loss Force: 10.233471734083547, time: 9.91595196723938


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.413556245747126, Training Loss Force: 3.6609563877184668, time: 1.1623144149780273
Validation Loss Energy: 11.098971635082972, Validation Loss Force: 3.81735589151798, time: 0.08414506912231445
Test Loss Energy: 20.744793143492217, Test Loss Force: 10.27413518180171, time: 9.881981134414673


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.6746681641026555, Training Loss Force: 3.71407263076757, time: 1.1815838813781738
Validation Loss Energy: 10.27697601341837, Validation Loss Force: 4.128833954269314, time: 0.08572649955749512
Test Loss Energy: 10.242945105461516, Test Loss Force: 10.377653941836378, time: 9.994511842727661


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.526866402600732, Training Loss Force: 3.6719989080352597, time: 1.2351562976837158
Validation Loss Energy: 3.9611990464416014, Validation Loss Force: 3.464173679087538, time: 0.0804443359375
Test Loss Energy: 10.697832616101524, Test Loss Force: 9.920899633698882, time: 9.877831220626831


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 15.696638879367471, Training Loss Force: 5.481166448195908, time: 1.1936564445495605
Validation Loss Energy: 18.094012855846337, Validation Loss Force: 9.126958902136584, time: 0.08887982368469238
Test Loss Energy: 28.011057361497226, Test Loss Force: 14.135517099106023, time: 9.828582525253296


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.271242889036087, Training Loss Force: 5.445125250475055, time: 1.148273229598999
Validation Loss Energy: 6.480794621663248, Validation Loss Force: 3.7182458546655215, time: 0.08831262588500977
Test Loss Energy: 9.809479392569965, Test Loss Force: 10.034053751669049, time: 9.965383768081665


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.645665386889482, Training Loss Force: 3.8486681601246953, time: 1.140655279159546
Validation Loss Energy: 27.79521678112243, Validation Loss Force: 4.484922667061552, time: 0.08302688598632812
Test Loss Energy: 35.26988791812293, Test Loss Force: 10.722275724055542, time: 9.803671836853027


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 14.268069525289517, Training Loss Force: 6.647543498720295, time: 1.1238152980804443
Validation Loss Energy: 9.094478153820098, Validation Loss Force: 4.634322307852656, time: 0.08313703536987305
Test Loss Energy: 17.619801897550992, Test Loss Force: 10.040258731695966, time: 9.92758059501648


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.900103037431462, Training Loss Force: 3.9459782000795127, time: 1.3575961589813232
Validation Loss Energy: 8.748032128392264, Validation Loss Force: 3.67272771652039, time: 0.09478545188903809
Test Loss Energy: 16.933873907006515, Test Loss Force: 10.139023946140139, time: 9.831459045410156


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.2054667717502285, Training Loss Force: 3.695496072408292, time: 1.1456623077392578
Validation Loss Energy: 8.367890917126052, Validation Loss Force: 3.7479784203829674, time: 0.0879049301147461
Test Loss Energy: 10.045343772188588, Test Loss Force: 10.168156009311035, time: 9.749918222427368


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 13.343605273821384, Training Loss Force: 5.9344559611093715, time: 1.1610102653503418
Validation Loss Energy: 13.622180462535589, Validation Loss Force: 5.173723617699091, time: 0.08377408981323242
Test Loss Energy: 24.897843536685645, Test Loss Force: 10.990934675589564, time: 9.886943101882935


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.979215269009316, Training Loss Force: 5.167476709033135, time: 1.1414368152618408
Validation Loss Energy: 1.983549889404344, Validation Loss Force: 4.598382171685035, time: 0.08542466163635254
Test Loss Energy: 11.200792254925597, Test Loss Force: 10.778415446848339, time: 9.762381553649902

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–ƒâ–„â–ƒâ–â–â–â–ƒâ–„â–â–â–†â–â–ˆâ–ƒâ–ƒâ–â–…â–‚
wandb:   test_error_force â–‚â–‚â–â–â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–‡â–â–‚â–â–â–â–ƒâ–‚
wandb:          test_loss â–‚â–â–ƒâ–ƒâ–†â–â–â–â–ƒâ–ƒâ–â–â–ˆâ–â–†â–‚â–‚â–â–…â–‚
wandb: train_error_energy â–ˆâ–â–â–â–„â–â–â–â–â–â–‚â–â–†â–‚â–‚â–…â–â–â–…â–„
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–…â–‚â–â–â–â–â–â–ƒâ–ƒâ–â–…â–â–â–„â–ƒ
wandb:         train_loss â–ˆâ–â–â–â–ƒâ–„â–â–â–â–â–â–â–„â–ƒâ–â–…â–â–â–„â–ƒ
wandb: valid_error_energy â–‚â–‚â–ƒâ–ƒâ–ˆâ–â–‚â–â–‚â–ƒâ–ƒâ–‚â–…â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–„â–
wandb:  valid_error_force â–‚â–‚â–‚â–â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–†â–â–‚â–‚â–â–â–ƒâ–‚
wandb:         valid_loss â–‚â–‚â–‚â–‚â–ˆâ–â–â–â–‚â–‚â–‚â–â–†â–â–„â–‚â–‚â–‚â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2571
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.20079
wandb:   test_error_force 10.77842
wandb:          test_loss 4.35606
wandb: train_error_energy 11.97922
wandb:  train_error_force 5.16748
wandb:         train_loss 2.53071
wandb: valid_error_energy 1.98355
wandb:  valid_error_force 4.59838
wandb:         valid_loss 1.67137
wandb: 
wandb: ğŸš€ View run al_74_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/84tzvnan
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_031528-84tzvnan/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5957000255584717, Uncertainty Bias: -0.01925671100616455
0.00011062622 0.004798889
0.62607175 5.2150984
(48745, 22, 3)
Found uncertainty sample 0 after 192 steps.
Found uncertainty sample 1 after 8 steps.
Found uncertainty sample 2 after 27 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 74 steps.
Found uncertainty sample 5 after 82 steps.
Found uncertainty sample 6 after 312 steps.
Found uncertainty sample 7 after 8 steps.
Found uncertainty sample 8 after 39 steps.
Found uncertainty sample 9 after 220 steps.
Found uncertainty sample 10 after 74 steps.
Found uncertainty sample 11 after 204 steps.
Found uncertainty sample 12 after 27 steps.
Found uncertainty sample 13 after 65 steps.
Found uncertainty sample 14 after 47 steps.
Found uncertainty sample 15 after 8 steps.
Found uncertainty sample 16 after 374 steps.
Found uncertainty sample 17 after 131 steps.
Found uncertainty sample 18 after 29 steps.
Found uncertainty sample 19 after 172 steps.
Found uncertainty sample 20 after 193 steps.
Found uncertainty sample 21 after 69 steps.
Found uncertainty sample 22 after 15 steps.
Found uncertainty sample 23 after 689 steps.
Found uncertainty sample 24 after 502 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 431 steps.
Found uncertainty sample 27 after 154 steps.
Found uncertainty sample 28 after 266 steps.
Found uncertainty sample 29 after 124 steps.
Found uncertainty sample 30 after 135 steps.
Found uncertainty sample 31 after 64 steps.
Found uncertainty sample 32 after 627 steps.
Found uncertainty sample 33 after 587 steps.
Found uncertainty sample 34 after 8 steps.
Found uncertainty sample 35 after 184 steps.
Found uncertainty sample 36 after 94 steps.
Found uncertainty sample 37 after 55 steps.
Found uncertainty sample 38 after 41 steps.
Found uncertainty sample 39 after 359 steps.
Found uncertainty sample 40 after 271 steps.
Found uncertainty sample 41 after 14 steps.
Found uncertainty sample 42 after 718 steps.
Found uncertainty sample 43 after 436 steps.
Found uncertainty sample 44 after 63 steps.
Found uncertainty sample 45 after 28 steps.
Found uncertainty sample 46 after 100 steps.
Found uncertainty sample 47 after 6 steps.
Found uncertainty sample 48 after 104 steps.
Found uncertainty sample 49 after 393 steps.
Found uncertainty sample 50 after 197 steps.
Found uncertainty sample 51 after 474 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 168 steps.
Found uncertainty sample 54 after 6 steps.
Found uncertainty sample 55 after 36 steps.
Found uncertainty sample 56 after 4 steps.
Found uncertainty sample 57 after 104 steps.
Found uncertainty sample 58 after 81 steps.
Found uncertainty sample 59 after 5 steps.
Found uncertainty sample 60 after 104 steps.
Found uncertainty sample 61 after 85 steps.
Found uncertainty sample 62 after 144 steps.
Found uncertainty sample 63 after 41 steps.
Found uncertainty sample 64 after 305 steps.
Found uncertainty sample 65 after 16 steps.
Found uncertainty sample 66 after 184 steps.
Found uncertainty sample 67 after 55 steps.
Found uncertainty sample 68 after 201 steps.
Found uncertainty sample 69 after 6 steps.
Found uncertainty sample 70 after 62 steps.
Found uncertainty sample 71 after 182 steps.
Found uncertainty sample 72 after 174 steps.
Found uncertainty sample 73 after 125 steps.
Found uncertainty sample 74 after 134 steps.
Found uncertainty sample 75 after 181 steps.
Found uncertainty sample 76 after 25 steps.
Found uncertainty sample 77 after 9 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 19 steps.
Found uncertainty sample 80 after 15 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 329 steps.
Found uncertainty sample 83 after 539 steps.
Found uncertainty sample 84 after 202 steps.
Found uncertainty sample 85 after 2 steps.
Found uncertainty sample 86 after 27 steps.
Found uncertainty sample 87 after 389 steps.
Found uncertainty sample 88 after 43 steps.
Found uncertainty sample 89 after 10 steps.
Found uncertainty sample 90 after 42 steps.
Found uncertainty sample 91 after 206 steps.
Found uncertainty sample 92 after 89 steps.
Found uncertainty sample 93 after 60 steps.
Found uncertainty sample 94 after 117 steps.
Found uncertainty sample 95 after 345 steps.
Found uncertainty sample 96 after 294 steps.
Found uncertainty sample 97 after 74 steps.
Found uncertainty sample 98 after 62 steps.
Found uncertainty sample 99 after 386 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_032649-iggfcb0z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/iggfcb0z
Training model 21. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 18.503516156435165, Training Loss Force: 10.995936752339693, time: 1.2257556915283203
Validation Loss Energy: 8.943136615407358, Validation Loss Force: 7.393390088092094, time: 0.08933854103088379
Test Loss Energy: 17.283193355352807, Test Loss Force: 12.203364397951535, time: 9.848843097686768


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 15.062046987177794, Training Loss Force: 6.624823715927012, time: 1.267082929611206
Validation Loss Energy: 13.439237273594486, Validation Loss Force: 7.310594351554326, time: 0.09273529052734375
Test Loss Energy: 10.61649795639026, Test Loss Force: 11.677005244335858, time: 9.807764053344727


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.22081429738266, Training Loss Force: 5.85619837885143, time: 1.2725865840911865
Validation Loss Energy: 16.83112163712571, Validation Loss Force: 5.880618663134721, time: 0.08749127388000488
Test Loss Energy: 11.646186566141386, Test Loss Force: 11.081107178625334, time: 10.024561882019043


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 11.715682557724394, Training Loss Force: 5.732208993461473, time: 1.215083360671997
Validation Loss Energy: 13.265781571623073, Validation Loss Force: 8.296244447394034, time: 0.09325313568115234
Test Loss Energy: 10.738175909888511, Test Loss Force: 12.670637074261107, time: 10.400060176849365


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 12.696412737697068, Training Loss Force: 6.876872878694485, time: 1.2026383876800537
Validation Loss Energy: 11.186874733820884, Validation Loss Force: 5.554386988112503, time: 0.08739185333251953
Test Loss Energy: 9.67388358221457, Test Loss Force: 11.181685418882774, time: 9.907725811004639


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 11.323708462842436, Training Loss Force: 5.256119445752416, time: 1.4333367347717285
Validation Loss Energy: 5.876119187702958, Validation Loss Force: 5.2352159290385085, time: 0.0832366943359375
Test Loss Energy: 8.915360106038133, Test Loss Force: 10.851163508643348, time: 9.99834156036377


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.542145620609366, Training Loss Force: 5.218878598372153, time: 1.198150396347046
Validation Loss Energy: 7.747496822816427, Validation Loss Force: 3.8973442154638898, time: 0.08397102355957031
Test Loss Energy: 17.145289172433213, Test Loss Force: 10.041740435146549, time: 10.056435108184814


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.881230071192823, Training Loss Force: 3.7949478338457383, time: 1.2152202129364014
Validation Loss Energy: 4.191923248723327, Validation Loss Force: 3.7255008607781406, time: 0.0873715877532959
Test Loss Energy: 13.762835875473845, Test Loss Force: 10.07518267349838, time: 10.112533569335938


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.018969522870376, Training Loss Force: 3.715581628937788, time: 1.1987907886505127
Validation Loss Energy: 7.915825345033706, Validation Loss Force: 3.724963782798163, time: 0.08884644508361816
Test Loss Energy: 18.684712438712136, Test Loss Force: 10.159168504341094, time: 9.880432844161987


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.1909487229654925, Training Loss Force: 3.6530307484786286, time: 1.1703505516052246
Validation Loss Energy: 3.4946119946630017, Validation Loss Force: 3.9557652512735255, time: 0.08974432945251465
Test Loss Energy: 13.481086636199334, Test Loss Force: 10.423716041469195, time: 9.98738980293274


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 13.737064170945128, Training Loss Force: 3.9614814174268695, time: 1.2298784255981445
Validation Loss Energy: 27.498435327340623, Validation Loss Force: 6.891983927961046, time: 0.08396577835083008
Test Loss Energy: 33.710460951113674, Test Loss Force: 11.677704840481379, time: 10.166674375534058


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.49151436136075, Training Loss Force: 6.137994119587605, time: 1.217270851135254
Validation Loss Energy: 8.29104245080687, Validation Loss Force: 6.533040151379723, time: 0.08427286148071289
Test Loss Energy: 19.416117340384247, Test Loss Force: 11.92456358262603, time: 9.913747549057007


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.899836440218531, Training Loss Force: 4.370873386093556, time: 1.2251777648925781
Validation Loss Energy: 6.982477782211829, Validation Loss Force: 4.2143426916810665, time: 0.08252501487731934
Test Loss Energy: 16.62784943132949, Test Loss Force: 10.206800512385652, time: 9.843872547149658


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 6.836251806320699, Training Loss Force: 3.7012407206747664, time: 1.2056353092193604
Validation Loss Energy: 10.54141521909246, Validation Loss Force: 4.025060557493691, time: 0.08671188354492188
Test Loss Energy: 18.42535755539353, Test Loss Force: 10.327363502014082, time: 10.723949670791626


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 18.720209327705717, Training Loss Force: 6.513225256167785, time: 1.2102985382080078
Validation Loss Energy: 3.5196453507247876, Validation Loss Force: 8.124051724818326, time: 0.09051084518432617
Test Loss Energy: 11.09587129015448, Test Loss Force: 12.729432295661116, time: 9.984947204589844


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.570569250935293, Training Loss Force: 6.788959818163117, time: 1.2141811847686768
Validation Loss Energy: 19.640524000471274, Validation Loss Force: 9.721558557243643, time: 0.09746479988098145
Test Loss Energy: 14.005620667587833, Test Loss Force: 12.504116893644381, time: 10.04406189918518


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.107490285619052, Training Loss Force: 6.042483301508277, time: 1.1575994491577148
Validation Loss Energy: 3.3502647167929998, Validation Loss Force: 6.348671211897244, time: 0.08353304862976074
Test Loss Energy: 12.006850837264869, Test Loss Force: 11.47497211422765, time: 9.912734746932983


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 13.22539798782212, Training Loss Force: 7.434359800704881, time: 1.211029052734375
Validation Loss Energy: 3.6554974666739253, Validation Loss Force: 5.780048362023267, time: 0.09117555618286133
Test Loss Energy: 13.447423813164578, Test Loss Force: 11.404923805075345, time: 9.88826847076416


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 9.025638300107577, Training Loss Force: 6.331331779946227, time: 1.2617897987365723
Validation Loss Energy: 6.11038961880273, Validation Loss Force: 5.921461305888233, time: 0.08993220329284668
Test Loss Energy: 9.218771751645859, Test Loss Force: 11.198378703249642, time: 10.021832942962646


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.477136917788602, Training Loss Force: 5.739084422903334, time: 1.186887502670288
Validation Loss Energy: 33.31750512117286, Validation Loss Force: 6.448213672231095, time: 0.09476876258850098
Test Loss Energy: 42.00405393359288, Test Loss Force: 12.178454486866316, time: 9.944470643997192

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–‚â–â–â–â–ƒâ–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–â–ˆ
wandb:   test_error_force â–‡â–…â–„â–ˆâ–„â–ƒâ–â–â–â–‚â–…â–†â–â–‚â–ˆâ–‡â–…â–…â–„â–‡
wandb:          test_loss â–„â–‚â–‚â–ƒâ–â–â–‚â–â–‚â–â–†â–„â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–ˆ
wandb: train_error_energy â–ˆâ–†â–‚â–„â–„â–„â–ƒâ–â–â–â–…â–…â–â–â–ˆâ–ƒâ–„â–…â–‚â–ƒ
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–â–â–â–â–ƒâ–‚â–â–„â–„â–ƒâ–…â–„â–ƒ
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–â–â–â–‚â–„â–â–â–…â–„â–ƒâ–…â–ƒâ–ƒ
wandb: valid_error_energy â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‡â–‚â–‚â–ƒâ–â–…â–â–â–‚â–ˆ
wandb:  valid_error_force â–…â–…â–„â–†â–ƒâ–ƒâ–â–â–â–â–…â–„â–‚â–â–†â–ˆâ–„â–ƒâ–„â–„
wandb:         valid_loss â–…â–…â–…â–†â–ƒâ–‚â–‚â–â–‚â–â–‡â–„â–‚â–‚â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2661
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 42.00405
wandb:   test_error_force 12.17845
wandb:          test_loss 6.88589
wandb: train_error_energy 10.47714
wandb:  train_error_force 5.73908
wandb:         train_loss 2.62145
wandb: valid_error_energy 33.31751
wandb:  valid_error_force 6.44821
wandb:         valid_loss 4.38722
wandb: 
wandb: ğŸš€ View run al_74_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/iggfcb0z
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_032649-iggfcb0z/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.6724039316177368, Uncertainty Bias: 0.0658780038356781
0.0 0.010093689
1.95049 5.014074
(48745, 22, 3)
Found uncertainty sample 0 after 17 steps.
Found uncertainty sample 1 after 11 steps.
Found uncertainty sample 2 after 24 steps.
Found uncertainty sample 3 after 124 steps.
Found uncertainty sample 4 after 5 steps.
Found uncertainty sample 5 after 58 steps.
Found uncertainty sample 6 after 122 steps.
Found uncertainty sample 7 after 5 steps.
Found uncertainty sample 8 after 23 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 46 steps.
Found uncertainty sample 11 after 18 steps.
Found uncertainty sample 12 after 5 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 194 steps.
Found uncertainty sample 15 after 14 steps.
Found uncertainty sample 16 after 34 steps.
Found uncertainty sample 17 after 11 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 5 steps.
Found uncertainty sample 20 after 66 steps.
Found uncertainty sample 21 after 38 steps.
Found uncertainty sample 22 after 42 steps.
Found uncertainty sample 23 after 17 steps.
Found uncertainty sample 24 after 3 steps.
Found uncertainty sample 25 after 68 steps.
Found uncertainty sample 26 after 119 steps.
Found uncertainty sample 27 after 11 steps.
Found uncertainty sample 28 after 18 steps.
Found uncertainty sample 29 after 44 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 41 steps.
Found uncertainty sample 32 after 9 steps.
Found uncertainty sample 33 after 3 steps.
Found uncertainty sample 34 after 6 steps.
Found uncertainty sample 35 after 67 steps.
Found uncertainty sample 36 after 39 steps.
Found uncertainty sample 37 after 38 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 30 steps.
Found uncertainty sample 40 after 11 steps.
Found uncertainty sample 41 after 111 steps.
Found uncertainty sample 42 after 441 steps.
Found uncertainty sample 43 after 9 steps.
Found uncertainty sample 44 after 25 steps.
Found uncertainty sample 45 after 336 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 47 steps.
Found uncertainty sample 48 after 13 steps.
Found uncertainty sample 49 after 8 steps.
Found uncertainty sample 50 after 6 steps.
Found uncertainty sample 51 after 2 steps.
Found uncertainty sample 52 after 21 steps.
Found uncertainty sample 53 after 4 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 29 steps.
Found uncertainty sample 56 after 7 steps.
Found uncertainty sample 57 after 27 steps.
Found uncertainty sample 58 after 154 steps.
Found uncertainty sample 59 after 33 steps.
Found uncertainty sample 60 after 77 steps.
Found uncertainty sample 61 after 16 steps.
Found uncertainty sample 62 after 173 steps.
Found uncertainty sample 63 after 106 steps.
Found uncertainty sample 64 after 3 steps.
Found uncertainty sample 65 after 22 steps.
Found uncertainty sample 66 after 50 steps.
Found uncertainty sample 67 after 27 steps.
Found uncertainty sample 68 after 9 steps.
Found uncertainty sample 69 after 3 steps.
Found uncertainty sample 70 after 19 steps.
Found uncertainty sample 71 after 19 steps.
Found uncertainty sample 72 after 29 steps.
Found uncertainty sample 73 after 9 steps.
Found uncertainty sample 74 after 137 steps.
Found uncertainty sample 75 after 244 steps.
Found uncertainty sample 76 after 2 steps.
Found uncertainty sample 77 after 40 steps.
Found uncertainty sample 78 after 259 steps.
Found uncertainty sample 79 after 31 steps.
Found uncertainty sample 80 after 2 steps.
Found uncertainty sample 81 after 126 steps.
Found uncertainty sample 82 after 57 steps.
Found uncertainty sample 83 after 3 steps.
Found uncertainty sample 84 after 47 steps.
Found uncertainty sample 85 after 8 steps.
Found uncertainty sample 86 after 3 steps.
Found uncertainty sample 87 after 33 steps.
Found uncertainty sample 88 after 16 steps.
Found uncertainty sample 89 after 7 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 17 steps.
Found uncertainty sample 93 after 151 steps.
Found uncertainty sample 94 after 40 steps.
Found uncertainty sample 95 after 14 steps.
Found uncertainty sample 96 after 26 steps.
Found uncertainty sample 97 after 82 steps.
Found uncertainty sample 98 after 193 steps.
Found uncertainty sample 99 after 43 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_033456-btmqe6m8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/btmqe6m8
Training model 22. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.879383755637047, Training Loss Force: 8.408154889374469, time: 1.2241706848144531
Validation Loss Energy: 3.956862119486366, Validation Loss Force: 5.288571909785725, time: 0.0867617130279541
Test Loss Energy: 8.852267486702422, Test Loss Force: 11.011626454291804, time: 9.784090995788574


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 10.43166951864898, Training Loss Force: 5.533107440296289, time: 1.2200407981872559
Validation Loss Energy: 8.069105886369185, Validation Loss Force: 4.922573974661409, time: 0.10411715507507324
Test Loss Energy: 9.316047470385147, Test Loss Force: 10.746154954457193, time: 9.859825849533081


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 5.824485521729381, Training Loss Force: 5.439577248858227, time: 1.2497124671936035
Validation Loss Energy: 20.261386145325638, Validation Loss Force: 4.558138731603214, time: 0.08468961715698242
Test Loss Energy: 29.78685586870588, Test Loss Force: 10.617732042424118, time: 9.902534484863281


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.298674532312194, Training Loss Force: 6.141195796753146, time: 1.2598702907562256
Validation Loss Energy: 9.078743461292257, Validation Loss Force: 5.140804656503418, time: 0.08678007125854492
Test Loss Energy: 9.785905407758976, Test Loss Force: 10.90459936582618, time: 9.92339277267456


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 11.53220174322339, Training Loss Force: 5.109850098048178, time: 1.2388737201690674
Validation Loss Energy: 4.520436837153014, Validation Loss Force: 5.7569275112558564, time: 0.08665013313293457
Test Loss Energy: 9.69057924949104, Test Loss Force: 10.988740053150526, time: 9.775349617004395


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 10.398035458080335, Training Loss Force: 4.948877989615256, time: 1.2229902744293213
Validation Loss Energy: 6.098214737910835, Validation Loss Force: 3.824256631019428, time: 0.08593440055847168
Test Loss Energy: 9.22757352490034, Test Loss Force: 10.06900781792555, time: 10.120890378952026


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.911155088953046, Training Loss Force: 3.6939946395138636, time: 1.231933355331421
Validation Loss Energy: 9.66129627026633, Validation Loss Force: 3.611208684883461, time: 0.09209847450256348
Test Loss Energy: 19.086965001610423, Test Loss Force: 10.129481918053571, time: 9.987014055252075


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.000438689790543, Training Loss Force: 3.6898700767836163, time: 1.243283987045288
Validation Loss Energy: 2.768847297794013, Validation Loss Force: 3.799047589001505, time: 0.08400559425354004
Test Loss Energy: 10.02855992793033, Test Loss Force: 10.274218280528002, time: 10.03767704963684


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.172861328616127, Training Loss Force: 3.634240524954376, time: 1.2915027141571045
Validation Loss Energy: 7.557538219763724, Validation Loss Force: 3.7985734150552526, time: 0.09192752838134766
Test Loss Energy: 17.97882150405167, Test Loss Force: 10.323940445373752, time: 9.919126510620117


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.465235212361566, Training Loss Force: 3.606630446714266, time: 1.2310218811035156
Validation Loss Energy: 2.4764585495884943, Validation Loss Force: 4.120153642953612, time: 0.08758735656738281
Test Loss Energy: 11.247879504653353, Test Loss Force: 10.258627807658302, time: 9.884097337722778


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.890646349839148, Training Loss Force: 6.078741075705739, time: 1.213857889175415
Validation Loss Energy: 2.7460004414106653, Validation Loss Force: 6.872913428958061, time: 0.08689451217651367
Test Loss Energy: 12.188392954633969, Test Loss Force: 11.618216737984438, time: 10.043557167053223


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.251327542789985, Training Loss Force: 6.401042171661456, time: 1.2479219436645508
Validation Loss Energy: 4.143289857892093, Validation Loss Force: 5.66406289860838, time: 0.08452415466308594
Test Loss Energy: 14.512928337679261, Test Loss Force: 11.079335263831762, time: 10.434425354003906


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.206433143644004, Training Loss Force: 5.353187355263341, time: 1.2952733039855957
Validation Loss Energy: 16.343237506219424, Validation Loss Force: 4.371533303219037, time: 0.08496642112731934
Test Loss Energy: 26.63345521073945, Test Loss Force: 10.728512292790198, time: 9.880118608474731


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.649822415280632, Training Loss Force: 5.33404091572489, time: 1.2300825119018555
Validation Loss Energy: 8.367557358745453, Validation Loss Force: 3.815207356928923, time: 0.08233952522277832
Test Loss Energy: 9.245932756863457, Test Loss Force: 10.048484092640713, time: 10.049374103546143


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.923470841739031, Training Loss Force: 3.735963586823473, time: 1.2655670642852783
Validation Loss Energy: 8.215035228521003, Validation Loss Force: 4.0351341096554645, time: 0.08349466323852539
Test Loss Energy: 17.898188468990195, Test Loss Force: 10.467649489352137, time: 9.799395561218262


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.092591233695692, Training Loss Force: 3.6160727007772215, time: 1.2481143474578857
Validation Loss Energy: 3.8257721172266126, Validation Loss Force: 3.8531414952983267, time: 0.09154891967773438
Test Loss Energy: 9.752819094961742, Test Loss Force: 10.332087445432046, time: 10.220185279846191


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.143398487731329, Training Loss Force: 3.582667694262806, time: 1.2674174308776855
Validation Loss Energy: 8.5017671784088, Validation Loss Force: 3.7161245970468406, time: 0.08871841430664062
Test Loss Energy: 19.65677309836365, Test Loss Force: 10.424403433946551, time: 9.977260112762451


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.149755067629943, Training Loss Force: 4.402804038915615, time: 1.219569444656372
Validation Loss Energy: 10.583272119805674, Validation Loss Force: 5.861916236229954, time: 0.08568954467773438
Test Loss Energy: 10.141842466541537, Test Loss Force: 11.230056161547026, time: 9.795631885528564


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.215710020442435, Training Loss Force: 5.789944928462494, time: 1.2371103763580322
Validation Loss Energy: 2.0156313919421818, Validation Loss Force: 5.26335039829563, time: 0.08777356147766113
Test Loss Energy: 14.696294733231246, Test Loss Force: 10.771608192248163, time: 9.97013783454895


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.702654393726527, Training Loss Force: 4.099916481906419, time: 1.242042064666748
Validation Loss Energy: 7.508177814171035, Validation Loss Force: 4.219393718587292, time: 0.0868527889251709
Test Loss Energy: 9.52990649121677, Test Loss Force: 10.544581152325401, time: 9.84251356124878

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–ˆâ–â–â–â–„â–â–„â–‚â–‚â–ƒâ–‡â–â–„â–â–…â–â–ƒâ–
wandb:   test_error_force â–…â–„â–„â–…â–…â–â–â–‚â–‚â–‚â–ˆâ–†â–„â–â–ƒâ–‚â–ƒâ–†â–„â–ƒ
wandb:          test_loss â–‚â–‚â–ˆâ–‚â–ƒâ–â–„â–‚â–„â–‚â–„â–„â–‡â–â–„â–‚â–…â–ƒâ–„â–‚
wandb: train_error_energy â–ˆâ–„â–â–†â–…â–„â–‚â–‚â–‚â–‚â–…â–„â–„â–ƒâ–‚â–‚â–‚â–ƒâ–…â–‚
wandb:  train_error_force â–ˆâ–„â–„â–…â–ƒâ–ƒâ–â–â–â–â–…â–…â–„â–„â–â–â–â–‚â–„â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–…â–ƒâ–ƒâ–â–â–â–â–…â–…â–„â–ƒâ–â–â–â–‚â–„â–
wandb: valid_error_energy â–‚â–ƒâ–ˆâ–„â–‚â–ƒâ–„â–â–ƒâ–â–â–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–„â–â–ƒ
wandb:  valid_error_force â–…â–„â–ƒâ–„â–†â–â–â–â–â–‚â–ˆâ–…â–ƒâ–â–‚â–‚â–â–†â–…â–‚
wandb:         valid_loss â–„â–…â–ˆâ–…â–…â–‚â–ƒâ–â–ƒâ–â–†â–…â–†â–ƒâ–ƒâ–â–ƒâ–‡â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2751
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.52991
wandb:   test_error_force 10.54458
wandb:          test_loss 4.166
wandb: train_error_energy 6.70265
wandb:  train_error_force 4.09992
wandb:         train_loss 1.82039
wandb: valid_error_energy 7.50818
wandb:  valid_error_force 4.21939
wandb:         valid_loss 1.91427
wandb: 
wandb: ğŸš€ View run al_74_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/btmqe6m8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_033456-btmqe6m8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.578807830810547, Uncertainty Bias: -0.019071802496910095
0.00020980835 0.0006990433
-0.21620037 6.0525846
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 4 steps.
Found uncertainty sample 2 after 2 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 2 steps.
Found uncertainty sample 5 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 3 steps.
Found uncertainty sample 8 after 2 steps.
Found uncertainty sample 9 after 3 steps.
Found uncertainty sample 10 after 7 steps.
Found uncertainty sample 11 after 4 steps.
Found uncertainty sample 12 after 2 steps.
Found uncertainty sample 13 after 18 steps.
Found uncertainty sample 14 after 7 steps.
Found uncertainty sample 15 after 2 steps.
Found uncertainty sample 16 after 7 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 4 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 7 steps.
Found uncertainty sample 22 after 3 steps.
Found uncertainty sample 23 after 5 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 5 steps.
Found uncertainty sample 27 after 2 steps.
Found uncertainty sample 28 after 3 steps.
Found uncertainty sample 29 after 2 steps.
Found uncertainty sample 30 after 6 steps.
Found uncertainty sample 31 after 2 steps.
Found uncertainty sample 32 after 13 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 7 steps.
Found uncertainty sample 35 after 9 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 16 steps.
Found uncertainty sample 38 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 6 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 2 steps.
Found uncertainty sample 43 after 4 steps.
Found uncertainty sample 44 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 4 steps.
Found uncertainty sample 48 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 2 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 9 steps.
Found uncertainty sample 53 after 23 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 3 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 5 steps.
Found uncertainty sample 60 after 2 steps.
Found uncertainty sample 61 after 15 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 2 steps.
Found uncertainty sample 64 after 2 steps.
Found uncertainty sample 65 after 4 steps.
Found uncertainty sample 66 after 15 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 8 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 3 steps.
Found uncertainty sample 73 after 2 steps.
Found uncertainty sample 74 after 5 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 8 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 11 steps.
Found uncertainty sample 79 after 27 steps.
Found uncertainty sample 80 after 21 steps.
Found uncertainty sample 81 after 2 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 6 steps.
Found uncertainty sample 84 after 15 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 4 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 2 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 22 steps.
Found uncertainty sample 91 after 14 steps.
Found uncertainty sample 92 after 3 steps.
Found uncertainty sample 93 after 10 steps.
Found uncertainty sample 94 after 17 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 9 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 2 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_034138-0yvatt2u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/0yvatt2u
Training model 23. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 13.210058894314653, Training Loss Force: 8.916736238416911, time: 1.3048744201660156
Validation Loss Energy: 11.618809679106484, Validation Loss Force: 4.391133532120184, time: 0.0907747745513916
Test Loss Energy: 18.724260736031354, Test Loss Force: 10.253941757632584, time: 9.819088459014893


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.976579716870694, Training Loss Force: 3.923396663157173, time: 1.3018877506256104
Validation Loss Energy: 7.23039315590491, Validation Loss Force: 3.7556932382819275, time: 0.08996129035949707
Test Loss Energy: 16.881392566001274, Test Loss Force: 10.115270282483875, time: 9.83156442642212


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.164003559445977, Training Loss Force: 3.658357734416084, time: 1.3033356666564941
Validation Loss Energy: 11.125895897531976, Validation Loss Force: 3.737871690518451, time: 0.08887100219726562
Test Loss Energy: 10.185639757487875, Test Loss Force: 10.145945361229561, time: 9.90181040763855


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.2794379608927, Training Loss Force: 4.549993937081568, time: 1.2418246269226074
Validation Loss Energy: 28.274421268720452, Validation Loss Force: 6.39381315052033, time: 0.0951380729675293
Test Loss Energy: 36.41296855441987, Test Loss Force: 11.57932929004774, time: 9.882883787155151


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 16.361884626111383, Training Loss Force: 7.021238796199885, time: 1.2810170650482178
Validation Loss Energy: 6.310433352812795, Validation Loss Force: 8.832563125584247, time: 0.08983087539672852
Test Loss Energy: 9.971930967215522, Test Loss Force: 13.130937566915984, time: 9.772650718688965


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 13.266932105601981, Training Loss Force: 6.506258006887633, time: 1.2789440155029297
Validation Loss Energy: 8.80502385095419, Validation Loss Force: 6.133793927392907, time: 0.10918974876403809
Test Loss Energy: 9.40085478949496, Test Loss Force: 11.536347350560204, time: 9.960809707641602


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.597640360394848, Training Loss Force: 5.554109787542927, time: 1.2555420398712158
Validation Loss Energy: 11.56073400314218, Validation Loss Force: 5.775913173314243, time: 0.08601760864257812
Test Loss Energy: 21.175694808344534, Test Loss Force: 10.667572438757317, time: 9.88314700126648


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.137457677694812, Training Loss Force: 6.06867018251147, time: 1.2574996948242188
Validation Loss Energy: 24.481582808853148, Validation Loss Force: 5.956720519807607, time: 0.08677339553833008
Test Loss Energy: 32.22641297862054, Test Loss Force: 11.413173582682877, time: 10.120257139205933


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.44704464160496, Training Loss Force: 7.813965809582536, time: 1.3196840286254883
Validation Loss Energy: 2.1682290070071, Validation Loss Force: 6.6870123030824535, time: 0.08811378479003906
Test Loss Energy: 11.392111884078252, Test Loss Force: 11.449654996067462, time: 10.408489227294922


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.2726727689726625, Training Loss Force: 4.831781353458602, time: 1.293715000152588
Validation Loss Energy: 9.958168573059677, Validation Loss Force: 4.530175049581018, time: 0.08743596076965332
Test Loss Energy: 9.356240015994535, Test Loss Force: 10.273376250740737, time: 9.828772783279419


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.683064994592679, Training Loss Force: 3.811790969241958, time: 1.2770323753356934
Validation Loss Energy: 2.8600045947650874, Validation Loss Force: 4.025976395690892, time: 0.08754277229309082
Test Loss Energy: 9.654040828141875, Test Loss Force: 10.249556178051868, time: 10.041726112365723


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.746698341074359, Training Loss Force: 3.7648526235160436, time: 1.3180937767028809
Validation Loss Energy: 6.7229125814729525, Validation Loss Force: 4.105820875368532, time: 0.08659195899963379
Test Loss Energy: 15.8521481520511, Test Loss Force: 10.034820139231892, time: 9.803480625152588


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.984099008742422, Training Loss Force: 3.763815713349071, time: 1.313523769378662
Validation Loss Energy: 8.756098986210935, Validation Loss Force: 4.235121731040755, time: 0.08775830268859863
Test Loss Energy: 9.59441080962152, Test Loss Force: 9.889872523194136, time: 9.912579774856567


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.7356820445067, Training Loss Force: 6.646743798961262, time: 1.2983291149139404
Validation Loss Energy: 10.822921124125331, Validation Loss Force: 5.792265772722034, time: 0.08591103553771973
Test Loss Energy: 19.511555378822845, Test Loss Force: 11.29422952598412, time: 10.0345938205719


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.100706516506884, Training Loss Force: 6.01081336529861, time: 1.2779099941253662
Validation Loss Energy: 3.993940985666261, Validation Loss Force: 4.1540902021461745, time: 0.08696556091308594
Test Loss Energy: 13.458283893371732, Test Loss Force: 10.012163159590958, time: 9.891940832138062


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.471279205496641, Training Loss Force: 5.006197187273951, time: 1.2904846668243408
Validation Loss Energy: 10.689764084183931, Validation Loss Force: 4.948123923141747, time: 0.09450292587280273
Test Loss Energy: 9.774534475567165, Test Loss Force: 10.509071224605787, time: 10.042588472366333


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.212947980294612, Training Loss Force: 5.041275641382941, time: 1.2956159114837646
Validation Loss Energy: 8.041168479306208, Validation Loss Force: 3.881996967249963, time: 0.08797430992126465
Test Loss Energy: 9.286326823878948, Test Loss Force: 10.159263652849022, time: 9.8907949924469


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.743238731805028, Training Loss Force: 3.6506260962399546, time: 1.2974982261657715
Validation Loss Energy: 10.269506799587369, Validation Loss Force: 3.527532625877268, time: 0.08767318725585938
Test Loss Energy: 19.016022285291857, Test Loss Force: 10.007728243056023, time: 9.86707854270935


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.9743522122937485, Training Loss Force: 3.530986529562471, time: 1.2689039707183838
Validation Loss Energy: 4.356940012733221, Validation Loss Force: 3.873416411711635, time: 0.09812259674072266
Test Loss Energy: 17.03211517978452, Test Loss Force: 10.132191113733354, time: 9.99010157585144


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.036410871347281, Training Loss Force: 3.5354244457320365, time: 1.3431808948516846
Validation Loss Energy: 1.2593184922742138, Validation Loss Force: 3.913919484017608, time: 0.08833551406860352
Test Loss Energy: 12.292031387093601, Test Loss Force: 10.273556349276546, time: 10.379392623901367

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–â–ˆâ–â–â–„â–‡â–‚â–â–â–ƒâ–â–„â–‚â–â–â–„â–ƒâ–‚
wandb:   test_error_force â–‚â–â–‚â–…â–ˆâ–…â–ƒâ–„â–„â–‚â–‚â–â–â–„â–â–‚â–‚â–â–‚â–‚
wandb:          test_loss â–ƒâ–ƒâ–â–ˆâ–„â–ƒâ–„â–‡â–ƒâ–â–â–‚â–â–„â–‚â–‚â–â–ƒâ–ƒâ–‚
wandb: train_error_energy â–†â–â–â–ƒâ–ˆâ–†â–ƒâ–„â–…â–â–â–â–â–ˆâ–ƒâ–„â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–†â–…â–„â–„â–‡â–ƒâ–â–â–â–…â–„â–ƒâ–ƒâ–â–â–
wandb:         train_loss â–ˆâ–â–â–ƒâ–‡â–…â–„â–…â–‡â–‚â–â–â–â–†â–„â–ƒâ–ƒâ–â–â–
wandb: valid_error_energy â–„â–ƒâ–„â–ˆâ–‚â–ƒâ–„â–‡â–â–ƒâ–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–
wandb:  valid_error_force â–‚â–â–â–…â–ˆâ–„â–„â–„â–…â–‚â–‚â–‚â–‚â–„â–‚â–ƒâ–â–â–â–‚
wandb:         valid_loss â–ƒâ–‚â–ƒâ–ˆâ–†â–„â–„â–‡â–„â–ƒâ–â–‚â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2841
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.29203
wandb:   test_error_force 10.27356
wandb:          test_loss 4.26016
wandb: train_error_energy 7.03641
wandb:  train_error_force 3.53542
wandb:         train_loss 1.65385
wandb: valid_error_energy 1.25932
wandb:  valid_error_force 3.91392
wandb:         valid_loss 1.39388
wandb: 
wandb: ğŸš€ View run al_74_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/0yvatt2u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_034138-0yvatt2u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9773401021957397, Uncertainty Bias: 0.0487680584192276
0.0004119873 0.02955246
0.86096334 4.744515
(48745, 22, 3)
Found uncertainty sample 0 after 5 steps.
Found uncertainty sample 1 after 28 steps.
Found uncertainty sample 2 after 13 steps.
Found uncertainty sample 3 after 98 steps.
Found uncertainty sample 4 after 394 steps.
Found uncertainty sample 5 after 50 steps.
Found uncertainty sample 6 after 306 steps.
Found uncertainty sample 7 after 285 steps.
Found uncertainty sample 8 after 261 steps.
Found uncertainty sample 9 after 4 steps.
Found uncertainty sample 10 after 304 steps.
Found uncertainty sample 11 after 91 steps.
Found uncertainty sample 12 after 55 steps.
Found uncertainty sample 13 after 16 steps.
Found uncertainty sample 14 after 105 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 120 steps.
Found uncertainty sample 17 after 38 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 19 steps.
Found uncertainty sample 20 after 153 steps.
Found uncertainty sample 21 after 68 steps.
Found uncertainty sample 22 after 62 steps.
Found uncertainty sample 23 after 210 steps.
Found uncertainty sample 24 after 29 steps.
Found uncertainty sample 25 after 18 steps.
Found uncertainty sample 26 after 4 steps.
Found uncertainty sample 27 after 14 steps.
Found uncertainty sample 28 after 236 steps.
Found uncertainty sample 29 after 34 steps.
Found uncertainty sample 30 after 44 steps.
Found uncertainty sample 31 after 81 steps.
Found uncertainty sample 32 after 24 steps.
Found uncertainty sample 33 after 191 steps.
Found uncertainty sample 34 after 5 steps.
Found uncertainty sample 35 after 11 steps.
Found uncertainty sample 36 after 7 steps.
Found uncertainty sample 37 after 19 steps.
Found uncertainty sample 38 after 64 steps.
Found uncertainty sample 39 after 6 steps.
Found uncertainty sample 40 after 69 steps.
Found uncertainty sample 41 after 262 steps.
Found uncertainty sample 42 after 16 steps.
Found uncertainty sample 43 after 41 steps.
Found uncertainty sample 44 after 54 steps.
Found uncertainty sample 45 after 125 steps.
Found uncertainty sample 46 after 124 steps.
Found uncertainty sample 47 after 4 steps.
Found uncertainty sample 48 after 3 steps.
Found uncertainty sample 49 after 25 steps.
Found uncertainty sample 50 after 24 steps.
Found uncertainty sample 51 after 16 steps.
Found uncertainty sample 52 after 59 steps.
Found uncertainty sample 53 after 147 steps.
Found uncertainty sample 54 after 80 steps.
Found uncertainty sample 55 after 125 steps.
Found uncertainty sample 56 after 18 steps.
Found uncertainty sample 57 after 59 steps.
Found uncertainty sample 58 after 43 steps.
Found uncertainty sample 59 after 11 steps.
Found uncertainty sample 60 after 110 steps.
Found uncertainty sample 61 after 5 steps.
Found uncertainty sample 62 after 91 steps.
Found uncertainty sample 63 after 40 steps.
Found uncertainty sample 64 after 24 steps.
Found uncertainty sample 65 after 76 steps.
Found uncertainty sample 66 after 47 steps.
Found uncertainty sample 67 after 20 steps.
Found uncertainty sample 68 after 18 steps.
Found uncertainty sample 69 after 87 steps.
Found uncertainty sample 70 after 57 steps.
Found uncertainty sample 71 after 125 steps.
Found uncertainty sample 72 after 10 steps.
Found uncertainty sample 73 after 36 steps.
Found uncertainty sample 74 after 7 steps.
Found uncertainty sample 75 after 58 steps.
Found uncertainty sample 76 after 87 steps.
Found uncertainty sample 77 after 27 steps.
Found uncertainty sample 78 after 32 steps.
Found uncertainty sample 79 after 18 steps.
Found uncertainty sample 80 after 7 steps.
Found uncertainty sample 81 after 24 steps.
Found uncertainty sample 82 after 45 steps.
Found uncertainty sample 83 after 84 steps.
Found uncertainty sample 84 after 48 steps.
Found uncertainty sample 85 after 23 steps.
Found uncertainty sample 86 after 348 steps.
Found uncertainty sample 87 after 3 steps.
Found uncertainty sample 88 after 104 steps.
Found uncertainty sample 89 after 25 steps.
Found uncertainty sample 90 after 18 steps.
Found uncertainty sample 91 after 170 steps.
Found uncertainty sample 92 after 36 steps.
Found uncertainty sample 93 after 10 steps.
Found uncertainty sample 94 after 7 steps.
Found uncertainty sample 95 after 23 steps.
Found uncertainty sample 96 after 4 steps.
Found uncertainty sample 97 after 21 steps.
Found uncertainty sample 98 after 20 steps.
Found uncertainty sample 99 after 62 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_035024-bzy6pj25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/bzy6pj25
Training model 24. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.294266291199225, Training Loss Force: 8.838855496674267, time: 1.3939626216888428
Validation Loss Energy: 1.8182952034120254, Validation Loss Force: 4.883442321625205, time: 0.09131264686584473
Test Loss Energy: 9.15282982527626, Test Loss Force: 10.450576907331, time: 9.996047496795654


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.105064582959805, Training Loss Force: 5.41999244018944, time: 1.410715103149414
Validation Loss Energy: 12.205144300854993, Validation Loss Force: 4.19533788007613, time: 0.0943288803100586
Test Loss Energy: 19.711385627914897, Test Loss Force: 10.108212234808578, time: 10.03144884109497


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.91508144929479, Training Loss Force: 3.7781921910669816, time: 1.3069515228271484
Validation Loss Energy: 4.089450462429067, Validation Loss Force: 3.9922963513544385, time: 0.09546327590942383
Test Loss Energy: 12.594020855358549, Test Loss Force: 10.050442667132154, time: 10.145510196685791


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.962867738926043, Training Loss Force: 3.7253979827920882, time: 1.3405423164367676
Validation Loss Energy: 6.4771746893579, Validation Loss Force: 3.782829036419563, time: 0.09113860130310059
Test Loss Energy: 15.853480706811354, Test Loss Force: 10.040287186714362, time: 10.566186904907227


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 7.39770930558928, Training Loss Force: 3.8401668086171123, time: 1.296386480331421
Validation Loss Energy: 7.403602140462633, Validation Loss Force: 3.8580415525236136, time: 0.09226703643798828
Test Loss Energy: 17.60363235899472, Test Loss Force: 10.149897796860131, time: 10.255554676055908


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.13491916461692, Training Loss Force: 3.692773148175653, time: 1.2836997509002686
Validation Loss Energy: 5.056610335060078, Validation Loss Force: 3.7785232831447573, time: 0.09673142433166504
Test Loss Energy: 15.027780495431092, Test Loss Force: 10.021720441096923, time: 10.02802300453186


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 13.304049901285921, Training Loss Force: 4.766699192556864, time: 1.3522288799285889
Validation Loss Energy: 4.227954901909924, Validation Loss Force: 6.382271986017747, time: 0.09893631935119629
Test Loss Energy: 9.985872368711782, Test Loss Force: 11.382532666746894, time: 10.043396711349487


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.7765678827992675, Training Loss Force: 4.441621301917438, time: 1.319960594177246
Validation Loss Energy: 4.5781671532719805, Validation Loss Force: 3.7491928579048572, time: 0.09303712844848633
Test Loss Energy: 15.05527112093309, Test Loss Force: 9.979672700101773, time: 10.203285455703735


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.847413682688861, Training Loss Force: 3.6409042270147616, time: 1.294736385345459
Validation Loss Energy: 9.350031969895085, Validation Loss Force: 3.666574700010968, time: 0.10570526123046875
Test Loss Energy: 19.9060695197269, Test Loss Force: 10.110733017416695, time: 10.01947283744812


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.161343628015512, Training Loss Force: 3.604445668669086, time: 1.3533849716186523
Validation Loss Energy: 11.779905907464027, Validation Loss Force: 4.079380918311921, time: 0.09378767013549805
Test Loss Energy: 20.04896375784417, Test Loss Force: 10.49673837569325, time: 9.971461057662964


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.110978092911541, Training Loss Force: 4.39788364562568, time: 1.3644335269927979
Validation Loss Energy: 9.543563076725054, Validation Loss Force: 6.097325842680291, time: 0.0925438404083252
Test Loss Energy: 18.213310217365454, Test Loss Force: 11.613524439232954, time: 10.220694780349731


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.590604422142299, Training Loss Force: 4.891031024076482, time: 1.325730323791504
Validation Loss Energy: 7.3493679526038775, Validation Loss Force: 3.755853782736141, time: 0.09054136276245117
Test Loss Energy: 9.135549841518277, Test Loss Force: 9.886001213744333, time: 9.99052357673645


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.989535905203013, Training Loss Force: 5.580930619439394, time: 1.3123512268066406
Validation Loss Energy: 20.47407258810319, Validation Loss Force: 5.466831030573092, time: 0.10113334655761719
Test Loss Energy: 14.036255964333849, Test Loss Force: 10.803794287496812, time: 10.11493730545044


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.015472913899133, Training Loss Force: 6.157012718700093, time: 1.409167766571045
Validation Loss Energy: 17.555593516933442, Validation Loss Force: 7.431283255338647, time: 0.09253740310668945
Test Loss Energy: 12.335980456790967, Test Loss Force: 11.553815980551265, time: 10.020485401153564


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.560978006170572, Training Loss Force: 5.975708645748499, time: 1.325979232788086
Validation Loss Energy: 28.24683701492292, Validation Loss Force: 5.654629297572004, time: 0.09917140007019043
Test Loss Energy: 37.38737959299508, Test Loss Force: 11.984951632204318, time: 10.039690017700195


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.02822916119236, Training Loss Force: 5.551134060545661, time: 1.3653044700622559
Validation Loss Energy: 7.953118864270276, Validation Loss Force: 4.447153303860135, time: 0.09337902069091797
Test Loss Energy: 9.094661915321648, Test Loss Force: 10.311405030492004, time: 10.17492151260376


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 14.070875244893713, Training Loss Force: 5.947815554686199, time: 1.3425531387329102
Validation Loss Energy: 5.268550836198774, Validation Loss Force: 6.306164562616213, time: 0.09485864639282227
Test Loss Energy: 8.737827474233242, Test Loss Force: 11.801999098153928, time: 9.916852235794067


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.622676420096051, Training Loss Force: 4.7961754806092465, time: 1.297184944152832
Validation Loss Energy: 5.857845176234957, Validation Loss Force: 4.034946622234592, time: 0.09242391586303711
Test Loss Energy: 9.869125727725745, Test Loss Force: 10.42576899969914, time: 10.464024782180786


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.623968752616028, Training Loss Force: 3.676989957339701, time: 1.3235576152801514
Validation Loss Energy: 5.692635358075542, Validation Loss Force: 3.7230869045671375, time: 0.09271240234375
Test Loss Energy: 9.257609447601032, Test Loss Force: 10.275253540501652, time: 10.102728128433228


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.585746366616904, Training Loss Force: 3.640052398936065, time: 1.3347368240356445
Validation Loss Energy: 6.668056033351329, Validation Loss Force: 3.6709918991933104, time: 0.09518146514892578
Test Loss Energy: 9.508402000442876, Test Loss Force: 10.323356497287268, time: 10.004342079162598

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–„â–ƒâ–â–‚â–‚â–ˆâ–â–â–â–â–
wandb:   test_error_force â–ƒâ–‚â–‚â–‚â–‚â–â–†â–â–‚â–ƒâ–‡â–â–„â–‡â–ˆâ–‚â–‡â–ƒâ–‚â–‚
wandb:          test_loss â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–„â–â–ƒâ–ƒâ–ˆâ–â–ƒâ–‚â–â–
wandb: train_error_energy â–ˆâ–„â–â–â–‚â–â–†â–â–â–â–„â–‚â–…â–„â–…â–ƒâ–†â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–ƒâ–‚â–â–â–‚â–ƒâ–„â–„â–„â–„â–„â–ƒâ–â–
wandb:         train_loss â–ˆâ–„â–â–â–â–â–ƒâ–‚â–â–â–‚â–‚â–„â–„â–„â–ƒâ–…â–‚â–â–
wandb: valid_error_energy â–â–„â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–‚â–†â–…â–ˆâ–ƒâ–‚â–‚â–‚â–‚
wandb:  valid_error_force â–ƒâ–‚â–‚â–â–â–â–†â–â–â–‚â–†â–â–„â–ˆâ–…â–‚â–†â–‚â–â–
wandb:         valid_loss â–‚â–ƒâ–â–â–‚â–â–„â–â–‚â–ƒâ–…â–‚â–†â–ˆâ–ˆâ–‚â–„â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2931
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.5084
wandb:   test_error_force 10.32336
wandb:          test_loss 4.09054
wandb: train_error_energy 6.58575
wandb:  train_error_force 3.64005
wandb:         train_loss 1.6587
wandb: valid_error_energy 6.66806
wandb:  valid_error_force 3.67099
wandb:         valid_loss 1.67456
wandb: 
wandb: ğŸš€ View run al_74_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/bzy6pj25
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_035024-bzy6pj25/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9614765644073486, Uncertainty Bias: 0.051235511898994446
0.00061798096 0.005842209
0.8117378 4.992959
(48745, 22, 3)
Found uncertainty sample 0 after 8 steps.
Found uncertainty sample 1 after 18 steps.
Found uncertainty sample 2 after 3 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 28 steps.
Found uncertainty sample 5 after 8 steps.
Found uncertainty sample 6 after 7 steps.
Found uncertainty sample 7 after 19 steps.
Found uncertainty sample 8 after 43 steps.
Found uncertainty sample 9 after 27 steps.
Found uncertainty sample 10 after 47 steps.
Found uncertainty sample 11 after 30 steps.
Found uncertainty sample 12 after 2 steps.
Found uncertainty sample 13 after 23 steps.
Found uncertainty sample 14 after 15 steps.
Found uncertainty sample 15 after 27 steps.
Found uncertainty sample 16 after 12 steps.
Found uncertainty sample 17 after 28 steps.
Found uncertainty sample 18 after 4 steps.
Found uncertainty sample 19 after 2 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 11 steps.
Found uncertainty sample 22 after 25 steps.
Found uncertainty sample 23 after 23 steps.
Found uncertainty sample 24 after 26 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 15 steps.
Found uncertainty sample 27 after 15 steps.
Found uncertainty sample 28 after 29 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 44 steps.
Found uncertainty sample 31 after 6 steps.
Found uncertainty sample 32 after 93 steps.
Found uncertainty sample 33 after 18 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 69 steps.
Found uncertainty sample 36 after 26 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 40 steps.
Found uncertainty sample 39 after 30 steps.
Found uncertainty sample 40 after 18 steps.
Found uncertainty sample 41 after 10 steps.
Found uncertainty sample 42 after 21 steps.
Found uncertainty sample 43 after 13 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 20 steps.
Found uncertainty sample 46 after 4 steps.
Found uncertainty sample 47 after 18 steps.
Found uncertainty sample 48 after 4 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 12 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 36 steps.
Found uncertainty sample 53 after 13 steps.
Found uncertainty sample 54 after 12 steps.
Found uncertainty sample 55 after 7 steps.
Found uncertainty sample 56 after 20 steps.
Found uncertainty sample 57 after 24 steps.
Found uncertainty sample 58 after 12 steps.
Found uncertainty sample 59 after 9 steps.
Found uncertainty sample 60 after 12 steps.
Found uncertainty sample 61 after 11 steps.
Found uncertainty sample 62 after 16 steps.
Found uncertainty sample 63 after 14 steps.
Found uncertainty sample 64 after 24 steps.
Found uncertainty sample 65 after 3 steps.
Found uncertainty sample 66 after 11 steps.
Found uncertainty sample 67 after 106 steps.
Found uncertainty sample 68 after 27 steps.
Found uncertainty sample 69 after 70 steps.
Found uncertainty sample 70 after 16 steps.
Found uncertainty sample 71 after 104 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 5 steps.
Found uncertainty sample 74 after 142 steps.
Found uncertainty sample 75 after 8 steps.
Found uncertainty sample 76 after 4 steps.
Found uncertainty sample 77 after 29 steps.
Found uncertainty sample 78 after 3 steps.
Found uncertainty sample 79 after 15 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 38 steps.
Found uncertainty sample 82 after 4 steps.
Found uncertainty sample 83 after 14 steps.
Found uncertainty sample 84 after 8 steps.
Found uncertainty sample 85 after 30 steps.
Found uncertainty sample 86 after 10 steps.
Found uncertainty sample 87 after 30 steps.
Found uncertainty sample 88 after 31 steps.
Found uncertainty sample 89 after 13 steps.
Found uncertainty sample 90 after 22 steps.
Found uncertainty sample 91 after 5 steps.
Found uncertainty sample 92 after 12 steps.
Found uncertainty sample 93 after 25 steps.
Found uncertainty sample 94 after 23 steps.
Found uncertainty sample 95 after 13 steps.
Found uncertainty sample 96 after 14 steps.
Found uncertainty sample 97 after 67 steps.
Found uncertainty sample 98 after 97 steps.
Found uncertainty sample 99 after 12 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_035749-02kit00m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/02kit00m
Training model 25. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 14.05068740811603, Training Loss Force: 7.47034457539525, time: 1.3522017002105713
Validation Loss Energy: 2.840688157690425, Validation Loss Force: 4.640313889231281, time: 0.09904098510742188
Test Loss Energy: 11.765661759867411, Test Loss Force: 10.415868616516091, time: 10.541285276412964


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.632314407899243, Training Loss Force: 3.7709033832429926, time: 1.3899061679840088
Validation Loss Energy: 8.13218360202761, Validation Loss Force: 3.6719958030377255, time: 0.09278273582458496
Test Loss Energy: 16.291328436577288, Test Loss Force: 9.97122356016279, time: 10.084988832473755


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.922660896811286, Training Loss Force: 3.6557113860943606, time: 1.374610424041748
Validation Loss Energy: 8.303045208448962, Validation Loss Force: 3.8277338324022363, time: 0.09630489349365234
Test Loss Energy: 9.731762409327416, Test Loss Force: 10.040337460977446, time: 10.24653148651123


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.936583112350691, Training Loss Force: 5.664520772001208, time: 1.3887107372283936
Validation Loss Energy: 9.0131687338314, Validation Loss Force: 5.2408539118134, time: 0.09373950958251953
Test Loss Energy: 18.83842514238823, Test Loss Force: 10.629138545720538, time: 9.944775104522705


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.834888965435583, Training Loss Force: 3.9723209788517746, time: 1.3755810260772705
Validation Loss Energy: 7.989188593880826, Validation Loss Force: 3.8022638221452865, time: 0.09879899024963379
Test Loss Energy: 9.620052320587309, Test Loss Force: 10.091660637966944, time: 10.161644220352173


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.467713146433022, Training Loss Force: 3.9163882613723384, time: 1.3575961589813232
Validation Loss Energy: 7.6301613163697795, Validation Loss Force: 4.934770454460457, time: 0.09647440910339355
Test Loss Energy: 17.231731899657884, Test Loss Force: 10.712927159316768, time: 10.112478733062744


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.26419853473628, Training Loss Force: 6.961985477427179, time: 1.3648765087127686
Validation Loss Energy: 2.6729581701374, Validation Loss Force: 5.883308061079236, time: 0.09801220893859863
Test Loss Energy: 11.122830149093401, Test Loss Force: 11.286522893216434, time: 10.315493822097778


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.324266874543607, Training Loss Force: 5.892912357938996, time: 1.3792579174041748
Validation Loss Energy: 14.35772122558739, Validation Loss Force: 6.111140236493652, time: 0.09832763671875
Test Loss Energy: 10.485859129618248, Test Loss Force: 10.923700605995181, time: 10.288016557693481


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.9698796313502, Training Loss Force: 5.935982144521735, time: 1.3781957626342773
Validation Loss Energy: 15.763208429345296, Validation Loss Force: 5.39624179394594, time: 0.09459304809570312
Test Loss Energy: 11.036546144166534, Test Loss Force: 10.531474356757132, time: 10.031092882156372


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.685834771105975, Training Loss Force: 5.63961680780818, time: 1.3665118217468262
Validation Loss Energy: 8.809080882792994, Validation Loss Force: 4.496926983387666, time: 0.09402966499328613
Test Loss Energy: 9.819266790397274, Test Loss Force: 10.694793445732, time: 10.015180349349976


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.765037001051729, Training Loss Force: 5.560265526225455, time: 1.3898835182189941
Validation Loss Energy: 4.999550030401208, Validation Loss Force: 7.382548772715161, time: 0.09451174736022949
Test Loss Energy: 17.264250287220683, Test Loss Force: 12.122364385484659, time: 10.27318811416626


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.098181558075504, Training Loss Force: 5.870951686082328, time: 1.511373519897461
Validation Loss Energy: 25.278894219676776, Validation Loss Force: 6.479509152683807, time: 0.09733748435974121
Test Loss Energy: 17.894325516045306, Test Loss Force: 12.05832624533853, time: 10.11506724357605


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.580508655924602, Training Loss Force: 5.40534613294429, time: 1.3752691745758057
Validation Loss Energy: 3.9105905802859877, Validation Loss Force: 6.176166752517236, time: 0.09657812118530273
Test Loss Energy: 10.21943778149746, Test Loss Force: 11.257828674529698, time: 10.230929851531982


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.920923133951428, Training Loss Force: 6.037249927434234, time: 1.3519470691680908
Validation Loss Energy: 13.023082000004205, Validation Loss Force: 5.018629213500884, time: 0.09264588356018066
Test Loss Energy: 10.435459295125913, Test Loss Force: 10.941935987280885, time: 10.092993974685669


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.071672979502408, Training Loss Force: 5.608026630600546, time: 1.3730316162109375
Validation Loss Energy: 9.86443955878771, Validation Loss Force: 3.854811736561931, time: 0.09368419647216797
Test Loss Energy: 19.783186947133704, Test Loss Force: 10.178324523451609, time: 10.573080062866211


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.6617826419016195, Training Loss Force: 3.6648178158387976, time: 1.320434331893921
Validation Loss Energy: 9.370700120020103, Validation Loss Force: 3.682990314787056, time: 0.10260868072509766
Test Loss Energy: 18.27464186184092, Test Loss Force: 10.208549969072276, time: 10.23849606513977


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.809132533512341, Training Loss Force: 3.5084611776005556, time: 1.3634512424468994
Validation Loss Energy: 2.590779672472145, Validation Loss Force: 3.765194530738666, time: 0.09775352478027344
Test Loss Energy: 9.866626125500051, Test Loss Force: 10.435605081628719, time: 10.07060980796814


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.544674128217066, Training Loss Force: 3.811388285746657, time: 1.3517115116119385
Validation Loss Energy: 7.950987475205455, Validation Loss Force: 5.037983170326635, time: 0.09629416465759277
Test Loss Energy: 9.642370013071817, Test Loss Force: 10.594036258756113, time: 10.205577611923218


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 13.603837865454812, Training Loss Force: 5.942703583795226, time: 1.3665783405303955
Validation Loss Energy: 9.900589894629086, Validation Loss Force: 6.3083106478446656, time: 0.09432744979858398
Test Loss Energy: 19.868455930497255, Test Loss Force: 11.282274738970386, time: 10.061001539230347


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.620291094379155, Training Loss Force: 4.037046743863554, time: 1.375842571258545
Validation Loss Energy: 6.263090329682212, Validation Loss Force: 4.131815271464141, time: 0.10146379470825195
Test Loss Energy: 16.640402417255046, Test Loss Force: 10.222269797281232, time: 10.015592098236084

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–â–‡â–â–†â–‚â–‚â–‚â–â–†â–‡â–â–‚â–ˆâ–‡â–â–â–ˆâ–†
wandb:   test_error_force â–‚â–â–â–ƒâ–â–ƒâ–…â–„â–ƒâ–ƒâ–ˆâ–ˆâ–…â–„â–‚â–‚â–ƒâ–ƒâ–…â–‚
wandb:          test_loss â–ƒâ–ƒâ–â–†â–â–…â–„â–ƒâ–‚â–‚â–ˆâ–ˆâ–„â–ƒâ–…â–…â–‚â–‚â–‡â–„
wandb: train_error_energy â–ˆâ–â–â–…â–â–‚â–„â–„â–…â–„â–…â–…â–ƒâ–„â–„â–â–â–ƒâ–ˆâ–
wandb:  train_error_force â–ˆâ–â–â–…â–‚â–‚â–‡â–…â–…â–…â–…â–…â–„â–…â–…â–â–â–‚â–…â–‚
wandb:         train_loss â–ˆâ–â–â–…â–‚â–‚â–†â–…â–…â–…â–…â–…â–„â–…â–…â–â–â–‚â–†â–‚
wandb: valid_error_energy â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–…â–…â–ƒâ–‚â–ˆâ–â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚
wandb:  valid_error_force â–ƒâ–â–â–„â–â–ƒâ–…â–†â–„â–ƒâ–ˆâ–†â–†â–„â–â–â–â–„â–†â–‚
wandb:         valid_loss â–‚â–‚â–‚â–„â–‚â–ƒâ–ƒâ–†â–…â–ƒâ–…â–ˆâ–„â–„â–‚â–‚â–â–ƒâ–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3021
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 16.6404
wandb:   test_error_force 10.22227
wandb:          test_loss 4.53399
wandb: train_error_energy 6.62029
wandb:  train_error_force 4.03705
wandb:         train_loss 1.79384
wandb: valid_error_energy 6.26309
wandb:  valid_error_force 4.13182
wandb:         valid_loss 1.80165
wandb: 
wandb: ğŸš€ View run al_74_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/02kit00m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_035749-02kit00m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.720863938331604, Uncertainty Bias: 0.0868699699640274
4.1007996e-05 1.1509495
1.3925954 5.12071
(48745, 22, 3)
Found uncertainty sample 0 after 126 steps.
Found uncertainty sample 1 after 7 steps.
Found uncertainty sample 2 after 83 steps.
Found uncertainty sample 3 after 113 steps.
Found uncertainty sample 4 after 46 steps.
Found uncertainty sample 5 after 77 steps.
Found uncertainty sample 6 after 38 steps.
Found uncertainty sample 7 after 78 steps.
Found uncertainty sample 8 after 6 steps.
Found uncertainty sample 9 after 33 steps.
Found uncertainty sample 10 after 3 steps.
Found uncertainty sample 11 after 124 steps.
Found uncertainty sample 12 after 10 steps.
Found uncertainty sample 13 after 91 steps.
Found uncertainty sample 14 after 43 steps.
Found uncertainty sample 15 after 21 steps.
Found uncertainty sample 16 after 14 steps.
Found uncertainty sample 17 after 208 steps.
Found uncertainty sample 18 after 135 steps.
Found uncertainty sample 19 after 57 steps.
Found uncertainty sample 20 after 10 steps.
Found uncertainty sample 21 after 4 steps.
Found uncertainty sample 22 after 83 steps.
Found uncertainty sample 23 after 25 steps.
Found uncertainty sample 24 after 57 steps.
Found uncertainty sample 25 after 93 steps.
Found uncertainty sample 26 after 5 steps.
Found uncertainty sample 27 after 43 steps.
Found uncertainty sample 28 after 22 steps.
Found uncertainty sample 29 after 65 steps.
Found uncertainty sample 30 after 2 steps.
Found uncertainty sample 31 after 5 steps.
Found uncertainty sample 32 after 135 steps.
Found uncertainty sample 33 after 13 steps.
Found uncertainty sample 34 after 66 steps.
Found uncertainty sample 35 after 63 steps.
Found uncertainty sample 36 after 33 steps.
Found uncertainty sample 37 after 2 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 4 steps.
Found uncertainty sample 40 after 65 steps.
Found uncertainty sample 41 after 42 steps.
Found uncertainty sample 42 after 9 steps.
Found uncertainty sample 43 after 65 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 64 steps.
Found uncertainty sample 46 after 4 steps.
Found uncertainty sample 47 after 343 steps.
Found uncertainty sample 48 after 35 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 139 steps.
Found uncertainty sample 51 after 146 steps.
Found uncertainty sample 52 after 17 steps.
Found uncertainty sample 53 after 36 steps.
Found uncertainty sample 54 after 32 steps.
Found uncertainty sample 55 after 23 steps.
Found uncertainty sample 56 after 62 steps.
Found uncertainty sample 57 after 5 steps.
Found uncertainty sample 58 after 24 steps.
Found uncertainty sample 59 after 59 steps.
Found uncertainty sample 60 after 76 steps.
Found uncertainty sample 61 after 14 steps.
Found uncertainty sample 62 after 32 steps.
Found uncertainty sample 63 after 21 steps.
Found uncertainty sample 64 after 28 steps.
Found uncertainty sample 65 after 139 steps.
Found uncertainty sample 66 after 4 steps.
Found uncertainty sample 67 after 43 steps.
Found uncertainty sample 68 after 45 steps.
Found uncertainty sample 69 after 14 steps.
Found uncertainty sample 70 after 87 steps.
Found uncertainty sample 71 after 200 steps.
Found uncertainty sample 72 after 161 steps.
Found uncertainty sample 73 after 287 steps.
Found uncertainty sample 74 after 19 steps.
Found uncertainty sample 75 after 4 steps.
Found uncertainty sample 76 after 33 steps.
Found uncertainty sample 77 after 17 steps.
Found uncertainty sample 78 after 3 steps.
Found uncertainty sample 79 after 56 steps.
Found uncertainty sample 80 after 38 steps.
Found uncertainty sample 81 after 51 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 7 steps.
Found uncertainty sample 84 after 7 steps.
Found uncertainty sample 85 after 136 steps.
Found uncertainty sample 86 after 63 steps.
Found uncertainty sample 87 after 21 steps.
Found uncertainty sample 88 after 27 steps.
Found uncertainty sample 89 after 32 steps.
Found uncertainty sample 90 after 42 steps.
Found uncertainty sample 91 after 46 steps.
Found uncertainty sample 92 after 10 steps.
Found uncertainty sample 93 after 14 steps.
Found uncertainty sample 94 after 21 steps.
Found uncertainty sample 95 after 44 steps.
Found uncertainty sample 96 after 24 steps.
Found uncertainty sample 97 after 19 steps.
Found uncertainty sample 98 after 12 steps.
Found uncertainty sample 99 after 78 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_040613-piosom1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/piosom1l
Training model 26. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 17.929495470566735, Training Loss Force: 8.974600024750247, time: 1.446410894393921
Validation Loss Energy: 17.022063101788543, Validation Loss Force: 6.397081265575112, time: 0.10879945755004883
Test Loss Energy: 11.599754980286404, Test Loss Force: 11.53253448534927, time: 10.056543350219727


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.433872368676552, Training Loss Force: 5.0016994556668495, time: 1.4962313175201416
Validation Loss Energy: 7.348931966416151, Validation Loss Force: 3.850614868499484, time: 0.10405564308166504
Test Loss Energy: 18.04095272428499, Test Loss Force: 9.90790004574663, time: 11.539147853851318


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.728607507337647, Training Loss Force: 3.852378926181817, time: 1.6478509902954102
Validation Loss Energy: 8.007273781913081, Validation Loss Force: 3.8292633467656145, time: 0.1070103645324707
Test Loss Energy: 9.06199118475721, Test Loss Force: 9.987815652478, time: 9.532795906066895


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.939289863046027, Training Loss Force: 3.6597111099027435, time: 1.4344189167022705
Validation Loss Energy: 4.722447185059913, Validation Loss Force: 3.6082710108412357, time: 0.09154152870178223
Test Loss Energy: 14.9234864503942, Test Loss Force: 10.066255282202997, time: 9.20573616027832


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.733242260533919, Training Loss Force: 4.369526577066058, time: 1.4977385997772217
Validation Loss Energy: 11.104148247387501, Validation Loss Force: 6.084698275414727, time: 0.08901071548461914
Test Loss Energy: 20.775068350420867, Test Loss Force: 11.536189812722366, time: 9.220615148544312


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.780348026839357, Training Loss Force: 4.0787044517187265, time: 1.574355125427246
Validation Loss Energy: 7.703400761171764, Validation Loss Force: 4.165059997620307, time: 0.09532928466796875
Test Loss Energy: 9.443168119988275, Test Loss Force: 10.486087660442005, time: 9.157346248626709


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.403566761061906, Training Loss Force: 3.601981145964568, time: 1.4111135005950928
Validation Loss Energy: 29.051883061199497, Validation Loss Force: 4.489925597432258, time: 0.08806014060974121
Test Loss Energy: 21.5433240491087, Test Loss Force: 10.572313636157316, time: 9.228219270706177


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.26536482401366, Training Loss Force: 4.560649448918793, time: 1.43184494972229
Validation Loss Energy: 2.5244063421194167, Validation Loss Force: 4.850760725739093, time: 0.09274792671203613
Test Loss Energy: 10.879393330424628, Test Loss Force: 10.537285200737687, time: 9.470250129699707


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 8.212653057194514, Training Loss Force: 4.957799047493164, time: 1.4424386024475098
Validation Loss Energy: 7.174107294535575, Validation Loss Force: 7.719786092944006, time: 0.09439206123352051
Test Loss Energy: 16.43266398134661, Test Loss Force: 12.248046065460304, time: 9.218605995178223


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 12.799203566346563, Training Loss Force: 5.992657370469257, time: 1.377720832824707
Validation Loss Energy: 10.688375074051633, Validation Loss Force: 5.128676758801316, time: 0.09177112579345703
Test Loss Energy: 9.946304555782605, Test Loss Force: 10.892309712396342, time: 9.175463199615479


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.640785617803152, Training Loss Force: 4.427050153971568, time: 1.490786075592041
Validation Loss Energy: 5.95039003598888, Validation Loss Force: 4.179572013867858, time: 0.09874916076660156
Test Loss Energy: 14.456870342623668, Test Loss Force: 10.185363395932605, time: 9.397790670394897


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.714188154400747, Training Loss Force: 3.688735380971932, time: 1.4084877967834473
Validation Loss Energy: 2.6257183541559552, Validation Loss Force: 3.698411377822858, time: 0.0900278091430664
Test Loss Energy: 10.545736313222195, Test Loss Force: 10.280681351582158, time: 10.964894533157349


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.71467337091893, Training Loss Force: 3.5409705361518165, time: 1.6857757568359375
Validation Loss Energy: 3.8819327272013626, Validation Loss Force: 4.001805437231284, time: 0.11101269721984863
Test Loss Energy: 13.559362474697496, Test Loss Force: 10.10641739558524, time: 11.522440671920776


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 14.474274836144515, Training Loss Force: 5.237015822820531, time: 1.745429277420044
Validation Loss Energy: 11.95858409158403, Validation Loss Force: 6.660561212568545, time: 0.09265947341918945
Test Loss Energy: 10.141427583792971, Test Loss Force: 11.926438853209138, time: 11.056358337402344


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.260698152454985, Training Loss Force: 6.354228088571798, time: 1.4909229278564453
Validation Loss Energy: 6.122735064260404, Validation Loss Force: 6.362386963278958, time: 0.09728312492370605
Test Loss Energy: 17.278322506257272, Test Loss Force: 11.669363822151139, time: 10.72367262840271


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 14.292481132362651, Training Loss Force: 6.695208299917227, time: 1.4772858619689941
Validation Loss Energy: 9.836588547353355, Validation Loss Force: 9.054760658260959, time: 0.10936498641967773
Test Loss Energy: 9.529875089038159, Test Loss Force: 13.408002994514305, time: 11.350243330001831


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.63211529877536, Training Loss Force: 6.885975141982697, time: 1.427809476852417
Validation Loss Energy: 17.689429252431633, Validation Loss Force: 5.401012925735734, time: 0.10779881477355957
Test Loss Energy: 12.783721127227764, Test Loss Force: 10.710084343496515, time: 11.255874395370483


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.297538291180901, Training Loss Force: 5.925108415190055, time: 1.4403953552246094
Validation Loss Energy: 32.84475002271749, Validation Loss Force: 6.169893271999866, time: 0.10652661323547363
Test Loss Energy: 25.07723719757476, Test Loss Force: 11.175920283864908, time: 11.281186580657959


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 9.461654722176492, Training Loss Force: 6.239666267157803, time: 1.4183926582336426
Validation Loss Energy: 6.340799412250405, Validation Loss Force: 4.3804507571751525, time: 0.11091208457946777
Test Loss Energy: 9.339974792659092, Test Loss Force: 10.609827586190287, time: 11.153729915618896


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.99756268385835, Training Loss Force: 4.71519366946729, time: 1.4986050128936768
Validation Loss Energy: 8.98250897379031, Validation Loss Force: 4.138870098014571, time: 0.10317468643188477
Test Loss Energy: 9.820530054249893, Test Loss Force: 10.447416912719152, time: 11.231918096542358

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–â–„â–†â–â–†â–‚â–„â–â–ƒâ–‚â–ƒâ–â–…â–â–ƒâ–ˆâ–â–
wandb:   test_error_force â–„â–â–â–â–„â–‚â–‚â–‚â–†â–ƒâ–‚â–‚â–â–…â–…â–ˆâ–ƒâ–„â–‚â–‚
wandb:          test_loss â–„â–„â–â–ƒâ–‡â–‚â–†â–‚â–‡â–ƒâ–ƒâ–‚â–ƒâ–„â–†â–‡â–ƒâ–ˆâ–‚â–‚
wandb: train_error_energy â–ˆâ–„â–â–â–„â–â–â–ƒâ–‚â–…â–‚â–â–â–†â–ƒâ–†â–…â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–â–‚â–‚â–â–‚â–ƒâ–„â–‚â–â–â–ƒâ–…â–…â–…â–„â–„â–ƒ
wandb:         train_loss â–ˆâ–ƒâ–â–â–‚â–‚â–â–ƒâ–ƒâ–„â–‚â–â–â–„â–„â–…â–…â–„â–„â–‚
wandb: valid_error_energy â–„â–‚â–‚â–‚â–ƒâ–‚â–‡â–â–‚â–ƒâ–‚â–â–â–ƒâ–‚â–ƒâ–…â–ˆâ–‚â–‚
wandb:  valid_error_force â–…â–â–â–â–„â–‚â–‚â–ƒâ–†â–ƒâ–‚â–â–‚â–…â–…â–ˆâ–ƒâ–„â–‚â–‚
wandb:         valid_loss â–†â–‚â–‚â–â–„â–‚â–†â–‚â–…â–„â–‚â–â–â–…â–„â–‡â–…â–ˆâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3111
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.82053
wandb:   test_error_force 10.44742
wandb:          test_loss 4.15294
wandb: train_error_energy 8.99756
wandb:  train_error_force 4.71519
wandb:         train_loss 2.17984
wandb: valid_error_energy 8.98251
wandb:  valid_error_force 4.13887
wandb:         valid_loss 1.98599
wandb: 
wandb: ğŸš€ View run al_74_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/piosom1l
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_040613-piosom1l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5953376293182373, Uncertainty Bias: 0.08251000940799713
0.00053596497 0.09162736
1.3286356 4.3278594
(48745, 22, 3)
Found uncertainty sample 0 after 18 steps.
Found uncertainty sample 1 after 3 steps.
Found uncertainty sample 2 after 26 steps.
Found uncertainty sample 3 after 5 steps.
Found uncertainty sample 4 after 29 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 18 steps.
Found uncertainty sample 7 after 45 steps.
Found uncertainty sample 8 after 3 steps.
Found uncertainty sample 9 after 10 steps.
Found uncertainty sample 10 after 5 steps.
Found uncertainty sample 11 after 5 steps.
Found uncertainty sample 12 after 31 steps.
Found uncertainty sample 13 after 12 steps.
Found uncertainty sample 14 after 21 steps.
Found uncertainty sample 15 after 6 steps.
Found uncertainty sample 16 after 3 steps.
Found uncertainty sample 17 after 3 steps.
Found uncertainty sample 18 after 7 steps.
Found uncertainty sample 19 after 45 steps.
Found uncertainty sample 20 after 8 steps.
Found uncertainty sample 21 after 29 steps.
Found uncertainty sample 22 after 19 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 18 steps.
Found uncertainty sample 25 after 2 steps.
Found uncertainty sample 26 after 11 steps.
Found uncertainty sample 27 after 6 steps.
Found uncertainty sample 28 after 4 steps.
Found uncertainty sample 29 after 41 steps.
Found uncertainty sample 30 after 8 steps.
Found uncertainty sample 31 after 6 steps.
Found uncertainty sample 32 after 10 steps.
Found uncertainty sample 33 after 8 steps.
Found uncertainty sample 34 after 8 steps.
Found uncertainty sample 35 after 2 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 3 steps.
Found uncertainty sample 38 after 18 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 9 steps.
Found uncertainty sample 41 after 4 steps.
Found uncertainty sample 42 after 11 steps.
Found uncertainty sample 43 after 20 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 75 steps.
Found uncertainty sample 46 after 50 steps.
Found uncertainty sample 47 after 2 steps.
Found uncertainty sample 48 after 13 steps.
Found uncertainty sample 49 after 21 steps.
Found uncertainty sample 50 after 27 steps.
Found uncertainty sample 51 after 103 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 8 steps.
Found uncertainty sample 54 after 4 steps.
Found uncertainty sample 55 after 3 steps.
Found uncertainty sample 56 after 8 steps.
Found uncertainty sample 57 after 34 steps.
Found uncertainty sample 58 after 3 steps.
Found uncertainty sample 59 after 3 steps.
Found uncertainty sample 60 after 2 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 12 steps.
Found uncertainty sample 65 after 58 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 51 steps.
Found uncertainty sample 68 after 17 steps.
Found uncertainty sample 69 after 9 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 3 steps.
Found uncertainty sample 74 after 2 steps.
Found uncertainty sample 75 after 15 steps.
Found uncertainty sample 76 after 3 steps.
Found uncertainty sample 77 after 20 steps.
Found uncertainty sample 78 after 62 steps.
Found uncertainty sample 79 after 3 steps.
Found uncertainty sample 80 after 22 steps.
Found uncertainty sample 81 after 24 steps.
Found uncertainty sample 82 after 12 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 3 steps.
Found uncertainty sample 85 after 7 steps.
Found uncertainty sample 86 after 15 steps.
Found uncertainty sample 87 after 76 steps.
Found uncertainty sample 88 after 4 steps.
Found uncertainty sample 89 after 6 steps.
Found uncertainty sample 90 after 11 steps.
Found uncertainty sample 91 after 30 steps.
Found uncertainty sample 92 after 5 steps.
Found uncertainty sample 93 after 13 steps.
Found uncertainty sample 94 after 22 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 42 steps.
Found uncertainty sample 97 after 11 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 14 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_041327-tv9bl4vg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/tv9bl4vg
Training model 27. Added 100 samples to the dataset.
Epoch 0, Batch 100/101, Loss: 0.8325471878051758

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 14.052929344080564, Training Loss Force: 6.75601035701603, time: 1.4672698974609375
Validation Loss Energy: 8.821587763381466, Validation Loss Force: 6.01702377790777, time: 0.09720134735107422
Test Loss Energy: 17.94219374924013, Test Loss Force: 11.70502832189547, time: 9.278577327728271

Epoch 1, Batch 100/101, Loss: 0.29907310009002686

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.679898003186826, Training Loss Force: 5.646953922976902, time: 1.5083489418029785
Validation Loss Energy: 3.9260585151770075, Validation Loss Force: 4.666394680955511, time: 0.09275031089782715
Test Loss Energy: 9.115892539367348, Test Loss Force: 10.589741528186934, time: 9.24479603767395

Epoch 2, Batch 100/101, Loss: 0.44144490361213684

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 9.77015770332395, Training Loss Force: 4.776550666130008, time: 1.4510138034820557
Validation Loss Energy: 5.302067886720408, Validation Loss Force: 4.36994411352455, time: 0.09502434730529785
Test Loss Energy: 12.941711550016612, Test Loss Force: 10.118100423649917, time: 9.460147619247437

Epoch 3, Batch 100/101, Loss: 0.507716953754425

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.481811096393509, Training Loss Force: 3.7175429609251127, time: 1.4390881061553955
Validation Loss Energy: 9.552846153418784, Validation Loss Force: 4.168108115558912, time: 0.09372735023498535
Test Loss Energy: 9.604049576376823, Test Loss Force: 10.045474930144575, time: 9.344204902648926

Epoch 4, Batch 100/101, Loss: 0.37717366218566895

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.776531499207188, Training Loss Force: 3.649413755385011, time: 1.4849636554718018
Validation Loss Energy: 10.820277150686586, Validation Loss Force: 3.639870657347286, time: 0.11958551406860352
Test Loss Energy: 9.809568623441322, Test Loss Force: 9.85663192282911, time: 11.66367483139038

Epoch 5, Batch 100/101, Loss: 0.33298903703689575

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.821222729023179, Training Loss Force: 3.5885325958932346, time: 1.7656476497650146
Validation Loss Energy: 7.444892125530314, Validation Loss Force: 4.012944238587176, time: 0.1071786880493164
Test Loss Energy: 18.10494443266806, Test Loss Force: 10.306802839298774, time: 11.412917137145996

Epoch 6, Batch 100/101, Loss: 1.5497695207595825

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 11.509822991347313, Training Loss Force: 4.413650215355344, time: 1.4494941234588623
Validation Loss Energy: 19.549741789676514, Validation Loss Force: 6.809032768359422, time: 0.10081195831298828
Test Loss Energy: 27.422562077268957, Test Loss Force: 12.328681618665003, time: 10.142066955566406

Epoch 7, Batch 100/101, Loss: 0.7187138199806213

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.902382175249942, Training Loss Force: 7.376974102935644, time: 1.466827392578125
Validation Loss Energy: 2.0911513028021855, Validation Loss Force: 10.326870379622994, time: 0.10733699798583984
Test Loss Energy: 11.081010234774554, Test Loss Force: 14.570237630743948, time: 10.328184127807617

Epoch 8, Batch 100/101, Loss: 0.6143844127655029

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.661650851750401, Training Loss Force: 4.153713106435934, time: 1.5054819583892822
Validation Loss Energy: 3.2137537228410618, Validation Loss Force: 4.401992215690499, time: 0.10387706756591797
Test Loss Energy: 11.084524555453731, Test Loss Force: 10.521935369095345, time: 10.149112224578857

Epoch 9, Batch 100/101, Loss: 0.48218464851379395

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.554538520108364, Training Loss Force: 3.6387346908575293, time: 1.4644756317138672
Validation Loss Energy: 6.74031194853575, Validation Loss Force: 3.5293609622344815, time: 0.10407829284667969
Test Loss Energy: 10.110553138052609, Test Loss Force: 10.199079129827211, time: 10.141589403152466

Epoch 10, Batch 100/101, Loss: 0.5384246110916138

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.877802989868459, Training Loss Force: 3.5088218433679175, time: 1.6092967987060547
Validation Loss Energy: 3.2775411964021304, Validation Loss Force: 3.717775577429322, time: 0.14678716659545898
Test Loss Energy: 13.80419704938303, Test Loss Force: 10.12570398042176, time: 10.154356241226196

Epoch 11, Batch 100/101, Loss: 0.8119006156921387

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 14.699548007141013, Training Loss Force: 6.53592332218803, time: 1.434089183807373
Validation Loss Energy: 15.087724652318261, Validation Loss Force: 8.946861424880439, time: 0.10396814346313477
Test Loss Energy: 11.503376303437301, Test Loss Force: 13.549090884561078, time: 10.944320440292358

Epoch 12, Batch 100/101, Loss: 0.7367148399353027

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.854441124523458, Training Loss Force: 7.883936358712005, time: 1.45843505859375
Validation Loss Energy: 4.119289686667412, Validation Loss Force: 4.647336874093843, time: 0.1093454360961914
Test Loss Energy: 8.342468855347127, Test Loss Force: 10.33221544638255, time: 10.338902950286865

Epoch 13, Batch 100/101, Loss: 0.4750640392303467

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.285232329741, Training Loss Force: 5.686754322006968, time: 1.4766550064086914
Validation Loss Energy: 6.350071578155983, Validation Loss Force: 4.01288879396984, time: 0.10318756103515625
Test Loss Energy: 8.808447164072069, Test Loss Force: 10.337016109230646, time: 10.220706701278687

Epoch 14, Batch 100/101, Loss: 0.14208614826202393

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.637848016095846, Training Loss Force: 3.66349553956831, time: 1.4619123935699463
Validation Loss Energy: 11.338991160861454, Validation Loss Force: 3.7714619991890954, time: 0.10198235511779785
Test Loss Energy: 20.239658285921585, Test Loss Force: 10.00650695758354, time: 10.222479343414307

Epoch 15, Batch 100/101, Loss: 1.1031522750854492

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.55215533698463, Training Loss Force: 5.686375813119273, time: 1.478041648864746
Validation Loss Energy: 5.713334681880989, Validation Loss Force: 4.775372746348051, time: 0.1102452278137207
Test Loss Energy: 14.910835671910332, Test Loss Force: 10.172050387750678, time: 10.41670560836792

Epoch 16, Batch 100/101, Loss: 1.01510751247406

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 13.44111902739795, Training Loss Force: 5.478107183517699, time: 1.4798314571380615
Validation Loss Energy: 22.97220931506263, Validation Loss Force: 8.038349487918763, time: 0.10521554946899414
Test Loss Energy: 32.13153963846248, Test Loss Force: 12.759738112019587, time: 10.17307996749878

Epoch 17, Batch 100/101, Loss: 0.4640960693359375

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.199986821040392, Training Loss Force: 5.950038119529288, time: 1.4509453773498535
Validation Loss Energy: 5.31910229905303, Validation Loss Force: 4.217715461234434, time: 0.10143661499023438
Test Loss Energy: 13.835452438897212, Test Loss Force: 9.949147506836477, time: 10.358788013458252

Epoch 18, Batch 100/101, Loss: 0.6806660890579224

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.563681195087005, Training Loss Force: 3.7096596596452613, time: 1.453519582748413
Validation Loss Energy: 5.11038871917712, Validation Loss Force: 3.7265229121579493, time: 0.1047816276550293
Test Loss Energy: 10.127510193258647, Test Loss Force: 10.154411106924117, time: 10.226280212402344

Epoch 19, Batch 100/101, Loss: 1.0974634885787964

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 13.496996343795981, Training Loss Force: 5.419582791745388, time: 1.4873621463775635
Validation Loss Energy: 9.212134303836882, Validation Loss Force: 4.519653264428493, time: 0.10225081443786621
Test Loss Energy: 9.561400540086332, Test Loss Force: 10.38471296412637, time: 10.127350091934204

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–‚â–â–â–„â–‡â–‚â–‚â–‚â–ƒâ–‚â–â–â–…â–ƒâ–ˆâ–ƒâ–‚â–
wandb:   test_error_force â–„â–‚â–â–â–â–‚â–…â–ˆâ–‚â–‚â–â–†â–‚â–‚â–â–â–…â–â–â–‚
wandb:          test_loss â–„â–‚â–‚â–â–â–ƒâ–‡â–†â–‚â–â–‚â–…â–â–â–ƒâ–‚â–ˆâ–‚â–â–
wandb: train_error_energy â–‡â–ƒâ–„â–â–â–â–…â–…â–â–â–â–ˆâ–…â–…â–â–…â–‡â–‚â–â–‡
wandb:  train_error_force â–†â–„â–ƒâ–â–â–â–‚â–‡â–‚â–â–â–†â–ˆâ–„â–â–„â–„â–…â–â–„
wandb:         train_loss â–‡â–„â–ƒâ–â–â–â–ƒâ–‡â–‚â–â–â–‡â–ˆâ–…â–â–…â–…â–…â–â–…
wandb: valid_error_energy â–ƒâ–‚â–‚â–„â–„â–ƒâ–‡â–â–â–ƒâ–â–…â–‚â–‚â–„â–‚â–ˆâ–‚â–‚â–ƒ
wandb:  valid_error_force â–„â–‚â–‚â–‚â–â–â–„â–ˆâ–‚â–â–â–‡â–‚â–â–â–‚â–†â–‚â–â–‚
wandb:         valid_loss â–„â–‚â–‚â–‚â–‚â–‚â–†â–†â–‚â–â–â–‡â–‚â–‚â–‚â–‚â–ˆâ–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3201
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.5614
wandb:   test_error_force 10.38471
wandb:          test_loss 4.11461
wandb: train_error_energy 13.497
wandb:  train_error_force 5.41958
wandb:         train_loss 2.71664
wandb: valid_error_energy 9.21213
wandb:  valid_error_force 4.51965
wandb:         valid_loss 2.12877
wandb: 
wandb: ğŸš€ View run al_74_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/tv9bl4vg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_041327-tv9bl4vg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.222517967224121, Uncertainty Bias: 0.10020950436592102
1.5258789e-05 0.015439987
1.840994 4.8348613
(48745, 22, 3)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 62 steps.
Found uncertainty sample 2 after 52 steps.
Found uncertainty sample 3 after 92 steps.
Found uncertainty sample 4 after 42 steps.
Found uncertainty sample 5 after 187 steps.
Found uncertainty sample 6 after 17 steps.
Found uncertainty sample 7 after 16 steps.
Found uncertainty sample 8 after 53 steps.
Found uncertainty sample 9 after 6 steps.
Found uncertainty sample 10 after 23 steps.
Found uncertainty sample 11 after 45 steps.
Found uncertainty sample 12 after 12 steps.
Found uncertainty sample 13 after 20 steps.
Found uncertainty sample 14 after 52 steps.
Found uncertainty sample 15 after 83 steps.
Found uncertainty sample 16 after 67 steps.
Found uncertainty sample 17 after 19 steps.
Found uncertainty sample 18 after 28 steps.
Found uncertainty sample 19 after 2 steps.
Found uncertainty sample 20 after 157 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 14 steps.
Found uncertainty sample 23 after 102 steps.
Found uncertainty sample 24 after 4 steps.
Found uncertainty sample 25 after 29 steps.
Found uncertainty sample 26 after 5 steps.
Found uncertainty sample 27 after 191 steps.
Found uncertainty sample 28 after 32 steps.
Found uncertainty sample 29 after 54 steps.
Found uncertainty sample 30 after 30 steps.
Found uncertainty sample 31 after 37 steps.
Found uncertainty sample 32 after 87 steps.
Found uncertainty sample 33 after 5 steps.
Found uncertainty sample 34 after 20 steps.
Found uncertainty sample 35 after 16 steps.
Found uncertainty sample 36 after 16 steps.
Found uncertainty sample 37 after 93 steps.
Found uncertainty sample 38 after 60 steps.
Found uncertainty sample 39 after 8 steps.
Found uncertainty sample 40 after 8 steps.
Found uncertainty sample 41 after 58 steps.
Found uncertainty sample 42 after 23 steps.
Found uncertainty sample 43 after 6 steps.
Found uncertainty sample 44 after 141 steps.
Found uncertainty sample 45 after 325 steps.
Found uncertainty sample 46 after 3 steps.
Found uncertainty sample 47 after 42 steps.
Found uncertainty sample 48 after 95 steps.
Found uncertainty sample 49 after 69 steps.
Found uncertainty sample 50 after 7 steps.
Found uncertainty sample 51 after 13 steps.
Found uncertainty sample 52 after 49 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 45 steps.
Found uncertainty sample 55 after 29 steps.
Found uncertainty sample 56 after 105 steps.
Found uncertainty sample 57 after 136 steps.
Found uncertainty sample 58 after 72 steps.
Found uncertainty sample 59 after 34 steps.
Found uncertainty sample 60 after 33 steps.
Found uncertainty sample 61 after 55 steps.
Found uncertainty sample 62 after 103 steps.
Found uncertainty sample 63 after 26 steps.
Found uncertainty sample 64 after 71 steps.
Found uncertainty sample 65 after 25 steps.
Found uncertainty sample 66 after 15 steps.
Found uncertainty sample 67 after 20 steps.
Found uncertainty sample 68 after 26 steps.
Found uncertainty sample 69 after 31 steps.
Found uncertainty sample 70 after 346 steps.
Found uncertainty sample 71 after 64 steps.
Found uncertainty sample 72 after 16 steps.
Found uncertainty sample 73 after 395 steps.
Found uncertainty sample 74 after 8 steps.
Found uncertainty sample 75 after 208 steps.
Found uncertainty sample 76 after 66 steps.
Found uncertainty sample 77 after 74 steps.
Found uncertainty sample 78 after 54 steps.
Found uncertainty sample 79 after 78 steps.
Found uncertainty sample 80 after 123 steps.
Found uncertainty sample 81 after 94 steps.
Found uncertainty sample 82 after 295 steps.
Found uncertainty sample 83 after 371 steps.
Found uncertainty sample 84 after 24 steps.
Found uncertainty sample 85 after 6 steps.
Found uncertainty sample 86 after 34 steps.
Found uncertainty sample 87 after 17 steps.
Found uncertainty sample 88 after 5 steps.
Found uncertainty sample 89 after 7 steps.
Found uncertainty sample 90 after 33 steps.
Found uncertainty sample 91 after 3 steps.
Found uncertainty sample 92 after 50 steps.
Found uncertainty sample 93 after 132 steps.
Found uncertainty sample 94 after 150 steps.
Found uncertainty sample 95 after 12 steps.
Found uncertainty sample 96 after 40 steps.
Found uncertainty sample 97 after 6 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 5 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_042216-r11z1vn6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/r11z1vn6
Training model 28. Added 100 samples to the dataset.
Epoch 0, Batch 100/103, Loss: 0.971729040145874

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 13.599069854548889, Training Loss Force: 8.04222991718281, time: 1.6281490325927734
Validation Loss Energy: 16.18985498241511, Validation Loss Force: 4.52402181040245, time: 0.1182398796081543
Test Loss Energy: 24.43858228173806, Test Loss Force: 10.440592516092162, time: 11.314790964126587

Epoch 1, Batch 100/103, Loss: 0.35848984122276306

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 10.051504845437712, Training Loss Force: 5.504797669990456, time: 1.6363463401794434
Validation Loss Energy: 2.097164928426257, Validation Loss Force: 5.336306385274849, time: 0.11591386795043945
Test Loss Energy: 9.600197139011494, Test Loss Force: 10.765798066404749, time: 11.290800094604492

Epoch 2, Batch 100/103, Loss: 0.5750064849853516

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.681163082952348, Training Loss Force: 3.8423036583161108, time: 1.8458659648895264
Validation Loss Energy: 7.574330590734721, Validation Loss Force: 3.792728015970929, time: 0.11947345733642578
Test Loss Energy: 15.906790908647459, Test Loss Force: 10.159945155669176, time: 11.56645679473877

Epoch 3, Batch 100/103, Loss: 2.1194024085998535

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 8.93478069844789, Training Loss Force: 3.7138582975025427, time: 1.5721516609191895
Validation Loss Energy: 44.11348684134727, Validation Loss Force: 5.509521381899512, time: 0.1151571273803711
Test Loss Energy: 32.10948323131651, Test Loss Force: 11.25033074453952, time: 11.371043920516968

Epoch 4, Batch 100/103, Loss: 0.12619230151176453

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 12.026128600032004, Training Loss Force: 5.981258030594466, time: 1.6065165996551514
Validation Loss Energy: 5.008035728883369, Validation Loss Force: 10.50502128320544, time: 0.11180877685546875
Test Loss Energy: 11.08332693120107, Test Loss Force: 14.174774639484552, time: 11.668185234069824

Epoch 5, Batch 100/103, Loss: 0.19941619038581848

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 13.74191923275056, Training Loss Force: 6.707247869750187, time: 1.667137861251831
Validation Loss Energy: 10.574605836646164, Validation Loss Force: 4.923207245712428, time: 0.1157829761505127
Test Loss Energy: 20.302717712399062, Test Loss Force: 10.709808341009815, time: 11.421437740325928

Epoch 6, Batch 100/103, Loss: 0.566756546497345

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 11.061399768604812, Training Loss Force: 5.80835369417959, time: 1.585108995437622
Validation Loss Energy: 16.034492484565206, Validation Loss Force: 5.736239766245998, time: 0.12310433387756348
Test Loss Energy: 25.40958072329378, Test Loss Force: 11.077636958095121, time: 11.608955383300781

Epoch 7, Batch 100/103, Loss: 0.7289515733718872

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.511809603193745, Training Loss Force: 5.437471258404492, time: 1.5546374320983887
Validation Loss Energy: 7.040155771081504, Validation Loss Force: 6.567427170254497, time: 0.12280797958374023
Test Loss Energy: 15.955276595223292, Test Loss Force: 10.844944590227382, time: 11.476646900177002

Epoch 8, Batch 100/103, Loss: 0.644821047782898

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.287512610266972, Training Loss Force: 4.243261641633983, time: 1.6715672016143799
Validation Loss Energy: 8.406594377394637, Validation Loss Force: 3.5711304653079186, time: 0.1172475814819336
Test Loss Energy: 19.183583965281542, Test Loss Force: 10.074125999980897, time: 10.608156681060791

Epoch 9, Batch 100/103, Loss: 0.6745172739028931

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.643649250971493, Training Loss Force: 3.553796384622524, time: 1.782350778579712
Validation Loss Energy: 10.538420764418024, Validation Loss Force: 3.8190334808634, time: 0.11624717712402344
Test Loss Energy: 10.199597666811918, Test Loss Force: 10.29191811337257, time: 11.708904504776001

Epoch 10, Batch 100/103, Loss: 0.4968467354774475

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.647991833290668, Training Loss Force: 3.477699184545175, time: 1.6830456256866455
Validation Loss Energy: 7.003379957609217, Validation Loss Force: 3.9831221598730675, time: 0.10227537155151367
Test Loss Energy: 9.841181169602343, Test Loss Force: 10.399840910045121, time: 9.512212991714478

Epoch 11, Batch 100/103, Loss: 0.4043373465538025

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.83347823463923, Training Loss Force: 3.502064286719831, time: 1.5285394191741943
Validation Loss Energy: 5.754839320005345, Validation Loss Force: 3.2353825789961848, time: 0.10033106803894043
Test Loss Energy: 19.090201431195485, Test Loss Force: 10.340416194808926, time: 9.695075750350952

Epoch 12, Batch 100/103, Loss: 0.1752733588218689

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 9.033433889553505, Training Loss Force: 5.193376792134732, time: 1.477604627609253
Validation Loss Energy: 9.02555270105132, Validation Loss Force: 5.642258467831693, time: 0.0989847183227539
Test Loss Energy: 10.007409436797793, Test Loss Force: 11.128594346802403, time: 9.987900495529175

Epoch 13, Batch 100/103, Loss: 0.3881901502609253

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.430087746378438, Training Loss Force: 5.032776037216259, time: 1.4732749462127686
Validation Loss Energy: 5.694877413705889, Validation Loss Force: 3.592599667685411, time: 0.09858584403991699
Test Loss Energy: 15.669226558519734, Test Loss Force: 10.183740200812371, time: 9.442866563796997

Epoch 14, Batch 100/103, Loss: 0.44943827390670776

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.478497795908512, Training Loss Force: 3.526100186614169, time: 1.5567259788513184
Validation Loss Energy: 8.382214332607003, Validation Loss Force: 3.5553171705715645, time: 0.09644722938537598
Test Loss Energy: 18.436622254584012, Test Loss Force: 10.197806366978773, time: 9.712857723236084

Epoch 15, Batch 100/103, Loss: 0.4258555769920349

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.701668501925665, Training Loss Force: 3.476447671529569, time: 1.6113150119781494
Validation Loss Energy: 6.026468735070589, Validation Loss Force: 3.3380356159640727, time: 0.10213923454284668
Test Loss Energy: 9.872749023384424, Test Loss Force: 10.107225957383806, time: 9.457571744918823

Epoch 16, Batch 100/103, Loss: 0.6176073551177979

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.706996396296489, Training Loss Force: 3.412233627659077, time: 1.5224220752716064
Validation Loss Energy: 10.157555878427548, Validation Loss Force: 3.8807771856685704, time: 0.1007075309753418
Test Loss Energy: 10.722013687937261, Test Loss Force: 10.389212820777038, time: 9.519922018051147

Epoch 17, Batch 100/103, Loss: 0.1525696963071823

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.71292763446237, Training Loss Force: 4.513696103808523, time: 1.5406856536865234
Validation Loss Energy: 2.2502101084744903, Validation Loss Force: 5.92767533374364, time: 0.09731006622314453
Test Loss Energy: 11.918964206717298, Test Loss Force: 11.784911635771643, time: 9.335833311080933

Epoch 18, Batch 100/103, Loss: 0.39922279119491577

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.817343444217459, Training Loss Force: 5.8893408513827135, time: 1.5232610702514648
Validation Loss Energy: 17.765471656442557, Validation Loss Force: 7.129457009386697, time: 0.09899234771728516
Test Loss Energy: 25.216544471244166, Test Loss Force: 12.191606744246181, time: 9.662131547927856

Epoch 19, Batch 100/103, Loss: 1.1636621952056885

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 14.448902450844306, Training Loss Force: 6.76912734004112, time: 1.5436570644378662
Validation Loss Energy: 4.715095095199668, Validation Loss Force: 4.13418469384596, time: 0.11747407913208008
Test Loss Energy: 9.744092805381923, Test Loss Force: 10.313996101938583, time: 11.944735765457153

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–ƒâ–ˆâ–â–„â–†â–ƒâ–„â–â–â–„â–â–ƒâ–„â–â–â–‚â–†â–
wandb:   test_error_force â–‚â–‚â–â–ƒâ–ˆâ–‚â–ƒâ–‚â–â–â–‚â–â–ƒâ–â–â–â–‚â–„â–…â–
wandb:          test_loss â–…â–‚â–ƒâ–ˆâ–†â–„â–†â–ƒâ–ƒâ–â–â–„â–‚â–ƒâ–ƒâ–â–‚â–„â–‡â–
wandb: train_error_energy â–‡â–„â–â–ƒâ–†â–‡â–…â–…â–â–â–â–â–ƒâ–„â–â–â–â–…â–‡â–ˆ
wandb:  train_error_force â–ˆâ–„â–‚â–â–…â–†â–…â–„â–‚â–â–â–â–„â–ƒâ–â–â–â–ƒâ–…â–†
wandb:         train_loss â–ˆâ–„â–â–‚â–…â–†â–…â–„â–‚â–â–â–â–„â–„â–â–â–â–ƒâ–…â–‡
wandb: valid_error_energy â–ƒâ–â–‚â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–„â–
wandb:  valid_error_force â–‚â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–â–‚â–‚â–â–ƒâ–â–â–â–‚â–„â–…â–‚
wandb:         valid_loss â–ƒâ–‚â–‚â–ˆâ–†â–ƒâ–„â–„â–‚â–‚â–‚â–â–ƒâ–â–‚â–â–‚â–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3291
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.74409
wandb:   test_error_force 10.314
wandb:          test_loss 4.10318
wandb: train_error_energy 14.4489
wandb:  train_error_force 6.76913
wandb:         train_loss 3.2319
wandb: valid_error_energy 4.7151
wandb:  valid_error_force 4.13418
wandb:         valid_loss 1.69885
wandb: 
wandb: ğŸš€ View run al_74_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/r11z1vn6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_042216-r11z1vn6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.271122455596924, Uncertainty Bias: 0.03202085196971893
1.5258789e-05 0.01249218
0.6342868 4.7198477
(48745, 22, 3)
Found uncertainty sample 0 after 102 steps.
Found uncertainty sample 1 after 34 steps.
Found uncertainty sample 2 after 29 steps.
Found uncertainty sample 3 after 30 steps.
Found uncertainty sample 4 after 307 steps.
Found uncertainty sample 5 after 31 steps.
Found uncertainty sample 6 after 14 steps.
Found uncertainty sample 7 after 10 steps.
Found uncertainty sample 8 after 115 steps.
Found uncertainty sample 9 after 101 steps.
Found uncertainty sample 10 after 69 steps.
Found uncertainty sample 11 after 42 steps.
Found uncertainty sample 12 after 173 steps.
Found uncertainty sample 13 after 150 steps.
Found uncertainty sample 14 after 10 steps.
Found uncertainty sample 15 after 34 steps.
Found uncertainty sample 16 after 186 steps.
Found uncertainty sample 17 after 130 steps.
Found uncertainty sample 18 after 106 steps.
Found uncertainty sample 19 after 223 steps.
Found uncertainty sample 20 after 839 steps.
Found uncertainty sample 21 after 210 steps.
Found uncertainty sample 22 after 153 steps.
Found uncertainty sample 23 after 51 steps.
Found uncertainty sample 24 after 19 steps.
Found uncertainty sample 25 after 34 steps.
Found uncertainty sample 26 after 143 steps.
Found uncertainty sample 27 after 102 steps.
Found uncertainty sample 28 after 3 steps.
Found uncertainty sample 29 after 6 steps.
Found uncertainty sample 30 after 118 steps.
Found uncertainty sample 31 after 20 steps.
Found uncertainty sample 32 after 17 steps.
Found uncertainty sample 33 after 3 steps.
Found uncertainty sample 34 after 21 steps.
Found uncertainty sample 35 after 30 steps.
Found uncertainty sample 36 after 75 steps.
Found uncertainty sample 37 after 698 steps.
Found uncertainty sample 38 after 215 steps.
Found uncertainty sample 39 after 301 steps.
Found uncertainty sample 40 after 20 steps.
Found uncertainty sample 41 after 121 steps.
Found uncertainty sample 42 after 22 steps.
Found uncertainty sample 43 after 17 steps.
Found uncertainty sample 44 after 1050 steps.
Found uncertainty sample 45 after 24 steps.
Found uncertainty sample 46 after 34 steps.
Found uncertainty sample 47 after 26 steps.
Found uncertainty sample 48 after 90 steps.
Found uncertainty sample 49 after 52 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 43 steps.
Found uncertainty sample 52 after 49 steps.
Found uncertainty sample 53 after 42 steps.
Found uncertainty sample 54 after 59 steps.
Found uncertainty sample 55 after 53 steps.
Found uncertainty sample 56 after 15 steps.
Found uncertainty sample 57 after 14 steps.
Found uncertainty sample 58 after 13 steps.
Found uncertainty sample 59 after 45 steps.
Found uncertainty sample 60 after 242 steps.
Found uncertainty sample 61 after 20 steps.
Found uncertainty sample 62 after 14 steps.
Found uncertainty sample 63 after 527 steps.
Found uncertainty sample 64 after 37 steps.
Found uncertainty sample 65 after 77 steps.
Found uncertainty sample 66 after 84 steps.
Found uncertainty sample 67 after 108 steps.
Found uncertainty sample 68 after 67 steps.
Found uncertainty sample 69 after 18 steps.
Found uncertainty sample 70 after 29 steps.
Found uncertainty sample 71 after 5 steps.
Found uncertainty sample 72 after 2 steps.
Found uncertainty sample 73 after 31 steps.
Found uncertainty sample 74 after 49 steps.
Found uncertainty sample 75 after 417 steps.
Found uncertainty sample 76 after 62 steps.
Found uncertainty sample 77 after 48 steps.
Found uncertainty sample 78 after 90 steps.
Found uncertainty sample 79 after 65 steps.
Found uncertainty sample 80 after 51 steps.
Found uncertainty sample 81 after 32 steps.
Found uncertainty sample 82 after 281 steps.
Found uncertainty sample 83 after 47 steps.
Found uncertainty sample 84 after 284 steps.
Found uncertainty sample 85 after 3 steps.
Found uncertainty sample 86 after 115 steps.
Found uncertainty sample 87 after 111 steps.
Found uncertainty sample 88 after 43 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 90 steps.
Found uncertainty sample 91 after 98 steps.
Found uncertainty sample 92 after 93 steps.
Found uncertainty sample 93 after 131 steps.
Found uncertainty sample 94 after 17 steps.
Found uncertainty sample 95 after 66 steps.
Found uncertainty sample 96 after 31 steps.
Found uncertainty sample 97 after 137 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 9 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_043235-p5gks0lp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/p5gks0lp
Training model 29. Added 100 samples to the dataset.
Epoch 0, Batch 100/106, Loss: 0.36295056343078613

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 12.137813596106739, Training Loss Force: 7.343040754205378, time: 1.5229859352111816
Validation Loss Energy: 23.286873773292193, Validation Loss Force: 4.353598416860283, time: 0.10463190078735352
Test Loss Energy: 15.213212150808976, Test Loss Force: 10.437749336540108, time: 10.241793155670166

Epoch 1, Batch 100/106, Loss: 0.23991164565086365

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 7.458690759199644, Training Loss Force: 4.316827602940517, time: 1.5243897438049316
Validation Loss Energy: 9.631177596249845, Validation Loss Force: 3.5188582152939327, time: 0.10852670669555664
Test Loss Energy: 10.436778750878185, Test Loss Force: 10.110895167187211, time: 10.304214715957642

Epoch 2, Batch 100/106, Loss: 0.43913817405700684

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.619101024247281, Training Loss Force: 3.5211920778332755, time: 1.4869616031646729
Validation Loss Energy: 8.035523371118648, Validation Loss Force: 3.6702657751084393, time: 0.10595011711120605
Test Loss Energy: 18.57097025036177, Test Loss Force: 10.504388644021837, time: 10.430132150650024

Epoch 3, Batch 100/106, Loss: 0.27197158336639404

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.909562175021835, Training Loss Force: 4.133012149633289, time: 1.498720645904541
Validation Loss Energy: 6.734600484942702, Validation Loss Force: 5.028742400770632, time: 0.1110696792602539
Test Loss Energy: 16.912111217951143, Test Loss Force: 10.63290790301249, time: 10.22939395904541

Epoch 4, Batch 100/106, Loss: 0.924231767654419

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.134277256066984, Training Loss Force: 3.907541395216004, time: 1.5584995746612549
Validation Loss Energy: 17.63684459760591, Validation Loss Force: 5.5434964628543195, time: 0.10829472541809082
Test Loss Energy: 25.441226854024197, Test Loss Force: 11.16811929533809, time: 10.378167152404785

Epoch 5, Batch 100/106, Loss: 0.3005334138870239

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 9.176835534634321, Training Loss Force: 4.328945623375411, time: 1.5574874877929688
Validation Loss Energy: 5.931490546889966, Validation Loss Force: 3.6273195769333473, time: 0.11026406288146973
Test Loss Energy: 9.150664930916916, Test Loss Force: 10.162273015863972, time: 10.25574541091919

Epoch 6, Batch 100/106, Loss: 0.29580432176589966

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.614019239589786, Training Loss Force: 3.556920926189239, time: 1.5127277374267578
Validation Loss Energy: 5.249935472930065, Validation Loss Force: 3.6434328070092654, time: 0.1094059944152832
Test Loss Energy: 17.00642963395496, Test Loss Force: 10.754657269187192, time: 10.251189470291138

Epoch 7, Batch 100/106, Loss: 0.662225604057312

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.660065399802744, Training Loss Force: 3.7948151211841896, time: 1.6016123294830322
Validation Loss Energy: 13.94688640856991, Validation Loss Force: 3.7466800365930624, time: 0.10767054557800293
Test Loss Energy: 23.190068863397116, Test Loss Force: 10.822630908119113, time: 10.456322431564331

Epoch 8, Batch 100/106, Loss: 0.14790546894073486

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 14.768025010302269, Training Loss Force: 5.310558977577076, time: 1.476973533630371
Validation Loss Energy: 2.1023005696079355, Validation Loss Force: 6.313013197537514, time: 0.11231827735900879
Test Loss Energy: 10.42451447473614, Test Loss Force: 11.716505183978775, time: 10.24828052520752

Epoch 9, Batch 100/106, Loss: 0.6599358320236206

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 13.84649313153012, Training Loss Force: 6.939078641383483, time: 1.4861440658569336
Validation Loss Energy: 4.6145548544229165, Validation Loss Force: 5.887517843952147, time: 0.1082303524017334
Test Loss Energy: 8.32322344215227, Test Loss Force: 11.11341638309812, time: 10.455142498016357

Epoch 10, Batch 100/106, Loss: 0.12831389904022217

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.782479574631678, Training Loss Force: 5.153235323325066, time: 1.5306940078735352
Validation Loss Energy: 5.034007190056949, Validation Loss Force: 7.961256976215644, time: 0.10658073425292969
Test Loss Energy: 14.048971673606992, Test Loss Force: 12.421154328952419, time: 10.88460659980774

Epoch 11, Batch 100/106, Loss: 0.20629122853279114

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.345281316775837, Training Loss Force: 4.344631942081627, time: 1.5425384044647217
Validation Loss Energy: 2.7979233235346905, Validation Loss Force: 3.8065424097842886, time: 0.10784149169921875
Test Loss Energy: 9.847829711231178, Test Loss Force: 10.228634814636296, time: 10.312992572784424

Epoch 12, Batch 100/106, Loss: 0.5497820973396301

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.240372793656993, Training Loss Force: 3.5296840131521767, time: 1.5253584384918213
Validation Loss Energy: 7.839298412961243, Validation Loss Force: 3.813727275115941, time: 0.1037905216217041
Test Loss Energy: 18.206068671660997, Test Loss Force: 10.645584217333907, time: 10.434551000595093

Epoch 13, Batch 100/106, Loss: 0.5028135776519775

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 6.587278834634443, Training Loss Force: 3.4761419482198384, time: 1.515352725982666
Validation Loss Energy: 8.864810961974092, Validation Loss Force: 3.792772549800114, time: 0.10409045219421387
Test Loss Energy: 9.655032081231122, Test Loss Force: 10.26893952487327, time: 10.3798189163208

Epoch 14, Batch 100/106, Loss: 2.7852683067321777

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.074045811370945, Training Loss Force: 3.4970794796964246, time: 1.5442819595336914
Validation Loss Energy: 9.984549522792618, Validation Loss Force: 4.785347878747324, time: 0.11058998107910156
Test Loss Energy: 16.40848374889195, Test Loss Force: 10.34559065736526, time: 10.467026233673096

Epoch 15, Batch 100/106, Loss: 0.18046453595161438

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 15.926926242389161, Training Loss Force: 8.526220968696782, time: 1.5465898513793945
Validation Loss Energy: 21.841284301690983, Validation Loss Force: 8.474048432447125, time: 0.11127662658691406
Test Loss Energy: 16.63462038736146, Test Loss Force: 12.213610531525282, time: 10.341436624526978

Epoch 16, Batch 100/106, Loss: 1.0005710124969482

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.850611801170706, Training Loss Force: 6.640178591509482, time: 1.525527000427246
Validation Loss Energy: 10.29916855651641, Validation Loss Force: 4.73830456828716, time: 0.10848855972290039
Test Loss Energy: 9.494240098201795, Test Loss Force: 10.306450145361309, time: 10.235039234161377

Epoch 17, Batch 100/106, Loss: 1.1815695762634277

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.43315264373633, Training Loss Force: 6.104772251829707, time: 1.5219252109527588
Validation Loss Energy: 5.436213577669728, Validation Loss Force: 10.290611826576697, time: 0.10676932334899902
Test Loss Energy: 12.985795718097782, Test Loss Force: 14.780086252018638, time: 10.420301675796509

Epoch 18, Batch 100/106, Loss: 0.2623457908630371

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.398710016939754, Training Loss Force: 6.537533163104295, time: 1.4821386337280273
Validation Loss Energy: 11.113384118222294, Validation Loss Force: 5.812114500390037, time: 0.10497117042541504
Test Loss Energy: 9.490807267435187, Test Loss Force: 11.450175985910194, time: 10.384136438369751

Epoch 19, Batch 100/106, Loss: 0.745529055595398

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.452231699242633, Training Loss Force: 4.912237809449842, time: 1.4797112941741943
Validation Loss Energy: 4.609668602684677, Validation Loss Force: 5.230422084995829, time: 0.10806727409362793
Test Loss Energy: 9.245269454622914, Test Loss Force: 10.877445919701472, time: 10.340954542160034

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–…â–…â–ˆâ–â–…â–‡â–‚â–â–ƒâ–‚â–…â–‚â–„â–„â–â–ƒâ–â–
wandb:   test_error_force â–â–â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–„â–â–‚â–â–â–„â–â–ˆâ–ƒâ–‚
wandb:          test_loss â–ƒâ–â–„â–„â–‡â–â–„â–†â–ƒâ–‚â–…â–â–„â–â–ƒâ–†â–â–ˆâ–ƒâ–‚
wandb: train_error_energy â–…â–‚â–â–â–„â–ƒâ–â–â–‡â–†â–ƒâ–â–â–â–ƒâ–ˆâ–„â–ƒâ–„â–„
wandb:  train_error_force â–†â–‚â–â–‚â–‚â–‚â–â–â–„â–†â–ƒâ–‚â–â–â–â–ˆâ–…â–…â–…â–ƒ
wandb:         train_loss â–†â–‚â–â–‚â–‚â–‚â–â–â–…â–†â–ƒâ–‚â–â–â–‚â–ˆâ–…â–„â–…â–ƒ
wandb: valid_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–†â–‚â–‚â–…â–â–‚â–‚â–â–ƒâ–ƒâ–„â–ˆâ–„â–‚â–„â–‚
wandb:  valid_error_force â–‚â–â–â–ƒâ–ƒâ–â–â–â–„â–ƒâ–†â–â–â–â–‚â–†â–‚â–ˆâ–ƒâ–ƒ
wandb:         valid_loss â–…â–‚â–‚â–ƒâ–…â–â–â–ƒâ–ƒâ–ƒâ–…â–â–‚â–‚â–ƒâ–ˆâ–ƒâ–‡â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3381
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.24527
wandb:   test_error_force 10.87745
wandb:          test_loss 4.25833
wandb: train_error_energy 10.45223
wandb:  train_error_force 4.91224
wandb:         train_loss 2.34312
wandb: valid_error_energy 4.60967
wandb:  valid_error_force 5.23042
wandb:         valid_loss 2.0586
wandb: 
wandb: ğŸš€ View run al_74_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/p5gks0lp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_043235-p5gks0lp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4665993452072144, Uncertainty Bias: 0.05539746582508087
0.00010681152 0.113679886
0.92491835 5.723997
(48745, 22, 3)
Found uncertainty sample 0 after 11 steps.
Found uncertainty sample 1 after 4 steps.
Found uncertainty sample 2 after 3 steps.
Found uncertainty sample 3 after 13 steps.
Found uncertainty sample 4 after 18 steps.
Found uncertainty sample 5 after 8 steps.
Found uncertainty sample 6 after 4 steps.
Found uncertainty sample 7 after 3 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 7 steps.
Found uncertainty sample 10 after 10 steps.
Found uncertainty sample 11 after 6 steps.
Found uncertainty sample 12 after 6 steps.
Found uncertainty sample 13 after 3 steps.
Found uncertainty sample 14 after 12 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 2 steps.
Found uncertainty sample 17 after 6 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 3 steps.
Found uncertainty sample 20 after 3 steps.
Found uncertainty sample 21 after 2 steps.
Found uncertainty sample 22 after 16 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 4 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 2 steps.
Found uncertainty sample 29 after 3 steps.
Found uncertainty sample 30 after 14 steps.
Found uncertainty sample 31 after 2 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 5 steps.
Found uncertainty sample 34 after 3 steps.
Found uncertainty sample 35 after 29 steps.
Found uncertainty sample 36 after 11 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 6 steps.
Found uncertainty sample 40 after 3 steps.
Found uncertainty sample 41 after 15 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 10 steps.
Found uncertainty sample 44 after 6 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 6 steps.
Found uncertainty sample 47 after 7 steps.
Found uncertainty sample 48 after 4 steps.
Found uncertainty sample 49 after 4 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 5 steps.
Found uncertainty sample 53 after 7 steps.
Found uncertainty sample 54 after 5 steps.
Found uncertainty sample 55 after 4 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 2 steps.
Found uncertainty sample 58 after 25 steps.
Found uncertainty sample 59 after 9 steps.
Found uncertainty sample 60 after 40 steps.
Found uncertainty sample 61 after 22 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 3 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 5 steps.
Found uncertainty sample 66 after 3 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 5 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 2 steps.
Found uncertainty sample 74 after 19 steps.
Found uncertainty sample 75 after 8 steps.
Found uncertainty sample 76 after 5 steps.
Found uncertainty sample 77 after 30 steps.
Found uncertainty sample 78 after 26 steps.
Found uncertainty sample 79 after 2 steps.
Found uncertainty sample 80 after 2 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 18 steps.
Found uncertainty sample 83 after 7 steps.
Found uncertainty sample 84 after 10 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 6 steps.
Found uncertainty sample 87 after 9 steps.
Found uncertainty sample 88 after 6 steps.
Found uncertainty sample 89 after 11 steps.
Found uncertainty sample 90 after 2 steps.
Found uncertainty sample 91 after 15 steps.
Found uncertainty sample 92 after 4 steps.
Found uncertainty sample 93 after 7 steps.
Found uncertainty sample 94 after 2 steps.
Found uncertainty sample 95 after 7 steps.
Found uncertainty sample 96 after 9 steps.
Found uncertainty sample 97 after 5 steps.
Found uncertainty sample 98 after 3 steps.
Found uncertainty sample 99 after 4 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_043938-cnpnfnu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/cnpnfnu4
Training model 30. Added 100 samples to the dataset.
Epoch 0, Batch 100/109, Loss: 0.8470176458358765

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 14.085565696444062, Training Loss Force: 7.343937258461156, time: 1.6473891735076904
Validation Loss Energy: 3.335336531911709, Validation Loss Force: 6.563199351180766, time: 0.11145782470703125
Test Loss Energy: 8.725421468596911, Test Loss Force: 11.314482690769552, time: 10.106630563735962

Epoch 1, Batch 100/109, Loss: 0.5882209539413452

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 5.809910867444379, Training Loss Force: 4.323054352847447, time: 1.5274696350097656
Validation Loss Energy: 2.470826578880543, Validation Loss Force: 3.664823407178246, time: 0.10825705528259277
Test Loss Energy: 12.30037680284802, Test Loss Force: 9.803493155250843, time: 10.21728515625

Epoch 2, Batch 100/109, Loss: 0.5923240184783936

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.484748711921623, Training Loss Force: 3.473332302114219, time: 1.5636460781097412
Validation Loss Energy: 5.823074943760041, Validation Loss Force: 3.5679724601457976, time: 0.10781145095825195
Test Loss Energy: 9.137934653718919, Test Loss Force: 10.037334300055985, time: 10.316623210906982

Epoch 3, Batch 100/109, Loss: 0.3152197003364563

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.740647764006615, Training Loss Force: 3.8812983213548335, time: 1.597689151763916
Validation Loss Energy: 18.026261760153183, Validation Loss Force: 4.593692982140942, time: 0.10673093795776367
Test Loss Energy: 25.984657083438304, Test Loss Force: 10.528711496647375, time: 10.158022403717041

Epoch 4, Batch 100/109, Loss: 0.27534085512161255

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.58128011087808, Training Loss Force: 4.247172928414849, time: 1.6145894527435303
Validation Loss Energy: 7.575313897683139, Validation Loss Force: 3.986835390550559, time: 0.11015081405639648
Test Loss Energy: 17.29906787011461, Test Loss Force: 10.085776096328123, time: 10.269855499267578

Epoch 5, Batch 100/109, Loss: 0.5342913866043091

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.674980742471343, Training Loss Force: 3.418780710623543, time: 1.5801634788513184
Validation Loss Energy: 3.8105034712211983, Validation Loss Force: 3.221455069256693, time: 0.10575103759765625
Test Loss Energy: 14.196481299853266, Test Loss Force: 9.944069451859677, time: 10.09652853012085

Epoch 6, Batch 100/109, Loss: 1.338573932647705

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 13.120229910049547, Training Loss Force: 4.543709489035698, time: 1.6026952266693115
Validation Loss Energy: 11.00672693333776, Validation Loss Force: 8.009181165817099, time: 0.1124258041381836
Test Loss Energy: 11.01601121780759, Test Loss Force: 12.718069645362561, time: 10.266551971435547

Epoch 7, Batch 100/109, Loss: 0.3036671578884125

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.769377172048802, Training Loss Force: 5.946458419992974, time: 1.5529263019561768
Validation Loss Energy: 2.2826654725083406, Validation Loss Force: 5.362718063349927, time: 0.11097526550292969
Test Loss Energy: 9.022178389135227, Test Loss Force: 10.977550968205096, time: 10.382055044174194

Epoch 8, Batch 100/109, Loss: 0.301946222782135

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.197747913554151, Training Loss Force: 4.269845076339182, time: 1.5798876285552979
Validation Loss Energy: 9.615892695396777, Validation Loss Force: 3.6168958775396027, time: 0.11219048500061035
Test Loss Energy: 17.369052824648765, Test Loss Force: 10.132902545152017, time: 10.150731325149536

Epoch 9, Batch 100/109, Loss: 0.18928144872188568

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.463558364856934, Training Loss Force: 3.4059589186633157, time: 1.5499708652496338
Validation Loss Energy: 8.993072843411415, Validation Loss Force: 3.3415329689045876, time: 0.11471724510192871
Test Loss Energy: 19.554108613753463, Test Loss Force: 10.154479278656984, time: 10.348606586456299

Epoch 10, Batch 100/109, Loss: 0.6896787881851196

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.735008337190266, Training Loss Force: 3.488631557977272, time: 1.5800049304962158
Validation Loss Energy: 9.254285573161013, Validation Loss Force: 3.5499000755894334, time: 0.10808682441711426
Test Loss Energy: 9.796679591302928, Test Loss Force: 10.004084065461521, time: 10.766806364059448

Epoch 11, Batch 100/109, Loss: 0.17897439002990723

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 16.07473309531889, Training Loss Force: 7.330589191038782, time: 1.6470708847045898
Validation Loss Energy: 33.053300163440284, Validation Loss Force: 7.336622148021825, time: 0.10721492767333984
Test Loss Energy: 36.73709415704309, Test Loss Force: 11.742753166423194, time: 10.200900793075562

Epoch 12, Batch 100/109, Loss: 0.9351661801338196

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.269203923341355, Training Loss Force: 6.64597361138155, time: 1.580784559249878
Validation Loss Energy: 5.660776970021924, Validation Loss Force: 4.308698964937112, time: 0.1080331802368164
Test Loss Energy: 13.898034131636614, Test Loss Force: 10.02319341964757, time: 10.368845224380493

Epoch 13, Batch 100/109, Loss: 0.31450125575065613

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.805845111963784, Training Loss Force: 4.585446744918282, time: 1.6111042499542236
Validation Loss Energy: 3.759761403578028, Validation Loss Force: 3.6299438441526792, time: 0.11010885238647461
Test Loss Energy: 9.4140650620967, Test Loss Force: 10.161899845691538, time: 10.191545963287354

Epoch 14, Batch 100/109, Loss: 0.40742364525794983

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.3395446246278695, Training Loss Force: 3.5088931346701875, time: 1.5387413501739502
Validation Loss Energy: 10.516389433781637, Validation Loss Force: 3.462384643834581, time: 0.10854387283325195
Test Loss Energy: 19.45136557240124, Test Loss Force: 10.445812454449776, time: 10.147378206253052

Epoch 15, Batch 100/109, Loss: 0.3715685307979584

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.892269026471487, Training Loss Force: 5.473728536264833, time: 1.8193345069885254
Validation Loss Energy: 7.451081214441378, Validation Loss Force: 4.758672337734321, time: 0.11009597778320312
Test Loss Energy: 8.66432382024864, Test Loss Force: 10.70879405157332, time: 10.169631481170654

Epoch 16, Batch 100/109, Loss: 0.43615174293518066

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.176357639751489, Training Loss Force: 4.78156419269209, time: 1.564558744430542
Validation Loss Energy: 3.834568216498198, Validation Loss Force: 4.745317755707301, time: 0.10787796974182129
Test Loss Energy: 16.97899584854133, Test Loss Force: 10.287627542402936, time: 10.125616550445557

Epoch 17, Batch 100/109, Loss: 0.19743949174880981

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.234351824936889, Training Loss Force: 5.733707999671273, time: 1.5974056720733643
Validation Loss Energy: 15.462813500663371, Validation Loss Force: 4.884031726854476, time: 0.1230158805847168
Test Loss Energy: 11.28069134450273, Test Loss Force: 10.741867386606511, time: 10.347123622894287

Epoch 18, Batch 100/109, Loss: 0.5420582294464111

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 13.108386213762588, Training Loss Force: 6.450174372117127, time: 1.571380376815796
Validation Loss Energy: 2.290070223621597, Validation Loss Force: 8.512655699644668, time: 0.11107301712036133
Test Loss Energy: 10.784050016140197, Test Loss Force: 13.367649870642301, time: 10.097223997116089

Epoch 19, Batch 100/109, Loss: 1.550957441329956

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.561767890424735, Training Loss Force: 5.426796354051177, time: 1.5732223987579346
Validation Loss Energy: 4.116885305229683, Validation Loss Force: 6.235974794436856, time: 0.11844944953918457
Test Loss Energy: 9.217492898621407, Test Loss Force: 11.584445770024795, time: 10.185503244400024

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.057 MB uploadedwandb: / 0.039 MB of 0.057 MB uploadedwandb: - 0.057 MB of 0.057 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–â–…â–ƒâ–‚â–‚â–â–ƒâ–„â–â–ˆâ–‚â–â–„â–â–ƒâ–‚â–‚â–
wandb:   test_error_force â–„â–â–â–‚â–‚â–â–‡â–ƒâ–‚â–‚â–â–…â–â–‚â–‚â–ƒâ–‚â–ƒâ–ˆâ–„
wandb:          test_loss â–‚â–â–â–…â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–â–ˆâ–‚â–â–ƒâ–‚â–ƒâ–‚â–…â–ƒ
wandb: train_error_energy â–‡â–â–â–‚â–ƒâ–‚â–†â–„â–â–â–‚â–ˆâ–…â–ƒâ–â–„â–ƒâ–ƒâ–†â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–‚â–â–ƒâ–†â–ƒâ–â–â–ˆâ–‡â–ƒâ–â–…â–ƒâ–…â–†â–…
wandb:         train_loss â–ˆâ–‚â–â–‚â–ƒâ–â–„â–…â–‚â–â–â–ˆâ–†â–ƒâ–â–„â–ƒâ–„â–†â–„
wandb: valid_error_energy â–â–â–‚â–…â–‚â–â–ƒâ–â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–â–ƒâ–‚â–â–„â–â–
wandb:  valid_error_force â–…â–‚â–â–ƒâ–‚â–â–‡â–„â–‚â–â–â–†â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–ˆâ–…
wandb:         valid_loss â–ƒâ–â–‚â–„â–‚â–â–…â–‚â–‚â–‚â–‚â–ˆâ–‚â–â–‚â–ƒâ–‚â–„â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3471
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.21749
wandb:   test_error_force 11.58445
wandb:          test_loss 4.49303
wandb: train_error_energy 8.56177
wandb:  train_error_force 5.4268
wandb:         train_loss 2.38878
wandb: valid_error_energy 4.11689
wandb:  valid_error_force 6.23597
wandb:         valid_loss 2.36208
wandb: 
wandb: ğŸš€ View run al_74_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/cnpnfnu4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_043938-cnpnfnu4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7328323721885681, Uncertainty Bias: 0.1374773383140564
1.5258789e-05 0.0009775162
2.1182804 3.5961266
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2421 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1279 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3990 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3563 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3033 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2154 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2353 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_065210-hvm5zxv6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hvm5zxv6
Training model 31. Added 7 samples to the dataset.
Epoch 0, Batch 100/109, Loss: 0.4219162166118622

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 12.957372308484045, Training Loss Force: 7.802717706688858, time: 1.5503239631652832
Validation Loss Energy: 4.469817460209249, Validation Loss Force: 5.217400838680264, time: 0.10903429985046387
Test Loss Energy: 12.909695732545206, Test Loss Force: 10.544127895872085, time: 10.196670055389404

Epoch 1, Batch 100/109, Loss: 0.330632746219635

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.95889299750483, Training Loss Force: 5.321238023016269, time: 1.562610149383545
Validation Loss Energy: 16.232648429556097, Validation Loss Force: 4.420060703536809, time: 0.11775994300842285
Test Loss Energy: 11.6928659186364, Test Loss Force: 10.297346498030143, time: 10.263017177581787

Epoch 2, Batch 100/109, Loss: 0.43132954835891724

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.75177331348407, Training Loss Force: 4.468177814503431, time: 1.5569696426391602
Validation Loss Energy: 5.401591420176855, Validation Loss Force: 3.7521642663226906, time: 0.10687756538391113
Test Loss Energy: 8.752712960265638, Test Loss Force: 10.122164501626512, time: 10.391760349273682

Epoch 3, Batch 100/109, Loss: 0.17899757623672485

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.2660374661417215, Training Loss Force: 3.5038606771450307, time: 1.5448660850524902
Validation Loss Energy: 8.608189670013527, Validation Loss Force: 4.063106921112642, time: 0.11143898963928223
Test Loss Energy: 16.980298824445192, Test Loss Force: 10.252060182364968, time: 10.337196826934814

Epoch 4, Batch 100/109, Loss: 0.0808173418045044

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.490501398440315, Training Loss Force: 4.5710519895115125, time: 1.5284981727600098
Validation Loss Energy: 7.435018084923293, Validation Loss Force: 4.44956881875516, time: 0.11270475387573242
Test Loss Energy: 8.866941929016761, Test Loss Force: 10.60231853906411, time: 10.323809146881104

Epoch 5, Batch 100/109, Loss: 0.46697568893432617

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.4482381249804215, Training Loss Force: 3.5360912188835973, time: 1.5380005836486816
Validation Loss Energy: 9.272651324317135, Validation Loss Force: 3.6874941322671644, time: 0.11114645004272461
Test Loss Energy: 17.971526377855348, Test Loss Force: 10.449621360579979, time: 10.30061411857605

Epoch 6, Batch 100/109, Loss: 0.279594361782074

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.543213289763469, Training Loss Force: 3.424329968936545, time: 1.6508724689483643
Validation Loss Energy: 8.996097135751407, Validation Loss Force: 3.4490865084360545, time: 0.10985851287841797
Test Loss Energy: 17.780746083685116, Test Loss Force: 10.505733015402319, time: 10.26944088935852

Epoch 7, Batch 100/109, Loss: 0.25184571743011475

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.057144072515394, Training Loss Force: 3.407675195240713, time: 1.5259404182434082
Validation Loss Energy: 1.6280029863114351, Validation Loss Force: 3.7574185901591486, time: 0.11052870750427246
Test Loss Energy: 12.44191668561327, Test Loss Force: 10.497783367824127, time: 11.076350212097168

Epoch 8, Batch 100/109, Loss: 0.6689224243164062

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.29573489487924, Training Loss Force: 6.002502493312374, time: 1.5860662460327148
Validation Loss Energy: 8.21026342872377, Validation Loss Force: 5.622950380850003, time: 0.11694455146789551
Test Loss Energy: 17.33353270777556, Test Loss Force: 11.118608421361492, time: 10.300130605697632

Epoch 9, Batch 100/109, Loss: 0.2450719177722931

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.390632509711683, Training Loss Force: 3.8021363389521525, time: 1.5889630317687988
Validation Loss Energy: 8.178330001167975, Validation Loss Force: 3.381260373240721, time: 0.10944223403930664
Test Loss Energy: 16.87022882570104, Test Loss Force: 10.275243356011291, time: 10.470434665679932

Epoch 10, Batch 100/109, Loss: 0.714055061340332

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.352618228835271, Training Loss Force: 3.4171589601628454, time: 1.570383071899414
Validation Loss Energy: 9.322048692988048, Validation Loss Force: 4.28762644764309, time: 0.10927152633666992
Test Loss Energy: 9.642658778814067, Test Loss Force: 10.655951669452161, time: 10.319194793701172

Epoch 11, Batch 100/109, Loss: 0.24696196615695953

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 14.022225639760684, Training Loss Force: 5.245010903713199, time: 1.5670850276947021
Validation Loss Energy: 12.730579356530546, Validation Loss Force: 3.516195092308636, time: 0.10881590843200684
Test Loss Energy: 21.616666555916847, Test Loss Force: 9.948404057693082, time: 10.152973175048828

Epoch 12, Batch 100/109, Loss: 0.512580156326294

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.471145223628396, Training Loss Force: 5.889017859760781, time: 1.5917201042175293
Validation Loss Energy: 14.05244806125648, Validation Loss Force: 6.6062517625384665, time: 0.10774564743041992
Test Loss Energy: 26.47244548759638, Test Loss Force: 12.203060891744988, time: 10.427615404129028

Epoch 13, Batch 100/109, Loss: 0.8791834115982056

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 19.0524116066472, Training Loss Force: 6.73211307651325, time: 1.585148572921753
Validation Loss Energy: 12.395891152684282, Validation Loss Force: 6.4293678463963495, time: 0.10988855361938477
Test Loss Energy: 10.078137299540872, Test Loss Force: 11.35245106306288, time: 10.243544101715088

Epoch 14, Batch 100/109, Loss: 1.2546350955963135

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.261759572092076, Training Loss Force: 5.119265782175868, time: 1.5992803573608398
Validation Loss Energy: 6.264513630862982, Validation Loss Force: 5.07784094744771, time: 0.10758614540100098
Test Loss Energy: 9.17595129975044, Test Loss Force: 10.698650322490563, time: 10.407231330871582

Epoch 15, Batch 100/109, Loss: 0.6316268444061279

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.931689374431267, Training Loss Force: 6.821103147965445, time: 1.5437166690826416
Validation Loss Energy: 2.856150748521942, Validation Loss Force: 4.2929139491822905, time: 0.10902047157287598
Test Loss Energy: 8.472858260033107, Test Loss Force: 10.107775350949424, time: 10.355801820755005

Epoch 16, Batch 100/109, Loss: 0.46082255244255066

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.1208063347609185, Training Loss Force: 3.76938281276056, time: 1.5317835807800293
Validation Loss Energy: 3.7641444230464707, Validation Loss Force: 3.6269001795969924, time: 0.10768651962280273
Test Loss Energy: 9.407824683504616, Test Loss Force: 10.129306156319977, time: 10.308245420455933

Epoch 17, Batch 100/109, Loss: 0.2274520993232727

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.202031077146245, Training Loss Force: 3.4805904133378642, time: 1.588210105895996
Validation Loss Energy: 8.403279724488355, Validation Loss Force: 3.628056611806368, time: 0.1081991195678711
Test Loss Energy: 16.545441081981096, Test Loss Force: 9.918311817185575, time: 10.449484825134277

Epoch 18, Batch 100/109, Loss: 0.44230008125305176

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.398810965629188, Training Loss Force: 3.411329970160308, time: 1.5715489387512207
Validation Loss Energy: 6.215488119665769, Validation Loss Force: 3.1721843993298138, time: 0.10892152786254883
Test Loss Energy: 14.905569674847918, Test Loss Force: 9.785471839455065, time: 10.240062236785889

Epoch 19, Batch 100/109, Loss: 0.4390125870704651

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.907914004539563, Training Loss Force: 4.718413557995465, time: 1.5834228992462158
Validation Loss Energy: 7.523222900353938, Validation Loss Force: 8.348418054976374, time: 0.11710953712463379
Test Loss Energy: 10.699670529563623, Test Loss Force: 13.36772937401966, time: 10.370003938674927

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–â–„â–â–…â–…â–ƒâ–„â–„â–â–†â–ˆâ–‚â–â–â–â–„â–„â–‚
wandb:   test_error_force â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–â–†â–„â–ƒâ–‚â–‚â–â–â–ˆ
wandb:          test_loss â–ƒâ–‚â–â–ƒâ–‚â–„â–„â–‚â–„â–ƒâ–‚â–„â–ˆâ–ƒâ–‚â–â–â–ƒâ–‚â–†
wandb: train_error_energy â–…â–ƒâ–‚â–â–‚â–â–â–‚â–„â–â–â–…â–ƒâ–ˆâ–ƒâ–…â–â–â–â–„
wandb:  train_error_force â–ˆâ–„â–ƒâ–â–ƒâ–â–â–â–…â–‚â–â–„â–…â–†â–„â–†â–‚â–â–â–ƒ
wandb:         train_loss â–ˆâ–„â–ƒâ–â–ƒâ–â–â–â–…â–â–â–…â–…â–ˆâ–„â–‡â–â–â–â–„
wandb: valid_error_energy â–‚â–ˆâ–ƒâ–„â–„â–…â–…â–â–„â–„â–…â–†â–‡â–†â–ƒâ–‚â–‚â–„â–ƒâ–„
wandb:  valid_error_force â–„â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–„â–â–ƒâ–â–†â–…â–„â–ƒâ–‚â–‚â–â–ˆ
wandb:         valid_loss â–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–…â–‚â–„â–ƒâ–‡â–‡â–„â–‚â–â–‚â–â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3477
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.69967
wandb:   test_error_force 13.36773
wandb:          test_loss 5.18891
wandb: train_error_energy 10.90791
wandb:  train_error_force 4.71841
wandb:         train_loss 2.30876
wandb: valid_error_energy 7.52322
wandb:  valid_error_force 8.34842
wandb:         valid_loss 3.29687
wandb: 
wandb: ğŸš€ View run al_74_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/hvm5zxv6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_065210-hvm5zxv6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4573638439178467, Uncertainty Bias: 0.028701409697532654
4.5776367e-05 0.0065808296
0.45897153 2.702326
(48745, 22, 3)
Found uncertainty sample 0 after 2104 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1188 steps.
Found uncertainty sample 3 after 694 steps.
Found uncertainty sample 4 after 995 steps.
Found uncertainty sample 5 after 3362 steps.
Found uncertainty sample 6 after 739 steps.
Found uncertainty sample 7 after 601 steps.
Found uncertainty sample 8 after 521 steps.
Found uncertainty sample 9 after 1609 steps.
Found uncertainty sample 10 after 3038 steps.
Found uncertainty sample 11 after 404 steps.
Found uncertainty sample 12 after 3464 steps.
Found uncertainty sample 13 after 3928 steps.
Found uncertainty sample 14 after 934 steps.
Found uncertainty sample 15 after 622 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1767 steps.
Found uncertainty sample 18 after 189 steps.
Found uncertainty sample 19 after 701 steps.
Found uncertainty sample 20 after 2070 steps.
Found uncertainty sample 21 after 1908 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1805 steps.
Found uncertainty sample 24 after 2033 steps.
Found uncertainty sample 25 after 644 steps.
Found uncertainty sample 26 after 2185 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 473 steps.
Found uncertainty sample 29 after 3278 steps.
Found uncertainty sample 30 after 3585 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 671 steps.
Found uncertainty sample 34 after 1750 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1768 steps.
Found uncertainty sample 37 after 882 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 235 steps.
Found uncertainty sample 40 after 1209 steps.
Found uncertainty sample 41 after 3212 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2046 steps.
Found uncertainty sample 44 after 1388 steps.
Found uncertainty sample 45 after 2842 steps.
Found uncertainty sample 46 after 954 steps.
Found uncertainty sample 47 after 1424 steps.
Found uncertainty sample 48 after 3634 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 195 steps.
Found uncertainty sample 52 after 775 steps.
Found uncertainty sample 53 after 1877 steps.
Found uncertainty sample 54 after 3632 steps.
Found uncertainty sample 55 after 1777 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1444 steps.
Found uncertainty sample 58 after 792 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3133 steps.
Found uncertainty sample 61 after 1716 steps.
Found uncertainty sample 62 after 1849 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 451 steps.
Found uncertainty sample 65 after 110 steps.
Found uncertainty sample 66 after 2538 steps.
Found uncertainty sample 67 after 2355 steps.
Found uncertainty sample 68 after 226 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2693 steps.
Found uncertainty sample 71 after 1376 steps.
Found uncertainty sample 72 after 3575 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2116 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1168 steps.
Found uncertainty sample 78 after 3384 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1353 steps.
Found uncertainty sample 82 after 917 steps.
Found uncertainty sample 83 after 1830 steps.
Found uncertainty sample 84 after 106 steps.
Found uncertainty sample 85 after 528 steps.
Found uncertainty sample 86 after 2682 steps.
Found uncertainty sample 87 after 2430 steps.
Found uncertainty sample 88 after 153 steps.
Found uncertainty sample 89 after 1 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3086 steps.
Found uncertainty sample 92 after 3145 steps.
Found uncertainty sample 93 after 3545 steps.
Found uncertainty sample 94 after 1561 steps.
Found uncertainty sample 95 after 217 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 981 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 386 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_080944-oayh9vne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/oayh9vne
Training model 32. Added 77 samples to the dataset.
Epoch 0, Batch 100/111, Loss: 0.451028048992157

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 11.685329093458124, Training Loss Force: 7.8206874649609155, time: 1.7929575443267822
Validation Loss Energy: 8.81096867181217, Validation Loss Force: 3.537820497091997, time: 0.12578296661376953
Test Loss Energy: 16.22302128822866, Test Loss Force: 10.08579158757216, time: 11.784207344055176

Epoch 1, Batch 100/111, Loss: 2.4444332122802734

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.208711448848996, Training Loss Force: 3.9583861172718033, time: 1.7210917472839355
Validation Loss Energy: 26.34337743193332, Validation Loss Force: 4.946032837192339, time: 0.1239326000213623
Test Loss Energy: 18.230488076426145, Test Loss Force: 10.920598915725355, time: 11.668095350265503

Epoch 2, Batch 100/111, Loss: 0.6742022037506104

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.939914507453375, Training Loss Force: 6.166556123491761, time: 1.9410607814788818
Validation Loss Energy: 1.6813878027130493, Validation Loss Force: 4.399209964712131, time: 0.12700557708740234
Test Loss Energy: 9.054834570427722, Test Loss Force: 10.230354869669203, time: 11.930123329162598

Epoch 3, Batch 100/111, Loss: 1.471797227859497

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 12.863252275634162, Training Loss Force: 5.8476986267078574, time: 1.7620301246643066
Validation Loss Energy: 8.290193190684302, Validation Loss Force: 6.895983065821909, time: 0.12723350524902344
Test Loss Energy: 17.171882732728886, Test Loss Force: 12.428520774560639, time: 11.857795476913452

Epoch 4, Batch 100/111, Loss: 0.23272310197353363

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 9.437763650502161, Training Loss Force: 5.917439277237964, time: 1.767575740814209
Validation Loss Energy: 1.714446711466937, Validation Loss Force: 5.243018033242672, time: 0.12392950057983398
Test Loss Energy: 9.676935021537451, Test Loss Force: 10.762138901194856, time: 12.023615598678589

Epoch 5, Batch 100/111, Loss: 1.897263526916504

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 11.976554613030244, Training Loss Force: 5.659412521700642, time: 1.765925407409668
Validation Loss Energy: 28.40851797245767, Validation Loss Force: 5.917512045916058, time: 0.12427020072937012
Test Loss Energy: 34.89012940633596, Test Loss Force: 12.361152124200776, time: 12.561443090438843

Epoch 6, Batch 100/111, Loss: 1.002756118774414

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.76417023815659, Training Loss Force: 5.738869759673229, time: 1.7947137355804443
Validation Loss Energy: 5.056525720784626, Validation Loss Force: 4.739729428151952, time: 0.12177658081054688
Test Loss Energy: 12.596470486430992, Test Loss Force: 10.866807394128704, time: 12.021034955978394

Epoch 7, Batch 100/111, Loss: 0.4554140567779541

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.102734330797824, Training Loss Force: 4.106571491053425, time: 1.7745380401611328
Validation Loss Energy: 7.604127730504486, Validation Loss Force: 3.2517487612218767, time: 0.13254475593566895
Test Loss Energy: 14.607636329092278, Test Loss Force: 10.295467380283783, time: 11.78316879272461

Epoch 8, Batch 100/111, Loss: 0.6558579206466675

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.243179784244832, Training Loss Force: 3.447032138823385, time: 1.7467763423919678
Validation Loss Energy: 9.972298711721962, Validation Loss Force: 3.591211436895124, time: 0.1262049674987793
Test Loss Energy: 17.338828558824833, Test Loss Force: 10.705000324250868, time: 12.12295150756836

Epoch 9, Batch 100/111, Loss: 0.5574937462806702

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.404587148601188, Training Loss Force: 3.415508229917376, time: 1.73529052734375
Validation Loss Energy: 7.9972095818554365, Validation Loss Force: 3.2726660781211874, time: 0.12840652465820312
Test Loss Energy: 9.279425656526312, Test Loss Force: 10.142571967969422, time: 11.842267513275146

Epoch 10, Batch 100/111, Loss: 0.386827290058136

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.4359769494974834, Training Loss Force: 3.3713534979618016, time: 1.6664586067199707
Validation Loss Energy: 6.412804601976511, Validation Loss Force: 3.5960031655809175, time: 0.1253952980041504
Test Loss Energy: 9.10546092122924, Test Loss Force: 10.369669618493388, time: 12.127867937088013

Epoch 11, Batch 100/111, Loss: 0.6955282688140869

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.4312627327437975, Training Loss Force: 3.3642019668031042, time: 1.7655630111694336
Validation Loss Energy: 8.62030554358175, Validation Loss Force: 3.4970041292977037, time: 0.1325211524963379
Test Loss Energy: 18.331983638953158, Test Loss Force: 11.171585953161964, time: 11.83736801147461

Epoch 12, Batch 100/111, Loss: 0.16121521592140198

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.547967676890192, Training Loss Force: 5.074723934471737, time: 1.734572172164917
Validation Loss Energy: 16.37521903031074, Validation Loss Force: 5.882333883565803, time: 0.12741971015930176
Test Loss Energy: 10.747186246023654, Test Loss Force: 11.535345246138968, time: 11.83632230758667

Epoch 13, Batch 100/111, Loss: 0.7865043878555298

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.045197748403373, Training Loss Force: 6.051543635979331, time: 1.9979875087738037
Validation Loss Energy: 1.7623310432912702, Validation Loss Force: 5.013638084594913, time: 0.12911033630371094
Test Loss Energy: 9.926286865367702, Test Loss Force: 10.80667885786225, time: 11.881731748580933

Epoch 14, Batch 100/111, Loss: 0.34072595834732056

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.290290767993001, Training Loss Force: 4.813728614061756, time: 1.67280912399292
Validation Loss Energy: 11.981910465973133, Validation Loss Force: 4.483862984596081, time: 0.12483096122741699
Test Loss Energy: 9.561244093443888, Test Loss Force: 10.762251783959577, time: 11.94210696220398

Epoch 15, Batch 100/111, Loss: 0.46846288442611694

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.337347738581258, Training Loss Force: 3.6359340062662526, time: 1.786271572113037
Validation Loss Energy: 8.812429826747747, Validation Loss Force: 3.4159466594476218, time: 0.12770318984985352
Test Loss Energy: 17.4800192357473, Test Loss Force: 10.289216593366383, time: 10.721668481826782

Epoch 16, Batch 100/111, Loss: 0.567700207233429

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.32104257472265, Training Loss Force: 3.3915438622865364, time: 1.7214128971099854
Validation Loss Energy: 9.334710996640379, Validation Loss Force: 3.9446974813751847, time: 0.12500286102294922
Test Loss Energy: 18.932797297433673, Test Loss Force: 10.728504794319274, time: 11.930376052856445

Epoch 17, Batch 100/111, Loss: 0.1509530395269394

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.402115189083696, Training Loss Force: 3.3596421059062, time: 1.7104823589324951
Validation Loss Energy: 5.190774062210219, Validation Loss Force: 3.213049197663346, time: 0.12600445747375488
Test Loss Energy: 10.367579559619989, Test Loss Force: 9.983794247702544, time: 10.229140520095825

Epoch 18, Batch 100/111, Loss: 0.467692106962204

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.51788250293451, Training Loss Force: 3.3365621480265335, time: 1.640563726425171
Validation Loss Energy: 5.893354892943498, Validation Loss Force: 3.4691915282910206, time: 0.10381340980529785
Test Loss Energy: 9.31584447073571, Test Loss Force: 10.271844865257052, time: 9.471046209335327

Epoch 19, Batch 100/111, Loss: 0.9668892025947571

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.168514478413707, Training Loss Force: 3.4816905271941385, time: 1.6651413440704346
Validation Loss Energy: 3.054351895349455, Validation Loss Force: 4.8328893000869275, time: 0.11088013648986816
Test Loss Energy: 10.78961577950016, Test Loss Force: 11.199021076922081, time: 9.402485847473145

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–â–ƒâ–â–ˆâ–‚â–ƒâ–ƒâ–â–â–„â–â–â–â–ƒâ–„â–â–â–
wandb:   test_error_force â–â–„â–‚â–ˆâ–ƒâ–ˆâ–„â–‚â–ƒâ–â–‚â–„â–…â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–„
wandb:          test_loss â–‚â–ƒâ–â–…â–‚â–ˆâ–‚â–‚â–ƒâ–â–â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–â–‚
wandb: train_error_energy â–‡â–ƒâ–†â–ˆâ–„â–‡â–…â–â–â–â–â–â–‡â–‡â–‚â–â–â–â–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–…â–…â–…â–…â–…â–‚â–â–â–â–â–„â–…â–ƒâ–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–†â–†â–…â–…â–…â–‚â–â–â–â–â–„â–†â–ƒâ–â–â–â–â–‚
wandb: valid_error_energy â–ƒâ–‡â–â–ƒâ–â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–…â–â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:  valid_error_force â–‚â–„â–ƒâ–ˆâ–…â–†â–„â–â–‚â–â–‚â–‚â–†â–„â–ƒâ–â–‚â–â–â–„
wandb:         valid_loss â–‚â–‡â–â–…â–‚â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–†â–‚â–„â–‚â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3546
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.78962
wandb:   test_error_force 11.19902
wandb:          test_loss 4.46928
wandb: train_error_energy 8.16851
wandb:  train_error_force 3.48169
wandb:         train_loss 1.71163
wandb: valid_error_energy 3.05435
wandb:  valid_error_force 4.83289
wandb:         valid_loss 1.8215
wandb: 
wandb: ğŸš€ View run al_74_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/oayh9vne
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_080944-oayh9vne/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.743227243423462, Uncertainty Bias: -0.0018326938152313232
7.6293945e-05 0.0014995933
0.05266645 3.5883176
(48745, 22, 3)
Found uncertainty sample 0 after 100 steps.
Found uncertainty sample 1 after 18 steps.
Found uncertainty sample 2 after 22 steps.
Found uncertainty sample 3 after 205 steps.
Found uncertainty sample 4 after 47 steps.
Found uncertainty sample 5 after 69 steps.
Found uncertainty sample 6 after 56 steps.
Found uncertainty sample 7 after 48 steps.
Found uncertainty sample 8 after 86 steps.
Found uncertainty sample 9 after 26 steps.
Found uncertainty sample 10 after 111 steps.
Found uncertainty sample 11 after 3 steps.
Found uncertainty sample 12 after 26 steps.
Found uncertainty sample 13 after 470 steps.
Found uncertainty sample 14 after 70 steps.
Found uncertainty sample 15 after 22 steps.
Found uncertainty sample 16 after 35 steps.
Found uncertainty sample 17 after 39 steps.
Found uncertainty sample 18 after 26 steps.
Found uncertainty sample 19 after 139 steps.
Found uncertainty sample 20 after 146 steps.
Found uncertainty sample 21 after 43 steps.
Found uncertainty sample 22 after 93 steps.
Found uncertainty sample 23 after 70 steps.
Found uncertainty sample 24 after 4 steps.
Found uncertainty sample 25 after 48 steps.
Found uncertainty sample 26 after 14 steps.
Found uncertainty sample 27 after 29 steps.
Found uncertainty sample 28 after 91 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 7 steps.
Found uncertainty sample 31 after 2 steps.
Found uncertainty sample 32 after 180 steps.
Found uncertainty sample 33 after 48 steps.
Found uncertainty sample 34 after 84 steps.
Found uncertainty sample 35 after 32 steps.
Found uncertainty sample 36 after 80 steps.
Found uncertainty sample 37 after 89 steps.
Found uncertainty sample 38 after 37 steps.
Found uncertainty sample 39 after 61 steps.
Found uncertainty sample 40 after 123 steps.
Found uncertainty sample 41 after 33 steps.
Found uncertainty sample 42 after 5 steps.
Found uncertainty sample 43 after 221 steps.
Found uncertainty sample 44 after 11 steps.
Found uncertainty sample 45 after 443 steps.
Found uncertainty sample 46 after 147 steps.
Found uncertainty sample 47 after 33 steps.
Found uncertainty sample 48 after 81 steps.
Found uncertainty sample 49 after 68 steps.
Found uncertainty sample 50 after 32 steps.
Found uncertainty sample 51 after 14 steps.
Found uncertainty sample 52 after 50 steps.
Found uncertainty sample 53 after 2 steps.
Found uncertainty sample 54 after 122 steps.
Found uncertainty sample 55 after 44 steps.
Found uncertainty sample 56 after 30 steps.
Found uncertainty sample 57 after 81 steps.
Found uncertainty sample 58 after 164 steps.
Found uncertainty sample 59 after 5 steps.
Found uncertainty sample 60 after 79 steps.
Found uncertainty sample 61 after 24 steps.
Found uncertainty sample 62 after 149 steps.
Found uncertainty sample 63 after 38 steps.
Found uncertainty sample 64 after 29 steps.
Found uncertainty sample 65 after 35 steps.
Found uncertainty sample 66 after 9 steps.
Found uncertainty sample 67 after 33 steps.
Found uncertainty sample 68 after 87 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 24 steps.
Found uncertainty sample 72 after 6 steps.
Found uncertainty sample 73 after 14 steps.
Found uncertainty sample 74 after 59 steps.
Found uncertainty sample 75 after 13 steps.
Found uncertainty sample 76 after 28 steps.
Found uncertainty sample 77 after 18 steps.
Found uncertainty sample 78 after 53 steps.
Found uncertainty sample 79 after 59 steps.
Found uncertainty sample 80 after 41 steps.
Found uncertainty sample 81 after 50 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 132 steps.
Found uncertainty sample 84 after 2 steps.
Found uncertainty sample 85 after 41 steps.
Found uncertainty sample 86 after 132 steps.
Found uncertainty sample 87 after 314 steps.
Found uncertainty sample 88 after 94 steps.
Found uncertainty sample 89 after 9 steps.
Found uncertainty sample 90 after 64 steps.
Found uncertainty sample 91 after 27 steps.
Found uncertainty sample 92 after 70 steps.
Found uncertainty sample 93 after 23 steps.
Found uncertainty sample 94 after 33 steps.
Found uncertainty sample 95 after 122 steps.
Found uncertainty sample 96 after 135 steps.
Found uncertainty sample 97 after 109 steps.
Found uncertainty sample 98 after 10 steps.
Found uncertainty sample 99 after 10 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_081911-3rv8xdwd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/3rv8xdwd
Training model 33. Added 100 samples to the dataset.
Epoch 0, Batch 100/114, Loss: 0.1435040980577469

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 14.316531748293759, Training Loss Force: 7.420231552777099, time: 1.679924488067627
Validation Loss Energy: 25.73215418906788, Validation Loss Force: 6.164475954348589, time: 0.11756753921508789
Test Loss Energy: 18.670428084762097, Test Loss Force: 11.197816070779195, time: 10.27155613899231

Epoch 1, Batch 100/114, Loss: 0.39416563510894775

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.88517671029816, Training Loss Force: 6.374206009109468, time: 1.6551928520202637
Validation Loss Energy: 3.3283324368150264, Validation Loss Force: 5.478259524487835, time: 0.12137341499328613
Test Loss Energy: 11.72435107006658, Test Loss Force: 11.25465291820658, time: 10.31068730354309

Epoch 2, Batch 100/114, Loss: 0.11912306398153305

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.565919364976876, Training Loss Force: 5.622058727647231, time: 1.6826708316802979
Validation Loss Energy: 15.60083927570353, Validation Loss Force: 6.876365542950428, time: 0.11898469924926758
Test Loss Energy: 10.727911757601051, Test Loss Force: 11.65470432081991, time: 10.724140167236328

Epoch 3, Batch 100/114, Loss: 0.16825227439403534

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.063090339416512, Training Loss Force: 4.108606831639617, time: 1.629542589187622
Validation Loss Energy: 8.563318868187132, Validation Loss Force: 3.7156817452271143, time: 0.11649036407470703
Test Loss Energy: 16.02198875631899, Test Loss Force: 10.570224719774822, time: 10.388095378875732

Epoch 4, Batch 100/114, Loss: 0.317898690700531

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.287054401159918, Training Loss Force: 3.3822997850009586, time: 1.6491971015930176
Validation Loss Energy: 7.392388373827612, Validation Loss Force: 3.2765533989592703, time: 0.11569476127624512
Test Loss Energy: 9.888093856046149, Test Loss Force: 10.290219154783985, time: 10.495355606079102

Epoch 5, Batch 100/114, Loss: 0.47648298740386963

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.54473666862959, Training Loss Force: 3.3087709738308893, time: 1.6842100620269775
Validation Loss Energy: 9.903106352870266, Validation Loss Force: 3.191699308836546, time: 0.11675858497619629
Test Loss Energy: 19.128005858375445, Test Loss Force: 10.730365520293667, time: 10.318559408187866

Epoch 6, Batch 100/114, Loss: 0.5062628984451294

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.506006230236063, Training Loss Force: 3.414698964140225, time: 1.6865394115447998
Validation Loss Energy: 5.4145050430718875, Validation Loss Force: 3.4309590132660737, time: 0.12561392784118652
Test Loss Energy: 9.20671317049914, Test Loss Force: 10.30882999588716, time: 10.54722285270691

Epoch 7, Batch 100/114, Loss: 0.6004859209060669

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.842673197120281, Training Loss Force: 3.7145080444395013, time: 1.7119598388671875
Validation Loss Energy: 4.1913136548248255, Validation Loss Force: 4.313936662810675, time: 0.12085509300231934
Test Loss Energy: 9.289423337965484, Test Loss Force: 10.913812738916587, time: 11.128635883331299

Epoch 8, Batch 100/114, Loss: 3.1045618057250977

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 15.107082519526735, Training Loss Force: 4.977857424460253, time: 1.6646413803100586
Validation Loss Energy: 31.855366284861905, Validation Loss Force: 10.24505104729012, time: 0.11806273460388184
Test Loss Energy: 26.40774634884444, Test Loss Force: 14.459318290270733, time: 10.425257921218872

Epoch 9, Batch 100/114, Loss: 0.16783320903778076

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 15.488961159541473, Training Loss Force: 7.778781779222138, time: 1.6391620635986328
Validation Loss Energy: 11.234292870676695, Validation Loss Force: 5.945082568449593, time: 0.11657929420471191
Test Loss Energy: 17.222360126032424, Test Loss Force: 11.006427976110306, time: 10.561921834945679

Epoch 10, Batch 100/114, Loss: 0.30754929780960083

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.82491593823636, Training Loss Force: 4.295793774171052, time: 1.6322178840637207
Validation Loss Energy: 7.595154312369694, Validation Loss Force: 4.118678088746597, time: 0.1158757209777832
Test Loss Energy: 14.915456357466553, Test Loss Force: 10.312780808714322, time: 10.39332914352417

Epoch 11, Batch 100/114, Loss: 0.3741001784801483

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.014458458577904, Training Loss Force: 6.024611131393353, time: 1.642435073852539
Validation Loss Energy: 2.798887703605704, Validation Loss Force: 6.076747428221083, time: 0.11824870109558105
Test Loss Energy: 9.942767450570507, Test Loss Force: 11.390183107614925, time: 10.339864015579224

Epoch 12, Batch 100/114, Loss: 0.8900060057640076

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.3680954805717525, Training Loss Force: 4.879320280161981, time: 1.6088552474975586
Validation Loss Energy: 16.18796793562642, Validation Loss Force: 9.80645072379032, time: 0.11901235580444336
Test Loss Energy: 11.364897326348153, Test Loss Force: 14.396690627427864, time: 10.537805795669556

Epoch 13, Batch 100/114, Loss: 1.143288254737854

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.507988510557619, Training Loss Force: 5.917108780373355, time: 1.6448335647583008
Validation Loss Energy: 10.429321938125343, Validation Loss Force: 4.34166520621477, time: 0.11841297149658203
Test Loss Energy: 9.0676501613854, Test Loss Force: 10.395849335940376, time: 10.372889757156372

Epoch 14, Batch 100/114, Loss: 0.39319470524787903

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.358043066512392, Training Loss Force: 4.058350003036662, time: 1.6612117290496826
Validation Loss Energy: 6.011012972759548, Validation Loss Force: 3.174834199277879, time: 0.11806488037109375
Test Loss Energy: 15.809613999050223, Test Loss Force: 10.160232904827684, time: 10.697460889816284

Epoch 15, Batch 100/114, Loss: 0.13735713064670563

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.218463378892561, Training Loss Force: 3.4659446898591035, time: 1.693795919418335
Validation Loss Energy: 6.257439728989051, Validation Loss Force: 3.8891790863288147, time: 0.12675070762634277
Test Loss Energy: 9.314330978058576, Test Loss Force: 10.452247602093545, time: 10.304049730300903

Epoch 16, Batch 100/114, Loss: 0.2957132160663605

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.336242589747374, Training Loss Force: 3.413231681896658, time: 1.6610190868377686
Validation Loss Energy: 9.855974716982217, Validation Loss Force: 3.6805094464977017, time: 0.12018704414367676
Test Loss Energy: 18.34198193593845, Test Loss Force: 11.282185522088714, time: 10.40610933303833

Epoch 17, Batch 100/114, Loss: 0.2707010507583618

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.85876614379492, Training Loss Force: 3.749136370258364, time: 1.556555986404419
Validation Loss Energy: 1.9396185287046184, Validation Loss Force: 3.7236282132608878, time: 0.1680903434753418
Test Loss Energy: 9.887520680016776, Test Loss Force: 10.454998496359774, time: 10.564142942428589

Epoch 18, Batch 100/114, Loss: 0.480915904045105

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.200944209969542, Training Loss Force: 3.3656747948176027, time: 1.6468615531921387
Validation Loss Energy: 6.364857551676075, Validation Loss Force: 3.695875547365984, time: 0.1251201629638672
Test Loss Energy: 13.574186448086877, Test Loss Force: 11.406384118298234, time: 10.290470838546753

Epoch 19, Batch 100/114, Loss: 0.18418751657009125

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.508971878554673, Training Loss Force: 3.309074743376889, time: 1.609555721282959
Validation Loss Energy: 3.8058006246361544, Validation Loss Force: 3.2467655370705857, time: 0.1165156364440918
Test Loss Energy: 9.560349429800079, Test Loss Force: 10.417111366827918, time: 10.619170904159546

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–‚â–„â–â–…â–â–â–ˆâ–„â–ƒâ–â–‚â–â–„â–â–…â–â–ƒâ–
wandb:   test_error_force â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚â–ˆâ–‚â–â–ƒâ–ˆâ–â–â–â–ƒâ–â–ƒâ–
wandb:          test_loss â–„â–‚â–ƒâ–‚â–â–ƒâ–â–‚â–ˆâ–ƒâ–‚â–‚â–…â–â–‚â–â–„â–â–ƒâ–
wandb: train_error_energy â–‡â–…â–…â–â–â–â–â–‚â–ˆâ–ˆâ–‚â–†â–‚â–„â–ƒâ–â–â–‚â–â–
wandb:  train_error_force â–‡â–†â–…â–‚â–â–â–â–‚â–„â–ˆâ–ƒâ–…â–ƒâ–…â–‚â–â–â–‚â–â–
wandb:         train_loss â–‡â–†â–…â–‚â–â–â–â–‚â–…â–ˆâ–‚â–…â–ƒâ–…â–‚â–â–â–‚â–â–
wandb: valid_error_energy â–‡â–â–„â–ƒâ–‚â–ƒâ–‚â–‚â–ˆâ–ƒâ–‚â–â–„â–ƒâ–‚â–‚â–ƒâ–â–‚â–
wandb:  valid_error_force â–„â–ƒâ–…â–‚â–â–â–â–‚â–ˆâ–„â–‚â–„â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–…â–‚â–„â–‚â–â–‚â–â–‚â–ˆâ–ƒâ–‚â–‚â–†â–‚â–â–‚â–‚â–â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3636
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.56035
wandb:   test_error_force 10.41711
wandb:          test_loss 4.12538
wandb: train_error_energy 6.50897
wandb:  train_error_force 3.30907
wandb:         train_loss 1.54281
wandb: valid_error_energy 3.8058
wandb:  valid_error_force 3.24677
wandb:         valid_loss 1.34106
wandb: 
wandb: ğŸš€ View run al_74_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/3rv8xdwd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_081911-3rv8xdwd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3621017932891846, Uncertainty Bias: 0.08109325170516968
9.918213e-05 0.5109081
1.2201923 5.2056217
(48745, 22, 3)
Found uncertainty sample 0 after 24 steps.
Found uncertainty sample 1 after 37 steps.
Found uncertainty sample 2 after 10 steps.
Found uncertainty sample 3 after 40 steps.
Found uncertainty sample 4 after 230 steps.
Found uncertainty sample 5 after 56 steps.
Found uncertainty sample 6 after 15 steps.
Found uncertainty sample 7 after 264 steps.
Found uncertainty sample 8 after 100 steps.
Found uncertainty sample 9 after 266 steps.
Found uncertainty sample 10 after 359 steps.
Found uncertainty sample 11 after 67 steps.
Found uncertainty sample 12 after 15 steps.
Found uncertainty sample 13 after 344 steps.
Found uncertainty sample 14 after 611 steps.
Found uncertainty sample 15 after 50 steps.
Found uncertainty sample 16 after 3 steps.
Found uncertainty sample 17 after 120 steps.
Found uncertainty sample 18 after 141 steps.
Found uncertainty sample 19 after 110 steps.
Found uncertainty sample 20 after 279 steps.
Found uncertainty sample 21 after 127 steps.
Found uncertainty sample 22 after 88 steps.
Found uncertainty sample 23 after 117 steps.
Found uncertainty sample 24 after 30 steps.
Found uncertainty sample 25 after 208 steps.
Found uncertainty sample 26 after 102 steps.
Found uncertainty sample 27 after 249 steps.
Found uncertainty sample 28 after 105 steps.
Found uncertainty sample 29 after 75 steps.
Found uncertainty sample 30 after 158 steps.
Found uncertainty sample 31 after 293 steps.
Found uncertainty sample 32 after 84 steps.
Found uncertainty sample 33 after 134 steps.
Found uncertainty sample 34 after 136 steps.
Found uncertainty sample 35 after 71 steps.
Found uncertainty sample 36 after 114 steps.
Found uncertainty sample 37 after 3 steps.
Found uncertainty sample 38 after 106 steps.
Found uncertainty sample 39 after 14 steps.
Found uncertainty sample 40 after 262 steps.
Found uncertainty sample 41 after 19 steps.
Found uncertainty sample 42 after 60 steps.
Found uncertainty sample 43 after 63 steps.
Found uncertainty sample 44 after 2 steps.
Found uncertainty sample 45 after 88 steps.
Found uncertainty sample 46 after 11 steps.
Found uncertainty sample 47 after 73 steps.
Found uncertainty sample 48 after 20 steps.
Found uncertainty sample 49 after 400 steps.
Found uncertainty sample 50 after 155 steps.
Found uncertainty sample 51 after 451 steps.
Found uncertainty sample 52 after 131 steps.
Found uncertainty sample 53 after 99 steps.
Found uncertainty sample 54 after 21 steps.
Found uncertainty sample 55 after 407 steps.
Found uncertainty sample 56 after 116 steps.
Found uncertainty sample 57 after 57 steps.
Found uncertainty sample 58 after 111 steps.
Found uncertainty sample 59 after 119 steps.
Found uncertainty sample 60 after 141 steps.
Found uncertainty sample 61 after 282 steps.
Found uncertainty sample 62 after 283 steps.
Found uncertainty sample 63 after 256 steps.
Found uncertainty sample 64 after 251 steps.
Found uncertainty sample 65 after 9 steps.
Found uncertainty sample 66 after 255 steps.
Found uncertainty sample 67 after 672 steps.
Found uncertainty sample 68 after 7 steps.
Found uncertainty sample 69 after 225 steps.
Found uncertainty sample 70 after 31 steps.
Found uncertainty sample 71 after 52 steps.
Found uncertainty sample 72 after 396 steps.
Found uncertainty sample 73 after 17 steps.
Found uncertainty sample 74 after 11 steps.
Found uncertainty sample 75 after 155 steps.
Found uncertainty sample 76 after 19 steps.
Found uncertainty sample 77 after 266 steps.
Found uncertainty sample 78 after 52 steps.
Found uncertainty sample 79 after 211 steps.
Found uncertainty sample 80 after 401 steps.
Found uncertainty sample 81 after 50 steps.
Found uncertainty sample 82 after 251 steps.
Found uncertainty sample 83 after 32 steps.
Found uncertainty sample 84 after 404 steps.
Found uncertainty sample 85 after 173 steps.
Found uncertainty sample 86 after 8 steps.
Found uncertainty sample 87 after 9 steps.
Found uncertainty sample 88 after 12 steps.
Found uncertainty sample 89 after 101 steps.
Found uncertainty sample 90 after 662 steps.
Found uncertainty sample 91 after 84 steps.
Found uncertainty sample 92 after 111 steps.
Found uncertainty sample 93 after 236 steps.
Found uncertainty sample 94 after 13 steps.
Found uncertainty sample 95 after 112 steps.
Found uncertainty sample 96 after 317 steps.
Found uncertainty sample 97 after 321 steps.
Found uncertainty sample 98 after 42 steps.
Found uncertainty sample 99 after 97 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241207_083100-zyn6aybk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_74_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/zyn6aybk
Training model 34. Added 100 samples to the dataset.
Epoch 0, Batch 100/117, Loss: 0.45286744832992554

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 13.148148078667674, Training Loss Force: 8.09724773606176, time: 1.7862730026245117
Validation Loss Energy: 4.701602458302175, Validation Loss Force: 4.299910436416488, time: 0.1284503936767578
Test Loss Energy: 14.992049073699048, Test Loss Force: 9.903279266925848, time: 11.348865985870361

Epoch 1, Batch 100/117, Loss: 0.37369412183761597

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.776214257592735, Training Loss Force: 4.554434637973325, time: 1.8816828727722168
Validation Loss Energy: 5.261829271136748, Validation Loss Force: 3.712238463777536, time: 0.1395728588104248
Test Loss Energy: 15.091529100402317, Test Loss Force: 10.000043009842488, time: 11.31261682510376

Epoch 2, Batch 100/117, Loss: 0.11867217719554901

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.2024065452369, Training Loss Force: 3.4124381169067353, time: 2.0339457988739014
Validation Loss Energy: 5.331837192846932, Validation Loss Force: 3.3851052756065045, time: 0.1312713623046875
Test Loss Energy: 9.152922007971059, Test Loss Force: 10.248588105869937, time: 11.363563776016235

Epoch 3, Batch 100/117, Loss: 0.5112951397895813

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.488120843839462, Training Loss Force: 3.3605170370705837, time: 1.7932262420654297
Validation Loss Energy: 3.234595406453805, Validation Loss Force: 3.4103440068438844, time: 0.12787151336669922
Test Loss Energy: 10.10643354900768, Test Loss Force: 10.22683667851063, time: 11.316915512084961

Epoch 4, Batch 100/117, Loss: 0.31675899028778076

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.6133615464985285, Training Loss Force: 3.327693627582686, time: 1.7462284564971924
Validation Loss Energy: 9.565230565976995, Validation Loss Force: 3.579527652804574, time: 0.1273791790008545
Test Loss Energy: 19.598742180063482, Test Loss Force: 10.49891974523778, time: 11.500779151916504

Epoch 5, Batch 100/117, Loss: 0.304124116897583

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 11.445460537643482, Training Loss Force: 6.416103376859849, time: 1.8166532516479492
Validation Loss Energy: 43.03026616890699, Validation Loss Force: 12.20400720374979, time: 0.11594748497009277
Test Loss Energy: 48.086607544897944, Test Loss Force: 17.697163034513824, time: 10.397616624832153

Epoch 6, Batch 100/117, Loss: 0.6846981048583984

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 16.381601472166672, Training Loss Force: 7.318851005320996, time: 1.8625445365905762
Validation Loss Energy: 17.248290500668258, Validation Loss Force: 6.768128743144682, time: 0.13637399673461914
Test Loss Energy: 24.035074051385873, Test Loss Force: 11.780561100350754, time: 12.08703327178955

Epoch 7, Batch 100/117, Loss: 0.8134024739265442

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.190735732302793, Training Loss Force: 5.2789426910499175, time: 1.8270761966705322
Validation Loss Energy: 6.007648738856773, Validation Loss Force: 4.275327465813866, time: 0.12139010429382324
Test Loss Energy: 8.60847073210281, Test Loss Force: 10.464213151837932, time: 9.672788619995117

Epoch 8, Batch 100/117, Loss: 0.6256734728813171

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.829488647065423, Training Loss Force: 5.858394346862396, time: 1.6104967594146729
Validation Loss Energy: 23.108437110972474, Validation Loss Force: 6.055781198332718, time: 0.11774992942810059
Test Loss Energy: 16.006448338540643, Test Loss Force: 11.224636571737811, time: 9.666972398757935

Epoch 9, Batch 100/117, Loss: 0.5596926212310791

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.646798835993106, Training Loss Force: 5.799091883802804, time: 1.67071533203125
Validation Loss Energy: 7.153415986819382, Validation Loss Force: 3.9142456943163926, time: 0.11464762687683105
Test Loss Energy: 8.319383040578892, Test Loss Force: 9.881415255248422, time: 9.888683319091797

Epoch 10, Batch 100/117, Loss: 0.4098660349845886

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.004316685403473, Training Loss Force: 3.519979071825147, time: 1.6673684120178223
Validation Loss Energy: 6.045245681916192, Validation Loss Force: 3.4166553411160616, time: 0.11539626121520996
Test Loss Energy: 15.987425790347299, Test Loss Force: 10.249487707872397, time: 9.671117067337036

Epoch 11, Batch 100/117, Loss: 0.5681875348091125

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.217839580069817, Training Loss Force: 3.3744080385859183, time: 1.7207450866699219
Validation Loss Energy: 4.537330522585408, Validation Loss Force: 3.333293134271054, time: 0.12203526496887207
Test Loss Energy: 15.149562065859655, Test Loss Force: 10.586548718438335, time: 10.557838439941406

Epoch 12, Batch 100/117, Loss: 0.5135706663131714

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.294086070820336, Training Loss Force: 3.336012347043263, time: 1.7280938625335693
Validation Loss Energy: 7.823165439554387, Validation Loss Force: 3.4349143595282374, time: 0.11316227912902832
Test Loss Energy: 9.195145184273834, Test Loss Force: 10.010051836397025, time: 9.702294111251831

Epoch 13, Batch 100/117, Loss: 0.8739333152770996

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.077509740233305, Training Loss Force: 3.420683513511029, time: 1.6723930835723877
Validation Loss Energy: 7.947545900885995, Validation Loss Force: 6.2219275629199045, time: 0.11750674247741699
Test Loss Energy: 8.927529303620673, Test Loss Force: 11.470561903475652, time: 9.75972867012024

Epoch 14, Batch 100/117, Loss: 0.1501549780368805

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 13.673501449023465, Training Loss Force: 6.868273887020889, time: 1.6698698997497559
Validation Loss Energy: 2.661569571111302, Validation Loss Force: 5.740678972562262, time: 0.11204195022583008
Test Loss Energy: 9.718197120500575, Test Loss Force: 10.873863972887126, time: 9.95731234550476

Epoch 15, Batch 100/117, Loss: 0.22492362558841705

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.331309208162974, Training Loss Force: 6.3804683830641284, time: 1.780329942703247
Validation Loss Energy: 9.063806963429519, Validation Loss Force: 5.440424770780563, time: 0.11154961585998535
Test Loss Energy: 8.592592220954456, Test Loss Force: 11.214734668342377, time: 11.084020853042603

Epoch 16, Batch 100/117, Loss: 0.269267201423645

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.960465095470472, Training Loss Force: 5.442365145878126, time: 1.7858552932739258
Validation Loss Energy: 6.625610246970186, Validation Loss Force: 5.226812469694242, time: 0.13465213775634766
Test Loss Energy: 12.958236062828934, Test Loss Force: 10.890930777168544, time: 11.976920127868652

Epoch 17, Batch 100/117, Loss: 0.42279940843582153

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 5.936584164504027, Training Loss Force: 3.8416642463564004, time: 1.7121028900146484
Validation Loss Energy: 7.676633406247589, Validation Loss Force: 3.7095021568662783, time: 0.13721394538879395
Test Loss Energy: 8.594240159163448, Test Loss Force: 10.193757500452524, time: 10.781418085098267

Epoch 18, Batch 100/117, Loss: 0.3128185272216797

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.182346831892087, Training Loss Force: 3.3222695004424843, time: 1.6460695266723633
Validation Loss Energy: 9.776642153671064, Validation Loss Force: 3.15456254867871, time: 0.12619519233703613
Test Loss Energy: 9.207550826178366, Test Loss Force: 10.075587534969573, time: 10.378303289413452

Epoch 19, Batch 100/117, Loss: 0.3023136258125305

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.200766105478902, Training Loss Force: 3.266684987885015, time: 1.625429630279541
Validation Loss Energy: 7.711806521430538, Validation Loss Force: 3.90665623914659, time: 0.12563180923461914
Test Loss Energy: 15.934377391468066, Test Loss Force: 10.71400237849275, time: 10.558082818984985

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–â–ƒâ–ˆâ–„â–â–‚â–â–‚â–‚â–â–â–â–â–‚â–â–â–‚
wandb:   test_error_force â–â–â–â–â–‚â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚
wandb:          test_loss â–‚â–‚â–â–â–‚â–ˆâ–ƒâ–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚
wandb: train_error_energy â–†â–‚â–â–â–â–…â–ˆâ–ƒâ–†â–ƒâ–â–â–â–‚â–†â–„â–„â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–†â–‡â–„â–…â–…â–â–â–â–â–†â–†â–„â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–†â–ˆâ–„â–†â–…â–â–â–â–â–‡â–…â–…â–‚â–â–
wandb: valid_error_energy â–â–â–â–â–‚â–ˆâ–„â–‚â–…â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:  valid_error_force â–‚â–â–â–â–â–ˆâ–„â–‚â–ƒâ–‚â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚
wandb:         valid_loss â–â–â–â–â–‚â–ˆâ–„â–‚â–„â–‚â–â–â–â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3726
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 15.93438
wandb:   test_error_force 10.714
wandb:          test_loss 4.65128
wandb: train_error_energy 6.20077
wandb:  train_error_force 3.26668
wandb:         train_loss 1.508
wandb: valid_error_energy 7.71181
wandb:  valid_error_force 3.90666
wandb:         valid_loss 1.82326
wandb: 
wandb: ğŸš€ View run al_74_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG/runs/zyn6aybk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-SWAG
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241207_083100-zyn6aybk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.9731647968292236, Uncertainty Bias: 0.10431799292564392
0.0 0.014670372
1.8111067 4.673585
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2164 steps.
Found uncertainty sample 2 after 1908 steps.
Found uncertainty sample 3 after 274 steps.
Found uncertainty sample 4 after 1048 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3610 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 717 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1923 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1132 steps.
slurmstepd: error: *** JOB 5124862 ON aimat01 CANCELLED AT 2024-12-07T08:54:02 ***
