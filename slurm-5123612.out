wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_142511-bxif8j87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/bxif8j87
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
58
Uncertainty Slope: 5.450389862060547, Uncertainty Bias: -0.39420199394226074
0.00034332275 0.002117157
1.6673805 2.2779713
(48745, 22, 3)
(48745,)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.996635103653107, Test Loss Force: 13.386480424404732, time: 6.235400915145874

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.044 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: / 0.044 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: - 0.056 MB of 0.056 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 5.4%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 3
wandb:  test_error_energy 10.99664
wandb:   test_error_force 13.38648
wandb:          test_loss 16.63181
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_59 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/bxif8j87
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_142511-bxif8j87/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 2275 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 216 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 457 steps.
Found uncertainty sample 9 after 765 steps.
Found uncertainty sample 10 after 3250 steps.
Found uncertainty sample 11 after 3011 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2303 steps.
Found uncertainty sample 14 after 2863 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1422 steps.
Found uncertainty sample 21 after 1486 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 609 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 465 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 376 steps.
Found uncertainty sample 29 after 772 steps.
Found uncertainty sample 30 after 670 steps.
Found uncertainty sample 31 after 539 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 952 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2242 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 418 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1506 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 343 steps.
Found uncertainty sample 43 after 1408 steps.
Found uncertainty sample 44 after 1205 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 579 steps.
Found uncertainty sample 47 after 759 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2589 steps.
Found uncertainty sample 51 after 1560 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 788 steps.
Found uncertainty sample 55 after 133 steps.
Found uncertainty sample 56 after 1729 steps.
Found uncertainty sample 57 after 862 steps.
Found uncertainty sample 58 after 1502 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3038 steps.
Found uncertainty sample 63 after 2125 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1180 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 145 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1592 steps.
Found uncertainty sample 71 after 3663 steps.
Found uncertainty sample 72 after 1308 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1560 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1269 steps.
Found uncertainty sample 82 after 325 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 86 steps.
Found uncertainty sample 86 after 547 steps.
Found uncertainty sample 87 after 2732 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3423 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 456 steps.
Found uncertainty sample 93 after 2230 steps.
Found uncertainty sample 94 after 2726 steps.
Found uncertainty sample 95 after 1364 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 373 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_145218-ehwzd77m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ehwzd77m
Training model 0. Added 51 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.158469537264953, Training Loss Force: 2.4389839343602424, time: 0.478104829788208
Validation Loss Energy: 2.3404958784084036, Validation Loss Force: 2.3499290341064882, time: 0.039447784423828125
Test Loss Energy: 11.123128684298704, Test Loss Force: 13.212284444285093, time: 8.513832807540894


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.666803406622563, Training Loss Force: 1.7999890698579724, time: 0.3961765766143799
Validation Loss Energy: 1.1413054036165078, Validation Loss Force: 2.2338787739701353, time: 0.0307462215423584
Test Loss Energy: 11.461322243767958, Test Loss Force: 13.036446382971068, time: 6.743255615234375


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6361646125309643, Training Loss Force: 1.7302597855958963, time: 0.402982234954834
Validation Loss Energy: 2.4216258270654847, Validation Loss Force: 2.2287912293239773, time: 0.03007674217224121
Test Loss Energy: 11.140789467270434, Test Loss Force: 12.868470706246171, time: 6.493224382400513


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2563780286824107, Training Loss Force: 1.6906560244882938, time: 0.4150872230529785
Validation Loss Energy: 1.848274486543159, Validation Loss Force: 2.246637270693506, time: 0.029697656631469727
Test Loss Energy: 11.120161523498847, Test Loss Force: 12.703520909690464, time: 6.583997488021851


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2272950136046523, Training Loss Force: 1.7207652639305948, time: 0.4200305938720703
Validation Loss Energy: 1.3036416764477237, Validation Loss Force: 2.2425969390406464, time: 0.030242204666137695
Test Loss Energy: 12.309364559632284, Test Loss Force: 12.856154085367724, time: 6.455463409423828


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.1638865868442447, Training Loss Force: 1.7394943162923109, time: 0.3983302116394043
Validation Loss Energy: 1.065492571495036, Validation Loss Force: 2.3226665372248196, time: 0.033380985260009766
Test Loss Energy: 11.447472521337852, Test Loss Force: 12.994273644144364, time: 6.563029527664185


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.353798210830661, Training Loss Force: 1.6809921134554815, time: 0.39088010787963867
Validation Loss Energy: 1.0308254348346848, Validation Loss Force: 2.2105334727036285, time: 0.031996965408325195
Test Loss Energy: 11.69490147836198, Test Loss Force: 12.800725462904387, time: 6.505043983459473


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2386894566649556, Training Loss Force: 1.6770077336107905, time: 0.38794374465942383
Validation Loss Energy: 1.5082776275888308, Validation Loss Force: 2.244324851613046, time: 0.031030654907226562
Test Loss Energy: 11.078681866287887, Test Loss Force: 12.853448471047189, time: 6.742794752120972


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.0583464547182782, Training Loss Force: 1.6928744029661233, time: 0.4156522750854492
Validation Loss Energy: 1.8918667592451608, Validation Loss Force: 2.2663601902940598, time: 0.033158302307128906
Test Loss Energy: 11.196617369320826, Test Loss Force: 12.676440331169399, time: 6.424734115600586


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1977612728787579, Training Loss Force: 1.7064056193549006, time: 0.40120816230773926
Validation Loss Energy: 1.0509001716858044, Validation Loss Force: 2.2222256068871507, time: 0.030088186264038086
Test Loss Energy: 12.153866762879765, Test Loss Force: 12.560932570015792, time: 6.50952935218811


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.0446215470988138, Training Loss Force: 1.672015829486311, time: 0.40035104751586914
Validation Loss Energy: 2.084230189073885, Validation Loss Force: 2.2462317901787716, time: 0.03052544593811035
Test Loss Energy: 11.3501717284206, Test Loss Force: 12.767773348487921, time: 6.463183164596558


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5484098774202824, Training Loss Force: 1.7420305013704178, time: 0.4061472415924072
Validation Loss Energy: 3.5763684229621506, Validation Loss Force: 2.3106896092036555, time: 0.03269481658935547
Test Loss Energy: 10.88600049522976, Test Loss Force: 12.608367747861806, time: 6.48827862739563


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4231825311036619, Training Loss Force: 1.694327640776513, time: 0.4050025939941406
Validation Loss Energy: 1.2536092553726255, Validation Loss Force: 2.201490433349209, time: 0.036803245544433594
Test Loss Energy: 11.50346674208476, Test Loss Force: 12.677710920953505, time: 7.0508363246917725


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.796190419462269, Training Loss Force: 1.6662044946578118, time: 0.4049093723297119
Validation Loss Energy: 1.4789997522673697, Validation Loss Force: 2.231913050749885, time: 0.03200650215148926
Test Loss Energy: 12.151339456415412, Test Loss Force: 12.700705154583375, time: 6.500452041625977


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.243734408620825, Training Loss Force: 1.665207971883233, time: 0.4119296073913574
Validation Loss Energy: 1.8160596051869105, Validation Loss Force: 2.2778441288261395, time: 0.032720327377319336
Test Loss Energy: 11.167048189129368, Test Loss Force: 12.586118404312836, time: 6.574718713760376


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.26864862225728, Training Loss Force: 1.6692949568456679, time: 0.42176055908203125
Validation Loss Energy: 1.5510191928188155, Validation Loss Force: 2.195916579288345, time: 0.03183102607727051
Test Loss Energy: 12.1609508406948, Test Loss Force: 12.552768931559331, time: 6.6205222606658936


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.1713855909205195, Training Loss Force: 1.6455147579961475, time: 0.3705010414123535
Validation Loss Energy: 1.0714726854126457, Validation Loss Force: 2.2239679929540355, time: 0.03236985206604004
Test Loss Energy: 11.757817426634594, Test Loss Force: 12.605056953776852, time: 6.666841983795166


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6283335489673219, Training Loss Force: 1.6777770183984468, time: 0.40988850593566895
Validation Loss Energy: 2.1221739022165638, Validation Loss Force: 2.216374529739606, time: 0.0329442024230957
Test Loss Energy: 11.29220796060633, Test Loss Force: 12.614786182495754, time: 7.853215456008911


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5504078938519466, Training Loss Force: 1.684100648955682, time: 0.43069887161254883
Validation Loss Energy: 3.0020013771306755, Validation Loss Force: 2.248150975547523, time: 0.041239261627197266
Test Loss Energy: 13.537273135834075, Test Loss Force: 12.706859543247692, time: 8.438251972198486


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3871428040987739, Training Loss Force: 1.65008568960624, time: 0.4169642925262451
Validation Loss Energy: 1.0057938601260665, Validation Loss Force: 2.2027603154884354, time: 0.03972625732421875
Test Loss Energy: 11.934480678818902, Test Loss Force: 12.530804515915811, time: 7.657163381576538

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–‚â–…â–‚â–ƒâ–‚â–‚â–„â–‚â–â–ƒâ–„â–‚â–„â–ƒâ–‚â–ˆâ–„
wandb:   test_error_force â–ˆâ–†â–„â–ƒâ–„â–†â–„â–„â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–
wandb:          test_loss â–ˆâ–†â–…â–„â–„â–„â–ƒâ–ƒâ–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–‚â–â–â–â–â–‚â–‚â–…â–â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–…â–â–…â–ƒâ–‚â–â–â–‚â–ƒâ–â–„â–ˆâ–‚â–‚â–ƒâ–‚â–â–„â–†â–
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‡â–‚â–ƒâ–„â–‚â–ƒâ–†â–â–ƒâ–…â–â–‚â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–„â–„â–ƒâ–…â–‚â–ƒâ–„â–‚â–ƒâ–†â–â–‚â–„â–â–‚â–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 845
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.93448
wandb:   test_error_force 12.5308
wandb:          test_loss 12.74483
wandb: train_error_energy 1.38714
wandb:  train_error_force 1.65009
wandb:         train_loss -2.91565
wandb: valid_error_energy 1.00579
wandb:  valid_error_force 2.20276
wandb:         valid_loss -2.10733
wandb: 
wandb: ğŸš€ View run al_59_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ehwzd77m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_145218-ehwzd77m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.062152862548828, Uncertainty Bias: -1.7496920824050903
7.8201294e-05 0.00035133958
0.34610265 8.46979
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 276 steps.
Found uncertainty sample 1 after 391 steps.
Found uncertainty sample 2 after 21 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 10 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 96 steps.
Found uncertainty sample 7 after 401 steps.
Found uncertainty sample 8 after 261 steps.
Found uncertainty sample 9 after 69 steps.
Found uncertainty sample 10 after 181 steps.
Found uncertainty sample 11 after 33 steps.
Found uncertainty sample 12 after 86 steps.
Found uncertainty sample 13 after 1132 steps.
Found uncertainty sample 14 after 134 steps.
Found uncertainty sample 15 after 32 steps.
Found uncertainty sample 16 after 145 steps.
Found uncertainty sample 17 after 101 steps.
Found uncertainty sample 18 after 112 steps.
Found uncertainty sample 19 after 7 steps.
Found uncertainty sample 20 after 182 steps.
Found uncertainty sample 21 after 20 steps.
Found uncertainty sample 22 after 47 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 316 steps.
Found uncertainty sample 25 after 171 steps.
Found uncertainty sample 26 after 22 steps.
Found uncertainty sample 27 after 12 steps.
Found uncertainty sample 28 after 224 steps.
Found uncertainty sample 29 after 72 steps.
Found uncertainty sample 30 after 8 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 600 steps.
Found uncertainty sample 33 after 39 steps.
Found uncertainty sample 34 after 6 steps.
Found uncertainty sample 35 after 38 steps.
Found uncertainty sample 36 after 53 steps.
Found uncertainty sample 37 after 71 steps.
Found uncertainty sample 38 after 143 steps.
Found uncertainty sample 39 after 146 steps.
Found uncertainty sample 40 after 52 steps.
Found uncertainty sample 41 after 91 steps.
Found uncertainty sample 42 after 128 steps.
Found uncertainty sample 43 after 53 steps.
Found uncertainty sample 44 after 13 steps.
Found uncertainty sample 45 after 89 steps.
Found uncertainty sample 46 after 56 steps.
Found uncertainty sample 47 after 29 steps.
Found uncertainty sample 48 after 95 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 124 steps.
Found uncertainty sample 51 after 198 steps.
Found uncertainty sample 52 after 71 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 39 steps.
Found uncertainty sample 56 after 187 steps.
Found uncertainty sample 57 after 108 steps.
Found uncertainty sample 58 after 269 steps.
Found uncertainty sample 59 after 97 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 40 steps.
Found uncertainty sample 62 after 29 steps.
Found uncertainty sample 63 after 39 steps.
Found uncertainty sample 64 after 92 steps.
Found uncertainty sample 65 after 109 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 381 steps.
Found uncertainty sample 68 after 77 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 14 steps.
Found uncertainty sample 71 after 73 steps.
Found uncertainty sample 72 after 310 steps.
Found uncertainty sample 73 after 16 steps.
Found uncertainty sample 74 after 22 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 154 steps.
Found uncertainty sample 77 after 13 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 49 steps.
Found uncertainty sample 80 after 3 steps.
Found uncertainty sample 81 after 72 steps.
Found uncertainty sample 82 after 38 steps.
Found uncertainty sample 83 after 49 steps.
Found uncertainty sample 84 after 43 steps.
Found uncertainty sample 85 after 70 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 88 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 75 steps.
Found uncertainty sample 90 after 3 steps.
Found uncertainty sample 91 after 21 steps.
Found uncertainty sample 92 after 313 steps.
Found uncertainty sample 93 after 65 steps.
Found uncertainty sample 94 after 83 steps.
Found uncertainty sample 95 after 20 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 25 steps.
Found uncertainty sample 98 after 15 steps.
Found uncertainty sample 99 after 36 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_145816-op6or3ng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/op6or3ng
Training model 1. Added 112 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.09632457626739, Training Loss Force: 2.2547797692210505, time: 0.44356298446655273
Validation Loss Energy: 2.414708610047238, Validation Loss Force: 2.2258531099434604, time: 0.037442684173583984
Test Loss Energy: 11.263757931863605, Test Loss Force: 12.87136957873246, time: 7.5180675983428955


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6032704970884744, Training Loss Force: 1.785531913927423, time: 0.4543116092681885
Validation Loss Energy: 1.5392423330252678, Validation Loss Force: 2.192590792924767, time: 0.03957104682922363
Test Loss Energy: 11.367857790752332, Test Loss Force: 12.46254318844735, time: 7.5002570152282715


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.1306057355056052, Training Loss Force: 1.7390035778233517, time: 0.45063304901123047
Validation Loss Energy: 1.8073306406628222, Validation Loss Force: 2.1991085414952196, time: 0.03603529930114746
Test Loss Energy: 12.467493806724253, Test Loss Force: 12.506425573981645, time: 7.53351092338562


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.147734095662046, Training Loss Force: 1.7226990229949473, time: 0.44643735885620117
Validation Loss Energy: 1.385326739285603, Validation Loss Force: 2.185419510411017, time: 0.03724503517150879
Test Loss Energy: 11.352036334200845, Test Loss Force: 12.641508676387566, time: 7.753612756729126


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.0604389542044126, Training Loss Force: 1.7323208833719015, time: 0.44348740577697754
Validation Loss Energy: 1.1898316905885507, Validation Loss Force: 2.2011599923366525, time: 0.03813576698303223
Test Loss Energy: 11.95122430273405, Test Loss Force: 12.37171015312858, time: 7.545669078826904


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.1186069432298875, Training Loss Force: 1.7443728137837184, time: 0.44508910179138184
Validation Loss Energy: 2.561210879911529, Validation Loss Force: 2.3308692232225074, time: 0.04329872131347656
Test Loss Energy: 11.106701992024059, Test Loss Force: 12.410161509954921, time: 7.531421184539795


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.1671371306231364, Training Loss Force: 1.7270127849367016, time: 0.4414184093475342
Validation Loss Energy: 1.5425116727603527, Validation Loss Force: 2.17970470678078, time: 0.03841400146484375
Test Loss Energy: 12.22256461047558, Test Loss Force: 12.608009737844212, time: 7.5367209911346436


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2805644651217614, Training Loss Force: 1.7130874091098585, time: 0.4365520477294922
Validation Loss Energy: 1.4066463079970322, Validation Loss Force: 2.1782526812801852, time: 0.03762173652648926
Test Loss Energy: 12.05116588643681, Test Loss Force: 12.492263452568839, time: 7.755529165267944


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2242534718281566, Training Loss Force: 1.677991148182628, time: 0.4728047847747803
Validation Loss Energy: 0.974328037776719, Validation Loss Force: 2.251684734893397, time: 0.03775382041931152
Test Loss Energy: 11.628460451342756, Test Loss Force: 12.586124298633267, time: 7.891258716583252


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1822270623720292, Training Loss Force: 1.6816140494099217, time: 0.426267147064209
Validation Loss Energy: 1.1023018966737856, Validation Loss Force: 2.1508178384795684, time: 0.0372776985168457
Test Loss Energy: 11.770595403993717, Test Loss Force: 12.48345536996662, time: 7.538065671920776


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.134072254336138, Training Loss Force: 1.6500487496196308, time: 0.45807385444641113
Validation Loss Energy: 2.5630592564918757, Validation Loss Force: 2.1697095341583736, time: 0.0376434326171875
Test Loss Energy: 11.022300294491629, Test Loss Force: 12.426060320135576, time: 7.7561938762664795


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.2150286750722212, Training Loss Force: 1.6800575289902953, time: 0.5176291465759277
Validation Loss Energy: 0.974777940786066, Validation Loss Force: 2.207522317843247, time: 0.04287528991699219
Test Loss Energy: 11.517732573692443, Test Loss Force: 12.56588084735215, time: 7.567763805389404


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0829121139091753, Training Loss Force: 1.7243394859714363, time: 0.4322779178619385
Validation Loss Energy: 0.9865002466388615, Validation Loss Force: 2.2257818558167632, time: 0.03885984420776367
Test Loss Energy: 11.649033751406447, Test Loss Force: 12.52231812144684, time: 7.609026908874512


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.660288815624305, Training Loss Force: 1.7679140342094226, time: 0.4451887607574463
Validation Loss Energy: 3.4186525349089365, Validation Loss Force: 2.316630199347863, time: 0.04057621955871582
Test Loss Energy: 10.881246432020937, Test Loss Force: 12.549721008310499, time: 7.549659490585327


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5308317278569938, Training Loss Force: 1.6987737688044142, time: 0.4308657646179199
Validation Loss Energy: 1.6200204644317833, Validation Loss Force: 2.1878815631575406, time: 0.03676724433898926
Test Loss Energy: 12.401257840501328, Test Loss Force: 12.523908147024983, time: 7.7870378494262695


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.1926842103826445, Training Loss Force: 1.690551962949396, time: 0.46242761611938477
Validation Loss Energy: 2.8657893165071453, Validation Loss Force: 2.2865179827366107, time: 0.03743147850036621
Test Loss Energy: 10.896429893671252, Test Loss Force: 12.803983128830609, time: 7.582693576812744


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7780981861359777, Training Loss Force: 1.7267264546819532, time: 0.4316692352294922
Validation Loss Energy: 1.5148014995607961, Validation Loss Force: 2.1961539445979037, time: 0.038666486740112305
Test Loss Energy: 12.522778545281883, Test Loss Force: 12.581612662668197, time: 7.6410510540008545


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8113998525039086, Training Loss Force: 1.7186228712988127, time: 0.4424777030944824
Validation Loss Energy: 1.5884394107994182, Validation Loss Force: 2.225541818477453, time: 0.03812408447265625
Test Loss Energy: 11.525470021071984, Test Loss Force: 12.592640078155616, time: 7.611482381820679


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6570133153761828, Training Loss Force: 1.719371562901623, time: 0.4488508701324463
Validation Loss Energy: 2.01559264751079, Validation Loss Force: 2.212181224383494, time: 0.03997659683227539
Test Loss Energy: 12.641287145069315, Test Loss Force: 12.63262293238312, time: 8.106772661209106


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6897894918376055, Training Loss Force: 1.7122926472607558, time: 0.4448213577270508
Validation Loss Energy: 2.5744254030457596, Validation Loss Force: 2.233990776550537, time: 0.037969112396240234
Test Loss Energy: 13.36658716290754, Test Loss Force: 12.634060349155613, time: 7.548441171646118

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–…â–‚â–„â–‚â–…â–„â–ƒâ–„â–â–ƒâ–ƒâ–â–…â–â–†â–ƒâ–†â–ˆ
wandb:   test_error_force â–ˆâ–‚â–ƒâ–…â–â–‚â–„â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–‡â–„â–„â–…â–…
wandb:          test_loss â–„â–â–ƒâ–„â–ƒâ–ƒâ–…â–…â–†â–†â–†â–‡â–‡â–…â–†â–ˆâ–‡â–†â–‡â–‡
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–‚â–â–â–â–â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–…â–ƒâ–ƒâ–‚â–‚â–†â–ƒâ–‚â–â–â–†â–â–â–ˆâ–ƒâ–†â–ƒâ–ƒâ–„â–†
wandb:  valid_error_force â–„â–ƒâ–ƒâ–‚â–ƒâ–ˆâ–‚â–‚â–…â–â–‚â–ƒâ–„â–‡â–‚â–†â–ƒâ–„â–ƒâ–„
wandb:         valid_loss â–„â–‚â–ƒâ–‚â–‚â–‡â–‚â–‚â–ƒâ–â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 945
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.36659
wandb:   test_error_force 12.63406
wandb:          test_loss 12.88631
wandb: train_error_energy 1.68979
wandb:  train_error_force 1.71229
wandb:         train_loss -2.8025
wandb: valid_error_energy 2.57443
wandb:  valid_error_force 2.23399
wandb:         valid_loss -1.981
wandb: 
wandb: ğŸš€ View run al_59_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/op6or3ng
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_145816-op6or3ng/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 16.72792625427246, Uncertainty Bias: -1.7685227394104004
9.1552734e-05 0.03167963
0.481628 7.708325
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 84 steps.
Found uncertainty sample 1 after 21 steps.
Found uncertainty sample 2 after 14 steps.
Found uncertainty sample 3 after 27 steps.
Found uncertainty sample 4 after 114 steps.
Found uncertainty sample 5 after 158 steps.
Found uncertainty sample 6 after 36 steps.
Found uncertainty sample 7 after 9 steps.
Found uncertainty sample 8 after 94 steps.
Found uncertainty sample 9 after 388 steps.
Found uncertainty sample 10 after 37 steps.
Found uncertainty sample 11 after 10 steps.
Found uncertainty sample 12 after 23 steps.
Found uncertainty sample 13 after 35 steps.
Found uncertainty sample 14 after 195 steps.
Found uncertainty sample 15 after 68 steps.
Found uncertainty sample 16 after 19 steps.
Found uncertainty sample 17 after 117 steps.
Found uncertainty sample 18 after 107 steps.
Found uncertainty sample 19 after 305 steps.
Found uncertainty sample 20 after 90 steps.
Found uncertainty sample 21 after 13 steps.
Found uncertainty sample 22 after 7 steps.
Found uncertainty sample 23 after 21 steps.
Found uncertainty sample 24 after 113 steps.
Found uncertainty sample 25 after 201 steps.
Found uncertainty sample 26 after 79 steps.
Found uncertainty sample 27 after 4 steps.
Found uncertainty sample 28 after 55 steps.
Found uncertainty sample 29 after 26 steps.
Found uncertainty sample 30 after 115 steps.
Found uncertainty sample 31 after 133 steps.
Found uncertainty sample 32 after 17 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 126 steps.
Found uncertainty sample 35 after 71 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 6 steps.
Found uncertainty sample 38 after 96 steps.
Found uncertainty sample 39 after 163 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 94 steps.
Found uncertainty sample 42 after 104 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 106 steps.
Found uncertainty sample 45 after 631 steps.
Found uncertainty sample 46 after 344 steps.
Found uncertainty sample 47 after 153 steps.
Found uncertainty sample 48 after 71 steps.
Found uncertainty sample 49 after 86 steps.
Found uncertainty sample 50 after 10 steps.
Found uncertainty sample 51 after 103 steps.
Found uncertainty sample 52 after 76 steps.
Found uncertainty sample 53 after 116 steps.
Found uncertainty sample 54 after 287 steps.
Found uncertainty sample 55 after 114 steps.
Found uncertainty sample 56 after 77 steps.
Found uncertainty sample 57 after 28 steps.
Found uncertainty sample 58 after 12 steps.
Found uncertainty sample 59 after 141 steps.
Found uncertainty sample 60 after 45 steps.
Found uncertainty sample 61 after 188 steps.
Found uncertainty sample 62 after 59 steps.
Found uncertainty sample 63 after 9 steps.
Found uncertainty sample 64 after 38 steps.
Found uncertainty sample 65 after 75 steps.
Found uncertainty sample 66 after 188 steps.
Found uncertainty sample 67 after 195 steps.
Found uncertainty sample 68 after 113 steps.
Found uncertainty sample 69 after 124 steps.
Found uncertainty sample 70 after 38 steps.
Found uncertainty sample 71 after 2 steps.
Found uncertainty sample 72 after 15 steps.
Found uncertainty sample 73 after 157 steps.
Found uncertainty sample 74 after 85 steps.
Found uncertainty sample 75 after 79 steps.
Found uncertainty sample 76 after 40 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 345 steps.
Found uncertainty sample 79 after 29 steps.
Found uncertainty sample 80 after 58 steps.
Found uncertainty sample 81 after 163 steps.
Found uncertainty sample 82 after 23 steps.
Found uncertainty sample 83 after 191 steps.
Found uncertainty sample 84 after 5 steps.
Found uncertainty sample 85 after 16 steps.
Found uncertainty sample 86 after 149 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 132 steps.
Found uncertainty sample 90 after 105 steps.
Found uncertainty sample 91 after 13 steps.
Found uncertainty sample 92 after 132 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 36 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 23 steps.
Found uncertainty sample 97 after 242 steps.
Found uncertainty sample 98 after 40 steps.
Found uncertainty sample 99 after 64 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_150425-f2qwa0t4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/f2qwa0t4
Training model 2. Added 109 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7471728034130005, Training Loss Force: 2.314812186741961, time: 0.5048828125
Validation Loss Energy: 3.0179333545218086, Validation Loss Force: 2.2480661386029244, time: 0.04686307907104492
Test Loss Energy: 11.178898072161806, Test Loss Force: 12.493945670168234, time: 7.785033226013184


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5608129055314441, Training Loss Force: 1.7644066453005987, time: 0.4927635192871094
Validation Loss Energy: 0.9372566310132123, Validation Loss Force: 2.1669664729496896, time: 0.040906667709350586
Test Loss Energy: 11.815185462384752, Test Loss Force: 12.510374400273598, time: 7.774883031845093


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.245345463563255, Training Loss Force: 1.7033235020119228, time: 0.522813081741333
Validation Loss Energy: 1.2883132437766278, Validation Loss Force: 2.182323963944329, time: 0.04792356491088867
Test Loss Energy: 11.510582408607535, Test Loss Force: 12.607775014253416, time: 7.7978270053863525


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2019362350205307, Training Loss Force: 1.726270124293971, time: 0.4698665142059326
Validation Loss Energy: 1.8002673526848467, Validation Loss Force: 2.1710920868854395, time: 0.04114341735839844
Test Loss Energy: 11.231284306628172, Test Loss Force: 12.460250283811048, time: 8.06793999671936


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7992148749157575, Training Loss Force: 1.7139692598983312, time: 0.48139452934265137
Validation Loss Energy: 3.2707153850682866, Validation Loss Force: 2.210669968890082, time: 0.040848731994628906
Test Loss Energy: 13.651103561788199, Test Loss Force: 12.465118745333749, time: 7.807694435119629


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.331180873480957, Training Loss Force: 1.7319376613373223, time: 0.4867880344390869
Validation Loss Energy: 0.9430187518369587, Validation Loss Force: 2.1741444355378174, time: 0.041457414627075195
Test Loss Energy: 11.72985855240066, Test Loss Force: 12.415355129052648, time: 8.138543844223022


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.1370580031530348, Training Loss Force: 1.712083812278963, time: 0.5229146480560303
Validation Loss Energy: 1.282095764549459, Validation Loss Force: 2.1479282609728636, time: 0.04299569129943848
Test Loss Energy: 12.207327596312764, Test Loss Force: 12.493528642334702, time: 7.9783642292022705


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2966341670908035, Training Loss Force: 1.7266872848175419, time: 0.4707062244415283
Validation Loss Energy: 0.9699100592523657, Validation Loss Force: 2.173450375809961, time: 0.041242361068725586
Test Loss Energy: 11.875363335605423, Test Loss Force: 12.541144795403424, time: 7.7933478355407715


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.1856465160300398, Training Loss Force: 1.70629334162441, time: 0.48598527908325195
Validation Loss Energy: 1.3495110751705561, Validation Loss Force: 2.168691268154046, time: 0.041441917419433594
Test Loss Energy: 11.584539603502375, Test Loss Force: 12.626420554437532, time: 7.820529937744141


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.0120104672324135, Training Loss Force: 1.7269762452672324, time: 0.48258066177368164
Validation Loss Energy: 1.1213009188809284, Validation Loss Force: 2.2315857271053714, time: 0.041931867599487305
Test Loss Energy: 11.927798142256588, Test Loss Force: 12.519822552913531, time: 7.8174285888671875


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7075416619680053, Training Loss Force: 1.7716482777693623, time: 0.4967386722564697
Validation Loss Energy: 2.013474173256433, Validation Loss Force: 2.2254821431463445, time: 0.04235386848449707
Test Loss Energy: 11.328247411876259, Test Loss Force: 12.529049514650874, time: 8.041995525360107


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.1923493903789064, Training Loss Force: 1.6982592026750896, time: 0.4901556968688965
Validation Loss Energy: 1.983909500075017, Validation Loss Force: 2.1443423970468425, time: 0.040076494216918945
Test Loss Energy: 11.354560688841753, Test Loss Force: 12.362139115099462, time: 7.83581280708313


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2893435474099355, Training Loss Force: 1.7403089989704006, time: 0.4727132320404053
Validation Loss Energy: 1.0683186882951516, Validation Loss Force: 2.195475694379408, time: 0.04154181480407715
Test Loss Energy: 12.228988939429955, Test Loss Force: 12.63489123382751, time: 7.835656642913818


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5346256121668496, Training Loss Force: 1.7691590526394858, time: 0.4900376796722412
Validation Loss Energy: 1.609932216106379, Validation Loss Force: 2.2047794793037085, time: 0.04372906684875488
Test Loss Energy: 11.281098281110468, Test Loss Force: 12.459334789526924, time: 7.8353331089019775


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.663855362158473, Training Loss Force: 1.7278401307041584, time: 0.5654070377349854
Validation Loss Energy: 2.3152202583158483, Validation Loss Force: 2.1680965188652728, time: 0.06555390357971191
Test Loss Energy: 12.892592494461965, Test Loss Force: 12.51354927058336, time: 7.945492267608643


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7601197092555112, Training Loss Force: 1.7226313933146669, time: 0.48619532585144043
Validation Loss Energy: 1.525680334688817, Validation Loss Force: 2.1937504538367594, time: 0.04138898849487305
Test Loss Energy: 11.421234993851026, Test Loss Force: 12.527785770485748, time: 7.853184938430786


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2420025013114666, Training Loss Force: 1.6878626655433733, time: 0.5241856575012207
Validation Loss Energy: 1.614060947410172, Validation Loss Force: 2.1638430928397603, time: 0.040392160415649414
Test Loss Energy: 12.434564346270319, Test Loss Force: 12.56502714550473, time: 8.169729471206665


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2525756960465024, Training Loss Force: 1.7103149960592112, time: 0.4754760265350342
Validation Loss Energy: 1.787973121130736, Validation Loss Force: 2.212523689529931, time: 0.04086804389953613
Test Loss Energy: 11.505423110869266, Test Loss Force: 12.59195713439795, time: 8.067025899887085


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.182257253777886, Training Loss Force: 1.7007218930650767, time: 0.4913797378540039
Validation Loss Energy: 1.022770823819039, Validation Loss Force: 2.165688352052064, time: 0.041491031646728516
Test Loss Energy: 11.75508191635815, Test Loss Force: 12.491162254548623, time: 7.843114137649536


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.464201923302145, Training Loss Force: 1.7312831456255169, time: 0.4903395175933838
Validation Loss Energy: 1.2968597309356282, Validation Loss Force: 2.1618221476713195, time: 0.04246711730957031
Test Loss Energy: 11.528005082484812, Test Loss Force: 12.307809293757048, time: 7.855837106704712

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–‚â–â–ˆâ–ƒâ–„â–ƒâ–‚â–ƒâ–â–â–„â–â–†â–‚â–…â–‚â–ƒâ–‚
wandb:   test_error_force â–…â–…â–‡â–„â–„â–ƒâ–…â–†â–ˆâ–†â–†â–‚â–ˆâ–„â–…â–†â–‡â–‡â–…â–
wandb:          test_loss â–â–‚â–…â–…â–†â–„â–†â–‡â–ˆâ–‡â–…â–…â–‡â–…â–†â–…â–‡â–‡â–†â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–â–ƒâ–‚â–â–‚â–â–â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚
wandb: valid_error_energy â–‡â–â–‚â–„â–ˆâ–â–‚â–â–‚â–‚â–„â–„â–â–ƒâ–…â–ƒâ–ƒâ–„â–â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–„â–ƒâ–…â–ƒâ–â–ƒâ–ƒâ–‡â–†â–â–„â–…â–ƒâ–„â–‚â–†â–‚â–‚
wandb:         valid_loss â–ˆâ–â–ƒâ–ƒâ–ˆâ–‚â–‚â–‚â–ƒâ–…â–†â–ƒâ–ƒâ–…â–„â–„â–ƒâ–†â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1043
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.52801
wandb:   test_error_force 12.30781
wandb:          test_loss 12.30484
wandb: train_error_energy 1.4642
wandb:  train_error_force 1.73128
wandb:         train_loss -2.78963
wandb: valid_error_energy 1.29686
wandb:  valid_error_force 2.16182
wandb:         valid_loss -2.17213
wandb: 
wandb: ğŸš€ View run al_59_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/f2qwa0t4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_150425-f2qwa0t4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.321643829345703, Uncertainty Bias: -1.9562382698059082
0.00032806396 0.0148386955
0.26865122 7.418477
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 273 steps.
Found uncertainty sample 1 after 146 steps.
Found uncertainty sample 2 after 33 steps.
Found uncertainty sample 3 after 12 steps.
Found uncertainty sample 4 after 268 steps.
Found uncertainty sample 5 after 7 steps.
Found uncertainty sample 6 after 119 steps.
Found uncertainty sample 7 after 109 steps.
Found uncertainty sample 8 after 277 steps.
Found uncertainty sample 9 after 121 steps.
Found uncertainty sample 10 after 76 steps.
Found uncertainty sample 11 after 87 steps.
Found uncertainty sample 12 after 25 steps.
Found uncertainty sample 13 after 252 steps.
Found uncertainty sample 14 after 75 steps.
Found uncertainty sample 15 after 2 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 262 steps.
Found uncertainty sample 18 after 162 steps.
Found uncertainty sample 19 after 14 steps.
Found uncertainty sample 20 after 99 steps.
Found uncertainty sample 21 after 335 steps.
Found uncertainty sample 22 after 141 steps.
Found uncertainty sample 23 after 9 steps.
Found uncertainty sample 24 after 752 steps.
Found uncertainty sample 25 after 374 steps.
Found uncertainty sample 26 after 82 steps.
Found uncertainty sample 27 after 371 steps.
Found uncertainty sample 28 after 73 steps.
Found uncertainty sample 29 after 101 steps.
Found uncertainty sample 30 after 221 steps.
Found uncertainty sample 31 after 88 steps.
Found uncertainty sample 32 after 22 steps.
Found uncertainty sample 33 after 101 steps.
Found uncertainty sample 34 after 56 steps.
Found uncertainty sample 35 after 23 steps.
Found uncertainty sample 36 after 43 steps.
Found uncertainty sample 37 after 201 steps.
Found uncertainty sample 38 after 226 steps.
Found uncertainty sample 39 after 71 steps.
Found uncertainty sample 40 after 176 steps.
Found uncertainty sample 41 after 114 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 78 steps.
Found uncertainty sample 44 after 5 steps.
Found uncertainty sample 45 after 202 steps.
Found uncertainty sample 46 after 177 steps.
Found uncertainty sample 47 after 1024 steps.
Found uncertainty sample 48 after 101 steps.
Found uncertainty sample 49 after 55 steps.
Found uncertainty sample 50 after 156 steps.
Found uncertainty sample 51 after 41 steps.
Found uncertainty sample 52 after 493 steps.
Found uncertainty sample 53 after 18 steps.
Found uncertainty sample 54 after 208 steps.
Found uncertainty sample 55 after 64 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 114 steps.
Found uncertainty sample 58 after 45 steps.
Found uncertainty sample 59 after 4 steps.
Found uncertainty sample 60 after 6 steps.
Found uncertainty sample 61 after 416 steps.
Found uncertainty sample 62 after 183 steps.
Found uncertainty sample 63 after 8 steps.
Found uncertainty sample 64 after 128 steps.
Found uncertainty sample 65 after 53 steps.
Found uncertainty sample 66 after 158 steps.
Found uncertainty sample 67 after 87 steps.
Found uncertainty sample 68 after 592 steps.
Found uncertainty sample 69 after 152 steps.
Found uncertainty sample 70 after 108 steps.
Found uncertainty sample 71 after 108 steps.
Found uncertainty sample 72 after 447 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 436 steps.
Found uncertainty sample 75 after 60 steps.
Found uncertainty sample 76 after 35 steps.
Found uncertainty sample 77 after 44 steps.
Found uncertainty sample 78 after 263 steps.
Found uncertainty sample 79 after 502 steps.
Found uncertainty sample 80 after 92 steps.
Found uncertainty sample 81 after 197 steps.
Found uncertainty sample 82 after 96 steps.
Found uncertainty sample 83 after 100 steps.
Found uncertainty sample 84 after 140 steps.
Found uncertainty sample 85 after 285 steps.
Found uncertainty sample 86 after 154 steps.
Found uncertainty sample 87 after 76 steps.
Found uncertainty sample 88 after 606 steps.
Found uncertainty sample 89 after 129 steps.
Found uncertainty sample 90 after 51 steps.
Found uncertainty sample 91 after 15 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 216 steps.
Found uncertainty sample 94 after 210 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 365 steps.
Found uncertainty sample 97 after 230 steps.
Found uncertainty sample 98 after 363 steps.
Found uncertainty sample 99 after 72 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_151121-7dk5m777
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7dk5m777
Training model 3. Added 103 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0153984433483187, Training Loss Force: 2.222699388069772, time: 0.5363197326660156
Validation Loss Energy: 1.5594355298620213, Validation Loss Force: 2.255991824183078, time: 0.047678232192993164
Test Loss Energy: 12.716507258737893, Test Loss Force: 12.575176479787771, time: 7.895150423049927


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5055788991885752, Training Loss Force: 1.72195615728293, time: 0.5416123867034912
Validation Loss Energy: 1.9440577350208832, Validation Loss Force: 2.1782544626333524, time: 0.045989274978637695
Test Loss Energy: 11.325568956196687, Test Loss Force: 12.404658546288955, time: 7.943426609039307


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.303816143908812, Training Loss Force: 1.7572752444615418, time: 0.5680468082427979
Validation Loss Energy: 1.9904508515749377, Validation Loss Force: 2.172486218408093, time: 0.044142961502075195
Test Loss Energy: 12.877844438427466, Test Loss Force: 12.382817137278552, time: 8.35720705986023


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.0981553371483403, Training Loss Force: 1.7364460179504622, time: 0.6006636619567871
Validation Loss Energy: 1.373110330597994, Validation Loss Force: 2.166782548235153, time: 0.0680088996887207
Test Loss Energy: 12.441261310860645, Test Loss Force: 12.399200209716737, time: 8.104352474212646


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3879188632859323, Training Loss Force: 1.7907006944632704, time: 0.541989803314209
Validation Loss Energy: 1.2518911402426467, Validation Loss Force: 2.219123603015231, time: 0.044008731842041016
Test Loss Energy: 12.361307339750981, Test Loss Force: 12.423887474972174, time: 7.934568643569946


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8294204080331937, Training Loss Force: 1.761888312083998, time: 0.5702989101409912
Validation Loss Energy: 3.5496868698822075, Validation Loss Force: 2.211490059354534, time: 0.04369783401489258
Test Loss Energy: 11.066795572769765, Test Loss Force: 12.455389166872733, time: 8.035615921020508


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4602044213004053, Training Loss Force: 1.7294387281700607, time: 0.5474004745483398
Validation Loss Energy: 0.9363625030577393, Validation Loss Force: 2.1812273184006346, time: 0.04871344566345215
Test Loss Energy: 12.0983842195089, Test Loss Force: 12.450658932759943, time: 8.157541036605835


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.282438757761961, Training Loss Force: 1.7733876488060443, time: 0.5326285362243652
Validation Loss Energy: 2.3902297001588124, Validation Loss Force: 2.235641645598446, time: 0.044832706451416016
Test Loss Energy: 11.417221120189094, Test Loss Force: 12.24267183020844, time: 7.968981742858887


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.450161670157505, Training Loss Force: 1.77453806894848, time: 0.5384392738342285
Validation Loss Energy: 2.350052838151624, Validation Loss Force: 2.1558165381365013, time: 0.04390311241149902
Test Loss Energy: 11.04289462105122, Test Loss Force: 12.262460304305039, time: 7.976045370101929


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2088760398837113, Training Loss Force: 1.763703795483288, time: 0.5392575263977051
Validation Loss Energy: 0.91903706215139, Validation Loss Force: 2.164542719296265, time: 0.04377269744873047
Test Loss Energy: 11.61134119973392, Test Loss Force: 12.388667488128306, time: 7.99926495552063


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3723317787534521, Training Loss Force: 1.7215046461075294, time: 0.5211987495422363
Validation Loss Energy: 0.9178555239958107, Validation Loss Force: 2.1123655490075905, time: 0.04518008232116699
Test Loss Energy: 11.573385096393947, Test Loss Force: 12.498404387819834, time: 8.195998907089233


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4898555055735765, Training Loss Force: 1.7259148590454183, time: 0.5413808822631836
Validation Loss Energy: 2.3343994198620464, Validation Loss Force: 2.14460826400708, time: 0.04671525955200195
Test Loss Energy: 11.227102747943864, Test Loss Force: 12.34898652196717, time: 7.982392072677612


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.577171745860575, Training Loss Force: 1.7547086640141403, time: 0.5402176380157471
Validation Loss Energy: 2.1648105902788166, Validation Loss Force: 2.209743219904731, time: 0.04464364051818848
Test Loss Energy: 11.088251393431074, Test Loss Force: 12.269065202781272, time: 7.956888914108276


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4777586114574168, Training Loss Force: 1.740703083997985, time: 0.5331544876098633
Validation Loss Energy: 1.333415658626312, Validation Loss Force: 2.179376492459683, time: 0.04446983337402344
Test Loss Energy: 11.684983622062907, Test Loss Force: 12.341191660922188, time: 8.506549835205078


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.356914383573304, Training Loss Force: 1.7466423319420632, time: 0.5288493633270264
Validation Loss Energy: 1.733477408360088, Validation Loss Force: 2.231672122733991, time: 0.044762611389160156
Test Loss Energy: 11.488338040723043, Test Loss Force: 12.138445397317028, time: 7.970984935760498


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2692837066186118, Training Loss Force: 1.7189428654172734, time: 0.5225169658660889
Validation Loss Energy: 2.5341532386441137, Validation Loss Force: 2.1376039833527756, time: 0.04452967643737793
Test Loss Energy: 11.228908405856595, Test Loss Force: 12.261696649393915, time: 8.009512186050415


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4347293236719958, Training Loss Force: 1.719261758560512, time: 0.5197477340698242
Validation Loss Energy: 2.7818334737190944, Validation Loss Force: 2.163703033946972, time: 0.04447054862976074
Test Loss Energy: 11.32578029836135, Test Loss Force: 12.40519406675072, time: 7.990680932998657


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2578783888508072, Training Loss Force: 1.7225724096074206, time: 0.56494140625
Validation Loss Energy: 0.9511812460538066, Validation Loss Force: 2.1314799138323237, time: 0.04413008689880371
Test Loss Energy: 11.640467405890215, Test Loss Force: 12.358238427312088, time: 8.135119438171387


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.0587536212301802, Training Loss Force: 1.7150673398586704, time: 0.5481259822845459
Validation Loss Energy: 0.9077382730141492, Validation Loss Force: 2.1704162860275487, time: 0.04411435127258301
Test Loss Energy: 11.837910585779182, Test Loss Force: 12.284675070017006, time: 7.984398365020752


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.1602268712425432, Training Loss Force: 1.7318354708190329, time: 0.5160539150238037
Validation Loss Energy: 2.6135336758216403, Validation Loss Force: 2.130661382051893, time: 0.0448763370513916
Test Loss Energy: 11.304246769665538, Test Loss Force: 12.180369833232465, time: 8.024566173553467

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‚â–ˆâ–†â–†â–â–…â–‚â–â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–‚
wandb:   test_error_force â–ˆâ–…â–…â–…â–†â–†â–†â–ƒâ–ƒâ–…â–‡â–„â–ƒâ–„â–â–ƒâ–…â–…â–ƒâ–‚
wandb:          test_loss â–ƒâ–â–…â–…â–†â–…â–‡â–ƒâ–‚â–„â–†â–‡â–ƒâ–‡â–ƒâ–…â–ˆâ–‡â–…â–„
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–‚â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–„â–„â–‚â–‚â–ˆâ–â–…â–…â–â–â–…â–„â–‚â–ƒâ–…â–†â–â–â–†
wandb:  valid_error_force â–ˆâ–„â–„â–„â–†â–†â–„â–‡â–ƒâ–„â–â–ƒâ–†â–„â–‡â–‚â–„â–‚â–„â–‚
wandb:         valid_loss â–†â–„â–„â–ƒâ–…â–ˆâ–ƒâ–‡â–„â–ƒâ–â–„â–†â–„â–†â–„â–†â–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1135
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.30425
wandb:   test_error_force 12.18037
wandb:          test_loss 12.16214
wandb: train_error_energy 1.16023
wandb:  train_error_force 1.73184
wandb:         train_loss -2.80938
wandb: valid_error_energy 2.61353
wandb:  valid_error_force 2.13066
wandb:         valid_loss -2.12933
wandb: 
wandb: ğŸš€ View run al_59_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7dk5m777
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_151121-7dk5m777/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.973161697387695, Uncertainty Bias: -1.9170265197753906
1.2397766e-05 0.073812485
0.43155417 6.77289
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 153 steps.
Found uncertainty sample 1 after 108 steps.
Found uncertainty sample 2 after 52 steps.
Found uncertainty sample 3 after 110 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 5 steps.
Found uncertainty sample 6 after 104 steps.
Found uncertainty sample 7 after 84 steps.
Found uncertainty sample 8 after 159 steps.
Found uncertainty sample 9 after 364 steps.
Found uncertainty sample 10 after 514 steps.
Found uncertainty sample 11 after 111 steps.
Found uncertainty sample 12 after 334 steps.
Found uncertainty sample 13 after 56 steps.
Found uncertainty sample 14 after 117 steps.
Found uncertainty sample 15 after 178 steps.
Found uncertainty sample 16 after 128 steps.
Found uncertainty sample 17 after 31 steps.
Found uncertainty sample 18 after 69 steps.
Found uncertainty sample 19 after 458 steps.
Found uncertainty sample 20 after 124 steps.
Found uncertainty sample 21 after 165 steps.
Found uncertainty sample 22 after 215 steps.
Found uncertainty sample 23 after 149 steps.
Found uncertainty sample 24 after 240 steps.
Found uncertainty sample 25 after 142 steps.
Found uncertainty sample 26 after 290 steps.
Found uncertainty sample 27 after 386 steps.
Found uncertainty sample 28 after 138 steps.
Found uncertainty sample 29 after 61 steps.
Found uncertainty sample 30 after 131 steps.
Found uncertainty sample 31 after 235 steps.
Found uncertainty sample 32 after 69 steps.
Found uncertainty sample 33 after 302 steps.
Found uncertainty sample 34 after 165 steps.
Found uncertainty sample 35 after 482 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 149 steps.
Found uncertainty sample 38 after 86 steps.
Found uncertainty sample 39 after 183 steps.
Found uncertainty sample 40 after 104 steps.
Found uncertainty sample 41 after 42 steps.
Found uncertainty sample 42 after 69 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 322 steps.
Found uncertainty sample 45 after 64 steps.
Found uncertainty sample 46 after 487 steps.
Found uncertainty sample 47 after 601 steps.
Found uncertainty sample 48 after 498 steps.
Found uncertainty sample 49 after 292 steps.
Found uncertainty sample 50 after 29 steps.
Found uncertainty sample 51 after 332 steps.
Found uncertainty sample 52 after 101 steps.
Found uncertainty sample 53 after 138 steps.
Found uncertainty sample 54 after 130 steps.
Found uncertainty sample 55 after 228 steps.
Found uncertainty sample 56 after 101 steps.
Found uncertainty sample 57 after 36 steps.
Found uncertainty sample 58 after 155 steps.
Found uncertainty sample 59 after 317 steps.
Found uncertainty sample 60 after 104 steps.
Found uncertainty sample 61 after 250 steps.
Found uncertainty sample 62 after 638 steps.
Found uncertainty sample 63 after 432 steps.
Found uncertainty sample 64 after 8 steps.
Found uncertainty sample 65 after 26 steps.
Found uncertainty sample 66 after 780 steps.
Found uncertainty sample 67 after 486 steps.
Found uncertainty sample 68 after 116 steps.
Found uncertainty sample 69 after 182 steps.
Found uncertainty sample 70 after 1045 steps.
Found uncertainty sample 71 after 39 steps.
Found uncertainty sample 72 after 345 steps.
Found uncertainty sample 73 after 324 steps.
Found uncertainty sample 74 after 272 steps.
Found uncertainty sample 75 after 57 steps.
Found uncertainty sample 76 after 302 steps.
Found uncertainty sample 77 after 269 steps.
Found uncertainty sample 78 after 2 steps.
Found uncertainty sample 79 after 90 steps.
Found uncertainty sample 80 after 1204 steps.
Found uncertainty sample 81 after 227 steps.
Found uncertainty sample 82 after 216 steps.
Found uncertainty sample 83 after 5 steps.
Found uncertainty sample 84 after 291 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 840 steps.
Found uncertainty sample 87 after 870 steps.
Found uncertainty sample 88 after 328 steps.
Found uncertainty sample 89 after 515 steps.
Found uncertainty sample 90 after 40 steps.
Found uncertainty sample 91 after 24 steps.
Found uncertainty sample 92 after 28 steps.
Found uncertainty sample 93 after 39 steps.
Found uncertainty sample 94 after 46 steps.
Found uncertainty sample 95 after 250 steps.
Found uncertainty sample 96 after 134 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 3 steps.
Found uncertainty sample 99 after 92 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_151855-0twrzil6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0twrzil6
Training model 4. Added 104 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.58587507556425, Training Loss Force: 2.203496967827282, time: 0.6663413047790527
Validation Loss Energy: 1.0924651531487068, Validation Loss Force: 2.1747674638081236, time: 0.053071022033691406
Test Loss Energy: 12.057396010590109, Test Loss Force: 12.44509793988242, time: 9.47465991973877


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.1015509235686494, Training Loss Force: 1.7893907699408789, time: 0.6010744571685791
Validation Loss Energy: 1.9121668372719596, Validation Loss Force: 2.195685671384018, time: 0.053759098052978516
Test Loss Energy: 11.181367932318123, Test Loss Force: 12.529911363157934, time: 8.723289251327515


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4455447208123418, Training Loss Force: 1.780241314717835, time: 0.6268093585968018
Validation Loss Energy: 1.6164608754649816, Validation Loss Force: 2.12108816746102, time: 0.05363273620605469
Test Loss Energy: 12.436855907896904, Test Loss Force: 12.309876101774709, time: 10.00917911529541


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5378035734672515, Training Loss Force: 1.782354721821755, time: 0.6038405895233154
Validation Loss Energy: 1.6540223770186755, Validation Loss Force: 2.1324218043195984, time: 0.05955338478088379
Test Loss Energy: 12.521229905853906, Test Loss Force: 12.390183512938346, time: 8.056160688400269


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.1504548902416114, Training Loss Force: 1.7567520749768812, time: 0.6106810569763184
Validation Loss Energy: 1.490793757585154, Validation Loss Force: 2.157621716902538, time: 0.04475808143615723
Test Loss Energy: 11.650235101578431, Test Loss Force: 12.285788695540335, time: 7.30884575843811


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7378866899414531, Training Loss Force: 1.7869250060419233, time: 0.5736620426177979
Validation Loss Energy: 1.7249811330934943, Validation Loss Force: 2.1788926324055815, time: 0.04461407661437988
Test Loss Energy: 12.86841308273546, Test Loss Force: 12.370817788456266, time: 7.248569488525391


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.2217362268226626, Training Loss Force: 1.7850819392642876, time: 0.5689833164215088
Validation Loss Energy: 1.3697289882825074, Validation Loss Force: 2.1840618966282954, time: 0.045882225036621094
Test Loss Energy: 11.549264856369911, Test Loss Force: 12.436902824635695, time: 7.454092741012573


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.1591494880668114, Training Loss Force: 1.8051070437337258, time: 0.5680720806121826
Validation Loss Energy: 1.6369145952024706, Validation Loss Force: 2.1495410535968187, time: 0.04701089859008789
Test Loss Energy: 11.392856401100897, Test Loss Force: 12.591791585134084, time: 7.3879876136779785


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.367035214032854, Training Loss Force: 1.7526127126487363, time: 0.6188502311706543
Validation Loss Energy: 0.8808951734688355, Validation Loss Force: 2.126535990785289, time: 0.04488945007324219
Test Loss Energy: 11.777600687242082, Test Loss Force: 12.405846037346768, time: 7.3112266063690186


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 0.9555729110800498, Training Loss Force: 1.7264843182577327, time: 0.5981652736663818
Validation Loss Energy: 0.8984316490582379, Validation Loss Force: 2.186437331077053, time: 0.04346609115600586
Test Loss Energy: 12.082762195237283, Test Loss Force: 12.237209380668965, time: 7.3343400955200195


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2647712257386239, Training Loss Force: 1.7429937138557807, time: 0.5680463314056396
Validation Loss Energy: 3.2356955404807857, Validation Loss Force: 2.1349925196093347, time: 0.04372143745422363
Test Loss Energy: 11.316077384239104, Test Loss Force: 12.202529521556308, time: 7.510226726531982


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.2118801453386794, Training Loss Force: 1.7092758814233702, time: 0.5723345279693604
Validation Loss Energy: 1.4515226023290266, Validation Loss Force: 2.142154672688102, time: 0.04374337196350098
Test Loss Energy: 12.445635022525627, Test Loss Force: 12.350136054347539, time: 7.318609714508057


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5275512693664857, Training Loss Force: 1.7466804982900948, time: 0.6031644344329834
Validation Loss Energy: 2.149794451084884, Validation Loss Force: 2.1031399209535104, time: 0.05145096778869629
Test Loss Energy: 12.992544859548293, Test Loss Force: 12.42863034177012, time: 7.664554834365845


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.403356291433435, Training Loss Force: 1.7371472214088561, time: 0.5932106971740723
Validation Loss Energy: 1.5312624275080808, Validation Loss Force: 2.2347115565759053, time: 0.045903921127319336
Test Loss Energy: 12.375503059722872, Test Loss Force: 12.366457670101449, time: 7.411562919616699


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5867187620942214, Training Loss Force: 1.747833835969289, time: 0.5740811824798584
Validation Loss Energy: 2.208126864574441, Validation Loss Force: 2.2104869348521294, time: 0.04321932792663574
Test Loss Energy: 11.27098275989501, Test Loss Force: 12.164176451590473, time: 7.294776916503906


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7011617806342378, Training Loss Force: 1.7376299252962382, time: 0.5886547565460205
Validation Loss Energy: 2.526226885056522, Validation Loss Force: 2.178812026174756, time: 0.04364347457885742
Test Loss Energy: 13.346764698540687, Test Loss Force: 12.379731978152652, time: 7.2886643409729


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7258480597290065, Training Loss Force: 1.7308191641128736, time: 0.5870170593261719
Validation Loss Energy: 2.2432061618239048, Validation Loss Force: 2.1724303284524655, time: 0.044867753982543945
Test Loss Energy: 11.407582871052117, Test Loss Force: 12.286421672807977, time: 7.995248079299927


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.642022027343566, Training Loss Force: 1.7415899875767236, time: 0.6549627780914307
Validation Loss Energy: 1.4815965198471797, Validation Loss Force: 2.1903857003726444, time: 0.05538535118103027
Test Loss Energy: 12.537056025633579, Test Loss Force: 12.452536045318189, time: 10.159111022949219


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7750435088781853, Training Loss Force: 1.7661453700431122, time: 0.5858197212219238
Validation Loss Energy: 2.5120012213306335, Validation Loss Force: 2.151413701114071, time: 0.05701780319213867
Test Loss Energy: 11.20200022221838, Test Loss Force: 12.293048525762515, time: 9.067416429519653


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2062483245041913, Training Loss Force: 1.7582240693322935, time: 0.6288151741027832
Validation Loss Energy: 1.297624822121036, Validation Loss Force: 2.189825687470636, time: 0.050701141357421875
Test Loss Energy: 12.199239558111667, Test Loss Force: 12.327035009476047, time: 8.08233380317688

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–…â–…â–ƒâ–†â–‚â–‚â–ƒâ–„â–â–…â–‡â–…â–â–ˆâ–‚â–…â–â–„
wandb:   test_error_force â–†â–‡â–ƒâ–…â–ƒâ–„â–…â–ˆâ–…â–‚â–‚â–„â–…â–„â–â–…â–ƒâ–†â–ƒâ–„
wandb:          test_loss â–â–ƒâ–â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–„â–ƒâ–†â–ˆâ–‡â–ƒâ–‡â–„â–ˆâ–„â–„
wandb: train_error_energy â–ˆâ–â–‚â–‚â–â–ƒâ–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–â–â–ˆâ–ƒâ–…â–ƒâ–…â–†â–…â–ƒâ–†â–‚
wandb:  valid_error_force â–…â–†â–‚â–ƒâ–„â–…â–…â–ƒâ–‚â–…â–ƒâ–ƒâ–â–ˆâ–‡â–…â–…â–†â–„â–†
wandb:         valid_loss â–ƒâ–†â–‚â–ƒâ–„â–…â–…â–ƒâ–â–„â–‡â–ƒâ–ƒâ–ˆâ–ˆâ–‡â–†â–†â–†â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1228
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.19924
wandb:   test_error_force 12.32704
wandb:          test_loss 12.12627
wandb: train_error_energy 1.20625
wandb:  train_error_force 1.75822
wandb:         train_loss -2.76863
wandb: valid_error_energy 1.29762
wandb:  valid_error_force 2.18983
wandb:         valid_loss -2.14008
wandb: 
wandb: ğŸš€ View run al_59_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0twrzil6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_151855-0twrzil6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.28591537475586, Uncertainty Bias: -1.9773021936416626
0.0003528595 0.0035438538
0.46188173 6.9280014
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 79 steps.
Found uncertainty sample 1 after 408 steps.
Found uncertainty sample 2 after 62 steps.
Found uncertainty sample 3 after 368 steps.
Found uncertainty sample 4 after 16 steps.
Found uncertainty sample 5 after 89 steps.
Found uncertainty sample 6 after 517 steps.
Found uncertainty sample 7 after 260 steps.
Found uncertainty sample 8 after 394 steps.
Found uncertainty sample 9 after 331 steps.
Found uncertainty sample 10 after 479 steps.
Found uncertainty sample 11 after 355 steps.
Found uncertainty sample 12 after 143 steps.
Found uncertainty sample 13 after 67 steps.
Found uncertainty sample 14 after 231 steps.
Found uncertainty sample 15 after 392 steps.
Found uncertainty sample 16 after 897 steps.
Found uncertainty sample 17 after 384 steps.
Found uncertainty sample 18 after 241 steps.
Found uncertainty sample 19 after 236 steps.
Found uncertainty sample 20 after 67 steps.
Found uncertainty sample 21 after 1027 steps.
Found uncertainty sample 22 after 666 steps.
Found uncertainty sample 23 after 5 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 775 steps.
Found uncertainty sample 26 after 368 steps.
Found uncertainty sample 27 after 1083 steps.
Found uncertainty sample 28 after 49 steps.
Found uncertainty sample 29 after 17 steps.
Found uncertainty sample 30 after 365 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 106 steps.
Found uncertainty sample 33 after 99 steps.
Found uncertainty sample 34 after 392 steps.
Found uncertainty sample 35 after 98 steps.
Found uncertainty sample 36 after 761 steps.
Found uncertainty sample 37 after 1511 steps.
Found uncertainty sample 38 after 262 steps.
Found uncertainty sample 39 after 263 steps.
Found uncertainty sample 40 after 501 steps.
Found uncertainty sample 41 after 71 steps.
Found uncertainty sample 42 after 292 steps.
Found uncertainty sample 43 after 62 steps.
Found uncertainty sample 44 after 327 steps.
Found uncertainty sample 45 after 170 steps.
Found uncertainty sample 46 after 285 steps.
Found uncertainty sample 47 after 413 steps.
Found uncertainty sample 48 after 115 steps.
Found uncertainty sample 49 after 203 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 107 steps.
Found uncertainty sample 52 after 74 steps.
Found uncertainty sample 53 after 584 steps.
Found uncertainty sample 54 after 528 steps.
Found uncertainty sample 55 after 462 steps.
Found uncertainty sample 56 after 227 steps.
Found uncertainty sample 57 after 309 steps.
Found uncertainty sample 58 after 3 steps.
Found uncertainty sample 59 after 191 steps.
Found uncertainty sample 60 after 614 steps.
Found uncertainty sample 61 after 445 steps.
Found uncertainty sample 62 after 326 steps.
Found uncertainty sample 63 after 203 steps.
Found uncertainty sample 64 after 65 steps.
Found uncertainty sample 65 after 362 steps.
Found uncertainty sample 66 after 131 steps.
Found uncertainty sample 67 after 1301 steps.
Found uncertainty sample 68 after 275 steps.
Found uncertainty sample 69 after 45 steps.
Found uncertainty sample 70 after 64 steps.
Found uncertainty sample 71 after 12 steps.
Found uncertainty sample 72 after 6 steps.
Found uncertainty sample 73 after 274 steps.
Found uncertainty sample 74 after 123 steps.
Found uncertainty sample 75 after 199 steps.
Found uncertainty sample 76 after 152 steps.
Found uncertainty sample 77 after 108 steps.
Found uncertainty sample 78 after 194 steps.
Found uncertainty sample 79 after 175 steps.
Found uncertainty sample 80 after 382 steps.
Found uncertainty sample 81 after 70 steps.
Found uncertainty sample 82 after 114 steps.
Found uncertainty sample 83 after 889 steps.
Found uncertainty sample 84 after 183 steps.
Found uncertainty sample 85 after 344 steps.
Found uncertainty sample 86 after 522 steps.
Found uncertainty sample 87 after 28 steps.
Found uncertainty sample 88 after 289 steps.
Found uncertainty sample 89 after 287 steps.
Found uncertainty sample 90 after 106 steps.
Found uncertainty sample 91 after 370 steps.
Found uncertainty sample 92 after 79 steps.
Found uncertainty sample 93 after 77 steps.
Found uncertainty sample 94 after 30 steps.
Found uncertainty sample 95 after 85 steps.
Found uncertainty sample 96 after 116 steps.
Found uncertainty sample 97 after 18 steps.
Found uncertainty sample 98 after 412 steps.
Found uncertainty sample 99 after 449 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_152705-m6kbt50b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m6kbt50b
Training model 5. Added 102 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.23399269641421, Training Loss Force: 2.2381495522840913, time: 0.643740177154541
Validation Loss Energy: 3.8316630521512782, Validation Loss Force: 2.3075113411492554, time: 0.05662059783935547
Test Loss Energy: 14.276458372595368, Test Loss Force: 12.492201315053244, time: 8.163506269454956


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4917919979458756, Training Loss Force: 1.8245707224124093, time: 0.6149659156799316
Validation Loss Energy: 2.3204643393715934, Validation Loss Force: 2.043211749029662, time: 0.055725812911987305
Test Loss Energy: 11.298999868522543, Test Loss Force: 12.323494649330671, time: 8.226008176803589


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.1638378498403938, Training Loss Force: 1.7838454050922148, time: 0.6593832969665527
Validation Loss Energy: 1.2167102501953533, Validation Loss Force: 2.2361369731135623, time: 0.060089111328125
Test Loss Energy: 11.727042344960443, Test Loss Force: 12.272743249402092, time: 8.363765478134155


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.285640353833377, Training Loss Force: 1.779540998435578, time: 0.7699768543243408
Validation Loss Energy: 2.2103442039295897, Validation Loss Force: 2.127134970787835, time: 0.0545649528503418
Test Loss Energy: 13.047859288879788, Test Loss Force: 12.138811987674496, time: 8.169660568237305


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.0824766910851447, Training Loss Force: 1.794375593354177, time: 0.5962064266204834
Validation Loss Energy: 0.767585859184281, Validation Loss Force: 1.8656074425331834, time: 0.056089162826538086
Test Loss Energy: 12.374436775292097, Test Loss Force: 12.24714041058766, time: 8.17803692817688


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7566691712980085, Training Loss Force: 1.7751738070322582, time: 0.6009044647216797
Validation Loss Energy: 3.356193728141619, Validation Loss Force: 2.1178727136592497, time: 0.05924177169799805
Test Loss Energy: 14.099090231501544, Test Loss Force: 12.315563384197993, time: 8.192030906677246


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.0570915098203235, Training Loss Force: 1.7745477117595494, time: 0.5947484970092773
Validation Loss Energy: 1.2571044372889673, Validation Loss Force: 1.9409952549223655, time: 0.05369448661804199
Test Loss Energy: 12.514770574708754, Test Loss Force: 12.394109074384875, time: 8.449641704559326


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.1336155471938887, Training Loss Force: 1.7643953744824654, time: 0.6274697780609131
Validation Loss Energy: 1.2437403361559598, Validation Loss Force: 2.238965873278002, time: 0.056356191635131836
Test Loss Energy: 12.644034215488432, Test Loss Force: 12.255041145565398, time: 8.184951066970825


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3343052099355892, Training Loss Force: 1.8076526891692362, time: 0.5955064296722412
Validation Loss Energy: 1.5742102957017676, Validation Loss Force: 2.015079673465859, time: 0.05415630340576172
Test Loss Energy: 11.689098188811084, Test Loss Force: 12.053521716674268, time: 8.25943636894226


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.15399551705467, Training Loss Force: 1.7983587043381792, time: 0.6809146404266357
Validation Loss Energy: 1.5898213511863324, Validation Loss Force: 2.0008290151283403, time: 0.06300997734069824
Test Loss Energy: 11.365424760772239, Test Loss Force: 12.15608208538872, time: 10.12936544418335


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.696799727035987, Training Loss Force: 1.8110710555318794, time: 0.6456804275512695
Validation Loss Energy: 1.3796534077837954, Validation Loss Force: 1.9326626414780286, time: 0.06183338165283203
Test Loss Energy: 11.611539205065966, Test Loss Force: 12.092395347465851, time: 9.796847820281982


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6563851233023503, Training Loss Force: 1.7700913201567006, time: 0.6990361213684082
Validation Loss Energy: 0.8939411917268851, Validation Loss Force: 1.9821933333000652, time: 0.06435966491699219
Test Loss Energy: 11.914663525868953, Test Loss Force: 12.14731096353311, time: 9.767831802368164


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.663848655093896, Training Loss Force: 1.7835406399528426, time: 0.6516108512878418
Validation Loss Energy: 0.8219366700082164, Validation Loss Force: 1.9990363058344756, time: 0.061702728271484375
Test Loss Energy: 11.766592027258431, Test Loss Force: 12.099439144315811, time: 9.830212116241455


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6960749031798794, Training Loss Force: 1.7673490515441426, time: 0.7448747158050537
Validation Loss Energy: 2.516967633961407, Validation Loss Force: 2.4014763847159064, time: 0.06928563117980957
Test Loss Energy: 11.387913393212397, Test Loss Force: 12.230877602804414, time: 9.755412101745605


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6695176008087755, Training Loss Force: 1.7646344707795516, time: 0.6252219676971436
Validation Loss Energy: 1.2322772171890244, Validation Loss Force: 1.9690226759875826, time: 0.06407976150512695
Test Loss Energy: 11.624274313368367, Test Loss Force: 12.271069523541225, time: 9.659993648529053


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6635008074510207, Training Loss Force: 1.761642555593708, time: 0.6585893630981445
Validation Loss Energy: 1.3745252260185055, Validation Loss Force: 1.8918551247822861, time: 0.061925411224365234
Test Loss Energy: 11.475095223451786, Test Loss Force: 12.156992202970743, time: 9.971160173416138


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6846880298396623, Training Loss Force: 1.7985327255773682, time: 0.7196638584136963
Validation Loss Energy: 2.8809186829617817, Validation Loss Force: 2.0265169071445808, time: 0.06581664085388184
Test Loss Energy: 11.208907237259162, Test Loss Force: 12.38662240609077, time: 9.774614334106445


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4740469801099019, Training Loss Force: 1.8149253948281336, time: 0.647291898727417
Validation Loss Energy: 1.2423600101203536, Validation Loss Force: 2.129641000690679, time: 0.06258583068847656
Test Loss Energy: 12.087028512757117, Test Loss Force: 12.273240834502557, time: 9.745462894439697


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.1873621969814008, Training Loss Force: 1.8108570174661796, time: 0.6881639957427979
Validation Loss Energy: 1.716875976181723, Validation Loss Force: 2.029535076083059, time: 0.06023097038269043
Test Loss Energy: 11.57816004620182, Test Loss Force: 12.245925532390704, time: 9.79720163345337


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4115364617469717, Training Loss Force: 1.7704584034978785, time: 0.6539480686187744
Validation Loss Energy: 1.4625407170078255, Validation Loss Force: 2.3960668604847366, time: 0.05746865272521973
Test Loss Energy: 12.885497392775491, Test Loss Force: 12.173228966624563, time: 9.793334722518921

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–…â–„â–ˆâ–„â–„â–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–â–ƒâ–‚â–…
wandb:   test_error_force â–ˆâ–…â–„â–‚â–„â–…â–†â–„â–â–ƒâ–‚â–‚â–‚â–„â–„â–ƒâ–†â–…â–„â–ƒ
wandb:          test_loss â–„â–‚â–ƒâ–„â–…â–†â–ˆâ–‡â–ƒâ–ƒâ–â–ƒâ–ƒâ–…â–†â–…â–‡â–„â–„â–„
wandb: train_error_energy â–ˆâ–‚â–â–‚â–â–ƒâ–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–ˆâ–…â–‚â–„â–â–‡â–‚â–‚â–ƒâ–ƒâ–‚â–â–â–…â–‚â–‚â–†â–‚â–ƒâ–ƒ
wandb:  valid_error_force â–‡â–ƒâ–†â–„â–â–„â–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ˆâ–‚â–â–ƒâ–„â–ƒâ–ˆ
wandb:         valid_loss â–‡â–„â–…â–…â–â–…â–‚â–…â–ƒâ–ƒâ–‚â–‚â–ƒâ–ˆâ–‚â–‚â–„â–„â–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1319
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.8855
wandb:   test_error_force 12.17323
wandb:          test_loss 11.70443
wandb: train_error_energy 1.41154
wandb:  train_error_force 1.77046
wandb:         train_loss -2.73769
wandb: valid_error_energy 1.46254
wandb:  valid_error_force 2.39607
wandb:         valid_loss -1.85838
wandb: 
wandb: ğŸš€ View run al_59_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m6kbt50b
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_152705-m6kbt50b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.187463760375977, Uncertainty Bias: -1.9020354747772217
4.5776367e-05 0.0826602
0.35625282 6.5521483
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 784 steps.
Found uncertainty sample 1 after 8 steps.
Found uncertainty sample 2 after 42 steps.
Found uncertainty sample 3 after 60 steps.
Found uncertainty sample 4 after 2594 steps.
Found uncertainty sample 5 after 159 steps.
Found uncertainty sample 6 after 143 steps.
Found uncertainty sample 7 after 184 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 20 steps.
Found uncertainty sample 10 after 16 steps.
Found uncertainty sample 11 after 56 steps.
Found uncertainty sample 12 after 431 steps.
Found uncertainty sample 13 after 323 steps.
Found uncertainty sample 14 after 758 steps.
Found uncertainty sample 15 after 205 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 66 steps.
Found uncertainty sample 19 after 97 steps.
Found uncertainty sample 20 after 965 steps.
Found uncertainty sample 21 after 762 steps.
Found uncertainty sample 22 after 134 steps.
Found uncertainty sample 23 after 413 steps.
Found uncertainty sample 24 after 531 steps.
Found uncertainty sample 25 after 4 steps.
Found uncertainty sample 26 after 344 steps.
Found uncertainty sample 27 after 211 steps.
Found uncertainty sample 28 after 125 steps.
Found uncertainty sample 29 after 587 steps.
Found uncertainty sample 30 after 227 steps.
Found uncertainty sample 31 after 28 steps.
Found uncertainty sample 32 after 294 steps.
Found uncertainty sample 33 after 11 steps.
Found uncertainty sample 34 after 76 steps.
Found uncertainty sample 35 after 72 steps.
Found uncertainty sample 36 after 85 steps.
Found uncertainty sample 37 after 5 steps.
Found uncertainty sample 38 after 122 steps.
Found uncertainty sample 39 after 34 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 2461 steps.
Found uncertainty sample 42 after 64 steps.
Found uncertainty sample 43 after 891 steps.
Found uncertainty sample 44 after 95 steps.
Found uncertainty sample 45 after 143 steps.
Found uncertainty sample 46 after 320 steps.
Found uncertainty sample 47 after 466 steps.
Found uncertainty sample 48 after 583 steps.
Found uncertainty sample 49 after 136 steps.
Found uncertainty sample 50 after 130 steps.
Found uncertainty sample 51 after 219 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 37 steps.
Found uncertainty sample 54 after 577 steps.
Found uncertainty sample 55 after 354 steps.
Found uncertainty sample 56 after 50 steps.
Found uncertainty sample 57 after 35 steps.
Found uncertainty sample 58 after 18 steps.
Found uncertainty sample 59 after 13 steps.
Found uncertainty sample 60 after 1199 steps.
Found uncertainty sample 61 after 1325 steps.
Found uncertainty sample 62 after 827 steps.
Found uncertainty sample 63 after 182 steps.
Found uncertainty sample 64 after 62 steps.
Found uncertainty sample 65 after 1160 steps.
Found uncertainty sample 66 after 677 steps.
Found uncertainty sample 67 after 620 steps.
Found uncertainty sample 68 after 22 steps.
Found uncertainty sample 69 after 1469 steps.
Found uncertainty sample 70 after 35 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 423 steps.
Found uncertainty sample 73 after 1340 steps.
Found uncertainty sample 74 after 104 steps.
Found uncertainty sample 75 after 55 steps.
Found uncertainty sample 76 after 140 steps.
Found uncertainty sample 77 after 1510 steps.
Found uncertainty sample 78 after 343 steps.
Found uncertainty sample 79 after 312 steps.
Found uncertainty sample 80 after 1547 steps.
Found uncertainty sample 81 after 71 steps.
Found uncertainty sample 82 after 270 steps.
Found uncertainty sample 83 after 55 steps.
Found uncertainty sample 84 after 72 steps.
Found uncertainty sample 85 after 113 steps.
Found uncertainty sample 86 after 345 steps.
Found uncertainty sample 87 after 74 steps.
Found uncertainty sample 88 after 351 steps.
Found uncertainty sample 89 after 555 steps.
Found uncertainty sample 90 after 371 steps.
Found uncertainty sample 91 after 949 steps.
Found uncertainty sample 92 after 159 steps.
Found uncertainty sample 93 after 651 steps.
Found uncertainty sample 94 after 36 steps.
Found uncertainty sample 95 after 407 steps.
Found uncertainty sample 96 after 195 steps.
Found uncertainty sample 97 after 163 steps.
Found uncertainty sample 98 after 246 steps.
Found uncertainty sample 99 after 444 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_153626-jnb6hueq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jnb6hueq
Training model 6. Added 104 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8814275759760886, Training Loss Force: 2.239694280958669, time: 0.7568457126617432
Validation Loss Energy: 1.6971764368414914, Validation Loss Force: 2.1019247040896096, time: 0.05824398994445801
Test Loss Energy: 11.427564295541412, Test Loss Force: 12.17872470228684, time: 9.817964553833008


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3068599903109681, Training Loss Force: 1.783706092494509, time: 0.7138504981994629
Validation Loss Energy: 0.719626432190484, Validation Loss Force: 2.0228231600173574, time: 0.06406378746032715
Test Loss Energy: 11.990020915648895, Test Loss Force: 12.042594681836803, time: 9.843785047531128


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2210053883371519, Training Loss Force: 1.7747584421281035, time: 0.6681406497955322
Validation Loss Energy: 0.6906811410721091, Validation Loss Force: 2.0316413035343897, time: 0.06186270713806152
Test Loss Energy: 11.60227531988784, Test Loss Force: 12.27688942817415, time: 9.959302186965942


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.1298488354521405, Training Loss Force: 1.7740509900881696, time: 0.6870653629302979
Validation Loss Energy: 3.9816730290713696, Validation Loss Force: 2.7194170854240762, time: 0.0644083023071289
Test Loss Energy: 13.724414069524524, Test Loss Force: 12.213741754766465, time: 9.761404514312744


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3188509489624274, Training Loss Force: 1.8355858015452402, time: 0.6618731021881104
Validation Loss Energy: 1.2546738365593062, Validation Loss Force: 2.012122905544371, time: 0.06529402732849121
Test Loss Energy: 12.776448202660838, Test Loss Force: 12.329917374134554, time: 9.75258493423462


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4537648033128436, Training Loss Force: 1.7964188628717115, time: 0.6578531265258789
Validation Loss Energy: 2.858279242887866, Validation Loss Force: 2.20282321952216, time: 0.06403684616088867
Test Loss Energy: 14.040204380261724, Test Loss Force: 12.201037619625684, time: 9.904350996017456


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1077281968406694, Training Loss Force: 1.823593855727234, time: 0.717052698135376
Validation Loss Energy: 2.4768574613634238, Validation Loss Force: 2.161041246976551, time: 0.06093645095825195
Test Loss Energy: 11.280695345552514, Test Loss Force: 12.189058052217362, time: 9.689015865325928


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.106227583405712, Training Loss Force: 1.782269074894349, time: 0.713580846786499
Validation Loss Energy: 1.2471210939649382, Validation Loss Force: 2.0855322469046977, time: 0.06458139419555664
Test Loss Energy: 12.814823693427803, Test Loss Force: 12.151237933274551, time: 9.370108127593994


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2425446510873093, Training Loss Force: 1.7903730640301556, time: 0.6554067134857178
Validation Loss Energy: 0.5916994033981701, Validation Loss Force: 2.0778954745413856, time: 0.05392718315124512
Test Loss Energy: 12.005871489397183, Test Loss Force: 12.175422684397327, time: 9.776368856430054


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1055107947247849, Training Loss Force: 1.7788227527738776, time: 0.7531769275665283
Validation Loss Energy: 0.7343806568015185, Validation Loss Force: 2.208773384439642, time: 0.06391286849975586
Test Loss Energy: 12.3028004830556, Test Loss Force: 12.171071454155436, time: 9.150474786758423


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4829040466796262, Training Loss Force: 1.8223779287961681, time: 0.6723275184631348
Validation Loss Energy: 3.0475817513020935, Validation Loss Force: 2.184947117817931, time: 0.05505871772766113
Test Loss Energy: 13.824257347713873, Test Loss Force: 12.342865853105874, time: 7.687477111816406


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4787648907486515, Training Loss Force: 1.792558504793099, time: 0.6495168209075928
Validation Loss Energy: 3.1456801465573156, Validation Loss Force: 2.9930697836837927, time: 0.05876040458679199
Test Loss Energy: 12.572038658825953, Test Loss Force: 12.245906030770424, time: 7.78428316116333


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2985191245006733, Training Loss Force: 1.791309271506005, time: 0.6516211032867432
Validation Loss Energy: 1.0173211634743158, Validation Loss Force: 2.275107747691833, time: 0.053963661193847656
Test Loss Energy: 12.338307892631999, Test Loss Force: 12.055054151384294, time: 7.67150616645813


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.1658657293855148, Training Loss Force: 1.7903506264025508, time: 0.6897759437561035
Validation Loss Energy: 0.7460936662174715, Validation Loss Force: 2.0199708795925955, time: 0.05641674995422363
Test Loss Energy: 11.841637675570844, Test Loss Force: 12.074869135933136, time: 7.700476169586182


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.1338669181276442, Training Loss Force: 1.7802914611417056, time: 0.6431312561035156
Validation Loss Energy: 1.4621420835693282, Validation Loss Force: 2.037276168941238, time: 0.056894779205322266
Test Loss Energy: 12.64488362250269, Test Loss Force: 11.980880708608744, time: 7.670517206192017


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3707187204728353, Training Loss Force: 1.7910263381927831, time: 0.6693320274353027
Validation Loss Energy: 0.840072069932878, Validation Loss Force: 2.0297784534595578, time: 0.054999589920043945
Test Loss Energy: 12.50068671625461, Test Loss Force: 12.157356983995669, time: 7.781253337860107


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6188193412877685, Training Loss Force: 1.7778114637361224, time: 0.6691718101501465
Validation Loss Energy: 1.1241716808448023, Validation Loss Force: 2.089025257796867, time: 0.05233168601989746
Test Loss Energy: 11.61559667524822, Test Loss Force: 12.06563543583107, time: 7.651500463485718


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6598518441256078, Training Loss Force: 1.7599307552546748, time: 0.6875317096710205
Validation Loss Energy: 1.6926138903741448, Validation Loss Force: 1.9020955674689324, time: 0.05370736122131348
Test Loss Energy: 12.871981618105544, Test Loss Force: 12.28924672639207, time: 7.748576402664185


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6608261342106656, Training Loss Force: 1.7674923569884233, time: 0.6622664928436279
Validation Loss Energy: 1.7281030658539749, Validation Loss Force: 2.057436076740675, time: 0.05760025978088379
Test Loss Energy: 11.540808875475175, Test Loss Force: 12.0845311395545, time: 8.137928247451782


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7187338594975494, Training Loss Force: 1.7691552229550942, time: 0.6732580661773682
Validation Loss Energy: 0.8996493709500304, Validation Loss Force: 2.078997464144582, time: 0.05463862419128418
Test Loss Energy: 12.429977599688844, Test Loss Force: 12.158400078192672, time: 7.760600566864014

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–‚â–‡â–…â–ˆâ–â–…â–ƒâ–„â–‡â–„â–„â–‚â–„â–„â–‚â–…â–‚â–„
wandb:   test_error_force â–…â–‚â–‡â–†â–ˆâ–…â–…â–„â–…â–…â–ˆâ–†â–‚â–ƒâ–â–„â–ƒâ–‡â–ƒâ–„
wandb:          test_loss â–â–‚â–†â–ˆâ–ˆâ–‡â–…â–†â–†â–…â–‡â–‡â–†â–…â–…â–‡â–…â–ˆâ–†â–‡
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–…â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–â–â–â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–â–â–ˆâ–‚â–†â–…â–‚â–â–â–†â–†â–‚â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚
wandb:  valid_error_force â–‚â–‚â–‚â–†â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–‚â–â–â–‡â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–â–‚â–‚â–‚â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1412
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.42998
wandb:   test_error_force 12.1584
wandb:          test_loss 11.82641
wandb: train_error_energy 1.71873
wandb:  train_error_force 1.76916
wandb:         train_loss -2.71923
wandb: valid_error_energy 0.89965
wandb:  valid_error_force 2.079
wandb:         valid_loss -2.33109
wandb: 
wandb: ğŸš€ View run al_59_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jnb6hueq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_153626-jnb6hueq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.76752281188965, Uncertainty Bias: -2.0581142902374268
0.0001373291 0.00065898895
0.30371 6.5230837
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 919 steps.
Found uncertainty sample 1 after 1525 steps.
Found uncertainty sample 2 after 511 steps.
Found uncertainty sample 3 after 111 steps.
Found uncertainty sample 4 after 17 steps.
Found uncertainty sample 5 after 273 steps.
Found uncertainty sample 6 after 48 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 10 steps.
Found uncertainty sample 9 after 140 steps.
Found uncertainty sample 10 after 1349 steps.
Found uncertainty sample 11 after 56 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1656 steps.
Found uncertainty sample 14 after 331 steps.
Found uncertainty sample 15 after 68 steps.
Found uncertainty sample 16 after 122 steps.
Found uncertainty sample 17 after 754 steps.
Found uncertainty sample 18 after 509 steps.
Found uncertainty sample 19 after 210 steps.
Found uncertainty sample 20 after 800 steps.
Found uncertainty sample 21 after 368 steps.
Found uncertainty sample 22 after 816 steps.
Found uncertainty sample 23 after 279 steps.
Found uncertainty sample 24 after 2293 steps.
Found uncertainty sample 25 after 605 steps.
Found uncertainty sample 26 after 1194 steps.
Found uncertainty sample 27 after 195 steps.
Found uncertainty sample 28 after 538 steps.
Found uncertainty sample 29 after 189 steps.
Found uncertainty sample 30 after 7 steps.
Found uncertainty sample 31 after 31 steps.
Found uncertainty sample 32 after 1333 steps.
Found uncertainty sample 33 after 594 steps.
Found uncertainty sample 34 after 196 steps.
Found uncertainty sample 35 after 276 steps.
Found uncertainty sample 36 after 2228 steps.
Found uncertainty sample 37 after 18 steps.
Found uncertainty sample 38 after 590 steps.
Found uncertainty sample 39 after 947 steps.
Found uncertainty sample 40 after 17 steps.
Found uncertainty sample 41 after 31 steps.
Found uncertainty sample 42 after 78 steps.
Found uncertainty sample 43 after 167 steps.
Found uncertainty sample 44 after 894 steps.
Found uncertainty sample 45 after 29 steps.
Found uncertainty sample 46 after 420 steps.
Found uncertainty sample 47 after 445 steps.
Found uncertainty sample 48 after 1946 steps.
Found uncertainty sample 49 after 90 steps.
Found uncertainty sample 50 after 357 steps.
Found uncertainty sample 51 after 80 steps.
Found uncertainty sample 52 after 23 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1456 steps.
Found uncertainty sample 55 after 55 steps.
Found uncertainty sample 56 after 2 steps.
Found uncertainty sample 57 after 214 steps.
Found uncertainty sample 58 after 205 steps.
Found uncertainty sample 59 after 584 steps.
Found uncertainty sample 60 after 27 steps.
Found uncertainty sample 61 after 61 steps.
Found uncertainty sample 62 after 510 steps.
Found uncertainty sample 63 after 447 steps.
Found uncertainty sample 64 after 1095 steps.
Found uncertainty sample 65 after 2615 steps.
Found uncertainty sample 66 after 192 steps.
Found uncertainty sample 67 after 363 steps.
Found uncertainty sample 68 after 96 steps.
Found uncertainty sample 69 after 220 steps.
Found uncertainty sample 70 after 837 steps.
Found uncertainty sample 71 after 296 steps.
Found uncertainty sample 72 after 345 steps.
Found uncertainty sample 73 after 475 steps.
Found uncertainty sample 74 after 93 steps.
Found uncertainty sample 75 after 5 steps.
Found uncertainty sample 76 after 2102 steps.
Found uncertainty sample 77 after 250 steps.
Found uncertainty sample 78 after 165 steps.
Found uncertainty sample 79 after 710 steps.
Found uncertainty sample 80 after 138 steps.
Found uncertainty sample 81 after 473 steps.
Found uncertainty sample 82 after 47 steps.
Found uncertainty sample 83 after 100 steps.
Found uncertainty sample 84 after 9 steps.
Found uncertainty sample 85 after 868 steps.
Found uncertainty sample 86 after 672 steps.
Found uncertainty sample 87 after 296 steps.
Found uncertainty sample 88 after 370 steps.
Found uncertainty sample 89 after 568 steps.
Found uncertainty sample 90 after 27 steps.
Found uncertainty sample 91 after 490 steps.
Found uncertainty sample 92 after 101 steps.
Found uncertainty sample 93 after 18 steps.
Found uncertainty sample 94 after 92 steps.
Found uncertainty sample 95 after 2421 steps.
Found uncertainty sample 96 after 565 steps.
Found uncertainty sample 97 after 146 steps.
Found uncertainty sample 98 after 329 steps.
Found uncertainty sample 99 after 9 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_154642-16h4plv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/16h4plv1
Training model 7. Added 103 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.35477435854506, Training Loss Force: 2.1432458249365895, time: 0.7185356616973877
Validation Loss Energy: 0.7794407923471196, Validation Loss Force: 2.0672690348902734, time: 0.06016087532043457
Test Loss Energy: 12.17357373307411, Test Loss Force: 12.27063486404192, time: 8.624691009521484


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.491545337017281, Training Loss Force: 1.8141171698429748, time: 0.684394121170044
Validation Loss Energy: 1.137723380733254, Validation Loss Force: 2.014602827489855, time: 0.07288694381713867
Test Loss Energy: 12.657030767679133, Test Loss Force: 12.293611713157107, time: 8.656829595565796


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.284743845523302, Training Loss Force: 1.7949949902787479, time: 0.6868999004364014
Validation Loss Energy: 3.6041205692957146, Validation Loss Force: 2.2206066908616826, time: 0.06274032592773438
Test Loss Energy: 14.552078185466046, Test Loss Force: 12.461370782932722, time: 8.742003440856934


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.507558227401521, Training Loss Force: 1.8150111556692055, time: 0.6853485107421875
Validation Loss Energy: 0.7424631014604053, Validation Loss Force: 2.014739490678168, time: 0.07082915306091309
Test Loss Energy: 12.234482432079473, Test Loss Force: 12.146121509256234, time: 9.212000131607056


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.1868004285858507, Training Loss Force: 1.7728689091831271, time: 0.7039234638214111
Validation Loss Energy: 2.2778611630158028, Validation Loss Force: 2.0424799468815706, time: 0.06699299812316895
Test Loss Energy: 11.336239606748432, Test Loss Force: 12.180762295179907, time: 9.758781433105469


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4572653639655913, Training Loss Force: 1.8473295402771799, time: 0.7242982387542725
Validation Loss Energy: 1.8883680702897707, Validation Loss Force: 2.4258796984292887, time: 0.06717920303344727
Test Loss Energy: 13.007356568647545, Test Loss Force: 12.349562710441953, time: 10.231295108795166


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2847378341145146, Training Loss Force: 1.9300374812132923, time: 0.766228437423706
Validation Loss Energy: 3.471831048346848, Validation Loss Force: 2.5920367511354803, time: 0.06452703475952148
Test Loss Energy: 13.654371733967528, Test Loss Force: 12.319302756932702, time: 9.7752206325531


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6437075142764652, Training Loss Force: 1.8044967067543929, time: 0.7220063209533691
Validation Loss Energy: 2.372975290710014, Validation Loss Force: 2.0523179150869524, time: 0.0647132396697998
Test Loss Energy: 13.305114581686583, Test Loss Force: 12.338409163958532, time: 9.741196393966675


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5737942123455744, Training Loss Force: 1.806139370207391, time: 0.7736921310424805
Validation Loss Energy: 0.9440303377669086, Validation Loss Force: 2.1795341422149996, time: 0.0630805492401123
Test Loss Energy: 11.805013949788457, Test Loss Force: 12.285443224943332, time: 9.937572479248047


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4972590817846645, Training Loss Force: 1.7893163632782625, time: 0.7116601467132568
Validation Loss Energy: 1.3438555015331364, Validation Loss Force: 2.1799562115811058, time: 0.06364941596984863
Test Loss Energy: 11.735166304008262, Test Loss Force: 12.147196406669469, time: 9.785889625549316


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2065006424477769, Training Loss Force: 1.8087796009094297, time: 0.7401213645935059
Validation Loss Energy: 2.2140637806777406, Validation Loss Force: 2.2221798483776625, time: 0.06306862831115723
Test Loss Energy: 13.264895460339757, Test Loss Force: 12.30332317497662, time: 9.841519117355347


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.2237909572963561, Training Loss Force: 1.7980633687408119, time: 0.7357203960418701
Validation Loss Energy: 1.6712482291495085, Validation Loss Force: 2.174753769655649, time: 0.0690145492553711
Test Loss Energy: 12.834258396381227, Test Loss Force: 12.41734739070451, time: 9.924094915390015


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2021771988199734, Training Loss Force: 1.7813839005020824, time: 0.7237899303436279
Validation Loss Energy: 1.8676360697871586, Validation Loss Force: 2.037526115057542, time: 0.0650641918182373
Test Loss Energy: 11.33549189075125, Test Loss Force: 12.328118547851114, time: 9.780056953430176


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.1805270055123835, Training Loss Force: 1.756907108339364, time: 0.7338111400604248
Validation Loss Energy: 1.3592495659349946, Validation Loss Force: 2.0320667129376844, time: 0.06536531448364258
Test Loss Energy: 11.585093674285865, Test Loss Force: 12.214901760757341, time: 9.902621746063232


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.1666243044320972, Training Loss Force: 1.7831950439586448, time: 0.7297759056091309
Validation Loss Energy: 4.041411820886606, Validation Loss Force: 1.9398091520492946, time: 0.06333470344543457
Test Loss Energy: 11.157224693252662, Test Loss Force: 12.056390166259865, time: 9.999330043792725


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2729014949438235, Training Loss Force: 1.769554102303501, time: 0.722832441329956
Validation Loss Energy: 0.7885796351015745, Validation Loss Force: 2.031571051418849, time: 0.05995631217956543
Test Loss Energy: 11.87853600953471, Test Loss Force: 12.260871230025453, time: 10.223472833633423


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.1612113276447555, Training Loss Force: 1.764325996574565, time: 0.789912223815918
Validation Loss Energy: 0.9872149032627168, Validation Loss Force: 2.1716401869881405, time: 0.06357026100158691
Test Loss Energy: 11.773535844496065, Test Loss Force: 12.19843377093387, time: 9.883547067642212


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3972904865961793, Training Loss Force: 1.7761686408878108, time: 0.7648389339447021
Validation Loss Energy: 2.272793380256346, Validation Loss Force: 2.4242478675933574, time: 0.0672142505645752
Test Loss Energy: 11.722508512029204, Test Loss Force: 12.090921977204037, time: 9.925544261932373


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.0786425584780788, Training Loss Force: 1.76765798924838, time: 0.8063545227050781
Validation Loss Energy: 1.9451942940089852, Validation Loss Force: 2.1111346339689017, time: 0.06332635879516602
Test Loss Energy: 12.807329349460101, Test Loss Force: 12.345937092495637, time: 9.77298617362976


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.387218038897058, Training Loss Force: 1.798875616039922, time: 0.7426621913909912
Validation Loss Energy: 0.9096988470104002, Validation Loss Force: 1.9610426591358223, time: 0.06346559524536133
Test Loss Energy: 12.430292101787456, Test Loss Force: 12.123905498462344, time: 9.763550996780396

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–ˆâ–ƒâ–â–…â–†â–…â–‚â–‚â–…â–„â–â–‚â–â–‚â–‚â–‚â–„â–„
wandb:   test_error_force â–…â–…â–ˆâ–ƒâ–ƒâ–†â–†â–†â–…â–ƒâ–…â–‡â–†â–„â–â–…â–ƒâ–‚â–†â–‚
wandb:          test_loss â–â–ƒâ–ˆâ–„â–…â–‡â–„â–…â–„â–„â–…â–‡â–…â–†â–ƒâ–†â–†â–…â–ˆâ–„
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ˆâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–ƒâ–…â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–â–‚â–‡â–â–„â–ƒâ–‡â–„â–â–‚â–„â–ƒâ–ƒâ–‚â–ˆâ–â–‚â–„â–„â–
wandb:  valid_error_force â–‚â–‚â–„â–‚â–‚â–†â–ˆâ–‚â–„â–„â–„â–„â–‚â–‚â–â–‚â–ƒâ–†â–ƒâ–
wandb:         valid_loss â–‚â–‚â–…â–â–‚â–†â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–†â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1504
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.43029
wandb:   test_error_force 12.12391
wandb:          test_loss 11.6061
wandb: train_error_energy 1.38722
wandb:  train_error_force 1.79888
wandb:         train_loss -2.69926
wandb: valid_error_energy 0.9097
wandb:  valid_error_force 1.96104
wandb:         valid_loss -2.50112
wandb: 
wandb: ğŸš€ View run al_59_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/16h4plv1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_154642-16h4plv1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.786935806274414, Uncertainty Bias: -2.1941864490509033
3.8146973e-05 0.0018005371
0.19080786 6.574789
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 843 steps.
Found uncertainty sample 1 after 2301 steps.
Found uncertainty sample 2 after 407 steps.
Found uncertainty sample 3 after 28 steps.
Found uncertainty sample 4 after 111 steps.
Found uncertainty sample 5 after 304 steps.
Found uncertainty sample 6 after 554 steps.
Found uncertainty sample 7 after 180 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 283 steps.
Found uncertainty sample 10 after 408 steps.
Found uncertainty sample 11 after 3100 steps.
Found uncertainty sample 12 after 575 steps.
Found uncertainty sample 13 after 1799 steps.
Found uncertainty sample 14 after 135 steps.
Found uncertainty sample 15 after 66 steps.
Found uncertainty sample 16 after 113 steps.
Found uncertainty sample 17 after 424 steps.
Found uncertainty sample 18 after 685 steps.
Found uncertainty sample 19 after 98 steps.
Found uncertainty sample 20 after 435 steps.
Found uncertainty sample 21 after 1106 steps.
Found uncertainty sample 22 after 308 steps.
Found uncertainty sample 23 after 389 steps.
Found uncertainty sample 24 after 255 steps.
Found uncertainty sample 25 after 100 steps.
Found uncertainty sample 26 after 685 steps.
Found uncertainty sample 27 after 1964 steps.
Found uncertainty sample 28 after 221 steps.
Found uncertainty sample 29 after 271 steps.
Found uncertainty sample 30 after 406 steps.
Found uncertainty sample 31 after 1743 steps.
Found uncertainty sample 32 after 184 steps.
Found uncertainty sample 33 after 17 steps.
Found uncertainty sample 34 after 542 steps.
Found uncertainty sample 35 after 27 steps.
Found uncertainty sample 36 after 552 steps.
Found uncertainty sample 37 after 1006 steps.
Found uncertainty sample 38 after 6 steps.
Found uncertainty sample 39 after 941 steps.
Found uncertainty sample 40 after 923 steps.
Found uncertainty sample 41 after 285 steps.
Found uncertainty sample 42 after 872 steps.
Found uncertainty sample 43 after 133 steps.
Found uncertainty sample 44 after 19 steps.
Found uncertainty sample 45 after 1366 steps.
Found uncertainty sample 46 after 547 steps.
Found uncertainty sample 47 after 1034 steps.
Found uncertainty sample 48 after 970 steps.
Found uncertainty sample 49 after 253 steps.
Found uncertainty sample 50 after 725 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1982 steps.
Found uncertainty sample 53 after 198 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 90 steps.
Found uncertainty sample 56 after 348 steps.
Found uncertainty sample 57 after 548 steps.
Found uncertainty sample 58 after 161 steps.
Found uncertainty sample 59 after 16 steps.
Found uncertainty sample 60 after 186 steps.
Found uncertainty sample 61 after 40 steps.
Found uncertainty sample 62 after 2 steps.
Found uncertainty sample 63 after 161 steps.
Found uncertainty sample 64 after 1726 steps.
Found uncertainty sample 65 after 61 steps.
Found uncertainty sample 66 after 690 steps.
Found uncertainty sample 67 after 495 steps.
Found uncertainty sample 68 after 908 steps.
Found uncertainty sample 69 after 1540 steps.
Found uncertainty sample 70 after 404 steps.
Found uncertainty sample 71 after 702 steps.
Found uncertainty sample 72 after 986 steps.
Found uncertainty sample 73 after 2375 steps.
Found uncertainty sample 74 after 258 steps.
Found uncertainty sample 75 after 163 steps.
Found uncertainty sample 76 after 325 steps.
Found uncertainty sample 77 after 415 steps.
Found uncertainty sample 78 after 2044 steps.
Found uncertainty sample 79 after 133 steps.
Found uncertainty sample 80 after 1450 steps.
Found uncertainty sample 81 after 751 steps.
Found uncertainty sample 82 after 401 steps.
Found uncertainty sample 83 after 46 steps.
Found uncertainty sample 84 after 90 steps.
Found uncertainty sample 85 after 136 steps.
Found uncertainty sample 86 after 25 steps.
Found uncertainty sample 87 after 44 steps.
Found uncertainty sample 88 after 728 steps.
Found uncertainty sample 89 after 3704 steps.
Found uncertainty sample 90 after 12 steps.
Found uncertainty sample 91 after 1416 steps.
Found uncertainty sample 92 after 1944 steps.
Found uncertainty sample 93 after 1881 steps.
Found uncertainty sample 94 after 2017 steps.
Found uncertainty sample 95 after 480 steps.
Found uncertainty sample 96 after 725 steps.
Found uncertainty sample 97 after 320 steps.
Found uncertainty sample 98 after 594 steps.
Found uncertainty sample 99 after 361 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_155849-hr9sls11
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hr9sls11
Training model 8. Added 103 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.5673376816669204, Training Loss Force: 2.1737742146823407, time: 0.8124732971191406
Validation Loss Energy: 1.932961240802718, Validation Loss Force: 2.074167547700262, time: 0.07474517822265625
Test Loss Energy: 11.461911335395131, Test Loss Force: 12.224936244393364, time: 10.359254121780396


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6841681955173942, Training Loss Force: 1.822044043339334, time: 0.806851863861084
Validation Loss Energy: 1.6345781278542502, Validation Loss Force: 2.01859734496594, time: 0.06328797340393066
Test Loss Energy: 11.669491818438416, Test Loss Force: 12.152940767005763, time: 7.500225782394409


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3211587892848693, Training Loss Force: 1.8262322718389188, time: 0.817415714263916
Validation Loss Energy: 1.2538039795407392, Validation Loss Force: 2.0189775525326117, time: 0.054737091064453125
Test Loss Energy: 11.577221967903592, Test Loss Force: 12.076134931918672, time: 7.686397552490234


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5867248973428747, Training Loss Force: 1.825683143004763, time: 0.778742790222168
Validation Loss Energy: 1.7433686501586325, Validation Loss Force: 2.1263192223717287, time: 0.05691361427307129
Test Loss Energy: 11.418330222381083, Test Loss Force: 12.033405492247775, time: 7.617393255233765


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.014968374477699, Training Loss Force: 1.777715670974724, time: 0.7578690052032471
Validation Loss Energy: 0.7503229326406509, Validation Loss Force: 2.1401150233114032, time: 0.05774044990539551
Test Loss Energy: 12.023784361821475, Test Loss Force: 12.32901067469879, time: 7.507066488265991


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2432859135196233, Training Loss Force: 1.790557011753837, time: 0.7273867130279541
Validation Loss Energy: 1.7010277780567449, Validation Loss Force: 2.3466787325833804, time: 0.05451488494873047
Test Loss Energy: 12.313249331821861, Test Loss Force: 12.108758988232179, time: 7.905198335647583


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3098642581383713, Training Loss Force: 1.7892191798980395, time: 0.7169289588928223
Validation Loss Energy: 1.952142963044094, Validation Loss Force: 2.484353840830229, time: 0.05598115921020508
Test Loss Energy: 12.394044745152033, Test Loss Force: 12.148731485429883, time: 7.790226459503174


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2858317386535156, Training Loss Force: 1.7915560703176368, time: 0.7930676937103271
Validation Loss Energy: 1.2521127517101311, Validation Loss Force: 2.073434854875587, time: 0.05714988708496094
Test Loss Energy: 12.423841010566516, Test Loss Force: 12.3511346053889, time: 7.463486671447754


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2114558974119063, Training Loss Force: 1.7563130867523098, time: 0.7405486106872559
Validation Loss Energy: 1.966774886626728, Validation Loss Force: 2.288549059351191, time: 0.05482077598571777
Test Loss Energy: 12.943797034263158, Test Loss Force: 12.205940976084912, time: 7.500054597854614


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7067423634712184, Training Loss Force: 1.8086513737549037, time: 0.7529659271240234
Validation Loss Energy: 1.046048906837119, Validation Loss Force: 2.1720903126666338, time: 0.055808067321777344
Test Loss Energy: 11.807824775863347, Test Loss Force: 12.199751380047786, time: 7.7441065311431885


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5685679664251477, Training Loss Force: 1.882670231821762, time: 0.8599538803100586
Validation Loss Energy: 1.4079525130406876, Validation Loss Force: 2.352099612940992, time: 0.08627557754516602
Test Loss Energy: 11.869186283652121, Test Loss Force: 12.349186485855054, time: 7.620673418045044


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3386237730482617, Training Loss Force: 1.768909611712241, time: 0.7478439807891846
Validation Loss Energy: 0.9941910997709911, Validation Loss Force: 2.024264831402667, time: 0.05658316612243652
Test Loss Energy: 12.27316496844318, Test Loss Force: 12.100368026728056, time: 7.561037302017212


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.1674339823661453, Training Loss Force: 1.7719854363726746, time: 0.7760865688323975
Validation Loss Energy: 0.8132265210269591, Validation Loss Force: 2.138521602903144, time: 0.054327964782714844
Test Loss Energy: 11.870078485111447, Test Loss Force: 12.269688466544602, time: 7.624271869659424


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.2771230192081755, Training Loss Force: 1.7900393638835324, time: 0.7522635459899902
Validation Loss Energy: 1.5152252389454968, Validation Loss Force: 2.039641917282148, time: 0.054256439208984375
Test Loss Energy: 11.607445403672907, Test Loss Force: 12.218160238085266, time: 8.28865933418274


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.1378916584869059, Training Loss Force: 1.8056690411887715, time: 0.7899963855743408
Validation Loss Energy: 1.16728204184773, Validation Loss Force: 2.157383238247249, time: 0.07083916664123535
Test Loss Energy: 12.410082645439825, Test Loss Force: 12.321489741003967, time: 10.630753517150879


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.19691497425583, Training Loss Force: 1.7915429150244955, time: 0.8732409477233887
Validation Loss Energy: 1.2505120945546293, Validation Loss Force: 2.092681262503855, time: 0.06865835189819336
Test Loss Energy: 12.701495096111794, Test Loss Force: 12.130097584663321, time: 9.489148616790771


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6496521988798787, Training Loss Force: 1.7787512428250734, time: 0.7478177547454834
Validation Loss Energy: 0.9450138673844717, Validation Loss Force: 2.062195407065736, time: 0.05751514434814453
Test Loss Energy: 11.803007889644388, Test Loss Force: 12.407127441157034, time: 8.947903394699097


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.062364010987427, Training Loss Force: 1.7881346609160322, time: 0.783085823059082
Validation Loss Energy: 1.2593302380716616, Validation Loss Force: 2.0831821967385755, time: 0.05844521522521973
Test Loss Energy: 11.8361810877092, Test Loss Force: 12.066381263220832, time: 8.414007425308228


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2466524166065525, Training Loss Force: 1.7879388902029323, time: 0.7426743507385254
Validation Loss Energy: 1.4587530591683073, Validation Loss Force: 2.0347673556740697, time: 0.05979728698730469
Test Loss Energy: 11.673528649172713, Test Loss Force: 12.182776320117718, time: 8.405166625976562


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3281209593069685, Training Loss Force: 1.8116366789541345, time: 0.7676987648010254
Validation Loss Energy: 1.7581164173644355, Validation Loss Force: 2.434233354107916, time: 0.058004140853881836
Test Loss Energy: 11.737291845384942, Test Loss Force: 12.248246696189822, time: 8.649375677108765

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‚â–â–„â–…â–…â–†â–ˆâ–ƒâ–ƒâ–…â–ƒâ–‚â–†â–‡â–ƒâ–ƒâ–‚â–‚
wandb:   test_error_force â–…â–ƒâ–‚â–â–‡â–‚â–ƒâ–‡â–„â–„â–‡â–‚â–…â–„â–†â–ƒâ–ˆâ–‚â–„â–…
wandb:          test_loss â–â–‚â–ƒâ–„â–‡â–…â–‡â–ˆâ–ˆâ–‡â–…â–…â–ˆâ–†â–†â–†â–ˆâ–…â–†â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–ƒâ–â–â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–‚â–ƒâ–â–â–â–‚â–â–‚â–â–â–‚
wandb: valid_error_energy â–ˆâ–†â–„â–‡â–â–†â–ˆâ–„â–ˆâ–ƒâ–…â–‚â–â–…â–ƒâ–„â–‚â–„â–…â–‡
wandb:  valid_error_force â–‚â–â–â–ƒâ–ƒâ–†â–ˆâ–‚â–…â–ƒâ–†â–â–ƒâ–â–ƒâ–‚â–‚â–‚â–â–‡
wandb:         valid_loss â–‚â–â–â–ƒâ–‚â–†â–ˆâ–‚â–…â–ƒâ–†â–â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1596
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.73729
wandb:   test_error_force 12.24825
wandb:          test_loss 11.64834
wandb: train_error_energy 1.32812
wandb:  train_error_force 1.81164
wandb:         train_loss -2.68558
wandb: valid_error_energy 1.75812
wandb:  valid_error_force 2.43423
wandb:         valid_loss -1.77942
wandb: 
wandb: ğŸš€ View run al_59_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hr9sls11
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_155849-hr9sls11/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.326894760131836, Uncertainty Bias: -2.146489381790161
/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py:240: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(8, 8))
0.00012588501 0.0039100647
0.3266966 6.6982408
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 98 steps.
Found uncertainty sample 1 after 152 steps.
Found uncertainty sample 2 after 309 steps.
Found uncertainty sample 3 after 591 steps.
Found uncertainty sample 4 after 1915 steps.
Found uncertainty sample 5 after 286 steps.
Found uncertainty sample 6 after 136 steps.
Found uncertainty sample 7 after 1715 steps.
Found uncertainty sample 8 after 929 steps.
Found uncertainty sample 9 after 1222 steps.
Found uncertainty sample 10 after 590 steps.
Found uncertainty sample 11 after 1346 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 360 steps.
Found uncertainty sample 14 after 1057 steps.
Found uncertainty sample 15 after 1630 steps.
Found uncertainty sample 16 after 1669 steps.
Found uncertainty sample 17 after 236 steps.
Found uncertainty sample 18 after 1074 steps.
Found uncertainty sample 19 after 49 steps.
Found uncertainty sample 20 after 81 steps.
Found uncertainty sample 21 after 803 steps.
Found uncertainty sample 22 after 359 steps.
Found uncertainty sample 23 after 1524 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 568 steps.
Found uncertainty sample 26 after 783 steps.
Found uncertainty sample 27 after 940 steps.
Found uncertainty sample 28 after 83 steps.
Found uncertainty sample 29 after 474 steps.
Found uncertainty sample 30 after 243 steps.
Found uncertainty sample 31 after 6 steps.
Found uncertainty sample 32 after 15 steps.
Found uncertainty sample 33 after 294 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 3354 steps.
Found uncertainty sample 36 after 65 steps.
Found uncertainty sample 37 after 127 steps.
Found uncertainty sample 38 after 132 steps.
Found uncertainty sample 39 after 1155 steps.
Found uncertainty sample 40 after 23 steps.
Found uncertainty sample 41 after 344 steps.
Found uncertainty sample 42 after 1083 steps.
Found uncertainty sample 43 after 47 steps.
Found uncertainty sample 44 after 421 steps.
Found uncertainty sample 45 after 113 steps.
Found uncertainty sample 46 after 490 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 775 steps.
Found uncertainty sample 49 after 18 steps.
Found uncertainty sample 50 after 670 steps.
Found uncertainty sample 51 after 1627 steps.
Found uncertainty sample 52 after 371 steps.
Found uncertainty sample 53 after 116 steps.
Found uncertainty sample 54 after 1744 steps.
Found uncertainty sample 55 after 355 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 901 steps.
Found uncertainty sample 58 after 2108 steps.
Found uncertainty sample 59 after 436 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1647 steps.
Found uncertainty sample 62 after 165 steps.
Found uncertainty sample 63 after 371 steps.
Found uncertainty sample 64 after 162 steps.
Found uncertainty sample 65 after 101 steps.
Found uncertainty sample 66 after 835 steps.
Found uncertainty sample 67 after 483 steps.
Found uncertainty sample 68 after 16 steps.
Found uncertainty sample 69 after 145 steps.
Found uncertainty sample 70 after 2802 steps.
Found uncertainty sample 71 after 2110 steps.
Found uncertainty sample 72 after 28 steps.
Found uncertainty sample 73 after 1237 steps.
Found uncertainty sample 74 after 326 steps.
Found uncertainty sample 75 after 787 steps.
Found uncertainty sample 76 after 34 steps.
Found uncertainty sample 77 after 221 steps.
Found uncertainty sample 78 after 85 steps.
Found uncertainty sample 79 after 187 steps.
Found uncertainty sample 80 after 35 steps.
Found uncertainty sample 81 after 951 steps.
Found uncertainty sample 82 after 2 steps.
Found uncertainty sample 83 after 465 steps.
Found uncertainty sample 84 after 44 steps.
Found uncertainty sample 85 after 113 steps.
Found uncertainty sample 86 after 46 steps.
Found uncertainty sample 87 after 668 steps.
Found uncertainty sample 88 after 302 steps.
Found uncertainty sample 89 after 909 steps.
Found uncertainty sample 90 after 1354 steps.
Found uncertainty sample 91 after 1574 steps.
Found uncertainty sample 92 after 666 steps.
Found uncertainty sample 93 after 111 steps.
Found uncertainty sample 94 after 1220 steps.
Found uncertainty sample 95 after 2408 steps.
Found uncertainty sample 96 after 487 steps.
Found uncertainty sample 97 after 1394 steps.
Found uncertainty sample 98 after 1156 steps.
Found uncertainty sample 99 after 69 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_161112-v8v0c6r2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v8v0c6r2
Training model 9. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.196770330605574, Training Loss Force: 2.0166909378652513, time: 0.8191723823547363
Validation Loss Energy: 1.1254130056660632, Validation Loss Force: 2.05401532198636, time: 0.06317734718322754
Test Loss Energy: 11.733348218592411, Test Loss Force: 12.174428390883307, time: 8.64088487625122


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4033267532185625, Training Loss Force: 1.7827669652519773, time: 0.7734596729278564
Validation Loss Energy: 1.0441154428093848, Validation Loss Force: 2.2356673638848004, time: 0.06011533737182617
Test Loss Energy: 11.994333622962738, Test Loss Force: 12.280016784851913, time: 8.637510776519775


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5614370707798182, Training Loss Force: 1.8088571784018626, time: 0.814110517501831
Validation Loss Energy: 1.5885116112699853, Validation Loss Force: 1.9703006855506353, time: 0.06057929992675781
Test Loss Energy: 12.986033486776579, Test Loss Force: 12.165699284713662, time: 8.965780258178711


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8367713921625728, Training Loss Force: 1.8004961557355492, time: 0.7636229991912842
Validation Loss Energy: 0.9703366933359634, Validation Loss Force: 2.0914192851193096, time: 0.061875104904174805
Test Loss Energy: 11.746346197730936, Test Loss Force: 12.222601398682745, time: 9.450531721115112


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4725490155562537, Training Loss Force: 1.8089993862619749, time: 0.842841625213623
Validation Loss Energy: 2.148944300285732, Validation Loss Force: 1.9949459292910685, time: 0.06981539726257324
Test Loss Energy: 11.303000731777836, Test Loss Force: 12.11270435440882, time: 10.275820255279541


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2747435486500762, Training Loss Force: 1.7960548788763138, time: 0.8062565326690674
Validation Loss Energy: 0.9487817355036454, Validation Loss Force: 2.0447883579174038, time: 0.06558847427368164
Test Loss Energy: 12.044263730479795, Test Loss Force: 12.054927320904069, time: 9.937238693237305


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.0810923895400149, Training Loss Force: 1.7726715663060753, time: 0.8009123802185059
Validation Loss Energy: 1.299359359100527, Validation Loss Force: 2.076652535368816, time: 0.07183408737182617
Test Loss Energy: 11.828552480075539, Test Loss Force: 12.110078873001449, time: 9.759702920913696


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.142953375339704, Training Loss Force: 1.7919597412044237, time: 0.812964677810669
Validation Loss Energy: 0.8925154411855096, Validation Loss Force: 1.9977693183941465, time: 0.06680965423583984
Test Loss Energy: 12.378286340108865, Test Loss Force: 12.125037287259461, time: 9.736724615097046


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4383363550253503, Training Loss Force: 1.8137191360960203, time: 0.8683137893676758
Validation Loss Energy: 1.540049508679256, Validation Loss Force: 2.175018523270157, time: 0.07026171684265137
Test Loss Energy: 11.481732004419133, Test Loss Force: 11.982550675907692, time: 9.865976572036743


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.39220607839154, Training Loss Force: 1.814814932976177, time: 0.9729440212249756
Validation Loss Energy: 2.1215509852808307, Validation Loss Force: 2.1375645709139466, time: 0.06657695770263672
Test Loss Energy: 13.31072936023802, Test Loss Force: 12.175307549293393, time: 9.701889753341675


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5050409635005846, Training Loss Force: 1.7898649160938862, time: 0.7997126579284668
Validation Loss Energy: 1.5483034085805074, Validation Loss Force: 2.042978837103022, time: 0.06629562377929688
Test Loss Energy: 11.538841147066805, Test Loss Force: 12.183741179335426, time: 9.696871757507324


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.441251347799313, Training Loss Force: 1.7693985735366058, time: 0.8838934898376465
Validation Loss Energy: 3.355342686665883, Validation Loss Force: 2.059626361794594, time: 0.06748509407043457
Test Loss Energy: 14.405522473840925, Test Loss Force: 12.247540608830667, time: 9.855893850326538


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.1855831832404455, Training Loss Force: 1.7750852704388, time: 0.7990145683288574
Validation Loss Energy: 0.7395173834952835, Validation Loss Force: 1.9895768751771712, time: 0.06609129905700684
Test Loss Energy: 12.046972072788824, Test Loss Force: 12.03325979900953, time: 9.701192140579224


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.0865862854212938, Training Loss Force: 1.7644243233720263, time: 0.8044590950012207
Validation Loss Energy: 1.3912931590507382, Validation Loss Force: 1.9734478912591786, time: 0.06971955299377441
Test Loss Energy: 11.484771431266205, Test Loss Force: 12.024247042658958, time: 9.637206792831421


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4984976878031393, Training Loss Force: 1.8006299525837712, time: 0.7999246120452881
Validation Loss Energy: 0.8041012610904059, Validation Loss Force: 2.0706384644064526, time: 0.06347870826721191
Test Loss Energy: 12.140085855708012, Test Loss Force: 12.016704457595662, time: 9.993598699569702


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5218960389433376, Training Loss Force: 1.7951335474732961, time: 0.8235414028167725
Validation Loss Energy: 0.7545568472822516, Validation Loss Force: 2.0735410680581947, time: 0.06442666053771973
Test Loss Energy: 11.78892511772241, Test Loss Force: 12.072041979233138, time: 10.299699306488037


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.188207347527814, Training Loss Force: 1.7722684364212866, time: 0.8215506076812744
Validation Loss Energy: 0.8049906294928848, Validation Loss Force: 2.0380902473387503, time: 0.06421971321105957
Test Loss Energy: 11.987828116532082, Test Loss Force: 11.899068394434291, time: 9.781706809997559


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5848607237520487, Training Loss Force: 1.7930746288128656, time: 1.0249648094177246
Validation Loss Energy: 3.7824084144029055, Validation Loss Force: 2.117991841652321, time: 0.06519770622253418
Test Loss Energy: 14.39282503975905, Test Loss Force: 12.285243489553626, time: 9.787235736846924


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7380295103840997, Training Loss Force: 1.7873522439284055, time: 0.7912099361419678
Validation Loss Energy: 1.963366434342725, Validation Loss Force: 2.1198873127570312, time: 0.06901669502258301
Test Loss Energy: 12.951791565412648, Test Loss Force: 12.10713994804826, time: 9.634355306625366


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.176991949036049, Training Loss Force: 1.7782504556305507, time: 0.8386020660400391
Validation Loss Energy: 0.8763125032774254, Validation Loss Force: 2.0600747061199196, time: 0.06410861015319824
Test Loss Energy: 11.806766861927164, Test Loss Force: 12.090347546766282, time: 9.840383529663086

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–…â–‚â–â–ƒâ–‚â–ƒâ–â–†â–‚â–ˆâ–ƒâ–â–ƒâ–‚â–ƒâ–ˆâ–…â–‚
wandb:   test_error_force â–†â–ˆâ–†â–‡â–…â–„â–…â–…â–ƒâ–†â–†â–‡â–ƒâ–ƒâ–ƒâ–„â–â–ˆâ–…â–„
wandb:          test_loss â–â–…â–…â–…â–„â–„â–„â–…â–ƒâ–†â–…â–ˆâ–…â–†â–…â–„â–ƒâ–ˆâ–…â–…
wandb: train_error_energy â–ˆâ–ƒâ–„â–†â–ƒâ–‚â–â–â–ƒâ–ƒâ–„â–ƒâ–‚â–â–„â–„â–‚â–„â–…â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–‚â–‚â–ƒâ–‚â–„â–â–‚â–â–ƒâ–„â–ƒâ–‡â–â–‚â–â–â–â–ˆâ–„â–
wandb:  valid_error_force â–ƒâ–ˆâ–â–„â–‚â–ƒâ–„â–‚â–†â–…â–ƒâ–ƒâ–‚â–â–„â–„â–ƒâ–…â–…â–ƒ
wandb:         valid_loss â–ƒâ–‡â–â–„â–ƒâ–ƒâ–„â–â–‡â–†â–ƒâ–†â–â–â–ƒâ–ƒâ–‚â–ˆâ–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1686
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.80677
wandb:   test_error_force 12.09035
wandb:          test_loss 11.64092
wandb: train_error_energy 1.17699
wandb:  train_error_force 1.77825
wandb:         train_loss -2.74249
wandb: valid_error_energy 0.87631
wandb:  valid_error_force 2.06007
wandb:         valid_loss -2.36263
wandb: 
wandb: ğŸš€ View run al_59_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v8v0c6r2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_161112-v8v0c6r2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.1651554107666, Uncertainty Bias: -2.35650372505188
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:801: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:622: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:622: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:649: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:649: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:913: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
1.1444092e-05 0.004631996
0.24955688 6.3834257
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2060 steps.
Found uncertainty sample 1 after 3 steps.
Found uncertainty sample 2 after 89 steps.
Found uncertainty sample 3 after 1911 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 581 steps.
Found uncertainty sample 6 after 1623 steps.
Found uncertainty sample 7 after 38 steps.
Found uncertainty sample 8 after 166 steps.
Found uncertainty sample 9 after 582 steps.
Found uncertainty sample 10 after 1628 steps.
Found uncertainty sample 11 after 1278 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 585 steps.
Found uncertainty sample 14 after 2224 steps.
Found uncertainty sample 15 after 152 steps.
Found uncertainty sample 16 after 916 steps.
Found uncertainty sample 17 after 106 steps.
Found uncertainty sample 18 after 678 steps.
Found uncertainty sample 19 after 1233 steps.
Found uncertainty sample 20 after 3193 steps.
Found uncertainty sample 21 after 1720 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 393 steps.
Found uncertainty sample 24 after 2146 steps.
Found uncertainty sample 25 after 74 steps.
Found uncertainty sample 26 after 630 steps.
Found uncertainty sample 27 after 293 steps.
Found uncertainty sample 28 after 917 steps.
Found uncertainty sample 29 after 200 steps.
Found uncertainty sample 30 after 122 steps.
Found uncertainty sample 31 after 278 steps.
Found uncertainty sample 32 after 313 steps.
Found uncertainty sample 33 after 654 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 634 steps.
Found uncertainty sample 36 after 390 steps.
Found uncertainty sample 37 after 199 steps.
Found uncertainty sample 38 after 378 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1941 steps.
Found uncertainty sample 41 after 122 steps.
Found uncertainty sample 42 after 14 steps.
Found uncertainty sample 43 after 969 steps.
Found uncertainty sample 44 after 1375 steps.
Found uncertainty sample 45 after 75 steps.
Found uncertainty sample 46 after 331 steps.
Found uncertainty sample 47 after 107 steps.
Found uncertainty sample 48 after 307 steps.
Found uncertainty sample 49 after 141 steps.
Found uncertainty sample 50 after 246 steps.
Found uncertainty sample 51 after 380 steps.
Found uncertainty sample 52 after 128 steps.
Found uncertainty sample 53 after 2986 steps.
Found uncertainty sample 54 after 2058 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 3140 steps.
Found uncertainty sample 57 after 154 steps.
Found uncertainty sample 58 after 439 steps.
Found uncertainty sample 59 after 160 steps.
Found uncertainty sample 60 after 552 steps.
Found uncertainty sample 61 after 191 steps.
Found uncertainty sample 62 after 2519 steps.
Found uncertainty sample 63 after 2340 steps.
Found uncertainty sample 64 after 336 steps.
Found uncertainty sample 65 after 82 steps.
Found uncertainty sample 66 after 1143 steps.
Found uncertainty sample 67 after 1252 steps.
Found uncertainty sample 68 after 1488 steps.
Found uncertainty sample 69 after 265 steps.
Found uncertainty sample 70 after 2059 steps.
Found uncertainty sample 71 after 35 steps.
Found uncertainty sample 72 after 954 steps.
Found uncertainty sample 73 after 359 steps.
Found uncertainty sample 74 after 3042 steps.
Found uncertainty sample 75 after 736 steps.
Found uncertainty sample 76 after 133 steps.
Found uncertainty sample 77 after 182 steps.
Found uncertainty sample 78 after 174 steps.
Found uncertainty sample 79 after 3382 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1002 steps.
Found uncertainty sample 82 after 248 steps.
Found uncertainty sample 83 after 1400 steps.
Found uncertainty sample 84 after 1966 steps.
Found uncertainty sample 85 after 644 steps.
Found uncertainty sample 86 after 822 steps.
Found uncertainty sample 87 after 14 steps.
Found uncertainty sample 88 after 101 steps.
Found uncertainty sample 89 after 4 steps.
Found uncertainty sample 90 after 358 steps.
Found uncertainty sample 91 after 65 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 5 steps.
Found uncertainty sample 94 after 1182 steps.
Found uncertainty sample 95 after 492 steps.
Found uncertainty sample 96 after 2 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3915 steps.
Found uncertainty sample 99 after 1131 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_162625-uzaixod5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/uzaixod5
Training model 10. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8278540369583687, Training Loss Force: 2.0929355844665, time: 0.8509159088134766
Validation Loss Energy: 1.5997316868641405, Validation Loss Force: 2.025632910635247, time: 0.07103705406188965
Test Loss Energy: 12.7072398061902, Test Loss Force: 12.297301944793185, time: 9.884539365768433


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3639720698649005, Training Loss Force: 1.8154547423450538, time: 0.8509275913238525
Validation Loss Energy: 1.317275930922028, Validation Loss Force: 2.0706762068266875, time: 0.07443761825561523
Test Loss Energy: 11.305198767699906, Test Loss Force: 12.13742384723425, time: 10.092857837677002


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.0129764341524445, Training Loss Force: 1.808010992321383, time: 0.8494174480438232
Validation Loss Energy: 0.7286433079202567, Validation Loss Force: 2.0224767981608665, time: 0.06629276275634766
Test Loss Energy: 11.80517980216215, Test Loss Force: 12.084849106431657, time: 10.013253688812256


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4515718450142132, Training Loss Force: 1.8266456721385012, time: 0.7936420440673828
Validation Loss Energy: 1.871039400680805, Validation Loss Force: 2.060344135786492, time: 0.06452393531799316
Test Loss Energy: 11.513893431190676, Test Loss Force: 12.035024602380116, time: 9.802209615707397


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2265349944380193, Training Loss Force: 1.7824967146429755, time: 0.8606688976287842
Validation Loss Energy: 0.7932451382152697, Validation Loss Force: 2.0391996963583354, time: 0.07289004325866699
Test Loss Energy: 11.76003675019334, Test Loss Force: 12.18124515846898, time: 10.203005075454712


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2019533197565724, Training Loss Force: 1.8030339194052483, time: 0.8445703983306885
Validation Loss Energy: 1.8595485037379154, Validation Loss Force: 2.219365867046, time: 0.07403302192687988
Test Loss Energy: 12.940326198186826, Test Loss Force: 12.087099216622889, time: 9.942498922348022


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5522480894213402, Training Loss Force: 1.8112853997676548, time: 0.8496754169464111
Validation Loss Energy: 0.8030372365765901, Validation Loss Force: 2.0128667318263425, time: 0.07978153228759766
Test Loss Energy: 12.195188611785648, Test Loss Force: 12.053134113810593, time: 9.814505815505981


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.437859666279421, Training Loss Force: 1.819108860328654, time: 0.8665628433227539
Validation Loss Energy: 1.2458489573006095, Validation Loss Force: 2.198743252761325, time: 0.07038450241088867
Test Loss Energy: 11.778310971506604, Test Loss Force: 11.976529981995498, time: 9.986056327819824


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2058757878590107, Training Loss Force: 1.8033506026455746, time: 0.9238386154174805
Validation Loss Energy: 2.497961041003303, Validation Loss Force: 2.2578757164922, time: 0.06711483001708984
Test Loss Energy: 12.952573411576935, Test Loss Force: 12.092383213746109, time: 10.250118732452393


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4152864484071277, Training Loss Force: 1.8322681654909292, time: 0.8560135364532471
Validation Loss Energy: 0.7557290611673453, Validation Loss Force: 2.0158401442664893, time: 0.06748080253601074
Test Loss Energy: 12.108990233054744, Test Loss Force: 12.046562622701094, time: 9.708988666534424


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3248117506613057, Training Loss Force: 1.8003633946589672, time: 0.8918411731719971
Validation Loss Energy: 1.0775313458714815, Validation Loss Force: 2.1544710598222325, time: 0.06632256507873535
Test Loss Energy: 12.223381225669225, Test Loss Force: 11.795368010988197, time: 9.954836368560791


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9793413411523224, Training Loss Force: 1.9158138755695897, time: 0.8778150081634521
Validation Loss Energy: 0.9284063396382367, Validation Loss Force: 2.020416663222743, time: 0.06792068481445312
Test Loss Energy: 12.499240607224781, Test Loss Force: 12.042782339465502, time: 9.947991609573364


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.371644144733897, Training Loss Force: 1.8041127394885643, time: 0.8612809181213379
Validation Loss Energy: 3.1819445446686934, Validation Loss Force: 2.0354881356994383, time: 0.0755774974822998
Test Loss Energy: 11.364425626827353, Test Loss Force: 12.106969502394803, time: 9.838258028030396


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.772934380024433, Training Loss Force: 1.8203500121837035, time: 0.9247283935546875
Validation Loss Energy: 1.0172585656106667, Validation Loss Force: 2.002235504788593, time: 0.06822824478149414
Test Loss Energy: 11.827578984559228, Test Loss Force: 12.040455015541948, time: 10.01228141784668


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.665264282141601, Training Loss Force: 1.8094719544095756, time: 0.9259147644042969
Validation Loss Energy: 0.8361647274274238, Validation Loss Force: 2.0515030573474293, time: 0.07027530670166016
Test Loss Energy: 12.001476891133155, Test Loss Force: 11.978941393249714, time: 9.809839963912964


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2266324251121254, Training Loss Force: 1.8087736043244251, time: 0.9248268604278564
Validation Loss Energy: 1.4324389936800748, Validation Loss Force: 2.3059636792504845, time: 0.07187318801879883
Test Loss Energy: 12.601442238458036, Test Loss Force: 12.121285864743118, time: 10.381779670715332


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2554458384407072, Training Loss Force: 1.8240793008852276, time: 0.871086835861206
Validation Loss Energy: 1.285595455516006, Validation Loss Force: 2.089627243832883, time: 0.0680234432220459
Test Loss Energy: 11.816225875225546, Test Loss Force: 12.184593864599098, time: 10.054239273071289


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.263436361498732, Training Loss Force: 1.8051228999383564, time: 0.8692505359649658
Validation Loss Energy: 0.9059828608022276, Validation Loss Force: 2.095734835836536, time: 0.0665597915649414
Test Loss Energy: 12.003681017231234, Test Loss Force: 11.939946126814103, time: 9.186585664749146


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4519663879012126, Training Loss Force: 1.7979898210880718, time: 0.8162059783935547
Validation Loss Energy: 2.84925924979005, Validation Loss Force: 2.1826308020274174, time: 0.062192678451538086
Test Loss Energy: 14.170573192132027, Test Loss Force: 12.204422512406529, time: 9.803006172180176


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.488454743458577, Training Loss Force: 1.793485739188353, time: 0.8896143436431885
Validation Loss Energy: 0.8038741385615595, Validation Loss Force: 2.1408393660431067, time: 0.06927371025085449
Test Loss Energy: 12.228134622036418, Test Loss Force: 12.063726711248947, time: 9.674412965774536

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–‚â–‚â–‚â–…â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–â–‚â–ƒâ–„â–‚â–ƒâ–ˆâ–ƒ
wandb:   test_error_force â–ˆâ–†â–…â–„â–†â–…â–…â–„â–…â–…â–â–„â–…â–„â–„â–†â–†â–ƒâ–‡â–…
wandb:          test_loss â–‚â–ƒâ–„â–ƒâ–†â–…â–ƒâ–ƒâ–…â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–†â–…â–ƒâ–ˆâ–…
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–†â–„â–„â–‚â–‚â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–„â–â–‚â–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–‚â–‚â–â–‚â–â–„â–‚â–‚â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–ƒâ–ƒâ–â–„â–â–„â–â–‚â–†â–â–‚â–‚â–ˆâ–‚â–â–ƒâ–ƒâ–‚â–‡â–
wandb:  valid_error_force â–‚â–ƒâ–â–‚â–‚â–†â–â–†â–‡â–â–…â–â–‚â–â–‚â–ˆâ–ƒâ–ƒâ–…â–„
wandb:         valid_loss â–‚â–ƒâ–â–ƒâ–‚â–‡â–â–…â–ˆâ–â–„â–â–„â–â–‚â–ˆâ–ƒâ–ƒâ–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1775
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.22813
wandb:   test_error_force 12.06373
wandb:          test_loss 11.60833
wandb: train_error_energy 1.48845
wandb:  train_error_force 1.79349
wandb:         train_loss -2.70022
wandb: valid_error_energy 0.80387
wandb:  valid_error_force 2.14084
wandb:         valid_loss -2.25583
wandb: 
wandb: ğŸš€ View run al_59_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/uzaixod5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_162625-uzaixod5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.576736450195312, Uncertainty Bias: -2.4180305004119873
0.00010681152 0.0020299107
0.35223052 6.1675434
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1325 steps.
Found uncertainty sample 1 after 378 steps.
Found uncertainty sample 2 after 1889 steps.
Found uncertainty sample 3 after 164 steps.
Found uncertainty sample 4 after 1257 steps.
Found uncertainty sample 5 after 1981 steps.
Found uncertainty sample 6 after 100 steps.
Found uncertainty sample 7 after 112 steps.
Found uncertainty sample 8 after 827 steps.
Found uncertainty sample 9 after 1108 steps.
Found uncertainty sample 10 after 409 steps.
Found uncertainty sample 11 after 94 steps.
Found uncertainty sample 12 after 710 steps.
Found uncertainty sample 13 after 71 steps.
Found uncertainty sample 14 after 2130 steps.
Found uncertainty sample 15 after 501 steps.
Found uncertainty sample 16 after 2758 steps.
Found uncertainty sample 17 after 68 steps.
Found uncertainty sample 18 after 231 steps.
Found uncertainty sample 19 after 326 steps.
Found uncertainty sample 20 after 2262 steps.
Found uncertainty sample 21 after 297 steps.
Found uncertainty sample 22 after 873 steps.
Found uncertainty sample 23 after 1111 steps.
Found uncertainty sample 24 after 586 steps.
Found uncertainty sample 25 after 354 steps.
Found uncertainty sample 26 after 112 steps.
Found uncertainty sample 27 after 1767 steps.
Found uncertainty sample 28 after 910 steps.
Found uncertainty sample 29 after 1218 steps.
Found uncertainty sample 30 after 41 steps.
Found uncertainty sample 31 after 2761 steps.
Found uncertainty sample 32 after 458 steps.
Found uncertainty sample 33 after 1741 steps.
Found uncertainty sample 34 after 1778 steps.
Found uncertainty sample 35 after 2648 steps.
Found uncertainty sample 36 after 539 steps.
Found uncertainty sample 37 after 188 steps.
Found uncertainty sample 38 after 207 steps.
Found uncertainty sample 39 after 267 steps.
Found uncertainty sample 40 after 123 steps.
Found uncertainty sample 41 after 166 steps.
Found uncertainty sample 42 after 441 steps.
Found uncertainty sample 43 after 306 steps.
Found uncertainty sample 44 after 505 steps.
Found uncertainty sample 45 after 131 steps.
Found uncertainty sample 46 after 132 steps.
Found uncertainty sample 47 after 66 steps.
Found uncertainty sample 48 after 12 steps.
Found uncertainty sample 49 after 318 steps.
Found uncertainty sample 50 after 2721 steps.
Found uncertainty sample 51 after 1154 steps.
Found uncertainty sample 52 after 1267 steps.
Found uncertainty sample 53 after 311 steps.
Found uncertainty sample 54 after 2934 steps.
Found uncertainty sample 55 after 340 steps.
Found uncertainty sample 56 after 478 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 46 steps.
Found uncertainty sample 59 after 445 steps.
Found uncertainty sample 60 after 314 steps.
Found uncertainty sample 61 after 526 steps.
Found uncertainty sample 62 after 247 steps.
Found uncertainty sample 63 after 2 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 299 steps.
Found uncertainty sample 66 after 824 steps.
Found uncertainty sample 67 after 175 steps.
Found uncertainty sample 68 after 529 steps.
Found uncertainty sample 69 after 370 steps.
Found uncertainty sample 70 after 135 steps.
Found uncertainty sample 71 after 336 steps.
Found uncertainty sample 72 after 3656 steps.
Found uncertainty sample 73 after 481 steps.
Found uncertainty sample 74 after 68 steps.
Found uncertainty sample 75 after 35 steps.
Found uncertainty sample 76 after 1785 steps.
Found uncertainty sample 77 after 32 steps.
Found uncertainty sample 78 after 1465 steps.
Found uncertainty sample 79 after 1965 steps.
Found uncertainty sample 80 after 1404 steps.
Found uncertainty sample 81 after 812 steps.
Found uncertainty sample 82 after 436 steps.
Found uncertainty sample 83 after 533 steps.
Found uncertainty sample 84 after 1616 steps.
Found uncertainty sample 85 after 653 steps.
Found uncertainty sample 86 after 1257 steps.
Found uncertainty sample 87 after 1046 steps.
Found uncertainty sample 88 after 60 steps.
Found uncertainty sample 89 after 435 steps.
Found uncertainty sample 90 after 92 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 434 steps.
Found uncertainty sample 93 after 23 steps.
Found uncertainty sample 94 after 2747 steps.
Found uncertainty sample 95 after 309 steps.
Found uncertainty sample 96 after 189 steps.
Found uncertainty sample 97 after 2069 steps.
Found uncertainty sample 98 after 2254 steps.
Found uncertainty sample 99 after 11 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_164013-1z30mqpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1z30mqpj
Training model 11. Added 101 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4325728800943063, Training Loss Force: 2.218673875499363, time: 0.9170615673065186
Validation Loss Energy: 2.3403627222591386, Validation Loss Force: 2.060865960929974, time: 0.07264852523803711
Test Loss Energy: 13.421386823142706, Test Loss Force: 12.147325372908208, time: 10.072427749633789


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.301576041770398, Training Loss Force: 1.8459962037749853, time: 0.9314789772033691
Validation Loss Energy: 1.004860264064478, Validation Loss Force: 2.113137320267376, time: 0.08000898361206055
Test Loss Energy: 11.859876670858394, Test Loss Force: 11.791011613889475, time: 9.017502069473267


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6657264343801517, Training Loss Force: 1.8269992893766227, time: 0.9406867027282715
Validation Loss Energy: 2.52833712055248, Validation Loss Force: 2.037249671312873, time: 0.07474875450134277
Test Loss Energy: 13.588039938405359, Test Loss Force: 12.168678374051224, time: 11.008018255233765


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2683909777361557, Training Loss Force: 1.791990172535686, time: 0.996086597442627
Validation Loss Energy: 2.363598804309568, Validation Loss Force: 2.208274716887337, time: 0.0673377513885498
Test Loss Energy: 11.398176985912471, Test Loss Force: 11.700827009776564, time: 8.093384265899658


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6521091499366038, Training Loss Force: 1.8865201277255559, time: 0.8881371021270752
Validation Loss Energy: 1.0921366048238905, Validation Loss Force: 2.184224111101104, time: 0.06378793716430664
Test Loss Energy: 12.21513566361997, Test Loss Force: 11.833357857447332, time: 8.038211345672607


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2224299110322139, Training Loss Force: 1.8140441701363181, time: 0.8738656044006348
Validation Loss Energy: 1.2745439404653183, Validation Loss Force: 2.195132561225533, time: 0.06234931945800781
Test Loss Energy: 12.807107547674619, Test Loss Force: 11.832245901359693, time: 8.571316003799438


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.462775954694825, Training Loss Force: 1.8195578412559021, time: 0.899289608001709
Validation Loss Energy: 1.4286841517059377, Validation Loss Force: 2.0050459234139204, time: 0.06914424896240234
Test Loss Energy: 13.080271126341739, Test Loss Force: 12.036691016299187, time: 8.054725885391235


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.1260680096031297, Training Loss Force: 1.816968578381121, time: 0.868621826171875
Validation Loss Energy: 1.1952126018344686, Validation Loss Force: 1.9896009234449314, time: 0.06290769577026367
Test Loss Energy: 12.600667461747687, Test Loss Force: 12.090372578975188, time: 8.020479917526245


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3833084387850274, Training Loss Force: 1.832841910757702, time: 0.9087579250335693
Validation Loss Energy: 1.4701236591051097, Validation Loss Force: 2.1484577682018795, time: 0.06232190132141113
Test Loss Energy: 13.184198054076385, Test Loss Force: 12.004220506100184, time: 8.068664312362671


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1285101410091996, Training Loss Force: 1.8206417229512655, time: 1.1371755599975586
Validation Loss Energy: 2.9484062497207324, Validation Loss Force: 2.090650408558421, time: 0.06656098365783691
Test Loss Energy: 14.293782479818455, Test Loss Force: 12.084462366265198, time: 8.037777185440063


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.721365989118297, Training Loss Force: 1.8122024717433227, time: 0.8988082408905029
Validation Loss Energy: 2.1701545384465106, Validation Loss Force: 1.9854602236745449, time: 0.06435728073120117
Test Loss Energy: 13.579874723777763, Test Loss Force: 11.8923155503806, time: 8.089611053466797


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.624956566696824, Training Loss Force: 1.8221476589165222, time: 0.9196348190307617
Validation Loss Energy: 1.8427750596443209, Validation Loss Force: 2.0434323028187036, time: 0.06591010093688965
Test Loss Energy: 11.61127720625351, Test Loss Force: 11.901548229235699, time: 7.962727069854736


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2460360607115555, Training Loss Force: 1.8155114956490757, time: 0.9128594398498535
Validation Loss Energy: 3.877656143584674, Validation Loss Force: 2.2248030022512646, time: 0.06779170036315918
Test Loss Energy: 11.029420782792355, Test Loss Force: 11.764368152388979, time: 8.310697555541992


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3598628779050261, Training Loss Force: 1.8445303369338364, time: 0.9038660526275635
Validation Loss Energy: 1.3103063309872018, Validation Loss Force: 2.191324139488157, time: 0.0606846809387207
Test Loss Energy: 12.650413045325388, Test Loss Force: 12.075506762439284, time: 8.01418948173523


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.350967329497897, Training Loss Force: 1.814894396416537, time: 0.8767335414886475
Validation Loss Energy: 3.9569202361334526, Validation Loss Force: 1.998458702069939, time: 0.07177400588989258
Test Loss Energy: 14.980821932148388, Test Loss Force: 12.064379488583471, time: 8.321206092834473


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2728443578241713, Training Loss Force: 1.8096561934488389, time: 0.9948718547821045
Validation Loss Energy: 1.1085691981223558, Validation Loss Force: 2.0409027813209644, time: 0.07677006721496582
Test Loss Energy: 12.887637725911976, Test Loss Force: 11.927069410261351, time: 11.115370512008667


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7255363755921054, Training Loss Force: 1.7945252758582875, time: 0.9123165607452393
Validation Loss Energy: 1.9412312842170487, Validation Loss Force: 2.088444870668006, time: 0.06906652450561523
Test Loss Energy: 13.616737160211049, Test Loss Force: 11.944761241006354, time: 10.358378171920776


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7453923211370843, Training Loss Force: 1.8030589444451832, time: 0.8525159358978271
Validation Loss Energy: 1.9818584945718762, Validation Loss Force: 2.1712919324439097, time: 0.06415128707885742
Test Loss Energy: 13.421374838646264, Test Loss Force: 11.858472325700202, time: 8.88783884048462


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.554541663971207, Training Loss Force: 1.803723089139393, time: 0.8753619194030762
Validation Loss Energy: 0.9384008164195623, Validation Loss Force: 2.0450439820969293, time: 0.06647539138793945
Test Loss Energy: 12.654587110202003, Test Loss Force: 11.828802928071775, time: 9.119491577148438


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5206104554427404, Training Loss Force: 1.8028701681851032, time: 0.8634493350982666
Validation Loss Energy: 1.1217457004999192, Validation Loss Force: 2.147547385398754, time: 0.06715583801269531
Test Loss Energy: 12.206546818027736, Test Loss Force: 11.8098886880163, time: 8.896759510040283

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–†â–‚â–ƒâ–„â–…â–„â–…â–‡â–†â–‚â–â–„â–ˆâ–„â–†â–…â–„â–ƒ
wandb:   test_error_force â–ˆâ–‚â–ˆâ–â–ƒâ–ƒâ–†â–‡â–†â–‡â–„â–„â–‚â–‡â–†â–„â–…â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–„â–â–‡â–„â–…â–†â–‡â–ˆâ–‡â–ˆâ–†â–…â–ƒâ–‡â–ˆâ–†â–†â–†â–„â–„
wandb: train_error_energy â–ˆâ–‚â–„â–‚â–„â–‚â–ƒâ–â–‚â–â–„â–„â–‚â–‚â–‚â–‚â–„â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–ƒâ–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–ƒâ–â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–„â–â–…â–„â–â–‚â–‚â–‚â–‚â–†â–„â–ƒâ–ˆâ–‚â–ˆâ–â–ƒâ–ƒâ–â–
wandb:  valid_error_force â–ƒâ–…â–ƒâ–ˆâ–‡â–‡â–‚â–â–†â–„â–â–ƒâ–ˆâ–‡â–â–ƒâ–„â–†â–ƒâ–†
wandb:         valid_loss â–ƒâ–ƒâ–ƒâ–†â–…â–…â–‚â–â–„â–…â–‚â–ƒâ–ˆâ–…â–„â–‚â–„â–…â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1865
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.20655
wandb:   test_error_force 11.80989
wandb:          test_loss 11.09849
wandb: train_error_energy 1.52061
wandb:  train_error_force 1.80287
wandb:         train_loss -2.68524
wandb: valid_error_energy 1.12175
wandb:  valid_error_force 2.14755
wandb:         valid_loss -2.23167
wandb: 
wandb: ğŸš€ View run al_59_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1z30mqpj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_164013-1z30mqpj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 22.312707901000977, Uncertainty Bias: -2.538860321044922
0.00034332275 0.0032539368
0.3254176 6.307348
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2061 steps.
Found uncertainty sample 1 after 1141 steps.
Found uncertainty sample 2 after 2117 steps.
Found uncertainty sample 3 after 3759 steps.
Found uncertainty sample 4 after 682 steps.
Found uncertainty sample 5 after 1739 steps.
Found uncertainty sample 6 after 3017 steps.
Found uncertainty sample 7 after 3588 steps.
Found uncertainty sample 8 after 1730 steps.
Found uncertainty sample 9 after 1990 steps.
Found uncertainty sample 10 after 1292 steps.
Found uncertainty sample 11 after 103 steps.
Found uncertainty sample 12 after 2501 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 701 steps.
Found uncertainty sample 15 after 30 steps.
Found uncertainty sample 16 after 97 steps.
Found uncertainty sample 17 after 347 steps.
Found uncertainty sample 18 after 1739 steps.
Found uncertainty sample 19 after 640 steps.
Found uncertainty sample 20 after 796 steps.
Found uncertainty sample 21 after 2439 steps.
Found uncertainty sample 22 after 10 steps.
Found uncertainty sample 23 after 1239 steps.
Found uncertainty sample 24 after 1552 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1120 steps.
Found uncertainty sample 28 after 147 steps.
Found uncertainty sample 29 after 558 steps.
Found uncertainty sample 30 after 120 steps.
Found uncertainty sample 31 after 155 steps.
Found uncertainty sample 32 after 3207 steps.
Found uncertainty sample 33 after 83 steps.
Found uncertainty sample 34 after 1458 steps.
Found uncertainty sample 35 after 5 steps.
Found uncertainty sample 36 after 391 steps.
Found uncertainty sample 37 after 606 steps.
Found uncertainty sample 38 after 636 steps.
Found uncertainty sample 39 after 44 steps.
Found uncertainty sample 40 after 578 steps.
Found uncertainty sample 41 after 271 steps.
Found uncertainty sample 42 after 721 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 59 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 83 steps.
Found uncertainty sample 47 after 36 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 54 steps.
Found uncertainty sample 50 after 448 steps.
Found uncertainty sample 51 after 1408 steps.
Found uncertainty sample 52 after 16 steps.
Found uncertainty sample 53 after 1331 steps.
Found uncertainty sample 54 after 1956 steps.
Found uncertainty sample 55 after 242 steps.
Found uncertainty sample 56 after 1588 steps.
Found uncertainty sample 57 after 265 steps.
Found uncertainty sample 58 after 106 steps.
Found uncertainty sample 59 after 972 steps.
Found uncertainty sample 60 after 995 steps.
Found uncertainty sample 61 after 1069 steps.
Found uncertainty sample 62 after 1383 steps.
Found uncertainty sample 63 after 1227 steps.
Found uncertainty sample 64 after 3344 steps.
Found uncertainty sample 65 after 425 steps.
Found uncertainty sample 66 after 3867 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 73 steps.
Found uncertainty sample 69 after 473 steps.
Found uncertainty sample 70 after 28 steps.
Found uncertainty sample 71 after 67 steps.
Found uncertainty sample 72 after 387 steps.
Found uncertainty sample 73 after 1156 steps.
Found uncertainty sample 74 after 120 steps.
Found uncertainty sample 75 after 54 steps.
Found uncertainty sample 76 after 2370 steps.
Found uncertainty sample 77 after 210 steps.
Found uncertainty sample 78 after 704 steps.
Found uncertainty sample 79 after 2415 steps.
Found uncertainty sample 80 after 383 steps.
Found uncertainty sample 81 after 67 steps.
Found uncertainty sample 82 after 1058 steps.
Found uncertainty sample 83 after 507 steps.
Found uncertainty sample 84 after 283 steps.
Found uncertainty sample 85 after 2312 steps.
Found uncertainty sample 86 after 241 steps.
Found uncertainty sample 87 after 189 steps.
Found uncertainty sample 88 after 567 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 353 steps.
Found uncertainty sample 91 after 180 steps.
Found uncertainty sample 92 after 22 steps.
Found uncertainty sample 93 after 377 steps.
Found uncertainty sample 94 after 22 steps.
Found uncertainty sample 95 after 831 steps.
Found uncertainty sample 96 after 1475 steps.
Found uncertainty sample 97 after 695 steps.
Found uncertainty sample 98 after 299 steps.
Found uncertainty sample 99 after 76 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_165609-m17ze3am
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m17ze3am
Training model 12. Added 96 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.1179042377698107, Training Loss Force: 2.1317557662261466, time: 0.9387178421020508
Validation Loss Energy: 1.4462265836949935, Validation Loss Force: 2.1655667746983873, time: 0.07060837745666504
Test Loss Energy: 11.9226109490873, Test Loss Force: 11.820988877842804, time: 9.06901240348816


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.1300751162693075, Training Loss Force: 1.818855594121519, time: 0.908780574798584
Validation Loss Energy: 0.9796093602471208, Validation Loss Force: 2.040289327823933, time: 0.06989693641662598
Test Loss Energy: 12.98670067814943, Test Loss Force: 11.120050729860353, time: 9.035840272903442


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5909637296873178, Training Loss Force: 1.8634046323398064, time: 0.9367785453796387
Validation Loss Energy: 4.691663175635396, Validation Loss Force: 2.0881132049751465, time: 0.06982231140136719
Test Loss Energy: 15.597131740382064, Test Loss Force: 11.111851697501947, time: 9.208040952682495


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7532523093426955, Training Loss Force: 1.8356475051529704, time: 0.9419362545013428
Validation Loss Energy: 1.6516079754693804, Validation Loss Force: 2.031011595189706, time: 0.06762051582336426
Test Loss Energy: 11.817299000612072, Test Loss Force: 10.977926148228878, time: 9.071160554885864


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3948210340906575, Training Loss Force: 1.845471737227267, time: 0.889298677444458
Validation Loss Energy: 0.8436565143430939, Validation Loss Force: 2.1330024141176054, time: 0.0709218978881836
Test Loss Energy: 12.306188360302487, Test Loss Force: 10.919342819254458, time: 9.047063827514648


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5810710688292569, Training Loss Force: 1.8645466731867588, time: 0.8946371078491211
Validation Loss Energy: 1.8203800546253472, Validation Loss Force: 2.0211524734154613, time: 0.06630635261535645
Test Loss Energy: 13.372002760993425, Test Loss Force: 10.8747540479144, time: 9.734681844711304


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7215098881103394, Training Loss Force: 1.8337249614954603, time: 0.8911652565002441
Validation Loss Energy: 0.8512045252181107, Validation Loss Force: 2.05941170873792, time: 0.06660079956054688
Test Loss Energy: 12.257572373804654, Test Loss Force: 10.668475346988563, time: 9.076611995697021


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6868592910221225, Training Loss Force: 1.8279992835802117, time: 0.8814690113067627
Validation Loss Energy: 2.3417035245213427, Validation Loss Force: 2.0333591959952226, time: 0.07347321510314941
Test Loss Energy: 11.55224374518866, Test Loss Force: 10.692413035618765, time: 9.119740009307861


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.210289136840209, Training Loss Force: 1.8269944744579567, time: 0.9278874397277832
Validation Loss Energy: 1.1137089030159475, Validation Loss Force: 2.1289875780819543, time: 0.06689643859863281
Test Loss Energy: 12.261705807974073, Test Loss Force: 10.805616765673616, time: 9.182744979858398


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1886039531480836, Training Loss Force: 1.8353036109086538, time: 0.8795361518859863
Validation Loss Energy: 2.1298582144425318, Validation Loss Force: 2.1465304554093017, time: 0.06727886199951172
Test Loss Energy: 13.276895788439964, Test Loss Force: 10.952599726928455, time: 9.061093091964722


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.223944624277703, Training Loss Force: 1.846361906417351, time: 0.8726804256439209
Validation Loss Energy: 2.7495120451765196, Validation Loss Force: 2.1210885014647385, time: 0.06649112701416016
Test Loss Energy: 11.23261533184958, Test Loss Force: 10.733082806674357, time: 9.074107646942139


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7095341327525053, Training Loss Force: 1.8219834312646803, time: 0.9006757736206055
Validation Loss Energy: 1.1772416430740746, Validation Loss Force: 1.996894562654369, time: 0.06565213203430176
Test Loss Energy: 11.959002660614477, Test Loss Force: 10.747810129996331, time: 9.223315000534058


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4056742987700355, Training Loss Force: 1.8309921558435869, time: 0.896883487701416
Validation Loss Energy: 4.150728566050102, Validation Loss Force: 1.9849965708454365, time: 0.06721806526184082
Test Loss Energy: 11.045791199229239, Test Loss Force: 10.763045656589355, time: 9.083384275436401


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3069025876080878, Training Loss Force: 1.818939861617154, time: 0.9150338172912598
Validation Loss Energy: 2.434813184563912, Validation Loss Force: 2.0169409091893833, time: 0.06644558906555176
Test Loss Energy: 14.294419523421078, Test Loss Force: 10.73830613519886, time: 9.085872888565063


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8024811110820917, Training Loss Force: 1.844676644112181, time: 0.8917043209075928
Validation Loss Energy: 0.7200896675149434, Validation Loss Force: 2.0270237021207125, time: 0.06663346290588379
Test Loss Energy: 12.517759699313377, Test Loss Force: 10.817569831956147, time: 9.215473175048828


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8419145629430893, Training Loss Force: 1.8252717508067202, time: 0.9210984706878662
Validation Loss Energy: 0.7778082100028204, Validation Loss Force: 2.061170349652457, time: 0.07508635520935059
Test Loss Energy: 12.000993845978178, Test Loss Force: 10.772259831755008, time: 9.092646598815918


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.0485554564534003, Training Loss Force: 1.8060000556291333, time: 0.9085071086883545
Validation Loss Energy: 1.4019546134250471, Validation Loss Force: 2.0053300492441246, time: 0.06891083717346191
Test Loss Energy: 11.679757682130619, Test Loss Force: 10.667201143202616, time: 9.432579517364502


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.1626246556632092, Training Loss Force: 1.8542152373011764, time: 0.9105129241943359
Validation Loss Energy: 1.2079240597007617, Validation Loss Force: 2.0795496836264826, time: 0.07187604904174805
Test Loss Energy: 12.836153644233885, Test Loss Force: 10.814240021226643, time: 9.191616773605347


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6340144117088233, Training Loss Force: 1.8174106666562395, time: 0.9401185512542725
Validation Loss Energy: 1.32529357885945, Validation Loss Force: 2.121670224608475, time: 0.06616854667663574
Test Loss Energy: 12.771001332966732, Test Loss Force: 10.839060300402883, time: 9.066248893737793


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3611329827907352, Training Loss Force: 1.8250991566664292, time: 0.8807671070098877
Validation Loss Energy: 1.0482131117673208, Validation Loss Force: 2.187584077178581, time: 0.06748795509338379
Test Loss Energy: 12.160184014788511, Test Loss Force: 10.63189820685576, time: 9.006958961486816

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ˆâ–‚â–ƒâ–…â–ƒâ–‚â–ƒâ–„â–â–‚â–â–†â–ƒâ–‚â–‚â–„â–„â–ƒ
wandb:   test_error_force â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–
wandb:          test_loss â–ˆâ–…â–…â–ƒâ–ƒâ–ƒâ–â–â–‚â–„â–â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–…â–†â–ƒâ–„â–…â–…â–‚â–‚â–‚â–…â–ƒâ–ƒâ–†â–†â–â–‚â–…â–ƒ
wandb:  train_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–â–ˆâ–ƒâ–â–ƒâ–â–„â–‚â–ƒâ–…â–‚â–‡â–„â–â–â–‚â–‚â–‚â–‚
wandb:  valid_error_force â–‡â–ƒâ–…â–ƒâ–†â–‚â–„â–ƒâ–†â–‡â–†â–â–â–‚â–‚â–„â–‚â–„â–†â–ˆ
wandb:         valid_loss â–†â–‚â–ˆâ–ƒâ–„â–‚â–‚â–„â–…â–†â–†â–â–…â–ƒâ–â–‚â–‚â–ƒâ–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1951
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.16018
wandb:   test_error_force 10.6319
wandb:          test_loss 9.6133
wandb: train_error_energy 1.36113
wandb:  train_error_force 1.8251
wandb:         train_loss -2.66519
wandb: valid_error_energy 1.04821
wandb:  valid_error_force 2.18758
wandb:         valid_loss -2.18274
wandb: 
wandb: ğŸš€ View run al_59_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m17ze3am
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_165609-m17ze3am/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 22.406190872192383, Uncertainty Bias: -2.563122034072876
3.8146973e-06 0.00012862682
0.37153682 5.907188
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 919 steps.
Found uncertainty sample 1 after 92 steps.
Found uncertainty sample 2 after 756 steps.
Found uncertainty sample 3 after 381 steps.
Found uncertainty sample 4 after 142 steps.
Found uncertainty sample 5 after 2534 steps.
Found uncertainty sample 6 after 160 steps.
Found uncertainty sample 7 after 53 steps.
Found uncertainty sample 8 after 82 steps.
Found uncertainty sample 9 after 112 steps.
Found uncertainty sample 10 after 367 steps.
Found uncertainty sample 11 after 605 steps.
Found uncertainty sample 12 after 68 steps.
Found uncertainty sample 13 after 1330 steps.
Found uncertainty sample 14 after 356 steps.
Found uncertainty sample 15 after 54 steps.
Found uncertainty sample 16 after 1486 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 617 steps.
Found uncertainty sample 19 after 761 steps.
Found uncertainty sample 20 after 189 steps.
Found uncertainty sample 21 after 1931 steps.
Found uncertainty sample 22 after 2639 steps.
Found uncertainty sample 23 after 1253 steps.
Found uncertainty sample 24 after 457 steps.
Found uncertainty sample 25 after 2651 steps.
Found uncertainty sample 26 after 866 steps.
Found uncertainty sample 27 after 769 steps.
Found uncertainty sample 28 after 334 steps.
Found uncertainty sample 29 after 601 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1887 steps.
Found uncertainty sample 32 after 2163 steps.
Found uncertainty sample 33 after 7 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 196 steps.
Found uncertainty sample 36 after 1678 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 403 steps.
Found uncertainty sample 39 after 1596 steps.
Found uncertainty sample 40 after 1528 steps.
Found uncertainty sample 41 after 1000 steps.
Found uncertainty sample 42 after 2610 steps.
Found uncertainty sample 43 after 273 steps.
Found uncertainty sample 44 after 3360 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1420 steps.
Found uncertainty sample 47 after 135 steps.
Found uncertainty sample 48 after 12 steps.
Found uncertainty sample 49 after 2544 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 441 steps.
Found uncertainty sample 52 after 3067 steps.
Found uncertainty sample 53 after 191 steps.
Found uncertainty sample 54 after 328 steps.
Found uncertainty sample 55 after 3577 steps.
Found uncertainty sample 56 after 691 steps.
Found uncertainty sample 57 after 54 steps.
Found uncertainty sample 58 after 653 steps.
Found uncertainty sample 59 after 1175 steps.
Found uncertainty sample 60 after 95 steps.
Found uncertainty sample 61 after 592 steps.
Found uncertainty sample 62 after 722 steps.
Found uncertainty sample 63 after 1736 steps.
Found uncertainty sample 64 after 844 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2233 steps.
Found uncertainty sample 68 after 1509 steps.
Found uncertainty sample 69 after 106 steps.
Found uncertainty sample 70 after 2945 steps.
Found uncertainty sample 71 after 233 steps.
Found uncertainty sample 72 after 43 steps.
Found uncertainty sample 73 after 1533 steps.
Found uncertainty sample 74 after 2037 steps.
Found uncertainty sample 75 after 190 steps.
Found uncertainty sample 76 after 713 steps.
Found uncertainty sample 77 after 60 steps.
Found uncertainty sample 78 after 730 steps.
Found uncertainty sample 79 after 1951 steps.
Found uncertainty sample 80 after 1267 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 70 steps.
Found uncertainty sample 83 after 1140 steps.
Found uncertainty sample 84 after 1412 steps.
Found uncertainty sample 85 after 941 steps.
Found uncertainty sample 86 after 3032 steps.
Found uncertainty sample 87 after 2541 steps.
Found uncertainty sample 88 after 884 steps.
Found uncertainty sample 89 after 480 steps.
Found uncertainty sample 90 after 1994 steps.
Found uncertainty sample 91 after 655 steps.
Found uncertainty sample 92 after 2024 steps.
Found uncertainty sample 93 after 3521 steps.
Found uncertainty sample 94 after 57 steps.
Found uncertainty sample 95 after 1408 steps.
Found uncertainty sample 96 after 1943 steps.
Found uncertainty sample 97 after 1555 steps.
Found uncertainty sample 98 after 66 steps.
Found uncertainty sample 99 after 522 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_171416-5rdu0mox
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5rdu0mox
Training model 13. Added 92 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.121420115839318, Training Loss Force: 2.1642048153881146, time: 1.072861909866333
Validation Loss Energy: 0.9759347626664474, Validation Loss Force: 2.1654931825456583, time: 0.07303237915039062
Test Loss Energy: 12.125881387520039, Test Loss Force: 10.722449326714486, time: 10.293264627456665


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8352306749711373, Training Loss Force: 1.873665551889864, time: 1.0624334812164307
Validation Loss Energy: 1.6732082743065377, Validation Loss Force: 2.059013353635855, time: 0.07903051376342773
Test Loss Energy: 13.409765317047496, Test Loss Force: 10.82545661455515, time: 10.452813863754272


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0365830581666557, Training Loss Force: 1.8687176521110513, time: 1.0707955360412598
Validation Loss Energy: 1.5732911174673778, Validation Loss Force: 2.2643680807800166, time: 0.07375931739807129
Test Loss Energy: 12.940402497926422, Test Loss Force: 10.730970173113299, time: 10.500221490859985


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.409093653272507, Training Loss Force: 1.8712386530347538, time: 1.0319468975067139
Validation Loss Energy: 2.643972993408261, Validation Loss Force: 2.046706986613291, time: 0.07695412635803223
Test Loss Energy: 11.476278685480445, Test Loss Force: 10.537273323495496, time: 10.324985027313232


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4784366689665913, Training Loss Force: 1.875689647478799, time: 1.0332324504852295
Validation Loss Energy: 1.2241044245241772, Validation Loss Force: 2.1787240718621144, time: 0.07303071022033691
Test Loss Energy: 12.967751142119807, Test Loss Force: 10.837277884019434, time: 8.835505962371826


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6746180813891445, Training Loss Force: 1.8501719460137582, time: 0.9796135425567627
Validation Loss Energy: 1.0461071348187791, Validation Loss Force: 2.069069092265954, time: 0.06807327270507812
Test Loss Energy: 12.798255570105475, Test Loss Force: 10.686224353574364, time: 11.72148084640503


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7200096182079945, Training Loss Force: 1.8521118796239433, time: 1.071852445602417
Validation Loss Energy: 3.0993945235334577, Validation Loss Force: 2.083326375010564, time: 0.08181047439575195
Test Loss Energy: 14.412437206524357, Test Loss Force: 10.782581500298924, time: 8.557696104049683


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4134643667914315, Training Loss Force: 1.82754407777702, time: 0.9497027397155762
Validation Loss Energy: 1.9912992210209226, Validation Loss Force: 2.1787083736873263, time: 0.06474709510803223
Test Loss Energy: 11.559879799997734, Test Loss Force: 10.648022936452389, time: 8.283479452133179


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2033986033026363, Training Loss Force: 1.818705986235797, time: 1.215954303741455
Validation Loss Energy: 1.6988034246234993, Validation Loss Force: 2.090390219661404, time: 0.06841588020324707
Test Loss Energy: 13.560471311085475, Test Loss Force: 10.607541900231213, time: 8.198732376098633


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.28322035681057, Training Loss Force: 1.8379806763248037, time: 0.9727077484130859
Validation Loss Energy: 1.133725300550834, Validation Loss Force: 2.152757732078891, time: 0.06806039810180664
Test Loss Energy: 12.618448537353727, Test Loss Force: 10.687770470195893, time: 8.196974754333496


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2070327255472288, Training Loss Force: 1.8209826808351575, time: 0.9666340351104736
Validation Loss Energy: 2.109591648122195, Validation Loss Force: 2.0474480295309387, time: 0.06785941123962402
Test Loss Energy: 13.370470293640798, Test Loss Force: 10.719237495658113, time: 8.288312196731567


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.175451084364051, Training Loss Force: 1.8285008523050172, time: 0.950084924697876
Validation Loss Energy: 1.7780726942299216, Validation Loss Force: 2.110165577845824, time: 0.07404232025146484
Test Loss Energy: 11.754902251502566, Test Loss Force: 10.580018394307269, time: 8.473269701004028


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.249307324439858, Training Loss Force: 1.8374587189715168, time: 0.9913613796234131
Validation Loss Energy: 2.7531186173331115, Validation Loss Force: 1.9985607958733467, time: 0.06470942497253418
Test Loss Energy: 11.405385492645223, Test Loss Force: 10.5154524466788, time: 8.220648050308228


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.2551404954218843, Training Loss Force: 1.8262659307853537, time: 0.9960906505584717
Validation Loss Energy: 0.9038370260765647, Validation Loss Force: 1.9936656373692703, time: 0.06642580032348633
Test Loss Energy: 12.5584130977748, Test Loss Force: 10.660708306762942, time: 8.232134103775024


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5673992266310273, Training Loss Force: 1.8423109579977155, time: 0.9482979774475098
Validation Loss Energy: 0.8482146352611654, Validation Loss Force: 1.9861845107389613, time: 0.075897216796875
Test Loss Energy: 12.322547030067568, Test Loss Force: 10.581723447735097, time: 8.780054330825806


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4664513604094078, Training Loss Force: 1.8535333577010813, time: 1.0125839710235596
Validation Loss Energy: 1.8595598598643575, Validation Loss Force: 2.013540417327347, time: 0.0659322738647461
Test Loss Energy: 13.496807441633637, Test Loss Force: 10.70697622263502, time: 8.266562700271606


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3863458985759185, Training Loss Force: 1.8262573006163465, time: 0.9554815292358398
Validation Loss Energy: 1.0873778868389812, Validation Loss Force: 2.098167941594089, time: 0.06396746635437012
Test Loss Energy: 12.004352186337725, Test Loss Force: 10.482173850330508, time: 8.19461441040039


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6887052414270607, Training Loss Force: 1.8528967239980387, time: 1.0149638652801514
Validation Loss Energy: 1.0979779401963006, Validation Loss Force: 1.9901439021572762, time: 0.06495380401611328
Test Loss Energy: 12.812300215473794, Test Loss Force: 10.626311090573932, time: 9.473575592041016


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6741320059510016, Training Loss Force: 1.8168963749620746, time: 1.069312334060669
Validation Loss Energy: 1.8112139349005163, Validation Loss Force: 2.072860925151958, time: 0.0823829174041748
Test Loss Energy: 11.959185976777736, Test Loss Force: 10.553654082972502, time: 11.00618839263916


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.721219889381412, Training Loss Force: 1.8166269870459668, time: 1.1170074939727783
Validation Loss Energy: 1.701454022469337, Validation Loss Force: 2.1039727035592803, time: 0.08515620231628418
Test Loss Energy: 13.248332154132143, Test Loss Force: 10.6627285431207, time: 9.790267705917358

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–…â–â–…â–„â–ˆâ–â–†â–„â–†â–‚â–â–„â–ƒâ–†â–‚â–„â–‚â–…
wandb:   test_error_force â–†â–ˆâ–†â–‚â–ˆâ–…â–‡â–„â–ƒâ–…â–†â–ƒâ–‚â–…â–ƒâ–…â–â–„â–‚â–…
wandb:          test_loss â–ƒâ–†â–„â–â–ˆâ–†â–ˆâ–†â–ˆâ–†â–ˆâ–„â–ƒâ–†â–„â–†â–â–…â–„â–‡
wandb: train_error_energy â–ˆâ–†â–‡â–ƒâ–ƒâ–…â–…â–ƒâ–â–‚â–â–â–‚â–‚â–„â–ƒâ–ƒâ–…â–…â–…
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–â–„â–ƒâ–‡â–‚â–‚â–ˆâ–…â–„â–‚â–…â–„â–‡â–â–â–„â–‚â–‚â–„â–„
wandb:  valid_error_force â–†â–ƒâ–ˆâ–ƒâ–†â–ƒâ–ƒâ–†â–„â–…â–ƒâ–„â–â–â–â–‚â–„â–â–ƒâ–„
wandb:         valid_loss â–…â–ƒâ–ˆâ–„â–†â–ƒâ–†â–‡â–„â–…â–„â–…â–ƒâ–â–â–ƒâ–„â–â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2033
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.24833
wandb:   test_error_force 10.66273
wandb:          test_loss 9.61248
wandb: train_error_energy 1.72122
wandb:  train_error_force 1.81663
wandb:         train_loss -2.6528
wandb: valid_error_energy 1.70145
wandb:  valid_error_force 2.10397
wandb:         valid_loss -2.2574
wandb: 
wandb: ğŸš€ View run al_59_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5rdu0mox
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_171416-5rdu0mox/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.815040588378906, Uncertainty Bias: -2.389277935028076
7.6293945e-06 0.034534454
0.39889842 5.4983244
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 246 steps.
Found uncertainty sample 1 after 2649 steps.
Found uncertainty sample 2 after 1107 steps.
Found uncertainty sample 3 after 564 steps.
Found uncertainty sample 4 after 183 steps.
Found uncertainty sample 5 after 637 steps.
Found uncertainty sample 6 after 2461 steps.
Found uncertainty sample 7 after 2829 steps.
Found uncertainty sample 8 after 3780 steps.
Found uncertainty sample 9 after 1951 steps.
Found uncertainty sample 10 after 1190 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 13 steps.
Found uncertainty sample 13 after 173 steps.
Found uncertainty sample 14 after 1268 steps.
Found uncertainty sample 15 after 345 steps.
Found uncertainty sample 16 after 2138 steps.
Found uncertainty sample 17 after 27 steps.
Found uncertainty sample 18 after 1710 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1711 steps.
Found uncertainty sample 21 after 496 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1682 steps.
Found uncertainty sample 24 after 792 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 840 steps.
Found uncertainty sample 27 after 1104 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 101 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 70 steps.
Found uncertainty sample 33 after 747 steps.
Found uncertainty sample 34 after 134 steps.
Found uncertainty sample 35 after 431 steps.
Found uncertainty sample 36 after 2127 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 107 steps.
Found uncertainty sample 39 after 1130 steps.
Found uncertainty sample 40 after 548 steps.
Found uncertainty sample 41 after 38 steps.
Found uncertainty sample 42 after 135 steps.
Found uncertainty sample 43 after 1529 steps.
Found uncertainty sample 44 after 86 steps.
Found uncertainty sample 45 after 3114 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 701 steps.
Found uncertainty sample 48 after 745 steps.
Found uncertainty sample 49 after 2005 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 95 steps.
Found uncertainty sample 52 after 119 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 152 steps.
Found uncertainty sample 55 after 3654 steps.
Found uncertainty sample 56 after 1215 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 124 steps.
Found uncertainty sample 59 after 54 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1691 steps.
Found uncertainty sample 63 after 3141 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 270 steps.
Found uncertainty sample 68 after 320 steps.
Found uncertainty sample 69 after 332 steps.
Found uncertainty sample 70 after 1032 steps.
Found uncertainty sample 71 after 3552 steps.
Found uncertainty sample 72 after 2841 steps.
Found uncertainty sample 73 after 569 steps.
Found uncertainty sample 74 after 3568 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 85 steps.
Found uncertainty sample 77 after 729 steps.
Found uncertainty sample 78 after 1778 steps.
Found uncertainty sample 79 after 1823 steps.
Found uncertainty sample 80 after 1060 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 124 steps.
Found uncertainty sample 84 after 930 steps.
Found uncertainty sample 85 after 1037 steps.
Found uncertainty sample 86 after 223 steps.
Found uncertainty sample 87 after 1104 steps.
Found uncertainty sample 88 after 1154 steps.
Found uncertainty sample 89 after 126 steps.
Found uncertainty sample 90 after 1469 steps.
Found uncertainty sample 91 after 590 steps.
Found uncertainty sample 92 after 42 steps.
Found uncertainty sample 93 after 222 steps.
Found uncertainty sample 94 after 3500 steps.
Found uncertainty sample 95 after 2666 steps.
Found uncertainty sample 96 after 111 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2084 steps.
Found uncertainty sample 99 after 585 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_173532-elr476iw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/elr476iw
Training model 14. Added 83 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6763766497951074, Training Loss Force: 2.064068096755175, time: 0.9383745193481445
Validation Loss Energy: 2.485422875399828, Validation Loss Force: 2.055331073969647, time: 0.06999754905700684
Test Loss Energy: 11.449355495573924, Test Loss Force: 10.490685318977437, time: 8.97432804107666


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2857511020924532, Training Loss Force: 1.871431031849418, time: 0.9523224830627441
Validation Loss Energy: 1.9015601038402623, Validation Loss Force: 2.1248420352576436, time: 0.07315921783447266
Test Loss Energy: 11.582439285526965, Test Loss Force: 10.570393491329366, time: 9.04457974433899


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.510141722164893, Training Loss Force: 1.8537063215479956, time: 0.9871156215667725
Validation Loss Energy: 1.3314346825695655, Validation Loss Force: 1.9787465819229626, time: 0.07049441337585449
Test Loss Energy: 12.396314100486, Test Loss Force: 10.563668813173921, time: 9.213903665542603


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.1145159209459574, Training Loss Force: 1.8437056918446264, time: 1.0097270011901855
Validation Loss Energy: 1.612920324710157, Validation Loss Force: 2.0903647240441954, time: 0.07279801368713379
Test Loss Energy: 13.398912175723883, Test Loss Force: 10.6071414361842, time: 9.437805891036987


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.370524747925548, Training Loss Force: 1.852528187531329, time: 1.0085461139678955
Validation Loss Energy: 2.8160369018830513, Validation Loss Force: 2.1481853325018374, time: 0.06933975219726562
Test Loss Energy: 11.384235295296065, Test Loss Force: 10.633719799019207, time: 8.972283840179443


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5637471594093255, Training Loss Force: 1.8654487772716102, time: 0.9734334945678711
Validation Loss Energy: 2.005980911157671, Validation Loss Force: 2.10654954225053, time: 0.07279229164123535
Test Loss Energy: 13.486250042241638, Test Loss Force: 10.721918609377756, time: 9.130524635314941


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7275314016202172, Training Loss Force: 1.844437529417355, time: 1.0430045127868652
Validation Loss Energy: 2.4503186392060208, Validation Loss Force: 2.1876325077178205, time: 0.07562780380249023
Test Loss Energy: 14.130059410722522, Test Loss Force: 10.68765900971577, time: 9.017637968063354


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7191939991023555, Training Loss Force: 1.8308735169372659, time: 0.9802284240722656
Validation Loss Energy: 2.6834750565687155, Validation Loss Force: 2.141058806486418, time: 0.06868171691894531
Test Loss Energy: 14.29467726004297, Test Loss Force: 10.648954593485408, time: 8.992511987686157


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6933072492002579, Training Loss Force: 1.8762674934171182, time: 0.9781334400177002
Validation Loss Energy: 2.4751306621367544, Validation Loss Force: 2.0379387209849464, time: 0.07095456123352051
Test Loss Energy: 14.012918568404924, Test Loss Force: 10.700025834908875, time: 9.146761178970337


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6364532879903881, Training Loss Force: 1.8609324211569436, time: 1.0199923515319824
Validation Loss Energy: 2.549301865979873, Validation Loss Force: 2.0468959213836104, time: 0.0700383186340332
Test Loss Energy: 11.71690916876307, Test Loss Force: 10.620385102162986, time: 8.96468734741211


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2130373555275802, Training Loss Force: 1.8778180668836606, time: 0.9726142883300781
Validation Loss Energy: 0.8136414371467523, Validation Loss Force: 2.1101370761951452, time: 0.06918883323669434
Test Loss Energy: 12.69699972548664, Test Loss Force: 10.459977378462723, time: 9.024904251098633


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4884809096135547, Training Loss Force: 1.8591374497469826, time: 0.9750728607177734
Validation Loss Energy: 0.7563953429192476, Validation Loss Force: 1.9834289800581049, time: 0.06858277320861816
Test Loss Energy: 12.477651231708197, Test Loss Force: 10.523798319429584, time: 9.162346124649048


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2831744692014753, Training Loss Force: 1.833565564981996, time: 0.954888105392456
Validation Loss Energy: 1.417081363517219, Validation Loss Force: 2.0360448085642577, time: 0.06757235527038574
Test Loss Energy: 12.088755977659613, Test Loss Force: 10.5863155756819, time: 9.13924503326416


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 0.9904917867585635, Training Loss Force: 1.8171268128573803, time: 1.004159688949585
Validation Loss Energy: 0.742757831908684, Validation Loss Force: 2.0132745503671092, time: 0.06997442245483398
Test Loss Energy: 12.87935266631998, Test Loss Force: 10.58128709082073, time: 9.035055875778198


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5935571203672991, Training Loss Force: 1.8357943245653108, time: 0.9415385723114014
Validation Loss Energy: 2.2125781321361107, Validation Loss Force: 2.0795263033661606, time: 0.06942176818847656
Test Loss Energy: 13.72814234377615, Test Loss Force: 10.650903351881514, time: 9.206855773925781


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3688397539875823, Training Loss Force: 1.8407486388391554, time: 0.9628407955169678
Validation Loss Energy: 1.1448671636074823, Validation Loss Force: 2.090367618743093, time: 0.07184338569641113
Test Loss Energy: 12.814974973213417, Test Loss Force: 10.504314120972184, time: 9.474743604660034


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.44911183433534, Training Loss Force: 1.8584420742469, time: 0.9728260040283203
Validation Loss Energy: 0.9511674962340455, Validation Loss Force: 2.19462420756538, time: 0.06896114349365234
Test Loss Energy: 12.667549616163706, Test Loss Force: 10.57189457981952, time: 8.928717136383057


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2582166359351272, Training Loss Force: 1.816858700649921, time: 0.9454498291015625
Validation Loss Energy: 1.175328469772263, Validation Loss Force: 1.9797822161206726, time: 0.06902742385864258
Test Loss Energy: 12.174094699600701, Test Loss Force: 10.455464833168156, time: 9.18210244178772


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.349428592277421, Training Loss Force: 1.880216006098144, time: 0.9400007724761963
Validation Loss Energy: 0.7427132702458552, Validation Loss Force: 2.0121138874439604, time: 0.06816673278808594
Test Loss Energy: 12.09712121679706, Test Loss Force: 10.461800136433215, time: 9.042490243911743


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.582731739329401, Training Loss Force: 1.8544492520927212, time: 0.9672327041625977
Validation Loss Energy: 2.1674862940708577, Validation Loss Force: 2.0815395664490666, time: 0.0715484619140625
Test Loss Energy: 13.980823340820733, Test Loss Force: 10.766159653118367, time: 9.07260274887085

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–ƒâ–†â–â–†â–ˆâ–ˆâ–‡â–‚â–„â–„â–ƒâ–…â–‡â–„â–„â–ƒâ–ƒâ–‡
wandb:   test_error_force â–‚â–„â–ƒâ–„â–…â–‡â–†â–…â–‡â–…â–â–ƒâ–„â–„â–…â–‚â–„â–â–â–ˆ
wandb:          test_loss â–â–„â–„â–†â–…â–†â–ˆâ–‡â–†â–…â–ƒâ–…â–†â–‡â–ˆâ–…â–…â–…â–ƒâ–ˆ
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–ƒâ–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚
wandb: valid_error_energy â–‡â–…â–ƒâ–„â–ˆâ–…â–‡â–ˆâ–‡â–‡â–â–â–ƒâ–â–†â–‚â–‚â–‚â–â–†
wandb:  valid_error_force â–ƒâ–†â–â–…â–†â–…â–ˆâ–†â–ƒâ–ƒâ–…â–â–ƒâ–‚â–„â–…â–ˆâ–â–‚â–„
wandb:         valid_loss â–…â–†â–‚â–…â–‡â–…â–ˆâ–‡â–„â–…â–„â–â–ƒâ–‚â–…â–„â–†â–â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2107
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.98082
wandb:   test_error_force 10.76616
wandb:          test_loss 9.59757
wandb: train_error_energy 1.58273
wandb:  train_error_force 1.85445
wandb:         train_loss -2.6107
wandb: valid_error_energy 2.16749
wandb:  valid_error_force 2.08154
wandb:         valid_loss -2.26403
wandb: 
wandb: ğŸš€ View run al_59_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/elr476iw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_173532-elr476iw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.459077835083008, Uncertainty Bias: -2.3899948596954346
5.722046e-06 0.068499565
0.5265751 5.41774
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1741 steps.
Found uncertainty sample 1 after 1779 steps.
Found uncertainty sample 2 after 3106 steps.
Found uncertainty sample 3 after 427 steps.
Found uncertainty sample 4 after 401 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3004 steps.
Found uncertainty sample 7 after 9 steps.
Found uncertainty sample 8 after 319 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2779 steps.
Found uncertainty sample 11 after 1361 steps.
Found uncertainty sample 12 after 3487 steps.
Found uncertainty sample 13 after 338 steps.
Found uncertainty sample 14 after 838 steps.
Found uncertainty sample 15 after 486 steps.
Found uncertainty sample 16 after 2680 steps.
Found uncertainty sample 17 after 1705 steps.
Found uncertainty sample 18 after 27 steps.
Found uncertainty sample 19 after 3483 steps.
Found uncertainty sample 20 after 1751 steps.
Found uncertainty sample 21 after 2411 steps.
Found uncertainty sample 22 after 1924 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1689 steps.
Found uncertainty sample 25 after 1979 steps.
Found uncertainty sample 26 after 1779 steps.
Found uncertainty sample 27 after 1451 steps.
Found uncertainty sample 28 after 3584 steps.
Found uncertainty sample 29 after 1791 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 106 steps.
Found uncertainty sample 32 after 2496 steps.
Found uncertainty sample 33 after 2821 steps.
Found uncertainty sample 34 after 908 steps.
Found uncertainty sample 35 after 1326 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 61 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 375 steps.
Found uncertainty sample 41 after 1205 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1348 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 765 steps.
Found uncertainty sample 46 after 364 steps.
Found uncertainty sample 47 after 3763 steps.
Found uncertainty sample 48 after 1387 steps.
Found uncertainty sample 49 after 106 steps.
Found uncertainty sample 50 after 272 steps.
Found uncertainty sample 51 after 1359 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 780 steps.
Found uncertainty sample 54 after 964 steps.
Found uncertainty sample 55 after 50 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 26 steps.
Found uncertainty sample 58 after 1838 steps.
Found uncertainty sample 59 after 1320 steps.
Found uncertainty sample 60 after 1732 steps.
Found uncertainty sample 61 after 1276 steps.
Found uncertainty sample 62 after 442 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 92 steps.
Found uncertainty sample 65 after 2203 steps.
Found uncertainty sample 66 after 2399 steps.
Found uncertainty sample 67 after 1273 steps.
Found uncertainty sample 68 after 333 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1854 steps.
Found uncertainty sample 71 after 3136 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1937 steps.
Found uncertainty sample 74 after 3869 steps.
Found uncertainty sample 75 after 2411 steps.
Found uncertainty sample 76 after 622 steps.
Found uncertainty sample 77 after 241 steps.
Found uncertainty sample 78 after 2072 steps.
Found uncertainty sample 79 after 32 steps.
Found uncertainty sample 80 after 2172 steps.
Found uncertainty sample 81 after 590 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1165 steps.
Found uncertainty sample 84 after 729 steps.
Found uncertainty sample 85 after 610 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1099 steps.
Found uncertainty sample 88 after 521 steps.
Found uncertainty sample 89 after 2652 steps.
Found uncertainty sample 90 after 1334 steps.
Found uncertainty sample 91 after 1847 steps.
Found uncertainty sample 92 after 1837 steps.
Found uncertainty sample 93 after 162 steps.
Found uncertainty sample 94 after 65 steps.
Found uncertainty sample 95 after 1308 steps.
Found uncertainty sample 96 after 641 steps.
Found uncertainty sample 97 after 246 steps.
Found uncertainty sample 98 after 1075 steps.
Found uncertainty sample 99 after 1617 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_175750-mpa1rb7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/mpa1rb7x
Training model 15. Added 86 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.133499377841412, Training Loss Force: 2.186290306512504, time: 1.0366532802581787
Validation Loss Energy: 2.1755570485995834, Validation Loss Force: 2.0741972740312438, time: 0.07619667053222656
Test Loss Energy: 11.811848698782022, Test Loss Force: 10.546520248512705, time: 9.072822332382202


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.270596981407651, Training Loss Force: 1.878632644453178, time: 1.0719048976898193
Validation Loss Energy: 1.3736395594905777, Validation Loss Force: 2.019247650206622, time: 0.07757329940795898
Test Loss Energy: 13.241111425078314, Test Loss Force: 10.56663855273897, time: 9.05638575553894


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2919277093930885, Training Loss Force: 1.8784739394397343, time: 1.0173964500427246
Validation Loss Energy: 2.177846644092586, Validation Loss Force: 1.993342878442248, time: 0.07196760177612305
Test Loss Energy: 11.809203118861163, Test Loss Force: 10.444891919215982, time: 9.20087456703186


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5089076408934317, Training Loss Force: 1.858555960053804, time: 1.0152676105499268
Validation Loss Energy: 0.9309142622288215, Validation Loss Force: 2.1763334959114333, time: 0.07374000549316406
Test Loss Energy: 12.8554586907908, Test Loss Force: 10.562307047952308, time: 9.033936500549316


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4996344915324584, Training Loss Force: 1.8818953751098446, time: 1.0211355686187744
Validation Loss Energy: 1.0462493647357405, Validation Loss Force: 2.1514812811998603, time: 0.07357549667358398
Test Loss Energy: 12.274004456771083, Test Loss Force: 10.558599501749976, time: 9.001311302185059


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.734221293536435, Training Loss Force: 1.8563862670552493, time: 1.0294084548950195
Validation Loss Energy: 1.6009894892022003, Validation Loss Force: 2.119624117826545, time: 0.07419204711914062
Test Loss Energy: 12.023634812093517, Test Loss Force: 10.42347258831524, time: 9.196901321411133


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.169700752038852, Training Loss Force: 1.8667600030424456, time: 1.060861587524414
Validation Loss Energy: 1.0414605585824876, Validation Loss Force: 2.0808096569887153, time: 0.0700674057006836
Test Loss Energy: 12.49131441102114, Test Loss Force: 10.440958700748768, time: 9.001238346099854


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7133364806850242, Training Loss Force: 1.8514364239133134, time: 1.0033018589019775
Validation Loss Energy: 2.437865755885436, Validation Loss Force: 2.0418486798528654, time: 0.07368326187133789
Test Loss Energy: 14.153919927589461, Test Loss Force: 10.692109347546321, time: 9.03626298904419


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2262997551318593, Training Loss Force: 1.8860941019755963, time: 0.9970808029174805
Validation Loss Energy: 1.256138888204938, Validation Loss Force: 2.0962445255115645, time: 0.0796973705291748
Test Loss Energy: 12.212351730382034, Test Loss Force: 10.56522643864262, time: 9.23867678642273


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4955626836595681, Training Loss Force: 1.8655918548861958, time: 1.0172173976898193
Validation Loss Energy: 1.4868341434976928, Validation Loss Force: 2.033456057073701, time: 0.07448220252990723
Test Loss Energy: 12.248379122543877, Test Loss Force: 10.567294836821095, time: 9.47261357307434


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6582659499344807, Training Loss Force: 1.8552628737837866, time: 1.0055859088897705
Validation Loss Energy: 1.2701379304075586, Validation Loss Force: 2.1472149403638836, time: 0.06974101066589355
Test Loss Energy: 12.94558662269156, Test Loss Force: 10.509273548087133, time: 9.03994369506836


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.522002096144899, Training Loss Force: 1.8436159398233434, time: 1.0244331359863281
Validation Loss Energy: 0.885388497665442, Validation Loss Force: 2.094942245011606, time: 0.07340288162231445
Test Loss Energy: 12.65009781109995, Test Loss Force: 10.437114843723304, time: 9.228542804718018


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4482211474102755, Training Loss Force: 1.8570172694626506, time: 0.9834988117218018
Validation Loss Energy: 1.0231975692372095, Validation Loss Force: 2.0783343554280087, time: 0.07118701934814453
Test Loss Energy: 12.788540573558995, Test Loss Force: 10.492708246017857, time: 9.072124719619751


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3655176789964658, Training Loss Force: 1.868094493118426, time: 1.009995460510254
Validation Loss Energy: 2.2952810156400254, Validation Loss Force: 2.179968347049559, time: 0.07152223587036133
Test Loss Energy: 11.575207956955461, Test Loss Force: 10.48142801827751, time: 9.03130292892456


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8444424844659382, Training Loss Force: 1.891040985876854, time: 1.028404712677002
Validation Loss Energy: 1.1575809594998074, Validation Loss Force: 2.0709765875045445, time: 0.073028564453125
Test Loss Energy: 12.06939915528014, Test Loss Force: 10.428032157602843, time: 9.202319622039795


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.211175190182375, Training Loss Force: 1.8483816694660324, time: 1.0293397903442383
Validation Loss Energy: 1.791600457185186, Validation Loss Force: 2.072646494764429, time: 0.07460737228393555
Test Loss Energy: 13.607523679866393, Test Loss Force: 10.551458798355062, time: 9.12275743484497


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2946417671387436, Training Loss Force: 1.8636108868971724, time: 0.9769341945648193
Validation Loss Energy: 0.7354794177020991, Validation Loss Force: 1.9623386492324086, time: 0.07788920402526855
Test Loss Energy: 12.618613139982271, Test Loss Force: 10.501533074272494, time: 9.045873880386353


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2302620638386945, Training Loss Force: 1.833306316414729, time: 1.0371108055114746
Validation Loss Energy: 1.374582006650717, Validation Loss Force: 2.107584508440802, time: 0.07169938087463379
Test Loss Energy: 13.170490424872368, Test Loss Force: 10.552748721883228, time: 9.208934783935547


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.1553035164174759, Training Loss Force: 1.820964528862517, time: 1.014568567276001
Validation Loss Energy: 0.843003119568012, Validation Loss Force: 2.005835842209099, time: 0.07404661178588867
Test Loss Energy: 13.244319660785754, Test Loss Force: 10.547524763822917, time: 9.100186824798584


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.0798898155129906, Training Loss Force: 1.8416052406627046, time: 0.9983606338500977
Validation Loss Energy: 0.7527312386220761, Validation Loss Force: 2.007819824299316, time: 0.0731809139251709
Test Loss Energy: 12.480126184109695, Test Loss Force: 10.470276187862064, time: 9.48251461982727

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‚â–„â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–ƒâ–…â–„â–„â–â–‚â–‡â–„â–…â–†â–ƒ
wandb:   test_error_force â–„â–…â–‚â–…â–…â–â–â–ˆâ–…â–…â–ƒâ–â–ƒâ–ƒâ–â–„â–ƒâ–„â–„â–‚
wandb:          test_loss â–â–„â–„â–†â–…â–…â–…â–ˆâ–…â–…â–…â–…â–…â–„â–ƒâ–†â–…â–‡â–‡â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–â–‚â–ƒâ–ƒâ–‚â–‚â–„â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–â–
wandb: valid_error_energy â–‡â–„â–‡â–‚â–‚â–…â–‚â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–‡â–ƒâ–…â–â–„â–â–
wandb:  valid_error_force â–…â–ƒâ–‚â–ˆâ–‡â–†â–…â–„â–…â–ƒâ–‡â–…â–…â–ˆâ–„â–…â–â–†â–‚â–‚
wandb:         valid_loss â–…â–ƒâ–ƒâ–†â–†â–†â–„â–…â–…â–„â–†â–„â–„â–ˆâ–„â–…â–â–…â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2184
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.48013
wandb:   test_error_force 10.47028
wandb:          test_loss 9.21568
wandb: train_error_energy 1.07989
wandb:  train_error_force 1.84161
wandb:         train_loss -2.6618
wandb: valid_error_energy 0.75273
wandb:  valid_error_force 2.00782
wandb:         valid_loss -2.45506
wandb: 
wandb: ğŸš€ View run al_59_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/mpa1rb7x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_175750-mpa1rb7x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.64335060119629, Uncertainty Bias: -2.3783044815063477
9.441376e-05 0.00039482117
0.5389591 5.017737
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 344 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 6 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 990 steps.
Found uncertainty sample 6 after 260 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1070 steps.
Found uncertainty sample 9 after 547 steps.
Found uncertainty sample 10 after 1078 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 138 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 66 steps.
Found uncertainty sample 16 after 101 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3621 steps.
Found uncertainty sample 19 after 466 steps.
Found uncertainty sample 20 after 1870 steps.
Found uncertainty sample 21 after 3138 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 399 steps.
Found uncertainty sample 24 after 301 steps.
Found uncertainty sample 25 after 1962 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 654 steps.
Found uncertainty sample 28 after 596 steps.
Found uncertainty sample 29 after 566 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 190 steps.
Found uncertainty sample 32 after 3927 steps.
Found uncertainty sample 33 after 1713 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 90 steps.
Found uncertainty sample 36 after 1454 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 379 steps.
Found uncertainty sample 39 after 791 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 318 steps.
Found uncertainty sample 42 after 1726 steps.
Found uncertainty sample 43 after 101 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 326 steps.
Found uncertainty sample 46 after 2961 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3981 steps.
Found uncertainty sample 49 after 1297 steps.
Found uncertainty sample 50 after 472 steps.
Found uncertainty sample 51 after 1106 steps.
Found uncertainty sample 52 after 1758 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 269 steps.
Found uncertainty sample 55 after 464 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 56 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 8 steps.
Found uncertainty sample 60 after 1503 steps.
Found uncertainty sample 61 after 865 steps.
Found uncertainty sample 62 after 1437 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3533 steps.
Found uncertainty sample 65 after 234 steps.
Found uncertainty sample 66 after 3845 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1035 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3053 steps.
Found uncertainty sample 71 after 2417 steps.
Found uncertainty sample 72 after 1121 steps.
Found uncertainty sample 73 after 27 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2214 steps.
Found uncertainty sample 78 after 2048 steps.
Found uncertainty sample 79 after 300 steps.
Found uncertainty sample 80 after 724 steps.
Found uncertainty sample 81 after 2717 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2123 steps.
Found uncertainty sample 84 after 1 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 57 steps.
Found uncertainty sample 87 after 417 steps.
Found uncertainty sample 88 after 1181 steps.
Found uncertainty sample 89 after 1449 steps.
Found uncertainty sample 90 after 189 steps.
Found uncertainty sample 91 after 494 steps.
Found uncertainty sample 92 after 925 steps.
Found uncertainty sample 93 after 3158 steps.
Found uncertainty sample 94 after 14 steps.
Found uncertainty sample 95 after 59 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1748 steps.
Found uncertainty sample 98 after 1545 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_182156-i3bnqb4y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/i3bnqb4y
Training model 16. Added 74 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.8256467938347833, Training Loss Force: 2.1646870747627145, time: 1.0597343444824219
Validation Loss Energy: 1.717585177411503, Validation Loss Force: 2.1793309566193404, time: 0.07553315162658691
Test Loss Energy: 13.630151495678248, Test Loss Force: 10.531565742039913, time: 9.283254384994507


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.0924684633921369, Training Loss Force: 1.872686151917607, time: 1.0495519638061523
Validation Loss Energy: 1.2209618948676986, Validation Loss Force: 2.0490368852217062, time: 0.07496786117553711
Test Loss Energy: 12.521583425182758, Test Loss Force: 10.438890279254156, time: 9.594384670257568


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6471069405695498, Training Loss Force: 1.8705347916257262, time: 1.1047449111938477
Validation Loss Energy: 0.781820123505931, Validation Loss Force: 1.9829453426731498, time: 0.08206534385681152
Test Loss Energy: 12.811224660545383, Test Loss Force: 10.535884422949058, time: 10.411353588104248


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5453053661102547, Training Loss Force: 1.8547614330711222, time: 1.146498441696167
Validation Loss Energy: 1.9717335058373937, Validation Loss Force: 2.0672855124070724, time: 0.08014988899230957
Test Loss Energy: 13.817189815032444, Test Loss Force: 10.458232389148701, time: 10.25023365020752


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.1753039887109513, Training Loss Force: 1.8907281013651445, time: 1.1200973987579346
Validation Loss Energy: 0.757003174020344, Validation Loss Force: 2.0287585174366356, time: 0.07379722595214844
Test Loss Energy: 12.860241796584775, Test Loss Force: 10.375079098423887, time: 10.346518516540527


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7075493159229096, Training Loss Force: 1.8618908145831234, time: 1.1209125518798828
Validation Loss Energy: 2.14130641457669, Validation Loss Force: 2.139559241123168, time: 0.07598519325256348
Test Loss Energy: 13.683447530627118, Test Loss Force: 10.51933916809776, time: 10.519782304763794


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4558276711314224, Training Loss Force: 1.9028121912649254, time: 1.1089563369750977
Validation Loss Energy: 2.5078094746585435, Validation Loss Force: 2.3965793335240893, time: 0.07665610313415527
Test Loss Energy: 14.230690695200591, Test Loss Force: 10.562401860707805, time: 10.258465051651001


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3482679729163594, Training Loss Force: 1.8851392155688376, time: 1.10520601272583
Validation Loss Energy: 1.426494089321165, Validation Loss Force: 2.0610248353655933, time: 0.08457708358764648
Test Loss Energy: 12.32297018538294, Test Loss Force: 10.302330127299383, time: 10.532022714614868


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2280280406943953, Training Loss Force: 1.866754374453682, time: 1.1031546592712402
Validation Loss Energy: 1.181948757484415, Validation Loss Force: 1.9876219514104982, time: 0.08484864234924316
Test Loss Energy: 12.348964712048938, Test Loss Force: 10.249781887622571, time: 10.343920707702637


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6324176302869235, Training Loss Force: 1.874645259355275, time: 1.1928105354309082
Validation Loss Energy: 1.6480270659318563, Validation Loss Force: 2.074627359486603, time: 0.08600282669067383
Test Loss Energy: 12.21144187394079, Test Loss Force: 10.21844719991307, time: 10.348872900009155


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.838437205162326, Training Loss Force: 1.8671037893864204, time: 1.076683521270752
Validation Loss Energy: 0.8274873108106178, Validation Loss Force: 2.053965221428526, time: 0.08035778999328613
Test Loss Energy: 12.813821798851833, Test Loss Force: 10.474626881832716, time: 10.515306949615479


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3496057973707596, Training Loss Force: 1.8748798993199356, time: 1.1767082214355469
Validation Loss Energy: 1.01544539858902, Validation Loss Force: 2.2899927347588136, time: 0.07701683044433594
Test Loss Energy: 12.108955683197108, Test Loss Force: 10.332066740698895, time: 10.31812047958374


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7576608911751077, Training Loss Force: 1.874929882270826, time: 1.1295952796936035
Validation Loss Energy: 3.3280890965500514, Validation Loss Force: 2.0762702124452583, time: 0.0798337459564209
Test Loss Energy: 14.974113500679945, Test Loss Force: 10.495368650341122, time: 10.311330318450928


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6184326146724037, Training Loss Force: 1.8606047230709295, time: 1.287118673324585
Validation Loss Energy: 1.762977396154612, Validation Loss Force: 2.2215410105979956, time: 0.08138084411621094
Test Loss Energy: 13.836340280238183, Test Loss Force: 10.563275218062032, time: 10.784629106521606


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.776155933132294, Training Loss Force: 1.851168025051713, time: 1.1091394424438477
Validation Loss Energy: 0.7855172663376295, Validation Loss Force: 2.0308333485383905, time: 0.08527612686157227
Test Loss Energy: 12.72293667061099, Test Loss Force: 10.410274468086154, time: 10.481799602508545


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.334120110103676, Training Loss Force: 1.849812644232821, time: 1.0588347911834717
Validation Loss Energy: 1.6401439658258612, Validation Loss Force: 2.044529727704409, time: 0.09031891822814941
Test Loss Energy: 12.175799869609236, Test Loss Force: 10.346584974195428, time: 10.554584264755249


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5446916773993367, Training Loss Force: 1.8638917210965236, time: 1.1200957298278809
Validation Loss Energy: 1.5059803500102937, Validation Loss Force: 2.033155676395845, time: 0.08443760871887207
Test Loss Energy: 12.154394728911862, Test Loss Force: 10.432604620716377, time: 10.343771696090698


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.471938357761181, Training Loss Force: 1.8561902115992637, time: 1.1336545944213867
Validation Loss Energy: 0.886230298371622, Validation Loss Force: 2.0421109841067686, time: 0.07711029052734375
Test Loss Energy: 12.512738531057229, Test Loss Force: 10.301891228925655, time: 10.382452726364136


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.1661870051670198, Training Loss Force: 1.863618570346266, time: 1.1414659023284912
Validation Loss Energy: 0.8836015777693715, Validation Loss Force: 2.095685848624432, time: 0.07582259178161621
Test Loss Energy: 13.044712006227982, Test Loss Force: 10.363173881525785, time: 10.494688272476196


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.1069116113658475, Training Loss Force: 1.8535792151474109, time: 1.1817667484283447
Validation Loss Energy: 0.8063227198247546, Validation Loss Force: 2.081874126840823, time: 0.09398531913757324
Test Loss Energy: 12.835863176413351, Test Loss Force: 10.26756014663879, time: 10.244642972946167

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–ƒâ–…â–ƒâ–…â–†â–‚â–‚â–â–ƒâ–â–ˆâ–…â–ƒâ–â–â–‚â–ƒâ–ƒ
wandb:   test_error_force â–‡â–…â–‡â–†â–„â–‡â–ˆâ–ƒâ–‚â–â–†â–ƒâ–‡â–ˆâ–…â–„â–…â–ƒâ–„â–‚
wandb:          test_loss â–„â–„â–†â–‡â–ƒâ–‡â–ˆâ–ƒâ–‚â–â–…â–ƒâ–‡â–ˆâ–…â–†â–…â–„â–…â–…
wandb: train_error_energy â–ˆâ–â–†â–…â–‚â–‡â–„â–ƒâ–‚â–†â–ˆâ–ƒâ–‡â–†â–‡â–ƒâ–…â–…â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–„â–‚â–â–„â–â–…â–†â–ƒâ–‚â–ƒâ–â–‚â–ˆâ–„â–â–ƒâ–ƒâ–â–â–
wandb:  valid_error_force â–„â–‚â–â–‚â–‚â–„â–ˆâ–‚â–â–ƒâ–‚â–†â–ƒâ–…â–‚â–‚â–‚â–‚â–ƒâ–ƒ
wandb:         valid_loss â–„â–‚â–â–ƒâ–‚â–„â–ˆâ–ƒâ–â–ƒâ–‚â–…â–„â–…â–‚â–ƒâ–‚â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2250
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.83586
wandb:   test_error_force 10.26756
wandb:          test_loss 8.9772
wandb: train_error_energy 1.10691
wandb:  train_error_force 1.85358
wandb:         train_loss -2.64366
wandb: valid_error_energy 0.80632
wandb:  valid_error_force 2.08187
wandb:         valid_loss -2.35258
wandb: 
wandb: ğŸš€ View run al_59_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/i3bnqb4y
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_182156-i3bnqb4y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.856603622436523, Uncertainty Bias: -2.4229562282562256
0.00023651123 0.0005569458
0.5559247 4.668385
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3925 steps.
Found uncertainty sample 1 after 1645 steps.
Found uncertainty sample 2 after 63 steps.
Found uncertainty sample 3 after 434 steps.
Found uncertainty sample 4 after 1771 steps.
Found uncertainty sample 5 after 90 steps.
Found uncertainty sample 6 after 532 steps.
Found uncertainty sample 7 after 2154 steps.
Found uncertainty sample 8 after 1858 steps.
Found uncertainty sample 9 after 2506 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3227 steps.
Found uncertainty sample 12 after 3172 steps.
Found uncertainty sample 13 after 2368 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 345 steps.
Found uncertainty sample 17 after 1638 steps.
Found uncertainty sample 18 after 640 steps.
Found uncertainty sample 19 after 2760 steps.
Found uncertainty sample 20 after 712 steps.
Found uncertainty sample 21 after 2620 steps.
Found uncertainty sample 22 after 3460 steps.
Found uncertainty sample 23 after 114 steps.
Found uncertainty sample 24 after 517 steps.
Found uncertainty sample 25 after 1366 steps.
Found uncertainty sample 26 after 3221 steps.
Found uncertainty sample 27 after 215 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3138 steps.
Found uncertainty sample 30 after 186 steps.
Found uncertainty sample 31 after 1707 steps.
Found uncertainty sample 32 after 2401 steps.
Found uncertainty sample 33 after 709 steps.
Found uncertainty sample 34 after 2419 steps.
Found uncertainty sample 35 after 2689 steps.
Found uncertainty sample 36 after 2315 steps.
Found uncertainty sample 37 after 3590 steps.
Found uncertainty sample 38 after 463 steps.
Found uncertainty sample 39 after 500 steps.
Found uncertainty sample 40 after 930 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3106 steps.
Found uncertainty sample 43 after 1818 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 699 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1651 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1126 steps.
Found uncertainty sample 51 after 345 steps.
Found uncertainty sample 52 after 158 steps.
Found uncertainty sample 53 after 3825 steps.
Found uncertainty sample 54 after 1355 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 433 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2528 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 420 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 77 steps.
Found uncertainty sample 63 after 150 steps.
Found uncertainty sample 64 after 3052 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3290 steps.
Found uncertainty sample 68 after 1817 steps.
Found uncertainty sample 69 after 2023 steps.
Found uncertainty sample 70 after 180 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 648 steps.
Found uncertainty sample 73 after 1926 steps.
Found uncertainty sample 74 after 47 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1163 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 76 steps.
Found uncertainty sample 80 after 1086 steps.
Found uncertainty sample 81 after 306 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 785 steps.
Found uncertainty sample 84 after 2223 steps.
Found uncertainty sample 85 after 1790 steps.
Found uncertainty sample 86 after 1521 steps.
Found uncertainty sample 87 after 1011 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1312 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 43 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3238 steps.
Found uncertainty sample 95 after 3309 steps.
Found uncertainty sample 96 after 680 steps.
Found uncertainty sample 97 after 643 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 499 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_184742-lyh9i5wo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lyh9i5wo
Training model 17. Added 77 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.0812504198871613, Training Loss Force: 2.170361555171585, time: 1.3245692253112793
Validation Loss Energy: 1.897838467402512, Validation Loss Force: 2.0932635423204564, time: 0.1013181209564209
Test Loss Energy: 12.119802897557697, Test Loss Force: 10.167449782055034, time: 11.296005725860596


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.318819739576983, Training Loss Force: 1.8547788337863147, time: 1.2369344234466553
Validation Loss Energy: 2.035335273330759, Validation Loss Force: 2.1300069574320113, time: 0.08830881118774414
Test Loss Energy: 11.941961611342338, Test Loss Force: 10.195813158691589, time: 11.884097814559937


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.407996660630413, Training Loss Force: 1.863842951978172, time: 1.3780128955841064
Validation Loss Energy: 1.715952789902706, Validation Loss Force: 2.0759905399979734, time: 0.12604331970214844
Test Loss Energy: 13.458485480063027, Test Loss Force: 10.20524385686842, time: 11.375752925872803


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5051513687938816, Training Loss Force: 1.903729691339528, time: 1.2373595237731934
Validation Loss Energy: 0.9755094089304388, Validation Loss Force: 2.070782865347587, time: 0.09428930282592773
Test Loss Energy: 12.176543910982604, Test Loss Force: 10.184486303332601, time: 11.542136192321777


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4296894342689004, Training Loss Force: 1.91310874911107, time: 1.2495498657226562
Validation Loss Energy: 1.9591461303526692, Validation Loss Force: 2.1781002642497977, time: 0.0919792652130127
Test Loss Energy: 11.869293896968989, Test Loss Force: 10.214340644590923, time: 11.600845575332642


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7837699565643919, Training Loss Force: 1.8670548842521482, time: 1.225104808807373
Validation Loss Energy: 2.585460329245076, Validation Loss Force: 2.0756173465093983, time: 0.08586406707763672
Test Loss Energy: 11.748346335575208, Test Loss Force: 10.118103650603823, time: 11.547865390777588


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7470570692402305, Training Loss Force: 1.8626400810508204, time: 1.190091609954834
Validation Loss Energy: 0.7959307786179479, Validation Loss Force: 2.058130693141397, time: 0.08723258972167969
Test Loss Energy: 12.666050416280967, Test Loss Force: 10.215616639056494, time: 11.646003007888794


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.423247853797667, Training Loss Force: 1.8535139037478887, time: 1.1912503242492676
Validation Loss Energy: 1.7609029547238624, Validation Loss Force: 2.0262592789427423, time: 0.08325791358947754
Test Loss Energy: 13.897264964789771, Test Loss Force: 10.173748395040716, time: 11.448784351348877


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6718780625549454, Training Loss Force: 1.8775798462528308, time: 1.304809808731079
Validation Loss Energy: 1.4719242731536548, Validation Loss Force: 2.0037100198729267, time: 0.09440112113952637
Test Loss Energy: 12.527565153160221, Test Loss Force: 10.171907930792795, time: 11.44051456451416


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3180854682415812, Training Loss Force: 1.871319526092038, time: 1.1955046653747559
Validation Loss Energy: 0.7731022367718527, Validation Loss Force: 1.9887812783187713, time: 0.09158825874328613
Test Loss Energy: 12.477028919243422, Test Loss Force: 10.113766218854137, time: 11.63551115989685


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.604435353715547, Training Loss Force: 1.8828572254966796, time: 1.2721784114837646
Validation Loss Energy: 1.1945663046384132, Validation Loss Force: 2.069265263783516, time: 0.0950620174407959
Test Loss Energy: 12.381046248395183, Test Loss Force: 10.157162989794724, time: 11.28016972541809


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.1582351606879777, Training Loss Force: 1.8424080482748078, time: 1.063983678817749
Validation Loss Energy: 1.2387438631904863, Validation Loss Force: 1.9905168729767053, time: 0.08374500274658203
Test Loss Energy: 12.43978046078082, Test Loss Force: 10.22632939389554, time: 12.137248516082764


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.334187733947998, Training Loss Force: 1.894514011715851, time: 1.2191269397735596
Validation Loss Energy: 2.8902727911130626, Validation Loss Force: 2.1024390698167026, time: 0.09543657302856445
Test Loss Energy: 14.410754513275682, Test Loss Force: 10.222387035501082, time: 11.229009866714478


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8577857487821372, Training Loss Force: 1.8805718500415314, time: 1.1075611114501953
Validation Loss Energy: 4.988664181195089, Validation Loss Force: 2.2541650465098866, time: 0.07604169845581055
Test Loss Energy: 16.498560450567844, Test Loss Force: 10.323794654207713, time: 10.542257070541382


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7897317803468469, Training Loss Force: 1.8848108788291154, time: 1.3438966274261475
Validation Loss Energy: 0.856769110675776, Validation Loss Force: 2.0136302643277286, time: 0.08535289764404297
Test Loss Energy: 12.425254458346128, Test Loss Force: 10.262564001265096, time: 10.932851076126099


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5595173211197402, Training Loss Force: 1.8892996630916117, time: 1.2690997123718262
Validation Loss Energy: 0.797102240994674, Validation Loss Force: 2.02285856441156, time: 0.08428668975830078
Test Loss Energy: 12.945327668967108, Test Loss Force: 10.166510901681551, time: 10.496289014816284


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.338689832605316, Training Loss Force: 1.8724674343434924, time: 1.2504782676696777
Validation Loss Energy: 1.5518537011104665, Validation Loss Force: 2.146119519500492, time: 0.08627057075500488
Test Loss Energy: 13.511315215509343, Test Loss Force: 10.238481859815344, time: 11.257463693618774


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.53413743009908, Training Loss Force: 1.8833216401287898, time: 1.266568660736084
Validation Loss Energy: 1.0958948703361462, Validation Loss Force: 2.0800658307067432, time: 0.08719325065612793
Test Loss Energy: 13.13929870241262, Test Loss Force: 10.182223467191646, time: 10.429189443588257


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3778390416277926, Training Loss Force: 1.8689338442871744, time: 1.2539160251617432
Validation Loss Energy: 1.1310170870634875, Validation Loss Force: 2.025814608658324, time: 0.08741617202758789
Test Loss Energy: 12.04112388101372, Test Loss Force: 10.067726386135913, time: 10.929975032806396


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7071358908926813, Training Loss Force: 1.8477431232295498, time: 1.4224724769592285
Validation Loss Energy: 2.290253702997841, Validation Loss Force: 2.0713605804466964, time: 0.0905764102935791
Test Loss Energy: 14.027566836019453, Test Loss Force: 10.224651657658432, time: 10.419847965240479

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–„â–‚â–â–â–‚â–„â–‚â–‚â–‚â–‚â–…â–ˆâ–‚â–ƒâ–„â–ƒâ–â–„
wandb:   test_error_force â–„â–…â–…â–„â–…â–‚â–…â–„â–„â–‚â–ƒâ–…â–…â–ˆâ–†â–„â–†â–„â–â–…
wandb:          test_loss â–â–„â–†â–„â–‚â–‚â–…â–†â–„â–‚â–„â–†â–…â–ˆâ–„â–„â–†â–…â–ƒâ–†
wandb: train_error_energy â–†â–‚â–‚â–ƒâ–ƒâ–…â–„â–ƒâ–„â–‚â–„â–â–ˆâ–…â–…â–ƒâ–ˆâ–ƒâ–‚â–„
wandb:  train_error_force â–ˆâ–â–â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–â–ƒâ–‚â–â–‚â–‚â–…â–ˆâ–â–â–‚â–‚â–‚â–„
wandb:  valid_error_force â–„â–…â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚â–â–â–ƒâ–â–„â–ˆâ–‚â–‚â–…â–ƒâ–‚â–ƒ
wandb:         valid_loss â–ƒâ–„â–ƒâ–‚â–…â–„â–‚â–‚â–‚â–â–ƒâ–â–„â–ˆâ–â–‚â–„â–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2319
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 14.02757
wandb:   test_error_force 10.22465
wandb:          test_loss 8.87825
wandb: train_error_energy 1.70714
wandb:  train_error_force 1.84774
wandb:         train_loss -2.61131
wandb: valid_error_energy 2.29025
wandb:  valid_error_force 2.07136
wandb:         valid_loss -2.27089
wandb: 
wandb: ğŸš€ View run al_59_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lyh9i5wo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_184742-lyh9i5wo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 22.76615333557129, Uncertainty Bias: -2.6918933391571045
0.00020599365 0.01402092
0.46593073 4.9118176
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 78 steps.
Found uncertainty sample 2 after 3553 steps.
Found uncertainty sample 3 after 1263 steps.
Found uncertainty sample 4 after 3149 steps.
Found uncertainty sample 5 after 2170 steps.
Found uncertainty sample 6 after 2353 steps.
Found uncertainty sample 7 after 2230 steps.
Found uncertainty sample 8 after 2129 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2802 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 74 steps.
Found uncertainty sample 16 after 415 steps.
Found uncertainty sample 17 after 626 steps.
Found uncertainty sample 18 after 1717 steps.
Found uncertainty sample 19 after 1103 steps.
Found uncertainty sample 20 after 3896 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 265 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 2237 steps.
Found uncertainty sample 26 after 321 steps.
Found uncertainty sample 27 after 1330 steps.
Found uncertainty sample 28 after 1270 steps.
Found uncertainty sample 29 after 946 steps.
Found uncertainty sample 30 after 3069 steps.
Found uncertainty sample 31 after 2395 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1859 steps.
Found uncertainty sample 34 after 497 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3401 steps.
Found uncertainty sample 37 after 3118 steps.
Found uncertainty sample 38 after 697 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1000 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3178 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 607 steps.
Found uncertainty sample 45 after 3667 steps.
Found uncertainty sample 46 after 3230 steps.
Found uncertainty sample 47 after 2870 steps.
Found uncertainty sample 48 after 835 steps.
Found uncertainty sample 49 after 527 steps.
Found uncertainty sample 50 after 1536 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3382 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1679 steps.
Found uncertainty sample 55 after 460 steps.
Found uncertainty sample 56 after 2453 steps.
Found uncertainty sample 57 after 249 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 271 steps.
Found uncertainty sample 60 after 2087 steps.
Found uncertainty sample 61 after 1373 steps.
Found uncertainty sample 62 after 792 steps.
Found uncertainty sample 63 after 1582 steps.
Found uncertainty sample 64 after 2978 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 650 steps.
Found uncertainty sample 69 after 3720 steps.
Found uncertainty sample 70 after 2069 steps.
Found uncertainty sample 71 after 2448 steps.
Found uncertainty sample 72 after 1993 steps.
Found uncertainty sample 73 after 2063 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 932 steps.
Found uncertainty sample 76 after 421 steps.
Found uncertainty sample 77 after 428 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3253 steps.
Found uncertainty sample 80 after 2388 steps.
Found uncertainty sample 81 after 2144 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 16 steps.
Found uncertainty sample 84 after 865 steps.
Found uncertainty sample 85 after 221 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3039 steps.
Found uncertainty sample 88 after 69 steps.
Found uncertainty sample 89 after 1134 steps.
Found uncertainty sample 90 after 90 steps.
Found uncertainty sample 91 after 2388 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2955 steps.
Found uncertainty sample 94 after 2665 steps.
Found uncertainty sample 95 after 132 steps.
Found uncertainty sample 96 after 87 steps.
Found uncertainty sample 97 after 161 steps.
Found uncertainty sample 98 after 876 steps.
Found uncertainty sample 99 after 421 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_191433-gaklsn4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/gaklsn4u
Training model 18. Added 77 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.854891930070347, Training Loss Force: 2.131605022718655, time: 1.1362264156341553
Validation Loss Energy: 1.0036437668529878, Validation Loss Force: 2.095589544218818, time: 0.07207775115966797
Test Loss Energy: 13.209981644278574, Test Loss Force: 10.204784603503654, time: 8.256054162979126


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4000373400420285, Training Loss Force: 1.8834526414711097, time: 1.109421968460083
Validation Loss Energy: 0.7987055145126405, Validation Loss Force: 2.0265131217690997, time: 0.07062888145446777
Test Loss Energy: 12.838168317360415, Test Loss Force: 10.135402828209024, time: 8.258559942245483


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6777212843112208, Training Loss Force: 1.9038984594228396, time: 1.1053354740142822
Validation Loss Energy: 1.328689784340427, Validation Loss Force: 2.10471719784869, time: 0.07172727584838867
Test Loss Energy: 12.25664867690215, Test Loss Force: 10.081180918630086, time: 8.406885623931885


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.262391748817164, Training Loss Force: 1.876274454729375, time: 1.2296473979949951
Validation Loss Energy: 2.379308557893065, Validation Loss Force: 2.164035812985561, time: 0.07098388671875
Test Loss Energy: 14.200732895561716, Test Loss Force: 10.302206724291873, time: 8.746426105499268


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3241015863874694, Training Loss Force: 1.8844756770485431, time: 1.178617000579834
Validation Loss Energy: 1.131822815368027, Validation Loss Force: 2.077341362371744, time: 0.07038688659667969
Test Loss Energy: 12.208772996531911, Test Loss Force: 10.088975467238779, time: 8.253320693969727


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3498017805029068, Training Loss Force: 1.8705865139049027, time: 1.1799867153167725
Validation Loss Energy: 2.891991462915906, Validation Loss Force: 2.216445449862584, time: 0.07302594184875488
Test Loss Energy: 11.806652911283186, Test Loss Force: 10.061623516816605, time: 8.201419830322266


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5757826323108295, Training Loss Force: 1.900567829263108, time: 1.3541085720062256
Validation Loss Energy: 1.8419961629718657, Validation Loss Force: 2.011705066892037, time: 0.06985688209533691
Test Loss Energy: 13.689990440811064, Test Loss Force: 10.131302260471866, time: 10.975930213928223


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.189531763042406, Training Loss Force: 1.9137721942309012, time: 1.203911304473877
Validation Loss Energy: 1.4020426790722615, Validation Loss Force: 2.087014444074566, time: 0.08591556549072266
Test Loss Energy: 12.366468679983202, Test Loss Force: 9.999953410576104, time: 10.594749450683594


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3218147282405006, Training Loss Force: 1.8644983742778376, time: 1.2414379119873047
Validation Loss Energy: 1.2805047378345185, Validation Loss Force: 2.079421537533001, time: 0.07822942733764648
Test Loss Energy: 12.251968763684728, Test Loss Force: 10.10599894080388, time: 9.291829347610474


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3329164173298407, Training Loss Force: 1.8830015108125382, time: 1.1101641654968262
Validation Loss Energy: 1.68263419325738, Validation Loss Force: 2.1061457317543897, time: 0.07534575462341309
Test Loss Energy: 14.012994467106896, Test Loss Force: 10.149063522021342, time: 9.004549741744995


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4983806602243142, Training Loss Force: 1.892931539349612, time: 1.1274690628051758
Validation Loss Energy: 0.924571141936063, Validation Loss Force: 2.08473486869313, time: 0.07622551918029785
Test Loss Energy: 12.207941361080275, Test Loss Force: 10.025472040815938, time: 9.029789924621582


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4900682643961967, Training Loss Force: 1.904966848251916, time: 1.1158640384674072
Validation Loss Energy: 2.0921831516244147, Validation Loss Force: 2.09665078536831, time: 0.07362937927246094
Test Loss Energy: 13.653268885164534, Test Loss Force: 10.126094810239335, time: 9.198785066604614


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8028029515658095, Training Loss Force: 1.8884799719268264, time: 1.087644100189209
Validation Loss Energy: 1.0372082459027048, Validation Loss Force: 2.05349394218117, time: 0.07887458801269531
Test Loss Energy: 12.944944276998488, Test Loss Force: 10.105115315021191, time: 9.116220951080322


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7703708631377826, Training Loss Force: 1.8797214265489317, time: 1.150953769683838
Validation Loss Energy: 1.0924323929506121, Validation Loss Force: 1.995294128168013, time: 0.07378053665161133
Test Loss Energy: 13.36884564359337, Test Loss Force: 10.06641732005604, time: 9.080161094665527


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5439211654851535, Training Loss Force: 1.8901624763225269, time: 1.1581227779388428
Validation Loss Energy: 1.6438815231075457, Validation Loss Force: 2.0782501864908483, time: 0.07691025733947754
Test Loss Energy: 12.430028596752296, Test Loss Force: 10.090036766678622, time: 9.206687450408936


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5911076217746993, Training Loss Force: 1.8804457841252444, time: 1.1816661357879639
Validation Loss Energy: 2.3462151354215584, Validation Loss Force: 2.126751311849401, time: 0.07480835914611816
Test Loss Energy: 11.956353727832553, Test Loss Force: 10.136965634524236, time: 9.038975954055786


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2121848909598374, Training Loss Force: 1.8801815946059064, time: 1.141273021697998
Validation Loss Energy: 1.577347926637036, Validation Loss Force: 2.0330732888118512, time: 0.07733917236328125
Test Loss Energy: 12.541878013424173, Test Loss Force: 10.034974552706847, time: 9.105614185333252


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6011790081079127, Training Loss Force: 1.885020172880002, time: 1.1280138492584229
Validation Loss Energy: 2.8925347756319697, Validation Loss Force: 2.2220008223843366, time: 0.0807192325592041
Test Loss Energy: 11.719730137359265, Test Loss Force: 9.9658057936758, time: 9.658920526504517


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5326071153468814, Training Loss Force: 1.86050048039527, time: 1.1180498600006104
Validation Loss Energy: 3.303397982965557, Validation Loss Force: 2.083708920603268, time: 0.0774235725402832
Test Loss Energy: 14.92749370227211, Test Loss Force: 10.167968090541558, time: 9.140539407730103


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0104094798266052, Training Loss Force: 1.8869944510488392, time: 1.1465425491333008
Validation Loss Energy: 2.577510595397162, Validation Loss Force: 2.047337696969131, time: 0.0801842212677002
Test Loss Energy: 11.70181617840281, Test Loss Force: 9.959453460301402, time: 9.020026922225952

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‚â–†â–‚â–â–…â–‚â–‚â–†â–‚â–…â–„â–…â–ƒâ–‚â–ƒâ–â–ˆâ–
wandb:   test_error_force â–†â–…â–ƒâ–ˆâ–„â–ƒâ–…â–‚â–„â–…â–‚â–„â–„â–ƒâ–„â–…â–ƒâ–â–…â–
wandb:          test_loss â–‚â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–â–„â–†â–ƒâ–„â–ƒâ–„â–„â–„â–ƒâ–â–‡â–
wandb: train_error_energy â–ˆâ–‚â–ƒâ–â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–â–‚â–â–â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚
wandb: valid_error_energy â–‚â–â–‚â–…â–‚â–‡â–„â–ƒâ–‚â–ƒâ–â–…â–‚â–‚â–ƒâ–…â–ƒâ–‡â–ˆâ–†
wandb:  valid_error_force â–„â–‚â–„â–†â–„â–ˆâ–‚â–„â–„â–„â–„â–„â–ƒâ–â–„â–…â–‚â–ˆâ–„â–ƒ
wandb:         valid_loss â–ƒâ–â–„â–†â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–„â–ƒâ–„â–‚â–â–ƒâ–…â–‚â–ˆâ–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2388
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.70182
wandb:   test_error_force 9.95945
wandb:          test_loss 8.28117
wandb: train_error_energy 2.01041
wandb:  train_error_force 1.88699
wandb:         train_loss -2.53825
wandb: valid_error_energy 2.57751
wandb:  valid_error_force 2.04734
wandb:         valid_loss -2.2866
wandb: 
wandb: ğŸš€ View run al_59_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/gaklsn4u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_191433-gaklsn4u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 22.281909942626953, Uncertainty Bias: -2.658825159072876
3.0517578e-05 0.13971901
0.48940897 4.904215
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1791 steps.
Found uncertainty sample 1 after 2450 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 836 steps.
Found uncertainty sample 4 after 2143 steps.
Found uncertainty sample 5 after 1575 steps.
Found uncertainty sample 6 after 22 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2674 steps.
Found uncertainty sample 9 after 789 steps.
Found uncertainty sample 10 after 3031 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2261 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 6 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 155 steps.
Found uncertainty sample 17 after 390 steps.
Found uncertainty sample 18 after 1077 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 692 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1755 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3436 steps.
Found uncertainty sample 29 after 1927 steps.
Found uncertainty sample 30 after 1509 steps.
Found uncertainty sample 31 after 1416 steps.
Found uncertainty sample 32 after 3654 steps.
Found uncertainty sample 33 after 177 steps.
Found uncertainty sample 34 after 229 steps.
Found uncertainty sample 35 after 489 steps.
Found uncertainty sample 36 after 440 steps.
Found uncertainty sample 37 after 1135 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2102 steps.
Found uncertainty sample 40 after 2269 steps.
Found uncertainty sample 41 after 1601 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 44 steps.
Found uncertainty sample 46 after 2561 steps.
Found uncertainty sample 47 after 3130 steps.
Found uncertainty sample 48 after 926 steps.
Found uncertainty sample 49 after 351 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 96 steps.
Found uncertainty sample 52 after 403 steps.
Found uncertainty sample 53 after 64 steps.
Found uncertainty sample 54 after 1168 steps.
Found uncertainty sample 55 after 353 steps.
Found uncertainty sample 56 after 121 steps.
Found uncertainty sample 57 after 1718 steps.
Found uncertainty sample 58 after 54 steps.
Found uncertainty sample 59 after 73 steps.
Found uncertainty sample 60 after 3939 steps.
Found uncertainty sample 61 after 1975 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1603 steps.
Found uncertainty sample 64 after 342 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3906 steps.
Found uncertainty sample 67 after 103 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3208 steps.
Found uncertainty sample 72 after 431 steps.
Found uncertainty sample 73 after 2568 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 698 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 701 steps.
Found uncertainty sample 78 after 2113 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1699 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1125 steps.
Found uncertainty sample 84 after 1117 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3397 steps.
Found uncertainty sample 87 after 199 steps.
Found uncertainty sample 88 after 883 steps.
Found uncertainty sample 89 after 3292 steps.
Found uncertainty sample 90 after 2111 steps.
Found uncertainty sample 91 after 3014 steps.
Found uncertainty sample 92 after 552 steps.
Found uncertainty sample 93 after 228 steps.
Found uncertainty sample 94 after 1189 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1789 steps.
Found uncertainty sample 98 after 3418 steps.
Found uncertainty sample 99 after 399 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_194009-tp0rpxgf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/tp0rpxgf
Training model 19. Added 73 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.568823234578726, Training Loss Force: 2.126704493492615, time: 1.1765389442443848
Validation Loss Energy: 0.7985868596915043, Validation Loss Force: 2.182734009176555, time: 0.07487034797668457
Test Loss Energy: 13.102684410340855, Test Loss Force: 10.13219262461929, time: 8.348295450210571


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.644221486117898, Training Loss Force: 1.9052297188373195, time: 1.1757426261901855
Validation Loss Energy: 1.26536195556384, Validation Loss Force: 2.06685832165061, time: 0.07447481155395508
Test Loss Energy: 12.363896769741238, Test Loss Force: 9.926083954319603, time: 8.43204951286316


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3283868140493218, Training Loss Force: 1.8988362688110152, time: 1.1961655616760254
Validation Loss Energy: 2.8884162871088894, Validation Loss Force: 2.0597029599807932, time: 0.07175421714782715
Test Loss Energy: 14.572932738811378, Test Loss Force: 10.085967801638889, time: 8.547683477401733


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4720812028490065, Training Loss Force: 1.88833436338633, time: 1.1455116271972656
Validation Loss Energy: 1.7822909385303776, Validation Loss Force: 2.1597996438188574, time: 0.07521796226501465
Test Loss Energy: 12.127573770956882, Test Loss Force: 10.031839860771143, time: 9.536787509918213


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.1944263397293549, Training Loss Force: 1.8654005127702942, time: 1.272078514099121
Validation Loss Energy: 0.8897813424099488, Validation Loss Force: 2.039793888974244, time: 0.08890342712402344
Test Loss Energy: 12.300261998833285, Test Loss Force: 10.016702028808638, time: 10.979910612106323


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.573603307562438, Training Loss Force: 1.9143077360443956, time: 1.1957619190216064
Validation Loss Energy: 2.195371039880822, Validation Loss Force: 1.99401422591722, time: 0.08509039878845215
Test Loss Energy: 11.760978946122055, Test Loss Force: 9.899621794467786, time: 9.956992387771606


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.302031011470835, Training Loss Force: 1.8655962389495648, time: 1.1025750637054443
Validation Loss Energy: 1.5698161984433152, Validation Loss Force: 2.1287758197241766, time: 0.07877755165100098
Test Loss Energy: 13.479539759471612, Test Loss Force: 9.978128859135596, time: 9.179926633834839


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.293367889417951, Training Loss Force: 1.8901784152691736, time: 1.1291546821594238
Validation Loss Energy: 0.7789745509891901, Validation Loss Force: 2.0662043423690197, time: 0.0801548957824707
Test Loss Energy: 12.66563669933945, Test Loss Force: 10.096426107431913, time: 9.653364896774292


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4967197397658463, Training Loss Force: 1.8862321671140825, time: 1.1790196895599365
Validation Loss Energy: 0.8276555095167231, Validation Loss Force: 2.117738110160536, time: 0.08167362213134766
Test Loss Energy: 12.472314027151363, Test Loss Force: 10.098763886313057, time: 9.364651679992676


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0186823196328514, Training Loss Force: 1.9082771658766797, time: 1.1174867153167725
Validation Loss Energy: 3.148343659213617, Validation Loss Force: 2.1012774048823974, time: 0.07802844047546387
Test Loss Energy: 14.56240344003244, Test Loss Force: 10.05057642250624, time: 9.208386898040771


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3494337164390924, Training Loss Force: 1.8893459493162799, time: 1.2025933265686035
Validation Loss Energy: 1.0142398121656804, Validation Loss Force: 2.019895060748407, time: 0.07842159271240234
Test Loss Energy: 12.739373155664826, Test Loss Force: 10.039358276322748, time: 9.225339889526367


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7881914337692828, Training Loss Force: 1.870992755832444, time: 1.1115508079528809
Validation Loss Energy: 1.9014091898266097, Validation Loss Force: 1.9956928172737969, time: 0.08087396621704102
Test Loss Energy: 11.898106127971454, Test Loss Force: 9.937940538410945, time: 9.369898319244385


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3867958394611608, Training Loss Force: 1.887823930516879, time: 1.1724679470062256
Validation Loss Energy: 2.1968222860394064, Validation Loss Force: 2.080958399978195, time: 0.08366727828979492
Test Loss Energy: 13.69979345112634, Test Loss Force: 9.988995659054572, time: 9.242348432540894


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.23232928851339, Training Loss Force: 1.8508691619005395, time: 1.1374874114990234
Validation Loss Energy: 2.1971343568474238, Validation Loss Force: 2.0136618833464506, time: 0.0833895206451416
Test Loss Energy: 13.805784617439915, Test Loss Force: 10.033907885891361, time: 9.191104650497437


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5423110868992675, Training Loss Force: 1.8928010789814738, time: 1.1704156398773193
Validation Loss Energy: 1.5224749009986136, Validation Loss Force: 2.056486504167866, time: 0.07711458206176758
Test Loss Energy: 12.014322853696013, Test Loss Force: 9.92432176702003, time: 9.400738000869751


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6496757726310132, Training Loss Force: 1.9247951000171297, time: 1.1200706958770752
Validation Loss Energy: 1.254218144152165, Validation Loss Force: 2.1293910545743753, time: 0.0793449878692627
Test Loss Energy: 13.26687614785926, Test Loss Force: 10.148960236180228, time: 9.165827989578247


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7207105846782018, Training Loss Force: 1.899126901207172, time: 1.0970158576965332
Validation Loss Energy: 1.8120256196047095, Validation Loss Force: 2.1657915592012014, time: 0.07863426208496094
Test Loss Energy: 13.548181000140461, Test Loss Force: 10.130814743281059, time: 9.164376258850098


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.84392951891831, Training Loss Force: 1.878026978257358, time: 1.338341474533081
Validation Loss Energy: 2.106806836448649, Validation Loss Force: 2.12675465188659, time: 0.0762031078338623
Test Loss Energy: 11.9476235444572, Test Loss Force: 9.983995307449051, time: 9.194197416305542


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.608966591835365, Training Loss Force: 1.8701725800596831, time: 1.1307268142700195
Validation Loss Energy: 0.8956352585891038, Validation Loss Force: 2.098293192988673, time: 0.08086276054382324
Test Loss Energy: 12.780182357243204, Test Loss Force: 9.947577341947182, time: 9.607859134674072


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4134409160094228, Training Loss Force: 1.8864298539385598, time: 1.1194818019866943
Validation Loss Energy: 1.5050440819189541, Validation Loss Force: 2.0182773694032417, time: 0.08289742469787598
Test Loss Energy: 13.078097716927727, Test Loss Force: 9.968242092578855, time: 9.359825849533081

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–ˆâ–‚â–‚â–â–…â–ƒâ–ƒâ–ˆâ–ƒâ–â–†â–†â–‚â–…â–…â–â–„â–„
wandb:   test_error_force â–ˆâ–‚â–†â–…â–„â–â–ƒâ–‡â–‡â–…â–…â–‚â–„â–…â–‚â–ˆâ–‡â–ƒâ–‚â–ƒ
wandb:          test_loss â–ƒâ–â–†â–…â–†â–‚â–†â–…â–‡â–†â–…â–„â–†â–ˆâ–ƒâ–ˆâ–‡â–„â–†â–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–…â–‚â–„â–‚â–â–ƒâ–ƒâ–„â–„â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–â–‚â–‡â–„â–â–…â–ƒâ–â–â–ˆâ–‚â–„â–…â–…â–ƒâ–‚â–„â–…â–â–ƒ
wandb:  valid_error_force â–ˆâ–„â–ƒâ–‡â–ƒâ–â–†â–„â–†â–…â–‚â–â–„â–‚â–ƒâ–†â–‡â–†â–…â–‚
wandb:         valid_loss â–†â–ƒâ–†â–ˆâ–‚â–‚â–†â–‚â–„â–ˆâ–â–‚â–†â–ƒâ–ƒâ–†â–ˆâ–‡â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2453
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.0781
wandb:   test_error_force 9.96824
wandb:          test_loss 8.5498
wandb: train_error_energy 1.41344
wandb:  train_error_force 1.88643
wandb:         train_loss -2.57894
wandb: valid_error_energy 1.50504
wandb:  valid_error_force 2.01828
wandb:         valid_loss -2.39465
wandb: 
wandb: ğŸš€ View run al_59_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/tp0rpxgf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_194009-tp0rpxgf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.682693481445312, Uncertainty Bias: -2.7996702194213867
9.727478e-05 0.0026605725
0.50656337 4.559605
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 573 steps.
Found uncertainty sample 1 after 3554 steps.
Found uncertainty sample 2 after 2216 steps.
Found uncertainty sample 3 after 2864 steps.
Found uncertainty sample 4 after 1988 steps.
Found uncertainty sample 5 after 268 steps.
Found uncertainty sample 6 after 607 steps.
Found uncertainty sample 7 after 440 steps.
Found uncertainty sample 8 after 1489 steps.
Found uncertainty sample 9 after 377 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2184 steps.
Found uncertainty sample 15 after 252 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 205 steps.
Found uncertainty sample 18 after 1740 steps.
Found uncertainty sample 19 after 411 steps.
Found uncertainty sample 20 after 1408 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1357 steps.
Found uncertainty sample 28 after 1398 steps.
Found uncertainty sample 29 after 2218 steps.
Found uncertainty sample 30 after 1511 steps.
Found uncertainty sample 31 after 177 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1149 steps.
Found uncertainty sample 35 after 620 steps.
Found uncertainty sample 36 after 956 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1296 steps.
Found uncertainty sample 39 after 787 steps.
Found uncertainty sample 40 after 641 steps.
Found uncertainty sample 41 after 3318 steps.
Found uncertainty sample 42 after 1120 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 368 steps.
Found uncertainty sample 45 after 934 steps.
Found uncertainty sample 46 after 47 steps.
Found uncertainty sample 47 after 260 steps.
Found uncertainty sample 48 after 2461 steps.
Found uncertainty sample 49 after 464 steps.
Found uncertainty sample 50 after 2927 steps.
Found uncertainty sample 51 after 961 steps.
Found uncertainty sample 52 after 378 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1223 steps.
Found uncertainty sample 55 after 390 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 579 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1723 steps.
Found uncertainty sample 62 after 68 steps.
Found uncertainty sample 63 after 2781 steps.
Found uncertainty sample 64 after 24 steps.
Found uncertainty sample 65 after 138 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 489 steps.
Found uncertainty sample 70 after 963 steps.
Found uncertainty sample 71 after 905 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1265 steps.
Found uncertainty sample 74 after 133 steps.
Found uncertainty sample 75 after 540 steps.
Found uncertainty sample 76 after 3130 steps.
Found uncertainty sample 77 after 284 steps.
Found uncertainty sample 78 after 886 steps.
Found uncertainty sample 79 after 1403 steps.
Found uncertainty sample 80 after 19 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1817 steps.
Found uncertainty sample 83 after 1087 steps.
Found uncertainty sample 84 after 927 steps.
Found uncertainty sample 85 after 3432 steps.
Found uncertainty sample 86 after 3188 steps.
Found uncertainty sample 87 after 562 steps.
Found uncertainty sample 88 after 1097 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 733 steps.
Found uncertainty sample 91 after 2839 steps.
Found uncertainty sample 92 after 243 steps.
Found uncertainty sample 93 after 1510 steps.
Found uncertainty sample 94 after 39 steps.
Found uncertainty sample 95 after 327 steps.
Found uncertainty sample 96 after 1332 steps.
Found uncertainty sample 97 after 793 steps.
Found uncertainty sample 98 after 1427 steps.
Found uncertainty sample 99 after 161 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_200301-8bz766if
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8bz766if
Training model 20. Added 78 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.9943146165305725, Training Loss Force: 2.054701066853704, time: 1.2771122455596924
Validation Loss Energy: 1.6875509506686115, Validation Loss Force: 2.0143490403307833, time: 0.07553648948669434
Test Loss Energy: 12.017535556776057, Test Loss Force: 9.892720393953743, time: 8.821611881256104


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2792371563749172, Training Loss Force: 1.8922186427327512, time: 1.2444772720336914
Validation Loss Energy: 0.8934056445972856, Validation Loss Force: 2.0667194874381236, time: 0.09474802017211914
Test Loss Energy: 12.792029185861177, Test Loss Force: 9.891812920422103, time: 11.032464504241943


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4797474759640443, Training Loss Force: 1.8925885455095814, time: 1.2203435897827148
Validation Loss Energy: 2.570443522043706, Validation Loss Force: 2.0445696968161027, time: 0.07440066337585449
Test Loss Energy: 14.201467367990846, Test Loss Force: 10.006815206293155, time: 8.48374891281128


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7215994962346441, Training Loss Force: 1.8910972935975447, time: 1.2255992889404297
Validation Loss Energy: 1.522288860927191, Validation Loss Force: 2.002768686058517, time: 0.0744171142578125
Test Loss Energy: 13.694453070911111, Test Loss Force: 9.911305260875915, time: 8.222328901290894


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5786749755562335, Training Loss Force: 1.8908485707522444, time: 1.2330846786499023
Validation Loss Energy: 1.683337939093085, Validation Loss Force: 2.0889084678298278, time: 0.07523059844970703
Test Loss Energy: 12.043618181148961, Test Loss Force: 9.812415407668762, time: 8.26164960861206


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5419027557948455, Training Loss Force: 1.8930928756228256, time: 1.2261381149291992
Validation Loss Energy: 1.2817448379754768, Validation Loss Force: 2.0529290305579506, time: 0.07783269882202148
Test Loss Energy: 12.934020664970511, Test Loss Force: 9.95605891463821, time: 8.52200198173523


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.2108321412953529, Training Loss Force: 1.8930720786064552, time: 1.2031919956207275
Validation Loss Energy: 1.6068068319741364, Validation Loss Force: 2.0522733812577667, time: 0.0742037296295166
Test Loss Energy: 13.572689556502088, Test Loss Force: 9.95558548972298, time: 8.334410190582275


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2493764755685546, Training Loss Force: 1.9184945447728539, time: 1.1502759456634521
Validation Loss Energy: 0.899078029755223, Validation Loss Force: 2.042701614016342, time: 0.07399797439575195
Test Loss Energy: 12.639819967574532, Test Loss Force: 9.83928966165869, time: 8.292120933532715


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.352902025025505, Training Loss Force: 1.896806220453487, time: 1.1952364444732666
Validation Loss Energy: 1.8768197247072314, Validation Loss Force: 2.007206148133139, time: 0.07394218444824219
Test Loss Energy: 11.829248289679773, Test Loss Force: 9.928050544900296, time: 8.515618085861206


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4613140495944896, Training Loss Force: 1.9143678780912055, time: 1.172614336013794
Validation Loss Energy: 2.0807444149289585, Validation Loss Force: 2.127637980388486, time: 0.0831449031829834
Test Loss Energy: 11.700889688226622, Test Loss Force: 9.887991283678948, time: 8.395819664001465


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7199683305875526, Training Loss Force: 1.9092941403413932, time: 1.217742919921875
Validation Loss Energy: 1.2471162230773711, Validation Loss Force: 2.131555732676512, time: 0.07475447654724121
Test Loss Energy: 13.400923239511792, Test Loss Force: 10.011839452279903, time: 8.430018663406372


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4467094861308374, Training Loss Force: 1.890585815522856, time: 1.2608082294464111
Validation Loss Energy: 1.9724093066952848, Validation Loss Force: 2.1022465723400483, time: 0.0754079818725586
Test Loss Energy: 13.825307250224029, Test Loss Force: 9.999399433057176, time: 8.503186464309692


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5254963691046275, Training Loss Force: 1.8760051227553667, time: 1.1812200546264648
Validation Loss Energy: 1.2579133386288366, Validation Loss Force: 2.04212645961241, time: 0.07518172264099121
Test Loss Energy: 12.171626135821821, Test Loss Force: 9.89513927103629, time: 8.748202323913574


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.2210917088658269, Training Loss Force: 1.869854902293954, time: 1.2587835788726807
Validation Loss Energy: 1.1152917744734183, Validation Loss Force: 2.1026424780815076, time: 0.08967161178588867
Test Loss Energy: 12.14011179724642, Test Loss Force: 9.833278615965613, time: 10.994106531143188


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5283664454448336, Training Loss Force: 1.8963230298161216, time: 1.2621500492095947
Validation Loss Energy: 0.9381205316321256, Validation Loss Force: 2.1981103157140254, time: 0.08450865745544434
Test Loss Energy: 13.025716556053627, Test Loss Force: 10.069472597215718, time: 10.740069150924683


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5111817349619567, Training Loss Force: 1.9314360205715402, time: 1.1781389713287354
Validation Loss Energy: 2.529210206273663, Validation Loss Force: 2.0086202085443534, time: 0.0772547721862793
Test Loss Energy: 11.762530826493627, Test Loss Force: 9.842351145575085, time: 9.053544044494629


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7695028049664736, Training Loss Force: 1.8696175820819432, time: 1.1769120693206787
Validation Loss Energy: 2.469524743718876, Validation Loss Force: 2.156531974102367, time: 0.07758092880249023
Test Loss Energy: 11.737744887329761, Test Loss Force: 9.764833930364839, time: 9.102158546447754


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9377968747706134, Training Loss Force: 1.8785904200555643, time: 1.1466026306152344
Validation Loss Energy: 1.0006628671628093, Validation Loss Force: 2.0472776876343035, time: 0.08780980110168457
Test Loss Energy: 12.48351776862299, Test Loss Force: 9.880926460333091, time: 9.257917881011963


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.45831617102961, Training Loss Force: 1.9075069118089754, time: 1.1446588039398193
Validation Loss Energy: 1.1009699455101323, Validation Loss Force: 2.075618682524274, time: 0.08122086524963379
Test Loss Energy: 12.336360365328131, Test Loss Force: 9.91797905388538, time: 9.091113328933716


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3986353824129396, Training Loss Force: 1.9131508235022017, time: 1.179401159286499
Validation Loss Energy: 1.794938991357368, Validation Loss Force: 2.106943109965957, time: 0.07866716384887695
Test Loss Energy: 13.734127028240284, Test Loss Force: 10.008760411309384, time: 9.130997657775879

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ˆâ–‡â–‚â–„â–†â–„â–â–â–†â–‡â–‚â–‚â–…â–â–â–ƒâ–ƒâ–‡
wandb:   test_error_force â–„â–„â–‡â–„â–‚â–…â–…â–ƒâ–…â–„â–‡â–†â–„â–ƒâ–ˆâ–ƒâ–â–„â–…â–‡
wandb:          test_loss â–â–„â–ˆâ–†â–ƒâ–…â–‡â–‚â–„â–„â–†â–ˆâ–†â–…â–†â–â–ƒâ–†â–„â–†
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–‚â–ƒâ–â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–„â–â–ˆâ–„â–„â–ƒâ–„â–â–…â–†â–‚â–†â–ƒâ–‚â–â–ˆâ–ˆâ–â–‚â–…
wandb:  valid_error_force â–â–ƒâ–‚â–â–„â–ƒâ–ƒâ–‚â–â–…â–†â–…â–‚â–…â–ˆâ–â–‡â–ƒâ–„â–…
wandb:         valid_loss â–‚â–‚â–„â–â–„â–‚â–ƒâ–â–‚â–†â–…â–…â–‚â–„â–‡â–ƒâ–ˆâ–‚â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2523
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.73413
wandb:   test_error_force 10.00876
wandb:          test_loss 8.38835
wandb: train_error_energy 1.39864
wandb:  train_error_force 1.91315
wandb:         train_loss -2.54478
wandb: valid_error_energy 1.79494
wandb:  valid_error_force 2.10694
wandb:         valid_loss -2.26224
wandb: 
wandb: ğŸš€ View run al_59_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8bz766if
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_200301-8bz766if/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.260026931762695, Uncertainty Bias: -2.5497546195983887
1.6212463e-05 0.012401581
0.6821193 4.700503
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3013 steps.
Found uncertainty sample 1 after 1424 steps.
Found uncertainty sample 2 after 2791 steps.
Found uncertainty sample 3 after 40 steps.
Found uncertainty sample 4 after 2852 steps.
Found uncertainty sample 5 after 175 steps.
Found uncertainty sample 6 after 2685 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 546 steps.
Found uncertainty sample 9 after 4 steps.
Found uncertainty sample 10 after 3155 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3284 steps.
Found uncertainty sample 13 after 3824 steps.
Found uncertainty sample 14 after 1960 steps.
Found uncertainty sample 15 after 427 steps.
Found uncertainty sample 16 after 933 steps.
Found uncertainty sample 17 after 2288 steps.
Found uncertainty sample 18 after 592 steps.
Found uncertainty sample 19 after 1994 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1093 steps.
Found uncertainty sample 25 after 926 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1907 steps.
Found uncertainty sample 28 after 28 steps.
Found uncertainty sample 29 after 492 steps.
Found uncertainty sample 30 after 2182 steps.
Found uncertainty sample 31 after 675 steps.
Found uncertainty sample 32 after 529 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 104 steps.
Found uncertainty sample 36 after 3927 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 343 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 280 steps.
Found uncertainty sample 41 after 2241 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 166 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1293 steps.
Found uncertainty sample 47 after 1426 steps.
Found uncertainty sample 48 after 1652 steps.
Found uncertainty sample 49 after 621 steps.
Found uncertainty sample 50 after 542 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 222 steps.
Found uncertainty sample 53 after 3718 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 44 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 788 steps.
Found uncertainty sample 59 after 168 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2784 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 114 steps.
Found uncertainty sample 65 after 514 steps.
Found uncertainty sample 66 after 3896 steps.
Found uncertainty sample 67 after 84 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 478 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1449 steps.
Found uncertainty sample 73 after 242 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 464 steps.
Found uncertainty sample 76 after 3539 steps.
Found uncertainty sample 77 after 1966 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3101 steps.
Found uncertainty sample 81 after 11 steps.
Found uncertainty sample 82 after 975 steps.
Found uncertainty sample 83 after 355 steps.
Found uncertainty sample 84 after 1425 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1404 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2226 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3053 steps.
Found uncertainty sample 91 after 3544 steps.
Found uncertainty sample 92 after 795 steps.
Found uncertainty sample 93 after 2880 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3156 steps.
Found uncertainty sample 96 after 2445 steps.
Found uncertainty sample 97 after 393 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_203021-duoo4w56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/duoo4w56
Training model 21. Added 67 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.307316412867758, Training Loss Force: 2.151527157916426, time: 1.310380458831787
Validation Loss Energy: 2.7099500840158104, Validation Loss Force: 2.0690142043214825, time: 0.09256291389465332
Test Loss Energy: 11.492510506112385, Test Loss Force: 9.808563021598944, time: 10.256216049194336


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8247257034760487, Training Loss Force: 1.8846797593136104, time: 1.3498494625091553
Validation Loss Energy: 1.49028668427259, Validation Loss Force: 2.0859367254082755, time: 0.09308028221130371
Test Loss Energy: 13.540157169928273, Test Loss Force: 9.96519994240652, time: 10.31920576095581


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4369377505914915, Training Loss Force: 1.8875741585694754, time: 1.3242089748382568
Validation Loss Energy: 0.8980684478475864, Validation Loss Force: 2.054745120112138, time: 0.08878803253173828
Test Loss Energy: 12.669756964552466, Test Loss Force: 9.853232779222923, time: 10.428165435791016


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3904579525126297, Training Loss Force: 1.8982652726114715, time: 1.3479301929473877
Validation Loss Energy: 1.0815046262777737, Validation Loss Force: 2.067976788770605, time: 0.09149694442749023
Test Loss Energy: 13.140723379245706, Test Loss Force: 9.9429388941548, time: 10.834724187850952


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4772598107503367, Training Loss Force: 1.90950906521867, time: 1.249276876449585
Validation Loss Energy: 1.014512581869442, Validation Loss Force: 2.162769159548951, time: 0.08839893341064453
Test Loss Energy: 12.386854317754967, Test Loss Force: 9.953831784835481, time: 10.43075156211853


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7084006744243745, Training Loss Force: 1.91160229126598, time: 1.2682223320007324
Validation Loss Energy: 2.7476652272801942, Validation Loss Force: 2.107646633132516, time: 0.0885777473449707
Test Loss Energy: 14.465815113770509, Test Loss Force: 9.946401448337872, time: 10.196430683135986


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4370171293930132, Training Loss Force: 1.928063674173063, time: 1.236053228378296
Validation Loss Energy: 3.363139892148836, Validation Loss Force: 2.3331354384551872, time: 0.08777165412902832
Test Loss Energy: 14.764413990789762, Test Loss Force: 10.18653929420514, time: 10.509634017944336


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.446346638101672, Training Loss Force: 1.8906998973229499, time: 1.2889223098754883
Validation Loss Energy: 1.9148835121868515, Validation Loss Force: 2.0579809481407607, time: 0.08619213104248047
Test Loss Energy: 11.620015055976006, Test Loss Force: 9.750307027927107, time: 10.519804239273071


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2193731230214857, Training Loss Force: 1.861532267969739, time: 1.216994285583496
Validation Loss Energy: 0.8971334601038357, Validation Loss Force: 2.0938496075125386, time: 0.08484363555908203
Test Loss Energy: 12.306284143009446, Test Loss Force: 9.760194172205335, time: 10.299683809280396


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3911020092722168, Training Loss Force: 1.9131137254445092, time: 1.2758598327636719
Validation Loss Energy: 0.794535951254213, Validation Loss Force: 1.9878368271363187, time: 0.08534550666809082
Test Loss Energy: 12.572390051722754, Test Loss Force: 9.783583744994441, time: 10.329349279403687


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2103167077115504, Training Loss Force: 1.8895715365454702, time: 1.4487910270690918
Validation Loss Energy: 0.9321308986085277, Validation Loss Force: 2.109990114558833, time: 0.12531065940856934
Test Loss Energy: 12.74786368175397, Test Loss Force: 9.83568018314513, time: 10.447628021240234


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.1675617644642982, Training Loss Force: 1.8899574565378858, time: 1.312972068786621
Validation Loss Energy: 0.8862946219211519, Validation Loss Force: 2.1471544856907645, time: 0.08522844314575195
Test Loss Energy: 12.530911956693238, Test Loss Force: 9.91716834700185, time: 10.200323104858398


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4101507513004437, Training Loss Force: 1.9052727228648532, time: 1.2854154109954834
Validation Loss Energy: 1.24484227009187, Validation Loss Force: 2.1739901258196896, time: 0.08960580825805664
Test Loss Energy: 13.09550120628424, Test Loss Force: 9.951603489225706, time: 10.347991466522217


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3306701497751485, Training Loss Force: 1.8885181382981187, time: 1.2627792358398438
Validation Loss Energy: 1.6296789056382606, Validation Loss Force: 2.072624227849837, time: 0.08108043670654297
Test Loss Energy: 13.601929093093009, Test Loss Force: 9.912623182426119, time: 10.377140283584595


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4141759826864073, Training Loss Force: 1.8953986149072877, time: 1.2647795677185059
Validation Loss Energy: 2.1880506803738724, Validation Loss Force: 2.187828345231664, time: 0.09560251235961914
Test Loss Energy: 11.754509271936794, Test Loss Force: 9.720794170205691, time: 10.174007892608643


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7618555697544152, Training Loss Force: 1.8882199224591811, time: 1.2132163047790527
Validation Loss Energy: 2.0060095241429234, Validation Loss Force: 2.0697633746629567, time: 0.08645176887512207
Test Loss Energy: 14.002073965452123, Test Loss Force: 9.89433544707756, time: 10.917654752731323


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6374304625717977, Training Loss Force: 1.8653680848845682, time: 1.2736527919769287
Validation Loss Energy: 0.8077352493855907, Validation Loss Force: 2.0695477195951257, time: 0.09018874168395996
Test Loss Energy: 12.418212391553825, Test Loss Force: 9.848034669436451, time: 10.266328811645508


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5002039852337126, Training Loss Force: 1.8937371649514445, time: 1.2851192951202393
Validation Loss Energy: 1.8306872980557714, Validation Loss Force: 2.2148697316514263, time: 0.09084510803222656
Test Loss Energy: 11.809215285223503, Test Loss Force: 9.705222429523616, time: 10.467921018600464


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0274021427664755, Training Loss Force: 1.9638527636876943, time: 1.2379887104034424
Validation Loss Energy: 1.420962932069032, Validation Loss Force: 2.1949587679571363, time: 0.08203291893005371
Test Loss Energy: 11.866053736801382, Test Loss Force: 9.891854362531, time: 10.292170524597168


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.526175513757836, Training Loss Force: 1.886293927812967, time: 1.2705624103546143
Validation Loss Energy: 2.069222177303779, Validation Loss Force: 2.1419458090292216, time: 0.08404207229614258
Test Loss Energy: 11.64168312813147, Test Loss Force: 9.785050973784733, time: 9.349807977676392

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–„â–…â–ƒâ–‡â–ˆâ–â–ƒâ–ƒâ–„â–ƒâ–„â–†â–‚â–†â–ƒâ–‚â–‚â–
wandb:   test_error_force â–ƒâ–…â–ƒâ–„â–…â–…â–ˆâ–‚â–‚â–‚â–ƒâ–„â–…â–„â–â–„â–ƒâ–â–„â–‚
wandb:          test_loss â–â–†â–…â–†â–…â–‡â–ˆâ–…â–…â–„â–…â–†â–†â–†â–ƒâ–…â–…â–ƒâ–‚â–„
wandb: train_error_energy â–ˆâ–…â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–â–‚â–â–â–‚â–‚â–ƒâ–…â–„â–ƒâ–†â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚
wandb: valid_error_energy â–†â–ƒâ–â–‚â–‚â–†â–ˆâ–„â–â–â–â–â–‚â–ƒâ–…â–„â–â–„â–ƒâ–„
wandb:  valid_error_force â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ˆâ–‚â–ƒâ–â–ƒâ–„â–…â–ƒâ–…â–ƒâ–ƒâ–†â–…â–„
wandb:         valid_loss â–„â–ƒâ–‚â–‚â–„â–„â–ˆâ–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–‚â–…â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2583
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.64168
wandb:   test_error_force 9.78505
wandb:          test_loss 8.16718
wandb: train_error_energy 1.52618
wandb:  train_error_force 1.88629
wandb:         train_loss -2.5718
wandb: valid_error_energy 2.06922
wandb:  valid_error_force 2.14195
wandb:         valid_loss -2.19416
wandb: 
wandb: ğŸš€ View run al_59_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/duoo4w56
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_203021-duoo4w56/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.457616806030273, Uncertainty Bias: -2.797220468521118
3.8146973e-06 0.07569885
0.67024124 4.394648
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3136 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1906 steps.
Found uncertainty sample 4 after 1871 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1406 steps.
Found uncertainty sample 7 after 103 steps.
Found uncertainty sample 8 after 949 steps.
Found uncertainty sample 9 after 2182 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 64 steps.
Found uncertainty sample 12 after 837 steps.
Found uncertainty sample 13 after 63 steps.
Found uncertainty sample 14 after 239 steps.
Found uncertainty sample 15 after 2763 steps.
Found uncertainty sample 16 after 1465 steps.
Found uncertainty sample 17 after 3328 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2573 steps.
Found uncertainty sample 20 after 1103 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 434 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 57 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 92 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 20 steps.
Found uncertainty sample 29 after 161 steps.
Found uncertainty sample 30 after 2942 steps.
Found uncertainty sample 31 after 915 steps.
Found uncertainty sample 32 after 1773 steps.
Found uncertainty sample 33 after 600 steps.
Found uncertainty sample 34 after 1101 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1790 steps.
Found uncertainty sample 37 after 308 steps.
Found uncertainty sample 38 after 318 steps.
Found uncertainty sample 39 after 1641 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 898 steps.
Found uncertainty sample 43 after 582 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1352 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 611 steps.
Found uncertainty sample 52 after 41 steps.
Found uncertainty sample 53 after 633 steps.
Found uncertainty sample 54 after 2595 steps.
Found uncertainty sample 55 after 593 steps.
Found uncertainty sample 56 after 152 steps.
Found uncertainty sample 57 after 256 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1119 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 600 steps.
Found uncertainty sample 62 after 341 steps.
Found uncertainty sample 63 after 74 steps.
Found uncertainty sample 64 after 3026 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1165 steps.
Found uncertainty sample 67 after 3116 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 104 steps.
Found uncertainty sample 70 after 558 steps.
Found uncertainty sample 71 after 458 steps.
Found uncertainty sample 72 after 3333 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 334 steps.
Found uncertainty sample 75 after 2181 steps.
Found uncertainty sample 76 after 24 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 340 steps.
Found uncertainty sample 79 after 2680 steps.
Found uncertainty sample 80 after 1119 steps.
Found uncertainty sample 81 after 1591 steps.
Found uncertainty sample 82 after 70 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 905 steps.
Found uncertainty sample 85 after 906 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 77 steps.
Found uncertainty sample 88 after 2379 steps.
Found uncertainty sample 89 after 3759 steps.
Found uncertainty sample 90 after 223 steps.
Found uncertainty sample 91 after 1394 steps.
Found uncertainty sample 92 after 67 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3730 steps.
Found uncertainty sample 96 after 1338 steps.
Found uncertainty sample 97 after 149 steps.
Found uncertainty sample 98 after 702 steps.
Found uncertainty sample 99 after 908 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_205430-6s7s5ydp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6s7s5ydp
Training model 22. Added 73 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.652270798701982, Training Loss Force: 2.054684697632148, time: 1.2375710010528564
Validation Loss Energy: 1.0502090066568446, Validation Loss Force: 2.0672665855296684, time: 0.0854954719543457
Test Loss Energy: 12.61832720948276, Test Loss Force: 9.792963576678208, time: 9.266274213790894


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6494553818632414, Training Loss Force: 1.8963877329805485, time: 1.2476248741149902
Validation Loss Energy: 0.9426423296457678, Validation Loss Force: 2.0437140906228755, time: 0.08361339569091797
Test Loss Energy: 12.1240387688607, Test Loss Force: 9.767015598355972, time: 9.315763473510742


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.574052527904976, Training Loss Force: 1.9279970575461645, time: 1.2032859325408936
Validation Loss Energy: 1.8230781366665543, Validation Loss Force: 2.04174781072976, time: 0.08443546295166016
Test Loss Energy: 11.658596931896072, Test Loss Force: 9.614057400337304, time: 9.505771160125732


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7131367867754406, Training Loss Force: 1.8687959124561941, time: 1.191641092300415
Validation Loss Energy: 0.7971142651285541, Validation Loss Force: 2.066675510281803, time: 0.087158203125
Test Loss Energy: 12.479934222321376, Test Loss Force: 9.81105327405212, time: 9.225352764129639


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4195023639873778, Training Loss Force: 1.9235655123004747, time: 1.2458696365356445
Validation Loss Energy: 1.8226566239733129, Validation Loss Force: 2.0319688498480497, time: 0.07880377769470215
Test Loss Energy: 13.398375438159563, Test Loss Force: 9.800460019098594, time: 9.286890268325806


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2466727358904635, Training Loss Force: 1.8950529964405007, time: 1.3009233474731445
Validation Loss Energy: 1.1866844292127208, Validation Loss Force: 2.005720722260655, time: 0.0821676254272461
Test Loss Energy: 11.979377442391025, Test Loss Force: 9.632629849082814, time: 9.435280323028564


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.500545899577894, Training Loss Force: 1.8895923347644503, time: 1.2145278453826904
Validation Loss Energy: 1.2054062283331834, Validation Loss Force: 2.082201673154483, time: 0.0900735855102539
Test Loss Energy: 13.221746801118085, Test Loss Force: 9.821027415515402, time: 9.196459770202637


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6935859518600018, Training Loss Force: 1.8940189625096044, time: 1.2088751792907715
Validation Loss Energy: 2.2079615327335897, Validation Loss Force: 2.0281152262740503, time: 0.08618927001953125
Test Loss Energy: 11.948641681056946, Test Loss Force: 9.735230256274482, time: 9.683349370956421


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6973584172251424, Training Loss Force: 1.8800695949765414, time: 1.278552532196045
Validation Loss Energy: 0.8568079386080971, Validation Loss Force: 2.160485242119169, time: 0.0847930908203125
Test Loss Energy: 12.887163960581095, Test Loss Force: 9.834387111937938, time: 9.390525817871094


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2752153281817025, Training Loss Force: 1.9195612986561885, time: 1.2279706001281738
Validation Loss Energy: 1.0046461676806682, Validation Loss Force: 2.0372904197665775, time: 0.08629179000854492
Test Loss Energy: 12.364433255491239, Test Loss Force: 9.727299839849332, time: 9.20426630973816


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6743730961796082, Training Loss Force: 1.9280348630112782, time: 1.2293660640716553
Validation Loss Energy: 1.0406773198616868, Validation Loss Force: 2.008860802556528, time: 0.08493471145629883
Test Loss Energy: 12.565147582699117, Test Loss Force: 9.692991266964924, time: 9.193856239318848


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6266269647655236, Training Loss Force: 1.9272356189395776, time: 1.30562424659729
Validation Loss Energy: 2.4364647216192585, Validation Loss Force: 2.113715146701059, time: 0.12126564979553223
Test Loss Energy: 11.662799754900913, Test Loss Force: 9.655194907169728, time: 9.940706253051758


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.330701256910556, Training Loss Force: 1.965642829981929, time: 1.3823111057281494
Validation Loss Energy: 0.9560558911628144, Validation Loss Force: 2.1627834103742902, time: 0.09476447105407715
Test Loss Energy: 12.569741328786101, Test Loss Force: 9.614402460570226, time: 10.372662782669067


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.0728796036439356, Training Loss Force: 1.8916605005470122, time: 1.2968454360961914
Validation Loss Energy: 2.6150196583669896, Validation Loss Force: 1.9966889276981048, time: 0.0852198600769043
Test Loss Energy: 11.51687515058893, Test Loss Force: 9.667407458784721, time: 10.503062009811401


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7051673953331512, Training Loss Force: 1.899868682180187, time: 1.3217487335205078
Validation Loss Energy: 1.4561632499993076, Validation Loss Force: 1.9949571184156514, time: 0.09093928337097168
Test Loss Energy: 12.181425881877367, Test Loss Force: 9.707881765967626, time: 10.306512117385864


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.487223586133054, Training Loss Force: 1.8738331969202513, time: 1.2906782627105713
Validation Loss Energy: 1.4088660967127862, Validation Loss Force: 2.0511725050002996, time: 0.08845233917236328
Test Loss Energy: 11.781454551555235, Test Loss Force: 9.649194363066526, time: 10.329033851623535


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.586016614891598, Training Loss Force: 1.8952611330712057, time: 1.3227944374084473
Validation Loss Energy: 0.7755391000712433, Validation Loss Force: 2.0007130045033117, time: 0.08527946472167969
Test Loss Energy: 12.288492668404547, Test Loss Force: 9.754113462546371, time: 10.482312679290771


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2270218749094999, Training Loss Force: 1.9169342091725012, time: 1.3114490509033203
Validation Loss Energy: 0.9767788457313733, Validation Loss Force: 1.9820916291676627, time: 0.09405803680419922
Test Loss Energy: 12.922587986974277, Test Loss Force: 9.779332984003839, time: 10.375227212905884


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.248678491267287, Training Loss Force: 1.8784627232056597, time: 1.2896127700805664
Validation Loss Energy: 1.1745675536333413, Validation Loss Force: 2.139243384939669, time: 0.09862351417541504
Test Loss Energy: 11.616343687097947, Test Loss Force: 9.73853103840852, time: 10.497575044631958


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5848449942319849, Training Loss Force: 1.9271307967684423, time: 1.32440185546875
Validation Loss Energy: 2.2061483378782993, Validation Loss Force: 2.032849617654767, time: 0.09005093574523926
Test Loss Energy: 13.894678407348076, Test Loss Force: 9.803152198658722, time: 10.335636377334595

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–â–„â–‡â–‚â–†â–‚â–…â–ƒâ–„â–â–„â–â–ƒâ–‚â–ƒâ–…â–â–ˆ
wandb:   test_error_force â–‡â–†â–â–‡â–‡â–‚â–ˆâ–…â–ˆâ–…â–„â–‚â–â–ƒâ–„â–‚â–…â–†â–…â–‡
wandb:          test_loss â–…â–†â–‚â–‡â–†â–„â–ˆâ–…â–ˆâ–…â–„â–â–â–„â–…â–„â–†â–…â–…â–†
wandb: train_error_energy â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–ƒâ–„â–„â–‚â–„â–ƒâ–‡â–â–„â–ƒâ–ƒâ–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–â–‚â–ƒâ–â–ƒ
wandb:         train_loss â–ˆâ–‚â–ƒâ–â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–…â–â–‚â–â–‚â–‚â–â–ƒ
wandb: valid_error_energy â–‚â–‚â–…â–â–…â–ƒâ–ƒâ–†â–â–‚â–‚â–‡â–‚â–ˆâ–„â–ƒâ–â–‚â–ƒâ–†
wandb:  valid_error_force â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–ƒâ–ˆâ–ƒâ–‚â–†â–ˆâ–‚â–â–„â–‚â–â–‡â–ƒ
wandb:         valid_loss â–„â–ƒâ–…â–„â–„â–‚â–…â–…â–‡â–ƒâ–‚â–ˆâ–‡â–„â–‚â–„â–â–â–‡â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2648
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.89468
wandb:   test_error_force 9.80315
wandb:          test_loss 8.11312
wandb: train_error_energy 1.58484
wandb:  train_error_force 1.92713
wandb:         train_loss -2.51413
wandb: valid_error_energy 2.20615
wandb:  valid_error_force 2.03285
wandb:         valid_loss -2.33322
wandb: 
wandb: ğŸš€ View run al_59_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6s7s5ydp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_205430-6s7s5ydp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.096759796142578, Uncertainty Bias: -2.7994377613067627
2.670288e-05 0.056171417
0.4959501 4.542753
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 740 steps.
Found uncertainty sample 2 after 1994 steps.
Found uncertainty sample 3 after 1054 steps.
Found uncertainty sample 4 after 1380 steps.
Found uncertainty sample 5 after 129 steps.
Found uncertainty sample 6 after 641 steps.
Found uncertainty sample 7 after 2965 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1527 steps.
Found uncertainty sample 11 after 1437 steps.
Found uncertainty sample 12 after 18 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1330 steps.
Found uncertainty sample 17 after 2275 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1795 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2680 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 547 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2562 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1380 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1072 steps.
Found uncertainty sample 37 after 1594 steps.
Found uncertainty sample 38 after 1690 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1827 steps.
Found uncertainty sample 44 after 1856 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 629 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3124 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1645 steps.
Found uncertainty sample 51 after 632 steps.
Found uncertainty sample 52 after 123 steps.
Found uncertainty sample 53 after 1631 steps.
Found uncertainty sample 54 after 509 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1409 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 418 steps.
Found uncertainty sample 59 after 373 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 622 steps.
Found uncertainty sample 62 after 1993 steps.
Found uncertainty sample 63 after 4 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2886 steps.
Found uncertainty sample 66 after 1850 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 983 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1342 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 886 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2903 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1048 steps.
Found uncertainty sample 82 after 512 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2574 steps.
Found uncertainty sample 85 after 3667 steps.
Found uncertainty sample 86 after 2054 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 840 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1061 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1013 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1213 steps.
Found uncertainty sample 97 after 142 steps.
Found uncertainty sample 98 after 1539 steps.
Found uncertainty sample 99 after 2861 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_212449-9drb0w2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/9drb0w2n
Training model 23. Added 55 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0585541389070485, Training Loss Force: 2.031542840547879, time: 1.2929434776306152
Validation Loss Energy: 1.4649476034734454, Validation Loss Force: 2.023221960457714, time: 0.08671832084655762
Test Loss Energy: 13.258676644514807, Test Loss Force: 9.742749292035432, time: 9.640034198760986


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5602018149469967, Training Loss Force: 1.9022163661355074, time: 1.256551742553711
Validation Loss Energy: 1.190607803896682, Validation Loss Force: 2.1090694889749946, time: 0.08339786529541016
Test Loss Energy: 12.789740767250391, Test Loss Force: 9.732548676232021, time: 9.373692750930786


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4652317293036492, Training Loss Force: 1.8826567285098437, time: 1.3058629035949707
Validation Loss Energy: 0.8009388303790097, Validation Loss Force: 2.0378498759957213, time: 0.09525227546691895
Test Loss Energy: 12.347903897584827, Test Loss Force: 9.761496481267566, time: 10.559722185134888


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6928293581379295, Training Loss Force: 1.896595475182293, time: 1.3783106803894043
Validation Loss Energy: 1.5300880704324578, Validation Loss Force: 2.0417745310272712, time: 0.09006333351135254
Test Loss Energy: 13.374580728768802, Test Loss Force: 9.755030076005259, time: 10.499877214431763


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7262042029742448, Training Loss Force: 1.8759780425396255, time: 1.3939807415008545
Validation Loss Energy: 3.869698504982079, Validation Loss Force: 2.1239196283206376, time: 0.08831453323364258
Test Loss Energy: 11.108896581820497, Test Loss Force: 9.705472257310504, time: 10.545130491256714


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8315269945385222, Training Loss Force: 1.927515255153812, time: 1.4608492851257324
Validation Loss Energy: 1.3579342036227127, Validation Loss Force: 2.0521235249225573, time: 0.08791375160217285
Test Loss Energy: 12.942177541746107, Test Loss Force: 9.760152245120704, time: 10.475136756896973


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4467665887918764, Training Loss Force: 1.8965242904759771, time: 1.3456087112426758
Validation Loss Energy: 2.5560788014361853, Validation Loss Force: 2.037618634087675, time: 0.09528636932373047
Test Loss Energy: 11.294731359285462, Test Loss Force: 9.606466028580716, time: 10.4075927734375


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2462608614927495, Training Loss Force: 1.8744597271244692, time: 1.2500088214874268
Validation Loss Energy: 1.42138656011916, Validation Loss Force: 2.104683129469363, time: 0.08800578117370605
Test Loss Energy: 12.839325851840357, Test Loss Force: 9.656338992899574, time: 10.684273958206177


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6040158012823267, Training Loss Force: 1.9345620577560774, time: 1.288569688796997
Validation Loss Energy: 2.015928488250136, Validation Loss Force: 2.0200563845446315, time: 0.08937597274780273
Test Loss Energy: 11.814349452825075, Test Loss Force: 9.70897289607818, time: 10.593169689178467


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6028679117092435, Training Loss Force: 1.8610417315443275, time: 1.2622499465942383
Validation Loss Energy: 0.8619376790574085, Validation Loss Force: 1.9954631340497722, time: 0.09738016128540039
Test Loss Energy: 12.057163903070332, Test Loss Force: 9.737102407157932, time: 10.503955841064453


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3563299280935892, Training Loss Force: 1.8871602394924218, time: 1.3505775928497314
Validation Loss Energy: 1.3332413086850505, Validation Loss Force: 2.051702346233035, time: 0.12766814231872559
Test Loss Energy: 12.912979932239816, Test Loss Force: 9.673782651303691, time: 11.070371866226196


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.326347031173199, Training Loss Force: 1.9066473563968935, time: 1.3127920627593994
Validation Loss Energy: 1.0922115329914952, Validation Loss Force: 2.0974302387136303, time: 0.0860297679901123
Test Loss Energy: 12.707276253981709, Test Loss Force: 9.767258627156163, time: 10.446884155273438


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0073799007971624, Training Loss Force: 1.9265752848604665, time: 1.3635759353637695
Validation Loss Energy: 1.4241404764487082, Validation Loss Force: 2.1887027669677224, time: 0.09060287475585938
Test Loss Energy: 13.040377185886078, Test Loss Force: 9.647282467489239, time: 10.580159902572632


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4418722132318116, Training Loss Force: 1.866991128908165, time: 1.3801028728485107
Validation Loss Energy: 1.763212423438139, Validation Loss Force: 2.016981212304796, time: 0.10108327865600586
Test Loss Energy: 13.507185311403662, Test Loss Force: 9.672573205767577, time: 10.404150247573853


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.1847072901055589, Training Loss Force: 1.89268222474047, time: 1.2941865921020508
Validation Loss Energy: 1.588072062375924, Validation Loss Force: 2.0359188891622355, time: 0.08846521377563477
Test Loss Energy: 11.947863999155434, Test Loss Force: 9.743595504738382, time: 10.24509859085083


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5655559145355633, Training Loss Force: 1.8898178730283615, time: 1.2757744789123535
Validation Loss Energy: 1.3391059686504967, Validation Loss Force: 2.004973889945213, time: 0.09450507164001465
Test Loss Energy: 12.173353568081719, Test Loss Force: 9.610168669066995, time: 10.530719757080078


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.405928406952739, Training Loss Force: 1.9098419434800533, time: 1.289461612701416
Validation Loss Energy: 0.790935084994485, Validation Loss Force: 2.003228720514004, time: 0.10013008117675781
Test Loss Energy: 12.467113478496552, Test Loss Force: 9.603134543752292, time: 10.21270203590393


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.370953115841701, Training Loss Force: 1.8696461912703797, time: 1.3081159591674805
Validation Loss Energy: 1.2118342412378267, Validation Loss Force: 2.00090639265655, time: 0.09106826782226562
Test Loss Energy: 11.564576081146093, Test Loss Force: 9.641290634296292, time: 10.28262186050415


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.1918174645104826, Training Loss Force: 1.873058024850854, time: 1.3066084384918213
Validation Loss Energy: 0.7683310771484149, Validation Loss Force: 1.9742378100543574, time: 0.09689593315124512
Test Loss Energy: 12.323211801224991, Test Loss Force: 9.615177353861283, time: 10.428472518920898


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.106426094040822, Training Loss Force: 1.8703816949655678, time: 1.3567564487457275
Validation Loss Energy: 2.4347311309836375, Validation Loss Force: 1.9744452820310756, time: 0.08710956573486328
Test Loss Energy: 13.722163203890325, Test Loss Force: 9.689135248240348, time: 10.355799436569214

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.055 MB of 0.058 MB uploadedwandb: | 0.055 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–„â–‡â–â–†â–â–†â–ƒâ–„â–†â–…â–†â–‡â–ƒâ–„â–…â–‚â–„â–ˆ
wandb:   test_error_force â–‡â–‡â–ˆâ–‡â–…â–ˆâ–â–ƒâ–†â–‡â–„â–ˆâ–ƒâ–„â–‡â–â–â–ƒâ–‚â–…
wandb:          test_loss â–ƒâ–…â–ˆâ–ˆâ–…â–„â–â–ˆâ–‚â–‡â–…â–…â–â–ˆâ–…â–‚â–‚â–…â–…â–‡
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–„â–‚â–â–ƒâ–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–„â–‚â–‚â–„â–â–‚â–ƒâ–„â–â–‚â–‚â–ƒâ–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–‚â–„â–‚â–â–ƒâ–â–‚â–‚â–„â–â–‚â–‚â–‚â–â–â–
wandb: valid_error_energy â–ƒâ–‚â–â–ƒâ–ˆâ–‚â–…â–‚â–„â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–â–…
wandb:  valid_error_force â–ƒâ–…â–ƒâ–ƒâ–†â–„â–ƒâ–…â–‚â–‚â–„â–…â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–
wandb:         valid_loss â–ƒâ–…â–‚â–ƒâ–ˆâ–ƒâ–„â–…â–ƒâ–‚â–ƒâ–„â–‡â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2697
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 13.72216
wandb:   test_error_force 9.68914
wandb:          test_loss 8.14628
wandb: train_error_energy 1.10643
wandb:  train_error_force 1.87038
wandb:         train_loss -2.62118
wandb: valid_error_energy 2.43473
wandb:  valid_error_force 1.97445
wandb:         valid_loss -2.39298
wandb: 
wandb: ğŸš€ View run al_59_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/9drb0w2n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_212449-9drb0w2n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 22.998088836669922, Uncertainty Bias: -2.744776487350464
2.2888184e-05 0.12150574
0.63147545 4.3378587
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1597 steps.
Found uncertainty sample 1 after 1794 steps.
Found uncertainty sample 2 after 1383 steps.
Found uncertainty sample 3 after 3684 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 189 steps.
Found uncertainty sample 6 after 107 steps.
Found uncertainty sample 7 after 1034 steps.
Found uncertainty sample 8 after 1563 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 62 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 150 steps.
Found uncertainty sample 16 after 1970 steps.
Found uncertainty sample 17 after 554 steps.
Found uncertainty sample 18 after 3325 steps.
Found uncertainty sample 19 after 3179 steps.
Found uncertainty sample 20 after 1133 steps.
Found uncertainty sample 21 after 2288 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 891 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 658 steps.
Found uncertainty sample 26 after 2218 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2255 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1144 steps.
Found uncertainty sample 32 after 2666 steps.
Found uncertainty sample 33 after 2955 steps.
Found uncertainty sample 34 after 1802 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 634 steps.
Found uncertainty sample 37 after 1866 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1002 steps.
Found uncertainty sample 41 after 2261 steps.
Found uncertainty sample 42 after 2539 steps.
Found uncertainty sample 43 after 3508 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1089 steps.
Found uncertainty sample 48 after 275 steps.
Found uncertainty sample 49 after 570 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 51 steps.
Found uncertainty sample 53 after 3169 steps.
Found uncertainty sample 54 after 2827 steps.
Found uncertainty sample 55 after 3424 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 104 steps.
Found uncertainty sample 58 after 1353 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 49 steps.
Found uncertainty sample 61 after 1378 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1566 steps.
Found uncertainty sample 64 after 1581 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1905 steps.
Found uncertainty sample 67 after 427 steps.
Found uncertainty sample 68 after 3894 steps.
Found uncertainty sample 69 after 3432 steps.
Found uncertainty sample 70 after 3689 steps.
Found uncertainty sample 71 after 1043 steps.
Found uncertainty sample 72 after 262 steps.
Found uncertainty sample 73 after 2098 steps.
Found uncertainty sample 74 after 1726 steps.
Found uncertainty sample 75 after 1981 steps.
Found uncertainty sample 76 after 282 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 786 steps.
Found uncertainty sample 81 after 1100 steps.
Found uncertainty sample 82 after 3567 steps.
Found uncertainty sample 83 after 2214 steps.
Found uncertainty sample 84 after 2738 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1098 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 645 steps.
Found uncertainty sample 96 after 957 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_215449-nanmnd4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nanmnd4u
Training model 24. Added 62 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.855500675546726, Training Loss Force: 2.0337766993492497, time: 1.3761835098266602
Validation Loss Energy: 1.2725799985982351, Validation Loss Force: 2.0011633528509507, time: 0.09505653381347656
Test Loss Energy: 13.008241919824663, Test Loss Force: 9.711473267736523, time: 10.405959844589233


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5223246925354528, Training Loss Force: 1.899203947102272, time: 1.344742774963379
Validation Loss Energy: 1.0236857991732993, Validation Loss Force: 2.0127585146214213, time: 0.09170341491699219
Test Loss Energy: 12.736772697139909, Test Loss Force: 9.612491348415272, time: 10.561176300048828


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.351318163453978, Training Loss Force: 1.8817017729180472, time: 1.2891645431518555
Validation Loss Energy: 1.417267681925074, Validation Loss Force: 1.9820783803534803, time: 0.09332084655761719
Test Loss Energy: 13.216167295224658, Test Loss Force: 9.667590145412175, time: 10.702598333358765


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3494177567322976, Training Loss Force: 1.8866891022080687, time: 1.3139939308166504
Validation Loss Energy: 4.822255512354001, Validation Loss Force: 2.0832172671290596, time: 0.10102248191833496
Test Loss Energy: 11.139655617326458, Test Loss Force: 9.3926888847096, time: 10.481672763824463


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5938961541590524, Training Loss Force: 1.9426485798038198, time: 1.266035795211792
Validation Loss Energy: 1.9146124125016846, Validation Loss Force: 2.0082563671599076, time: 0.09178638458251953
Test Loss Energy: 13.901054010231128, Test Loss Force: 9.574253460185648, time: 11.216398239135742


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4667026525534168, Training Loss Force: 1.8941744000011003, time: 1.2693614959716797
Validation Loss Energy: 3.095764125778251, Validation Loss Force: 2.0292453835242066, time: 0.08760857582092285
Test Loss Energy: 11.482275946671002, Test Loss Force: 9.631342145251265, time: 10.494733333587646


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3652834641607559, Training Loss Force: 1.8783538607499752, time: 1.3091139793395996
Validation Loss Energy: 2.307879190578328, Validation Loss Force: 2.0606170168248266, time: 0.08831191062927246
Test Loss Energy: 13.920539756880283, Test Loss Force: 9.752230889347924, time: 10.48550796508789


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.623941473903363, Training Loss Force: 1.9063910844359653, time: 1.2862751483917236
Validation Loss Energy: 0.8325376975430492, Validation Loss Force: 1.998427862393228, time: 0.09121012687683105
Test Loss Energy: 12.434481088994268, Test Loss Force: 9.580330112836087, time: 10.609843492507935


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7104558188374135, Training Loss Force: 1.8885909297401433, time: 1.39347243309021
Validation Loss Energy: 1.097467582513834, Validation Loss Force: 2.134025690177716, time: 0.09075021743774414
Test Loss Energy: 11.98504067188332, Test Loss Force: 9.789914977261292, time: 10.399950504302979


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.186636500973648, Training Loss Force: 1.8754930153306233, time: 1.2977182865142822
Validation Loss Energy: 1.7752857671994895, Validation Loss Force: 2.0209917062921012, time: 0.09816884994506836
Test Loss Energy: 13.271882216582535, Test Loss Force: 9.713746330336892, time: 10.53507685661316


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6810112821331658, Training Loss Force: 1.8889749692874658, time: 1.3526577949523926
Validation Loss Energy: 1.151787386659199, Validation Loss Force: 2.0524027520315506, time: 0.09405970573425293
Test Loss Energy: 12.15179093151556, Test Loss Force: 9.59584270046861, time: 10.44395399093628


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5514262116278092, Training Loss Force: 1.9000966212353558, time: 1.332165002822876
Validation Loss Energy: 1.0692164902915324, Validation Loss Force: 2.0574529995957658, time: 0.09224772453308105
Test Loss Energy: 12.28567815371616, Test Loss Force: 9.537127360167448, time: 10.480582475662231


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.151043393375368, Training Loss Force: 1.8662235680599657, time: 1.4335498809814453
Validation Loss Energy: 1.1190176416249416, Validation Loss Force: 1.9545829158778845, time: 0.09302830696105957
Test Loss Energy: 12.049727518365764, Test Loss Force: 9.581374046414163, time: 10.641523838043213


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3806211848538723, Training Loss Force: 1.8932041489732445, time: 1.3734748363494873
Validation Loss Energy: 0.9548241411148284, Validation Loss Force: 1.9959581275611697, time: 0.0941324234008789
Test Loss Energy: 12.134763466227133, Test Loss Force: 9.55443948755732, time: 10.4958975315094


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.586212797015424, Training Loss Force: 1.8776481769159483, time: 1.2904832363128662
Validation Loss Energy: 2.6453534307784405, Validation Loss Force: 2.129571639251723, time: 0.09739089012145996
Test Loss Energy: 14.185190481921708, Test Loss Force: 9.75669581841947, time: 10.408060789108276


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.016379612056021, Training Loss Force: 1.8940640493150596, time: 1.5032048225402832
Validation Loss Energy: 1.5516785718271944, Validation Loss Force: 2.1642227437335673, time: 0.0910036563873291
Test Loss Energy: 11.671209830977377, Test Loss Force: 9.559617475514166, time: 10.377155303955078


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6874036841568116, Training Loss Force: 1.897875799438332, time: 1.3035132884979248
Validation Loss Energy: 0.9487366728352384, Validation Loss Force: 2.0181236163579785, time: 0.09100198745727539
Test Loss Energy: 12.630609401747497, Test Loss Force: 9.61643968040504, time: 10.88398003578186


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6709536676449712, Training Loss Force: 1.8841381630455025, time: 1.299340009689331
Validation Loss Energy: 0.8194147749287247, Validation Loss Force: 2.015969960378565, time: 0.09475207328796387
Test Loss Energy: 12.342838326069884, Test Loss Force: 9.582349770953549, time: 10.570261478424072


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6380393947999499, Training Loss Force: 1.879854591242478, time: 1.3807384967803955
Validation Loss Energy: 3.056878299479152, Validation Loss Force: 1.991190669812283, time: 0.10322833061218262
Test Loss Energy: 14.54037161276225, Test Loss Force: 9.634003845951963, time: 10.402006387710571


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4919066644494414, Training Loss Force: 1.883020095953217, time: 1.3354742527008057
Validation Loss Energy: 1.9438346205366637, Validation Loss Force: 2.0326060176091216, time: 0.09761691093444824
Test Loss Energy: 11.713088068291155, Test Loss Force: 9.5107755602739, time: 10.472584009170532

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–…â–â–‡â–‚â–‡â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‡â–‚â–„â–ƒâ–ˆâ–‚
wandb:   test_error_force â–‡â–…â–†â–â–„â–…â–‡â–„â–ˆâ–‡â–…â–„â–„â–„â–‡â–„â–…â–„â–…â–ƒ
wandb:          test_loss â–ƒâ–„â–†â–â–„â–ƒâ–ˆâ–ƒâ–‡â–†â–…â–ƒâ–†â–„â–ˆâ–ƒâ–…â–„â–†â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–„â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–â–‚â–ˆâ–ƒâ–…â–„â–â–â–ƒâ–‚â–â–‚â–â–„â–‚â–â–â–…â–ƒ
wandb:  valid_error_force â–ƒâ–ƒâ–‚â–…â–ƒâ–ƒâ–…â–‚â–‡â–ƒâ–„â–„â–â–‚â–‡â–ˆâ–ƒâ–ƒâ–‚â–„
wandb:         valid_loss â–‚â–‚â–‚â–ˆâ–ƒâ–…â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–â–‚â–‡â–†â–‚â–‚â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2752
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.71309
wandb:   test_error_force 9.51078
wandb:          test_loss 7.81799
wandb: train_error_energy 1.49191
wandb:  train_error_force 1.88302
wandb:         train_loss -2.57847
wandb: valid_error_energy 1.94383
wandb:  valid_error_force 2.03261
wandb:         valid_loss -2.34832
wandb: 
wandb: ğŸš€ View run al_59_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nanmnd4u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_215449-nanmnd4u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 24.683185577392578, Uncertainty Bias: -2.9540114402770996
6.2942505e-05 0.025138855
0.5931015 4.114452
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3382 steps.
Found uncertainty sample 2 after 402 steps.
Found uncertainty sample 3 after 676 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 158 steps.
Found uncertainty sample 7 after 1232 steps.
Found uncertainty sample 8 after 3774 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1435 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1146 steps.
Found uncertainty sample 13 after 1635 steps.
Found uncertainty sample 14 after 3099 steps.
Found uncertainty sample 15 after 387 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2427 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 194 steps.
Found uncertainty sample 20 after 1978 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1096 steps.
Found uncertainty sample 23 after 743 steps.
Found uncertainty sample 24 after 2694 steps.
Found uncertainty sample 25 after 1860 steps.
Found uncertainty sample 26 after 3177 steps.
Found uncertainty sample 27 after 3437 steps.
Found uncertainty sample 28 after 1380 steps.
Found uncertainty sample 29 after 379 steps.
Found uncertainty sample 30 after 1933 steps.
Found uncertainty sample 31 after 200 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 151 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 647 steps.
Found uncertainty sample 36 after 1709 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1714 steps.
Found uncertainty sample 45 after 1220 steps.
Found uncertainty sample 46 after 1155 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2551 steps.
Found uncertainty sample 50 after 3406 steps.
Found uncertainty sample 51 after 3226 steps.
Found uncertainty sample 52 after 2772 steps.
Found uncertainty sample 53 after 1954 steps.
Found uncertainty sample 54 after 95 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1640 steps.
Found uncertainty sample 57 after 2974 steps.
Found uncertainty sample 58 after 3516 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2701 steps.
Found uncertainty sample 61 after 1220 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1466 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2442 steps.
Found uncertainty sample 69 after 2243 steps.
Found uncertainty sample 70 after 1879 steps.
Found uncertainty sample 71 after 88 steps.
Found uncertainty sample 72 after 1649 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 298 steps.
Found uncertainty sample 76 after 1152 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1924 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 966 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 23 steps.
Found uncertainty sample 87 after 59 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1965 steps.
Found uncertainty sample 90 after 18 steps.
Found uncertainty sample 91 after 3379 steps.
Found uncertainty sample 92 after 1157 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3521 steps.
Found uncertainty sample 95 after 3602 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3223 steps.
Found uncertainty sample 98 after 1218 steps.
Found uncertainty sample 99 after 64 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_222509-j97eyyia
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/j97eyyia
Training model 25. Added 62 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9288854517115666, Training Loss Force: 2.0987085582422553, time: 1.436769962310791
Validation Loss Energy: 1.3308421599722515, Validation Loss Force: 1.990995834309596, time: 0.09560656547546387
Test Loss Energy: 11.787076012512658, Test Loss Force: 9.520823660536232, time: 10.532798290252686


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.362845625198018, Training Loss Force: 1.9025313486998312, time: 1.409125566482544
Validation Loss Energy: 1.4050236622633698, Validation Loss Force: 2.0749023558818243, time: 0.10201072692871094
Test Loss Energy: 11.71916854012548, Test Loss Force: 9.498094340236433, time: 10.470248222351074


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.380680524254091, Training Loss Force: 1.9092271086007968, time: 1.3992042541503906
Validation Loss Energy: 1.693760692142959, Validation Loss Force: 2.0548178215882835, time: 0.09254217147827148
Test Loss Energy: 11.48189415418965, Test Loss Force: 9.52031887541145, time: 10.66966724395752


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8491875078491473, Training Loss Force: 1.8951642021037598, time: 1.355745792388916
Validation Loss Energy: 3.1920064067003056, Validation Loss Force: 2.1072316891790797, time: 0.09837508201599121
Test Loss Energy: 11.201163126126534, Test Loss Force: 9.450494839555567, time: 10.350088119506836


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5431017934407711, Training Loss Force: 1.9114814945350995, time: 1.463383674621582
Validation Loss Energy: 2.783157575795354, Validation Loss Force: 1.9691312828635086, time: 0.09618282318115234
Test Loss Energy: 11.392369438834242, Test Loss Force: 9.54292542690277, time: 10.430330038070679


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6585999283500603, Training Loss Force: 1.916385073981422, time: 1.3359770774841309
Validation Loss Energy: 1.0887112296847967, Validation Loss Force: 2.004214699492172, time: 0.09706497192382812
Test Loss Energy: 12.653490435513131, Test Loss Force: 9.466882388692813, time: 10.55333399772644


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5625855872538315, Training Loss Force: 1.9070103006152004, time: 1.3281219005584717
Validation Loss Energy: 1.3499005791740704, Validation Loss Force: 2.1870981017675937, time: 0.09316444396972656
Test Loss Energy: 11.912828340395341, Test Loss Force: 9.386850261878735, time: 10.438119888305664


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5676212348070009, Training Loss Force: 1.911063557199849, time: 1.4442462921142578
Validation Loss Energy: 1.5356416616010424, Validation Loss Force: 2.044505122763784, time: 0.10141706466674805
Test Loss Energy: 13.276777398402754, Test Loss Force: 9.50085928947242, time: 10.56050729751587


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5488003105942154, Training Loss Force: 1.9001497516294272, time: 1.4048850536346436
Validation Loss Energy: 1.1070532665768793, Validation Loss Force: 2.0424611313387397, time: 0.1010732650756836
Test Loss Energy: 12.58246830441854, Test Loss Force: 9.537509572339335, time: 10.503093004226685


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1864189443324946, Training Loss Force: 1.8942045309791162, time: 1.3681490421295166
Validation Loss Energy: 0.8654737485956715, Validation Loss Force: 2.013818642425184, time: 0.09229850769042969
Test Loss Energy: 11.958902965459071, Test Loss Force: 9.442083704926308, time: 11.055610656738281


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5022230460238957, Training Loss Force: 1.8937179419628123, time: 1.3865618705749512
Validation Loss Energy: 1.1374758839775554, Validation Loss Force: 2.0401091884848777, time: 0.09926819801330566
Test Loss Energy: 12.012477353161653, Test Loss Force: 9.42432180451457, time: 10.445911645889282


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9363422048336891, Training Loss Force: 1.9577842137417354, time: 1.3668229579925537
Validation Loss Energy: 0.8851713952481626, Validation Loss Force: 2.046606896832196, time: 0.10023713111877441
Test Loss Energy: 11.745211760220213, Test Loss Force: 9.418143894527278, time: 10.587715148925781


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.13731909959551, Training Loss Force: 1.8707598332422648, time: 1.3241901397705078
Validation Loss Energy: 0.8402893393520171, Validation Loss Force: 2.0047317372490165, time: 0.10242390632629395
Test Loss Energy: 12.12244712047915, Test Loss Force: 9.463245355163894, time: 10.70303726196289


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7960820374820934, Training Loss Force: 1.8852113606572258, time: 1.32895827293396
Validation Loss Energy: 0.8715376696130797, Validation Loss Force: 2.117627777598729, time: 0.09767913818359375
Test Loss Energy: 11.88879581103027, Test Loss Force: 9.535578268406335, time: 10.470345258712769


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3094922355099543, Training Loss Force: 1.8818844229929506, time: 1.3695521354675293
Validation Loss Energy: 1.999241829456167, Validation Loss Force: 2.061523057579607, time: 0.08972764015197754
Test Loss Energy: 13.39591091739952, Test Loss Force: 9.605734913675878, time: 10.669398307800293


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8026695175524408, Training Loss Force: 1.9452406939574336, time: 1.4267373085021973
Validation Loss Energy: 1.9849208633358213, Validation Loss Force: 2.0328743339299646, time: 0.08915305137634277
Test Loss Energy: 11.471195146547299, Test Loss Force: 9.426865390308523, time: 10.472699642181396


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2339431094458724, Training Loss Force: 1.8714069768341082, time: 1.438239574432373
Validation Loss Energy: 2.894218265709757, Validation Loss Force: 2.017063154550497, time: 0.10463309288024902
Test Loss Energy: 13.990117728174425, Test Loss Force: 9.567517123959737, time: 10.458121538162231


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3774571694931372, Training Loss Force: 1.8969223356868914, time: 1.4041569232940674
Validation Loss Energy: 2.3677149548066163, Validation Loss Force: 1.9993813316760907, time: 0.10001468658447266
Test Loss Energy: 11.310767594800781, Test Loss Force: 9.446328002682645, time: 10.490710735321045


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4918027391717124, Training Loss Force: 1.8927612503031617, time: 1.3737866878509521
Validation Loss Energy: 0.8358459765450281, Validation Loss Force: 2.0587618488355295, time: 0.09990048408508301
Test Loss Energy: 12.011786649792281, Test Loss Force: 9.465754400426666, time: 10.384418964385986


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.1119322274820467, Training Loss Force: 1.8691940174822725, time: 1.427093505859375
Validation Loss Energy: 0.8059338838286781, Validation Loss Force: 2.0048428491528343, time: 0.10779142379760742
Test Loss Energy: 12.329464080375407, Test Loss Force: 9.52568756142177, time: 9.230740070343018

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–â–â–…â–ƒâ–†â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‡â–‚â–ˆâ–â–ƒâ–„
wandb:   test_error_force â–…â–…â–…â–ƒâ–†â–„â–â–…â–†â–ƒâ–‚â–‚â–ƒâ–†â–ˆâ–‚â–‡â–ƒâ–„â–…
wandb:          test_loss â–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–…â–…â–„â–ƒâ–â–…â–†â–ˆâ–ƒâ–ˆâ–…â–…â–‡
wandb: train_error_energy â–ˆâ–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–â–„â–‚â–„â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–â–â–â–ƒâ–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–â–‚â–â–ƒâ–â–‚â–‚â–
wandb: valid_error_energy â–ƒâ–ƒâ–„â–ˆâ–‡â–‚â–ƒâ–ƒâ–‚â–â–‚â–â–â–â–…â–„â–‡â–†â–â–
wandb:  valid_error_force â–‚â–„â–„â–…â–â–‚â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–†â–„â–ƒâ–ƒâ–‚â–„â–‚
wandb:         valid_loss â–â–„â–„â–ˆâ–ƒâ–â–ˆâ–ƒâ–ƒâ–â–ƒâ–‚â–â–…â–…â–„â–…â–ƒâ–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2807
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.32946
wandb:   test_error_force 9.52569
wandb:          test_loss 7.9449
wandb: train_error_energy 1.11193
wandb:  train_error_force 1.86919
wandb:         train_loss -2.62231
wandb: valid_error_energy 0.80593
wandb:  valid_error_force 2.00484
wandb:         valid_loss -2.45986
wandb: 
wandb: ğŸš€ View run al_59_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/j97eyyia
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_222509-j97eyyia/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.92055320739746, Uncertainty Bias: -2.835618734359741
0.0001296997 0.0012295246
0.66249233 4.0226517
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1312 steps.
Found uncertainty sample 1 after 1031 steps.
Found uncertainty sample 2 after 964 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 297 steps.
Found uncertainty sample 8 after 54 steps.
Found uncertainty sample 9 after 318 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 135 steps.
Found uncertainty sample 12 after 2894 steps.
Found uncertainty sample 13 after 767 steps.
Found uncertainty sample 14 after 50 steps.
Found uncertainty sample 15 after 848 steps.
Found uncertainty sample 16 after 1857 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1553 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2598 steps.
Found uncertainty sample 22 after 120 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2164 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2455 steps.
Found uncertainty sample 33 after 3648 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1423 steps.
Found uncertainty sample 36 after 1059 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 125 steps.
Found uncertainty sample 41 after 1678 steps.
Found uncertainty sample 42 after 591 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1383 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1137 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3517 steps.
Found uncertainty sample 49 after 3205 steps.
Found uncertainty sample 50 after 879 steps.
Found uncertainty sample 51 after 2282 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 473 steps.
Found uncertainty sample 55 after 1954 steps.
Found uncertainty sample 56 after 1530 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 371 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1304 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1369 steps.
Found uncertainty sample 65 after 823 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2228 steps.
Found uncertainty sample 71 after 203 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 819 steps.
Found uncertainty sample 75 after 154 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3406 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 749 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2015 steps.
Found uncertainty sample 83 after 37 steps.
Found uncertainty sample 84 after 413 steps.
Found uncertainty sample 85 after 3640 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 764 steps.
Found uncertainty sample 88 after 2685 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1246 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1137 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3993 steps.
Found uncertainty sample 96 after 1040 steps.
Found uncertainty sample 97 after 2295 steps.
Found uncertainty sample 98 after 1807 steps.
Found uncertainty sample 99 after 1441 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_225540-82vifh4q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/82vifh4q
Training model 26. Added 55 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.469745258251147, Training Loss Force: 2.073791918458641, time: 1.3383457660675049
Validation Loss Energy: 1.470980267309494, Validation Loss Force: 2.013101870444442, time: 0.09444093704223633
Test Loss Energy: 13.078880458431822, Test Loss Force: 9.481251263653743, time: 10.479658603668213


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6875239773942092, Training Loss Force: 1.9126835793736596, time: 1.346935510635376
Validation Loss Energy: 0.9629926752322595, Validation Loss Force: 2.1002564668483186, time: 0.09571266174316406
Test Loss Energy: 11.748843678187804, Test Loss Force: 9.47137534842899, time: 10.840245723724365


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.764977399289878, Training Loss Force: 1.9222348833205745, time: 1.3794310092926025
Validation Loss Energy: 1.1469128250511207, Validation Loss Force: 1.9845374270665337, time: 0.09727740287780762
Test Loss Energy: 11.741523384548952, Test Loss Force: 9.427743019179765, time: 10.713374853134155


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9080260150335426, Training Loss Force: 1.8739086522056394, time: 1.3737473487854004
Validation Loss Energy: 2.36542446863703, Validation Loss Force: 1.9801652070516684, time: 0.09716677665710449
Test Loss Energy: 11.261673300987812, Test Loss Force: 9.39372473225, time: 10.432600259780884


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9113522139535655, Training Loss Force: 1.888710633163222, time: 1.3645503520965576
Validation Loss Energy: 1.4241400311104164, Validation Loss Force: 2.0054423858282453, time: 0.09148311614990234
Test Loss Energy: 11.73022046554025, Test Loss Force: 9.542648211976738, time: 10.713013410568237


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2801115041228102, Training Loss Force: 1.9223705395495272, time: 1.4583196640014648
Validation Loss Energy: 1.5362191540310062, Validation Loss Force: 2.0140287307643665, time: 0.10034418106079102
Test Loss Energy: 11.500344057961636, Test Loss Force: 9.400547860478923, time: 10.663038969039917


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5768904943179296, Training Loss Force: 1.9308401526599979, time: 1.453660011291504
Validation Loss Energy: 1.0059246504156558, Validation Loss Force: 2.136415486786386, time: 0.10762453079223633
Test Loss Energy: 11.782982971225799, Test Loss Force: 9.47209995346728, time: 10.41359806060791


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5977709174138615, Training Loss Force: 1.9066374848769596, time: 1.3923249244689941
Validation Loss Energy: 0.9995217712908591, Validation Loss Force: 2.0219968348168194, time: 0.09566283226013184
Test Loss Energy: 11.926557275888948, Test Loss Force: 9.552455675674935, time: 10.730763673782349


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8360175786675834, Training Loss Force: 1.8969397969964619, time: 1.4484117031097412
Validation Loss Energy: 0.9524822183725329, Validation Loss Force: 2.0145289570006932, time: 0.09244179725646973
Test Loss Energy: 12.132839301696482, Test Loss Force: 9.383578671553147, time: 10.719603300094604


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.781196695957883, Training Loss Force: 1.930230128267814, time: 1.4588723182678223
Validation Loss Energy: 0.8452707821501406, Validation Loss Force: 2.0469800903207713, time: 0.09504151344299316
Test Loss Energy: 12.518775196525965, Test Loss Force: 9.405261073808829, time: 10.809893131256104


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1701743065184655, Training Loss Force: 1.8949815876228355, time: 1.4056496620178223
Validation Loss Energy: 1.4411080880375515, Validation Loss Force: 2.11714625557066, time: 0.09902787208557129
Test Loss Energy: 11.884204900186026, Test Loss Force: 9.537055238680306, time: 10.515844583511353


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4024847605185953, Training Loss Force: 1.8951820962405401, time: 1.4624712467193604
Validation Loss Energy: 1.7903869103398795, Validation Loss Force: 2.019115273399368, time: 0.10832571983337402
Test Loss Energy: 11.573102444143851, Test Loss Force: 9.43887016246519, time: 10.595689535140991


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4989888740689306, Training Loss Force: 1.8851890736124428, time: 1.44453763961792
Validation Loss Energy: 0.7918579929370693, Validation Loss Force: 2.004419109768134, time: 0.11557531356811523
Test Loss Energy: 12.236945274077364, Test Loss Force: 9.37328683834317, time: 10.89208459854126


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6395625884378262, Training Loss Force: 1.925176600044849, time: 1.3990545272827148
Validation Loss Energy: 1.1946673964306642, Validation Loss Force: 2.036752562444589, time: 0.09349441528320312
Test Loss Energy: 12.743519530292465, Test Loss Force: 9.450003367947257, time: 10.525114297866821


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.495480934447578, Training Loss Force: 1.8966629004911957, time: 1.4773063659667969
Validation Loss Energy: 1.088121824455526, Validation Loss Force: 2.126006038217981, time: 0.09369301795959473
Test Loss Energy: 12.058505224699575, Test Loss Force: 9.432287759401733, time: 11.251326560974121


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3539340501431338, Training Loss Force: 1.907550887321114, time: 1.3938369750976562
Validation Loss Energy: 0.9101418194425802, Validation Loss Force: 2.049725489555488, time: 0.1038367748260498
Test Loss Energy: 12.040196761301727, Test Loss Force: 9.447957637721002, time: 10.609404563903809


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4681969543230053, Training Loss Force: 1.9271234384474232, time: 1.481489658355713
Validation Loss Energy: 3.802659616552173, Validation Loss Force: 1.9856838391643428, time: 0.1003572940826416
Test Loss Energy: 11.178894392874765, Test Loss Force: 9.47240982964353, time: 10.518887281417847


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0690566076399097, Training Loss Force: 1.9129140976069818, time: 1.4368431568145752
Validation Loss Energy: 2.113709468637838, Validation Loss Force: 2.044534515091047, time: 0.10052490234375
Test Loss Energy: 11.478641249419407, Test Loss Force: 9.429105605129541, time: 10.73045301437378


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4745259833699786, Training Loss Force: 1.8829128234235863, time: 1.4509060382843018
Validation Loss Energy: 1.1988156112847261, Validation Loss Force: 2.25381846198425, time: 0.0931861400604248
Test Loss Energy: 12.41811231867693, Test Loss Force: 9.621426448026847, time: 10.608927249908447


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4807875798494723, Training Loss Force: 1.9048701747103407, time: 1.4300992488861084
Validation Loss Energy: 2.191180406554461, Validation Loss Force: 2.0256312406166526, time: 0.10484957695007324
Test Loss Energy: 11.135944312562208, Test Loss Force: 9.360166663973231, time: 10.652694463729858

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–„â–…â–†â–„â–ƒâ–…â–‡â–„â–„â–â–‚â–†â–
wandb:   test_error_force â–„â–„â–ƒâ–‚â–†â–‚â–„â–†â–‚â–‚â–†â–ƒâ–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ˆâ–
wandb:          test_loss â–ƒâ–„â–ƒâ–„â–†â–â–„â–†â–…â–…â–†â–…â–„â–…â–„â–…â–ƒâ–ƒâ–ˆâ–‚
wandb: train_error_energy â–‚â–„â–…â–†â–†â–â–ƒâ–ƒâ–…â–…â–ˆâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–‡â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚
wandb: valid_error_energy â–ƒâ–â–‚â–…â–‚â–ƒâ–â–â–â–â–ƒâ–ƒâ–â–‚â–‚â–â–ˆâ–„â–‚â–„
wandb:  valid_error_force â–‚â–„â–â–â–‚â–‚â–…â–‚â–‚â–ƒâ–…â–‚â–‚â–‚â–…â–ƒâ–â–ƒâ–ˆâ–‚
wandb:         valid_loss â–‚â–„â–â–‚â–‚â–‚â–…â–‚â–‚â–‚â–…â–ƒâ–â–‚â–…â–‚â–„â–„â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2856
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.13594
wandb:   test_error_force 9.36017
wandb:          test_loss 7.45194
wandb: train_error_energy 1.48079
wandb:  train_error_force 1.90487
wandb:         train_loss -2.55043
wandb: valid_error_energy 2.19118
wandb:  valid_error_force 2.02563
wandb:         valid_loss -2.34364
wandb: 
wandb: ğŸš€ View run al_59_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/82vifh4q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_225540-82vifh4q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 24.35953140258789, Uncertainty Bias: -2.9579546451568604
0.0 0.030385971
0.6064973 3.9903736
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1984 steps.
Found uncertainty sample 2 after 1313 steps.
Found uncertainty sample 3 after 1827 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 195 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 721 steps.
Found uncertainty sample 8 after 2349 steps.
Found uncertainty sample 9 after 1773 steps.
Found uncertainty sample 10 after 750 steps.
Found uncertainty sample 11 after 856 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1951 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 854 steps.
Found uncertainty sample 19 after 2319 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 58 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3852 steps.
Found uncertainty sample 24 after 1587 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3984 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1693 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1024 steps.
Found uncertainty sample 34 after 173 steps.
Found uncertainty sample 35 after 1292 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1820 steps.
Found uncertainty sample 39 after 690 steps.
Found uncertainty sample 40 after 760 steps.
Found uncertainty sample 41 after 2311 steps.
Found uncertainty sample 42 after 2095 steps.
Found uncertainty sample 43 after 3673 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1461 steps.
Found uncertainty sample 47 after 388 steps.
Found uncertainty sample 48 after 2364 steps.
Found uncertainty sample 49 after 2977 steps.
Found uncertainty sample 50 after 1957 steps.
Found uncertainty sample 51 after 1352 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1896 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 520 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3044 steps.
Found uncertainty sample 62 after 1211 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 470 steps.
Found uncertainty sample 65 after 3355 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3179 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 522 steps.
Found uncertainty sample 70 after 1173 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 432 steps.
Found uncertainty sample 74 after 2349 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1883 steps.
Found uncertainty sample 77 after 2441 steps.
Found uncertainty sample 78 after 1498 steps.
Found uncertainty sample 79 after 1047 steps.
Found uncertainty sample 80 after 1906 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2050 steps.
Found uncertainty sample 83 after 1139 steps.
Found uncertainty sample 84 after 1796 steps.
Found uncertainty sample 85 after 2445 steps.
Found uncertainty sample 86 after 1113 steps.
Found uncertainty sample 87 after 1231 steps.
Found uncertainty sample 88 after 2357 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3554 steps.
Found uncertainty sample 92 after 2276 steps.
Found uncertainty sample 93 after 1936 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 606 steps.
Found uncertainty sample 98 after 302 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_232610-kfvmkm3k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kfvmkm3k
Training model 27. Added 62 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5485642285543553, Training Loss Force: 2.0267650633435186, time: 1.409461259841919
Validation Loss Energy: 1.0955974956917596, Validation Loss Force: 2.0044667609653626, time: 0.08899545669555664
Test Loss Energy: 12.64470871413985, Test Loss Force: 9.411125134549454, time: 9.440993547439575


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5739709630736005, Training Loss Force: 1.9049647260926095, time: 1.4325881004333496
Validation Loss Energy: 1.2309789447336925, Validation Loss Force: 2.0249779293425005, time: 0.09009194374084473
Test Loss Energy: 11.80911596312635, Test Loss Force: 9.300497068635256, time: 9.41438603401184


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.27421041053009, Training Loss Force: 1.9018024168093062, time: 1.3445358276367188
Validation Loss Energy: 0.9719969423216442, Validation Loss Force: 1.983901372651191, time: 0.09012365341186523
Test Loss Energy: 11.786431792201858, Test Loss Force: 9.386023243023004, time: 9.666020154953003


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2593800957733112, Training Loss Force: 1.8816036520204473, time: 1.3648276329040527
Validation Loss Energy: 1.1617938597407615, Validation Loss Force: 1.972667714239134, time: 0.09054446220397949
Test Loss Energy: 12.78286006680627, Test Loss Force: 9.39656161178077, time: 9.446494102478027


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7275127950289855, Training Loss Force: 1.8916970963670756, time: 1.4339077472686768
Validation Loss Energy: 2.1611239685642634, Validation Loss Force: 2.145583220862525, time: 0.09040427207946777
Test Loss Energy: 11.206858233446718, Test Loss Force: 9.32493819938052, time: 9.460363626480103


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4491626550087509, Training Loss Force: 1.8784669019741076, time: 1.3829405307769775
Validation Loss Energy: 0.8044650468075655, Validation Loss Force: 1.9397442996605432, time: 0.09093236923217773
Test Loss Energy: 11.629833772043819, Test Loss Force: 9.299059246161908, time: 9.537395000457764


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.1702568325120135, Training Loss Force: 1.90909184488028, time: 1.3494908809661865
Validation Loss Energy: 2.3720547764607485, Validation Loss Force: 1.9985740446875293, time: 0.08852434158325195
Test Loss Energy: 11.153542902059607, Test Loss Force: 9.485829178081032, time: 9.381837129592896


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7561839801228587, Training Loss Force: 1.8995411663645057, time: 1.2874135971069336
Validation Loss Energy: 1.9874107497255857, Validation Loss Force: 1.9741863178143615, time: 0.09037590026855469
Test Loss Energy: 11.236005540710558, Test Loss Force: 9.24963778492257, time: 9.856828927993774


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6128568162887507, Training Loss Force: 1.879907582359372, time: 1.5315842628479004
Validation Loss Energy: 1.6685016609017758, Validation Loss Force: 1.9588889474891225, time: 0.09214234352111816
Test Loss Energy: 11.34758428496555, Test Loss Force: 9.343766318937842, time: 9.365806579589844


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.199952036689131, Training Loss Force: 1.9303414355305022, time: 1.3263659477233887
Validation Loss Energy: 1.4286028218003874, Validation Loss Force: 2.137095629692623, time: 0.09841537475585938
Test Loss Energy: 11.530447905244099, Test Loss Force: 9.360055459970658, time: 9.351913690567017


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.933192605668177, Training Loss Force: 1.8849819577160423, time: 1.3880627155303955
Validation Loss Energy: 1.2050000241437244, Validation Loss Force: 1.9894910362214162, time: 0.09323596954345703
Test Loss Energy: 12.722602830105084, Test Loss Force: 9.385756576319134, time: 9.569718837738037


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6492053692675352, Training Loss Force: 1.8925410307819945, time: 1.4095189571380615
Validation Loss Energy: 2.4208301188725114, Validation Loss Force: 2.1057808883587867, time: 0.09077095985412598
Test Loss Energy: 13.060585830832007, Test Loss Force: 9.424923505510762, time: 9.376380681991577


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4216520055985138, Training Loss Force: 1.9252353812057246, time: 1.3082106113433838
Validation Loss Energy: 2.148172751695092, Validation Loss Force: 2.142036546706187, time: 0.09197497367858887
Test Loss Energy: 11.124940511662329, Test Loss Force: 9.324505246622733, time: 9.277790784835815


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9094537054880927, Training Loss Force: 1.8943623359327153, time: 1.3752453327178955
Validation Loss Energy: 2.6160261229065833, Validation Loss Force: 2.038550615797956, time: 0.0978236198425293
Test Loss Energy: 11.213189288510899, Test Loss Force: 9.335350749578575, time: 10.764972686767578


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5712401572321402, Training Loss Force: 1.899358692669788, time: 1.4043910503387451
Validation Loss Energy: 1.8444588280585403, Validation Loss Force: 2.058485516425433, time: 0.09752082824707031
Test Loss Energy: 11.130923675914074, Test Loss Force: 9.265222643265536, time: 10.603090286254883


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2841653867836935, Training Loss Force: 1.898130749407778, time: 1.4076602458953857
Validation Loss Energy: 2.34951665084823, Validation Loss Force: 1.974390950759469, time: 0.09640240669250488
Test Loss Energy: 13.804867411751044, Test Loss Force: 9.357536640581607, time: 10.626362085342407


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4226865258387664, Training Loss Force: 1.8898767185966443, time: 1.5621283054351807
Validation Loss Energy: 0.8070721128353745, Validation Loss Force: 1.9795268146102936, time: 0.09418749809265137
Test Loss Energy: 12.079245309782605, Test Loss Force: 9.39725658200393, time: 10.645039796829224


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3284002037278764, Training Loss Force: 1.9003158788145489, time: 1.3952648639678955
Validation Loss Energy: 2.0307504042815325, Validation Loss Force: 2.0026839604484916, time: 0.10105514526367188
Test Loss Energy: 13.446923551371135, Test Loss Force: 9.471916371500015, time: 10.56326413154602


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8215847399727196, Training Loss Force: 1.882841966526139, time: 1.404794454574585
Validation Loss Energy: 0.8102941075433063, Validation Loss Force: 2.112392157970529, time: 0.10181689262390137
Test Loss Energy: 11.904205849611733, Test Loss Force: 9.31146577874303, time: 10.85033106803894


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.1838411405840465, Training Loss Force: 1.893135816774473, time: 1.41237473487854
Validation Loss Energy: 4.189201786421798, Validation Loss Force: 2.1624815823469845, time: 0.10538887977600098
Test Loss Energy: 15.351113148743718, Test Loss Force: 9.60093273994185, time: 10.942017316818237

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–‚â–„â–â–‚â–â–â–â–‚â–„â–„â–â–â–â–…â–ƒâ–…â–‚â–ˆ
wandb:   test_error_force â–„â–‚â–„â–„â–ƒâ–‚â–†â–â–ƒâ–ƒâ–„â–„â–‚â–ƒâ–â–ƒâ–„â–…â–‚â–ˆ
wandb:          test_loss â–‚â–â–‚â–„â–‚â–‚â–„â–â–ƒâ–â–„â–„â–‚â–‚â–‚â–…â–„â–†â–„â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–„â–‚â–â–„â–ƒâ–†â–…â–ƒâ–‚â–…â–ƒâ–‚â–‚â–‚â–„â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–â–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–„â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–‚â–â–‚â–„â–â–„â–ƒâ–ƒâ–‚â–‚â–„â–„â–…â–ƒâ–„â–â–„â–â–ˆ
wandb:  valid_error_force â–ƒâ–„â–‚â–‚â–‡â–â–ƒâ–‚â–‚â–‡â–ƒâ–†â–‡â–„â–…â–‚â–‚â–ƒâ–†â–ˆ
wandb:         valid_loss â–‚â–ƒâ–‚â–‚â–†â–â–ƒâ–ƒâ–‚â–…â–‚â–…â–†â–„â–„â–ƒâ–‚â–ƒâ–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2911
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 15.35111
wandb:   test_error_force 9.60093
wandb:          test_loss 8.0223
wandb: train_error_energy 1.18384
wandb:  train_error_force 1.89314
wandb:         train_loss -2.58577
wandb: valid_error_energy 4.1892
wandb:  valid_error_force 2.16248
wandb:         valid_loss -2.02956
wandb: 
wandb: ğŸš€ View run al_59_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kfvmkm3k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_232610-kfvmkm3k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.43349266052246, Uncertainty Bias: -2.8307461738586426
2.2888184e-05 0.03141594
0.85088825 4.0669894
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1664 steps.
Found uncertainty sample 3 after 1394 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1376 steps.
Found uncertainty sample 7 after 1040 steps.
Found uncertainty sample 8 after 184 steps.
Found uncertainty sample 9 after 176 steps.
Found uncertainty sample 10 after 2949 steps.
Found uncertainty sample 11 after 2152 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 868 steps.
Found uncertainty sample 14 after 13 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 721 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 6 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3967 steps.
Found uncertainty sample 21 after 443 steps.
Found uncertainty sample 22 after 1313 steps.
Found uncertainty sample 23 after 1934 steps.
Found uncertainty sample 24 after 2253 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1354 steps.
Found uncertainty sample 35 after 3035 steps.
Found uncertainty sample 36 after 3713 steps.
Found uncertainty sample 37 after 542 steps.
Found uncertainty sample 38 after 2463 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1351 steps.
Found uncertainty sample 41 after 1035 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2864 steps.
Found uncertainty sample 47 after 3129 steps.
Found uncertainty sample 48 after 620 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1994 steps.
Found uncertainty sample 51 after 435 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2037 steps.
Found uncertainty sample 55 after 1859 steps.
Found uncertainty sample 56 after 248 steps.
Found uncertainty sample 57 after 686 steps.
Found uncertainty sample 58 after 3887 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 454 steps.
Found uncertainty sample 61 after 2486 steps.
Found uncertainty sample 62 after 560 steps.
Found uncertainty sample 63 after 10 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3861 steps.
Found uncertainty sample 66 after 1074 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1941 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1630 steps.
Found uncertainty sample 71 after 3607 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 53 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1482 steps.
Found uncertainty sample 77 after 106 steps.
Found uncertainty sample 78 after 2246 steps.
Found uncertainty sample 79 after 3528 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 559 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1833 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 420 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 139 steps.
Found uncertainty sample 94 after 2080 steps.
Found uncertainty sample 95 after 139 steps.
Found uncertainty sample 96 after 121 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 353 steps.
Found uncertainty sample 99 after 2344 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_235624-66v0jcss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/66v0jcss
Training model 28. Added 57 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.390136910573696, Training Loss Force: 2.078591695117674, time: 1.3800358772277832
Validation Loss Energy: 0.8425110764227981, Validation Loss Force: 1.9847692256474443, time: 0.09491109848022461
Test Loss Energy: 12.363567452566677, Test Loss Force: 9.393092473119495, time: 9.997697114944458


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6368565503841408, Training Loss Force: 1.9151222171027238, time: 1.389603853225708
Validation Loss Energy: 1.9792719697727792, Validation Loss Force: 2.0996803104332304, time: 0.09824562072753906
Test Loss Energy: 13.023661928387996, Test Loss Force: 9.302105854380391, time: 9.503343105316162


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3992636729579802, Training Loss Force: 1.908276633706439, time: 1.4376940727233887
Validation Loss Energy: 3.680339549939359, Validation Loss Force: 1.968144635877903, time: 0.09689140319824219
Test Loss Energy: 10.937170065482782, Test Loss Force: 9.249456264102164, time: 9.66891860961914


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6078744946144823, Training Loss Force: 1.909724925308829, time: 1.3652153015136719
Validation Loss Energy: 1.2130826914717572, Validation Loss Force: 2.026490854854507, time: 0.09704256057739258
Test Loss Energy: 12.655085567326136, Test Loss Force: 9.371431722232286, time: 9.523446083068848


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2881553731478839, Training Loss Force: 1.8925088807961579, time: 1.4044644832611084
Validation Loss Energy: 1.3733008797196216, Validation Loss Force: 2.02337582483755, time: 0.09254217147827148
Test Loss Energy: 11.286728466967828, Test Loss Force: 9.261289275575022, time: 9.451748132705688


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5093566367784508, Training Loss Force: 1.9196963896529238, time: 1.3736279010772705
Validation Loss Energy: 2.1125660625734985, Validation Loss Force: 2.120282773160199, time: 0.09204840660095215
Test Loss Energy: 11.371796647062421, Test Loss Force: 9.29681733392583, time: 9.707304000854492


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8552286199509378, Training Loss Force: 1.8749359443312554, time: 1.3557817935943604
Validation Loss Energy: 3.2556332244725867, Validation Loss Force: 2.0431445029475923, time: 0.0934598445892334
Test Loss Energy: 14.562976905181959, Test Loss Force: 9.466096252358597, time: 9.510575771331787


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3557356073830649, Training Loss Force: 1.913222159731895, time: 1.3981835842132568
Validation Loss Energy: 1.2513299026603355, Validation Loss Force: 1.975914675725053, time: 0.09448647499084473
Test Loss Energy: 11.596251776743221, Test Loss Force: 9.277575240949442, time: 9.668290376663208


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3908038896926809, Training Loss Force: 1.90025525546225, time: 1.3617682456970215
Validation Loss Energy: 1.3239456511845762, Validation Loss Force: 1.9786738804468174, time: 0.09507608413696289
Test Loss Energy: 12.485912103135588, Test Loss Force: 9.35554395457598, time: 9.471619367599487


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1864902431617095, Training Loss Force: 1.8977571327083778, time: 1.3896517753601074
Validation Loss Energy: 1.1923496889579885, Validation Loss Force: 2.0451019874094434, time: 0.09581565856933594
Test Loss Energy: 12.794560619282473, Test Loss Force: 9.320530683974415, time: 9.493624687194824


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3306908969905558, Training Loss Force: 1.8767382451584376, time: 1.3830029964447021
Validation Loss Energy: 0.9758824632507976, Validation Loss Force: 1.9672503965878567, time: 0.09350728988647461
Test Loss Energy: 12.072732589337942, Test Loss Force: 9.241503058480864, time: 9.625896692276001


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3707936760151773, Training Loss Force: 1.8771542868947069, time: 1.3349878787994385
Validation Loss Energy: 0.9223949963729108, Validation Loss Force: 1.9968466887879948, time: 0.0921010971069336
Test Loss Energy: 11.60636141296471, Test Loss Force: 9.281649564038364, time: 9.993293046951294


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.540282712709508, Training Loss Force: 1.8881555313928362, time: 1.373810052871704
Validation Loss Energy: 1.150294501370326, Validation Loss Force: 1.9967804447170812, time: 0.09520816802978516
Test Loss Energy: 12.612163223894834, Test Loss Force: 9.387151156677499, time: 9.51151990890503


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5439653880324502, Training Loss Force: 1.8959957670896672, time: 1.320500135421753
Validation Loss Energy: 1.0912132515430144, Validation Loss Force: 1.9421830834813172, time: 0.10397934913635254
Test Loss Energy: 11.611597229614299, Test Loss Force: 9.229703291161753, time: 9.652813911437988


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2074623049465505, Training Loss Force: 1.8748399092834793, time: 1.3517210483551025
Validation Loss Energy: 1.8581907786206207, Validation Loss Force: 1.958138552467346, time: 0.09879803657531738
Test Loss Energy: 11.538267933731607, Test Loss Force: 9.213892396822107, time: 9.547269344329834


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7213347767842564, Training Loss Force: 1.8847971096336293, time: 1.3436875343322754
Validation Loss Energy: 1.3798488556266335, Validation Loss Force: 2.0405737876578556, time: 0.09264612197875977
Test Loss Energy: 11.526508629243473, Test Loss Force: 9.235604028192066, time: 9.557304859161377


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.534449965662113, Training Loss Force: 1.8919256300941933, time: 1.357882022857666
Validation Loss Energy: 2.314518293833311, Validation Loss Force: 2.017644098352223, time: 0.09395074844360352
Test Loss Energy: 13.473699182748135, Test Loss Force: 9.399887346848837, time: 9.719865798950195


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2971931450601417, Training Loss Force: 1.8476304280100222, time: 1.4138686656951904
Validation Loss Energy: 1.354672044967584, Validation Loss Force: 2.0339099681276753, time: 0.09653162956237793
Test Loss Energy: 13.02538715027773, Test Loss Force: 9.414038658898706, time: 9.583609580993652


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2249186250305757, Training Loss Force: 1.8612153073969362, time: 1.3918585777282715
Validation Loss Energy: 1.1757390160100676, Validation Loss Force: 1.9497484903833597, time: 0.09447598457336426
Test Loss Energy: 11.694902117224236, Test Loss Force: 9.252907682496327, time: 9.624004364013672


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6359434967484092, Training Loss Force: 1.8881402821477786, time: 1.3661446571350098
Validation Loss Energy: 1.7637645315854669, Validation Loss Force: 2.0504437088856777, time: 0.10234427452087402
Test Loss Energy: 11.25560630588295, Test Loss Force: 9.214778046445833, time: 9.346322536468506

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–â–„â–‚â–‚â–ˆâ–‚â–„â–…â–ƒâ–‚â–„â–‚â–‚â–‚â–†â–…â–‚â–‚
wandb:   test_error_force â–†â–ƒâ–‚â–…â–‚â–ƒâ–ˆâ–ƒâ–…â–„â–‚â–ƒâ–†â–â–â–‚â–†â–‡â–‚â–
wandb:          test_loss â–‚â–ƒâ–â–„â–‚â–‚â–ˆâ–‚â–ƒâ–„â–„â–„â–…â–â–ƒâ–‚â–…â–ˆâ–„â–‚
wandb: train_error_energy â–ˆâ–„â–‚â–ƒâ–‚â–ƒâ–…â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–â–„â–ƒâ–‚â–â–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb: valid_error_energy â–â–„â–ˆâ–‚â–‚â–„â–‡â–‚â–‚â–‚â–â–â–‚â–‚â–„â–‚â–…â–‚â–‚â–ƒ
wandb:  valid_error_force â–ƒâ–‡â–‚â–„â–„â–ˆâ–…â–‚â–‚â–…â–‚â–ƒâ–ƒâ–â–‚â–…â–„â–…â–â–…
wandb:         valid_loss â–‚â–‡â–†â–„â–„â–ˆâ–‡â–‚â–‚â–„â–‚â–‚â–ƒâ–â–ƒâ–„â–…â–„â–â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2962
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.25561
wandb:   test_error_force 9.21478
wandb:          test_loss 7.4304
wandb: train_error_energy 1.63594
wandb:  train_error_force 1.88814
wandb:         train_loss -2.5617
wandb: valid_error_energy 1.76376
wandb:  valid_error_force 2.05044
wandb:         valid_loss -2.33617
wandb: 
wandb: ğŸš€ View run al_59_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/66v0jcss
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_235624-66v0jcss/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 25.694015502929688, Uncertainty Bias: -3.075810432434082
2.5749207e-05 0.0038642883
0.743772 3.9475284
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1574 steps.
Found uncertainty sample 5 after 379 steps.
Found uncertainty sample 6 after 2656 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1019 steps.
Found uncertainty sample 10 after 543 steps.
Found uncertainty sample 11 after 576 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2366 steps.
Found uncertainty sample 14 after 862 steps.
Found uncertainty sample 15 after 1120 steps.
Found uncertainty sample 16 after 374 steps.
Found uncertainty sample 17 after 2037 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 791 steps.
Found uncertainty sample 20 after 527 steps.
Found uncertainty sample 21 after 1166 steps.
Found uncertainty sample 22 after 30 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1201 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1208 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3187 steps.
Found uncertainty sample 31 after 82 steps.
Found uncertainty sample 32 after 1084 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 325 steps.
Found uncertainty sample 36 after 1831 steps.
Found uncertainty sample 37 after 1546 steps.
Found uncertainty sample 38 after 1380 steps.
Found uncertainty sample 39 after 228 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2166 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 625 steps.
Found uncertainty sample 47 after 2404 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 516 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1754 steps.
Found uncertainty sample 53 after 1438 steps.
Found uncertainty sample 54 after 229 steps.
Found uncertainty sample 55 after 2721 steps.
Found uncertainty sample 56 after 2067 steps.
Found uncertainty sample 57 after 1086 steps.
Found uncertainty sample 58 after 1063 steps.
Found uncertainty sample 59 after 2577 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 945 steps.
Found uncertainty sample 62 after 37 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 913 steps.
Found uncertainty sample 65 after 846 steps.
Found uncertainty sample 66 after 2162 steps.
Found uncertainty sample 67 after 2514 steps.
Found uncertainty sample 68 after 2676 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 63 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3664 steps.
Found uncertainty sample 75 after 1301 steps.
Found uncertainty sample 76 after 1504 steps.
Found uncertainty sample 77 after 1881 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1373 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3678 steps.
Found uncertainty sample 82 after 838 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3635 steps.
Found uncertainty sample 85 after 2360 steps.
Found uncertainty sample 86 after 1992 steps.
Found uncertainty sample 87 after 2008 steps.
Found uncertainty sample 88 after 1107 steps.
Found uncertainty sample 89 after 1851 steps.
Found uncertainty sample 90 after 917 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 866 steps.
Found uncertainty sample 93 after 30 steps.
Found uncertainty sample 94 after 1352 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1107 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2344 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_002435-pohsaptw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pohsaptw
Training model 29. Added 64 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.494907254962991, Training Loss Force: 2.0663228211057394, time: 1.392134666442871
Validation Loss Energy: 1.5056682235349896, Validation Loss Force: 2.042145052486095, time: 0.10022473335266113
Test Loss Energy: 11.68176867130688, Test Loss Force: 9.283267550332713, time: 9.210359811782837


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8047918994904981, Training Loss Force: 1.9060783924709706, time: 1.3773679733276367
Validation Loss Energy: 3.2588043671143176, Validation Loss Force: 2.0340932248347734, time: 0.09186720848083496
Test Loss Energy: 11.069150414402849, Test Loss Force: 9.153714808058353, time: 9.193535089492798


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5939796793214194, Training Loss Force: 1.905219639611128, time: 1.412505865097046
Validation Loss Energy: 0.8207164430885321, Validation Loss Force: 2.073766854572165, time: 0.09209632873535156
Test Loss Energy: 12.241768488296971, Test Loss Force: 9.338983945270696, time: 9.393417835235596


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2445655108015823, Training Loss Force: 1.909697823184769, time: 1.4140615463256836
Validation Loss Energy: 0.8193227290705268, Validation Loss Force: 2.0063408558320637, time: 0.09515118598937988
Test Loss Energy: 12.019332876836787, Test Loss Force: 9.176949682915586, time: 9.217939138412476


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.49736107230749, Training Loss Force: 1.9188819609453052, time: 1.391301155090332
Validation Loss Energy: 0.9260846241209342, Validation Loss Force: 2.229008665744976, time: 0.09143924713134766
Test Loss Energy: 11.85568333285968, Test Loss Force: 9.503370866868096, time: 9.210904598236084


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.641564483056336, Training Loss Force: 1.8921853437116685, time: 1.4343948364257812
Validation Loss Energy: 1.6111297864404652, Validation Loss Force: 2.0372070301714276, time: 0.09383821487426758
Test Loss Energy: 13.087440000298137, Test Loss Force: 9.335608416252049, time: 9.846246242523193


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7109478150776583, Training Loss Force: 1.901032708452304, time: 1.3783643245697021
Validation Loss Energy: 2.412454084944719, Validation Loss Force: 2.174210902277877, time: 0.09133577346801758
Test Loss Energy: 11.367189913884937, Test Loss Force: 9.26583565725331, time: 9.211315870285034


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.557932239478348, Training Loss Force: 1.888492980648979, time: 1.4476773738861084
Validation Loss Energy: 2.570329181437272, Validation Loss Force: 2.0449074859104757, time: 0.09857583045959473
Test Loss Energy: 13.97394414659931, Test Loss Force: 9.302154944183515, time: 9.185470819473267


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6828200748235291, Training Loss Force: 1.8913123447142581, time: 1.3840384483337402
Validation Loss Energy: 2.536825825068112, Validation Loss Force: 2.135981727290119, time: 0.09638500213623047
Test Loss Energy: 11.168509971269135, Test Loss Force: 9.22232731391512, time: 9.367732286453247


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9727372526414644, Training Loss Force: 1.9149852567512828, time: 1.417468786239624
Validation Loss Energy: 1.8076655350582977, Validation Loss Force: 2.000918639459576, time: 0.09304451942443848
Test Loss Energy: 11.205422308907245, Test Loss Force: 9.187615073345938, time: 9.179652452468872


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6063990556233134, Training Loss Force: 1.8942993095017922, time: 1.3746509552001953
Validation Loss Energy: 1.8231909185889665, Validation Loss Force: 2.0318882436172236, time: 0.09407186508178711
Test Loss Energy: 11.486835385388215, Test Loss Force: 9.143835311474355, time: 9.281569004058838


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9985022836955397, Training Loss Force: 1.9072483172586467, time: 1.4865586757659912
Validation Loss Energy: 0.8236885473474465, Validation Loss Force: 1.9670315128174098, time: 0.09579157829284668
Test Loss Energy: 12.04542837638272, Test Loss Force: 9.213684985758809, time: 9.205450534820557


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6319995142555195, Training Loss Force: 1.8834642874580891, time: 1.4087908267974854
Validation Loss Energy: 0.9013327496932446, Validation Loss Force: 2.0792733512163863, time: 0.09344363212585449
Test Loss Energy: 12.444650293292616, Test Loss Force: 9.166997663806823, time: 9.20795750617981


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4226103040394067, Training Loss Force: 1.9014017356839636, time: 1.3986279964447021
Validation Loss Energy: 5.994642188704839, Validation Loss Force: 2.0131309287679855, time: 0.09490966796875
Test Loss Energy: 10.52866417887096, Test Loss Force: 9.049873487866765, time: 9.373377799987793


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7614252685675222, Training Loss Force: 1.8902143279974017, time: 1.3653898239135742
Validation Loss Energy: 2.9889782381273697, Validation Loss Force: 2.0005193936809276, time: 0.09852719306945801
Test Loss Energy: 14.265271670559539, Test Loss Force: 9.2622929748203, time: 9.192577362060547


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5532537023090014, Training Loss Force: 1.8977919371686414, time: 1.4275121688842773
Validation Loss Energy: 0.7781977418399778, Validation Loss Force: 2.0098743925087916, time: 0.09200906753540039
Test Loss Energy: 12.1198498003068, Test Loss Force: 9.284826691350569, time: 9.177372217178345


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3565085204680523, Training Loss Force: 1.8767421696296755, time: 1.3904964923858643
Validation Loss Energy: 2.1307040231933385, Validation Loss Force: 2.016542442752745, time: 0.09184861183166504
Test Loss Energy: 13.60940474217891, Test Loss Force: 9.318319758889638, time: 9.396174192428589


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.577449589165467, Training Loss Force: 1.8935700164833915, time: 1.3515141010284424
Validation Loss Energy: 1.4169712536245576, Validation Loss Force: 2.0762825705828574, time: 0.1008291244506836
Test Loss Energy: 11.540901226046193, Test Loss Force: 9.225921338490467, time: 9.688432455062866


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.623026018577173, Training Loss Force: 1.8966406591640224, time: 1.4307172298431396
Validation Loss Energy: 0.7924579471171285, Validation Loss Force: 1.9638361549060595, time: 0.0937047004699707
Test Loss Energy: 12.067619718699504, Test Loss Force: 9.18924099645466, time: 9.221607208251953


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4295206534724159, Training Loss Force: 1.8983641511679037, time: 1.4076526165008545
Validation Loss Energy: 1.0591379837412624, Validation Loss Force: 2.0309883262639565, time: 0.09421133995056152
Test Loss Energy: 11.881296001759136, Test Loss Force: 9.27647540925509, time: 9.339812755584717

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–„â–„â–ƒâ–†â–ƒâ–‡â–‚â–‚â–ƒâ–„â–…â–â–ˆâ–„â–‡â–ƒâ–„â–„
wandb:   test_error_force â–…â–ƒâ–…â–ƒâ–ˆâ–…â–„â–…â–„â–ƒâ–‚â–„â–ƒâ–â–„â–…â–…â–„â–ƒâ–„
wandb:          test_loss â–‚â–‚â–…â–‚â–†â–‡â–…â–†â–„â–‚â–ƒâ–„â–ƒâ–â–‡â–†â–ˆâ–…â–„â–…
wandb: train_error_energy â–ˆâ–„â–ƒâ–â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–…â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–„â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–ˆâ–„â–â–ƒâ–‚â–â–
wandb:  valid_error_force â–ƒâ–ƒâ–„â–‚â–ˆâ–ƒâ–‡â–ƒâ–†â–‚â–ƒâ–â–„â–‚â–‚â–‚â–‚â–„â–â–ƒ
wandb:         valid_loss â–„â–…â–ƒâ–‚â–‡â–„â–ˆâ–…â–‡â–ƒâ–„â–â–„â–ˆâ–„â–‚â–„â–„â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3019
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.8813
wandb:   test_error_force 9.27648
wandb:          test_loss 7.53715
wandb: train_error_energy 1.42952
wandb:  train_error_force 1.89836
wandb:         train_loss -2.56201
wandb: valid_error_energy 1.05914
wandb:  valid_error_force 2.03099
wandb:         valid_loss -2.41003
wandb: 
wandb: ğŸš€ View run al_59_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pohsaptw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_002435-pohsaptw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 24.103435516357422, Uncertainty Bias: -2.8872931003570557
2.8133392e-05 0.0049114227
0.7324354 3.7195866
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3812 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 370 steps.
Found uncertainty sample 5 after 334 steps.
Found uncertainty sample 6 after 675 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 828 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1073 steps.
Found uncertainty sample 14 after 3899 steps.
Found uncertainty sample 15 after 2356 steps.
Found uncertainty sample 16 after 797 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1864 steps.
Found uncertainty sample 19 after 3585 steps.
Found uncertainty sample 20 after 189 steps.
Found uncertainty sample 21 after 3191 steps.
Found uncertainty sample 22 after 787 steps.
Found uncertainty sample 23 after 926 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 5 steps.
Found uncertainty sample 26 after 2477 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1320 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 166 steps.
Found uncertainty sample 33 after 1203 steps.
Found uncertainty sample 34 after 2575 steps.
Found uncertainty sample 35 after 516 steps.
Found uncertainty sample 36 after 1193 steps.
Found uncertainty sample 37 after 258 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2914 steps.
Found uncertainty sample 40 after 68 steps.
Found uncertainty sample 41 after 79 steps.
Found uncertainty sample 42 after 1346 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 306 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1005 steps.
Found uncertainty sample 50 after 725 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 317 steps.
Found uncertainty sample 54 after 2379 steps.
Found uncertainty sample 55 after 3304 steps.
Found uncertainty sample 56 after 354 steps.
Found uncertainty sample 57 after 799 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 401 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 42 steps.
Found uncertainty sample 64 after 1917 steps.
Found uncertainty sample 65 after 103 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1934 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 5 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3741 steps.
Found uncertainty sample 73 after 462 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 909 steps.
Found uncertainty sample 77 after 148 steps.
Found uncertainty sample 78 after 860 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 934 steps.
Found uncertainty sample 82 after 2699 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 733 steps.
Found uncertainty sample 87 after 1357 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1136 steps.
Found uncertainty sample 93 after 2297 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1699 steps.
Found uncertainty sample 96 after 223 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2542 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_005350-c7k5l3fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/c7k5l3fa
Training model 30. Added 56 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7700546493342277, Training Loss Force: 2.052824771529046, time: 1.5162591934204102
Validation Loss Energy: 4.9193085316363785, Validation Loss Force: 2.1098457136176987, time: 0.09346771240234375
Test Loss Energy: 10.63976563705779, Test Loss Force: 9.0354946475872, time: 9.367092370986938


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.495308658653948, Training Loss Force: 1.921228089106939, time: 1.44675612449646
Validation Loss Energy: 0.835795374981616, Validation Loss Force: 2.018665147720875, time: 0.09502458572387695
Test Loss Energy: 12.070773879612888, Test Loss Force: 9.183731681471905, time: 9.32234001159668


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7664897792624767, Training Loss Force: 1.9286544437662905, time: 1.434577465057373
Validation Loss Energy: 0.7967692671205823, Validation Loss Force: 1.9923452093339185, time: 0.09405946731567383
Test Loss Energy: 12.046028207424413, Test Loss Force: 9.23198168383194, time: 9.54577088356018


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5332199577794698, Training Loss Force: 1.9053298066604196, time: 1.4511456489562988
Validation Loss Energy: 0.9043556781847168, Validation Loss Force: 1.9827034126460994, time: 0.09497499465942383
Test Loss Energy: 12.262529865679904, Test Loss Force: 9.10810201978781, time: 9.400649070739746


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4462329138192944, Training Loss Force: 1.8887089616756292, time: 1.427227258682251
Validation Loss Energy: 0.8056724145840725, Validation Loss Force: 1.9551488851795462, time: 0.09467172622680664
Test Loss Energy: 12.220698041476266, Test Loss Force: 9.135854121820705, time: 9.38046932220459


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3903565381099836, Training Loss Force: 1.8931811021502591, time: 1.424652099609375
Validation Loss Energy: 1.2126523833472518, Validation Loss Force: 2.0150035762852383, time: 0.10028862953186035
Test Loss Energy: 11.295418602539515, Test Loss Force: 9.050743133291355, time: 9.565975189208984


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7401914270255892, Training Loss Force: 1.9260099658427603, time: 1.4232985973358154
Validation Loss Energy: 0.782968010786832, Validation Loss Force: 1.9942437978066718, time: 0.09376311302185059
Test Loss Energy: 11.697274142853189, Test Loss Force: 9.1287619766209, time: 9.287713289260864


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.563372252517519, Training Loss Force: 1.8789800004547956, time: 1.3968493938446045
Validation Loss Energy: 2.083401971185607, Validation Loss Force: 2.008264049245442, time: 0.09531879425048828
Test Loss Energy: 11.298395598087621, Test Loss Force: 9.102064421673436, time: 9.353680849075317


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5457482586758857, Training Loss Force: 1.9140033497618745, time: 1.6107168197631836
Validation Loss Energy: 2.2518544087825942, Validation Loss Force: 1.9714866770891328, time: 0.10521602630615234
Test Loss Energy: 11.114856136147935, Test Loss Force: 9.037736564486508, time: 9.327794551849365


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7477273685370556, Training Loss Force: 1.8856402653967876, time: 1.416262149810791
Validation Loss Energy: 1.6662238112062209, Validation Loss Force: 1.9670888501224861, time: 0.09473085403442383
Test Loss Energy: 12.916780220724327, Test Loss Force: 9.053514597057118, time: 9.36716604232788


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3292352669209286, Training Loss Force: 1.8930976371723254, time: 1.4475247859954834
Validation Loss Energy: 4.313356535462484, Validation Loss Force: 2.0730719041677244, time: 0.10112166404724121
Test Loss Energy: 10.624405672220597, Test Loss Force: 9.043980440499732, time: 9.507919549942017


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5541585042102948, Training Loss Force: 1.9046382218073414, time: 1.408315658569336
Validation Loss Energy: 0.8937074447909474, Validation Loss Force: 2.0462846945780386, time: 0.09891653060913086
Test Loss Energy: 11.346410848877495, Test Loss Force: 9.118341237794153, time: 9.407392263412476


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4080220327834905, Training Loss Force: 1.905145887744559, time: 1.4087293148040771
Validation Loss Energy: 1.4322697929628128, Validation Loss Force: 1.9910606310310612, time: 0.10374999046325684
Test Loss Energy: 12.593733903612064, Test Loss Force: 9.099905514899085, time: 9.809795379638672


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3739253518601708, Training Loss Force: 1.8799423996981985, time: 1.4502146244049072
Validation Loss Energy: 0.8707775606498119, Validation Loss Force: 1.9727032299679095, time: 0.0944523811340332
Test Loss Energy: 11.536225593672246, Test Loss Force: 9.146144789223635, time: 9.466883897781372


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7444805305629287, Training Loss Force: 1.894105820439389, time: 1.405073881149292
Validation Loss Energy: 1.872924851673949, Validation Loss Force: 1.9558684961918984, time: 0.09451889991760254
Test Loss Energy: 11.056494221911061, Test Loss Force: 9.058638416955343, time: 9.375516414642334


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7298964506935555, Training Loss Force: 1.9011338095590589, time: 1.3620128631591797
Validation Loss Energy: 1.8656031561521242, Validation Loss Force: 2.1260290844745846, time: 0.09710240364074707
Test Loss Energy: 11.188316534027873, Test Loss Force: 9.050092570990218, time: 9.4123694896698


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8539438401534536, Training Loss Force: 1.902853949586584, time: 1.3867764472961426
Validation Loss Energy: 2.620360600501214, Validation Loss Force: 1.989618180303741, time: 0.09706234931945801
Test Loss Energy: 11.097077490083777, Test Loss Force: 9.01422626071964, time: 9.50388216972351


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8133633914790057, Training Loss Force: 1.868969745476958, time: 1.4072082042694092
Validation Loss Energy: 2.866324724468529, Validation Loss Force: 1.9815244908529848, time: 0.09774112701416016
Test Loss Energy: 13.982749864944836, Test Loss Force: 9.200586812499456, time: 9.373516082763672


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.79929078959624, Training Loss Force: 1.886505867347144, time: 1.4495429992675781
Validation Loss Energy: 2.159045574756173, Validation Loss Force: 2.003506722942695, time: 0.10105490684509277
Test Loss Energy: 10.96546138591739, Test Loss Force: 9.036600830598344, time: 9.378982305526733


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6518772126199206, Training Loss Force: 1.923159321804274, time: 1.4404594898223877
Validation Loss Energy: 2.0373307228819906, Validation Loss Force: 1.9542224701979138, time: 0.09638786315917969
Test Loss Energy: 11.254949275684318, Test Loss Force: 9.11505255673726, time: 9.62242865562439

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–„â–„â–„â–‚â–ƒâ–‚â–‚â–†â–â–ƒâ–…â–ƒâ–‚â–‚â–‚â–ˆâ–‚â–‚
wandb:   test_error_force â–‚â–†â–ˆâ–„â–…â–‚â–…â–„â–‚â–‚â–‚â–„â–„â–…â–‚â–‚â–â–‡â–‚â–„
wandb:          test_loss â–â–…â–…â–„â–„â–„â–…â–…â–ƒâ–„â–ƒâ–„â–„â–†â–„â–ƒâ–ƒâ–ˆâ–„â–‚
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–â–â–ƒâ–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–ƒ
wandb: valid_error_energy â–ˆâ–â–â–â–â–‚â–â–ƒâ–ƒâ–‚â–‡â–â–‚â–â–ƒâ–ƒâ–„â–…â–ƒâ–ƒ
wandb:  valid_error_force â–‡â–„â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–‚â–†â–…â–ƒâ–‚â–â–ˆâ–‚â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–‡â–ƒâ–‚â–â–‚â–…â–ƒâ–„â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3069
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.25495
wandb:   test_error_force 9.11505
wandb:          test_loss 7.03126
wandb: train_error_energy 1.65188
wandb:  train_error_force 1.92316
wandb:         train_loss -2.51493
wandb: valid_error_energy 2.03733
wandb:  valid_error_force 1.95422
wandb:         valid_loss -2.44868
wandb: 
wandb: ğŸš€ View run al_59_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/c7k5l3fa
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_005350-c7k5l3fa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 22.486597061157227, Uncertainty Bias: -2.754716157913208
4.386902e-05 0.06183529
0.69972265 4.113312
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1182 steps.
Found uncertainty sample 2 after 2094 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 707 steps.
Found uncertainty sample 5 after 2178 steps.
Found uncertainty sample 6 after 3738 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2721 steps.
Found uncertainty sample 9 after 357 steps.
Found uncertainty sample 10 after 337 steps.
Found uncertainty sample 11 after 208 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 10 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1605 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 893 steps.
Found uncertainty sample 19 after 51 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 960 steps.
Found uncertainty sample 25 after 343 steps.
Found uncertainty sample 26 after 80 steps.
Found uncertainty sample 27 after 818 steps.
Found uncertainty sample 28 after 634 steps.
Found uncertainty sample 29 after 359 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1449 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3199 steps.
Found uncertainty sample 35 after 949 steps.
Found uncertainty sample 36 after 192 steps.
Found uncertainty sample 37 after 1575 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1684 steps.
Found uncertainty sample 40 after 513 steps.
Found uncertainty sample 41 after 2226 steps.
Found uncertainty sample 42 after 2407 steps.
Found uncertainty sample 43 after 2118 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2414 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 11 steps.
Found uncertainty sample 50 after 1952 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3488 steps.
Found uncertainty sample 59 after 3817 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 61 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 193 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 120 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2544 steps.
Found uncertainty sample 72 after 1383 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2965 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3968 steps.
Found uncertainty sample 77 after 1334 steps.
Found uncertainty sample 78 after 1789 steps.
Found uncertainty sample 79 after 2706 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 314 steps.
Found uncertainty sample 83 after 1577 steps.
Found uncertainty sample 84 after 1377 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 519 steps.
Found uncertainty sample 88 after 115 steps.
Found uncertainty sample 89 after 331 steps.
Found uncertainty sample 90 after 406 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2515 steps.
Found uncertainty sample 94 after 2060 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 372 steps.
Found uncertainty sample 97 after 1602 steps.
Found uncertainty sample 98 after 2914 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_012338-qgrucfae
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qgrucfae
Training model 31. Added 56 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.525343880762264, Training Loss Force: 1.9872284075524795, time: 1.4450976848602295
Validation Loss Energy: 1.1408262196144712, Validation Loss Force: 2.0173611972023218, time: 0.10162210464477539
Test Loss Energy: 12.56263870997579, Test Loss Force: 9.109412951158959, time: 9.468443632125854


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2998407783145258, Training Loss Force: 1.8939088398053918, time: 1.4494826793670654
Validation Loss Energy: 0.8462571507993142, Validation Loss Force: 1.9567356255134278, time: 0.09798574447631836
Test Loss Energy: 11.665401575088463, Test Loss Force: 9.101263176479893, time: 9.46526026725769


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7700315859394486, Training Loss Force: 1.892388929753032, time: 1.4887707233428955
Validation Loss Energy: 0.898335455987197, Validation Loss Force: 1.940913424011237, time: 0.0986015796661377
Test Loss Energy: 11.799637550798714, Test Loss Force: 9.10706732406477, time: 9.691449642181396


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5710470555425835, Training Loss Force: 1.895660443920491, time: 1.435427188873291
Validation Loss Energy: 0.8090271201029773, Validation Loss Force: 2.046123259447241, time: 0.09519791603088379
Test Loss Energy: 11.692885672070995, Test Loss Force: 8.975123311018734, time: 9.467931270599365


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3560725964052562, Training Loss Force: 1.908725936640273, time: 1.4420511722564697
Validation Loss Energy: 1.1920290453878524, Validation Loss Force: 1.9744180050606994, time: 0.09616398811340332
Test Loss Energy: 11.326697476070846, Test Loss Force: 9.074167251274872, time: 9.516231536865234


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.736307949005378, Training Loss Force: 1.8939172501099186, time: 1.4603800773620605
Validation Loss Energy: 1.954862755327029, Validation Loss Force: 2.0158749919878267, time: 0.09895610809326172
Test Loss Energy: 10.719260541331812, Test Loss Force: 8.965378647014532, time: 9.700547218322754


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.033563404619279, Training Loss Force: 1.9014365656348209, time: 1.4450647830963135
Validation Loss Energy: 2.3621441067792217, Validation Loss Force: 2.1173172654747328, time: 0.0972292423248291
Test Loss Energy: 13.363926581381607, Test Loss Force: 9.114319399338475, time: 9.38693380355835


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.35418241823703, Training Loss Force: 1.9039080999971199, time: 1.499293565750122
Validation Loss Energy: 0.9013595256580422, Validation Loss Force: 2.081117942421252, time: 0.09730696678161621
Test Loss Energy: 11.73984687474086, Test Loss Force: 9.18353084089712, time: 10.157993078231812


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3017575864629314, Training Loss Force: 1.9131986202022984, time: 1.4287307262420654
Validation Loss Energy: 3.2565694368966405, Validation Loss Force: 2.0131150079240516, time: 0.09739804267883301
Test Loss Energy: 10.618527794334856, Test Loss Force: 8.993035311419353, time: 9.422733306884766


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8701420661760242, Training Loss Force: 1.8998101731519588, time: 1.4474093914031982
Validation Loss Energy: 1.8880807157569506, Validation Loss Force: 2.00793416490575, time: 0.09638714790344238
Test Loss Energy: 13.042800702880673, Test Loss Force: 9.157821913641431, time: 9.447028398513794


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.600561632710434, Training Loss Force: 1.8991893329468315, time: 1.4914135932922363
Validation Loss Energy: 2.472162371086964, Validation Loss Force: 2.0164710772914756, time: 0.09619426727294922
Test Loss Energy: 13.330439221633839, Test Loss Force: 9.155162884970483, time: 9.659536838531494


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8854801429204862, Training Loss Force: 1.88384353321842, time: 1.5106546878814697
Validation Loss Energy: 2.132564535242138, Validation Loss Force: 1.9543530656520005, time: 0.09980916976928711
Test Loss Energy: 10.879694738178497, Test Loss Force: 8.963332506424196, time: 9.507806062698364


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6691108689161622, Training Loss Force: 1.8864439884719426, time: 1.4245388507843018
Validation Loss Energy: 1.1529935297554035, Validation Loss Force: 2.0289431101586093, time: 0.09804224967956543
Test Loss Energy: 12.150238314353935, Test Loss Force: 9.073333834470068, time: 9.508890151977539


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7951643149240073, Training Loss Force: 1.897853279444984, time: 1.471480369567871
Validation Loss Energy: 4.492567344179545, Validation Loss Force: 2.05379521353561, time: 0.09579849243164062
Test Loss Energy: 10.358699756568255, Test Loss Force: 8.943451038231093, time: 9.574800252914429


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4170503704714532, Training Loss Force: 1.9098542421011035, time: 1.461451530456543
Validation Loss Energy: 4.398640377036848, Validation Loss Force: 2.056750144436645, time: 0.09601354598999023
Test Loss Energy: 15.205425119324122, Test Loss Force: 9.151159093207887, time: 9.4640634059906


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8015671116839411, Training Loss Force: 1.9328186428000256, time: 1.442781686782837
Validation Loss Energy: 1.1599609586660569, Validation Loss Force: 1.9668110703629411, time: 0.09945273399353027
Test Loss Energy: 12.013288852793972, Test Loss Force: 9.071646739133989, time: 9.41305136680603


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5853987358042287, Training Loss Force: 1.9142823270781208, time: 1.4551076889038086
Validation Loss Energy: 5.087985085728741, Validation Loss Force: 1.985557029085737, time: 0.10314273834228516
Test Loss Energy: 10.487645537725024, Test Loss Force: 8.925001064510685, time: 9.567646026611328


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9011432835325475, Training Loss Force: 1.9219323823376282, time: 1.4636821746826172
Validation Loss Energy: 1.895450173810577, Validation Loss Force: 1.993709391856445, time: 0.09682250022888184
Test Loss Energy: 11.004227044323532, Test Loss Force: 8.923931077476729, time: 9.419785976409912


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6416904700722872, Training Loss Force: 1.9016726858148703, time: 1.4459474086761475
Validation Loss Energy: 1.901613878439004, Validation Loss Force: 2.0992544556916437, time: 0.09845352172851562
Test Loss Energy: 12.801741570999875, Test Loss Force: 9.084745416021983, time: 9.598853826522827


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3734023486861402, Training Loss Force: 1.882047432764348, time: 1.4589335918426514
Validation Loss Energy: 1.5776260960675863, Validation Loss Force: 1.967447236112857, time: 0.0963444709777832
Test Loss Energy: 11.118553185423615, Test Loss Force: 8.971373548611625, time: 9.428661584854126

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–â–…â–…â–‚â–„â–â–ˆâ–ƒâ–â–‚â–…â–‚
wandb:   test_error_force â–†â–†â–†â–‚â–…â–‚â–†â–ˆâ–ƒâ–‡â–‡â–‚â–…â–‚â–‡â–…â–â–â–…â–‚
wandb:          test_loss â–„â–…â–†â–ƒâ–ƒâ–ƒâ–†â–‡â–‚â–‡â–ˆâ–„â–…â–ƒâ–ˆâ–ƒâ–â–‚â–†â–„
wandb: train_error_energy â–ˆâ–â–‚â–‚â–â–‚â–ƒâ–â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–†â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–„â–ƒâ–„â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–…â–‚â–
wandb: valid_error_energy â–‚â–â–â–â–‚â–ƒâ–„â–â–…â–ƒâ–„â–ƒâ–‚â–‡â–‡â–‚â–ˆâ–ƒâ–ƒâ–‚
wandb:  valid_error_force â–„â–‚â–â–…â–‚â–„â–ˆâ–‡â–„â–„â–„â–‚â–„â–…â–†â–‚â–ƒâ–ƒâ–‡â–‚
wandb:         valid_loss â–ƒâ–â–â–ƒâ–‚â–„â–‡â–„â–†â–„â–…â–ƒâ–ƒâ–ˆâ–ˆâ–‚â–‡â–ƒâ–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3119
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.11855
wandb:   test_error_force 8.97137
wandb:          test_loss 7.09301
wandb: train_error_energy 1.3734
wandb:  train_error_force 1.88205
wandb:         train_loss -2.58773
wandb: valid_error_energy 1.57763
wandb:  valid_error_force 1.96745
wandb:         valid_loss -2.46054
wandb: 
wandb: ğŸš€ View run al_59_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qgrucfae
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_012338-qgrucfae/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 26.05010414123535, Uncertainty Bias: -3.147369623184204
1.5258789e-05 0.034520626
0.7211024 3.4691105
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1449 steps.
Found uncertainty sample 1 after 678 steps.
Found uncertainty sample 2 after 3332 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3889 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2728 steps.
Found uncertainty sample 9 after 3855 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1535 steps.
Found uncertainty sample 12 after 1611 steps.
Found uncertainty sample 13 after 1394 steps.
Found uncertainty sample 14 after 1349 steps.
Found uncertainty sample 15 after 226 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2778 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1476 steps.
Found uncertainty sample 23 after 463 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1169 steps.
Found uncertainty sample 27 after 3753 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3517 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 252 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2038 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2954 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 96 steps.
Found uncertainty sample 46 after 3716 steps.
Found uncertainty sample 47 after 1444 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 914 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 698 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1561 steps.
Found uncertainty sample 57 after 1072 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3476 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3315 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 319 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2708 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1250 steps.
Found uncertainty sample 79 after 548 steps.
Found uncertainty sample 80 after 1178 steps.
Found uncertainty sample 81 after 704 steps.
Found uncertainty sample 82 after 1012 steps.
Found uncertainty sample 83 after 3946 steps.
Found uncertainty sample 84 after 1173 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3802 steps.
Found uncertainty sample 87 after 981 steps.
Found uncertainty sample 88 after 1826 steps.
Found uncertainty sample 89 after 1876 steps.
Found uncertainty sample 90 after 3343 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3266 steps.
Found uncertainty sample 94 after 1438 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 456 steps.
Found uncertainty sample 99 after 2137 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_015741-63p72a4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/63p72a4i
Training model 32. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8092877572877897, Training Loss Force: 2.0073132812317134, time: 1.4443984031677246
Validation Loss Energy: 0.8044883714006015, Validation Loss Force: 1.94353435119338, time: 0.09890079498291016
Test Loss Energy: 11.762420620421883, Test Loss Force: 9.062315255800064, time: 9.378237009048462


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8127601781269258, Training Loss Force: 1.9369097225574738, time: 1.4649591445922852
Validation Loss Energy: 1.9209233571028563, Validation Loss Force: 2.0703418691040767, time: 0.09712457656860352
Test Loss Energy: 13.261812572205983, Test Loss Force: 9.089727734924102, time: 9.901212215423584


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3956400639453537, Training Loss Force: 1.8936433857538946, time: 1.4373505115509033
Validation Loss Energy: 0.8380848591400455, Validation Loss Force: 2.0566607427745547, time: 0.09864258766174316
Test Loss Energy: 11.463693644524334, Test Loss Force: 8.924979837495977, time: 9.621742010116577


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.090200482494945, Training Loss Force: 1.96084636784925, time: 1.4467194080352783
Validation Loss Energy: 1.696727981181593, Validation Loss Force: 1.9597864154817843, time: 0.09967470169067383
Test Loss Energy: 12.729508320270247, Test Loss Force: 8.996606994468458, time: 9.47392201423645


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9556600137695863, Training Loss Force: 1.8812385483622063, time: 1.47812819480896
Validation Loss Energy: 1.4028606541798272, Validation Loss Force: 1.9664486763279436, time: 0.09829306602478027
Test Loss Energy: 11.164424885449561, Test Loss Force: 8.959193182597575, time: 9.455085515975952


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9520372413080358, Training Loss Force: 1.8826247470153887, time: 1.4411554336547852
Validation Loss Energy: 1.4133484266203125, Validation Loss Force: 1.991998068135417, time: 0.1066892147064209
Test Loss Energy: 12.740934222595927, Test Loss Force: 9.0498838169172, time: 9.603567600250244


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.127452110597282, Training Loss Force: 1.9241246877204392, time: 1.4540634155273438
Validation Loss Energy: 2.706759346489238, Validation Loss Force: 2.010231887822579, time: 0.09855270385742188
Test Loss Energy: 10.662878685078637, Test Loss Force: 8.924608206188845, time: 9.416860580444336


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3044538132377588, Training Loss Force: 1.90026841024606, time: 1.4452109336853027
Validation Loss Energy: 1.0210918984587434, Validation Loss Force: 1.9630785231370402, time: 0.0993967056274414
Test Loss Energy: 11.396152063010385, Test Loss Force: 8.959907430606064, time: 9.71097207069397


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4760188095615605, Training Loss Force: 1.891041450675471, time: 1.4587969779968262
Validation Loss Energy: 2.8231462823742337, Validation Loss Force: 2.024318940005127, time: 0.09829902648925781
Test Loss Energy: 13.36789120202743, Test Loss Force: 9.08788596497229, time: 9.425832986831665


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4087875737879847, Training Loss Force: 1.8913324646295073, time: 1.441715955734253
Validation Loss Energy: 2.3673064682584117, Validation Loss Force: 2.191087664855182, time: 0.09813427925109863
Test Loss Energy: 13.448140164288972, Test Loss Force: 9.096446490779746, time: 9.413596391677856


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.5927610865573376, Training Loss Force: 2.036019323068374, time: 1.5244081020355225
Validation Loss Energy: 4.497521064669001, Validation Loss Force: 2.254449172340091, time: 0.09791827201843262
Test Loss Energy: 14.936839618297268, Test Loss Force: 8.993925283855608, time: 9.618517637252808


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.2909546576447877, Training Loss Force: 1.9028383799315352, time: 1.4887168407440186
Validation Loss Energy: 1.0251619007752981, Validation Loss Force: 2.0505246491202227, time: 0.0971369743347168
Test Loss Energy: 11.85168052037501, Test Loss Force: 8.972798556533913, time: 9.421977043151855


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9293031347962386, Training Loss Force: 1.9110609307160598, time: 1.5167646408081055
Validation Loss Energy: 2.2832326108230188, Validation Loss Force: 2.0241588408892053, time: 0.09748673439025879
Test Loss Energy: 10.924424245745236, Test Loss Force: 8.917167400743958, time: 9.468976497650146


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6760602724587967, Training Loss Force: 1.8805085792984981, time: 1.4664077758789062
Validation Loss Energy: 1.2581419641744178, Validation Loss Force: 1.9458289567421658, time: 0.09693741798400879
Test Loss Energy: 11.952371923190862, Test Loss Force: 8.985715106381837, time: 9.681416988372803


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.431783981742206, Training Loss Force: 1.9102320009612692, time: 1.435136079788208
Validation Loss Energy: 1.2314808409886138, Validation Loss Force: 1.9468560181777579, time: 0.09866952896118164
Test Loss Energy: 11.163165991041751, Test Loss Force: 9.044105620197183, time: 9.972397804260254


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9170175035567414, Training Loss Force: 1.908523363889684, time: 1.4426910877227783
Validation Loss Energy: 1.7557910278062252, Validation Loss Force: 2.0195077277690654, time: 0.11188530921936035
Test Loss Energy: 10.852898873054393, Test Loss Force: 8.906830338883795, time: 9.429527997970581


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.386846559106696, Training Loss Force: 1.8760742807001765, time: 1.4302520751953125
Validation Loss Energy: 0.7694521327972315, Validation Loss Force: 1.93195911831147, time: 0.1031796932220459
Test Loss Energy: 11.620247289402945, Test Loss Force: 8.957997148505727, time: 9.622310638427734


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2412611760736083, Training Loss Force: 1.897523647530215, time: 1.4419207572937012
Validation Loss Energy: 4.111759016152135, Validation Loss Force: 2.0646683706004096, time: 0.10069847106933594
Test Loss Energy: 14.457309012499216, Test Loss Force: 8.923581288730423, time: 9.471375942230225


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7554753268163736, Training Loss Force: 1.9301776718029409, time: 1.4382479190826416
Validation Loss Energy: 4.01731790595149, Validation Loss Force: 2.0570931662559464, time: 0.0971827507019043
Test Loss Energy: 14.905326058480973, Test Loss Force: 9.064074999568067, time: 9.655728340148926


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4978793903556937, Training Loss Force: 1.887220698915287, time: 1.4527442455291748
Validation Loss Energy: 1.7647983844300095, Validation Loss Force: 2.0298110744894364, time: 0.09824466705322266
Test Loss Energy: 10.967873762459845, Test Loss Force: 8.895306023790459, time: 9.477261781692505

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–‚â–„â–‚â–„â–â–‚â–…â–†â–ˆâ–ƒâ–â–ƒâ–‚â–â–ƒâ–‡â–ˆâ–
wandb:   test_error_force â–‡â–ˆâ–‚â–…â–ƒâ–†â–‚â–ƒâ–ˆâ–ˆâ–„â–„â–‚â–„â–†â–â–ƒâ–‚â–‡â–
wandb:          test_loss â–„â–…â–„â–…â–„â–‡â–â–„â–‡â–ˆâ–„â–…â–ƒâ–†â–…â–ƒâ–†â–†â–ˆâ–„
wandb: train_error_energy â–‡â–‚â–â–ƒâ–ƒâ–ƒâ–ˆâ–â–â–â–„â–â–ƒâ–‚â–â–ƒâ–â–ƒâ–‚â–‚
wandb:  train_error_force â–‡â–„â–‚â–…â–â–â–ƒâ–‚â–‚â–‚â–ˆâ–‚â–ƒâ–â–‚â–‚â–â–‚â–ƒâ–
wandb:         train_loss â–ˆâ–ƒâ–‚â–„â–‚â–‚â–†â–‚â–‚â–â–‡â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–ƒâ–
wandb: valid_error_energy â–â–ƒâ–â–ƒâ–‚â–‚â–…â–â–…â–„â–ˆâ–â–„â–‚â–‚â–ƒâ–â–‡â–‡â–ƒ
wandb:  valid_error_force â–â–„â–„â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‡â–ˆâ–„â–ƒâ–â–â–ƒâ–â–„â–„â–ƒ
wandb:         valid_loss â–â–„â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–†â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–…â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3161
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 10.96787
wandb:   test_error_force 8.89531
wandb:          test_loss 7.0513
wandb: train_error_energy 1.49788
wandb:  train_error_force 1.88722
wandb:         train_loss -2.57244
wandb: valid_error_energy 1.7648
wandb:  valid_error_force 2.02981
wandb:         valid_loss -2.36381
wandb: 
wandb: ğŸš€ View run al_59_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/63p72a4i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_015741-63p72a4i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.730295181274414, Uncertainty Bias: -2.8333444595336914
3.0517578e-05 0.024629593
0.8521067 3.4041018
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 600 steps.
Found uncertainty sample 1 after 2478 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1544 steps.
Found uncertainty sample 6 after 1124 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 7 steps.
Found uncertainty sample 9 after 2802 steps.
Found uncertainty sample 10 after 1866 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2549 steps.
Found uncertainty sample 13 after 968 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 133 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 835 steps.
Found uncertainty sample 19 after 2758 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2182 steps.
Found uncertainty sample 22 after 1152 steps.
Found uncertainty sample 23 after 541 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 449 steps.
Found uncertainty sample 26 after 2358 steps.
Found uncertainty sample 27 after 2872 steps.
Found uncertainty sample 28 after 1389 steps.
Found uncertainty sample 29 after 3611 steps.
Found uncertainty sample 30 after 974 steps.
Found uncertainty sample 31 after 2824 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1155 steps.
Found uncertainty sample 35 after 319 steps.
Found uncertainty sample 36 after 3457 steps.
Found uncertainty sample 37 after 1187 steps.
Found uncertainty sample 38 after 1976 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1262 steps.
Found uncertainty sample 42 after 3558 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2241 steps.
Found uncertainty sample 45 after 3395 steps.
Found uncertainty sample 46 after 1402 steps.
Found uncertainty sample 47 after 2216 steps.
Found uncertainty sample 48 after 565 steps.
Found uncertainty sample 49 after 586 steps.
Found uncertainty sample 50 after 1363 steps.
Found uncertainty sample 51 after 1392 steps.
Found uncertainty sample 52 after 2652 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1747 steps.
Found uncertainty sample 55 after 2299 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 197 steps.
Found uncertainty sample 59 after 309 steps.
Found uncertainty sample 60 after 422 steps.
Found uncertainty sample 61 after 1302 steps.
Found uncertainty sample 62 after 547 steps.
Found uncertainty sample 63 after 3084 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 274 steps.
Found uncertainty sample 66 after 1765 steps.
Found uncertainty sample 67 after 1105 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3747 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 455 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1618 steps.
Found uncertainty sample 78 after 3160 steps.
Found uncertainty sample 79 after 891 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 834 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 53 steps.
Found uncertainty sample 84 after 2921 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3506 steps.
Found uncertainty sample 87 after 1820 steps.
Found uncertainty sample 88 after 3031 steps.
Found uncertainty sample 89 after 2072 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 725 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 440 steps.
Found uncertainty sample 94 after 131 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1690 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_022648-wmbq1o8h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wmbq1o8h
Training model 33. Added 65 samples to the dataset.
Epoch 0, Batch 100/101, Loss: 0.1557995080947876, Uncertainty: 0.12893250584602356

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4248707101223212, Training Loss Force: 2.1037861784659557, time: 1.4512436389923096
Validation Loss Energy: 1.049650107100566, Validation Loss Force: 2.0280536582552013, time: 0.10038471221923828
Test Loss Energy: 11.85105639857769, Test Loss Force: 8.950837563699883, time: 9.538941621780396

Epoch 1, Batch 100/101, Loss: 0.06263402104377747, Uncertainty: 0.12726780772209167

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6274300222223206, Training Loss Force: 1.9151402618376538, time: 1.4773039817810059
Validation Loss Energy: 1.894087939643077, Validation Loss Force: 2.002100455951588, time: 0.09997415542602539
Test Loss Energy: 12.828148975226318, Test Loss Force: 9.012877981553942, time: 9.475895881652832

Epoch 2, Batch 100/101, Loss: 0.06977195292711258, Uncertainty: 0.1265261173248291

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.776450319667596, Training Loss Force: 1.8833765875382755, time: 1.5094516277313232
Validation Loss Energy: 1.995161751360759, Validation Loss Force: 2.00518074958178, time: 0.10378217697143555
Test Loss Energy: 12.497991253781837, Test Loss Force: 8.931537021821399, time: 9.729989528656006

Epoch 3, Batch 100/101, Loss: 0.04073703661561012, Uncertainty: 0.12738683819770813

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6963472907976642, Training Loss Force: 1.91897408769947, time: 1.5360746383666992
Validation Loss Energy: 0.7812509811689397, Validation Loss Force: 1.9254979833713697, time: 0.11086750030517578
Test Loss Energy: 11.403105020175266, Test Loss Force: 8.920438473451219, time: 9.487996339797974

Epoch 4, Batch 100/101, Loss: 0.25825971364974976, Uncertainty: 0.12757515907287598

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.079144152404913, Training Loss Force: 1.909065773681136, time: 1.6281816959381104
Validation Loss Energy: 1.920757691258286, Validation Loss Force: 2.0098551316276687, time: 0.10042047500610352
Test Loss Energy: 12.816121945481513, Test Loss Force: 8.819142692946192, time: 9.5421462059021

Epoch 5, Batch 100/101, Loss: 0.12546180188655853, Uncertainty: 0.12636688351631165

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2696751743178083, Training Loss Force: 1.9016358841031635, time: 1.4885025024414062
Validation Loss Energy: 1.2441449816613972, Validation Loss Force: 1.9662256731782972, time: 0.10067129135131836
Test Loss Energy: 11.835172729898964, Test Loss Force: 8.860426727734708, time: 9.690309524536133

Epoch 6, Batch 100/101, Loss: 0.09095731377601624, Uncertainty: 0.12625855207443237

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4811346913618169, Training Loss Force: 1.9059613722577686, time: 1.521369218826294
Validation Loss Energy: 1.1067685284065243, Validation Loss Force: 1.9087927317037157, time: 0.10037040710449219
Test Loss Energy: 10.961112384698573, Test Loss Force: 8.856759373896118, time: 9.56794023513794

Epoch 7, Batch 100/101, Loss: 0.16334182024002075, Uncertainty: 0.12656281888484955

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5332365236944954, Training Loss Force: 1.9021848980312206, time: 1.4947900772094727
Validation Loss Energy: 1.4710259144844091, Validation Loss Force: 2.0262338946601064, time: 0.10412859916687012
Test Loss Energy: 12.359237500635, Test Loss Force: 9.006778050068391, time: 10.191230058670044

Epoch 8, Batch 100/101, Loss: 0.04959144443273544, Uncertainty: 0.12670378386974335

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7371780990167673, Training Loss Force: 1.8922660094330994, time: 1.4681904315948486
Validation Loss Energy: 0.8832057276951985, Validation Loss Force: 1.958957863589787, time: 0.10058450698852539
Test Loss Energy: 11.803226021469289, Test Loss Force: 8.894616005915633, time: 9.593727827072144

Epoch 9, Batch 100/101, Loss: 0.12396712601184845, Uncertainty: 0.1265106350183487

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.19111119723601, Training Loss Force: 1.8963491100968148, time: 1.491286277770996
Validation Loss Energy: 0.8398887853921362, Validation Loss Force: 1.9314291100768752, time: 0.10219740867614746
Test Loss Energy: 11.34080872632736, Test Loss Force: 8.820831686216142, time: 9.536335229873657

Epoch 10, Batch 100/101, Loss: 0.2987578511238098, Uncertainty: 0.12694303691387177

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5430374150068547, Training Loss Force: 1.8855816415091107, time: 1.5096397399902344
Validation Loss Energy: 1.1529598510470818, Validation Loss Force: 2.0816200613453195, time: 0.10327410697937012
Test Loss Energy: 11.16233626285044, Test Loss Force: 8.886874781321257, time: 9.825384378433228

Epoch 11, Batch 100/101, Loss: 0.2425275444984436, Uncertainty: 0.12579743564128876

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3582327423196643, Training Loss Force: 1.9038968070854985, time: 1.54170560836792
Validation Loss Energy: 0.8464640104358812, Validation Loss Force: 1.996734797542166, time: 0.10848474502563477
Test Loss Energy: 11.572271480197076, Test Loss Force: 8.986201383153947, time: 9.621699810028076

Epoch 12, Batch 100/101, Loss: 0.06494784355163574, Uncertainty: 0.12566007673740387

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.487336071168806, Training Loss Force: 1.890455834941472, time: 1.4660329818725586
Validation Loss Energy: 2.0947802532079436, Validation Loss Force: 1.9730533771998808, time: 0.10042524337768555
Test Loss Energy: 12.697165451953179, Test Loss Force: 8.935946215989656, time: 9.51541256904602

Epoch 13, Batch 100/101, Loss: 0.06783026456832886, Uncertainty: 0.1261175125837326

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6928249779686777, Training Loss Force: 1.8860547241560843, time: 1.489081859588623
Validation Loss Energy: 5.3441554726688025, Validation Loss Force: 1.9659929839208026, time: 0.10061216354370117
Test Loss Energy: 15.291955547881303, Test Loss Force: 8.860817371023158, time: 9.842620372772217

Epoch 14, Batch 100/101, Loss: 0.12822283804416656, Uncertainty: 0.12674668431282043

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6965962580515839, Training Loss Force: 1.916711569656471, time: 1.49403715133667
Validation Loss Energy: 1.1135877153332763, Validation Loss Force: 1.973265914899669, time: 0.10839962959289551
Test Loss Energy: 12.179686106052463, Test Loss Force: 8.98730100966626, time: 9.604769706726074

Epoch 15, Batch 100/101, Loss: 0.06983941793441772, Uncertainty: 0.12538671493530273

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4073589561892839, Training Loss Force: 1.8773313693512217, time: 1.4870579242706299
Validation Loss Energy: 1.9781997065005639, Validation Loss Force: 2.079040884628038, time: 0.1020820140838623
Test Loss Energy: 10.65674237575, Test Loss Force: 8.788542029995916, time: 9.743157625198364

Epoch 16, Batch 100/101, Loss: 0.11631173640489578, Uncertainty: 0.1266726851463318

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7359258115981986, Training Loss Force: 1.915704704973808, time: 1.500917911529541
Validation Loss Energy: 3.058341569771616, Validation Loss Force: 2.070375826148831, time: 0.10026860237121582
Test Loss Energy: 10.54712855730324, Test Loss Force: 8.931158143857665, time: 9.611914157867432

Epoch 17, Batch 100/101, Loss: 0.14812271296977997, Uncertainty: 0.1262173056602478

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.841200130971657, Training Loss Force: 1.9120594953111074, time: 1.5161948204040527
Validation Loss Energy: 1.0494944613675623, Validation Loss Force: 1.9240104978092856, time: 0.10259222984313965
Test Loss Energy: 11.161482365147439, Test Loss Force: 8.934223945923362, time: 9.640543222427368

Epoch 18, Batch 100/101, Loss: 0.13183599710464478, Uncertainty: 0.12653866410255432

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6418587012350407, Training Loss Force: 1.8936869780994499, time: 1.4958775043487549
Validation Loss Energy: 2.187259759567537, Validation Loss Force: 1.9804280679784363, time: 0.10715818405151367
Test Loss Energy: 10.604887721317581, Test Loss Force: 8.837307319070613, time: 9.823811054229736

Epoch 19, Batch 100/101, Loss: 0.14965346455574036, Uncertainty: 0.12607544660568237

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.637850002379934, Training Loss Force: 1.8785299091779502, time: 1.4906764030456543
Validation Loss Energy: 1.969297282711798, Validation Loss Force: 2.024017334646968, time: 0.1002197265625
Test Loss Energy: 12.471311871434617, Test Loss Force: 8.935130911163132, time: 9.525575160980225

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–„â–‚â–„â–ƒâ–‚â–„â–ƒâ–‚â–‚â–ƒâ–„â–ˆâ–ƒâ–â–â–‚â–â–„
wandb:   test_error_force â–†â–ˆâ–…â–…â–‚â–ƒâ–ƒâ–ˆâ–„â–‚â–„â–‡â–†â–ƒâ–‡â–â–…â–†â–ƒâ–†
wandb:          test_loss â–‚â–‡â–†â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–‚â–„â–‡â–‡â–ˆâ–†â–‚â–ƒâ–ƒâ–â–‡
wandb: train_error_energy â–ˆâ–ƒâ–„â–„â–†â–â–‚â–ƒâ–„â–‡â–ƒâ–‚â–‚â–„â–„â–‚â–„â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–â–ƒâ–ƒâ–â–ƒâ–‚â–â–‚â–â–â–‚â–â–ƒâ–ˆâ–‚â–ƒâ–„â–â–ƒâ–ƒ
wandb:  valid_error_force â–†â–…â–…â–‚â–…â–ƒâ–â–†â–ƒâ–‚â–ˆâ–…â–„â–ƒâ–„â–ˆâ–ˆâ–‚â–„â–†
wandb:         valid_loss â–„â–„â–…â–â–…â–ƒâ–â–…â–‚â–â–†â–ƒâ–„â–ˆâ–ƒâ–‡â–ˆâ–â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3219
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 12.47131
wandb:   test_error_force 8.93513
wandb:          test_loss 7.17729
wandb: train_error_energy 1.63785
wandb:  train_error_force 1.87853
wandb:         train_loss -2.57458
wandb: valid_error_energy 1.9693
wandb:  valid_error_force 2.02402
wandb:         valid_loss -2.35862
wandb: 
wandb: ğŸš€ View run al_59_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wmbq1o8h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_022648-wmbq1o8h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 25.563493728637695, Uncertainty Bias: -3.076259136199951
1.5258789e-05 0.030624628
0.7380752 3.4723668
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1934 steps.
Found uncertainty sample 1 after 988 steps.
Found uncertainty sample 2 after 897 steps.
Found uncertainty sample 3 after 1270 steps.
Found uncertainty sample 4 after 3323 steps.
Found uncertainty sample 5 after 2128 steps.
Found uncertainty sample 6 after 2470 steps.
Found uncertainty sample 7 after 3450 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 514 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 543 steps.
Found uncertainty sample 16 after 2311 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1832 steps.
Found uncertainty sample 19 after 831 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 792 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1262 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 356 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1212 steps.
Found uncertainty sample 37 after 113 steps.
Found uncertainty sample 38 after 225 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 696 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 141 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3008 steps.
Found uncertainty sample 47 after 82 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1060 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1581 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3630 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3571 steps.
Found uncertainty sample 59 after 2964 steps.
Found uncertainty sample 60 after 1517 steps.
Found uncertainty sample 61 after 3867 steps.
Found uncertainty sample 62 after 3069 steps.
Found uncertainty sample 63 after 2893 steps.
Found uncertainty sample 64 after 44 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 393 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 11 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 326 steps.
Found uncertainty sample 74 after 2007 steps.
Found uncertainty sample 75 after 1982 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 549 steps.
Found uncertainty sample 80 after 2522 steps.
Found uncertainty sample 81 after 2629 steps.
Found uncertainty sample 82 after 117 steps.
Found uncertainty sample 83 after 342 steps.
Found uncertainty sample 84 after 2037 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1272 steps.
Found uncertainty sample 88 after 707 steps.
Found uncertainty sample 89 after 1800 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 472 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 461 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 716 steps.
Found uncertainty sample 97 after 354 steps.
Found uncertainty sample 98 after 1386 steps.
Found uncertainty sample 99 after 1624 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_025736-1xvnul5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1xvnul5a
Training model 34. Added 53 samples to the dataset.
Epoch 0, Batch 100/103, Loss: 0.15163803100585938, Uncertainty: 0.1289392113685608

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7612197743071425, Training Loss Force: 2.035573212607874, time: 1.4652092456817627
Validation Loss Energy: 1.1696214038948474, Validation Loss Force: 2.0567118453435453, time: 0.10075664520263672
Test Loss Energy: 12.188361048826716, Test Loss Force: 8.960170334084786, time: 9.533552169799805

Epoch 1, Batch 100/103, Loss: 0.13646718859672546, Uncertainty: 0.1282847374677658

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5438319154182356, Training Loss Force: 1.916166148079732, time: 1.4939892292022705
Validation Loss Energy: 0.8026012225552202, Validation Loss Force: 2.159885260105467, time: 0.10108661651611328
Test Loss Energy: 11.15350745686216, Test Loss Force: 8.821411325479783, time: 9.572479009628296

Epoch 2, Batch 100/103, Loss: 0.10091447085142136, Uncertainty: 0.12801524996757507

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5155667285632726, Training Loss Force: 1.9209847808191274, time: 1.5044925212860107
Validation Loss Energy: 0.7735525851194918, Validation Loss Force: 1.9895541629242866, time: 0.1024174690246582
Test Loss Energy: 11.475708946250247, Test Loss Force: 8.83027069892883, time: 10.309091329574585

Epoch 3, Batch 100/103, Loss: 0.05165758728981018, Uncertainty: 0.1257486790418625

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5003488857125113, Training Loss Force: 1.8963109111224241, time: 1.511279821395874
Validation Loss Energy: 0.8834566479890158, Validation Loss Force: 2.133141025660945, time: 0.10137295722961426
Test Loss Energy: 11.653250358913812, Test Loss Force: 8.987772336128803, time: 9.55788540840149

Epoch 4, Batch 100/103, Loss: 0.050600603222846985, Uncertainty: 0.12679505348205566

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2567410423237313, Training Loss Force: 1.8993585167058107, time: 1.573850154876709
Validation Loss Energy: 0.9978614944715349, Validation Loss Force: 2.012262407764294, time: 0.10428690910339355
Test Loss Energy: 11.231389252578516, Test Loss Force: 8.881084464871183, time: 9.606430053710938

Epoch 5, Batch 100/103, Loss: 0.05193094164133072, Uncertainty: 0.1259840875864029

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.1400625963159572, Training Loss Force: 1.8777585318753856, time: 1.7400670051574707
Validation Loss Energy: 0.9818329621719989, Validation Loss Force: 2.016676378244021, time: 0.10157656669616699
Test Loss Energy: 11.398068192798867, Test Loss Force: 8.985453079590012, time: 9.56633710861206

Epoch 6, Batch 100/103, Loss: 0.14466296136379242, Uncertainty: 0.12769292294979095

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6958881272090625, Training Loss Force: 1.9188703567652068, time: 1.5062155723571777
Validation Loss Energy: 0.8325412045820976, Validation Loss Force: 1.921363295667923, time: 0.10282254219055176
Test Loss Energy: 11.004402237143287, Test Loss Force: 8.881980546136361, time: 9.544613122940063

Epoch 7, Batch 100/103, Loss: 0.15810461342334747, Uncertainty: 0.12677839398384094

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.239013576057623, Training Loss Force: 1.9139213879920887, time: 1.4808990955352783
Validation Loss Energy: 2.8684286138938275, Validation Loss Force: 2.1536972845401334, time: 0.10070586204528809
Test Loss Energy: 13.645412660699844, Test Loss Force: 8.960725962386492, time: 9.779974222183228

Epoch 8, Batch 100/103, Loss: 0.058974720537662506, Uncertainty: 0.12532825767993927

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3780802648602106, Training Loss Force: 1.8897690040305568, time: 1.5239002704620361
Validation Loss Energy: 0.8502111146571971, Validation Loss Force: 1.95905639468686, time: 0.1096498966217041
Test Loss Energy: 11.622883780692064, Test Loss Force: 8.851028355055666, time: 9.613152027130127

Epoch 9, Batch 100/103, Loss: 0.13837292790412903, Uncertainty: 0.12619219720363617

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.0792828619138086, Training Loss Force: 1.8960705311320498, time: 1.4975392818450928
Validation Loss Energy: 0.7580551744002798, Validation Loss Force: 1.9317076135111444, time: 0.10020613670349121
Test Loss Energy: 11.066632140611496, Test Loss Force: 8.768535004383878, time: 9.508724927902222

Epoch 10, Batch 100/103, Loss: 0.07743214070796967, Uncertainty: 0.12654319405555725

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.1848048031525567, Training Loss Force: 1.9038201805385746, time: 1.5208771228790283
Validation Loss Energy: 1.4148464889668282, Validation Loss Force: 2.0851512599960156, time: 0.10231399536132812
Test Loss Energy: 10.799377403665277, Test Loss Force: 8.7752701514866, time: 9.771065950393677

Epoch 11, Batch 100/103, Loss: 0.13621845841407776, Uncertainty: 0.1244480311870575

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3900812379063805, Training Loss Force: 1.8760885824596913, time: 1.6397838592529297
Validation Loss Energy: 2.6959808238114578, Validation Loss Force: 1.9646603090824248, time: 0.10600113868713379
Test Loss Energy: 10.537840773080655, Test Loss Force: 8.739398842235405, time: 9.556780576705933

Epoch 12, Batch 100/103, Loss: 0.04445381462574005, Uncertainty: 0.12424252927303314

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5526359443056197, Training Loss Force: 1.873882031748938, time: 1.605055332183838
Validation Loss Energy: 1.4587201041347098, Validation Loss Force: 2.0117915738552297, time: 0.10205984115600586
Test Loss Energy: 10.788054917751099, Test Loss Force: 8.83801989298018, time: 9.593482494354248

Epoch 13, Batch 100/103, Loss: 0.07699573040008545, Uncertainty: 0.12591123580932617

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3471747359111406, Training Loss Force: 1.8888447335906018, time: 1.5049433708190918
Validation Loss Energy: 2.382083794793336, Validation Loss Force: 2.119255266386315, time: 0.10488295555114746
Test Loss Energy: 10.579296615185262, Test Loss Force: 8.798412750384468, time: 10.271539211273193

Epoch 14, Batch 100/103, Loss: 0.15754981338977814, Uncertainty: 0.12459922581911087

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2273799081982208, Training Loss Force: 1.8711474060257622, time: 1.477625846862793
Validation Loss Energy: 4.259166881432914, Validation Loss Force: 2.031429990514904, time: 0.10306668281555176
Test Loss Energy: 14.649856842691754, Test Loss Force: 8.92406607793274, time: 9.615179300308228

Epoch 15, Batch 100/103, Loss: 0.15882420539855957, Uncertainty: 0.12456157058477402

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8912119346855512, Training Loss Force: 1.8743528721435112, time: 1.5376403331756592
Validation Loss Energy: 2.438784377446961, Validation Loss Force: 1.9130344675990671, time: 0.10424160957336426
Test Loss Energy: 13.321832077534197, Test Loss Force: 8.835506921279274, time: 9.75296401977539

Epoch 16, Batch 100/103, Loss: 0.08325879275798798, Uncertainty: 0.1244695633649826

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8725334393093807, Training Loss Force: 1.8722035906399888, time: 1.4900414943695068
Validation Loss Energy: 0.7687462437709971, Validation Loss Force: 1.996829654598331, time: 0.10350489616394043
Test Loss Energy: 11.65301736071745, Test Loss Force: 8.784846099894999, time: 9.591635942459106

Epoch 17, Batch 100/103, Loss: 0.1340710073709488, Uncertainty: 0.12430250644683838

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.837783909660445, Training Loss Force: 1.8618420170188763, time: 1.504019021987915
Validation Loss Energy: 3.370703517697711, Validation Loss Force: 2.035688537930773, time: 0.10467004776000977
Test Loss Energy: 10.410021767750704, Test Loss Force: 8.792797207063613, time: 9.628139972686768

Epoch 18, Batch 100/103, Loss: 0.24288010597229004, Uncertainty: 0.12522943317890167

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.689016675185813, Training Loss Force: 1.8905411449643614, time: 1.487941026687622
Validation Loss Energy: 2.0941577816105026, Validation Loss Force: 1.9538831224195197, time: 0.10460805892944336
Test Loss Energy: 10.771348002768242, Test Loss Force: 8.764416543840166, time: 9.781215190887451

Epoch 19, Batch 100/103, Loss: 0.0449756495654583, Uncertainty: 0.12528502941131592

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.935372677933893, Training Loss Force: 1.8813345216137944, time: 1.5939161777496338
Validation Loss Energy: 2.3091086582675686, Validation Loss Force: 2.0069583173737215, time: 0.10550045967102051
Test Loss Energy: 10.66297150197247, Test Loss Force: 8.754377606821226, time: 9.622154712677002

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–†â–ƒâ–‚â–‚â–â–‚â–â–ˆâ–†â–ƒâ–â–‚â–
wandb:   test_error_force â–‡â–ƒâ–„â–ˆâ–…â–ˆâ–…â–‡â–„â–‚â–‚â–â–„â–ƒâ–†â–„â–‚â–ƒâ–‚â–
wandb:          test_loss â–ƒâ–â–â–†â–„â–†â–‚â–…â–„â–‚â–‚â–ƒâ–…â–‚â–ˆâ–†â–„â–„â–‚â–‚
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–„â–‚â–‚â–â–â–‚â–ƒâ–‚â–‚â–„â–„â–„â–„â–…
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–â–â–â–â–â–â–…â–â–â–‚â–…â–‚â–„â–ˆâ–„â–â–†â–„â–„
wandb:  valid_error_force â–…â–ˆâ–ƒâ–‡â–„â–„â–â–ˆâ–‚â–‚â–†â–‚â–„â–‡â–„â–â–ƒâ–„â–‚â–„
wandb:         valid_loss â–„â–†â–‚â–†â–ƒâ–ƒâ–â–ˆâ–‚â–â–…â–„â–„â–‡â–‡â–ƒâ–ƒâ–†â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3266
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 10.66297
wandb:   test_error_force 8.75438
wandb:          test_loss 6.87997
wandb: train_error_energy 1.93537
wandb:  train_error_force 1.88133
wandb:         train_loss -2.55099
wandb: valid_error_energy 2.30911
wandb:  valid_error_force 2.00696
wandb:         valid_loss -2.35739
wandb: 
wandb: ğŸš€ View run al_59_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1xvnul5a
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_025736-1xvnul5a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 24.670551300048828, Uncertainty Bias: -2.944234609603882
3.33786e-06 0.040996075
0.82370836 3.42841
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2622 steps.
Found uncertainty sample 1 after 3373 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2019 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 443 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 522 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1360 steps.
Found uncertainty sample 15 after 1869 steps.
Found uncertainty sample 16 after 14 steps.
Found uncertainty sample 17 after 36 steps.
Found uncertainty sample 18 after 2030 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1381 steps.
Found uncertainty sample 21 after 3839 steps.
Found uncertainty sample 22 after 2415 steps.
Found uncertainty sample 23 after 585 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 733 steps.
Found uncertainty sample 27 after 2831 steps.
Found uncertainty sample 28 after 2287 steps.
Found uncertainty sample 29 after 1680 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1688 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1598 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2347 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3124 steps.
Found uncertainty sample 42 after 1580 steps.
Found uncertainty sample 43 after 2854 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 214 steps.
Found uncertainty sample 47 after 624 steps.
Found uncertainty sample 48 after 2242 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 68 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1902 steps.
Found uncertainty sample 55 after 1294 steps.
Found uncertainty sample 56 after 1034 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3242 steps.
Found uncertainty sample 60 after 23 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 468 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 301 steps.
Found uncertainty sample 65 after 1556 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2403 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 818 steps.
Found uncertainty sample 73 after 3551 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 368 steps.
Found uncertainty sample 76 after 955 steps.
Found uncertainty sample 77 after 506 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 864 steps.
Found uncertainty sample 81 after 3542 steps.
Found uncertainty sample 82 after 1799 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2486 steps.
Found uncertainty sample 87 after 1429 steps.
Found uncertainty sample 88 after 557 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 926 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 700 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_032931-2eocn2gt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2eocn2gt
Training model 35. Added 51 samples to the dataset.
Epoch 0, Batch 100/104, Loss: 0.07369857281446457, Uncertainty: 0.1268044114112854

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.533295214135499, Training Loss Force: 2.009713782752569, time: 1.5303959846496582
Validation Loss Energy: 1.1221862514051373, Validation Loss Force: 1.944114626987668, time: 0.10087943077087402
Test Loss Energy: 11.895115333931145, Test Loss Force: 8.864959460144092, time: 9.353520631790161

Epoch 1, Batch 100/104, Loss: 0.057656917721033096, Uncertainty: 0.12580406665802002

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4833984586700903, Training Loss Force: 1.903918584388712, time: 1.5736515522003174
Validation Loss Energy: 1.7663167653360912, Validation Loss Force: 2.0685854548809988, time: 0.1050422191619873
Test Loss Energy: 10.663871220555636, Test Loss Force: 8.965516328826752, time: 9.362267017364502

Epoch 2, Batch 100/104, Loss: 0.24330487847328186, Uncertainty: 0.12517967820167542

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6200329312276436, Training Loss Force: 1.8837238759710258, time: 1.5247085094451904
Validation Loss Energy: 0.7776138198384254, Validation Loss Force: 2.020493484078088, time: 0.10155463218688965
Test Loss Energy: 11.40188395387451, Test Loss Force: 8.780148051383156, time: 9.528463363647461

Epoch 3, Batch 100/104, Loss: 0.11191873997449875, Uncertainty: 0.12602075934410095

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3184500926268863, Training Loss Force: 1.8958698901633042, time: 1.562824010848999
Validation Loss Energy: 0.9182432188125141, Validation Loss Force: 2.0825557170965077, time: 0.10105013847351074
Test Loss Energy: 11.538195159392519, Test Loss Force: 8.887658469460675, time: 9.395054817199707

Epoch 4, Batch 100/104, Loss: 0.1343478262424469, Uncertainty: 0.1270877718925476

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.454349095686219, Training Loss Force: 1.9065256236534023, time: 1.5231735706329346
Validation Loss Energy: 1.0696930300974612, Validation Loss Force: 2.1181989239580337, time: 0.10375618934631348
Test Loss Energy: 11.604636983823763, Test Loss Force: 8.884786559759764, time: 9.336493730545044

Epoch 5, Batch 100/104, Loss: 0.06264710426330566, Uncertainty: 0.12641987204551697

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4053848144896686, Training Loss Force: 1.892020422366346, time: 1.498436689376831
Validation Loss Energy: 0.9345614993381888, Validation Loss Force: 2.022833180128924, time: 0.10094356536865234
Test Loss Energy: 11.633706009476029, Test Loss Force: 8.789741570835364, time: 9.488986253738403

Epoch 6, Batch 100/104, Loss: 0.14816705882549286, Uncertainty: 0.12614870071411133

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7773625380920732, Training Loss Force: 1.892467426394697, time: 1.5372858047485352
Validation Loss Energy: 1.7906995934880485, Validation Loss Force: 2.0904852993867156, time: 0.10838627815246582
Test Loss Energy: 12.391758695461165, Test Loss Force: 8.790414773109347, time: 9.37228775024414

Epoch 7, Batch 100/104, Loss: 0.06051529571413994, Uncertainty: 0.12559114396572113

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5149661307432052, Training Loss Force: 1.8859362523734797, time: 1.5509557723999023
Validation Loss Energy: 4.13754855663349, Validation Loss Force: 2.2671256154831863, time: 0.10073351860046387
Test Loss Energy: 14.3036453240146, Test Loss Force: 8.99384500171914, time: 9.47852087020874

Epoch 8, Batch 100/104, Loss: 0.2204533815383911, Uncertainty: 0.12648646533489227

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9603346692047858, Training Loss Force: 1.9090244339374, time: 1.5737860202789307
Validation Loss Energy: 1.4781133620647178, Validation Loss Force: 1.9306335688857619, time: 0.10506653785705566
Test Loss Energy: 11.89094919654245, Test Loss Force: 8.832651719924957, time: 9.37647271156311

Epoch 9, Batch 100/104, Loss: 0.04341486841440201, Uncertainty: 0.1250249147415161

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8212472192741929, Training Loss Force: 1.8739512226210833, time: 1.5088739395141602
Validation Loss Energy: 1.1097639850921177, Validation Loss Force: 1.9179161546198151, time: 0.1047213077545166
Test Loss Energy: 11.627558237932508, Test Loss Force: 8.781560370661545, time: 9.346441984176636

Epoch 10, Batch 100/104, Loss: 0.06707412004470825, Uncertainty: 0.12537863850593567

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7620835398447918, Training Loss Force: 1.8764391007064356, time: 1.5164282321929932
Validation Loss Energy: 0.7696543998826637, Validation Loss Force: 2.0232042582606127, time: 0.10114312171936035
Test Loss Energy: 11.43428496332061, Test Loss Force: 8.826798832279067, time: 9.5138840675354

Epoch 11, Batch 100/104, Loss: 0.18195341527462006, Uncertainty: 0.12518274784088135

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8039910766458402, Training Loss Force: 1.889312003338249, time: 1.5704936981201172
Validation Loss Energy: 1.96210918867753, Validation Loss Force: 1.9733829275358539, time: 0.10322809219360352
Test Loss Energy: 12.768847975433921, Test Loss Force: 8.889467988526349, time: 9.332008838653564

Epoch 12, Batch 100/104, Loss: 0.22261416912078857, Uncertainty: 0.12495937943458557

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.857320448965381, Training Loss Force: 1.8754689804817664, time: 1.5402884483337402
Validation Loss Energy: 1.1409022611278057, Validation Loss Force: 1.921703367121041, time: 0.10156130790710449
Test Loss Energy: 11.02817218012915, Test Loss Force: 8.758614872429456, time: 9.867452144622803

Epoch 13, Batch 100/104, Loss: 0.07924467325210571, Uncertainty: 0.12501150369644165

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3378371495423371, Training Loss Force: 1.8712094471126117, time: 1.569368600845337
Validation Loss Energy: 3.9504485800762077, Validation Loss Force: 2.0041957726147683, time: 0.11448264122009277
Test Loss Energy: 14.13242065030468, Test Loss Force: 8.90668354046047, time: 9.562161922454834

Epoch 14, Batch 100/104, Loss: 0.1325252801179886, Uncertainty: 0.12636366486549377

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.7354038693998004, Training Loss Force: 1.9028012199091988, time: 1.5756475925445557
Validation Loss Energy: 0.9253925684153906, Validation Loss Force: 1.9528469315489447, time: 0.10222649574279785
Test Loss Energy: 11.636245999921044, Test Loss Force: 8.629804152350665, time: 9.395801782608032

Epoch 15, Batch 100/104, Loss: 0.5027955770492554, Uncertainty: 0.12484516948461533

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.963129983261294, Training Loss Force: 1.8901820316407745, time: 1.5188143253326416
Validation Loss Energy: 9.389024009376794, Validation Loss Force: 2.084756690269431, time: 0.10259246826171875
Test Loss Energy: 19.015851228755505, Test Loss Force: 8.81793994846898, time: 9.294334888458252

Epoch 16, Batch 100/104, Loss: 0.03295426815748215, Uncertainty: 0.1263745129108429

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.065213094268081, Training Loss Force: 1.904172491446554, time: 1.5026133060455322
Validation Loss Energy: 0.9695874116599164, Validation Loss Force: 1.9973187473773617, time: 0.10154938697814941
Test Loss Energy: 11.017805730604953, Test Loss Force: 8.67684315165637, time: 9.53065013885498

Epoch 17, Batch 100/104, Loss: 0.058152101933956146, Uncertainty: 0.12523408234119415

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.340601551126452, Training Loss Force: 1.8761748898479704, time: 1.5963139533996582
Validation Loss Energy: 4.905433126477034, Validation Loss Force: 2.048271348698006, time: 0.10320878028869629
Test Loss Energy: 14.808423705769703, Test Loss Force: 8.993181349736485, time: 9.40900444984436

Epoch 18, Batch 100/104, Loss: 0.2684653401374817, Uncertainty: 0.1282990574836731

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7358436180971606, Training Loss Force: 1.9125589961768292, time: 1.5940284729003906
Validation Loss Energy: 0.8129935534330321, Validation Loss Force: 2.0841137331105646, time: 0.10525202751159668
Test Loss Energy: 11.50106605159214, Test Loss Force: 8.705484162909496, time: 9.546391248703003

Epoch 19, Batch 100/104, Loss: 0.3743465542793274, Uncertainty: 0.1253024935722351

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1293701204630837, Training Loss Force: 1.8829424881875003, time: 1.5540809631347656
Validation Loss Energy: 1.3142751858442188, Validation Loss Force: 2.02075612233571, time: 0.10128045082092285
Test Loss Energy: 11.91048498429328, Test Loss Force: 8.852098472660012, time: 9.380758285522461

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–ƒâ–â–„â–‚â–ˆâ–â–„â–‚â–‚
wandb:   test_error_force â–†â–‡â–„â–†â–†â–„â–„â–ˆâ–…â–„â–…â–†â–ƒâ–†â–â–…â–‚â–ˆâ–‚â–…
wandb:          test_loss â–ƒâ–…â–„â–…â–„â–„â–„â–‡â–„â–„â–„â–…â–ƒâ–†â–â–ˆâ–â–ˆâ–â–„
wandb: train_error_energy â–‡â–‚â–‚â–â–‚â–â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–„â–â–ˆâ–„â–…â–â–ƒâ–…
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–â–‚â–â–â–ƒâ–‚â–ƒâ–â–ƒâ–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–…â–ƒâ–ƒâ–â–ƒâ–ƒ
wandb: valid_error_energy â–â–‚â–â–â–â–â–‚â–„â–‚â–â–â–‚â–â–„â–â–ˆâ–â–„â–â–
wandb:  valid_error_force â–‚â–„â–ƒâ–„â–…â–ƒâ–„â–ˆâ–â–â–ƒâ–‚â–â–ƒâ–‚â–„â–ƒâ–„â–„â–ƒ
wandb:         valid_loss â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‡â–â–â–‚â–‚â–â–„â–â–ˆâ–‚â–…â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3311
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.91048
wandb:   test_error_force 8.8521
wandb:          test_loss 7.07152
wandb: train_error_energy 2.12937
wandb:  train_error_force 1.88294
wandb:         train_loss -2.53596
wandb: valid_error_energy 1.31428
wandb:  valid_error_force 2.02076
wandb:         valid_loss -2.40638
wandb: 
wandb: ğŸš€ View run al_59_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2eocn2gt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_032931-2eocn2gt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 26.81230926513672, Uncertainty Bias: -3.224442720413208
4.5776367e-05 0.009031296
0.89789104 3.5443797
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1590 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1487 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1995 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 384 steps.
Found uncertainty sample 11 after 751 steps.
Found uncertainty sample 12 after 3953 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3405 steps.
Found uncertainty sample 16 after 1744 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3603 steps.
Found uncertainty sample 19 after 609 steps.
Found uncertainty sample 20 after 2980 steps.
Found uncertainty sample 21 after 104 steps.
Found uncertainty sample 22 after 1060 steps.
Found uncertainty sample 23 after 2462 steps.
Found uncertainty sample 24 after 505 steps.
Found uncertainty sample 25 after 881 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 243 steps.
Found uncertainty sample 28 after 3540 steps.
Found uncertainty sample 29 after 56 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 878 steps.
Found uncertainty sample 34 after 1416 steps.
Found uncertainty sample 35 after 579 steps.
Found uncertainty sample 36 after 2231 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1111 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 559 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3449 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1024 steps.
Found uncertainty sample 48 after 888 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1452 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2720 steps.
Found uncertainty sample 56 after 1565 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1493 steps.
Found uncertainty sample 62 after 281 steps.
Found uncertainty sample 63 after 2379 steps.
Found uncertainty sample 64 after 1147 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3038 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3289 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1196 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 144 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3683 steps.
Found uncertainty sample 81 after 3903 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2319 steps.
Found uncertainty sample 84 after 2828 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1196 steps.
Found uncertainty sample 90 after 139 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1158 steps.
Found uncertainty sample 93 after 582 steps.
Found uncertainty sample 94 after 1909 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3263 steps.
Found uncertainty sample 99 after 1742 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_040128-9mw8rg0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_36
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/9mw8rg0s
Training model 36. Added 51 samples to the dataset.
Epoch 0, Batch 100/105, Loss: 0.053274430334568024, Uncertainty: 0.1272890716791153

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.783823498095635, Training Loss Force: 1.9728603357743124, time: 1.568904161453247
Validation Loss Energy: 0.9122844254656272, Validation Loss Force: 1.9905023994822202, time: 0.10399341583251953
Test Loss Energy: 11.324730325902774, Test Loss Force: 8.817594118803406, time: 9.33224892616272

Epoch 1, Batch 100/105, Loss: 0.105038121342659, Uncertainty: 0.12722930312156677

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.978641117862982, Training Loss Force: 1.884734072716705, time: 1.5613126754760742
Validation Loss Energy: 0.8597150234764006, Validation Loss Force: 1.9512571851815936, time: 0.11267566680908203
Test Loss Energy: 10.983940225020277, Test Loss Force: 8.72389885464544, time: 9.534784317016602

Epoch 2, Batch 100/105, Loss: 0.0955411046743393, Uncertainty: 0.12427683174610138

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2474926314842816, Training Loss Force: 1.8534205518218545, time: 1.5637478828430176
Validation Loss Energy: 1.986423546067115, Validation Loss Force: 1.9298109177261316, time: 0.10342001914978027
Test Loss Energy: 10.639875754528195, Test Loss Force: 8.703889954415674, time: 9.547019958496094

Epoch 3, Batch 100/105, Loss: 0.0821094959974289, Uncertainty: 0.12464868277311325

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8731088055475398, Training Loss Force: 1.908498590003262, time: 1.5160624980926514
Validation Loss Energy: 2.8881534261821216, Validation Loss Force: 1.9540389908216693, time: 0.10495305061340332
Test Loss Energy: 13.332192632737966, Test Loss Force: 8.738853351791779, time: 9.4104163646698

Epoch 4, Batch 100/105, Loss: 0.08053407073020935, Uncertainty: 0.12451229244470596

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4757027771706166, Training Loss Force: 1.8503168270355357, time: 1.5635294914245605
Validation Loss Energy: 0.7898169240445654, Validation Loss Force: 1.9632273217938065, time: 0.10219573974609375
Test Loss Energy: 11.416234973334712, Test Loss Force: 8.649063685800474, time: 9.38055944442749

Epoch 5, Batch 100/105, Loss: 0.06851649284362793, Uncertainty: 0.12562164664268494

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6583566327394066, Training Loss Force: 1.8931950029675346, time: 1.6104307174682617
Validation Loss Energy: 1.8612911681412325, Validation Loss Force: 2.0557243076813556, time: 0.1564793586730957
Test Loss Energy: 12.399158940147286, Test Loss Force: 8.818151649702214, time: 9.504911661148071

Epoch 6, Batch 100/105, Loss: 0.06737187504768372, Uncertainty: 0.12518101930618286

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5045082699721202, Training Loss Force: 1.8943027088058062, time: 1.565864086151123
Validation Loss Energy: 1.2049961831009572, Validation Loss Force: 1.9895721991251065, time: 0.11114668846130371
Test Loss Energy: 10.58120511593243, Test Loss Force: 8.811847282292947, time: 9.439541101455688

Epoch 7, Batch 100/105, Loss: 0.05102263763546944, Uncertainty: 0.12473572790622711

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6721132500062914, Training Loss Force: 1.8675340210477447, time: 1.5926854610443115
Validation Loss Energy: 0.9593813156890298, Validation Loss Force: 2.100376262848828, time: 0.10531163215637207
Test Loss Energy: 10.870869583497885, Test Loss Force: 8.64207349742175, time: 10.06782579421997

Epoch 8, Batch 100/105, Loss: 0.17282608151435852, Uncertainty: 0.1264544427394867

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6028268468408111, Training Loss Force: 1.9025240979514224, time: 1.571488618850708
Validation Loss Energy: 2.6338438852945787, Validation Loss Force: 2.0220761050327694, time: 0.10378408432006836
Test Loss Energy: 12.770882173496872, Test Loss Force: 8.825128407983758, time: 9.405231952667236

Epoch 9, Batch 100/105, Loss: 0.07140197604894638, Uncertainty: 0.1246248334646225

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.491543141582975, Training Loss Force: 1.8714413004636075, time: 1.5388402938842773
Validation Loss Energy: 0.9836950050711768, Validation Loss Force: 2.0045348977240165, time: 0.10201907157897949
Test Loss Energy: 10.969946073086765, Test Loss Force: 8.630925448884364, time: 9.42160940170288

Epoch 10, Batch 100/105, Loss: 0.1630893349647522, Uncertainty: 0.12447977811098099

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8999819102904323, Training Loss Force: 1.863677115754666, time: 1.5174031257629395
Validation Loss Energy: 1.4193066632943347, Validation Loss Force: 1.9857952850718794, time: 0.10644054412841797
Test Loss Energy: 10.766841692209765, Test Loss Force: 8.655399231553398, time: 9.57518982887268

Epoch 11, Batch 100/105, Loss: 0.07704585790634155, Uncertainty: 0.12539328634738922

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3593083463482023, Training Loss Force: 1.868191486691962, time: 1.5786516666412354
Validation Loss Energy: 4.508998545795849, Validation Loss Force: 2.087200484145989, time: 0.10335564613342285
Test Loss Energy: 9.944386523397023, Test Loss Force: 8.74012648769847, time: 9.40093994140625

Epoch 12, Batch 100/105, Loss: 0.041336119174957275, Uncertainty: 0.12677231431007385

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7201129774646786, Training Loss Force: 1.9050859085959801, time: 1.5683608055114746
Validation Loss Energy: 2.0859686784307163, Validation Loss Force: 1.9832904798493378, time: 0.10231304168701172
Test Loss Energy: 10.397781316041467, Test Loss Force: 8.611301456172376, time: 9.39072036743164

Epoch 13, Batch 100/105, Loss: 0.08602400124073029, Uncertainty: 0.12552419304847717

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8031125580625793, Training Loss Force: 1.8840263336809828, time: 1.5804879665374756
Validation Loss Energy: 1.7417856952002322, Validation Loss Force: 1.912550830214112, time: 0.10308575630187988
Test Loss Energy: 10.450781068124252, Test Loss Force: 8.605635559313557, time: 9.616766452789307

Epoch 14, Batch 100/105, Loss: 0.08032207936048508, Uncertainty: 0.12531644105911255

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3072025303873402, Training Loss Force: 1.8808722050826598, time: 1.5197439193725586
Validation Loss Energy: 0.928598920615821, Validation Loss Force: 2.071084804709465, time: 0.10419917106628418
Test Loss Energy: 11.273453692593804, Test Loss Force: 8.614930007289221, time: 9.42575478553772

Epoch 15, Batch 100/105, Loss: 0.10033278912305832, Uncertainty: 0.12503264844417572

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5362260472315665, Training Loss Force: 1.8920365402276136, time: 1.4937050342559814
Validation Loss Energy: 1.8372560378606413, Validation Loss Force: 1.9322188618701945, time: 0.10890579223632812
Test Loss Energy: 10.472473710829034, Test Loss Force: 8.618069534992554, time: 9.453701496124268

Epoch 16, Batch 100/105, Loss: 0.16680216789245605, Uncertainty: 0.12410127371549606

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4647177967210614, Training Loss Force: 1.8694479895965057, time: 1.7657382488250732
Validation Loss Energy: 2.2281493855108403, Validation Loss Force: 1.9729538440916512, time: 0.10837483406066895
Test Loss Energy: 12.792878369040485, Test Loss Force: 8.658667263835879, time: 9.42971420288086

Epoch 17, Batch 100/105, Loss: 0.2055802047252655, Uncertainty: 0.12438560277223587

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8870646207767956, Training Loss Force: 1.868178113819255, time: 1.5766143798828125
Validation Loss Energy: 2.051731627225724, Validation Loss Force: 1.9888705686462882, time: 0.10811996459960938
Test Loss Energy: 10.576775207704568, Test Loss Force: 8.672515568644616, time: 9.478231191635132

Epoch 18, Batch 100/105, Loss: 0.11205869913101196, Uncertainty: 0.12374211847782135

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5839517182766274, Training Loss Force: 1.864956468754899, time: 1.56168794631958
Validation Loss Energy: 2.0473309055601803, Validation Loss Force: 1.9829493507177767, time: 0.1111135482788086
Test Loss Energy: 12.752307467748919, Test Loss Force: 8.852865951418254, time: 9.682661294937134

Epoch 19, Batch 100/105, Loss: 0.1752057522535324, Uncertainty: 0.1240820437669754

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4173759187460866, Training Loss Force: 1.854120007565348, time: 1.5367040634155273
Validation Loss Energy: 0.799509823301375, Validation Loss Force: 2.1441326427113783, time: 0.10338258743286133
Test Loss Energy: 11.135472822886678, Test Loss Force: 8.947890655300041, time: 9.443984270095825

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–‚â–ˆâ–„â–†â–‚â–ƒâ–‡â–ƒâ–ƒâ–â–‚â–‚â–„â–‚â–‡â–‚â–‡â–ƒ
wandb:   test_error_force â–…â–ƒâ–ƒâ–„â–‚â–…â–…â–‚â–…â–‚â–‚â–„â–â–â–â–â–‚â–‚â–†â–ˆ
wandb:          test_loss â–„â–ƒâ–„â–†â–„â–†â–…â–ƒâ–…â–„â–„â–ƒâ–â–‚â–‚â–‚â–†â–„â–ˆâ–ˆ
wandb: train_error_energy â–ˆâ–„â–â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–„â–â–‚â–‚â–„â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–„â–â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–â–„â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–
wandb: valid_error_energy â–â–â–ƒâ–…â–â–ƒâ–‚â–â–„â–â–‚â–ˆâ–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–ƒâ–
wandb:  valid_error_force â–ƒâ–‚â–‚â–‚â–ƒâ–…â–ƒâ–‡â–„â–„â–ƒâ–†â–ƒâ–â–†â–‚â–ƒâ–ƒâ–ƒâ–ˆ
wandb:         valid_loss â–‚â–â–‚â–ƒâ–â–„â–‚â–„â–„â–‚â–‚â–ˆâ–ƒâ–â–„â–‚â–ƒâ–ƒâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3356
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 11.13547
wandb:   test_error_force 8.94789
wandb:          test_loss 7.24175
wandb: train_error_energy 1.41738
wandb:  train_error_force 1.85412
wandb:         train_loss -2.62225
wandb: valid_error_energy 0.79951
wandb:  valid_error_force 2.14413
wandb:         valid_loss -2.27218
wandb: 
wandb: ğŸš€ View run al_59_36 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/9mw8rg0s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_040128-9mw8rg0s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.787181854248047, Uncertainty Bias: -2.558398485183716
4.1007996e-05 0.00057935715
1.0903057 3.3354414
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2361 steps.
Found uncertainty sample 1 after 2167 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1458 steps.
Found uncertainty sample 4 after 57 steps.
Found uncertainty sample 5 after 3294 steps.
Found uncertainty sample 6 after 1540 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3332 steps.
Found uncertainty sample 10 after 458 steps.
Found uncertainty sample 11 after 1039 steps.
Found uncertainty sample 12 after 29 steps.
Found uncertainty sample 13 after 1332 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 14 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3399 steps.
Found uncertainty sample 20 after 412 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2787 steps.
Found uncertainty sample 23 after 380 steps.
Found uncertainty sample 24 after 750 steps.
Found uncertainty sample 25 after 3843 steps.
Found uncertainty sample 26 after 510 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1975 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 413 steps.
Found uncertainty sample 32 after 441 steps.
Found uncertainty sample 33 after 1041 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1144 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 815 steps.
Found uncertainty sample 40 after 1153 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2579 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 172 steps.
Found uncertainty sample 51 after 2879 steps.
Found uncertainty sample 52 after 787 steps.
Found uncertainty sample 53 after 594 steps.
Found uncertainty sample 54 after 2453 steps.
Found uncertainty sample 55 after 2436 steps.
Found uncertainty sample 56 after 1080 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 451 steps.
Found uncertainty sample 59 after 1982 steps.
Found uncertainty sample 60 after 1752 steps.
Found uncertainty sample 61 after 580 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2760 steps.
Found uncertainty sample 65 after 3282 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2198 steps.
Found uncertainty sample 69 after 254 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3621 steps.
Found uncertainty sample 74 after 1978 steps.
Found uncertainty sample 75 after 2648 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2278 steps.
Found uncertainty sample 80 after 1976 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 734 steps.
Found uncertainty sample 85 after 2446 steps.
Found uncertainty sample 86 after 1744 steps.
Found uncertainty sample 87 after 3465 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1675 steps.
Found uncertainty sample 90 after 1457 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2841 steps.
Found uncertainty sample 94 after 320 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2735 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_043244-1kmd1jp4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_59_37
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1kmd1jp4
Training model 37. Added 56 samples to the dataset.
Epoch 0, Batch 100/107, Loss: 0.08673965930938721, Uncertainty: 0.12762287259101868
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.227630804677626, Training Loss Force: 2.107446535770619, time: 1.6462790966033936
Validation Loss Energy: 1.5113084144455782, Validation Loss Force: 1.8205106500794337, time: 0.12225747108459473
Test Loss Energy: 11.811531692529876, Test Loss Force: 8.797347426578698, time: 9.32477355003357

Epoch 1, Batch 100/107, Loss: 0.1232651099562645, Uncertainty: 0.12524867057800293

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4442170602051272, Training Loss Force: 1.8553047664215259, time: 1.5825326442718506
Validation Loss Energy: 1.4874143821804564, Validation Loss Force: 1.95969233776763, time: 0.10672688484191895
Test Loss Energy: 10.580340320265154, Test Loss Force: 8.708462981779823, time: 9.436653852462769

Epoch 2, Batch 100/107, Loss: 0.06982265412807465, Uncertainty: 0.12644581496715546

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3326659254736035, Training Loss Force: 1.8950992212238438, time: 1.6378357410430908
Validation Loss Energy: 0.8694471217807745, Validation Loss Force: 1.8301390866184974, time: 0.11461162567138672
Test Loss Energy: 10.85312920388423, Test Loss Force: 8.708686154554394, time: 9.537103414535522

Epoch 3, Batch 100/107, Loss: 0.13151168823242188, Uncertainty: 0.12656015157699585

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6580171546222673, Training Loss Force: 1.914054923877003, time: 1.5779883861541748
Validation Loss Energy: 1.5982705504843249, Validation Loss Force: 2.2622271540534453, time: 0.10899853706359863
Test Loss Energy: 11.830937749272541, Test Loss Force: 8.578792977969476, time: 9.30483365058899

Epoch 4, Batch 100/107, Loss: 0.0505334809422493, Uncertainty: 0.12500503659248352

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3559698460718732, Training Loss Force: 1.8811847168191884, time: 1.5476062297821045
Validation Loss Energy: 3.0272367683308663, Validation Loss Force: 2.1242734495935167, time: 0.10784006118774414
Test Loss Energy: 10.149440189614914, Test Loss Force: 8.509155154141556, time: 9.864516973495483

Epoch 5, Batch 100/107, Loss: 0.08193197846412659, Uncertainty: 0.12569758296012878

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.601328084691844, Training Loss Force: 1.9030448138418472, time: 1.6375699043273926
Validation Loss Energy: 4.848224078828683, Validation Loss Force: 4.694939084110286, time: 0.16124653816223145
Test Loss Energy: 10.929037428167304, Test Loss Force: 8.57462816027436, time: 9.426186084747314

Epoch 6, Batch 100/107, Loss: 0.05115540325641632, Uncertainty: 0.12677910923957825

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4285271767213739, Training Loss Force: 1.898081397879954, time: 1.6048028469085693
Validation Loss Energy: 0.598816526281114, Validation Loss Force: 2.260630727611716, time: 0.11402392387390137
Test Loss Energy: 11.146135406053663, Test Loss Force: 8.636786054172903, time: 9.38708758354187

Epoch 7, Batch 100/107, Loss: 0.06292026489973068, Uncertainty: 0.12583383917808533

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3930647142554844, Training Loss Force: 1.8843189515297267, time: 1.5787885189056396
Validation Loss Energy: 2.8187296027532316, Validation Loss Force: 1.9898404783344255, time: 0.11371207237243652
Test Loss Energy: 10.073604604437312, Test Loss Force: 8.670681763486545, time: 9.476750373840332

Epoch 8, Batch 100/107, Loss: 0.05429159104824066, Uncertainty: 0.12490738928318024

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4717453142732253, Training Loss Force: 1.8789743748939765, time: 1.6244027614593506
Validation Loss Energy: 2.825900365705641, Validation Loss Force: 2.158537258207544, time: 0.10917806625366211
Test Loss Energy: 13.267998544914807, Test Loss Force: 8.70406311406794, time: 9.337849617004395

Epoch 9, Batch 100/107, Loss: 0.13418446481227875, Uncertainty: 0.1249563992023468

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.888894650043824, Training Loss Force: 1.8683806415945652, time: 1.5961973667144775
Validation Loss Energy: 1.557531040656901, Validation Loss Force: 1.8323185722188384, time: 0.10698628425598145
Test Loss Energy: 12.185595437412326, Test Loss Force: 8.656099037544188, time: 9.356185674667358

Epoch 10, Batch 100/107, Loss: 0.05958752706646919, Uncertainty: 0.12483121454715729

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4812922242503437, Training Loss Force: 1.8754606828244968, time: 1.6050806045532227
Validation Loss Energy: 0.68600710230782, Validation Loss Force: 1.7307733513634649, time: 0.10897326469421387
Test Loss Energy: 11.527640222185008, Test Loss Force: 8.54372132375101, time: 9.497244119644165

Epoch 11, Batch 100/107, Loss: 0.09979680925607681, Uncertainty: 0.1240200400352478

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5403090014750638, Training Loss Force: 1.8762471471263833, time: 1.5871219635009766
Validation Loss Energy: 1.5179772440315427, Validation Loss Force: 1.8513233096007264, time: 0.10872673988342285
Test Loss Energy: 11.767259493761745, Test Loss Force: 8.756659851317895, time: 9.37367057800293

Epoch 12, Batch 100/107, Loss: 0.1222718134522438, Uncertainty: 0.1241421028971672

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5639350635623452, Training Loss Force: 1.868003950951787, time: 1.6599640846252441
Validation Loss Energy: 1.0252291654131305, Validation Loss Force: 1.7902809012706558, time: 0.1083064079284668
Test Loss Energy: 10.731595096985863, Test Loss Force: 8.573023562108135, time: 9.363707542419434

Epoch 13, Batch 100/107, Loss: 0.15074323117733002, Uncertainty: 0.12414763867855072

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9009888862060207, Training Loss Force: 1.863175601515569, time: 1.5847389698028564
Validation Loss Energy: 1.7916021828710669, Validation Loss Force: 2.0661484895249163, time: 0.10798358917236328
Test Loss Energy: 10.479056519593343, Test Loss Force: 8.53820183360435, time: 9.571779489517212

Epoch 14, Batch 100/107, Loss: 0.03664726763963699, Uncertainty: 0.12443932145833969

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9029851140587533, Training Loss Force: 1.8685701091060187, time: 1.5760798454284668
Validation Loss Energy: 1.993163369999106, Validation Loss Force: 2.650796169823878, time: 0.1077413558959961
Test Loss Energy: 10.458847412987822, Test Loss Force: 8.723931529885348, time: 9.32720136642456

Epoch 15, Batch 100/107, Loss: 0.057098932564258575, Uncertainty: 0.12438838928937912

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8246648509876846, Training Loss Force: 1.8785597503771179, time: 1.6082191467285156
Validation Loss Energy: 2.193794319658507, Validation Loss Force: 1.673803932827657, time: 0.10967016220092773
Test Loss Energy: 12.768314576740986, Test Loss Force: 8.76299266908233, time: 9.892330169677734

Epoch 16, Batch 100/107, Loss: 0.0915534645318985, Uncertainty: 0.1252758800983429

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5012757260607046, Training Loss Force: 1.919546753491874, time: 1.7807252407073975
Validation Loss Energy: 4.078429156159176, Validation Loss Force: 1.6802287912527332, time: 0.10796809196472168
Test Loss Energy: 10.345488901062994, Test Loss Force: 8.589802132255313, time: 9.379999876022339

Epoch 17, Batch 100/107, Loss: 0.05380656570196152, Uncertainty: 0.12538880109786987

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7772916884436396, Training Loss Force: 1.8768995209010007, time: 1.5579400062561035
Validation Loss Energy: 1.0702940605117257, Validation Loss Force: 1.7847504676932473, time: 0.10851716995239258
Test Loss Energy: 11.523692650301436, Test Loss Force: 8.697260490053353, time: 9.313488006591797

Epoch 18, Batch 100/107, Loss: 0.12497693300247192, Uncertainty: 0.12697288393974304

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6855089533810355, Training Loss Force: 1.9074887666180225, time: 1.5779027938842773
Validation Loss Energy: 2.3423942071004866, Validation Loss Force: 1.7971787460732067, time: 0.10866022109985352
Test Loss Energy: 12.9993325146004, Test Loss Force: 8.76650330114801, time: 9.57232403755188

Epoch 19, Batch 100/107, Loss: 0.07550204545259476, Uncertainty: 0.12504842877388

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7026272828473914, Training Loss Force: 1.8857748550111952, time: 1.6309106349945068
Validation Loss Energy: 2.8251026163788304, Validation Loss Force: 1.9896060077237634, time: 0.10839676856994629
Test Loss Energy: 10.220297144503895, Test Loss Force: 8.528263361173467, time: 9.374677419662476

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.057 MB uploadedwandb: | 0.053 MB of 0.060 MB uploadedwandb: / 0.053 MB of 0.060 MB uploadedwandb: - 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–ƒâ–…â–â–ƒâ–ƒâ–â–ˆâ–†â–„â–…â–‚â–‚â–‚â–‡â–‚â–„â–‡â–
wandb:   test_error_force â–ˆâ–†â–†â–ƒâ–â–ƒâ–„â–…â–†â–…â–‚â–‡â–ƒâ–‚â–†â–‡â–ƒâ–†â–‡â–
wandb:          test_loss â–…â–…â–„â–ƒâ–â–ƒâ–ƒâ–„â–ˆâ–†â–ƒâ–ˆâ–„â–ƒâ–†â–ˆâ–‚â–…â–‡â–
wandb: train_error_energy â–‡â–‚â–ˆâ–ƒâ–â–ƒâ–‚â–â–‚â–…â–‚â–‚â–‚â–…â–…â–„â–‚â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–ƒâ–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb: valid_error_energy â–ƒâ–‚â–â–ƒâ–…â–ˆâ–â–…â–…â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–„â–‡â–‚â–„â–…
wandb:  valid_error_force â–â–‚â–â–‚â–‚â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚â–ƒâ–â–â–â–â–‚
wandb:         valid_loss â–â–‚â–â–‚â–‚â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚â–ƒâ–â–â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3406
wandb:                 lr 0.0001
wandb:    max_uncertainty 3
wandb:  test_error_energy 10.2203
wandb:   test_error_force 8.52826
wandb:          test_loss 6.53001
wandb: train_error_energy 1.70263
wandb:  train_error_force 1.88577
wandb:         train_loss -2.56069
wandb: valid_error_energy 2.8251
wandb:  valid_error_force 1.98961
wandb:         valid_loss -2.34754
wandb: 
wandb: ğŸš€ View run al_59_37 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1kmd1jp4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_043244-1kmd1jp4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Traceback (most recent call last):
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 885, in <module>
    int(x.split("run")[1])
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 578, in improve_model
    self.model.calibrate_uncertainty(
  File "/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py", line 757, in calibrate_uncertainty
    uncertainties = torch.cat(
                    ^^^^^^^^^^
RuntimeError: zero-dimensional tensor (at position 1) cannot be concatenated
