wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_145620-ahlzgt5c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ahlzgt5c
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
68
Uncertainty Slope: 5.4503936767578125, Uncertainty Bias: -0.39420241117477417
0.0002784729 0.0020980835
1.6673777 2.2779703
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.996635043031139, Test Loss Force: 13.386480671555825, time: 6.43362283706665

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.044 MB of 0.056 MB uploaded (0.003 MB deduped)wandb: \ 0.044 MB of 0.056 MB uploaded (0.003 MB deduped)wandb: | 0.056 MB of 0.056 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 5.4%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 5
wandb:  test_error_energy 10.99664
wandb:   test_error_force 13.38648
wandb:          test_loss 16.63181
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_69 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ahlzgt5c
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_145620-ahlzgt5c/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2113 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1250 steps.
Found uncertainty sample 11 after 1354 steps.
Found uncertainty sample 12 after 2358 steps.
Found uncertainty sample 13 after 659 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 257 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 936 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 169 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1735 steps.
Found uncertainty sample 24 after 1873 steps.
Found uncertainty sample 25 after 2790 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3376 steps.
Found uncertainty sample 28 after 3705 steps.
Found uncertainty sample 29 after 724 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1102 steps.
Found uncertainty sample 32 after 1641 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3799 steps.
Found uncertainty sample 36 after 881 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2414 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1546 steps.
Found uncertainty sample 44 after 2134 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 928 steps.
Found uncertainty sample 48 after 1516 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1980 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2856 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3516 steps.
Found uncertainty sample 60 after 2193 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1805 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1030 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2099 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 702 steps.
Found uncertainty sample 71 after 758 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1133 steps.
Found uncertainty sample 74 after 291 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1796 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1748 steps.
Found uncertainty sample 79 after 443 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1014 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3052 steps.
Found uncertainty sample 85 after 1986 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3269 steps.
Found uncertainty sample 88 after 770 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 329 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 402 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3699 steps.
Found uncertainty sample 98 after 2585 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_152755-aem4tjll
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/aem4tjll
Training model 0. Added 46 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.39551696946644, Training Loss Force: 2.4885709717849553, time: 1.0628645420074463
Validation Loss Energy: 5.455387395156424, Validation Loss Force: 2.7732052669835388, time: 0.041747331619262695
Test Loss Energy: 14.910454238497552, Test Loss Force: 12.366155408976828, time: 7.536529779434204


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.8936059719478604, Training Loss Force: 2.1293630394970156, time: 0.38429903984069824
Validation Loss Energy: 1.862150337040795, Validation Loss Force: 2.74403115548408, time: 0.036240577697753906
Test Loss Energy: 11.912232281905254, Test Loss Force: 12.314308919856963, time: 7.196727752685547


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.609895944416878, Training Loss Force: 2.135867382560182, time: 0.4093971252441406
Validation Loss Energy: 2.1065619003881286, Validation Loss Force: 2.720597899904931, time: 0.0315854549407959
Test Loss Energy: 11.771094775110576, Test Loss Force: 12.190850806977704, time: 7.17902684211731


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7352567417132057, Training Loss Force: 2.158550634850311, time: 0.42886805534362793
Validation Loss Energy: 3.1421936487376647, Validation Loss Force: 2.6778162542286794, time: 0.03345155715942383
Test Loss Energy: 13.403789073026376, Test Loss Force: 12.178979757552527, time: 7.43706202507019


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4011902342458757, Training Loss Force: 2.055511279284746, time: 0.3823568820953369
Validation Loss Energy: 3.046499356583739, Validation Loss Force: 2.663796336793628, time: 0.03318285942077637
Test Loss Energy: 13.515668334358653, Test Loss Force: 11.906892563868428, time: 7.190979719161987


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.3963345933299474, Training Loss Force: 2.0196676000923395, time: 0.3931407928466797
Validation Loss Energy: 2.84702120220433, Validation Loss Force: 2.6517637414859823, time: 0.03371429443359375
Test Loss Energy: 12.036407711197143, Test Loss Force: 11.797910766727533, time: 7.197799444198608


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.5598977071791817, Training Loss Force: 2.0246503170527976, time: 0.4133589267730713
Validation Loss Energy: 3.028555340790002, Validation Loss Force: 2.677127315891179, time: 0.03362727165222168
Test Loss Energy: 13.661119490439265, Test Loss Force: 11.738754448252866, time: 7.160630464553833


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.5031193202148176, Training Loss Force: 2.0265669664673873, time: 0.40172672271728516
Validation Loss Energy: 1.8530347075448033, Validation Loss Force: 2.70285918506374, time: 0.03428339958190918
Test Loss Energy: 12.677108702338984, Test Loss Force: 11.424495742171082, time: 7.410252332687378


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2545540247668066, Training Loss Force: 2.0174365047321747, time: 0.43912768363952637
Validation Loss Energy: 3.6559839987577774, Validation Loss Force: 2.6983686163978144, time: 0.03215980529785156
Test Loss Energy: 14.704004042691912, Test Loss Force: 11.526025849892504, time: 7.196635961532593


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.356709559071903, Training Loss Force: 2.0055251816390056, time: 0.412595272064209
Validation Loss Energy: 1.9956886978945971, Validation Loss Force: 2.668931087298723, time: 0.033086538314819336
Test Loss Energy: 12.777497205167954, Test Loss Force: 11.197154783053232, time: 8.147283792495728


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0298625626059295, Training Loss Force: 1.9727862443243132, time: 0.3925325870513916
Validation Loss Energy: 3.1430863293436895, Validation Loss Force: 2.744034050182977, time: 0.04438042640686035
Test Loss Energy: 14.912385463155674, Test Loss Force: 11.08208330886557, time: 8.945743560791016


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.50980426032584, Training Loss Force: 1.9978446176769944, time: 0.567065954208374
Validation Loss Energy: 1.9026675488375342, Validation Loss Force: 2.6459055389257684, time: 0.041001081466674805
Test Loss Energy: 13.013675905019294, Test Loss Force: 10.929797916746491, time: 8.617563724517822


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2709841336548933, Training Loss Force: 1.918895849379865, time: 0.45415306091308594
Validation Loss Energy: 1.8970921360926483, Validation Loss Force: 2.6749173246178457, time: 0.0476839542388916
Test Loss Energy: 13.13416037987474, Test Loss Force: 10.809680894945721, time: 8.544447660446167


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.221238942376658, Training Loss Force: 1.9165951657880957, time: 0.3844125270843506
Validation Loss Energy: 1.8129054967348432, Validation Loss Force: 2.6369281869693975, time: 0.03950309753417969
Test Loss Energy: 13.3916347091727, Test Loss Force: 10.87538001168685, time: 8.52958345413208


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.6340740571536734, Training Loss Force: 1.9623077435796545, time: 0.4225482940673828
Validation Loss Energy: 2.2296362587327736, Validation Loss Force: 2.6823270857868846, time: 0.0400998592376709
Test Loss Energy: 12.476296162882257, Test Loss Force: 10.709373937988058, time: 8.793749332427979


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.5876475525982383, Training Loss Force: 2.006972959931818, time: 0.4094381332397461
Validation Loss Energy: 2.9248211337840613, Validation Loss Force: 2.662314250958333, time: 0.04059720039367676
Test Loss Energy: 12.31393105847697, Test Loss Force: 10.735744297529786, time: 8.491618156433105


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1616343455045115, Training Loss Force: 1.9891300606713482, time: 0.4183957576751709
Validation Loss Energy: 5.062120283076061, Validation Loss Force: 2.816885159994463, time: 0.039519309997558594
Test Loss Energy: 16.356857476059986, Test Loss Force: 10.842117270314395, time: 8.542640924453735


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.4302948647247993, Training Loss Force: 1.997013352520219, time: 0.3905904293060303
Validation Loss Energy: 2.137272874332781, Validation Loss Force: 2.6852605291153373, time: 0.04163479804992676
Test Loss Energy: 13.841486618865325, Test Loss Force: 10.742559279099066, time: 8.782066583633423


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1389914203687925, Training Loss Force: 1.8905496465059817, time: 0.4023096561431885
Validation Loss Energy: 1.867047165563466, Validation Loss Force: 2.6608878324095193, time: 0.04133319854736328
Test Loss Energy: 13.445223426975499, Test Loss Force: 10.73686542618727, time: 8.542447566986084


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.114887493569115, Training Loss Force: 1.9359436259847447, time: 0.4235672950744629
Validation Loss Energy: 3.049399622209448, Validation Loss Force: 2.65582990275977, time: 0.04210042953491211
Test Loss Energy: 12.490098348364224, Test Loss Force: 10.686518025032665, time: 8.564248085021973

wandb: - 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: \ 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–â–ƒâ–„â–â–„â–‚â–…â–ƒâ–†â–ƒâ–ƒâ–ƒâ–‚â–‚â–ˆâ–„â–„â–‚
wandb:   test_error_force â–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–
wandb:          test_loss â–ˆâ–‡â–†â–†â–…â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–ƒâ–‚â–â–
wandb:  train_error_force â–ˆâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–ˆâ–â–‚â–„â–ƒâ–ƒâ–ƒâ–â–…â–â–„â–â–â–â–‚â–ƒâ–‡â–‚â–â–ƒ
wandb:  valid_error_force â–†â–…â–„â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–‚â–…â–â–‚â–â–ƒâ–‚â–ˆâ–ƒâ–‚â–‚
wandb:         valid_loss â–ˆâ–…â–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚â–â–‚â–‚â–…â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 841
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.4901
wandb:   test_error_force 10.68652
wandb:          test_loss 8.63762
wandb: train_error_energy 2.11489
wandb:  train_error_force 1.93594
wandb:         train_loss -2.46548
wandb: valid_error_energy 3.0494
wandb:  valid_error_force 2.65583
wandb:         valid_loss -1.43782
wandb: 
wandb: ğŸš€ View run al_69_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/aem4tjll
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_152755-aem4tjll/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 38.25705337524414, Uncertainty Bias: -4.6374382972717285
0.0005350113 0.007040024
-5.406592 50.22518
(48745, 22, 3)
Found uncertainty sample 0 after 43 steps.
Found uncertainty sample 1 after 34 steps.
Found uncertainty sample 2 after 46 steps.
Found uncertainty sample 3 after 43 steps.
Found uncertainty sample 4 after 13 steps.
Found uncertainty sample 5 after 98 steps.
Found uncertainty sample 6 after 66 steps.
Found uncertainty sample 7 after 28 steps.
Found uncertainty sample 8 after 267 steps.
Found uncertainty sample 9 after 395 steps.
Found uncertainty sample 10 after 11 steps.
Found uncertainty sample 11 after 268 steps.
Found uncertainty sample 12 after 47 steps.
Found uncertainty sample 13 after 35 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 14 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 77 steps.
Found uncertainty sample 18 after 111 steps.
Found uncertainty sample 19 after 84 steps.
Found uncertainty sample 20 after 130 steps.
Found uncertainty sample 21 after 11 steps.
Found uncertainty sample 22 after 17 steps.
Found uncertainty sample 23 after 119 steps.
Found uncertainty sample 24 after 414 steps.
Found uncertainty sample 25 after 79 steps.
Found uncertainty sample 26 after 33 steps.
Found uncertainty sample 27 after 13 steps.
Found uncertainty sample 28 after 12 steps.
Found uncertainty sample 29 after 20 steps.
Found uncertainty sample 30 after 59 steps.
Found uncertainty sample 31 after 36 steps.
Found uncertainty sample 32 after 116 steps.
Found uncertainty sample 33 after 28 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 400 steps.
Found uncertainty sample 36 after 501 steps.
Found uncertainty sample 37 after 9 steps.
Found uncertainty sample 38 after 201 steps.
Found uncertainty sample 39 after 14 steps.
Found uncertainty sample 40 after 111 steps.
Found uncertainty sample 41 after 98 steps.
Found uncertainty sample 42 after 78 steps.
Found uncertainty sample 43 after 64 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 187 steps.
Found uncertainty sample 46 after 77 steps.
Found uncertainty sample 47 after 374 steps.
Found uncertainty sample 48 after 4 steps.
Found uncertainty sample 49 after 86 steps.
Found uncertainty sample 50 after 155 steps.
Found uncertainty sample 51 after 32 steps.
Found uncertainty sample 52 after 503 steps.
Found uncertainty sample 53 after 15 steps.
Found uncertainty sample 54 after 49 steps.
Found uncertainty sample 55 after 10 steps.
Found uncertainty sample 56 after 47 steps.
Found uncertainty sample 57 after 3 steps.
Found uncertainty sample 58 after 145 steps.
Found uncertainty sample 59 after 36 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 35 steps.
Found uncertainty sample 62 after 18 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 125 steps.
Found uncertainty sample 65 after 57 steps.
Found uncertainty sample 66 after 24 steps.
Found uncertainty sample 67 after 32 steps.
Found uncertainty sample 68 after 37 steps.
Found uncertainty sample 69 after 44 steps.
Found uncertainty sample 70 after 185 steps.
Found uncertainty sample 71 after 181 steps.
Found uncertainty sample 72 after 26 steps.
Found uncertainty sample 73 after 95 steps.
Found uncertainty sample 74 after 33 steps.
Found uncertainty sample 75 after 13 steps.
Found uncertainty sample 76 after 8 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 122 steps.
Found uncertainty sample 79 after 272 steps.
Found uncertainty sample 80 after 5 steps.
Found uncertainty sample 81 after 23 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 6 steps.
Found uncertainty sample 84 after 4 steps.
Found uncertainty sample 85 after 114 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 103 steps.
Found uncertainty sample 88 after 42 steps.
Found uncertainty sample 89 after 45 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 88 steps.
Found uncertainty sample 92 after 285 steps.
Found uncertainty sample 93 after 233 steps.
Found uncertainty sample 94 after 9 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 18 steps.
Found uncertainty sample 97 after 192 steps.
Found uncertainty sample 98 after 86 steps.
Found uncertainty sample 99 after 28 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_153410-x8zffvln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/x8zffvln
Training model 1. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.774164036332227, Training Loss Force: 2.122994115149046, time: 0.48900485038757324
Validation Loss Energy: 2.843558696985153, Validation Loss Force: 2.7206960969982856, time: 0.04222297668457031
Test Loss Energy: 12.537044759274277, Test Loss Force: 10.76485103004517, time: 9.010451793670654


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8031324959639385, Training Loss Force: 1.918017320635115, time: 0.508404016494751
Validation Loss Energy: 2.0518171321777605, Validation Loss Force: 2.635344786672705, time: 0.03569340705871582
Test Loss Energy: 13.98622014143379, Test Loss Force: 10.612229554407426, time: 7.518773555755615


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.913229880185957, Training Loss Force: 1.918919783838951, time: 0.46449971199035645
Validation Loss Energy: 3.319838870689708, Validation Loss Force: 2.6239652799700655, time: 0.03592658042907715
Test Loss Energy: 14.561802018829937, Test Loss Force: 10.68144956231625, time: 7.537390470504761


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.4654229182702156, Training Loss Force: 1.8894562172943954, time: 0.47292637825012207
Validation Loss Energy: 2.0831800813816894, Validation Loss Force: 2.62099643224741, time: 0.03583693504333496
Test Loss Energy: 13.493192800926476, Test Loss Force: 10.650100805647307, time: 7.707334756851196


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.326772144008951, Training Loss Force: 1.9533370560283514, time: 0.4531538486480713
Validation Loss Energy: 4.375695434894719, Validation Loss Force: 2.699874305162578, time: 0.039687395095825195
Test Loss Energy: 12.031689554845359, Test Loss Force: 10.585569221347349, time: 7.480215311050415


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.351157021045908, Training Loss Force: 1.9556996721566084, time: 0.420166015625
Validation Loss Energy: 1.9372796862188413, Validation Loss Force: 2.642995253188492, time: 0.038846492767333984
Test Loss Energy: 13.204634712227746, Test Loss Force: 10.572305065143908, time: 7.5273144245147705


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.25646107528563, Training Loss Force: 1.9408603730872196, time: 0.4600355625152588
Validation Loss Energy: 1.8663146954079366, Validation Loss Force: 2.6013732684242323, time: 0.040999650955200195
Test Loss Energy: 13.321500260869328, Test Loss Force: 10.542185656668986, time: 8.0336754322052


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.346396411996887, Training Loss Force: 1.9369405462649836, time: 0.4382517337799072
Validation Loss Energy: 2.167142826913264, Validation Loss Force: 2.6454907063069046, time: 0.03748488426208496
Test Loss Energy: 13.756671456205698, Test Loss Force: 10.584658427597237, time: 7.448832273483276


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.244952450167572, Training Loss Force: 2.014372992108581, time: 0.4576890468597412
Validation Loss Energy: 3.356440779559026, Validation Loss Force: 2.7090001774392825, time: 0.03497624397277832
Test Loss Energy: 14.856021163956623, Test Loss Force: 10.668934054755631, time: 7.498202085494995


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2872207525392256, Training Loss Force: 1.9105844389864233, time: 0.49073362350463867
Validation Loss Energy: 2.704161576898272, Validation Loss Force: 2.613754340945255, time: 0.03647899627685547
Test Loss Energy: 12.46319698236562, Test Loss Force: 10.476330009347302, time: 7.545053720474243


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.4644809461375874, Training Loss Force: 1.8991411783961523, time: 0.44329285621643066
Validation Loss Energy: 1.7748232833833975, Validation Loss Force: 2.6221618825571964, time: 0.035909414291381836
Test Loss Energy: 13.397207299498728, Test Loss Force: 10.47179543962601, time: 7.735934019088745


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.4487276663027897, Training Loss Force: 1.9025570307181048, time: 0.43927764892578125
Validation Loss Energy: 2.690956851206462, Validation Loss Force: 2.718149429976309, time: 0.03980135917663574
Test Loss Energy: 12.563605541739022, Test Loss Force: 10.435798274509278, time: 7.529172420501709


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.933776438112688, Training Loss Force: 1.9001552656428415, time: 0.4767262935638428
Validation Loss Energy: 3.2616229131634715, Validation Loss Force: 2.661823265491562, time: 0.04256868362426758
Test Loss Energy: 12.35669432986836, Test Loss Force: 10.426866569727824, time: 7.593362092971802


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.12562960118218, Training Loss Force: 1.9023359981904, time: 0.4413797855377197
Validation Loss Energy: 2.644638996823731, Validation Loss Force: 2.6556495407515683, time: 0.03762507438659668
Test Loss Energy: 12.719792181232865, Test Loss Force: 10.386518622039103, time: 7.5453596115112305


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0715504726943434, Training Loss Force: 1.8670806475807085, time: 0.4383511543273926
Validation Loss Energy: 1.8487597939467086, Validation Loss Force: 2.6787407765225715, time: 0.03683924674987793
Test Loss Energy: 12.961612664390065, Test Loss Force: 10.400697083403477, time: 7.754347801208496


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8380607771430582, Training Loss Force: 1.8963386571032004, time: 0.44698596000671387
Validation Loss Energy: 2.250814766540257, Validation Loss Force: 2.6532930331802143, time: 0.03635811805725098
Test Loss Energy: 13.627511255153662, Test Loss Force: 10.362003849594307, time: 7.56522536277771


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8265380310899955, Training Loss Force: 1.9318615409805715, time: 0.4548921585083008
Validation Loss Energy: 2.5526024907299605, Validation Loss Force: 2.6451224115395404, time: 0.03767848014831543
Test Loss Energy: 12.45216764562819, Test Loss Force: 10.321381769373387, time: 7.670536518096924


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.567182888672227, Training Loss Force: 1.934960835711216, time: 0.4336392879486084
Validation Loss Energy: 1.862396720450764, Validation Loss Force: 2.6611434565890444, time: 0.039793968200683594
Test Loss Energy: 13.62029030226488, Test Loss Force: 10.386217666618371, time: 7.894852876663208


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.052436011379647, Training Loss Force: 1.8349584930791292, time: 0.46231532096862793
Validation Loss Energy: 2.432713637186959, Validation Loss Force: 2.662351436705703, time: 0.04464983940124512
Test Loss Energy: 13.981214333851293, Test Loss Force: 10.416820292787715, time: 7.7575860023498535


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2602588497266782, Training Loss Force: 1.8796552233006956, time: 0.4390387535095215
Validation Loss Energy: 3.3492360966733865, Validation Loss Force: 2.6498187264963033, time: 0.04174447059631348
Test Loss Energy: 12.632764941671095, Test Loss Force: 10.335244287701638, time: 7.5369672775268555

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‡â–…â–â–„â–„â–…â–ˆâ–‚â–„â–‚â–‚â–ƒâ–ƒâ–…â–‚â–…â–†â–‚
wandb:   test_error_force â–ˆâ–†â–‡â–†â–…â–…â–„â–…â–†â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–
wandb:          test_loss â–ƒâ–…â–ˆâ–†â–†â–„â–…â–†â–ˆâ–â–ƒâ–â–ƒâ–ƒâ–„â–„â–‚â–ƒâ–„â–‚
wandb: train_error_energy â–ˆâ–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚
wandb: valid_error_energy â–„â–‚â–…â–‚â–ˆâ–â–â–‚â–…â–„â–â–ƒâ–…â–ƒâ–â–‚â–ƒâ–â–ƒâ–…
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–‡â–ƒâ–â–„â–‡â–‚â–‚â–ˆâ–…â–„â–†â–„â–„â–…â–…â–„
wandb:         valid_loss â–…â–‚â–„â–‚â–ˆâ–‚â–â–ƒâ–†â–‚â–â–…â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 931
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.63276
wandb:   test_error_force 10.33524
wandb:          test_loss 8.3082
wandb: train_error_energy 2.26026
wandb:  train_error_force 1.87966
wandb:         train_loss -2.52887
wandb: valid_error_energy 3.34924
wandb:  valid_error_force 2.64982
wandb:         valid_loss -1.44029
wandb: 
wandb: ğŸš€ View run al_69_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/x8zffvln
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_153410-x8zffvln/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.27521514892578, Uncertainty Bias: -4.584943771362305
3.4332275e-05 0.11149025
-4.8581133 76.75987
(48745, 22, 3)
Found uncertainty sample 0 after 252 steps.
Found uncertainty sample 1 after 10 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 39 steps.
Found uncertainty sample 4 after 14 steps.
Found uncertainty sample 5 after 210 steps.
Found uncertainty sample 6 after 101 steps.
Found uncertainty sample 7 after 54 steps.
Found uncertainty sample 8 after 234 steps.
Found uncertainty sample 9 after 49 steps.
Found uncertainty sample 10 after 274 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 153 steps.
Found uncertainty sample 13 after 34 steps.
Found uncertainty sample 14 after 13 steps.
Found uncertainty sample 15 after 162 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 190 steps.
Found uncertainty sample 18 after 489 steps.
Found uncertainty sample 19 after 38 steps.
Found uncertainty sample 20 after 196 steps.
Found uncertainty sample 21 after 20 steps.
Found uncertainty sample 22 after 122 steps.
Found uncertainty sample 23 after 354 steps.
Found uncertainty sample 24 after 35 steps.
Found uncertainty sample 25 after 329 steps.
Found uncertainty sample 26 after 409 steps.
Found uncertainty sample 27 after 6 steps.
Found uncertainty sample 28 after 223 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 101 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 170 steps.
Found uncertainty sample 33 after 2 steps.
Found uncertainty sample 34 after 713 steps.
Found uncertainty sample 35 after 45 steps.
Found uncertainty sample 36 after 16 steps.
Found uncertainty sample 37 after 166 steps.
Found uncertainty sample 38 after 18 steps.
Found uncertainty sample 39 after 9 steps.
Found uncertainty sample 40 after 14 steps.
Found uncertainty sample 41 after 12 steps.
Found uncertainty sample 42 after 67 steps.
Found uncertainty sample 43 after 75 steps.
Found uncertainty sample 44 after 14 steps.
Found uncertainty sample 45 after 82 steps.
Found uncertainty sample 46 after 35 steps.
Found uncertainty sample 47 after 119 steps.
Found uncertainty sample 48 after 38 steps.
Found uncertainty sample 49 after 3 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 105 steps.
Found uncertainty sample 52 after 3 steps.
Found uncertainty sample 53 after 18 steps.
Found uncertainty sample 54 after 35 steps.
Found uncertainty sample 55 after 156 steps.
Found uncertainty sample 56 after 738 steps.
Found uncertainty sample 57 after 423 steps.
Found uncertainty sample 58 after 100 steps.
Found uncertainty sample 59 after 568 steps.
Found uncertainty sample 60 after 348 steps.
Found uncertainty sample 61 after 349 steps.
Found uncertainty sample 62 after 17 steps.
Found uncertainty sample 63 after 55 steps.
Found uncertainty sample 64 after 3 steps.
Found uncertainty sample 65 after 154 steps.
Found uncertainty sample 66 after 27 steps.
Found uncertainty sample 67 after 23 steps.
Found uncertainty sample 68 after 31 steps.
Found uncertainty sample 69 after 160 steps.
Found uncertainty sample 70 after 6 steps.
Found uncertainty sample 71 after 10 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 196 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 385 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 101 steps.
Found uncertainty sample 78 after 26 steps.
Found uncertainty sample 79 after 6 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 157 steps.
Found uncertainty sample 82 after 8 steps.
Found uncertainty sample 83 after 17 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 414 steps.
Found uncertainty sample 87 after 130 steps.
Found uncertainty sample 88 after 355 steps.
Found uncertainty sample 89 after 92 steps.
Found uncertainty sample 90 after 117 steps.
Found uncertainty sample 91 after 336 steps.
Found uncertainty sample 92 after 205 steps.
Found uncertainty sample 93 after 111 steps.
Found uncertainty sample 94 after 26 steps.
Found uncertainty sample 95 after 147 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 49 steps.
Found uncertainty sample 98 after 110 steps.
Found uncertainty sample 99 after 68 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_154042-7kw28u9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7kw28u9r
Training model 2. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.619431717525369, Training Loss Force: 2.3434433742474874, time: 0.4815361499786377
Validation Loss Energy: 2.1359724865205627, Validation Loss Force: 2.6437590083590243, time: 0.041941165924072266
Test Loss Energy: 14.195723245479194, Test Loss Force: 10.33072429056843, time: 8.103510618209839


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1843808510442075, Training Loss Force: 1.9217045952805492, time: 0.48520851135253906
Validation Loss Energy: 2.159171716827341, Validation Loss Force: 2.710787097335353, time: 0.04323744773864746
Test Loss Energy: 12.840047836144402, Test Loss Force: 10.308919739713618, time: 8.009197235107422


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6793923531618173, Training Loss Force: 1.8744344336695606, time: 0.485851526260376
Validation Loss Energy: 2.1653583563777987, Validation Loss Force: 2.565879361225051, time: 0.03970193862915039
Test Loss Energy: 13.827736344439534, Test Loss Force: 10.351947709926584, time: 7.995299577713013


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8355062149922028, Training Loss Force: 1.837110572282653, time: 0.46965765953063965
Validation Loss Energy: 2.900005770816139, Validation Loss Force: 2.620907809927331, time: 0.04014015197753906
Test Loss Energy: 14.590938456108871, Test Loss Force: 10.414815925395478, time: 8.602144718170166


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9509830655461349, Training Loss Force: 1.8763087024965324, time: 0.4685056209564209
Validation Loss Energy: 2.16277628496162, Validation Loss Force: 2.6155802279418627, time: 0.03990912437438965
Test Loss Energy: 13.932879973693352, Test Loss Force: 10.334944819850696, time: 8.026817083358765


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7935397523611791, Training Loss Force: 1.8858272970417507, time: 0.4763636589050293
Validation Loss Energy: 1.8027604677772273, Validation Loss Force: 2.5953654321979545, time: 0.04025864601135254
Test Loss Energy: 13.295134154191707, Test Loss Force: 10.281431245306901, time: 8.061872243881226


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.077917525745243, Training Loss Force: 1.8607454408566177, time: 0.4603722095489502
Validation Loss Energy: 2.013239925314917, Validation Loss Force: 2.627004936481126, time: 0.04804062843322754
Test Loss Energy: 14.239718541757577, Test Loss Force: 10.331601597676931, time: 8.225216150283813


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3173374052533435, Training Loss Force: 1.8776123259697775, time: 0.5048713684082031
Validation Loss Energy: 2.548445035106343, Validation Loss Force: 2.605185586871662, time: 0.040463924407958984
Test Loss Energy: 12.888540391655352, Test Loss Force: 10.255644073745465, time: 7.955371141433716


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3863646978435358, Training Loss Force: 1.8551904058177895, time: 0.4930403232574463
Validation Loss Energy: 2.1779115521486236, Validation Loss Force: 2.5566481664423226, time: 0.039990901947021484
Test Loss Energy: 13.078502457154986, Test Loss Force: 10.251416843404295, time: 8.097972631454468


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.3710734126485504, Training Loss Force: 1.8738226641079458, time: 0.5027987957000732
Validation Loss Energy: 3.572037730743001, Validation Loss Force: 2.587382965985589, time: 0.04098820686340332
Test Loss Energy: 15.160514132906028, Test Loss Force: 10.35379440424736, time: 8.012653112411499


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3219258404881096, Training Loss Force: 1.9245071230680182, time: 0.5020530223846436
Validation Loss Energy: 3.1429320196255612, Validation Loss Force: 2.661959093670578, time: 0.04106426239013672
Test Loss Energy: 12.7090901937877, Test Loss Force: 10.202709462297223, time: 8.229500770568848


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.34448585900064, Training Loss Force: 1.8577118903510434, time: 0.49016833305358887
Validation Loss Energy: 3.313922328813261, Validation Loss Force: 2.6026304584221402, time: 0.04223322868347168
Test Loss Energy: 15.327666735866242, Test Loss Force: 10.323423694405442, time: 8.006489276885986


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3986689721240486, Training Loss Force: 1.8996123855079836, time: 0.47083282470703125
Validation Loss Energy: 2.9248480767507186, Validation Loss Force: 2.6805232430357235, time: 0.04583120346069336
Test Loss Energy: 14.527698222284902, Test Loss Force: 10.289565295580521, time: 8.042105674743652


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8013845551136773, Training Loss Force: 1.829592607825515, time: 0.5052611827850342
Validation Loss Energy: 1.7977927191315783, Validation Loss Force: 2.615736319013158, time: 0.04675102233886719
Test Loss Energy: 13.43148686710381, Test Loss Force: 10.236219186887377, time: 8.53838324546814


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.887267303627274, Training Loss Force: 1.883144099041267, time: 0.472243070602417
Validation Loss Energy: 2.0771426301590035, Validation Loss Force: 2.6278294803284963, time: 0.043056488037109375
Test Loss Energy: 13.836705308414205, Test Loss Force: 10.214023116057213, time: 8.129191398620605


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9580902141270498, Training Loss Force: 1.8937773718517943, time: 0.490570068359375
Validation Loss Energy: 2.9626857993799356, Validation Loss Force: 2.5883014762125414, time: 0.042160749435424805
Test Loss Energy: 12.471052591284192, Test Loss Force: 10.187153935659556, time: 7.984966993331909


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.161943498876645, Training Loss Force: 1.8602649869446082, time: 0.47250843048095703
Validation Loss Energy: 4.252751783338734, Validation Loss Force: 2.6177857658322776, time: 0.03975629806518555
Test Loss Energy: 12.170209848136247, Test Loss Force: 10.228911488627858, time: 8.087997674942017


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.800061323089781, Training Loss Force: 1.9218594721091582, time: 0.4836752414703369
Validation Loss Energy: 2.802408102802822, Validation Loss Force: 2.673217023019541, time: 0.04780459403991699
Test Loss Energy: 14.476088508576233, Test Loss Force: 10.227081838406106, time: 8.321096420288086


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9650230632151817, Training Loss Force: 1.8759197029778019, time: 0.48204922676086426
Validation Loss Energy: 4.3718806670866845, Validation Loss Force: 2.6252774692470178, time: 0.04027962684631348
Test Loss Energy: 16.029659207099172, Test Loss Force: 10.240568980854986, time: 8.046969652175903


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7950255296334094, Training Loss Force: 1.8475628707448277, time: 0.46419835090637207
Validation Loss Energy: 1.8016765143748508, Validation Loss Force: 2.591120244930841, time: 0.04157137870788574
Test Loss Energy: 13.572791331457271, Test Loss Force: 10.185368413566133, time: 8.02170467376709

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–„â–…â–„â–ƒâ–…â–‚â–ƒâ–†â–‚â–‡â–…â–ƒâ–„â–‚â–â–…â–ˆâ–„
wandb:   test_error_force â–…â–…â–†â–ˆâ–†â–„â–…â–ƒâ–ƒâ–†â–‚â–…â–„â–ƒâ–‚â–â–‚â–‚â–ƒâ–
wandb:          test_loss â–â–ƒâ–…â–‡â–‡â–†â–ˆâ–†â–†â–ˆâ–†â–ˆâ–‡â–‡â–‡â–…â–†â–…â–†â–„
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚â–‚â–„â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–
wandb: valid_error_energy â–‚â–‚â–‚â–„â–‚â–â–‚â–ƒâ–‚â–†â–…â–…â–„â–â–‚â–„â–ˆâ–„â–ˆâ–
wandb:  valid_error_force â–…â–ˆâ–â–„â–„â–ƒâ–„â–ƒâ–â–‚â–†â–ƒâ–‡â–„â–„â–‚â–„â–†â–„â–ƒ
wandb:         valid_loss â–‚â–†â–â–…â–ƒâ–‚â–„â–„â–â–…â–‡â–…â–‡â–ƒâ–„â–„â–ˆâ–‡â–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1021
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.57279
wandb:   test_error_force 10.18537
wandb:          test_loss 8.5219
wandb: train_error_energy 1.79503
wandb:  train_error_force 1.84756
wandb:         train_loss -2.60482
wandb: valid_error_energy 1.80168
wandb:  valid_error_force 2.59112
wandb:         valid_loss -1.60848
wandb: 
wandb: ğŸš€ View run al_69_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7kw28u9r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_154042-7kw28u9r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 33.77214813232422, Uncertainty Bias: -4.084042549133301
0.00016021729 0.00050640106
-2.8455691 92.041504
(48745, 22, 3)
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 428 steps.
Found uncertainty sample 2 after 351 steps.
Found uncertainty sample 3 after 396 steps.
Found uncertainty sample 4 after 370 steps.
Found uncertainty sample 5 after 226 steps.
Found uncertainty sample 6 after 78 steps.
Found uncertainty sample 7 after 18 steps.
Found uncertainty sample 8 after 215 steps.
Found uncertainty sample 9 after 522 steps.
Found uncertainty sample 10 after 26 steps.
Found uncertainty sample 11 after 190 steps.
Found uncertainty sample 12 after 119 steps.
Found uncertainty sample 13 after 415 steps.
Found uncertainty sample 14 after 34 steps.
Found uncertainty sample 15 after 58 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 98 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 200 steps.
Found uncertainty sample 20 after 355 steps.
Found uncertainty sample 21 after 48 steps.
Found uncertainty sample 22 after 28 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 126 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 601 steps.
Found uncertainty sample 27 after 657 steps.
Found uncertainty sample 28 after 141 steps.
Found uncertainty sample 29 after 95 steps.
Found uncertainty sample 30 after 186 steps.
Found uncertainty sample 31 after 60 steps.
Found uncertainty sample 32 after 471 steps.
Found uncertainty sample 33 after 400 steps.
Found uncertainty sample 34 after 8 steps.
Found uncertainty sample 35 after 31 steps.
Found uncertainty sample 36 after 66 steps.
Found uncertainty sample 37 after 144 steps.
Found uncertainty sample 38 after 423 steps.
Found uncertainty sample 39 after 10 steps.
Found uncertainty sample 40 after 262 steps.
Found uncertainty sample 41 after 319 steps.
Found uncertainty sample 42 after 220 steps.
Found uncertainty sample 43 after 8 steps.
Found uncertainty sample 44 after 207 steps.
Found uncertainty sample 45 after 373 steps.
Found uncertainty sample 46 after 80 steps.
Found uncertainty sample 47 after 164 steps.
Found uncertainty sample 48 after 102 steps.
Found uncertainty sample 49 after 348 steps.
Found uncertainty sample 50 after 437 steps.
Found uncertainty sample 51 after 107 steps.
Found uncertainty sample 52 after 107 steps.
Found uncertainty sample 53 after 401 steps.
Found uncertainty sample 54 after 185 steps.
Found uncertainty sample 55 after 114 steps.
Found uncertainty sample 56 after 15 steps.
Found uncertainty sample 57 after 557 steps.
Found uncertainty sample 58 after 43 steps.
Found uncertainty sample 59 after 588 steps.
Found uncertainty sample 60 after 370 steps.
Found uncertainty sample 61 after 155 steps.
Found uncertainty sample 62 after 308 steps.
Found uncertainty sample 63 after 175 steps.
Found uncertainty sample 64 after 666 steps.
Found uncertainty sample 65 after 16 steps.
Found uncertainty sample 66 after 48 steps.
Found uncertainty sample 67 after 182 steps.
Found uncertainty sample 68 after 241 steps.
Found uncertainty sample 69 after 157 steps.
Found uncertainty sample 70 after 19 steps.
Found uncertainty sample 71 after 32 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 504 steps.
Found uncertainty sample 74 after 26 steps.
Found uncertainty sample 75 after 150 steps.
Found uncertainty sample 76 after 7 steps.
Found uncertainty sample 77 after 718 steps.
Found uncertainty sample 78 after 117 steps.
Found uncertainty sample 79 after 398 steps.
Found uncertainty sample 80 after 276 steps.
Found uncertainty sample 81 after 670 steps.
Found uncertainty sample 82 after 120 steps.
Found uncertainty sample 83 after 136 steps.
Found uncertainty sample 84 after 75 steps.
Found uncertainty sample 85 after 363 steps.
Found uncertainty sample 86 after 583 steps.
Found uncertainty sample 87 after 50 steps.
Found uncertainty sample 88 after 2 steps.
Found uncertainty sample 89 after 146 steps.
Found uncertainty sample 90 after 219 steps.
Found uncertainty sample 91 after 459 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 33 steps.
Found uncertainty sample 94 after 9 steps.
Found uncertainty sample 95 after 4 steps.
Found uncertainty sample 96 after 399 steps.
Found uncertainty sample 97 after 354 steps.
Found uncertainty sample 98 after 1340 steps.
Found uncertainty sample 99 after 211 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_154823-sceqzd91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/sceqzd91
Training model 3. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.322469666292559, Training Loss Force: 2.3573601110747675, time: 0.5198955535888672
Validation Loss Energy: 3.275229333994535, Validation Loss Force: 2.607897474399916, time: 0.04839730262756348
Test Loss Energy: 12.585318268967603, Test Loss Force: 10.162220829677333, time: 8.324678897857666


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.885014959241, Training Loss Force: 1.8530650382634666, time: 0.5109593868255615
Validation Loss Energy: 3.0582108629829565, Validation Loss Force: 2.6292788337993405, time: 0.3818359375
Test Loss Energy: 12.524147393947114, Test Loss Force: 10.200830055430712, time: 8.379610538482666


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0662665863477767, Training Loss Force: 1.9178842206833009, time: 0.5589320659637451
Validation Loss Energy: 4.156740410321007, Validation Loss Force: 2.62783037100508, time: 0.0437626838684082
Test Loss Energy: 15.555073162044609, Test Loss Force: 10.227875934870836, time: 8.362672567367554


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2168627429755103, Training Loss Force: 1.862177365894123, time: 0.6743111610412598
Validation Loss Energy: 1.7447935656907112, Validation Loss Force: 2.5814279023468965, time: 0.04462718963623047
Test Loss Energy: 13.56825384721836, Test Loss Force: 10.126516062957608, time: 8.307956457138062


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7026477947039913, Training Loss Force: 1.8879025740782327, time: 0.5227508544921875
Validation Loss Energy: 1.8481092660368805, Validation Loss Force: 2.6621949002961154, time: 0.043901920318603516
Test Loss Energy: 13.330461656424648, Test Loss Force: 10.183778350682168, time: 8.84772539138794


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9503623319609025, Training Loss Force: 1.914441195833405, time: 0.5860555171966553
Validation Loss Energy: 2.5355600623080856, Validation Loss Force: 2.7078166909286763, time: 0.05196237564086914
Test Loss Energy: 12.72017891207287, Test Loss Force: 10.17220383127417, time: 9.557498693466187


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.053867172251105, Training Loss Force: 1.883262365384268, time: 0.5320701599121094
Validation Loss Energy: 1.8791525736818302, Validation Loss Force: 2.5835405872034594, time: 0.05106854438781738
Test Loss Energy: 13.39983285085452, Test Loss Force: 10.150545304746805, time: 9.835418939590454


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8348485295119064, Training Loss Force: 1.8834275540806682, time: 0.5411992073059082
Validation Loss Energy: 2.6207336826552154, Validation Loss Force: 2.67465078965017, time: 0.051157236099243164
Test Loss Energy: 12.749070375985456, Test Loss Force: 10.189790142491754, time: 9.740971803665161


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7186749758789597, Training Loss Force: 1.8245595735803384, time: 0.5281059741973877
Validation Loss Energy: 2.9494205076804336, Validation Loss Force: 2.5706852294016103, time: 0.04877328872680664
Test Loss Energy: 14.859578917943132, Test Loss Force: 10.105011390317813, time: 9.606251001358032


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9785685961126465, Training Loss Force: 1.8521816429608269, time: 0.5637452602386475
Validation Loss Energy: 2.4433031137598467, Validation Loss Force: 2.631661393660768, time: 0.053554534912109375
Test Loss Energy: 13.072907310794221, Test Loss Force: 10.157601967443334, time: 9.730908155441284


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7031010011691678, Training Loss Force: 1.8795812690455218, time: 0.5751104354858398
Validation Loss Energy: 1.9302774095868502, Validation Loss Force: 2.5655669564133143, time: 0.045282840728759766
Test Loss Energy: 13.123748771648778, Test Loss Force: 10.072248295192678, time: 9.298197507858276


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7308910919156915, Training Loss Force: 1.8456206774901378, time: 0.5444097518920898
Validation Loss Energy: 3.8387933635421776, Validation Loss Force: 2.6717202410206147, time: 0.05011248588562012
Test Loss Energy: 12.276075433714743, Test Loss Force: 10.082189066595054, time: 9.646166324615479


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.298966155014264, Training Loss Force: 1.904838875204171, time: 0.5281379222869873
Validation Loss Energy: 1.9529500273635094, Validation Loss Force: 2.640263325437104, time: 0.047393083572387695
Test Loss Energy: 13.36060480539427, Test Loss Force: 10.072876432029462, time: 9.60843276977539


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7397956962715937, Training Loss Force: 1.8481183064042053, time: 0.557711124420166
Validation Loss Energy: 1.7988868039800945, Validation Loss Force: 2.681983061956426, time: 0.051497459411621094
Test Loss Energy: 13.472852797505743, Test Loss Force: 10.170077725646886, time: 9.388981819152832


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8361931950837926, Training Loss Force: 1.8550870045289904, time: 0.5371818542480469
Validation Loss Energy: 2.0029347972413793, Validation Loss Force: 2.5892645202686793, time: 0.049790143966674805
Test Loss Energy: 13.083000588411226, Test Loss Force: 10.092789321054088, time: 9.530703783035278


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6645108985817874, Training Loss Force: 1.839015652157446, time: 0.5876708030700684
Validation Loss Energy: 1.7773129471040159, Validation Loss Force: 2.5973955068013783, time: 0.05011248588562012
Test Loss Energy: 14.11098318410952, Test Loss Force: 10.058948968922252, time: 9.635091781616211


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0700840548144526, Training Loss Force: 1.884348214655373, time: 0.5683753490447998
Validation Loss Energy: 3.0318448320827933, Validation Loss Force: 2.5522856325353054, time: 0.0494542121887207
Test Loss Energy: 14.82552173969029, Test Loss Force: 10.077747290451457, time: 9.51650333404541


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9609288990596614, Training Loss Force: 1.8250493248238435, time: 0.5648226737976074
Validation Loss Energy: 3.6930880265511625, Validation Loss Force: 2.6105824189615134, time: 0.05018329620361328
Test Loss Energy: 12.361064525459287, Test Loss Force: 9.998904645893626, time: 9.565373182296753


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8316794815506414, Training Loss Force: 1.8230660489129182, time: 0.5546321868896484
Validation Loss Energy: 1.786125301223254, Validation Loss Force: 2.565327587081442, time: 0.0520782470703125
Test Loss Energy: 13.575195794501493, Test Loss Force: 10.081379968525246, time: 9.661748886108398


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7229962873650904, Training Loss Force: 1.8396620638690617, time: 0.5274345874786377
Validation Loss Energy: 2.0292805652492634, Validation Loss Force: 2.574461030109108, time: 0.05323457717895508
Test Loss Energy: 13.059279763207858, Test Loss Force: 10.078038005423087, time: 9.600029468536377

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–‡â–ƒâ–ƒâ–â–ƒâ–„â–ƒâ–…â–†â–â–„â–ƒ
wandb:   test_error_force â–†â–‡â–ˆâ–…â–‡â–†â–†â–‡â–„â–†â–ƒâ–„â–ƒâ–†â–„â–ƒâ–ƒâ–â–„â–ƒ
wandb:          test_loss â–â–„â–†â–…â–†â–†â–…â–‡â–‡â–‡â–‡â–‡â–†â–ˆâ–‡â–‡â–ˆâ–‡â–ˆâ–ˆ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–ƒâ–â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–…â–…â–ˆâ–â–â–ƒâ–â–„â–„â–ƒâ–‚â–‡â–‚â–â–‚â–â–…â–‡â–â–‚
wandb:  valid_error_force â–„â–„â–„â–‚â–†â–ˆâ–‚â–‡â–‚â–…â–‚â–†â–…â–‡â–ƒâ–ƒâ–â–„â–‚â–‚
wandb:         valid_loss â–ƒâ–„â–†â–â–„â–‡â–â–†â–ƒâ–„â–â–ˆâ–„â–…â–‚â–‚â–ƒâ–†â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1111
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.05928
wandb:   test_error_force 10.07804
wandb:          test_loss 8.80792
wandb: train_error_energy 1.723
wandb:  train_error_force 1.83966
wandb:         train_loss -2.62109
wandb: valid_error_energy 2.02928
wandb:  valid_error_force 2.57446
wandb:         valid_loss -1.58804
wandb: 
wandb: ğŸš€ View run al_69_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/sceqzd91
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_154823-sceqzd91/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 27.069236755371094, Uncertainty Bias: -3.153153896331787
3.0517578e-05 0.0103645325
-1.0109322 98.7419
(48745, 22, 3)
Found uncertainty sample 0 after 960 steps.
Found uncertainty sample 1 after 943 steps.
Found uncertainty sample 2 after 639 steps.
Found uncertainty sample 3 after 935 steps.
Found uncertainty sample 4 after 751 steps.
Found uncertainty sample 5 after 1635 steps.
Found uncertainty sample 6 after 639 steps.
Found uncertainty sample 7 after 644 steps.
Found uncertainty sample 8 after 1000 steps.
Found uncertainty sample 9 after 439 steps.
Found uncertainty sample 10 after 158 steps.
Found uncertainty sample 11 after 1305 steps.
Found uncertainty sample 12 after 142 steps.
Found uncertainty sample 13 after 1140 steps.
Found uncertainty sample 14 after 1669 steps.
Found uncertainty sample 15 after 868 steps.
Found uncertainty sample 16 after 313 steps.
Found uncertainty sample 17 after 635 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2453 steps.
Found uncertainty sample 20 after 2950 steps.
Found uncertainty sample 21 after 345 steps.
Found uncertainty sample 22 after 1947 steps.
Found uncertainty sample 23 after 34 steps.
Found uncertainty sample 24 after 1340 steps.
Found uncertainty sample 25 after 13 steps.
Found uncertainty sample 26 after 362 steps.
Found uncertainty sample 27 after 463 steps.
Found uncertainty sample 28 after 1239 steps.
Found uncertainty sample 29 after 1456 steps.
Found uncertainty sample 30 after 2467 steps.
Found uncertainty sample 31 after 302 steps.
Found uncertainty sample 32 after 159 steps.
Found uncertainty sample 33 after 1692 steps.
Found uncertainty sample 34 after 2754 steps.
Found uncertainty sample 35 after 223 steps.
Found uncertainty sample 36 after 1382 steps.
Found uncertainty sample 37 after 658 steps.
Found uncertainty sample 38 after 108 steps.
Found uncertainty sample 39 after 553 steps.
Found uncertainty sample 40 after 1071 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 286 steps.
Found uncertainty sample 43 after 749 steps.
Found uncertainty sample 44 after 1150 steps.
Found uncertainty sample 45 after 177 steps.
Found uncertainty sample 46 after 320 steps.
Found uncertainty sample 47 after 1454 steps.
Found uncertainty sample 48 after 1010 steps.
Found uncertainty sample 49 after 347 steps.
Found uncertainty sample 50 after 3246 steps.
Found uncertainty sample 51 after 1760 steps.
Found uncertainty sample 52 after 2855 steps.
Found uncertainty sample 53 after 1433 steps.
Found uncertainty sample 54 after 123 steps.
Found uncertainty sample 55 after 2961 steps.
Found uncertainty sample 56 after 859 steps.
Found uncertainty sample 57 after 791 steps.
Found uncertainty sample 58 after 34 steps.
Found uncertainty sample 59 after 122 steps.
Found uncertainty sample 60 after 2821 steps.
Found uncertainty sample 61 after 1344 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 561 steps.
Found uncertainty sample 64 after 36 steps.
Found uncertainty sample 65 after 1508 steps.
Found uncertainty sample 66 after 57 steps.
Found uncertainty sample 67 after 1242 steps.
Found uncertainty sample 68 after 1408 steps.
Found uncertainty sample 69 after 1568 steps.
Found uncertainty sample 70 after 19 steps.
Found uncertainty sample 71 after 568 steps.
Found uncertainty sample 72 after 676 steps.
Found uncertainty sample 73 after 1032 steps.
Found uncertainty sample 74 after 100 steps.
Found uncertainty sample 75 after 30 steps.
Found uncertainty sample 76 after 3063 steps.
Found uncertainty sample 77 after 850 steps.
Found uncertainty sample 78 after 87 steps.
Found uncertainty sample 79 after 1589 steps.
Found uncertainty sample 80 after 1016 steps.
Found uncertainty sample 81 after 222 steps.
Found uncertainty sample 82 after 2008 steps.
Found uncertainty sample 83 after 317 steps.
Found uncertainty sample 84 after 83 steps.
Found uncertainty sample 85 after 238 steps.
Found uncertainty sample 86 after 1248 steps.
Found uncertainty sample 87 after 1429 steps.
Found uncertainty sample 88 after 807 steps.
Found uncertainty sample 89 after 896 steps.
Found uncertainty sample 90 after 1296 steps.
Found uncertainty sample 91 after 1657 steps.
Found uncertainty sample 92 after 52 steps.
Found uncertainty sample 93 after 45 steps.
Found uncertainty sample 94 after 125 steps.
Found uncertainty sample 95 after 31 steps.
Found uncertainty sample 96 after 499 steps.
Found uncertainty sample 97 after 1324 steps.
Found uncertainty sample 98 after 385 steps.
Found uncertainty sample 99 after 3768 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_160445-5aqel9vy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5aqel9vy
Training model 4. Added 97 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5124846156968967, Training Loss Force: 2.2647853686191994, time: 0.5902233123779297
Validation Loss Energy: 1.702786474638569, Validation Loss Force: 2.5733089399480775, time: 0.048404693603515625
Test Loss Energy: 13.170128572354741, Test Loss Force: 10.153679036057502, time: 8.323293447494507


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8056117666998326, Training Loss Force: 1.9347282376699422, time: 0.5585229396820068
Validation Loss Energy: 1.8368752736211047, Validation Loss Force: 2.576070260026728, time: 0.04574251174926758
Test Loss Energy: 13.76343605625765, Test Loss Force: 10.109714591696802, time: 8.290306568145752


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2979993649682977, Training Loss Force: 1.9264340434428495, time: 0.5561728477478027
Validation Loss Energy: 1.7269279294363409, Validation Loss Force: 2.63178430702932, time: 0.04703950881958008
Test Loss Energy: 13.63179244370819, Test Loss Force: 10.137652304201222, time: 8.272690057754517


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7044696541514948, Training Loss Force: 1.9141996366425638, time: 0.7497284412384033
Validation Loss Energy: 1.9595120870940013, Validation Loss Force: 2.5652182565307915, time: 0.06382632255554199
Test Loss Energy: 13.218538197015619, Test Loss Force: 10.027520130635654, time: 8.325637817382812


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8976407606397856, Training Loss Force: 1.9069622770597592, time: 0.5687565803527832
Validation Loss Energy: 2.066881367907213, Validation Loss Force: 2.6219015823256067, time: 0.04975247383117676
Test Loss Energy: 14.174956593985181, Test Loss Force: 10.081999762846804, time: 8.270646095275879


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5467522015545443, Training Loss Force: 1.9037144102479708, time: 0.5712664127349854
Validation Loss Energy: 1.814787273687079, Validation Loss Force: 2.587994638129453, time: 0.04596138000488281
Test Loss Energy: 13.715101117859417, Test Loss Force: 10.050309709170085, time: 8.222514867782593


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.097696602284661, Training Loss Force: 1.9280429686553224, time: 0.543980598449707
Validation Loss Energy: 3.060365186969808, Validation Loss Force: 2.6012837554275694, time: 0.04813742637634277
Test Loss Energy: 12.93731085225011, Test Loss Force: 10.104837978851224, time: 8.457109212875366


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8196533621481834, Training Loss Force: 1.9218301391115036, time: 0.5514516830444336
Validation Loss Energy: 3.109092989518915, Validation Loss Force: 2.589440651563108, time: 0.04885721206665039
Test Loss Energy: 14.637178355306002, Test Loss Force: 10.0914910223681, time: 8.278127670288086


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9144261219274725, Training Loss Force: 1.8850286483708625, time: 0.5946235656738281
Validation Loss Energy: 1.8336916615072023, Validation Loss Force: 2.558676459692579, time: 0.046244144439697266
Test Loss Energy: 14.195622710942711, Test Loss Force: 10.021601104424391, time: 8.241519212722778


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8104446672036938, Training Loss Force: 1.8971809459235875, time: 0.5663938522338867
Validation Loss Energy: 2.0210092971546296, Validation Loss Force: 2.5739444376905554, time: 0.0476231575012207
Test Loss Energy: 13.959407955011027, Test Loss Force: 10.035511364882819, time: 8.517716646194458


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.841566566802656, Training Loss Force: 1.8997208479053274, time: 0.5636839866638184
Validation Loss Energy: 2.9601540511907367, Validation Loss Force: 2.5321779406505884, time: 0.04619717597961426
Test Loss Energy: 12.993808491795942, Test Loss Force: 10.059757824504194, time: 8.690560579299927


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6438246692289042, Training Loss Force: 1.9123239303544117, time: 0.5833432674407959
Validation Loss Energy: 2.8205030882774977, Validation Loss Force: 2.669572819777287, time: 0.048261404037475586
Test Loss Energy: 12.310789838021805, Test Loss Force: 10.034970514351238, time: 8.287520170211792


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7161785910659628, Training Loss Force: 1.9203763762055994, time: 0.5685994625091553
Validation Loss Energy: 2.7469514613329227, Validation Loss Force: 2.6175052027084087, time: 0.050444841384887695
Test Loss Energy: 14.605765507228856, Test Loss Force: 10.046645521663436, time: 8.300325870513916


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6426245440593548, Training Loss Force: 1.8950549419362692, time: 0.5667917728424072
Validation Loss Energy: 2.1004816966894246, Validation Loss Force: 2.5063474290463814, time: 0.05050063133239746
Test Loss Energy: 13.58724637821187, Test Loss Force: 9.988111660213624, time: 8.415392875671387


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.264860768493811, Training Loss Force: 1.882584872073448, time: 0.5428144931793213
Validation Loss Energy: 2.8641644997493105, Validation Loss Force: 2.5585266033573695, time: 0.04584383964538574
Test Loss Energy: 13.190715260546565, Test Loss Force: 10.014439397849722, time: 8.277169466018677


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6797669647012692, Training Loss Force: 1.876561460726384, time: 0.564690351486206
Validation Loss Energy: 1.939637084466779, Validation Loss Force: 2.5622338219679213, time: 0.045575857162475586
Test Loss Energy: 14.07420620599599, Test Loss Force: 10.049653415761508, time: 8.332998752593994


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6284973220698948, Training Loss Force: 1.8979174827208873, time: 0.5513613224029541
Validation Loss Energy: 2.2522347276838386, Validation Loss Force: 2.6813005810241575, time: 0.04679250717163086
Test Loss Energy: 13.122092863982813, Test Loss Force: 10.023143070772836, time: 8.426734924316406


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.745623689451087, Training Loss Force: 2.0003705247075887, time: 0.5453567504882812
Validation Loss Energy: 2.22355382834261, Validation Loss Force: 2.5939156333888187, time: 0.049039363861083984
Test Loss Energy: 13.132125804090306, Test Loss Force: 10.045490994965679, time: 8.31372594833374


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9697292403458972, Training Loss Force: 1.8905058112849646, time: 0.5768458843231201
Validation Loss Energy: 2.722984690480131, Validation Loss Force: 2.5799257762884675, time: 0.0468442440032959
Test Loss Energy: 14.785162702844937, Test Loss Force: 10.106201525426009, time: 8.344910144805908


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.956890853741783, Training Loss Force: 1.9132972699286914, time: 0.5661239624023438
Validation Loss Energy: 2.173223698619406, Validation Loss Force: 2.5923959164678614, time: 0.049086809158325195
Test Loss Energy: 12.950151591997402, Test Loss Force: 10.004388117265771, time: 8.388395547866821

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–…â–„â–†â–…â–ƒâ–ˆâ–†â–†â–ƒâ–â–‡â–…â–ƒâ–†â–ƒâ–ƒâ–ˆâ–ƒ
wandb:   test_error_force â–ˆâ–†â–‡â–ƒâ–…â–„â–†â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–â–‚â–„â–‚â–ƒâ–†â–‚
wandb:          test_loss â–ƒâ–ƒâ–„â–ƒâ–†â–‡â–†â–‡â–‡â–‡â–†â–†â–ˆâ–‡â–„â–ˆâ–ƒâ–ƒâ–‡â–
wandb: train_error_energy â–ˆâ–‚â–„â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–„â–â–â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–ƒâ–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–‚â–â–â–â–â–ƒâ–â–‚
wandb: valid_error_energy â–â–‚â–â–‚â–ƒâ–‚â–ˆâ–ˆâ–‚â–ƒâ–‡â–‡â–†â–ƒâ–‡â–‚â–„â–„â–†â–ƒ
wandb:  valid_error_force â–„â–„â–†â–ƒâ–†â–„â–…â–„â–ƒâ–„â–‚â–ˆâ–…â–â–ƒâ–ƒâ–ˆâ–…â–„â–„
wandb:         valid_loss â–‚â–‚â–„â–‚â–…â–ƒâ–†â–…â–‚â–ƒâ–ƒâ–ˆâ–†â–â–„â–ƒâ–‡â–„â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1198
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.95015
wandb:   test_error_force 10.00439
wandb:          test_loss 8.17596
wandb: train_error_energy 1.95689
wandb:  train_error_force 1.9133
wandb:         train_loss -2.50735
wandb: valid_error_energy 2.17322
wandb:  valid_error_force 2.5924
wandb:         valid_loss -1.60104
wandb: 
wandb: ğŸš€ View run al_69_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5aqel9vy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_160445-5aqel9vy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.877323150634766, Uncertainty Bias: -4.687611103057861
0.00011444092 0.01004982
-3.0261912 91.25822
(48745, 22, 3)
Found uncertainty sample 0 after 496 steps.
Found uncertainty sample 1 after 16 steps.
Found uncertainty sample 2 after 852 steps.
Found uncertainty sample 3 after 389 steps.
Found uncertainty sample 4 after 693 steps.
Found uncertainty sample 5 after 141 steps.
Found uncertainty sample 6 after 1591 steps.
Found uncertainty sample 7 after 498 steps.
Found uncertainty sample 8 after 356 steps.
Found uncertainty sample 9 after 472 steps.
Found uncertainty sample 10 after 167 steps.
Found uncertainty sample 11 after 44 steps.
Found uncertainty sample 12 after 112 steps.
Found uncertainty sample 13 after 323 steps.
Found uncertainty sample 14 after 2974 steps.
Found uncertainty sample 15 after 51 steps.
Found uncertainty sample 16 after 176 steps.
Found uncertainty sample 17 after 2 steps.
Found uncertainty sample 18 after 437 steps.
Found uncertainty sample 19 after 391 steps.
Found uncertainty sample 20 after 48 steps.
Found uncertainty sample 21 after 165 steps.
Found uncertainty sample 22 after 118 steps.
Found uncertainty sample 23 after 168 steps.
Found uncertainty sample 24 after 704 steps.
Found uncertainty sample 25 after 35 steps.
Found uncertainty sample 26 after 28 steps.
Found uncertainty sample 27 after 148 steps.
Found uncertainty sample 28 after 696 steps.
Found uncertainty sample 29 after 2 steps.
Found uncertainty sample 30 after 49 steps.
Found uncertainty sample 31 after 154 steps.
Found uncertainty sample 32 after 218 steps.
Found uncertainty sample 33 after 397 steps.
Found uncertainty sample 34 after 648 steps.
Found uncertainty sample 35 after 42 steps.
Found uncertainty sample 36 after 561 steps.
Found uncertainty sample 37 after 29 steps.
Found uncertainty sample 38 after 2123 steps.
Found uncertainty sample 39 after 8 steps.
Found uncertainty sample 40 after 40 steps.
Found uncertainty sample 41 after 118 steps.
Found uncertainty sample 42 after 879 steps.
Found uncertainty sample 43 after 31 steps.
Found uncertainty sample 44 after 1598 steps.
Found uncertainty sample 45 after 131 steps.
Found uncertainty sample 46 after 689 steps.
Found uncertainty sample 47 after 119 steps.
Found uncertainty sample 48 after 14 steps.
Found uncertainty sample 49 after 352 steps.
Found uncertainty sample 50 after 308 steps.
Found uncertainty sample 51 after 593 steps.
Found uncertainty sample 52 after 140 steps.
Found uncertainty sample 53 after 111 steps.
Found uncertainty sample 54 after 116 steps.
Found uncertainty sample 55 after 311 steps.
Found uncertainty sample 56 after 2321 steps.
Found uncertainty sample 57 after 64 steps.
Found uncertainty sample 58 after 180 steps.
Found uncertainty sample 59 after 369 steps.
Found uncertainty sample 60 after 760 steps.
Found uncertainty sample 61 after 457 steps.
Found uncertainty sample 62 after 102 steps.
Found uncertainty sample 63 after 86 steps.
Found uncertainty sample 64 after 1475 steps.
Found uncertainty sample 65 after 371 steps.
Found uncertainty sample 66 after 33 steps.
Found uncertainty sample 67 after 419 steps.
Found uncertainty sample 68 after 196 steps.
Found uncertainty sample 69 after 68 steps.
Found uncertainty sample 70 after 84 steps.
Found uncertainty sample 71 after 158 steps.
Found uncertainty sample 72 after 1077 steps.
Found uncertainty sample 73 after 165 steps.
Found uncertainty sample 74 after 1807 steps.
Found uncertainty sample 75 after 489 steps.
Found uncertainty sample 76 after 1673 steps.
Found uncertainty sample 77 after 219 steps.
Found uncertainty sample 78 after 543 steps.
Found uncertainty sample 79 after 1651 steps.
Found uncertainty sample 80 after 292 steps.
Found uncertainty sample 81 after 979 steps.
Found uncertainty sample 82 after 1985 steps.
Found uncertainty sample 83 after 533 steps.
Found uncertainty sample 84 after 800 steps.
Found uncertainty sample 85 after 45 steps.
Found uncertainty sample 86 after 612 steps.
Found uncertainty sample 87 after 366 steps.
Found uncertainty sample 88 after 370 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 823 steps.
Found uncertainty sample 91 after 162 steps.
Found uncertainty sample 92 after 1333 steps.
Found uncertainty sample 93 after 3 steps.
Found uncertainty sample 94 after 634 steps.
Found uncertainty sample 95 after 251 steps.
Found uncertainty sample 96 after 605 steps.
Found uncertainty sample 97 after 110 steps.
Found uncertainty sample 98 after 343 steps.
Found uncertainty sample 99 after 37 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_161518-69ml324m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/69ml324m
Training model 5. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.8760922534378786, Training Loss Force: 2.2218145216270844, time: 0.6309912204742432
Validation Loss Energy: 2.006919238938611, Validation Loss Force: 2.7242458885226664, time: 0.059264183044433594
Test Loss Energy: 13.382980634344586, Test Loss Force: 10.004294642856763, time: 9.64138674736023


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.725977231298154, Training Loss Force: 1.9101945887595422, time: 0.6118617057800293
Validation Loss Energy: 2.147420797989294, Validation Loss Force: 2.5368885064326907, time: 0.053708553314208984
Test Loss Energy: 13.103731752738735, Test Loss Force: 9.960816158168655, time: 9.582340955734253


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4451589503117273, Training Loss Force: 1.9024983583033128, time: 0.6443181037902832
Validation Loss Energy: 2.210836748080382, Validation Loss Force: 2.50862711576239, time: 0.05258893966674805
Test Loss Energy: 14.301690335545636, Test Loss Force: 9.955865399994904, time: 9.601498126983643


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.112866822060451, Training Loss Force: 1.9432397001728148, time: 0.6324949264526367
Validation Loss Energy: 3.468110469587541, Validation Loss Force: 2.509724429313522, time: 0.053903818130493164
Test Loss Energy: 15.30570919382107, Test Loss Force: 10.032942215271946, time: 8.17655611038208


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0837821122230817, Training Loss Force: 1.8847359617838086, time: 0.6625020503997803
Validation Loss Energy: 3.3708227570253557, Validation Loss Force: 2.597537347047334, time: 0.060821533203125
Test Loss Energy: 14.965770220684036, Test Loss Force: 10.088550022278369, time: 10.110633134841919


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0627782802141468, Training Loss Force: 1.897467550841728, time: 0.6297256946563721
Validation Loss Energy: 2.847239417967339, Validation Loss Force: 2.5688388568435774, time: 0.05871868133544922
Test Loss Energy: 14.875898397938537, Test Loss Force: 10.091608353852509, time: 8.133776426315308


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.098825228327139, Training Loss Force: 1.9079117195040334, time: 0.6547830104827881
Validation Loss Energy: 1.6793228247210015, Validation Loss Force: 2.53373239395831, time: 0.04761457443237305
Test Loss Energy: 13.811307908117545, Test Loss Force: 9.94506603968197, time: 8.009762048721313


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.172947895727401, Training Loss Force: 1.8931704083457237, time: 0.6309661865234375
Validation Loss Energy: 2.4390176233773206, Validation Loss Force: 2.537156154746096, time: 0.047438621520996094
Test Loss Energy: 13.065171500207773, Test Loss Force: 10.046811658494054, time: 8.01675796508789


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6883439243758531, Training Loss Force: 1.97155154441301, time: 0.6257514953613281
Validation Loss Energy: 2.4702086720005934, Validation Loss Force: 2.691179297683244, time: 0.04754519462585449
Test Loss Energy: 12.636932566629584, Test Loss Force: 9.976836417464211, time: 8.31365156173706


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6114101839202135, Training Loss Force: 1.9232967698786976, time: 0.6226329803466797
Validation Loss Energy: 2.3123026244967564, Validation Loss Force: 2.640069157941855, time: 0.05322146415710449
Test Loss Energy: 12.884324893996302, Test Loss Force: 10.018782733246294, time: 8.217442512512207


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9117168283589943, Training Loss Force: 1.9288322651059597, time: 0.6293978691101074
Validation Loss Energy: 2.4205757193732893, Validation Loss Force: 2.5485390014859246, time: 0.048100948333740234
Test Loss Energy: 12.731710865533973, Test Loss Force: 9.981925300456856, time: 7.9404613971710205


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5669518164935679, Training Loss Force: 1.8697355207646644, time: 0.6159403324127197
Validation Loss Energy: 1.9659966579617103, Validation Loss Force: 2.5359236810233856, time: 0.0508272647857666
Test Loss Energy: 13.025822252783717, Test Loss Force: 9.956174646635352, time: 7.953594923019409


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5894011392067606, Training Loss Force: 1.9607227528177977, time: 0.6263771057128906
Validation Loss Energy: 2.196097609303984, Validation Loss Force: 2.6641290044976444, time: 0.051142215728759766
Test Loss Energy: 14.162375987759074, Test Loss Force: 10.091464684455296, time: 8.11961817741394


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6860543682572728, Training Loss Force: 1.9075353326140483, time: 0.5984647274017334
Validation Loss Energy: 1.7957693246025326, Validation Loss Force: 2.5389869404639143, time: 0.047592878341674805
Test Loss Energy: 13.15959950207398, Test Loss Force: 9.927880169195257, time: 7.943946361541748


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6792249195414666, Training Loss Force: 1.8790602311577274, time: 0.587550163269043
Validation Loss Energy: 2.825356162312994, Validation Loss Force: 2.6147084782355554, time: 0.04932141304016113
Test Loss Energy: 12.783666875231038, Test Loss Force: 9.917798689545565, time: 8.127959489822388


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1366890575559774, Training Loss Force: 1.935272261412322, time: 0.645836591720581
Validation Loss Energy: 1.7576814331878656, Validation Loss Force: 2.540622445340754, time: 0.049121856689453125
Test Loss Energy: 13.60533764709368, Test Loss Force: 9.932004328203814, time: 7.958008527755737


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5896130245131064, Training Loss Force: 1.8885653334292434, time: 0.6158430576324463
Validation Loss Energy: 1.6196738799061468, Validation Loss Force: 2.565921000355339, time: 0.04734516143798828
Test Loss Energy: 13.834131546870656, Test Loss Force: 9.849004919345944, time: 8.183767318725586


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1448029251640683, Training Loss Force: 1.9292164780017809, time: 0.6270248889923096
Validation Loss Energy: 3.9373387114405634, Validation Loss Force: 2.594907401764781, time: 0.047826290130615234
Test Loss Energy: 12.401420060220264, Test Loss Force: 9.943175021377275, time: 8.009765863418579


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.149680125413576, Training Loss Force: 1.905067303101791, time: 0.623539924621582
Validation Loss Energy: 1.7683108788724473, Validation Loss Force: 2.491279630610594, time: 0.04893684387207031
Test Loss Energy: 13.061868670916558, Test Loss Force: 9.914397801892036, time: 9.532283544540405


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6674187203724653, Training Loss Force: 1.8930252009078048, time: 0.6618473529815674
Validation Loss Energy: 3.148939633182693, Validation Loss Force: 2.4967350246858246, time: 0.05840349197387695
Test Loss Energy: 15.202971631761969, Test Loss Force: 9.895387737160549, time: 10.346825361251831

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–†â–ˆâ–‡â–‡â–„â–ƒâ–‚â–‚â–‚â–ƒâ–…â–ƒâ–‚â–„â–„â–â–ƒâ–ˆ
wandb:   test_error_force â–…â–„â–„â–†â–ˆâ–ˆâ–„â–‡â–…â–†â–…â–„â–ˆâ–ƒâ–ƒâ–ƒâ–â–„â–ƒâ–‚
wandb:          test_loss â–â–‚â–…â–‡â–‡â–ˆâ–†â–†â–„â–…â–„â–„â–†â–„â–…â–…â–ƒâ–…â–„â–†
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–„â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–ƒâ–‚â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–‡â–†â–…â–â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–â–â–ˆâ–â–†
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–„â–ƒâ–‚â–‚â–‡â–…â–ƒâ–‚â–†â–‚â–…â–‚â–ƒâ–„â–â–
wandb:         valid_loss â–‡â–‚â–‚â–„â–‡â–…â–‚â–ƒâ–ˆâ–†â–ƒâ–‚â–‡â–‚â–†â–‚â–ƒâ–‡â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1287
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.20297
wandb:   test_error_force 9.89539
wandb:          test_loss 8.37749
wandb: train_error_energy 1.66742
wandb:  train_error_force 1.89303
wandb:         train_loss -2.55361
wandb: valid_error_energy 3.14894
wandb:  valid_error_force 2.49674
wandb:         valid_loss -1.64659
wandb: 
wandb: ğŸš€ View run al_69_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/69ml324m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_161518-69ml324m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.216224670410156, Uncertainty Bias: -4.772764682769775
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:925: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00015640259 0.07491064
-2.4365919 92.141426
(48745, 22, 3)
Found uncertainty sample 0 after 205 steps.
Found uncertainty sample 1 after 272 steps.
Found uncertainty sample 2 after 399 steps.
Found uncertainty sample 3 after 642 steps.
Found uncertainty sample 4 after 796 steps.
Found uncertainty sample 5 after 11 steps.
Found uncertainty sample 6 after 837 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 104 steps.
Found uncertainty sample 9 after 1365 steps.
Found uncertainty sample 10 after 1219 steps.
Found uncertainty sample 11 after 1382 steps.
Found uncertainty sample 12 after 540 steps.
Found uncertainty sample 13 after 75 steps.
Found uncertainty sample 14 after 927 steps.
Found uncertainty sample 15 after 1094 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1338 steps.
Found uncertainty sample 18 after 161 steps.
Found uncertainty sample 19 after 650 steps.
Found uncertainty sample 20 after 676 steps.
Found uncertainty sample 21 after 80 steps.
Found uncertainty sample 22 after 369 steps.
Found uncertainty sample 23 after 1241 steps.
Found uncertainty sample 24 after 837 steps.
Found uncertainty sample 25 after 148 steps.
Found uncertainty sample 26 after 34 steps.
Found uncertainty sample 27 after 180 steps.
Found uncertainty sample 28 after 420 steps.
Found uncertainty sample 29 after 25 steps.
Found uncertainty sample 30 after 116 steps.
Found uncertainty sample 31 after 731 steps.
Found uncertainty sample 32 after 128 steps.
Found uncertainty sample 33 after 72 steps.
Found uncertainty sample 34 after 1126 steps.
Found uncertainty sample 35 after 84 steps.
Found uncertainty sample 36 after 1093 steps.
Found uncertainty sample 37 after 457 steps.
Found uncertainty sample 38 after 36 steps.
Found uncertainty sample 39 after 1330 steps.
Found uncertainty sample 40 after 319 steps.
Found uncertainty sample 41 after 736 steps.
Found uncertainty sample 42 after 422 steps.
Found uncertainty sample 43 after 3945 steps.
Found uncertainty sample 44 after 629 steps.
Found uncertainty sample 45 after 16 steps.
Found uncertainty sample 46 after 348 steps.
Found uncertainty sample 47 after 380 steps.
Found uncertainty sample 48 after 216 steps.
Found uncertainty sample 49 after 6 steps.
Found uncertainty sample 50 after 401 steps.
Found uncertainty sample 51 after 152 steps.
Found uncertainty sample 52 after 1787 steps.
Found uncertainty sample 53 after 978 steps.
Found uncertainty sample 54 after 636 steps.
Found uncertainty sample 55 after 158 steps.
Found uncertainty sample 56 after 314 steps.
Found uncertainty sample 57 after 2127 steps.
Found uncertainty sample 58 after 801 steps.
Found uncertainty sample 59 after 189 steps.
Found uncertainty sample 60 after 359 steps.
Found uncertainty sample 61 after 143 steps.
Found uncertainty sample 62 after 1290 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 33 steps.
Found uncertainty sample 65 after 315 steps.
Found uncertainty sample 66 after 2813 steps.
Found uncertainty sample 67 after 123 steps.
Found uncertainty sample 68 after 209 steps.
Found uncertainty sample 69 after 774 steps.
Found uncertainty sample 70 after 1260 steps.
Found uncertainty sample 71 after 1358 steps.
Found uncertainty sample 72 after 90 steps.
Found uncertainty sample 73 after 61 steps.
Found uncertainty sample 74 after 995 steps.
Found uncertainty sample 75 after 287 steps.
Found uncertainty sample 76 after 238 steps.
Found uncertainty sample 77 after 14 steps.
Found uncertainty sample 78 after 1387 steps.
Found uncertainty sample 79 after 732 steps.
Found uncertainty sample 80 after 206 steps.
Found uncertainty sample 81 after 2981 steps.
Found uncertainty sample 82 after 8 steps.
Found uncertainty sample 83 after 1192 steps.
Found uncertainty sample 84 after 164 steps.
Found uncertainty sample 85 after 2300 steps.
Found uncertainty sample 86 after 1052 steps.
Found uncertainty sample 87 after 197 steps.
Found uncertainty sample 88 after 47 steps.
Found uncertainty sample 89 after 130 steps.
Found uncertainty sample 90 after 877 steps.
Found uncertainty sample 91 after 7 steps.
Found uncertainty sample 92 after 385 steps.
Found uncertainty sample 93 after 2052 steps.
Found uncertainty sample 94 after 782 steps.
Found uncertainty sample 95 after 3283 steps.
Found uncertainty sample 96 after 1123 steps.
Found uncertainty sample 97 after 289 steps.
Found uncertainty sample 98 after 825 steps.
Found uncertainty sample 99 after 679 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_162821-6fwy0bt1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6fwy0bt1
Training model 6. Added 98 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.641334465962202, Training Loss Force: 2.0810052019256577, time: 0.693150520324707
Validation Loss Energy: 2.499219455681514, Validation Loss Force: 2.3746883957842098, time: 0.059781789779663086
Test Loss Energy: 12.547805274896415, Test Loss Force: 9.884481961980388, time: 8.954289436340332


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.710027386571004, Training Loss Force: 1.9425425103204863, time: 0.6243767738342285
Validation Loss Energy: 1.0287864256317807, Validation Loss Force: 2.2677694633186367, time: 0.056794166564941406
Test Loss Energy: 13.266115123008833, Test Loss Force: 9.853832871405391, time: 8.874741792678833


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9188840572649335, Training Loss Force: 1.9368025761468737, time: 0.6618974208831787
Validation Loss Energy: 1.3991941840229805, Validation Loss Force: 2.4769390696054066, time: 0.0568385124206543
Test Loss Energy: 13.417500194988309, Test Loss Force: 9.881214759752524, time: 9.131199598312378


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9460414763177212, Training Loss Force: 1.9110155756472857, time: 0.6415679454803467
Validation Loss Energy: 3.097605376945928, Validation Loss Force: 2.322406570996949, time: 0.05994057655334473
Test Loss Energy: 15.419910444343849, Test Loss Force: 9.984556704164024, time: 8.908427953720093


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.170040599162374, Training Loss Force: 1.9512044980368206, time: 0.6486153602600098
Validation Loss Energy: 2.696451991724241, Validation Loss Force: 2.4279872618954954, time: 0.06005668640136719
Test Loss Energy: 15.1789687325488, Test Loss Force: 10.047290530059803, time: 8.961251497268677


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0950144234741765, Training Loss Force: 1.898971603499789, time: 0.652228832244873
Validation Loss Energy: 2.9659644912191494, Validation Loss Force: 2.171232145778228, time: 0.057447195053100586
Test Loss Energy: 15.362167956033506, Test Loss Force: 9.905326349488277, time: 9.05833911895752


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1032168505542526, Training Loss Force: 1.8857543876223986, time: 0.6232664585113525
Validation Loss Energy: 1.0386667009748884, Validation Loss Force: 2.2616046453444802, time: 0.05817866325378418
Test Loss Energy: 13.515768910864184, Test Loss Force: 9.83444281419863, time: 8.851072311401367


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.01452883595671, Training Loss Force: 1.925720242132883, time: 0.6248486042022705
Validation Loss Energy: 2.263044535376622, Validation Loss Force: 2.1632912630288645, time: 0.0588834285736084
Test Loss Energy: 14.677814238682354, Test Loss Force: 9.892203461119532, time: 8.902958154678345


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6755785329922406, Training Loss Force: 1.9375589107386588, time: 0.655343770980835
Validation Loss Energy: 1.2780901692833642, Validation Loss Force: 2.377609814978782, time: 0.058069467544555664
Test Loss Energy: 13.298699541882756, Test Loss Force: 9.887493707904943, time: 8.977573156356812


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8132649183956604, Training Loss Force: 1.9619342587608188, time: 0.6445910930633545
Validation Loss Energy: 1.962675714652057, Validation Loss Force: 2.036874529469271, time: 0.057703256607055664
Test Loss Energy: 12.72919722232821, Test Loss Force: 9.869619787425698, time: 9.555935382843018


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.923746904145677, Training Loss Force: 1.913173213779565, time: 0.6308448314666748
Validation Loss Energy: 2.1273533535527034, Validation Loss Force: 2.342507471472715, time: 0.05730152130126953
Test Loss Energy: 12.797741803603206, Test Loss Force: 9.877717581100162, time: 8.856002569198608


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.334785859041425, Training Loss Force: 1.8875479642902617, time: 0.6143853664398193
Validation Loss Energy: 1.8121686288636818, Validation Loss Force: 2.313105569436972, time: 0.057024478912353516
Test Loss Energy: 14.413884462708317, Test Loss Force: 9.956839259243013, time: 8.912251234054565


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6082934177975208, Training Loss Force: 1.9155039719944507, time: 0.6684904098510742
Validation Loss Energy: 2.7121784454936826, Validation Loss Force: 2.3782254951672726, time: 0.057266950607299805
Test Loss Energy: 15.386404580906637, Test Loss Force: 9.907004691945048, time: 9.062963962554932


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7009558196741448, Training Loss Force: 1.8949202160649166, time: 0.6532907485961914
Validation Loss Energy: 1.5857949363550932, Validation Loss Force: 2.3567519507414345, time: 0.06191301345825195
Test Loss Energy: 14.260165589581337, Test Loss Force: 9.888688254427, time: 8.898781776428223


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5764414198305554, Training Loss Force: 1.943555458157073, time: 0.6284418106079102
Validation Loss Energy: 3.065020419469147, Validation Loss Force: 2.1801374085986045, time: 0.05667829513549805
Test Loss Energy: 14.989251090154587, Test Loss Force: 9.932252407280131, time: 8.929707527160645


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5479817746505071, Training Loss Force: 1.8833968392022464, time: 0.6575882434844971
Validation Loss Energy: 1.2949920934741588, Validation Loss Force: 2.5397657258017965, time: 0.06257367134094238
Test Loss Energy: 13.455906006064946, Test Loss Force: 9.922264416029133, time: 9.091792821884155


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.551599278308659, Training Loss Force: 1.897519228460418, time: 0.6610817909240723
Validation Loss Energy: 2.476518336254176, Validation Loss Force: 2.2187939413446847, time: 0.058765411376953125
Test Loss Energy: 12.60758074416715, Test Loss Force: 9.854935874094911, time: 8.89817500114441


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2061216913723074, Training Loss Force: 1.9033866692010122, time: 0.6460137367248535
Validation Loss Energy: 4.13034927347464, Validation Loss Force: 4.465104111062822, time: 0.057977914810180664
Test Loss Energy: 14.17046562078421, Test Loss Force: 9.945999659934056, time: 8.935819387435913


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5282116349505481, Training Loss Force: 1.8929224336660042, time: 0.6612143516540527
Validation Loss Energy: 2.19465744093541, Validation Loss Force: 2.3204156861632086, time: 0.060022592544555664
Test Loss Energy: 15.24122840606575, Test Loss Force: 9.882917490892712, time: 9.143080234527588


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3518761943416697, Training Loss Force: 1.9047666793571327, time: 0.6747856140136719
Validation Loss Energy: 1.1314006625009911, Validation Loss Force: 2.2727748430499473, time: 0.057341575622558594
Test Loss Energy: 13.250997641374132, Test Loss Force: 9.99170041534112, time: 8.964555025100708

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–ƒâ–ˆâ–‡â–ˆâ–ƒâ–†â–ƒâ–â–‚â–†â–ˆâ–…â–‡â–ƒâ–â–…â–ˆâ–ƒ
wandb:   test_error_force â–ƒâ–‚â–ƒâ–†â–ˆâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–„â–„â–‚â–…â–ƒâ–†
wandb:          test_loss â–â–ƒâ–ƒâ–‡â–ˆâ–…â–„â–…â–„â–‚â–ƒâ–†â–…â–†â–…â–„â–„â–…â–‡â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–ƒâ–„â–‚â–â–‚â–â–ƒâ–â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–â–‚â–â–
wandb: valid_error_energy â–„â–â–‚â–†â–…â–…â–â–„â–‚â–ƒâ–ƒâ–ƒâ–…â–‚â–†â–‚â–„â–ˆâ–„â–
wandb:  valid_error_force â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–ˆâ–‚â–‚
wandb:         valid_loss â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1375
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.251
wandb:   test_error_force 9.9917
wandb:          test_loss 8.37962
wandb: train_error_energy 1.35188
wandb:  train_error_force 1.90477
wandb:         train_loss -2.55971
wandb: valid_error_energy 1.1314
wandb:  valid_error_force 2.27277
wandb:         valid_loss -2.08428
wandb: 
wandb: ğŸš€ View run al_69_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6fwy0bt1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_162821-6fwy0bt1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 46.719825744628906, Uncertainty Bias: -5.7314653396606445
0.00027894974 0.0056419373
-3.0453942 88.14118
(48745, 22, 3)
Found uncertainty sample 0 after 677 steps.
Found uncertainty sample 1 after 362 steps.
Found uncertainty sample 2 after 2977 steps.
Found uncertainty sample 3 after 160 steps.
Found uncertainty sample 4 after 4 steps.
Found uncertainty sample 5 after 1183 steps.
Found uncertainty sample 6 after 490 steps.
Found uncertainty sample 7 after 432 steps.
Found uncertainty sample 8 after 122 steps.
Found uncertainty sample 9 after 11 steps.
Found uncertainty sample 10 after 17 steps.
Found uncertainty sample 11 after 1005 steps.
Found uncertainty sample 12 after 830 steps.
Found uncertainty sample 13 after 1068 steps.
Found uncertainty sample 14 after 506 steps.
Found uncertainty sample 15 after 357 steps.
Found uncertainty sample 16 after 95 steps.
Found uncertainty sample 17 after 718 steps.
Found uncertainty sample 18 after 621 steps.
Found uncertainty sample 19 after 211 steps.
Found uncertainty sample 20 after 947 steps.
Found uncertainty sample 21 after 1449 steps.
Found uncertainty sample 22 after 7 steps.
Found uncertainty sample 23 after 77 steps.
Found uncertainty sample 24 after 322 steps.
Found uncertainty sample 25 after 139 steps.
Found uncertainty sample 26 after 94 steps.
Found uncertainty sample 27 after 1020 steps.
Found uncertainty sample 28 after 283 steps.
Found uncertainty sample 29 after 744 steps.
Found uncertainty sample 30 after 127 steps.
Found uncertainty sample 31 after 824 steps.
Found uncertainty sample 32 after 896 steps.
Found uncertainty sample 33 after 123 steps.
Found uncertainty sample 34 after 49 steps.
Found uncertainty sample 35 after 886 steps.
Found uncertainty sample 36 after 219 steps.
Found uncertainty sample 37 after 41 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 108 steps.
Found uncertainty sample 40 after 6 steps.
Found uncertainty sample 41 after 5 steps.
Found uncertainty sample 42 after 36 steps.
Found uncertainty sample 43 after 256 steps.
Found uncertainty sample 44 after 180 steps.
Found uncertainty sample 45 after 134 steps.
Found uncertainty sample 46 after 329 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 357 steps.
Found uncertainty sample 49 after 914 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 416 steps.
Found uncertainty sample 52 after 801 steps.
Found uncertainty sample 53 after 2167 steps.
Found uncertainty sample 54 after 940 steps.
Found uncertainty sample 55 after 215 steps.
Found uncertainty sample 56 after 878 steps.
Found uncertainty sample 57 after 414 steps.
Found uncertainty sample 58 after 1261 steps.
Found uncertainty sample 59 after 1418 steps.
Found uncertainty sample 60 after 701 steps.
Found uncertainty sample 61 after 959 steps.
Found uncertainty sample 62 after 243 steps.
Found uncertainty sample 63 after 606 steps.
Found uncertainty sample 64 after 546 steps.
Found uncertainty sample 65 after 1017 steps.
Found uncertainty sample 66 after 2066 steps.
Found uncertainty sample 67 after 368 steps.
Found uncertainty sample 68 after 291 steps.
Found uncertainty sample 69 after 1378 steps.
Found uncertainty sample 70 after 266 steps.
Found uncertainty sample 71 after 217 steps.
Found uncertainty sample 72 after 112 steps.
Found uncertainty sample 73 after 983 steps.
Found uncertainty sample 74 after 110 steps.
Found uncertainty sample 75 after 520 steps.
Found uncertainty sample 76 after 1011 steps.
Found uncertainty sample 77 after 49 steps.
Found uncertainty sample 78 after 526 steps.
Found uncertainty sample 79 after 260 steps.
Found uncertainty sample 80 after 106 steps.
Found uncertainty sample 81 after 260 steps.
Found uncertainty sample 82 after 778 steps.
Found uncertainty sample 83 after 32 steps.
Found uncertainty sample 84 after 677 steps.
Found uncertainty sample 85 after 1684 steps.
Found uncertainty sample 86 after 68 steps.
Found uncertainty sample 87 after 422 steps.
Found uncertainty sample 88 after 28 steps.
Found uncertainty sample 89 after 1214 steps.
Found uncertainty sample 90 after 342 steps.
Found uncertainty sample 91 after 2887 steps.
Found uncertainty sample 92 after 17 steps.
Found uncertainty sample 93 after 2247 steps.
Found uncertainty sample 94 after 148 steps.
Found uncertainty sample 95 after 1216 steps.
Found uncertainty sample 96 after 129 steps.
Found uncertainty sample 97 after 1433 steps.
Found uncertainty sample 98 after 788 steps.
Found uncertainty sample 99 after 48 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_163956-a2iwxnb2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/a2iwxnb2
Training model 7. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.333362018578745, Training Loss Force: 2.2931906243215403, time: 0.7065713405609131
Validation Loss Energy: 1.1742607712175395, Validation Loss Force: 2.326445566634933, time: 0.060838937759399414
Test Loss Energy: 13.231174538145018, Test Loss Force: 9.876483289884266, time: 8.708683013916016


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5571272434725032, Training Loss Force: 1.9293920117140875, time: 0.6913609504699707
Validation Loss Energy: 2.4348702991998428, Validation Loss Force: 2.249216892749079, time: 0.05781412124633789
Test Loss Energy: 15.027265166747378, Test Loss Force: 9.937124972443643, time: 8.725792407989502


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6489119736904663, Training Loss Force: 1.8988505640193076, time: 0.6905980110168457
Validation Loss Energy: 1.3359775784847843, Validation Loss Force: 2.322452218171864, time: 0.057332754135131836
Test Loss Energy: 12.948299432373185, Test Loss Force: 9.789346954099067, time: 8.860460758209229


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2299660668324863, Training Loss Force: 1.93675127297302, time: 0.6709177494049072
Validation Loss Energy: 3.9120354803739135, Validation Loss Force: 2.327592312736461, time: 0.05691337585449219
Test Loss Energy: 12.166097412483353, Test Loss Force: 9.906958889717796, time: 8.704379320144653


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7397584051712909, Training Loss Force: 1.920554520184528, time: 0.6767420768737793
Validation Loss Energy: 3.4116364527898977, Validation Loss Force: 2.268896948539042, time: 0.057378292083740234
Test Loss Energy: 15.558326453862794, Test Loss Force: 9.891832375410099, time: 8.808419466018677


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8890452483079228, Training Loss Force: 1.9052111953041388, time: 0.6703619956970215
Validation Loss Energy: 1.1937069687369912, Validation Loss Force: 2.3168143467315456, time: 0.05730462074279785
Test Loss Energy: 13.649860676242755, Test Loss Force: 9.905078060566687, time: 8.66217565536499


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5664632040883906, Training Loss Force: 1.900889153297246, time: 0.7315394878387451
Validation Loss Energy: 1.0577009884080173, Validation Loss Force: 2.3593864607414794, time: 0.08522295951843262
Test Loss Energy: 13.5506760603819, Test Loss Force: 9.813757013754925, time: 8.78532600402832


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.110230006679135, Training Loss Force: 1.9206580589170674, time: 0.7077353000640869
Validation Loss Energy: 2.784635764920596, Validation Loss Force: 2.3470873304661577, time: 0.058257102966308594
Test Loss Energy: 15.15738930369794, Test Loss Force: 9.894107653043857, time: 8.669870376586914


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.918929046310681, Training Loss Force: 1.891648761310664, time: 0.6830658912658691
Validation Loss Energy: 2.416579810215042, Validation Loss Force: 2.2307460417560776, time: 0.05694460868835449
Test Loss Energy: 14.82773678706878, Test Loss Force: 9.896957692204571, time: 8.676983833312988


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.015740767268693, Training Loss Force: 1.8863117497709292, time: 0.750960111618042
Validation Loss Energy: 2.701036192766029, Validation Loss Force: 2.2803577294799453, time: 0.05680394172668457
Test Loss Energy: 12.71551533880701, Test Loss Force: 9.788883764969711, time: 9.333661317825317


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0651555537494826, Training Loss Force: 1.8717715803983181, time: 0.6860215663909912
Validation Loss Energy: 5.995989559706848, Validation Loss Force: 4.498894710630229, time: 0.05740499496459961
Test Loss Energy: 15.101186743905325, Test Loss Force: 9.932370153791851, time: 8.736509084701538


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9486759790286718, Training Loss Force: 1.8904381914550257, time: 0.6923117637634277
Validation Loss Energy: 2.1897070604831432, Validation Loss Force: 2.3585523421208334, time: 0.05811119079589844
Test Loss Energy: 14.897834153381616, Test Loss Force: 9.937892260009527, time: 8.67481255531311


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5722454619479422, Training Loss Force: 1.897348471845314, time: 0.6626832485198975
Validation Loss Energy: 1.4979759508870547, Validation Loss Force: 2.2015499973457446, time: 0.05861926078796387
Test Loss Energy: 14.221130331300795, Test Loss Force: 9.82256263883589, time: 8.890589237213135


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0288138071536963, Training Loss Force: 1.9182049589224006, time: 0.6929609775543213
Validation Loss Energy: 1.3998352206604632, Validation Loss Force: 2.2445206891268894, time: 0.05729246139526367
Test Loss Energy: 13.373645849445102, Test Loss Force: 9.800071935922418, time: 8.679664134979248


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7370757127144787, Training Loss Force: 1.925197060542549, time: 0.7215285301208496
Validation Loss Energy: 3.788634577726765, Validation Loss Force: 3.363705694448639, time: 0.0568547248840332
Test Loss Energy: 14.878347152324073, Test Loss Force: 9.916153595905767, time: 8.635420799255371


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4885492634856277, Training Loss Force: 1.9111468141176322, time: 0.6843297481536865
Validation Loss Energy: 1.0785761930051043, Validation Loss Force: 2.346516629445145, time: 0.05720353126525879
Test Loss Energy: 13.542136607702622, Test Loss Force: 9.821556048389136, time: 8.876788854598999


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4094217651461325, Training Loss Force: 1.8851630117486713, time: 0.6842353343963623
Validation Loss Energy: 1.1197562073483407, Validation Loss Force: 2.1792129419719988, time: 0.05700874328613281
Test Loss Energy: 14.064399763544769, Test Loss Force: 9.862101516434171, time: 8.649132490158081


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.470155050614052, Training Loss Force: 1.886049791622329, time: 0.7819128036499023
Validation Loss Energy: 2.8621495666478096, Validation Loss Force: 2.364800995028432, time: 0.058763980865478516
Test Loss Energy: 15.919335192989216, Test Loss Force: 9.860972012618863, time: 8.70317792892456


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.952715331663385, Training Loss Force: 1.9039072835106552, time: 0.6693723201751709
Validation Loss Energy: 2.130408207232973, Validation Loss Force: 2.3020939121634054, time: 0.05758237838745117
Test Loss Energy: 12.925015271857244, Test Loss Force: 9.791647366532752, time: 8.928623676300049


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2737616783423475, Training Loss Force: 1.905778169037275, time: 0.6777205467224121
Validation Loss Energy: 1.0952612096141219, Validation Loss Force: 2.2414454055524806, time: 0.05712771415710449
Test Loss Energy: 13.541887152973992, Test Loss Force: 9.858311832130552, time: 8.65539264678955

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–‚â–â–‡â–„â–„â–‡â–†â–‚â–†â–†â–…â–ƒâ–†â–„â–…â–ˆâ–‚â–„
wandb:   test_error_force â–…â–ˆâ–â–‡â–†â–†â–‚â–†â–†â–â–ˆâ–ˆâ–ƒâ–‚â–‡â–ƒâ–„â–„â–â–„
wandb:          test_loss â–â–„â–‚â–ƒâ–…â–…â–„â–‡â–†â–„â–ˆâ–ˆâ–…â–…â–‡â–…â–†â–ˆâ–…â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–â–â–â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–
wandb: valid_error_energy â–â–ƒâ–â–…â–„â–â–â–ƒâ–ƒâ–ƒâ–ˆâ–ƒâ–‚â–â–…â–â–â–„â–ƒâ–
wandb:  valid_error_force â–â–â–â–â–â–â–‚â–‚â–â–â–ˆâ–‚â–â–â–…â–‚â–â–‚â–â–
wandb:         valid_loss â–â–â–â–‚â–‚â–â–â–‚â–â–â–ˆâ–‚â–â–â–…â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1465
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.54189
wandb:   test_error_force 9.85831
wandb:          test_loss 8.24994
wandb: train_error_energy 1.27376
wandb:  train_error_force 1.90578
wandb:         train_loss -2.5627
wandb: valid_error_energy 1.09526
wandb:  valid_error_force 2.24145
wandb:         valid_loss -2.12513
wandb: 
wandb: ğŸš€ View run al_69_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/a2iwxnb2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_163956-a2iwxnb2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 67.63064575195312, Uncertainty Bias: -8.314443588256836
1.1444092e-05 0.00056391954
-4.4200644 77.37876
(48745, 22, 3)
Found uncertainty sample 0 after 123 steps.
Found uncertainty sample 1 after 152 steps.
Found uncertainty sample 2 after 121 steps.
Found uncertainty sample 3 after 588 steps.
Found uncertainty sample 4 after 491 steps.
Found uncertainty sample 5 after 138 steps.
Found uncertainty sample 6 after 1234 steps.
Found uncertainty sample 7 after 214 steps.
Found uncertainty sample 8 after 77 steps.
Found uncertainty sample 9 after 7 steps.
Found uncertainty sample 10 after 61 steps.
Found uncertainty sample 11 after 2 steps.
Found uncertainty sample 12 after 87 steps.
Found uncertainty sample 13 after 101 steps.
Found uncertainty sample 14 after 521 steps.
Found uncertainty sample 15 after 34 steps.
Found uncertainty sample 16 after 206 steps.
Found uncertainty sample 17 after 678 steps.
Found uncertainty sample 18 after 138 steps.
Found uncertainty sample 19 after 529 steps.
Found uncertainty sample 20 after 112 steps.
Found uncertainty sample 21 after 86 steps.
Found uncertainty sample 22 after 100 steps.
Found uncertainty sample 23 after 278 steps.
Found uncertainty sample 24 after 20 steps.
Found uncertainty sample 25 after 60 steps.
Found uncertainty sample 26 after 16 steps.
Found uncertainty sample 27 after 92 steps.
Found uncertainty sample 28 after 454 steps.
Found uncertainty sample 29 after 151 steps.
Found uncertainty sample 30 after 118 steps.
Found uncertainty sample 31 after 108 steps.
Found uncertainty sample 32 after 78 steps.
Found uncertainty sample 33 after 1035 steps.
Found uncertainty sample 34 after 770 steps.
Found uncertainty sample 35 after 147 steps.
Found uncertainty sample 36 after 585 steps.
Found uncertainty sample 37 after 81 steps.
Found uncertainty sample 38 after 12 steps.
Found uncertainty sample 39 after 35 steps.
Found uncertainty sample 40 after 13 steps.
Found uncertainty sample 41 after 285 steps.
Found uncertainty sample 42 after 154 steps.
Found uncertainty sample 43 after 329 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 103 steps.
Found uncertainty sample 46 after 33 steps.
Found uncertainty sample 47 after 1069 steps.
Found uncertainty sample 48 after 30 steps.
Found uncertainty sample 49 after 250 steps.
Found uncertainty sample 50 after 375 steps.
Found uncertainty sample 51 after 411 steps.
Found uncertainty sample 52 after 70 steps.
Found uncertainty sample 53 after 16 steps.
Found uncertainty sample 54 after 14 steps.
Found uncertainty sample 55 after 660 steps.
Found uncertainty sample 56 after 429 steps.
Found uncertainty sample 57 after 262 steps.
Found uncertainty sample 58 after 65 steps.
Found uncertainty sample 59 after 146 steps.
Found uncertainty sample 60 after 11 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 735 steps.
Found uncertainty sample 63 after 137 steps.
Found uncertainty sample 64 after 327 steps.
Found uncertainty sample 65 after 13 steps.
Found uncertainty sample 66 after 108 steps.
Found uncertainty sample 67 after 24 steps.
Found uncertainty sample 68 after 435 steps.
Found uncertainty sample 69 after 11 steps.
Found uncertainty sample 70 after 8 steps.
Found uncertainty sample 71 after 457 steps.
Found uncertainty sample 72 after 12 steps.
Found uncertainty sample 73 after 30 steps.
Found uncertainty sample 74 after 322 steps.
Found uncertainty sample 75 after 121 steps.
Found uncertainty sample 76 after 454 steps.
Found uncertainty sample 77 after 25 steps.
Found uncertainty sample 78 after 481 steps.
Found uncertainty sample 79 after 45 steps.
Found uncertainty sample 80 after 282 steps.
Found uncertainty sample 81 after 670 steps.
Found uncertainty sample 82 after 34 steps.
Found uncertainty sample 83 after 161 steps.
Found uncertainty sample 84 after 166 steps.
Found uncertainty sample 85 after 437 steps.
Found uncertainty sample 86 after 20 steps.
Found uncertainty sample 87 after 348 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 181 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 46 steps.
Found uncertainty sample 92 after 58 steps.
Found uncertainty sample 93 after 159 steps.
Found uncertainty sample 94 after 78 steps.
Found uncertainty sample 95 after 131 steps.
Found uncertainty sample 96 after 833 steps.
Found uncertainty sample 97 after 139 steps.
Found uncertainty sample 98 after 394 steps.
Found uncertainty sample 99 after 314 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_164758-w85k3ofp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w85k3ofp
Training model 8. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.8480715974610054, Training Loss Force: 2.220547785784048, time: 0.8610601425170898
Validation Loss Energy: 2.9823802173298106, Validation Loss Force: 2.281461611770882, time: 0.06857967376708984
Test Loss Energy: 12.648746095135078, Test Loss Force: 9.754208443178085, time: 9.99955940246582


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4131928967661502, Training Loss Force: 1.8867372891798122, time: 0.774522066116333
Validation Loss Energy: 1.7202459067034803, Validation Loss Force: 2.2314924287332274, time: 0.06412672996520996
Test Loss Energy: 14.800656847409984, Test Loss Force: 9.806054848359842, time: 9.91658353805542


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5578938982072632, Training Loss Force: 1.9065656380766949, time: 0.8284590244293213
Validation Loss Energy: 2.1389880390965765, Validation Loss Force: 2.269098018777815, time: 0.06451845169067383
Test Loss Energy: 14.79245398654124, Test Loss Force: 9.803121356067495, time: 10.328428030014038


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3955304909820883, Training Loss Force: 1.8851099980678965, time: 0.8113329410552979
Validation Loss Energy: 1.8999293306827738, Validation Loss Force: 2.8968499923454774, time: 0.0642538070678711
Test Loss Energy: 13.571202383084838, Test Loss Force: 9.811201676625942, time: 10.019862174987793


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8922105626786077, Training Loss Force: 1.9106344418424894, time: 0.7813799381256104
Validation Loss Energy: 1.9376614524695346, Validation Loss Force: 2.3511149699777, time: 0.06370353698730469
Test Loss Energy: 14.904377058902327, Test Loss Force: 9.776644623627593, time: 10.23140263557434


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6475041706131937, Training Loss Force: 1.9099229593900304, time: 0.7643380165100098
Validation Loss Energy: 2.113252440215821, Validation Loss Force: 2.8183767092684606, time: 0.0632779598236084
Test Loss Energy: 13.33993807755385, Test Loss Force: 9.849386310789674, time: 10.310388803482056


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4547851409985906, Training Loss Force: 1.843134837316854, time: 0.7916080951690674
Validation Loss Energy: 1.5387752288243979, Validation Loss Force: 2.2465872814702452, time: 0.06549811363220215
Test Loss Energy: 13.07287148321206, Test Loss Force: 9.791815130830006, time: 10.096908330917358


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3454443878977151, Training Loss Force: 1.8684286935580334, time: 0.8087937831878662
Validation Loss Energy: 1.7217404620109478, Validation Loss Force: 2.2349096207812083, time: 0.06903910636901855
Test Loss Energy: 13.58371763416791, Test Loss Force: 9.743850350158798, time: 10.229288578033447


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4629102637211022, Training Loss Force: 1.8606559498712545, time: 0.9237394332885742
Validation Loss Energy: 2.1891449322242487, Validation Loss Force: 2.7686933220796037, time: 0.09258389472961426
Test Loss Energy: 14.20003127091193, Test Loss Force: 9.77709219560575, time: 10.224576950073242


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3162220821609678, Training Loss Force: 1.8705365115032642, time: 0.7769327163696289
Validation Loss Energy: 0.9434489486268911, Validation Loss Force: 2.242261376637733, time: 0.06864643096923828
Test Loss Energy: 13.936887095000873, Test Loss Force: 9.837418093678762, time: 10.605937004089355


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3246762911360541, Training Loss Force: 1.8784999190544451, time: 0.7769958972930908
Validation Loss Energy: 1.5363640003104324, Validation Loss Force: 2.2087135977739605, time: 0.07332873344421387
Test Loss Energy: 13.195628260561683, Test Loss Force: 9.765866415717715, time: 8.543807744979858


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.455063050837815, Training Loss Force: 1.8725974575932764, time: 0.7647027969360352
Validation Loss Energy: 0.9310102326307164, Validation Loss Force: 2.320324057809659, time: 0.06306314468383789
Test Loss Energy: 13.759896353627449, Test Loss Force: 9.831389971244066, time: 10.577636003494263


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.104964394543171, Training Loss Force: 1.9267323327408143, time: 0.8189194202423096
Validation Loss Energy: 3.6137599166229286, Validation Loss Force: 2.307491634929841, time: 0.07271265983581543
Test Loss Energy: 12.5177273598259, Test Loss Force: 9.74359681976873, time: 8.324760437011719


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.832707518413421, Training Loss Force: 1.8731362146803854, time: 0.7444822788238525
Validation Loss Energy: 0.9197938032438255, Validation Loss Force: 2.222600359059747, time: 0.059568166732788086
Test Loss Energy: 13.73766875004829, Test Loss Force: 9.789330847308909, time: 7.943134307861328


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3399304068436295, Training Loss Force: 1.850123690180333, time: 0.9320151805877686
Validation Loss Energy: 1.8987133901441486, Validation Loss Force: 2.344910182891849, time: 0.05706477165222168
Test Loss Energy: 12.966892721085467, Test Loss Force: 9.7536484174522, time: 7.870679140090942


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4237044022157836, Training Loss Force: 1.8353374091647545, time: 0.7696108818054199
Validation Loss Energy: 0.9934228633838971, Validation Loss Force: 2.3131658014409453, time: 0.054866790771484375
Test Loss Energy: 14.088531335213299, Test Loss Force: 9.769170597345104, time: 7.940377473831177


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4820569269326658, Training Loss Force: 1.9079141406015063, time: 0.7403850555419922
Validation Loss Energy: 1.7512786375639986, Validation Loss Force: 2.424747982495111, time: 0.05729413032531738
Test Loss Energy: 13.554372997740108, Test Loss Force: 9.865059826426927, time: 7.923868894577026


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9193825797705357, Training Loss Force: 1.9116659657495365, time: 0.7649972438812256
Validation Loss Energy: 2.027253663681169, Validation Loss Force: 2.289729985166619, time: 0.055849313735961914
Test Loss Energy: 15.22227482701729, Test Loss Force: 9.803782401305595, time: 8.103365898132324


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9338484944163439, Training Loss Force: 1.8538872077306585, time: 0.7981722354888916
Validation Loss Energy: 1.598071020373811, Validation Loss Force: 2.1414373440344954, time: 0.05585980415344238
Test Loss Energy: 14.935772018836145, Test Loss Force: 9.79453209544795, time: 7.992150783538818


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9333072856964957, Training Loss Force: 1.8583218250933344, time: 0.7494697570800781
Validation Loss Energy: 1.5634918936933877, Validation Loss Force: 2.1999822952238404, time: 0.0552518367767334
Test Loss Energy: 13.28354879277817, Test Loss Force: 9.749936217348136, time: 7.865849256515503

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–‡â–„â–‡â–ƒâ–‚â–„â–…â–…â–ƒâ–„â–â–„â–‚â–…â–„â–ˆâ–‡â–ƒ
wandb:   test_error_force â–‚â–…â–„â–…â–ƒâ–‡â–„â–â–ƒâ–†â–‚â–†â–â–„â–‚â–‚â–ˆâ–„â–„â–
wandb:          test_loss â–â–…â–†â–†â–†â–†â–…â–†â–‡â–ˆâ–†â–‡â–„â–†â–†â–ˆâ–ˆâ–‡â–‡â–†
wandb: train_error_energy â–ƒâ–â–‚â–â–ƒâ–‚â–‚â–â–‚â–â–â–‚â–ˆâ–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–â–‚â–‚â–‚â–„â–‚â–â–â–‚â–ƒâ–‚â–‚
wandb: valid_error_energy â–†â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–„â–â–ƒâ–â–ˆâ–â–„â–â–ƒâ–„â–ƒâ–ƒ
wandb:  valid_error_force â–‚â–‚â–‚â–ˆâ–ƒâ–‡â–‚â–‚â–‡â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–â–‚
wandb:         valid_loss â–ƒâ–‚â–‚â–ˆâ–ƒâ–‡â–‚â–‚â–‡â–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–„â–ƒâ–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1555
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.28355
wandb:   test_error_force 9.74994
wandb:          test_loss 8.18246
wandb: train_error_energy 1.93331
wandb:  train_error_force 1.85832
wandb:         train_loss -2.58199
wandb: valid_error_energy 1.56349
wandb:  valid_error_force 2.19998
wandb:         valid_loss -2.14714
wandb: 
wandb: ğŸš€ View run al_69_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w85k3ofp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_164758-w85k3ofp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 66.68254852294922, Uncertainty Bias: -8.159247398376465
6.866455e-05 0.018399239
-4.1275663 79.18008
(48745, 22, 3)
Found uncertainty sample 0 after 1772 steps.
Found uncertainty sample 1 after 246 steps.
Found uncertainty sample 2 after 227 steps.
Found uncertainty sample 3 after 295 steps.
Found uncertainty sample 4 after 125 steps.
Found uncertainty sample 5 after 117 steps.
Found uncertainty sample 6 after 1836 steps.
Found uncertainty sample 7 after 228 steps.
Found uncertainty sample 8 after 110 steps.
Found uncertainty sample 9 after 112 steps.
Found uncertainty sample 10 after 257 steps.
Found uncertainty sample 11 after 33 steps.
Found uncertainty sample 12 after 371 steps.
Found uncertainty sample 13 after 694 steps.
Found uncertainty sample 14 after 66 steps.
Found uncertainty sample 15 after 326 steps.
Found uncertainty sample 16 after 513 steps.
Found uncertainty sample 17 after 294 steps.
Found uncertainty sample 18 after 45 steps.
Found uncertainty sample 19 after 1744 steps.
Found uncertainty sample 20 after 164 steps.
Found uncertainty sample 21 after 1354 steps.
Found uncertainty sample 22 after 386 steps.
Found uncertainty sample 23 after 91 steps.
Found uncertainty sample 24 after 79 steps.
Found uncertainty sample 25 after 275 steps.
Found uncertainty sample 26 after 68 steps.
Found uncertainty sample 27 after 36 steps.
Found uncertainty sample 28 after 156 steps.
Found uncertainty sample 29 after 127 steps.
Found uncertainty sample 30 after 1171 steps.
Found uncertainty sample 31 after 478 steps.
Found uncertainty sample 32 after 1172 steps.
Found uncertainty sample 33 after 638 steps.
Found uncertainty sample 34 after 104 steps.
Found uncertainty sample 35 after 1226 steps.
Found uncertainty sample 36 after 877 steps.
Found uncertainty sample 37 after 180 steps.
Found uncertainty sample 38 after 55 steps.
Found uncertainty sample 39 after 16 steps.
Found uncertainty sample 40 after 54 steps.
Found uncertainty sample 41 after 72 steps.
Found uncertainty sample 42 after 78 steps.
Found uncertainty sample 43 after 25 steps.
Found uncertainty sample 44 after 903 steps.
Found uncertainty sample 45 after 171 steps.
Found uncertainty sample 46 after 40 steps.
Found uncertainty sample 47 after 79 steps.
Found uncertainty sample 48 after 121 steps.
Found uncertainty sample 49 after 107 steps.
Found uncertainty sample 50 after 94 steps.
Found uncertainty sample 51 after 116 steps.
Found uncertainty sample 52 after 475 steps.
Found uncertainty sample 53 after 219 steps.
Found uncertainty sample 54 after 38 steps.
Found uncertainty sample 55 after 2025 steps.
Found uncertainty sample 56 after 388 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 40 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 380 steps.
Found uncertainty sample 61 after 37 steps.
Found uncertainty sample 62 after 46 steps.
Found uncertainty sample 63 after 544 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 554 steps.
Found uncertainty sample 66 after 243 steps.
Found uncertainty sample 67 after 113 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 312 steps.
Found uncertainty sample 70 after 149 steps.
Found uncertainty sample 71 after 407 steps.
Found uncertainty sample 72 after 137 steps.
Found uncertainty sample 73 after 110 steps.
Found uncertainty sample 74 after 232 steps.
Found uncertainty sample 75 after 48 steps.
Found uncertainty sample 76 after 109 steps.
Found uncertainty sample 77 after 18 steps.
Found uncertainty sample 78 after 95 steps.
Found uncertainty sample 79 after 253 steps.
Found uncertainty sample 80 after 1226 steps.
Found uncertainty sample 81 after 81 steps.
Found uncertainty sample 82 after 233 steps.
Found uncertainty sample 83 after 22 steps.
Found uncertainty sample 84 after 2524 steps.
Found uncertainty sample 85 after 61 steps.
Found uncertainty sample 86 after 83 steps.
Found uncertainty sample 87 after 65 steps.
Found uncertainty sample 88 after 428 steps.
Found uncertainty sample 89 after 199 steps.
Found uncertainty sample 90 after 1068 steps.
Found uncertainty sample 91 after 90 steps.
Found uncertainty sample 92 after 1112 steps.
Found uncertainty sample 93 after 112 steps.
Found uncertainty sample 94 after 20 steps.
Found uncertainty sample 95 after 77 steps.
Found uncertainty sample 96 after 203 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 388 steps.
Found uncertainty sample 99 after 81 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_165725-nslddc12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nslddc12
Training model 9. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.465802478197406, Training Loss Force: 2.263790243641087, time: 0.8010389804840088
Validation Loss Energy: 1.6845084551259406, Validation Loss Force: 2.584395970727541, time: 0.06425666809082031
Test Loss Energy: 13.424222686089735, Test Loss Force: 9.824067066197427, time: 8.877332210540771


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7240478870934959, Training Loss Force: 1.9516143807484534, time: 0.8737082481384277
Validation Loss Energy: 1.5231966273678519, Validation Loss Force: 2.293534732863087, time: 0.06265687942504883
Test Loss Energy: 14.721962162419299, Test Loss Force: 9.758492401690152, time: 8.825886726379395


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.199150493218732, Training Loss Force: 1.925905108212105, time: 0.775090217590332
Validation Loss Energy: 1.0813137988197135, Validation Loss Force: 2.2276071861405065, time: 0.06164860725402832
Test Loss Energy: 13.713261889366963, Test Loss Force: 9.719760738217492, time: 9.154369115829468


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.668939317108097, Training Loss Force: 1.8777289791772809, time: 0.7446086406707764
Validation Loss Energy: 3.725235661825341, Validation Loss Force: 3.2766309249335777, time: 0.06105995178222656
Test Loss Energy: 14.732462992190158, Test Loss Force: 9.849425971545404, time: 8.774643659591675


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9772508083583415, Training Loss Force: 1.9099642005035906, time: 0.7822682857513428
Validation Loss Energy: 2.2669119644376687, Validation Loss Force: 2.180813042454636, time: 0.06639719009399414
Test Loss Energy: 12.554649163817228, Test Loss Force: 9.717723089365686, time: 8.898915529251099


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.709393845399208, Training Loss Force: 1.8588034056725529, time: 0.7583622932434082
Validation Loss Energy: 1.7928796914285412, Validation Loss Force: 2.306237784969121, time: 0.06055116653442383
Test Loss Energy: 13.312627056285475, Test Loss Force: 9.769418825644724, time: 9.066280364990234


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.548374743381387, Training Loss Force: 1.9045438468441502, time: 0.7563588619232178
Validation Loss Energy: 1.0536990950164735, Validation Loss Force: 2.254912880836485, time: 0.06283974647521973
Test Loss Energy: 13.59499190696586, Test Loss Force: 9.81825247764464, time: 8.862224578857422


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.598515638202517, Training Loss Force: 1.922130894022272, time: 0.7687771320343018
Validation Loss Energy: 1.0790003777280968, Validation Loss Force: 2.205450270105816, time: 0.060091495513916016
Test Loss Energy: 13.2970284647355, Test Loss Force: 9.736369063230022, time: 8.814791679382324


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3644028343770422, Training Loss Force: 1.849990415661618, time: 0.7531366348266602
Validation Loss Energy: 1.4483016931331811, Validation Loss Force: 2.1838765245643104, time: 0.06206798553466797
Test Loss Energy: 13.46849395687545, Test Loss Force: 9.758372491440552, time: 8.956417560577393


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.533188829284105, Training Loss Force: 1.8604920621027345, time: 0.8811640739440918
Validation Loss Energy: 1.4387047642782664, Validation Loss Force: 2.297963176837299, time: 0.0598752498626709
Test Loss Energy: 13.866338011100023, Test Loss Force: 9.915735318327082, time: 8.928414106369019


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8218417929969086, Training Loss Force: 1.923786580431511, time: 0.7726356983184814
Validation Loss Energy: 4.088804053898438, Validation Loss Force: 2.624715340988123, time: 0.06391763687133789
Test Loss Energy: 12.419603278635467, Test Loss Force: 9.711807430005173, time: 9.321396589279175


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5626897457588411, Training Loss Force: 1.8831319196812994, time: 0.8600566387176514
Validation Loss Energy: 1.1674716724591307, Validation Loss Force: 2.1581653079550343, time: 0.06060481071472168
Test Loss Energy: 14.148860721380997, Test Loss Force: 9.729754651768289, time: 8.882174730300903


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2909134727477496, Training Loss Force: 1.8780274714494967, time: 0.8931119441986084
Validation Loss Energy: 1.0218447150074819, Validation Loss Force: 2.3116610033527656, time: 0.09196758270263672
Test Loss Energy: 12.904061942012454, Test Loss Force: 9.806799001650692, time: 8.92441725730896


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8942836090845363, Training Loss Force: 1.8797811751039328, time: 0.8130786418914795
Validation Loss Energy: 1.6872003580983481, Validation Loss Force: 2.2877947676193604, time: 0.0628976821899414
Test Loss Energy: 14.425445514713314, Test Loss Force: 9.830999752309378, time: 8.828544616699219


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6597843918604722, Training Loss Force: 1.8768208872970988, time: 0.771291971206665
Validation Loss Energy: 1.503443536098025, Validation Loss Force: 2.1927864077694648, time: 0.06045174598693848
Test Loss Energy: 13.584629878181982, Test Loss Force: 9.683330830188236, time: 8.808599710464478


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4838432568822146, Training Loss Force: 1.8962104305062586, time: 0.8177316188812256
Validation Loss Energy: 1.0795341156708858, Validation Loss Force: 2.157116647612287, time: 0.06390857696533203
Test Loss Energy: 13.490872872882825, Test Loss Force: 9.747758130716253, time: 9.000242233276367


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.953246693320518, Training Loss Force: 1.8780805159503646, time: 0.7702338695526123
Validation Loss Energy: 1.598315177092321, Validation Loss Force: 2.1409986301497312, time: 0.061157941818237305
Test Loss Energy: 14.69256798851847, Test Loss Force: 9.786986138870674, time: 8.887548208236694


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5652353925707403, Training Loss Force: 1.9097683822591924, time: 0.783348560333252
Validation Loss Energy: 1.8137710673723508, Validation Loss Force: 2.2119643446353603, time: 0.0668942928314209
Test Loss Energy: 13.135235594387492, Test Loss Force: 9.706828417331838, time: 8.975567102432251


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.686647860280015, Training Loss Force: 1.861997682353915, time: 0.7730062007904053
Validation Loss Energy: 0.989196769996047, Validation Loss Force: 2.210066090166326, time: 0.06050825119018555
Test Loss Energy: 13.982667433060177, Test Loss Force: 9.713884809561133, time: 9.092411279678345


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4744695688334393, Training Loss Force: 1.8948749273415177, time: 0.8059968948364258
Validation Loss Energy: 1.4088885862965248, Validation Loss Force: 2.778647189575441, time: 0.06398272514343262
Test Loss Energy: 14.047934072692792, Test Loss Force: 9.82127552257109, time: 8.923439025878906

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–…â–ˆâ–â–„â–…â–„â–„â–…â–â–†â–‚â–‡â–…â–„â–ˆâ–ƒâ–†â–†
wandb:   test_error_force â–…â–ƒâ–‚â–†â–‚â–„â–…â–ƒâ–ƒâ–ˆâ–‚â–‚â–…â–…â–â–ƒâ–„â–‚â–‚â–…
wandb:          test_loss â–â–‚â–‚â–†â–ƒâ–…â–†â–„â–†â–†â–‚â–…â–†â–ˆâ–…â–†â–‡â–„â–†â–ˆ
wandb: train_error_energy â–ˆâ–‚â–„â–‚â–ƒâ–‚â–…â–‚â–â–‚â–ƒâ–‚â–„â–ƒâ–‚â–â–ƒâ–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb: valid_error_energy â–ƒâ–‚â–â–‡â–„â–ƒâ–â–â–‚â–‚â–ˆâ–â–â–ƒâ–‚â–â–‚â–ƒâ–â–‚
wandb:  valid_error_force â–„â–‚â–‚â–ˆâ–â–‚â–‚â–â–â–‚â–„â–â–‚â–‚â–â–â–â–â–â–…
wandb:         valid_loss â–ƒâ–‚â–â–ˆâ–â–‚â–‚â–â–â–‚â–„â–â–‚â–‚â–â–â–â–‚â–â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1645
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.04793
wandb:   test_error_force 9.82128
wandb:          test_loss 8.38366
wandb: train_error_energy 1.47447
wandb:  train_error_force 1.89487
wandb:         train_loss -2.56337
wandb: valid_error_energy 1.40889
wandb:  valid_error_force 2.77865
wandb:         valid_loss -1.38267
wandb: 
wandb: ğŸš€ View run al_69_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nslddc12
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_165725-nslddc12/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 65.28448486328125, Uncertainty Bias: -7.989007949829102
0.00020980835 0.0069532394
-3.5593288 81.8834
(48745, 22, 3)
Found uncertainty sample 0 after 72 steps.
Found uncertainty sample 1 after 571 steps.
Found uncertainty sample 2 after 435 steps.
Found uncertainty sample 3 after 102 steps.
Found uncertainty sample 4 after 896 steps.
Found uncertainty sample 5 after 102 steps.
Found uncertainty sample 6 after 501 steps.
Found uncertainty sample 7 after 32 steps.
Found uncertainty sample 8 after 79 steps.
Found uncertainty sample 9 after 92 steps.
Found uncertainty sample 10 after 614 steps.
Found uncertainty sample 11 after 1123 steps.
Found uncertainty sample 12 after 123 steps.
Found uncertainty sample 13 after 417 steps.
Found uncertainty sample 14 after 188 steps.
Found uncertainty sample 15 after 75 steps.
Found uncertainty sample 16 after 933 steps.
Found uncertainty sample 17 after 378 steps.
Found uncertainty sample 18 after 916 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 330 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 44 steps.
Found uncertainty sample 23 after 21 steps.
Found uncertainty sample 24 after 659 steps.
Found uncertainty sample 25 after 1077 steps.
Found uncertainty sample 26 after 1756 steps.
Found uncertainty sample 27 after 309 steps.
Found uncertainty sample 28 after 211 steps.
Found uncertainty sample 29 after 957 steps.
Found uncertainty sample 30 after 242 steps.
Found uncertainty sample 31 after 143 steps.
Found uncertainty sample 32 after 119 steps.
Found uncertainty sample 33 after 758 steps.
Found uncertainty sample 34 after 273 steps.
Found uncertainty sample 35 after 19 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1838 steps.
Found uncertainty sample 38 after 124 steps.
Found uncertainty sample 39 after 583 steps.
Found uncertainty sample 40 after 1056 steps.
Found uncertainty sample 41 after 2682 steps.
Found uncertainty sample 42 after 918 steps.
Found uncertainty sample 43 after 119 steps.
Found uncertainty sample 44 after 519 steps.
Found uncertainty sample 45 after 161 steps.
Found uncertainty sample 46 after 274 steps.
Found uncertainty sample 47 after 314 steps.
Found uncertainty sample 48 after 153 steps.
Found uncertainty sample 49 after 385 steps.
Found uncertainty sample 50 after 956 steps.
Found uncertainty sample 51 after 549 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 20 steps.
Found uncertainty sample 54 after 35 steps.
Found uncertainty sample 55 after 116 steps.
Found uncertainty sample 56 after 429 steps.
Found uncertainty sample 57 after 667 steps.
Found uncertainty sample 58 after 29 steps.
Found uncertainty sample 59 after 17 steps.
Found uncertainty sample 60 after 320 steps.
Found uncertainty sample 61 after 889 steps.
Found uncertainty sample 62 after 1747 steps.
Found uncertainty sample 63 after 794 steps.
Found uncertainty sample 64 after 330 steps.
Found uncertainty sample 65 after 288 steps.
Found uncertainty sample 66 after 171 steps.
Found uncertainty sample 67 after 659 steps.
Found uncertainty sample 68 after 38 steps.
Found uncertainty sample 69 after 268 steps.
Found uncertainty sample 70 after 195 steps.
Found uncertainty sample 71 after 2001 steps.
Found uncertainty sample 72 after 81 steps.
Found uncertainty sample 73 after 442 steps.
Found uncertainty sample 74 after 11 steps.
Found uncertainty sample 75 after 317 steps.
Found uncertainty sample 76 after 786 steps.
Found uncertainty sample 77 after 277 steps.
Found uncertainty sample 78 after 267 steps.
Found uncertainty sample 79 after 1017 steps.
Found uncertainty sample 80 after 151 steps.
Found uncertainty sample 81 after 235 steps.
Found uncertainty sample 82 after 290 steps.
Found uncertainty sample 83 after 440 steps.
Found uncertainty sample 84 after 348 steps.
Found uncertainty sample 85 after 335 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 801 steps.
Found uncertainty sample 88 after 102 steps.
Found uncertainty sample 89 after 227 steps.
Found uncertainty sample 90 after 54 steps.
Found uncertainty sample 91 after 565 steps.
Found uncertainty sample 92 after 1934 steps.
Found uncertainty sample 93 after 93 steps.
Found uncertainty sample 94 after 781 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 261 steps.
Found uncertainty sample 97 after 346 steps.
Found uncertainty sample 98 after 451 steps.
Found uncertainty sample 99 after 14 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_170744-btkthw5v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/btkthw5v
Training model 10. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.761590161302687, Training Loss Force: 2.1426958923141934, time: 0.844123125076294
Validation Loss Energy: 1.4092019374521318, Validation Loss Force: 2.248262198785914, time: 0.06576728820800781
Test Loss Energy: 13.483857503071894, Test Loss Force: 9.75371178606003, time: 9.279882192611694


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.13561075660464, Training Loss Force: 1.8685557571241866, time: 0.8374111652374268
Validation Loss Energy: 2.0827560636605567, Validation Loss Force: 2.227284204544338, time: 0.06859016418457031
Test Loss Energy: 15.439416774482224, Test Loss Force: 9.776471622525083, time: 8.864644289016724


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4976611078481705, Training Loss Force: 1.8862943990918386, time: 0.8194606304168701
Validation Loss Energy: 0.9930576024836457, Validation Loss Force: 2.224658378640985, time: 0.06162738800048828
Test Loss Energy: 13.789892349768406, Test Loss Force: 9.648474113483365, time: 9.128258466720581


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4843067555752245, Training Loss Force: 1.8403028400270212, time: 0.865572452545166
Validation Loss Energy: 3.745400301344129, Validation Loss Force: 3.241349221430465, time: 0.06346821784973145
Test Loss Energy: 12.881820801081863, Test Loss Force: 9.731780381408848, time: 8.817915678024292


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.478482457428875, Training Loss Force: 1.870246603380849, time: 0.8154945373535156
Validation Loss Energy: 2.1292910761278536, Validation Loss Force: 2.1734629566167056, time: 0.06186270713806152
Test Loss Energy: 12.787187990233683, Test Loss Force: 9.705209293209812, time: 9.043193101882935


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4013208990600015, Training Loss Force: 1.9012438853133353, time: 0.8322057723999023
Validation Loss Energy: 0.9414162298273596, Validation Loss Force: 2.212650944946829, time: 0.06197166442871094
Test Loss Energy: 14.062303180815134, Test Loss Force: 9.682796746000756, time: 9.020753860473633


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4548933789935385, Training Loss Force: 1.8718494669851606, time: 0.850837230682373
Validation Loss Energy: 1.636421438711527, Validation Loss Force: 2.253859544441674, time: 0.061414480209350586
Test Loss Energy: 14.9331923676354, Test Loss Force: 9.717934030492724, time: 8.9396493434906


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8958313702306828, Training Loss Force: 1.8753072030360851, time: 0.8166370391845703
Validation Loss Energy: 1.9642691907276024, Validation Loss Force: 2.1641161965472406, time: 0.0636749267578125
Test Loss Energy: 13.338571905581599, Test Loss Force: 9.680886118821533, time: 8.879662036895752


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.628313328397174, Training Loss Force: 1.852828906598812, time: 0.8543798923492432
Validation Loss Energy: 1.3871656524272478, Validation Loss Force: 2.120702615834846, time: 0.06252074241638184
Test Loss Energy: 13.498384736598823, Test Loss Force: 9.699273470050617, time: 9.028294801712036


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.553944821472379, Training Loss Force: 1.8836426625969598, time: 0.8215346336364746
Validation Loss Energy: 1.8149669676878428, Validation Loss Force: 2.2857625776590504, time: 0.0634775161743164
Test Loss Energy: 13.192886944566148, Test Loss Force: 9.720528841848308, time: 8.909703731536865


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3444869011511968, Training Loss Force: 1.8853307335863578, time: 0.8592054843902588
Validation Loss Energy: 1.011581170396946, Validation Loss Force: 2.217199518925269, time: 0.06587481498718262
Test Loss Energy: 13.943814343788757, Test Loss Force: 9.75018790576307, time: 8.881255626678467


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2816756514752736, Training Loss Force: 1.893809169005833, time: 0.8255956172943115
Validation Loss Energy: 1.9115080706037322, Validation Loss Force: 2.149405726423381, time: 0.06425976753234863
Test Loss Energy: 13.40036755991458, Test Loss Force: 9.674288051974594, time: 8.867668390274048


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3059164786123767, Training Loss Force: 1.855872895036893, time: 0.9945461750030518
Validation Loss Energy: 1.810627257368283, Validation Loss Force: 2.1801671905968725, time: 0.06222677230834961
Test Loss Energy: 14.868373304644164, Test Loss Force: 9.673430381719992, time: 9.272628784179688


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.815838094932674, Training Loss Force: 1.8581694924624022, time: 0.7875800132751465
Validation Loss Energy: 2.139336015304375, Validation Loss Force: 2.5424490003447993, time: 0.061916351318359375
Test Loss Energy: 13.387432781507671, Test Loss Force: 9.693442821339955, time: 8.896601438522339


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6103849409410846, Training Loss Force: 1.855278342101821, time: 0.8110129833221436
Validation Loss Energy: 1.6017123845844545, Validation Loss Force: 2.1858130224591577, time: 0.06284427642822266
Test Loss Energy: 13.436245434991065, Test Loss Force: 9.71446249493216, time: 8.959438800811768


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.102925643397987, Training Loss Force: 1.8896952593700986, time: 0.906423807144165
Validation Loss Energy: 1.98363238832291, Validation Loss Force: 2.3322060174400847, time: 0.09129667282104492
Test Loss Energy: 13.143059959677213, Test Loss Force: 9.708953991351107, time: 8.994980096817017


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7472080087374373, Training Loss Force: 1.8975202883749682, time: 0.8693044185638428
Validation Loss Energy: 1.9340719145026055, Validation Loss Force: 2.273692685269462, time: 0.06999707221984863
Test Loss Energy: 13.036308122918548, Test Loss Force: 9.698240383141304, time: 8.899474620819092


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6203412436276718, Training Loss Force: 1.8683146772884205, time: 0.816399335861206
Validation Loss Energy: 3.3830003099470005, Validation Loss Force: 2.234404050485379, time: 0.06818556785583496
Test Loss Energy: 15.938636844716012, Test Loss Force: 9.72999400128144, time: 8.941032648086548


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7332234764660719, Training Loss Force: 1.8886312692687872, time: 0.833575963973999
Validation Loss Energy: 1.5749334694204546, Validation Loss Force: 2.2107205147862077, time: 0.06131386756896973
Test Loss Energy: 13.425316278384772, Test Loss Force: 9.672639610136956, time: 9.082534313201904


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5782618488674496, Training Loss Force: 1.873726100280125, time: 0.8576648235321045
Validation Loss Energy: 4.681856158441298, Validation Loss Force: 2.171136732049198, time: 0.06572103500366211
Test Loss Energy: 12.455477054734372, Test Loss Force: 9.641843669843125, time: 8.96553087234497

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‡â–„â–‚â–‚â–„â–†â–ƒâ–ƒâ–‚â–„â–ƒâ–†â–ƒâ–ƒâ–‚â–‚â–ˆâ–ƒâ–
wandb:   test_error_force â–‡â–ˆâ–â–†â–„â–ƒâ–…â–ƒâ–„â–…â–‡â–ƒâ–ƒâ–„â–…â–„â–„â–†â–ƒâ–
wandb:          test_loss â–â–ˆâ–…â–†â–†â–…â–‡â–…â–†â–„â–…â–ƒâ–…â–„â–…â–„â–ƒâ–‡â–ƒâ–‚
wandb: train_error_energy â–…â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–†â–„â–„â–‚â–ˆâ–‚â–…â–„â–‡â–…â–„â–…â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–â–ƒâ–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–‚â–ƒâ–â–†â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–ˆ
wandb:  valid_error_force â–‚â–‚â–‚â–ˆâ–â–‚â–‚â–â–â–‚â–‚â–â–â–„â–â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–‚â–‚â–â–ˆâ–‚â–â–‚â–â–â–‚â–â–â–â–„â–â–‚â–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1735
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.45548
wandb:   test_error_force 9.64184
wandb:          test_loss 7.92731
wandb: train_error_energy 1.57826
wandb:  train_error_force 1.87373
wandb:         train_loss -2.58475
wandb: valid_error_energy 4.68186
wandb:  valid_error_force 2.17114
wandb:         valid_loss -1.97958
wandb: 
wandb: ğŸš€ View run al_69_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/btkthw5v
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_170744-btkthw5v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 72.30541229248047, Uncertainty Bias: -8.903060913085938
0.000102996826 0.73949814
-4.1614547 75.212746
(48745, 22, 3)
Found uncertainty sample 0 after 756 steps.
Found uncertainty sample 1 after 387 steps.
Found uncertainty sample 2 after 50 steps.
Found uncertainty sample 3 after 636 steps.
Found uncertainty sample 4 after 3 steps.
Found uncertainty sample 5 after 12 steps.
Found uncertainty sample 6 after 314 steps.
Found uncertainty sample 7 after 197 steps.
Found uncertainty sample 8 after 469 steps.
Found uncertainty sample 9 after 38 steps.
Found uncertainty sample 10 after 716 steps.
Found uncertainty sample 11 after 574 steps.
Found uncertainty sample 12 after 6 steps.
Found uncertainty sample 13 after 134 steps.
Found uncertainty sample 14 after 1999 steps.
Found uncertainty sample 15 after 154 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 58 steps.
Found uncertainty sample 18 after 484 steps.
Found uncertainty sample 19 after 314 steps.
Found uncertainty sample 20 after 40 steps.
Found uncertainty sample 21 after 45 steps.
Found uncertainty sample 22 after 1333 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 88 steps.
Found uncertainty sample 25 after 8 steps.
Found uncertainty sample 26 after 972 steps.
Found uncertainty sample 27 after 106 steps.
Found uncertainty sample 28 after 1217 steps.
Found uncertainty sample 29 after 5 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 58 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 173 steps.
Found uncertainty sample 34 after 1776 steps.
Found uncertainty sample 35 after 378 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 629 steps.
Found uncertainty sample 38 after 1821 steps.
Found uncertainty sample 39 after 226 steps.
Found uncertainty sample 40 after 98 steps.
Found uncertainty sample 41 after 26 steps.
Found uncertainty sample 42 after 389 steps.
Found uncertainty sample 43 after 446 steps.
Found uncertainty sample 44 after 317 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 2651 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 147 steps.
Found uncertainty sample 49 after 3781 steps.
Found uncertainty sample 50 after 998 steps.
Found uncertainty sample 51 after 74 steps.
Found uncertainty sample 52 after 251 steps.
Found uncertainty sample 53 after 498 steps.
Found uncertainty sample 54 after 186 steps.
Found uncertainty sample 55 after 665 steps.
Found uncertainty sample 56 after 9 steps.
Found uncertainty sample 57 after 540 steps.
Found uncertainty sample 58 after 245 steps.
Found uncertainty sample 59 after 529 steps.
Found uncertainty sample 60 after 240 steps.
Found uncertainty sample 61 after 29 steps.
Found uncertainty sample 62 after 383 steps.
Found uncertainty sample 63 after 1384 steps.
Found uncertainty sample 64 after 1190 steps.
Found uncertainty sample 65 after 367 steps.
Found uncertainty sample 66 after 124 steps.
Found uncertainty sample 67 after 424 steps.
Found uncertainty sample 68 after 497 steps.
Found uncertainty sample 69 after 32 steps.
Found uncertainty sample 70 after 1277 steps.
Found uncertainty sample 71 after 19 steps.
Found uncertainty sample 72 after 60 steps.
Found uncertainty sample 73 after 1310 steps.
Found uncertainty sample 74 after 1144 steps.
Found uncertainty sample 75 after 1407 steps.
Found uncertainty sample 76 after 1223 steps.
Found uncertainty sample 77 after 164 steps.
Found uncertainty sample 78 after 186 steps.
Found uncertainty sample 79 after 289 steps.
Found uncertainty sample 80 after 185 steps.
Found uncertainty sample 81 after 792 steps.
Found uncertainty sample 82 after 1088 steps.
Found uncertainty sample 83 after 250 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 885 steps.
Found uncertainty sample 86 after 2716 steps.
Found uncertainty sample 87 after 24 steps.
Found uncertainty sample 88 after 11 steps.
Found uncertainty sample 89 after 964 steps.
Found uncertainty sample 90 after 724 steps.
Found uncertainty sample 91 after 22 steps.
Found uncertainty sample 92 after 76 steps.
Found uncertainty sample 93 after 361 steps.
Found uncertainty sample 94 after 136 steps.
Found uncertainty sample 95 after 144 steps.
Found uncertainty sample 96 after 350 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 857 steps.
Found uncertainty sample 99 after 194 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_171856-1vuqtluv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1vuqtluv
Training model 11. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.265577977182727, Training Loss Force: 2.206353062625599, time: 0.8905200958251953
Validation Loss Energy: 1.709698625933746, Validation Loss Force: 2.383084358600563, time: 0.06534743309020996
Test Loss Energy: 14.799328564166752, Test Loss Force: 9.627969964430456, time: 8.681641578674316


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4347283455066215, Training Loss Force: 1.8819229274867955, time: 0.8512482643127441
Validation Loss Energy: 1.0217150937309087, Validation Loss Force: 2.236547909022372, time: 0.06375241279602051
Test Loss Energy: 14.367997700455335, Test Loss Force: 9.697934610605857, time: 8.753395557403564


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.509554395869057, Training Loss Force: 1.8932110031129363, time: 0.8470871448516846
Validation Loss Energy: 2.3842459122002952, Validation Loss Force: 2.896316922410126, time: 0.06255245208740234
Test Loss Energy: 14.874949901988533, Test Loss Force: 9.728567351902832, time: 8.913870573043823


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7173815562437424, Training Loss Force: 1.8883521494458366, time: 0.859290599822998
Validation Loss Energy: 1.948450162260741, Validation Loss Force: 2.2433532347947898, time: 0.06366443634033203
Test Loss Energy: 13.130949667993129, Test Loss Force: 9.638386506351836, time: 9.153953313827515


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5562920499551958, Training Loss Force: 1.8931470716759593, time: 0.8320739269256592
Validation Loss Energy: 1.0239651097832225, Validation Loss Force: 2.2598727247274537, time: 0.061982154846191406
Test Loss Energy: 14.29282863980895, Test Loss Force: 9.716984116921354, time: 8.775476694107056


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.829389064665202, Training Loss Force: 1.8581873985420505, time: 0.8209733963012695
Validation Loss Energy: 2.205441363339979, Validation Loss Force: 2.2109626674824043, time: 0.07124733924865723
Test Loss Energy: 12.781638398949076, Test Loss Force: 9.61856358498862, time: 8.951131820678711


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.406495614210978, Training Loss Force: 1.8825431899719205, time: 0.858222246170044
Validation Loss Energy: 0.9628637497967674, Validation Loss Force: 2.1881951926495797, time: 0.061754703521728516
Test Loss Energy: 13.885926027006551, Test Loss Force: 9.658032542143465, time: 8.707069635391235


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.778352655756449, Training Loss Force: 1.87945246214368, time: 0.8420441150665283
Validation Loss Energy: 3.4815660320722386, Validation Loss Force: 2.839521148696617, time: 0.062256574630737305
Test Loss Energy: 13.056562085116003, Test Loss Force: 9.663808211393803, time: 8.769794225692749


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9679376932287156, Training Loss Force: 1.8673335766822727, time: 0.8821806907653809
Validation Loss Energy: 1.9875825946389556, Validation Loss Force: 2.7591166561169684, time: 0.06212258338928223
Test Loss Energy: 14.00127653011601, Test Loss Force: 9.670530763117194, time: 8.732829332351685


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.640849485201781, Training Loss Force: 1.8526633520533016, time: 1.0636520385742188
Validation Loss Energy: 2.107593637875785, Validation Loss Force: 2.230710748696448, time: 0.07195448875427246
Test Loss Energy: 13.156679817600294, Test Loss Force: 9.641525950117062, time: 8.858834505081177


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5882670277689457, Training Loss Force: 1.8463542640049644, time: 0.8571381568908691
Validation Loss Energy: 3.398017785155808, Validation Loss Force: 2.408960851383404, time: 0.06275558471679688
Test Loss Energy: 13.016706998677593, Test Loss Force: 9.675358108956974, time: 8.782392501831055


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8890612549669488, Training Loss Force: 1.8530733894725748, time: 0.8678064346313477
Validation Loss Energy: 1.5471362325848403, Validation Loss Force: 2.151322685100673, time: 0.061809539794921875
Test Loss Energy: 14.824580387805867, Test Loss Force: 9.68501873692602, time: 8.762089967727661


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9169131370571975, Training Loss Force: 1.8592198860731453, time: 0.8741128444671631
Validation Loss Energy: 5.130350340102108, Validation Loss Force: 2.2575274619479693, time: 0.062207937240600586
Test Loss Energy: 12.22728011811375, Test Loss Force: 9.618427031677621, time: 9.017332315444946


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8134500145988284, Training Loss Force: 1.8565548274288703, time: 0.8686618804931641
Validation Loss Energy: 4.0517797416592956, Validation Loss Force: 2.4749144503960583, time: 0.06457924842834473
Test Loss Energy: 12.662342720855333, Test Loss Force: 9.677324429070431, time: 8.946107149124146


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.753469376905234, Training Loss Force: 1.9059006579586906, time: 0.8332583904266357
Validation Loss Energy: 4.047016625958754, Validation Loss Force: 2.192681085263441, time: 0.06407904624938965
Test Loss Energy: 12.590309457329734, Test Loss Force: 9.63197537433323, time: 8.792880296707153


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5306950118335891, Training Loss Force: 1.863762459704074, time: 0.8390102386474609
Validation Loss Energy: 2.1725759540739022, Validation Loss Force: 3.0782847091574927, time: 0.062456607818603516
Test Loss Energy: 13.893156539513118, Test Loss Force: 9.568993805113564, time: 9.379952669143677


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.666939856582381, Training Loss Force: 1.9004249482537512, time: 0.8885269165039062
Validation Loss Energy: 3.4670854121742627, Validation Loss Force: 2.7537503297001087, time: 0.062194108963012695
Test Loss Energy: 13.194919953505906, Test Loss Force: 9.606428214463346, time: 8.729562759399414


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3227873804898178, Training Loss Force: 1.8858097502491578, time: 0.863286018371582
Validation Loss Energy: 2.366366414791591, Validation Loss Force: 3.0259412050168097, time: 0.06224250793457031
Test Loss Energy: 13.483725337858617, Test Loss Force: 9.63862809421452, time: 8.814961194992065


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.47777841786167, Training Loss Force: 1.9162412998077663, time: 0.8317556381225586
Validation Loss Energy: 1.6052627884489867, Validation Loss Force: 2.1494230946167634, time: 0.06231951713562012
Test Loss Energy: 13.504205564550926, Test Loss Force: 9.635277863208785, time: 10.2052481174469


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4741862264207521, Training Loss Force: 1.8580709777370161, time: 0.9177296161651611
Validation Loss Energy: 3.242287883215124, Validation Loss Force: 2.214213414343804, time: 0.0752403736114502
Test Loss Energy: 16.30149911911897, Test Loss Force: 9.61881137494479, time: 10.1462721824646

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–…â–†â–ƒâ–…â–‚â–„â–‚â–„â–ƒâ–‚â–…â–â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ˆ
wandb:   test_error_force â–„â–‡â–ˆâ–„â–‡â–ƒâ–…â–…â–…â–„â–†â–†â–ƒâ–†â–„â–â–ƒâ–„â–„â–ƒ
wandb:          test_loss â–â–…â–‡â–…â–†â–„â–…â–†â–†â–…â–‡â–ˆâ–†â–‡â–„â–†â–…â–†â–…â–ˆ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–†â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–ƒâ–â–‚â–â–‚â–
wandb: valid_error_energy â–‚â–â–ƒâ–ƒâ–â–ƒâ–â–…â–ƒâ–ƒâ–…â–‚â–ˆâ–†â–†â–ƒâ–…â–ƒâ–‚â–…
wandb:  valid_error_force â–ƒâ–‚â–‡â–‚â–‚â–â–â–†â–†â–‚â–ƒâ–â–‚â–ƒâ–â–ˆâ–†â–ˆâ–â–
wandb:         valid_loss â–ƒâ–â–‡â–‚â–‚â–‚â–â–‡â–†â–‚â–„â–â–ƒâ–„â–‚â–ˆâ–†â–ˆâ–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1824
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 16.3015
wandb:   test_error_force 9.61881
wandb:          test_loss 8.3119
wandb: train_error_energy 1.47419
wandb:  train_error_force 1.85807
wandb:         train_loss -2.61294
wandb: valid_error_energy 3.24229
wandb:  valid_error_force 2.21421
wandb:         valid_loss -2.01314
wandb: 
wandb: ğŸš€ View run al_69_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1vuqtluv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_171856-1vuqtluv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 77.87068939208984, Uncertainty Bias: -9.500259399414062
0.00011444092 0.0015220642
-3.8724337 75.85907
(48745, 22, 3)
Found uncertainty sample 0 after 679 steps.
Found uncertainty sample 1 after 857 steps.
Found uncertainty sample 2 after 76 steps.
Found uncertainty sample 3 after 117 steps.
Found uncertainty sample 4 after 332 steps.
Found uncertainty sample 5 after 1714 steps.
Found uncertainty sample 6 after 1360 steps.
Found uncertainty sample 7 after 311 steps.
Found uncertainty sample 8 after 103 steps.
Found uncertainty sample 9 after 473 steps.
Found uncertainty sample 10 after 817 steps.
Found uncertainty sample 11 after 498 steps.
Found uncertainty sample 12 after 174 steps.
Found uncertainty sample 13 after 55 steps.
Found uncertainty sample 14 after 55 steps.
Found uncertainty sample 15 after 273 steps.
Found uncertainty sample 16 after 595 steps.
Found uncertainty sample 17 after 1386 steps.
Found uncertainty sample 18 after 2160 steps.
Found uncertainty sample 19 after 21 steps.
Found uncertainty sample 20 after 771 steps.
Found uncertainty sample 21 after 1185 steps.
Found uncertainty sample 22 after 533 steps.
Found uncertainty sample 23 after 90 steps.
Found uncertainty sample 24 after 2631 steps.
Found uncertainty sample 25 after 12 steps.
Found uncertainty sample 26 after 306 steps.
Found uncertainty sample 27 after 1112 steps.
Found uncertainty sample 28 after 743 steps.
Found uncertainty sample 29 after 361 steps.
Found uncertainty sample 30 after 177 steps.
Found uncertainty sample 31 after 1020 steps.
Found uncertainty sample 32 after 16 steps.
Found uncertainty sample 33 after 1992 steps.
Found uncertainty sample 34 after 344 steps.
Found uncertainty sample 35 after 603 steps.
Found uncertainty sample 36 after 2078 steps.
Found uncertainty sample 37 after 992 steps.
Found uncertainty sample 38 after 47 steps.
Found uncertainty sample 39 after 1496 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 30 steps.
Found uncertainty sample 42 after 3143 steps.
Found uncertainty sample 43 after 1509 steps.
Found uncertainty sample 44 after 53 steps.
Found uncertainty sample 45 after 3948 steps.
Found uncertainty sample 46 after 1332 steps.
Found uncertainty sample 47 after 361 steps.
Found uncertainty sample 48 after 134 steps.
Found uncertainty sample 49 after 14 steps.
Found uncertainty sample 50 after 15 steps.
Found uncertainty sample 51 after 26 steps.
Found uncertainty sample 52 after 846 steps.
Found uncertainty sample 53 after 511 steps.
Found uncertainty sample 54 after 406 steps.
Found uncertainty sample 55 after 54 steps.
Found uncertainty sample 56 after 17 steps.
Found uncertainty sample 57 after 1756 steps.
Found uncertainty sample 58 after 119 steps.
Found uncertainty sample 59 after 290 steps.
Found uncertainty sample 60 after 259 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 769 steps.
Found uncertainty sample 63 after 1007 steps.
Found uncertainty sample 64 after 388 steps.
Found uncertainty sample 65 after 209 steps.
Found uncertainty sample 66 after 817 steps.
Found uncertainty sample 67 after 1422 steps.
Found uncertainty sample 68 after 986 steps.
Found uncertainty sample 69 after 11 steps.
Found uncertainty sample 70 after 913 steps.
Found uncertainty sample 71 after 129 steps.
Found uncertainty sample 72 after 379 steps.
Found uncertainty sample 73 after 419 steps.
Found uncertainty sample 74 after 1447 steps.
Found uncertainty sample 75 after 543 steps.
Found uncertainty sample 76 after 251 steps.
Found uncertainty sample 77 after 346 steps.
Found uncertainty sample 78 after 76 steps.
Found uncertainty sample 79 after 1959 steps.
Found uncertainty sample 80 after 129 steps.
Found uncertainty sample 81 after 821 steps.
Found uncertainty sample 82 after 32 steps.
Found uncertainty sample 83 after 179 steps.
Found uncertainty sample 84 after 702 steps.
Found uncertainty sample 85 after 178 steps.
Found uncertainty sample 86 after 582 steps.
Found uncertainty sample 87 after 939 steps.
Found uncertainty sample 88 after 464 steps.
Found uncertainty sample 89 after 309 steps.
Found uncertainty sample 90 after 146 steps.
Found uncertainty sample 91 after 259 steps.
Found uncertainty sample 92 after 46 steps.
Found uncertainty sample 93 after 485 steps.
Found uncertainty sample 94 after 6 steps.
Found uncertainty sample 95 after 175 steps.
Found uncertainty sample 96 after 741 steps.
Found uncertainty sample 97 after 93 steps.
Found uncertainty sample 98 after 35 steps.
Found uncertainty sample 99 after 2846 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_173109-wqlfkjmc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wqlfkjmc
Training model 12. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1210943860958524, Training Loss Force: 2.08801364588885, time: 0.9390370845794678
Validation Loss Energy: 2.7408878464855904, Validation Loss Force: 2.1628034505974236, time: 0.06553244590759277
Test Loss Energy: 12.90994778935517, Test Loss Force: 9.577901834685514, time: 8.950276851654053


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4200906563068676, Training Loss Force: 1.881983529824717, time: 0.8721654415130615
Validation Loss Energy: 0.9788905285767793, Validation Loss Force: 2.201950579139269, time: 0.06746697425842285
Test Loss Energy: 13.406870221776039, Test Loss Force: 9.646386395550513, time: 8.974032402038574


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.558924486544143, Training Loss Force: 1.887747424579326, time: 0.9936578273773193
Validation Loss Energy: 1.265552226349035, Validation Loss Force: 2.2585083195357814, time: 0.06738471984863281
Test Loss Energy: 13.609383426562866, Test Loss Force: 9.691516791518032, time: 9.10555386543274


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4467501187519585, Training Loss Force: 1.909260043729122, time: 0.8874692916870117
Validation Loss Energy: 2.151430401300016, Validation Loss Force: 2.705088103214477, time: 0.06510734558105469
Test Loss Energy: 14.421216824781723, Test Loss Force: 9.575677488830015, time: 8.917404651641846


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6856068486224305, Training Loss Force: 1.882962060519954, time: 0.9393661022186279
Validation Loss Energy: 1.6617426503117105, Validation Loss Force: 2.1698062839022794, time: 0.06737709045410156
Test Loss Energy: 14.902247577097835, Test Loss Force: 9.606854564090025, time: 8.958407163619995


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8808491260883902, Training Loss Force: 1.8464178916157514, time: 0.8955655097961426
Validation Loss Energy: 2.6658344274863053, Validation Loss Force: 2.7610426328946707, time: 0.06675171852111816
Test Loss Energy: 14.746663804407236, Test Loss Force: 9.631452155467423, time: 9.163720846176147


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.192316467649204, Training Loss Force: 1.8746312692514615, time: 0.9131155014038086
Validation Loss Energy: 1.0841886801627871, Validation Loss Force: 2.0851860520500667, time: 0.0657033920288086
Test Loss Energy: 13.58466245083087, Test Loss Force: 9.558274335225931, time: 8.907641410827637


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4750451760693355, Training Loss Force: 1.8570801141986135, time: 0.9196538925170898
Validation Loss Energy: 2.797203545520479, Validation Loss Force: 2.196403445375916, time: 0.06631875038146973
Test Loss Energy: 13.000894019874949, Test Loss Force: 9.541031675946355, time: 9.349320650100708


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4266726124533367, Training Loss Force: 1.8943177583241655, time: 0.8735013008117676
Validation Loss Energy: 1.3996502661011267, Validation Loss Force: 2.394535564768191, time: 0.06491851806640625
Test Loss Energy: 13.694086182107045, Test Loss Force: 9.676927905451238, time: 9.087656736373901


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.002280614774194, Training Loss Force: 1.8682407389863827, time: 0.8857986927032471
Validation Loss Energy: 1.5976728879408921, Validation Loss Force: 2.173900278819308, time: 0.06509232521057129
Test Loss Energy: 14.766519895312543, Test Loss Force: 9.549125272715452, time: 8.911043167114258


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5547172922000534, Training Loss Force: 1.8450034118443122, time: 0.8975248336791992
Validation Loss Energy: 1.968685554900648, Validation Loss Force: 2.322152505501445, time: 0.06655073165893555
Test Loss Energy: 13.161907865311726, Test Loss Force: 9.544579585858164, time: 8.968668699264526


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.091059746816109, Training Loss Force: 1.8635105096631188, time: 0.95448899269104
Validation Loss Energy: 2.808461363534869, Validation Loss Force: 2.2199385720893265, time: 0.06806778907775879
Test Loss Energy: 15.846689176616627, Test Loss Force: 9.593169924600968, time: 9.201281309127808


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.779175309162303, Training Loss Force: 1.880290093858412, time: 0.9117617607116699
Validation Loss Energy: 1.7360409982371545, Validation Loss Force: 2.431785329517586, time: 0.0727238655090332
Test Loss Energy: 14.760022316369806, Test Loss Force: 9.620708017102679, time: 8.96569561958313


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4895090057859204, Training Loss Force: 1.863787855217829, time: 0.9032268524169922
Validation Loss Energy: 1.826242933237626, Validation Loss Force: 2.6772289643562948, time: 0.06509160995483398
Test Loss Energy: 14.229371062245644, Test Loss Force: 9.622403011947307, time: 8.874947786331177


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5787004960358144, Training Loss Force: 1.9154655711898831, time: 0.9023900032043457
Validation Loss Energy: 1.1085829479421168, Validation Loss Force: 2.210692347139248, time: 0.0704340934753418
Test Loss Energy: 14.144322574963686, Test Loss Force: 9.567948878267886, time: 9.05306601524353


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3184415627494275, Training Loss Force: 1.9051938267880482, time: 0.8623020648956299
Validation Loss Energy: 1.2878783152673443, Validation Loss Force: 2.2149423217929987, time: 0.06649494171142578
Test Loss Energy: 13.81133657298121, Test Loss Force: 9.59296692961476, time: 8.95282244682312


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8499817057295969, Training Loss Force: 1.8805624442019488, time: 0.9268238544464111
Validation Loss Energy: 1.5672187628560676, Validation Loss Force: 2.3157184805298616, time: 0.06504440307617188
Test Loss Energy: 13.773160309312075, Test Loss Force: 9.583045062939455, time: 8.882634401321411


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9125253086188363, Training Loss Force: 1.8427481389445781, time: 0.8972952365875244
Validation Loss Energy: 2.0439918703824205, Validation Loss Force: 2.3642825099221394, time: 0.06958770751953125
Test Loss Energy: 13.426947387003237, Test Loss Force: 9.583431588597415, time: 9.058485507965088


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.732754564933967, Training Loss Force: 1.846254979446286, time: 0.8881659507751465
Validation Loss Energy: 2.6822433621880157, Validation Loss Force: 2.3955625148692103, time: 0.06629610061645508
Test Loss Energy: 13.309584001446876, Test Loss Force: 9.554540483753396, time: 8.957969188690186


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9068966157862703, Training Loss Force: 1.8631966649242384, time: 0.8928158283233643
Validation Loss Energy: 2.7251639534113266, Validation Loss Force: 2.193496499675829, time: 0.06983041763305664
Test Loss Energy: 13.09062304058368, Test Loss Force: 9.548234894578345, time: 9.435627460479736

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–ƒâ–…â–†â–…â–ƒâ–â–ƒâ–…â–‚â–ˆâ–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–
wandb:   test_error_force â–ƒâ–†â–ˆâ–ƒâ–„â–…â–‚â–â–‡â–â–â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–
wandb:          test_loss â–â–…â–†â–…â–‡â–ˆâ–…â–…â–†â–…â–†â–ˆâ–‡â–†â–ƒâ–„â–„â–†â–†â–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–„â–‚â–„â–ƒâ–‚â–‚â–…â–ƒâ–„â–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–‚â–â–ƒâ–ƒâ–‚â–â–â–‚
wandb: valid_error_energy â–ˆâ–â–‚â–…â–„â–‡â–â–ˆâ–ƒâ–ƒâ–…â–ˆâ–„â–„â–â–‚â–ƒâ–…â–ˆâ–ˆ
wandb:  valid_error_force â–‚â–‚â–ƒâ–‡â–‚â–ˆâ–â–‚â–„â–‚â–ƒâ–‚â–…â–‡â–‚â–‚â–ƒâ–„â–„â–‚
wandb:         valid_loss â–‚â–‚â–ƒâ–‡â–‚â–ˆâ–â–ƒâ–„â–‚â–„â–ƒâ–…â–‡â–‚â–‚â–ƒâ–„â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1914
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.09062
wandb:   test_error_force 9.54823
wandb:          test_loss 8.08008
wandb: train_error_energy 1.9069
wandb:  train_error_force 1.8632
wandb:         train_loss -2.57717
wandb: valid_error_energy 2.72516
wandb:  valid_error_force 2.1935
wandb:         valid_loss -2.0735
wandb: 
wandb: ğŸš€ View run al_69_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wqlfkjmc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_173109-wqlfkjmc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 76.86894989013672, Uncertainty Bias: -9.33273696899414
4.5776367e-05 0.016152382
-3.459787 78.04872
(48745, 22, 3)
Found uncertainty sample 0 after 485 steps.
Found uncertainty sample 1 after 1917 steps.
Found uncertainty sample 2 after 99 steps.
Found uncertainty sample 3 after 102 steps.
Found uncertainty sample 4 after 1627 steps.
Found uncertainty sample 5 after 640 steps.
Found uncertainty sample 6 after 1213 steps.
Found uncertainty sample 7 after 820 steps.
Found uncertainty sample 8 after 912 steps.
Found uncertainty sample 9 after 300 steps.
Found uncertainty sample 10 after 76 steps.
Found uncertainty sample 11 after 8 steps.
Found uncertainty sample 12 after 229 steps.
Found uncertainty sample 13 after 758 steps.
Found uncertainty sample 14 after 106 steps.
Found uncertainty sample 15 after 296 steps.
Found uncertainty sample 16 after 356 steps.
Found uncertainty sample 17 after 589 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 215 steps.
Found uncertainty sample 20 after 7 steps.
Found uncertainty sample 21 after 99 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 201 steps.
Found uncertainty sample 24 after 258 steps.
Found uncertainty sample 25 after 101 steps.
Found uncertainty sample 26 after 246 steps.
Found uncertainty sample 27 after 77 steps.
Found uncertainty sample 28 after 164 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 304 steps.
Found uncertainty sample 31 after 1382 steps.
Found uncertainty sample 32 after 1605 steps.
Found uncertainty sample 33 after 933 steps.
Found uncertainty sample 34 after 233 steps.
Found uncertainty sample 35 after 24 steps.
Found uncertainty sample 36 after 31 steps.
Found uncertainty sample 37 after 23 steps.
Found uncertainty sample 38 after 2499 steps.
Found uncertainty sample 39 after 1160 steps.
Found uncertainty sample 40 after 1099 steps.
Found uncertainty sample 41 after 334 steps.
Found uncertainty sample 42 after 46 steps.
Found uncertainty sample 43 after 82 steps.
Found uncertainty sample 44 after 80 steps.
Found uncertainty sample 45 after 120 steps.
Found uncertainty sample 46 after 1171 steps.
Found uncertainty sample 47 after 411 steps.
Found uncertainty sample 48 after 1839 steps.
Found uncertainty sample 49 after 2903 steps.
Found uncertainty sample 50 after 681 steps.
Found uncertainty sample 51 after 3025 steps.
Found uncertainty sample 52 after 864 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3374 steps.
Found uncertainty sample 55 after 105 steps.
Found uncertainty sample 56 after 272 steps.
Found uncertainty sample 57 after 1998 steps.
Found uncertainty sample 58 after 2397 steps.
Found uncertainty sample 59 after 2059 steps.
Found uncertainty sample 60 after 2506 steps.
Found uncertainty sample 61 after 443 steps.
Found uncertainty sample 62 after 512 steps.
Found uncertainty sample 63 after 2837 steps.
Found uncertainty sample 64 after 397 steps.
Found uncertainty sample 65 after 1597 steps.
Found uncertainty sample 66 after 194 steps.
Found uncertainty sample 67 after 26 steps.
Found uncertainty sample 68 after 242 steps.
Found uncertainty sample 69 after 774 steps.
Found uncertainty sample 70 after 459 steps.
Found uncertainty sample 71 after 51 steps.
Found uncertainty sample 72 after 194 steps.
Found uncertainty sample 73 after 6 steps.
Found uncertainty sample 74 after 132 steps.
Found uncertainty sample 75 after 81 steps.
Found uncertainty sample 76 after 1341 steps.
Found uncertainty sample 77 after 46 steps.
Found uncertainty sample 78 after 56 steps.
Found uncertainty sample 79 after 278 steps.
Found uncertainty sample 80 after 87 steps.
Found uncertainty sample 81 after 68 steps.
Found uncertainty sample 82 after 127 steps.
Found uncertainty sample 83 after 78 steps.
Found uncertainty sample 84 after 164 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 2106 steps.
Found uncertainty sample 87 after 909 steps.
Found uncertainty sample 88 after 700 steps.
Found uncertainty sample 89 after 206 steps.
Found uncertainty sample 90 after 6 steps.
Found uncertainty sample 91 after 1422 steps.
Found uncertainty sample 92 after 1241 steps.
Found uncertainty sample 93 after 381 steps.
Found uncertainty sample 94 after 49 steps.
Found uncertainty sample 95 after 124 steps.
Found uncertainty sample 96 after 74 steps.
Found uncertainty sample 97 after 10 steps.
Found uncertainty sample 98 after 480 steps.
Found uncertainty sample 99 after 68 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_174413-m005xcol
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m005xcol
Training model 13. Added 98 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0878127007051583, Training Loss Force: 2.08833541817949, time: 1.027982234954834
Validation Loss Energy: 1.033526801245794, Validation Loss Force: 2.1598735699753053, time: 0.07008934020996094
Test Loss Energy: 13.960620151851776, Test Loss Force: 9.539670619535425, time: 8.82206392288208


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6987176519383231, Training Loss Force: 1.8622847938606264, time: 0.9717185497283936
Validation Loss Energy: 2.221810607266428, Validation Loss Force: 2.7482687720002317, time: 0.06537318229675293
Test Loss Energy: 13.727646152980915, Test Loss Force: 9.623682391916542, time: 8.75331735610962


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4860255589311921, Training Loss Force: 1.8656966877967067, time: 0.9327578544616699
Validation Loss Energy: 2.0847272979421687, Validation Loss Force: 2.45240415842678, time: 0.06702208518981934
Test Loss Energy: 15.407335760417542, Test Loss Force: 9.67512794600335, time: 8.970367431640625


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2616371452071524, Training Loss Force: 1.8496601053890198, time: 1.0090174674987793
Validation Loss Energy: 0.9668749952924403, Validation Loss Force: 2.1636053935264825, time: 0.06588006019592285
Test Loss Energy: 14.481705474181686, Test Loss Force: 9.559309012296055, time: 8.836575269699097


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5233342298311736, Training Loss Force: 1.8755316163915248, time: 0.9838435649871826
Validation Loss Energy: 0.9816573318831484, Validation Loss Force: 2.1753695611787123, time: 0.06447696685791016
Test Loss Energy: 14.180603879900307, Test Loss Force: 9.525782500084427, time: 8.841292381286621


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5098244301790922, Training Loss Force: 1.8639317502935424, time: 0.9465534687042236
Validation Loss Energy: 1.2482259504333886, Validation Loss Force: 2.3567577401392286, time: 0.0707390308380127
Test Loss Energy: 14.638693065085693, Test Loss Force: 9.67545169062023, time: 8.99115514755249


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5172819967349074, Training Loss Force: 1.8662485838781808, time: 0.9424989223480225
Validation Loss Energy: 2.745229338158317, Validation Loss Force: 2.6379182853267658, time: 0.07261824607849121
Test Loss Energy: 15.230096953957483, Test Loss Force: 9.639336573809736, time: 8.88068413734436


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8831738777260059, Training Loss Force: 1.8637034543336413, time: 0.9829025268554688
Validation Loss Energy: 1.5789622222777262, Validation Loss Force: 2.3295679447337054, time: 0.06596636772155762
Test Loss Energy: 13.688762277077007, Test Loss Force: 9.548516772732562, time: 8.7936692237854


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8239723379614685, Training Loss Force: 1.8489690640651408, time: 0.9880151748657227
Validation Loss Energy: 1.616566587642011, Validation Loss Force: 2.356470385606409, time: 0.0649864673614502
Test Loss Energy: 15.140401564450437, Test Loss Force: 9.631598086530307, time: 9.018304586410522


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7188167763625684, Training Loss Force: 1.8820405978061596, time: 0.9528951644897461
Validation Loss Energy: 2.9724780647431155, Validation Loss Force: 2.6866322823888256, time: 0.0646660327911377
Test Loss Energy: 15.450838666431663, Test Loss Force: 9.59164200855905, time: 8.907967567443848


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6618182632752998, Training Loss Force: 1.8822198199603999, time: 0.9789175987243652
Validation Loss Energy: 1.191795437620131, Validation Loss Force: 2.2212263790947997, time: 0.06716346740722656
Test Loss Energy: 13.88567816243873, Test Loss Force: 9.435781202808316, time: 8.909022092819214


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.261964939927531, Training Loss Force: 1.8774983469245783, time: 0.9274518489837646
Validation Loss Energy: 5.9077063647368355, Validation Loss Force: 2.1663140523521207, time: 0.06487250328063965
Test Loss Energy: 12.093291512669138, Test Loss Force: 9.587561068349332, time: 9.409756898880005


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3756181207603686, Training Loss Force: 1.881119675330127, time: 0.9207112789154053
Validation Loss Energy: 1.0816093642772893, Validation Loss Force: 2.2064339110579523, time: 0.07326531410217285
Test Loss Energy: 14.196725816223248, Test Loss Force: 9.558067982715428, time: 8.70430040359497


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.356973192747943, Training Loss Force: 1.8516515574989174, time: 0.9528937339782715
Validation Loss Energy: 2.3166288633329875, Validation Loss Force: 2.202905829775299, time: 0.0665276050567627
Test Loss Energy: 15.635387087738026, Test Loss Force: 9.57219485478637, time: 8.856091260910034


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.547874535434942, Training Loss Force: 1.8475661565505934, time: 0.979957103729248
Validation Loss Energy: 1.3261482943760938, Validation Loss Force: 2.143354080042642, time: 0.06455826759338379
Test Loss Energy: 14.510061711415887, Test Loss Force: 9.54124424920326, time: 8.849474906921387


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6836950672678634, Training Loss Force: 1.9050172561638599, time: 1.1388473510742188
Validation Loss Energy: 1.0963063350841773, Validation Loss Force: 2.1960864758466876, time: 0.0674581527709961
Test Loss Energy: 14.262459879196413, Test Loss Force: 9.562225045462071, time: 8.811292171478271


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6069685913889677, Training Loss Force: 1.843689251680336, time: 0.9939508438110352
Validation Loss Energy: 3.8508261815189693, Validation Loss Force: 2.3065670013013757, time: 0.07323074340820312
Test Loss Energy: 12.872407771876636, Test Loss Force: 9.471564927307703, time: 8.899818897247314


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1005342881374265, Training Loss Force: 1.8748860366849394, time: 0.9570975303649902
Validation Loss Energy: 1.0556534342766384, Validation Loss Force: 2.1867254649518832, time: 0.06572866439819336
Test Loss Energy: 13.8503246720351, Test Loss Force: 9.55453206196329, time: 8.88996958732605


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.1759478337213465, Training Loss Force: 1.8299774464907081, time: 1.03194260597229
Validation Loss Energy: 2.3167950858504227, Validation Loss Force: 2.2701926602991955, time: 0.0978693962097168
Test Loss Energy: 15.577862568039592, Test Loss Force: 9.501555248299955, time: 9.01165509223938


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7716956676998532, Training Loss Force: 1.8659804000984967, time: 0.9439737796783447
Validation Loss Energy: 1.8325210898070599, Validation Loss Force: 2.170483532109619, time: 0.0700995922088623
Test Loss Energy: 13.124719375963613, Test Loss Force: 9.478943688501563, time: 8.877152919769287

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–ˆâ–†â–…â–†â–‡â–„â–‡â–ˆâ–…â–â–…â–ˆâ–†â–…â–ƒâ–„â–ˆâ–ƒ
wandb:   test_error_force â–„â–†â–ˆâ–…â–„â–ˆâ–‡â–„â–‡â–†â–â–…â–…â–…â–„â–…â–‚â–„â–ƒâ–‚
wandb:          test_loss â–â–…â–ˆâ–†â–…â–‡â–‡â–…â–‡â–†â–‚â–„â–„â–ˆâ–‡â–…â–„â–…â–ˆâ–…
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–‚â–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–…â–…â–‚â–‚â–ƒâ–ƒâ–„â–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–‚
wandb: valid_error_energy â–â–ƒâ–ƒâ–â–â–â–„â–‚â–‚â–„â–â–ˆâ–â–ƒâ–‚â–â–…â–â–ƒâ–‚
wandb:  valid_error_force â–â–ˆâ–…â–â–â–ƒâ–‡â–ƒâ–ƒâ–‡â–‚â–â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–
wandb:         valid_loss â–â–ˆâ–…â–â–â–ƒâ–‡â–ƒâ–„â–ˆâ–‚â–„â–‚â–‚â–â–‚â–„â–â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2002
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.12472
wandb:   test_error_force 9.47894
wandb:          test_loss 8.11745
wandb: train_error_energy 1.7717
wandb:  train_error_force 1.86598
wandb:         train_loss -2.58237
wandb: valid_error_energy 1.83252
wandb:  valid_error_force 2.17048
wandb:         valid_loss -2.15962
wandb: 
wandb: ğŸš€ View run al_69_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m005xcol
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_174413-m005xcol/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 84.3673095703125, Uncertainty Bias: -10.144156455993652
0.00022697449 0.040143967
-3.347134 73.459
(48745, 22, 3)
Found uncertainty sample 0 after 306 steps.
Found uncertainty sample 1 after 190 steps.
Found uncertainty sample 2 after 108 steps.
Found uncertainty sample 3 after 2611 steps.
Found uncertainty sample 4 after 139 steps.
Found uncertainty sample 5 after 257 steps.
Found uncertainty sample 6 after 518 steps.
Found uncertainty sample 7 after 364 steps.
Found uncertainty sample 8 after 1424 steps.
Found uncertainty sample 9 after 338 steps.
Found uncertainty sample 10 after 2867 steps.
Found uncertainty sample 11 after 464 steps.
Found uncertainty sample 12 after 808 steps.
Found uncertainty sample 13 after 3441 steps.
Found uncertainty sample 14 after 2306 steps.
Found uncertainty sample 15 after 80 steps.
Found uncertainty sample 16 after 58 steps.
Found uncertainty sample 17 after 264 steps.
Found uncertainty sample 18 after 2703 steps.
Found uncertainty sample 19 after 164 steps.
Found uncertainty sample 20 after 249 steps.
Found uncertainty sample 21 after 194 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 116 steps.
Found uncertainty sample 24 after 789 steps.
Found uncertainty sample 25 after 108 steps.
Found uncertainty sample 26 after 561 steps.
Found uncertainty sample 27 after 1303 steps.
Found uncertainty sample 28 after 88 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 242 steps.
Found uncertainty sample 31 after 329 steps.
Found uncertainty sample 32 after 910 steps.
Found uncertainty sample 33 after 210 steps.
Found uncertainty sample 34 after 393 steps.
Found uncertainty sample 35 after 387 steps.
Found uncertainty sample 36 after 1004 steps.
Found uncertainty sample 37 after 123 steps.
Found uncertainty sample 38 after 473 steps.
Found uncertainty sample 39 after 147 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 105 steps.
Found uncertainty sample 42 after 111 steps.
Found uncertainty sample 43 after 924 steps.
Found uncertainty sample 44 after 661 steps.
Found uncertainty sample 45 after 71 steps.
Found uncertainty sample 46 after 95 steps.
Found uncertainty sample 47 after 12 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 369 steps.
Found uncertainty sample 50 after 1465 steps.
Found uncertainty sample 51 after 40 steps.
Found uncertainty sample 52 after 1680 steps.
Found uncertainty sample 53 after 23 steps.
Found uncertainty sample 54 after 1269 steps.
Found uncertainty sample 55 after 604 steps.
Found uncertainty sample 56 after 782 steps.
Found uncertainty sample 57 after 97 steps.
Found uncertainty sample 58 after 1026 steps.
Found uncertainty sample 59 after 432 steps.
Found uncertainty sample 60 after 781 steps.
Found uncertainty sample 61 after 392 steps.
Found uncertainty sample 62 after 2237 steps.
Found uncertainty sample 63 after 532 steps.
Found uncertainty sample 64 after 209 steps.
Found uncertainty sample 65 after 109 steps.
Found uncertainty sample 66 after 324 steps.
Found uncertainty sample 67 after 1693 steps.
Found uncertainty sample 68 after 355 steps.
Found uncertainty sample 69 after 10 steps.
Found uncertainty sample 70 after 2719 steps.
Found uncertainty sample 71 after 301 steps.
Found uncertainty sample 72 after 521 steps.
Found uncertainty sample 73 after 102 steps.
Found uncertainty sample 74 after 188 steps.
Found uncertainty sample 75 after 293 steps.
Found uncertainty sample 76 after 665 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 428 steps.
Found uncertainty sample 79 after 536 steps.
Found uncertainty sample 80 after 288 steps.
Found uncertainty sample 81 after 1458 steps.
Found uncertainty sample 82 after 27 steps.
Found uncertainty sample 83 after 1069 steps.
Found uncertainty sample 84 after 487 steps.
Found uncertainty sample 85 after 1006 steps.
Found uncertainty sample 86 after 735 steps.
Found uncertainty sample 87 after 289 steps.
Found uncertainty sample 88 after 240 steps.
Found uncertainty sample 89 after 3026 steps.
Found uncertainty sample 90 after 725 steps.
Found uncertainty sample 91 after 275 steps.
Found uncertainty sample 92 after 1137 steps.
Found uncertainty sample 93 after 599 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 33 steps.
Found uncertainty sample 96 after 715 steps.
Found uncertainty sample 97 after 467 steps.
Found uncertainty sample 98 after 608 steps.
Found uncertainty sample 99 after 971 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_175647-ml08fu3h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ml08fu3h
Training model 14. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7775427443786773, Training Loss Force: 2.072452042185198, time: 1.0629281997680664
Validation Loss Energy: 2.1898735613370106, Validation Loss Force: 2.3052159562584587, time: 0.08457756042480469
Test Loss Energy: 13.365778713026451, Test Loss Force: 9.62857700948615, time: 10.585312128067017


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2348481391224757, Training Loss Force: 1.8568355770869795, time: 1.1159462928771973
Validation Loss Energy: 1.6165079143220589, Validation Loss Force: 2.4771146442269707, time: 0.08339619636535645
Test Loss Energy: 13.812333678421833, Test Loss Force: 9.572565497489126, time: 10.494644403457642


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.207969246355398, Training Loss Force: 1.8478620847291387, time: 1.07938551902771
Validation Loss Energy: 1.8532240319861282, Validation Loss Force: 2.659107369918681, time: 0.08376097679138184
Test Loss Energy: 13.839596024914394, Test Loss Force: 9.548397170256024, time: 10.852519273757935


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3148738934144384, Training Loss Force: 1.84932947608769, time: 1.087782859802246
Validation Loss Energy: 1.6211461961326645, Validation Loss Force: 2.5125421960206653, time: 0.07697820663452148
Test Loss Energy: 14.316462621713795, Test Loss Force: 9.482679815629453, time: 11.163424253463745


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4609356764752348, Training Loss Force: 1.8828325439990927, time: 1.1152434349060059
Validation Loss Energy: 1.8732824583223087, Validation Loss Force: 2.2634790742149002, time: 0.08425784111022949
Test Loss Energy: 13.432239106432334, Test Loss Force: 9.559113040131498, time: 10.68894648551941


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7007671252656744, Training Loss Force: 1.864627139931349, time: 1.0312132835388184
Validation Loss Energy: 2.396198235280834, Validation Loss Force: 2.1318809409641397, time: 0.07937121391296387
Test Loss Energy: 13.363935334260916, Test Loss Force: 9.468654821104714, time: 10.650071620941162


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.675910131180179, Training Loss Force: 1.8648760469249719, time: 1.0177364349365234
Validation Loss Energy: 1.2051059589898996, Validation Loss Force: 2.2183110833017405, time: 0.08212876319885254
Test Loss Energy: 14.677334868151192, Test Loss Force: 9.495039795203578, time: 10.699686527252197


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4252603706755025, Training Loss Force: 1.8720260898385979, time: 0.9916412830352783
Validation Loss Energy: 3.232177145305981, Validation Loss Force: 2.1981649809893504, time: 0.07889795303344727
Test Loss Energy: 12.994394473049915, Test Loss Force: 9.546592375040504, time: 10.725385189056396


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2780772451950195, Training Loss Force: 1.8457623467339015, time: 1.029358148574829
Validation Loss Energy: 1.658063376678973, Validation Loss Force: 2.5637277092679507, time: 0.08322548866271973
Test Loss Energy: 14.393368958694774, Test Loss Force: 9.594859519427356, time: 10.905726194381714


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5391834682435883, Training Loss Force: 1.8811563480227222, time: 1.1544151306152344
Validation Loss Energy: 1.3439946697493412, Validation Loss Force: 2.144208795559286, time: 0.08139371871948242
Test Loss Energy: 14.876606038152678, Test Loss Force: 9.553359796345509, time: 10.764872550964355


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5684493413607061, Training Loss Force: 1.8812675375233638, time: 1.249861240386963
Validation Loss Energy: 1.0559200249116005, Validation Loss Force: 2.1230689208486204, time: 0.0727241039276123
Test Loss Energy: 14.076907730665404, Test Loss Force: 9.513961258599515, time: 10.896019220352173


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.46455214138339, Training Loss Force: 1.8744401776268238, time: 1.056504726409912
Validation Loss Energy: 1.101926086822746, Validation Loss Force: 2.2557040243119664, time: 0.07933950424194336
Test Loss Energy: 14.38448970124074, Test Loss Force: 9.487509022097282, time: 10.72506833076477


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6798410264301993, Training Loss Force: 1.8642332989401513, time: 1.048889398574829
Validation Loss Energy: 1.196222406411251, Validation Loss Force: 2.2299611330166824, time: 0.07477712631225586
Test Loss Energy: 14.101548358975743, Test Loss Force: 9.545381814992853, time: 10.847811698913574


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.1857723536180198, Training Loss Force: 1.8451879429948939, time: 1.0334253311157227
Validation Loss Energy: 1.0005332180525928, Validation Loss Force: 2.197679784920374, time: 0.07953572273254395
Test Loss Energy: 14.181548803817513, Test Loss Force: 9.482671967416415, time: 11.099195957183838


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4867589256071656, Training Loss Force: 1.8499865271913614, time: 0.9972422122955322
Validation Loss Energy: 2.3501343350590336, Validation Loss Force: 2.563079074045863, time: 0.0773165225982666
Test Loss Energy: 15.047873007342254, Test Loss Force: 9.521139211861186, time: 9.333414316177368


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4476197714041084, Training Loss Force: 1.85884698459367, time: 1.043151617050171
Validation Loss Energy: 1.04861820261105, Validation Loss Force: 2.2897492460477418, time: 0.0756990909576416
Test Loss Energy: 14.53419325510505, Test Loss Force: 9.56831001264837, time: 10.533725500106812


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2964081145632003, Training Loss Force: 1.9564722214088948, time: 1.0476930141448975
Validation Loss Energy: 3.531468525700688, Validation Loss Force: 2.6507090690762958, time: 0.06554198265075684
Test Loss Energy: 13.095972695959771, Test Loss Force: 9.459166783874096, time: 8.213138103485107


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8700072634008187, Training Loss Force: 1.8626673747976394, time: 1.046722173690796
Validation Loss Energy: 1.143246132225128, Validation Loss Force: 2.239807451315036, time: 0.06444549560546875
Test Loss Energy: 14.779520178085797, Test Loss Force: 9.499701517167843, time: 8.197582721710205


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6660105439276023, Training Loss Force: 1.8642412998474176, time: 1.0602493286132812
Validation Loss Energy: 2.296174141584342, Validation Loss Force: 2.490154038077929, time: 0.06403946876525879
Test Loss Energy: 15.120547422774505, Test Loss Force: 9.504584028997076, time: 8.365171432495117


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3310844088210336, Training Loss Force: 1.8575344393834612, time: 1.0375399589538574
Validation Loss Energy: 2.3798201402558345, Validation Loss Force: 2.544340240735737, time: 0.06489086151123047
Test Loss Energy: 15.000956040054973, Test Loss Force: 9.643346054710719, time: 8.168452739715576

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–„â–…â–‚â–‚â–‡â–â–†â–‡â–…â–†â–…â–…â–ˆâ–†â–â–‡â–ˆâ–ˆ
wandb:   test_error_force â–‡â–…â–„â–‚â–…â–â–‚â–„â–†â–…â–ƒâ–‚â–„â–‚â–ƒâ–…â–â–ƒâ–ƒâ–ˆ
wandb:          test_loss â–„â–„â–†â–„â–†â–ƒâ–…â–„â–ˆâ–‡â–„â–‚â–„â–†â–‡â–†â–â–…â–…â–ˆ
wandb: train_error_energy â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–„â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–„â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–„â–‚â–‚â–
wandb: valid_error_energy â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–‡â–ƒâ–‚â–â–â–‚â–â–…â–â–ˆâ–â–…â–…
wandb:  valid_error_force â–ƒâ–†â–ˆâ–†â–ƒâ–â–‚â–‚â–‡â–â–â–ƒâ–‚â–‚â–‡â–ƒâ–ˆâ–ƒâ–†â–‡
wandb:         valid_loss â–„â–…â–‡â–†â–ƒâ–‚â–‚â–ƒâ–†â–â–â–‚â–‚â–‚â–‡â–ƒâ–ˆâ–‚â–†â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2091
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.00096
wandb:   test_error_force 9.64335
wandb:          test_loss 8.29663
wandb: train_error_energy 1.33108
wandb:  train_error_force 1.85753
wandb:         train_loss -2.62352
wandb: valid_error_energy 2.37982
wandb:  valid_error_force 2.54434
wandb:         valid_loss -1.61908
wandb: 
wandb: ğŸš€ View run al_69_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ml08fu3h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_175647-ml08fu3h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 90.08296966552734, Uncertainty Bias: -10.937929153442383
0.0 8.869171e-05
-3.9394553 66.16029
(48745, 22, 3)
Found uncertainty sample 0 after 53 steps.
Found uncertainty sample 1 after 312 steps.
Found uncertainty sample 2 after 225 steps.
Found uncertainty sample 3 after 766 steps.
Found uncertainty sample 4 after 705 steps.
Found uncertainty sample 5 after 166 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3039 steps.
Found uncertainty sample 8 after 354 steps.
Found uncertainty sample 9 after 309 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 170 steps.
Found uncertainty sample 12 after 561 steps.
Found uncertainty sample 13 after 110 steps.
Found uncertainty sample 14 after 467 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 325 steps.
Found uncertainty sample 17 after 544 steps.
Found uncertainty sample 18 after 292 steps.
Found uncertainty sample 19 after 1424 steps.
Found uncertainty sample 20 after 244 steps.
Found uncertainty sample 21 after 409 steps.
Found uncertainty sample 22 after 629 steps.
Found uncertainty sample 23 after 294 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 481 steps.
Found uncertainty sample 26 after 325 steps.
Found uncertainty sample 27 after 1079 steps.
Found uncertainty sample 28 after 1066 steps.
Found uncertainty sample 29 after 1226 steps.
Found uncertainty sample 30 after 711 steps.
Found uncertainty sample 31 after 273 steps.
Found uncertainty sample 32 after 124 steps.
Found uncertainty sample 33 after 314 steps.
Found uncertainty sample 34 after 594 steps.
Found uncertainty sample 35 after 124 steps.
Found uncertainty sample 36 after 610 steps.
Found uncertainty sample 37 after 232 steps.
Found uncertainty sample 38 after 1318 steps.
Found uncertainty sample 39 after 1396 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 672 steps.
Found uncertainty sample 42 after 705 steps.
Found uncertainty sample 43 after 907 steps.
Found uncertainty sample 44 after 144 steps.
Found uncertainty sample 45 after 119 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 746 steps.
Found uncertainty sample 48 after 168 steps.
Found uncertainty sample 49 after 714 steps.
Found uncertainty sample 50 after 8 steps.
Found uncertainty sample 51 after 29 steps.
Found uncertainty sample 52 after 1327 steps.
Found uncertainty sample 53 after 282 steps.
Found uncertainty sample 54 after 758 steps.
Found uncertainty sample 55 after 545 steps.
Found uncertainty sample 56 after 433 steps.
Found uncertainty sample 57 after 576 steps.
Found uncertainty sample 58 after 453 steps.
Found uncertainty sample 59 after 38 steps.
Found uncertainty sample 60 after 74 steps.
Found uncertainty sample 61 after 360 steps.
Found uncertainty sample 62 after 389 steps.
Found uncertainty sample 63 after 328 steps.
Found uncertainty sample 64 after 485 steps.
Found uncertainty sample 65 after 1123 steps.
Found uncertainty sample 66 after 755 steps.
Found uncertainty sample 67 after 417 steps.
Found uncertainty sample 68 after 1758 steps.
Found uncertainty sample 69 after 1385 steps.
Found uncertainty sample 70 after 279 steps.
Found uncertainty sample 71 after 71 steps.
Found uncertainty sample 72 after 108 steps.
Found uncertainty sample 73 after 140 steps.
Found uncertainty sample 74 after 754 steps.
Found uncertainty sample 75 after 107 steps.
Found uncertainty sample 76 after 45 steps.
Found uncertainty sample 77 after 116 steps.
Found uncertainty sample 78 after 742 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 110 steps.
Found uncertainty sample 81 after 1446 steps.
Found uncertainty sample 82 after 76 steps.
Found uncertainty sample 83 after 110 steps.
Found uncertainty sample 84 after 74 steps.
Found uncertainty sample 85 after 832 steps.
Found uncertainty sample 86 after 91 steps.
Found uncertainty sample 87 after 184 steps.
Found uncertainty sample 88 after 157 steps.
Found uncertainty sample 89 after 502 steps.
Found uncertainty sample 90 after 545 steps.
Found uncertainty sample 91 after 22 steps.
Found uncertainty sample 92 after 2298 steps.
Found uncertainty sample 93 after 2109 steps.
Found uncertainty sample 94 after 848 steps.
Found uncertainty sample 95 after 145 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 89 steps.
Found uncertainty sample 98 after 248 steps.
Found uncertainty sample 99 after 70 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_180824-jvu1okdf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jvu1okdf
Training model 15. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8604096678598268, Training Loss Force: 2.053565707801485, time: 1.0131072998046875
Validation Loss Energy: 2.330074294371545, Validation Loss Force: 2.2130461826808507, time: 0.07190513610839844
Test Loss Energy: 15.691296274518939, Test Loss Force: 9.523355182558863, time: 9.1007559299469


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7553500912638629, Training Loss Force: 1.8688068294652393, time: 1.002394676208496
Validation Loss Energy: 1.8349712854215627, Validation Loss Force: 2.126295396773114, time: 0.07971668243408203
Test Loss Energy: 13.223288893373692, Test Loss Force: 9.526413080452784, time: 9.082944869995117


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8930688983305999, Training Loss Force: 1.849169458382424, time: 1.0096399784088135
Validation Loss Energy: 2.8981890132545143, Validation Loss Force: 2.7083548822543837, time: 0.0690617561340332
Test Loss Energy: 15.727314354214093, Test Loss Force: 9.460835296245849, time: 9.257784366607666


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.748216347863736, Training Loss Force: 1.88393273970748, time: 1.0207698345184326
Validation Loss Energy: 2.295920632761703, Validation Loss Force: 2.531137741735387, time: 0.07694101333618164
Test Loss Energy: 13.434483667382027, Test Loss Force: 9.458844340297878, time: 9.063621044158936


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.277855179918134, Training Loss Force: 1.9185235379623025, time: 1.0443968772888184
Validation Loss Energy: 2.0463244966878733, Validation Loss Force: 2.6522933600495717, time: 0.07294940948486328
Test Loss Energy: 14.840429940307184, Test Loss Force: 9.604660342688614, time: 9.126063823699951


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.551014874973638, Training Loss Force: 1.9039176892593659, time: 1.004659652709961
Validation Loss Energy: 1.107602090354305, Validation Loss Force: 2.2725530645806034, time: 0.06965184211730957
Test Loss Energy: 13.72736439607063, Test Loss Force: 9.451033806142961, time: 9.268945217132568


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.554782524054141, Training Loss Force: 1.8662439850457484, time: 1.0343570709228516
Validation Loss Energy: 1.0938772930385376, Validation Loss Force: 2.1976030753996016, time: 0.07262611389160156
Test Loss Energy: 14.471209498831369, Test Loss Force: 9.572937287346015, time: 9.157070875167847


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.78384726677685, Training Loss Force: 1.858023443564228, time: 1.0187327861785889
Validation Loss Energy: 1.1272451830660435, Validation Loss Force: 2.227787659483281, time: 0.07430505752563477
Test Loss Energy: 14.190447698125451, Test Loss Force: 9.410902316180223, time: 9.14456820487976


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.317235436601588, Training Loss Force: 1.8466516625128253, time: 1.017763376235962
Validation Loss Energy: 1.5499045110743013, Validation Loss Force: 2.5151064539051697, time: 0.07503771781921387
Test Loss Energy: 14.217944315875664, Test Loss Force: 9.426639097834293, time: 9.254878044128418


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.342300170457187, Training Loss Force: 1.8765681142197386, time: 1.015211582183838
Validation Loss Energy: 1.69455500865377, Validation Loss Force: 2.180874387804339, time: 0.07645845413208008
Test Loss Energy: 13.833826539104626, Test Loss Force: 9.45605725005446, time: 9.201539993286133


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.425496129774819, Training Loss Force: 1.8784011782624415, time: 1.0427296161651611
Validation Loss Energy: 2.5303994821820632, Validation Loss Force: 2.3361658541966914, time: 0.06887459754943848
Test Loss Energy: 15.465395889179065, Test Loss Force: 9.538793312426925, time: 9.157045841217041


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6913652279591076, Training Loss Force: 1.8787599595712232, time: 1.036970615386963
Validation Loss Energy: 1.8477872307845824, Validation Loss Force: 2.128124289803192, time: 0.07738280296325684
Test Loss Energy: 15.231840423059113, Test Loss Force: 9.48003942121834, time: 9.775076150894165


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2782044518021949, Training Loss Force: 1.812169555845017, time: 1.1013801097869873
Validation Loss Energy: 1.8497915871016515, Validation Loss Force: 2.6336222181598075, time: 0.06848859786987305
Test Loss Energy: 13.778531606730184, Test Loss Force: 9.528032344471654, time: 9.13437533378601


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4127949582549413, Training Loss Force: 1.8556348200024353, time: 1.0530686378479004
Validation Loss Energy: 1.6744207078061146, Validation Loss Force: 2.347820245959979, time: 0.06843018531799316
Test Loss Energy: 14.102050537355968, Test Loss Force: 9.389091600537748, time: 9.062420129776001


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2775479094051099, Training Loss Force: 1.8577400051039963, time: 1.018538475036621
Validation Loss Energy: 4.139348725343744, Validation Loss Force: 2.625946590030531, time: 0.07610464096069336
Test Loss Energy: 16.932596900620428, Test Loss Force: 9.528865187699392, time: 9.376967191696167


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5273059525715142, Training Loss Force: 1.892171756273934, time: 1.0456702709197998
Validation Loss Energy: 1.8836325098960378, Validation Loss Force: 2.306666645744178, time: 0.07809042930603027
Test Loss Energy: 13.323688196239143, Test Loss Force: 9.436226042134756, time: 9.121747732162476


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.99374998379633, Training Loss Force: 1.8391611886190211, time: 1.0178914070129395
Validation Loss Energy: 1.7851206737041143, Validation Loss Force: 2.0948015737786663, time: 0.0740671157836914
Test Loss Energy: 13.553576849454977, Test Loss Force: 9.473904263707064, time: 9.08025050163269


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.650738023251686, Training Loss Force: 1.8603035078496584, time: 1.0322999954223633
Validation Loss Energy: 4.784053725671192, Validation Loss Force: 2.5678574425829, time: 0.06968092918395996
Test Loss Energy: 12.74688001573698, Test Loss Force: 9.40772906867387, time: 9.173110246658325


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6403555426598782, Training Loss Force: 1.87230711582972, time: 1.0586719512939453
Validation Loss Energy: 1.6291938765711431, Validation Loss Force: 2.186291928124762, time: 0.07198357582092285
Test Loss Energy: 13.725912775105078, Test Loss Force: 9.53143877204027, time: 9.080942630767822


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.446507242421377, Training Loss Force: 1.8563045942714853, time: 1.0105745792388916
Validation Loss Energy: 1.5936132119059798, Validation Loss Force: 2.4302101679792925, time: 0.07972264289855957
Test Loss Energy: 14.731258139933805, Test Loss Force: 9.482057405236882, time: 9.063292026519775

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–†â–‚â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–†â–…â–ƒâ–ƒâ–ˆâ–‚â–‚â–â–ƒâ–„
wandb:   test_error_force â–…â–…â–ƒâ–ƒâ–ˆâ–ƒâ–‡â–‚â–‚â–ƒâ–†â–„â–†â–â–†â–ƒâ–„â–‚â–†â–„
wandb:          test_loss â–…â–„â–†â–„â–‡â–â–„â–ƒâ–…â–…â–†â–‡â–†â–…â–ˆâ–„â–‡â–†â–‡â–†
wandb: train_error_energy â–ˆâ–ƒâ–„â–ƒâ–â–‚â–‚â–ƒâ–â–â–‚â–ƒâ–â–‚â–â–‚â–„â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–„â–„â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚
wandb: valid_error_energy â–ƒâ–‚â–„â–ƒâ–ƒâ–â–â–â–‚â–‚â–„â–‚â–‚â–‚â–‡â–‚â–‚â–ˆâ–‚â–‚
wandb:  valid_error_force â–‚â–â–ˆâ–†â–‡â–ƒâ–‚â–ƒâ–†â–‚â–„â–â–‡â–„â–‡â–ƒâ–â–†â–‚â–…
wandb:         valid_loss â–‚â–â–ˆâ–†â–‡â–‚â–‚â–‚â–…â–‚â–„â–â–‡â–„â–ˆâ–ƒâ–â–ˆâ–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2180
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.73126
wandb:   test_error_force 9.48206
wandb:          test_loss 8.09913
wandb: train_error_energy 1.44651
wandb:  train_error_force 1.8563
wandb:         train_loss -2.61748
wandb: valid_error_energy 1.59361
wandb:  valid_error_force 2.43021
wandb:         valid_loss -1.82331
wandb: 
wandb: ğŸš€ View run al_69_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jvu1okdf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_180824-jvu1okdf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 91.53036499023438, Uncertainty Bias: -11.069865226745605
7.8201294e-05 7.43866e-05
-4.146705 66.43472
(48745, 22, 3)
Found uncertainty sample 0 after 307 steps.
Found uncertainty sample 1 after 302 steps.
Found uncertainty sample 2 after 96 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 918 steps.
Found uncertainty sample 5 after 66 steps.
Found uncertainty sample 6 after 408 steps.
Found uncertainty sample 7 after 157 steps.
Found uncertainty sample 8 after 488 steps.
Found uncertainty sample 9 after 809 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2725 steps.
Found uncertainty sample 12 after 230 steps.
Found uncertainty sample 13 after 19 steps.
Found uncertainty sample 14 after 504 steps.
Found uncertainty sample 15 after 391 steps.
Found uncertainty sample 16 after 20 steps.
Found uncertainty sample 17 after 1606 steps.
Found uncertainty sample 18 after 2112 steps.
Found uncertainty sample 19 after 385 steps.
Found uncertainty sample 20 after 271 steps.
Found uncertainty sample 21 after 67 steps.
Found uncertainty sample 22 after 762 steps.
Found uncertainty sample 23 after 890 steps.
Found uncertainty sample 24 after 16 steps.
Found uncertainty sample 25 after 1904 steps.
Found uncertainty sample 26 after 298 steps.
Found uncertainty sample 27 after 36 steps.
Found uncertainty sample 28 after 61 steps.
Found uncertainty sample 29 after 563 steps.
Found uncertainty sample 30 after 866 steps.
Found uncertainty sample 31 after 428 steps.
Found uncertainty sample 32 after 65 steps.
Found uncertainty sample 33 after 3736 steps.
Found uncertainty sample 34 after 291 steps.
Found uncertainty sample 35 after 1145 steps.
Found uncertainty sample 36 after 1143 steps.
Found uncertainty sample 37 after 14 steps.
Found uncertainty sample 38 after 67 steps.
Found uncertainty sample 39 after 525 steps.
Found uncertainty sample 40 after 507 steps.
Found uncertainty sample 41 after 267 steps.
Found uncertainty sample 42 after 267 steps.
Found uncertainty sample 43 after 480 steps.
Found uncertainty sample 44 after 170 steps.
Found uncertainty sample 45 after 421 steps.
Found uncertainty sample 46 after 138 steps.
Found uncertainty sample 47 after 1166 steps.
Found uncertainty sample 48 after 2230 steps.
Found uncertainty sample 49 after 299 steps.
Found uncertainty sample 50 after 502 steps.
Found uncertainty sample 51 after 1214 steps.
Found uncertainty sample 52 after 1492 steps.
Found uncertainty sample 53 after 989 steps.
Found uncertainty sample 54 after 1812 steps.
Found uncertainty sample 55 after 163 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 37 steps.
Found uncertainty sample 58 after 871 steps.
Found uncertainty sample 59 after 1857 steps.
Found uncertainty sample 60 after 823 steps.
Found uncertainty sample 61 after 27 steps.
Found uncertainty sample 62 after 64 steps.
Found uncertainty sample 63 after 70 steps.
Found uncertainty sample 64 after 110 steps.
Found uncertainty sample 65 after 1268 steps.
Found uncertainty sample 66 after 200 steps.
Found uncertainty sample 67 after 29 steps.
Found uncertainty sample 68 after 198 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 107 steps.
Found uncertainty sample 71 after 1485 steps.
Found uncertainty sample 72 after 56 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 449 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 410 steps.
Found uncertainty sample 77 after 1994 steps.
Found uncertainty sample 78 after 493 steps.
Found uncertainty sample 79 after 25 steps.
Found uncertainty sample 80 after 26 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 231 steps.
Found uncertainty sample 83 after 529 steps.
Found uncertainty sample 84 after 1403 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 9 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3023 steps.
Found uncertainty sample 89 after 12 steps.
Found uncertainty sample 90 after 479 steps.
Found uncertainty sample 91 after 309 steps.
Found uncertainty sample 92 after 625 steps.
Found uncertainty sample 93 after 1844 steps.
Found uncertainty sample 94 after 380 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 734 steps.
Found uncertainty sample 97 after 11 steps.
Found uncertainty sample 98 after 363 steps.
Found uncertainty sample 99 after 1365 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_182321-pa6ap3qs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pa6ap3qs
Training model 16. Added 92 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.860031109317955, Training Loss Force: 2.0636571343551044, time: 1.0615930557250977
Validation Loss Energy: 2.9985994379191907, Validation Loss Force: 2.532213567713937, time: 0.07921075820922852
Test Loss Energy: 16.131920322471185, Test Loss Force: 9.486238646821674, time: 9.041200399398804


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3575977254537344, Training Loss Force: 1.8411190856710282, time: 1.0740470886230469
Validation Loss Energy: 1.9196285916865727, Validation Loss Force: 2.1799630029900565, time: 0.06980013847351074
Test Loss Energy: 15.732951791391288, Test Loss Force: 9.417496465915484, time: 9.030334711074829


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6473454309855329, Training Loss Force: 1.8663935892816679, time: 1.0707015991210938
Validation Loss Energy: 2.991404663810545, Validation Loss Force: 2.253791741686739, time: 0.07129716873168945
Test Loss Energy: 16.57859301572537, Test Loss Force: 9.488135736649468, time: 9.315911769866943


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9104029714729556, Training Loss Force: 1.8497299696878862, time: 1.0735175609588623
Validation Loss Energy: 0.9632216904488463, Validation Loss Force: 2.1248165396404346, time: 0.07122421264648438
Test Loss Energy: 14.050224407890367, Test Loss Force: 9.35536303064878, time: 9.075730800628662


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8889452749747462, Training Loss Force: 1.8468854748427685, time: 1.0657413005828857
Validation Loss Energy: 3.3571630069338427, Validation Loss Force: 2.3995607620534893, time: 0.0751047134399414
Test Loss Energy: 13.097283874482015, Test Loss Force: 9.381752695955205, time: 9.586553573608398


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1105286900672215, Training Loss Force: 1.894427187847592, time: 1.0488789081573486
Validation Loss Energy: 4.221300879822164, Validation Loss Force: 2.2761179976069075, time: 0.06949996948242188
Test Loss Energy: 12.688523907219201, Test Loss Force: 9.501947038742541, time: 9.247994899749756


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6399268955544797, Training Loss Force: 1.877930308241796, time: 1.0858962535858154
Validation Loss Energy: 1.8300132785510481, Validation Loss Force: 2.5546229905601097, time: 0.07060694694519043
Test Loss Energy: 15.255700086555294, Test Loss Force: 9.505059431121053, time: 9.123409986495972


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6876009747819318, Training Loss Force: 1.8935055963187268, time: 1.0613510608673096
Validation Loss Energy: 1.6718040113377444, Validation Loss Force: 2.4766804393924113, time: 0.07123827934265137
Test Loss Energy: 14.990501161734667, Test Loss Force: 9.484927897316425, time: 9.112959384918213


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.77939511923117, Training Loss Force: 1.885976457829896, time: 1.0536561012268066
Validation Loss Energy: 2.2842354013217046, Validation Loss Force: 2.238070409307653, time: 0.07126522064208984
Test Loss Energy: 13.539875175193353, Test Loss Force: 9.39511196802397, time: 9.232354164123535


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5583255586676077, Training Loss Force: 1.850875698097332, time: 1.133293867111206
Validation Loss Energy: 1.0498578295800733, Validation Loss Force: 2.197629795697113, time: 0.07315540313720703
Test Loss Energy: 14.738460845610694, Test Loss Force: 9.445871127564255, time: 9.035320520401001


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4889769318115018, Training Loss Force: 1.8730101794315246, time: 1.0697190761566162
Validation Loss Energy: 1.5993050249468999, Validation Loss Force: 2.369561772702941, time: 0.07109522819519043
Test Loss Energy: 14.060110087914943, Test Loss Force: 9.440670369064172, time: 9.09669041633606


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.409845619853815, Training Loss Force: 1.8781715671252233, time: 1.0674426555633545
Validation Loss Energy: 1.5303235430542763, Validation Loss Force: 2.5146970766803816, time: 0.0715172290802002
Test Loss Energy: 14.447220668577637, Test Loss Force: 9.49595940711819, time: 9.229209184646606


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8922095395782061, Training Loss Force: 1.8520906969963646, time: 1.140009880065918
Validation Loss Energy: 2.6938208217613853, Validation Loss Force: 2.5271983905402053, time: 0.07379555702209473
Test Loss Energy: 13.533987215408265, Test Loss Force: 9.387719907303323, time: 9.046863555908203


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.224162880203777, Training Loss Force: 1.8897643767568288, time: 1.0947225093841553
Validation Loss Energy: 1.5340199622112505, Validation Loss Force: 2.197320842257138, time: 0.07352447509765625
Test Loss Energy: 14.393111413265238, Test Loss Force: 9.452722771433542, time: 9.083970069885254


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2934980607335431, Training Loss Force: 1.8793668598048412, time: 1.1030969619750977
Validation Loss Energy: 1.2205746175556436, Validation Loss Force: 2.404585848004215, time: 0.0716392993927002
Test Loss Energy: 14.597971863286434, Test Loss Force: 9.632965746072351, time: 9.207244873046875


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5279851971311487, Training Loss Force: 1.8756692488975086, time: 1.0982046127319336
Validation Loss Energy: 1.544550598462327, Validation Loss Force: 2.202105779533981, time: 0.07170248031616211
Test Loss Energy: 13.842883507521641, Test Loss Force: 9.433443918229356, time: 9.147845029830933


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5805136836648113, Training Loss Force: 1.8655328899237507, time: 1.071516990661621
Validation Loss Energy: 1.4206994309684697, Validation Loss Force: 2.3852796537102647, time: 0.07362627983093262
Test Loss Energy: 14.349747443471713, Test Loss Force: 9.381698075563447, time: 9.051939487457275


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8430003953316763, Training Loss Force: 1.8411532622487428, time: 1.0525596141815186
Validation Loss Energy: 3.1783574560623697, Validation Loss Force: 2.1677923528119356, time: 0.07363224029541016
Test Loss Energy: 13.058114221965123, Test Loss Force: 9.425825807522346, time: 9.240740776062012


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0093003773241174, Training Loss Force: 1.8608446145776296, time: 1.100207805633545
Validation Loss Energy: 2.4905661986670413, Validation Loss Force: 2.141564599451393, time: 0.08071589469909668
Test Loss Energy: 13.548600765288944, Test Loss Force: 9.383149015697684, time: 9.13747239112854


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7987501768579106, Training Loss Force: 1.8522005309047325, time: 1.073662519454956
Validation Loss Energy: 1.6868675233924726, Validation Loss Force: 2.118128059502342, time: 0.07103657722473145
Test Loss Energy: 15.520151304705193, Test Loss Force: 9.416985492686898, time: 9.059425592422485

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–ˆâ–ƒâ–‚â–â–†â–…â–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–‚â–ƒâ–†
wandb:   test_error_force â–„â–ƒâ–„â–â–‚â–…â–…â–„â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒ
wandb:          test_loss â–‚â–„â–‡â–‚â–ƒâ–‚â–…â–‚â–â–†â–ƒâ–„â–„â–â–ˆâ–ƒâ–‚â–ƒâ–‚â–†
wandb: train_error_energy â–…â–â–„â–†â–…â–‡â–„â–„â–…â–ƒâ–‚â–‚â–†â–ˆâ–â–ƒâ–ƒâ–…â–†â–…
wandb:  train_error_force â–ˆâ–â–‚â–â–â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–„â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–…â–ƒâ–…â–â–†â–ˆâ–ƒâ–ƒâ–„â–â–‚â–‚â–…â–‚â–‚â–‚â–‚â–†â–„â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–â–†â–„â–ˆâ–‡â–ƒâ–‚â–…â–‡â–ˆâ–‚â–†â–‚â–…â–‚â–â–
wandb:         valid_loss â–ˆâ–‚â–„â–â–‡â–…â–ˆâ–†â–ƒâ–‚â–…â–‡â–ˆâ–‚â–…â–‚â–…â–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2262
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.52015
wandb:   test_error_force 9.41699
wandb:          test_loss 8.12909
wandb: train_error_energy 1.79875
wandb:  train_error_force 1.8522
wandb:         train_loss -2.59926
wandb: valid_error_energy 1.68687
wandb:  valid_error_force 2.11813
wandb:         valid_loss -2.24444
wandb: 
wandb: ğŸš€ View run al_69_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pa6ap3qs
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_182321-pa6ap3qs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 94.16471862792969, Uncertainty Bias: -11.42712688446045
7.6293945e-06 0.0031118393
-3.6940846 70.44524
(48745, 22, 3)
Found uncertainty sample 0 after 1399 steps.
Found uncertainty sample 1 after 967 steps.
Found uncertainty sample 2 after 1815 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 2374 steps.
Found uncertainty sample 5 after 631 steps.
Found uncertainty sample 6 after 227 steps.
Found uncertainty sample 7 after 310 steps.
Found uncertainty sample 8 after 145 steps.
Found uncertainty sample 9 after 52 steps.
Found uncertainty sample 10 after 1959 steps.
Found uncertainty sample 11 after 94 steps.
Found uncertainty sample 12 after 1101 steps.
Found uncertainty sample 13 after 67 steps.
Found uncertainty sample 14 after 237 steps.
Found uncertainty sample 15 after 69 steps.
Found uncertainty sample 16 after 299 steps.
Found uncertainty sample 17 after 953 steps.
Found uncertainty sample 18 after 2093 steps.
Found uncertainty sample 19 after 444 steps.
Found uncertainty sample 20 after 641 steps.
Found uncertainty sample 21 after 270 steps.
Found uncertainty sample 22 after 829 steps.
Found uncertainty sample 23 after 75 steps.
Found uncertainty sample 24 after 1030 steps.
Found uncertainty sample 25 after 987 steps.
Found uncertainty sample 26 after 722 steps.
Found uncertainty sample 27 after 94 steps.
Found uncertainty sample 28 after 1384 steps.
Found uncertainty sample 29 after 36 steps.
Found uncertainty sample 30 after 1632 steps.
Found uncertainty sample 31 after 526 steps.
Found uncertainty sample 32 after 714 steps.
Found uncertainty sample 33 after 521 steps.
Found uncertainty sample 34 after 906 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 71 steps.
Found uncertainty sample 37 after 114 steps.
Found uncertainty sample 38 after 51 steps.
Found uncertainty sample 39 after 1240 steps.
Found uncertainty sample 40 after 701 steps.
Found uncertainty sample 41 after 317 steps.
Found uncertainty sample 42 after 2 steps.
Found uncertainty sample 43 after 233 steps.
Found uncertainty sample 44 after 38 steps.
Found uncertainty sample 45 after 863 steps.
Found uncertainty sample 46 after 280 steps.
Found uncertainty sample 47 after 782 steps.
Found uncertainty sample 48 after 1066 steps.
Found uncertainty sample 49 after 32 steps.
Found uncertainty sample 50 after 395 steps.
Found uncertainty sample 51 after 695 steps.
Found uncertainty sample 52 after 224 steps.
Found uncertainty sample 53 after 1422 steps.
Found uncertainty sample 54 after 71 steps.
Found uncertainty sample 55 after 1011 steps.
Found uncertainty sample 56 after 592 steps.
Found uncertainty sample 57 after 387 steps.
Found uncertainty sample 58 after 363 steps.
Found uncertainty sample 59 after 65 steps.
Found uncertainty sample 60 after 461 steps.
Found uncertainty sample 61 after 1504 steps.
Found uncertainty sample 62 after 44 steps.
Found uncertainty sample 63 after 518 steps.
Found uncertainty sample 64 after 565 steps.
Found uncertainty sample 65 after 2477 steps.
Found uncertainty sample 66 after 572 steps.
Found uncertainty sample 67 after 975 steps.
Found uncertainty sample 68 after 11 steps.
Found uncertainty sample 69 after 1865 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 173 steps.
Found uncertainty sample 72 after 16 steps.
Found uncertainty sample 73 after 487 steps.
Found uncertainty sample 74 after 514 steps.
Found uncertainty sample 75 after 1115 steps.
Found uncertainty sample 76 after 1883 steps.
Found uncertainty sample 77 after 314 steps.
Found uncertainty sample 78 after 56 steps.
Found uncertainty sample 79 after 8 steps.
Found uncertainty sample 80 after 3636 steps.
Found uncertainty sample 81 after 130 steps.
Found uncertainty sample 82 after 1936 steps.
Found uncertainty sample 83 after 3731 steps.
Found uncertainty sample 84 after 124 steps.
Found uncertainty sample 85 after 278 steps.
Found uncertainty sample 86 after 137 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1087 steps.
Found uncertainty sample 89 after 781 steps.
Found uncertainty sample 90 after 118 steps.
Found uncertainty sample 91 after 1469 steps.
Found uncertainty sample 92 after 167 steps.
Found uncertainty sample 93 after 1192 steps.
Found uncertainty sample 94 after 752 steps.
Found uncertainty sample 95 after 2780 steps.
Found uncertainty sample 96 after 1599 steps.
Found uncertainty sample 97 after 1010 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 86 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_183639-rbpuwj63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rbpuwj63
Training model 17. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.543624002029679, Training Loss Force: 2.0478735277009874, time: 1.130279541015625
Validation Loss Energy: 1.7990498534622001, Validation Loss Force: 2.4039362107709703, time: 0.07285332679748535
Test Loss Energy: 14.89092552486388, Test Loss Force: 9.415823061817362, time: 8.215182781219482


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.504583519376506, Training Loss Force: 1.8670197005279328, time: 1.138942003250122
Validation Loss Energy: 1.4760561774927772, Validation Loss Force: 2.1291698327778956, time: 0.07063508033752441
Test Loss Energy: 15.354097027216628, Test Loss Force: 9.401838973130278, time: 8.22212266921997


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5088118635281553, Training Loss Force: 1.8695430279116603, time: 1.141814947128296
Validation Loss Energy: 1.8601778224115937, Validation Loss Force: 2.227479708054463, time: 0.07287263870239258
Test Loss Energy: 15.236394839479567, Test Loss Force: 9.493883613059813, time: 10.368111371994019


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8487570512044589, Training Loss Force: 1.8583126463468993, time: 1.20162034034729
Validation Loss Energy: 3.335047062022003, Validation Loss Force: 2.2065233127200417, time: 0.07948112487792969
Test Loss Energy: 13.204745468560416, Test Loss Force: 9.381789955148417, time: 10.677308797836304


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.794990197738325, Training Loss Force: 1.8593233370867026, time: 1.1280648708343506
Validation Loss Energy: 3.3962504601445795, Validation Loss Force: 2.436006802520658, time: 0.0751640796661377
Test Loss Energy: 13.232387205971811, Test Loss Force: 9.366767775908176, time: 9.066574573516846


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8981348212292262, Training Loss Force: 1.845798334927943, time: 1.1208300590515137
Validation Loss Energy: 1.4370343003455162, Validation Loss Force: 2.194613964784667, time: 0.07555031776428223
Test Loss Energy: 14.834397835475611, Test Loss Force: 9.415685874307329, time: 9.219440221786499


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8242111728181347, Training Loss Force: 1.8454833814571983, time: 1.1018121242523193
Validation Loss Energy: 1.914320715920519, Validation Loss Force: 2.380493937091412, time: 0.07231020927429199
Test Loss Energy: 13.809715485640119, Test Loss Force: 9.38742188971635, time: 9.14068341255188


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4637083353327418, Training Loss Force: 1.8909494541397351, time: 1.1499838829040527
Validation Loss Energy: 2.015411840164297, Validation Loss Force: 2.3121478694403366, time: 0.07401871681213379
Test Loss Energy: 14.93856951274165, Test Loss Force: 9.555451785795379, time: 9.11594533920288


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4100168237775583, Training Loss Force: 1.8850184402733239, time: 1.1026084423065186
Validation Loss Energy: 2.171424420585737, Validation Loss Force: 2.3793123432685457, time: 0.07674551010131836
Test Loss Energy: 15.739511796969762, Test Loss Force: 9.523544379052865, time: 9.311996459960938


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6839498940869446, Training Loss Force: 1.8652318403060768, time: 1.1165306568145752
Validation Loss Energy: 3.5199245778337804, Validation Loss Force: 2.282942806929594, time: 0.07322525978088379
Test Loss Energy: 16.74960050890894, Test Loss Force: 9.354640202300432, time: 9.16691541671753


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2817296227520125, Training Loss Force: 1.8631019723122468, time: 1.111410140991211
Validation Loss Energy: 3.0036029249627614, Validation Loss Force: 2.4464479814423576, time: 0.07284736633300781
Test Loss Energy: 15.82404430271606, Test Loss Force: 9.3757235802529, time: 9.130839824676514


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6566169088798985, Training Loss Force: 1.8503138605924674, time: 1.1132051944732666
Validation Loss Energy: 1.6451339257188167, Validation Loss Force: 2.469131287338022, time: 0.07071805000305176
Test Loss Energy: 14.008391734979195, Test Loss Force: 9.348835602382419, time: 9.326040506362915


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4201028439069823, Training Loss Force: 1.8793819830829859, time: 1.0913515090942383
Validation Loss Energy: 2.6867779080102623, Validation Loss Force: 2.270943500659264, time: 0.0802614688873291
Test Loss Energy: 13.944544278896863, Test Loss Force: 9.33896991361708, time: 9.596707582473755


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.45095126188648, Training Loss Force: 1.8570049676246738, time: 1.057783603668213
Validation Loss Energy: 1.1338642460978932, Validation Loss Force: 2.2217794892532843, time: 0.07861709594726562
Test Loss Energy: 13.983578292095482, Test Loss Force: 9.397597510616679, time: 9.068118810653687


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6483357207243616, Training Loss Force: 1.8730303186140134, time: 1.1160006523132324
Validation Loss Energy: 2.5319390166570077, Validation Loss Force: 2.1483674201959198, time: 0.07307672500610352
Test Loss Energy: 15.816279552135482, Test Loss Force: 9.418706900055977, time: 9.297565937042236


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4502398843667028, Training Loss Force: 1.8091449142598528, time: 1.0658769607543945
Validation Loss Energy: 1.8127753466190484, Validation Loss Force: 2.189730496410752, time: 0.07381772994995117
Test Loss Energy: 13.930670671411987, Test Loss Force: 9.303024309814413, time: 9.092175722122192


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4458522309727904, Training Loss Force: 1.8301350183930203, time: 1.131101369857788
Validation Loss Energy: 1.4475463437229077, Validation Loss Force: 2.41729268548573, time: 0.0713953971862793
Test Loss Energy: 14.906544089020183, Test Loss Force: 9.350467662299435, time: 9.122895956039429


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5894728957885138, Training Loss Force: 1.880455290492953, time: 1.1547911167144775
Validation Loss Energy: 3.198414490716388, Validation Loss Force: 2.182610761804284, time: 0.07825756072998047
Test Loss Energy: 16.72566892444443, Test Loss Force: 9.387201934569228, time: 9.213756799697876


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4096575252950456, Training Loss Force: 1.8428513057725464, time: 1.1090466976165771
Validation Loss Energy: 1.6951145205502, Validation Loss Force: 2.1034601191853546, time: 0.07401704788208008
Test Loss Energy: 13.443667363688249, Test Loss Force: 9.349860398072016, time: 9.138640403747559


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7428298743264172, Training Loss Force: 1.8653775215948003, time: 1.0925507545471191
Validation Loss Energy: 2.4669582591429124, Validation Loss Force: 2.428639571158491, time: 0.07171869277954102
Test Loss Energy: 15.455485461402503, Test Loss Force: 9.395954072422887, time: 9.11275601387024

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–…â–â–â–„â–‚â–„â–†â–ˆâ–†â–ƒâ–‚â–ƒâ–†â–‚â–„â–ˆâ–â–…
wandb:   test_error_force â–„â–„â–†â–ƒâ–ƒâ–„â–ƒâ–ˆâ–‡â–‚â–ƒâ–‚â–‚â–„â–„â–â–‚â–ƒâ–‚â–„
wandb:          test_loss â–ƒâ–„â–‡â–„â–ƒâ–†â–†â–‡â–‡â–ˆâ–†â–â–‚â–…â–‡â–†â–†â–ˆâ–†â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–‚â–ƒ
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–ƒâ–‚â–‚
wandb: valid_error_energy â–ƒâ–‚â–ƒâ–‡â–ˆâ–‚â–ƒâ–„â–„â–ˆâ–†â–‚â–†â–â–…â–ƒâ–‚â–‡â–ƒâ–…
wandb:  valid_error_force â–‡â–â–ƒâ–ƒâ–‡â–ƒâ–†â–…â–†â–„â–ˆâ–ˆâ–„â–ƒâ–‚â–ƒâ–‡â–ƒâ–â–‡
wandb:         valid_loss â–†â–â–ƒâ–„â–ˆâ–‚â–†â–…â–†â–†â–ˆâ–‡â–…â–‚â–‚â–ƒâ–†â–„â–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 2351
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.45549
wandb:   test_error_force 9.39595
wandb:          test_loss 8.00449
wandb: train_error_energy 1.74283
wandb:  train_error_force 1.86538
wandb:         train_loss -2.585
wandb: valid_error_energy 2.46696
wandb:  valid_error_force 2.42864
wandb:         valid_loss -1.77533
wandb: 
wandb: ğŸš€ View run al_69_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rbpuwj63
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_183639-rbpuwj63/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 90.6915054321289, Uncertainty Bias: -11.06987190246582
4.196167e-05 0.014693737
-3.5138829 69.29707
(48745, 22, 3)
Found uncertainty sample 0 after 724 steps.
Found uncertainty sample 1 after 2094 steps.
Found uncertainty sample 2 after 274 steps.
Found uncertainty sample 3 after 2382 steps.
Found uncertainty sample 4 after 36 steps.
Found uncertainty sample 5 after 2775 steps.
Found uncertainty sample 6 after 591 steps.
Found uncertainty sample 7 after 2310 steps.
Found uncertainty sample 8 after 112 steps.
Found uncertainty sample 9 after 38 steps.
Found uncertainty sample 10 after 344 steps.
Found uncertainty sample 11 after 38 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 849 steps.
Found uncertainty sample 15 after 75 steps.
Found uncertainty sample 16 after 1718 steps.
Found uncertainty sample 17 after 330 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 2304 steps.
Found uncertainty sample 20 after 3832 steps.
Found uncertainty sample 21 after 458 steps.
Found uncertainty sample 22 after 218 steps.
Found uncertainty sample 23 after 1670 steps.
Found uncertainty sample 24 after 77 steps.
Found uncertainty sample 25 after 1811 steps.
Found uncertainty sample 26 after 1198 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 968 steps.
Found uncertainty sample 29 after 3903 steps.
Found uncertainty sample 30 after 144 steps.
Found uncertainty sample 31 after 491 steps.
Found uncertainty sample 32 after 1514 steps.
Found uncertainty sample 33 after 138 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1291 steps.
Found uncertainty sample 36 after 111 steps.
Found uncertainty sample 37 after 661 steps.
Found uncertainty sample 38 after 691 steps.
Found uncertainty sample 39 after 2754 steps.
Found uncertainty sample 40 after 283 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2737 steps.
Found uncertainty sample 43 after 1803 steps.
Found uncertainty sample 44 after 18 steps.
Found uncertainty sample 45 after 129 steps.
Found uncertainty sample 46 after 1406 steps.
Found uncertainty sample 47 after 3774 steps.
Found uncertainty sample 48 after 189 steps.
Found uncertainty sample 49 after 3132 steps.
Found uncertainty sample 50 after 508 steps.
Found uncertainty sample 51 after 596 steps.
Found uncertainty sample 52 after 959 steps.
Found uncertainty sample 53 after 66 steps.
Found uncertainty sample 54 after 2514 steps.
Found uncertainty sample 55 after 1089 steps.
Found uncertainty sample 56 after 2524 steps.
Found uncertainty sample 57 after 1955 steps.
Found uncertainty sample 58 after 120 steps.
Found uncertainty sample 59 after 2578 steps.
Found uncertainty sample 60 after 708 steps.
Found uncertainty sample 61 after 1030 steps.
Found uncertainty sample 62 after 77 steps.
Found uncertainty sample 63 after 597 steps.
Found uncertainty sample 64 after 55 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 295 steps.
Found uncertainty sample 67 after 3566 steps.
Found uncertainty sample 68 after 151 steps.
Found uncertainty sample 69 after 316 steps.
Found uncertainty sample 70 after 998 steps.
Found uncertainty sample 71 after 2698 steps.
Found uncertainty sample 72 after 185 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 406 steps.
Found uncertainty sample 75 after 1367 steps.
Found uncertainty sample 76 after 3222 steps.
Found uncertainty sample 77 after 1005 steps.
Found uncertainty sample 78 after 2939 steps.
Found uncertainty sample 79 after 547 steps.
Found uncertainty sample 80 after 699 steps.
Found uncertainty sample 81 after 231 steps.
Found uncertainty sample 82 after 1935 steps.
Found uncertainty sample 83 after 1831 steps.
Found uncertainty sample 84 after 74 steps.
Found uncertainty sample 85 after 2594 steps.
Found uncertainty sample 86 after 399 steps.
Found uncertainty sample 87 after 877 steps.
Found uncertainty sample 88 after 92 steps.
Found uncertainty sample 89 after 394 steps.
Found uncertainty sample 90 after 1719 steps.
Found uncertainty sample 91 after 1037 steps.
Found uncertainty sample 92 after 110 steps.
Found uncertainty sample 93 after 762 steps.
Found uncertainty sample 94 after 3138 steps.
Found uncertainty sample 95 after 3642 steps.
Found uncertainty sample 96 after 3476 steps.
Found uncertainty sample 97 after 1372 steps.
Found uncertainty sample 98 after 41 steps.
Found uncertainty sample 99 after 285 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_185555-chipsvmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/chipsvmk
Training model 18. Added 94 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.281216399093437, Training Loss Force: 1.980177689536973, time: 1.1539883613586426
Validation Loss Energy: 1.917188249181777, Validation Loss Force: 2.0498713935133575, time: 0.07447624206542969
Test Loss Energy: 13.540013290685796, Test Loss Force: 9.355673228587778, time: 9.22230577468872


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6774462038608071, Training Loss Force: 1.8686373124460995, time: 1.1862919330596924
Validation Loss Energy: 2.304277628477519, Validation Loss Force: 2.174998149043305, time: 0.07365179061889648
Test Loss Energy: 15.482267308862678, Test Loss Force: 9.415010484979328, time: 9.216798543930054


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2911973644433539, Training Loss Force: 1.867420539789984, time: 1.163475513458252
Validation Loss Energy: 2.86113686737213, Validation Loss Force: 2.1298208060260158, time: 0.07769918441772461
Test Loss Energy: 16.26861382876242, Test Loss Force: 9.408716246101681, time: 9.336879253387451


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.215424048142815, Training Loss Force: 1.8736520153634681, time: 1.1934058666229248
Validation Loss Energy: 1.1868144679939425, Validation Loss Force: 2.1438271406431655, time: 0.07704615592956543
Test Loss Energy: 14.765132431040389, Test Loss Force: 9.322018123195669, time: 9.206796646118164


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2077784264883313, Training Loss Force: 1.8423582266179024, time: 1.1650166511535645
Validation Loss Energy: 1.7664073916784837, Validation Loss Force: 2.217835796009757, time: 0.07866215705871582
Test Loss Energy: 15.034900792539458, Test Loss Force: 9.347309710181536, time: 9.23741602897644


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2919456318180638, Training Loss Force: 1.822215713038112, time: 1.1203339099884033
Validation Loss Energy: 1.1145366198986475, Validation Loss Force: 2.3198224955584568, time: 0.08616042137145996
Test Loss Energy: 14.357529923645863, Test Loss Force: 9.369718247014353, time: 9.369234085083008


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.958672906365045, Training Loss Force: 1.856940029400053, time: 1.1103301048278809
Validation Loss Energy: 1.0122519890326966, Validation Loss Force: 2.2480607945434223, time: 0.07550573348999023
Test Loss Energy: 13.939311642568896, Test Loss Force: 9.38685855309845, time: 9.275636911392212


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.176903927720783, Training Loss Force: 1.8579843288977094, time: 1.171426773071289
Validation Loss Energy: 1.1330366127161227, Validation Loss Force: 2.1626165198494167, time: 0.07550382614135742
Test Loss Energy: 13.884953333565488, Test Loss Force: 9.41872749287165, time: 9.316208362579346


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2969015551415706, Training Loss Force: 1.8574216439659488, time: 1.1606793403625488
Validation Loss Energy: 1.5466426864228913, Validation Loss Force: 2.1121766142372707, time: 0.07439255714416504
Test Loss Energy: 14.981240680713118, Test Loss Force: 9.317560473423322, time: 9.477768182754517


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3972772752293603, Training Loss Force: 1.8409529211526539, time: 1.1289498805999756
Validation Loss Energy: 1.8006456675637779, Validation Loss Force: 2.5695530681291405, time: 0.08206963539123535
Test Loss Energy: 14.878062998514501, Test Loss Force: 9.456788859261486, time: 9.205382347106934


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7241753021298032, Training Loss Force: 1.858020016689006, time: 1.1687135696411133
Validation Loss Energy: 1.3396021868421966, Validation Loss Force: 2.368581249118848, time: 0.07810831069946289
Test Loss Energy: 14.404018708657784, Test Loss Force: 9.411621619128063, time: 9.244468688964844


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.340410327998277, Training Loss Force: 1.8609558544337288, time: 1.1697659492492676
Validation Loss Energy: 2.3150186314042105, Validation Loss Force: 2.3110512238966425, time: 0.07857608795166016
Test Loss Energy: 15.7331780978552, Test Loss Force: 9.247095206385907, time: 9.479092836380005


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2992410925044928, Training Loss Force: 1.839332549102316, time: 1.155484676361084
Validation Loss Energy: 1.2645695595744126, Validation Loss Force: 2.1732169072104552, time: 0.07280254364013672
Test Loss Energy: 13.772422138942993, Test Loss Force: 9.422247782482906, time: 9.76944613456726


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4661916487622262, Training Loss Force: 1.8552185033836122, time: 1.20841646194458
Validation Loss Energy: 2.1409093954895004, Validation Loss Force: 2.184653751218171, time: 0.08104920387268066
Test Loss Energy: 15.606725814758425, Test Loss Force: 9.383069381749936, time: 9.322834253311157


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5756311171579584, Training Loss Force: 1.8641925615717068, time: 1.1752290725708008
Validation Loss Energy: 2.3111643398227737, Validation Loss Force: 2.2067563359812556, time: 0.1108701229095459
Test Loss Energy: 15.9841820581469, Test Loss Force: 9.371720371393831, time: 9.404098510742188


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3853236385454508, Training Loss Force: 1.8435200968705119, time: 1.1784436702728271
Validation Loss Energy: 2.550812008127555, Validation Loss Force: 2.357813637229218, time: 0.07310748100280762
Test Loss Energy: 15.46759753443975, Test Loss Force: 9.311867767665655, time: 9.30967402458191


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5010946148210957, Training Loss Force: 1.8324294513321855, time: 1.152186393737793
Validation Loss Energy: 1.9451340620050117, Validation Loss Force: 2.2547543404045847, time: 0.07487082481384277
Test Loss Energy: 13.771346672615918, Test Loss Force: 9.359219026057216, time: 9.414124488830566


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7156191809154824, Training Loss Force: 1.8924283062508305, time: 1.2317631244659424
Validation Loss Energy: 1.0603903028516035, Validation Loss Force: 2.269352863615329, time: 0.07617306709289551
Test Loss Energy: 14.090409949331017, Test Loss Force: 9.3898355393201, time: 9.250104188919067


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5945675830711792, Training Loss Force: 1.8646222074723888, time: 1.1174702644348145
Validation Loss Energy: 2.1200991824493816, Validation Loss Force: 2.4384185320402016, time: 0.07440304756164551
Test Loss Energy: 13.85620510536989, Test Loss Force: 9.397704508387429, time: 9.271346092224121


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9358636333525419, Training Loss Force: 1.8501764034858725, time: 1.1476294994354248
Validation Loss Energy: 2.479087047521599, Validation Loss Force: 2.4022536113697672, time: 0.07399249076843262
Test Loss Energy: 14.076726680831046, Test Loss Force: 9.361223859772272, time: 9.505281686782837

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–ˆâ–„â–…â–ƒâ–‚â–‚â–…â–„â–ƒâ–‡â–‚â–†â–‡â–†â–‚â–‚â–‚â–‚
wandb:   test_error_force â–…â–‡â–†â–„â–„â–…â–†â–‡â–ƒâ–ˆâ–†â–â–‡â–†â–…â–ƒâ–…â–†â–†â–…
wandb:          test_loss â–â–…â–‡â–„â–†â–‡â–†â–…â–…â–ˆâ–‡â–„â–‡â–‡â–‡â–†â–†â–…â–…â–…
wandb: train_error_energy â–ˆâ–ƒâ–â–â–â–â–„â–â–â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–„â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–„â–ƒâ–ƒ
wandb: valid_error_energy â–„â–†â–ˆâ–‚â–„â–â–â–â–ƒâ–„â–‚â–†â–‚â–…â–†â–‡â–…â–â–…â–‡
wandb:  valid_error_force â–â–ƒâ–‚â–‚â–ƒâ–…â–„â–ƒâ–‚â–ˆâ–…â–…â–ƒâ–ƒâ–ƒâ–…â–„â–„â–†â–†
wandb:         valid_loss â–â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–ˆâ–…â–…â–‚â–ƒâ–ƒâ–†â–„â–ƒâ–†â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2435
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.07673
wandb:   test_error_force 9.36122
wandb:          test_loss 7.92069
wandb: train_error_energy 1.93586
wandb:  train_error_force 1.85018
wandb:         train_loss -2.59276
wandb: valid_error_energy 2.47909
wandb:  valid_error_force 2.40225
wandb:         valid_loss -1.80929
wandb: 
wandb: ğŸš€ View run al_69_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/chipsvmk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_185555-chipsvmk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 97.86825561523438, Uncertainty Bias: -11.949384689331055
3.8146973e-05 0.10189438
-3.5735939 67.634926
(48745, 22, 3)
Found uncertainty sample 0 after 2306 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 354 steps.
Found uncertainty sample 3 after 456 steps.
Found uncertainty sample 4 after 56 steps.
Found uncertainty sample 5 after 30 steps.
Found uncertainty sample 6 after 837 steps.
Found uncertainty sample 7 after 298 steps.
Found uncertainty sample 8 after 77 steps.
Found uncertainty sample 9 after 1036 steps.
Found uncertainty sample 10 after 658 steps.
Found uncertainty sample 11 after 744 steps.
Found uncertainty sample 12 after 139 steps.
Found uncertainty sample 13 after 680 steps.
Found uncertainty sample 14 after 898 steps.
Found uncertainty sample 15 after 85 steps.
Found uncertainty sample 16 after 1976 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2346 steps.
Found uncertainty sample 19 after 2542 steps.
Found uncertainty sample 20 after 2 steps.
Found uncertainty sample 21 after 70 steps.
Found uncertainty sample 22 after 1998 steps.
Found uncertainty sample 23 after 3696 steps.
Found uncertainty sample 24 after 57 steps.
Found uncertainty sample 25 after 679 steps.
Found uncertainty sample 26 after 516 steps.
Found uncertainty sample 27 after 713 steps.
Found uncertainty sample 28 after 18 steps.
Found uncertainty sample 29 after 1744 steps.
Found uncertainty sample 30 after 1473 steps.
Found uncertainty sample 31 after 43 steps.
Found uncertainty sample 32 after 191 steps.
Found uncertainty sample 33 after 1643 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 372 steps.
Found uncertainty sample 36 after 1655 steps.
Found uncertainty sample 37 after 2429 steps.
Found uncertainty sample 38 after 94 steps.
Found uncertainty sample 39 after 764 steps.
Found uncertainty sample 40 after 75 steps.
Found uncertainty sample 41 after 79 steps.
Found uncertainty sample 42 after 1472 steps.
Found uncertainty sample 43 after 1333 steps.
Found uncertainty sample 44 after 28 steps.
Found uncertainty sample 45 after 557 steps.
Found uncertainty sample 46 after 565 steps.
Found uncertainty sample 47 after 3875 steps.
Found uncertainty sample 48 after 8 steps.
Found uncertainty sample 49 after 669 steps.
Found uncertainty sample 50 after 2151 steps.
Found uncertainty sample 51 after 34 steps.
Found uncertainty sample 52 after 945 steps.
Found uncertainty sample 53 after 438 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 220 steps.
Found uncertainty sample 56 after 127 steps.
Found uncertainty sample 57 after 542 steps.
Found uncertainty sample 58 after 52 steps.
Found uncertainty sample 59 after 2641 steps.
Found uncertainty sample 60 after 269 steps.
Found uncertainty sample 61 after 2651 steps.
Found uncertainty sample 62 after 1050 steps.
Found uncertainty sample 63 after 585 steps.
Found uncertainty sample 64 after 852 steps.
Found uncertainty sample 65 after 116 steps.
Found uncertainty sample 66 after 836 steps.
Found uncertainty sample 67 after 394 steps.
Found uncertainty sample 68 after 3386 steps.
Found uncertainty sample 69 after 55 steps.
Found uncertainty sample 70 after 569 steps.
Found uncertainty sample 71 after 747 steps.
Found uncertainty sample 72 after 191 steps.
Found uncertainty sample 73 after 644 steps.
Found uncertainty sample 74 after 357 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 184 steps.
Found uncertainty sample 77 after 57 steps.
Found uncertainty sample 78 after 181 steps.
Found uncertainty sample 79 after 914 steps.
Found uncertainty sample 80 after 1969 steps.
Found uncertainty sample 81 after 503 steps.
Found uncertainty sample 82 after 60 steps.
Found uncertainty sample 83 after 890 steps.
Found uncertainty sample 84 after 912 steps.
Found uncertainty sample 85 after 6 steps.
Found uncertainty sample 86 after 99 steps.
Found uncertainty sample 87 after 51 steps.
Found uncertainty sample 88 after 233 steps.
Found uncertainty sample 89 after 1147 steps.
Found uncertainty sample 90 after 1099 steps.
Found uncertainty sample 91 after 1530 steps.
Found uncertainty sample 92 after 3752 steps.
Found uncertainty sample 93 after 184 steps.
Found uncertainty sample 94 after 819 steps.
Found uncertainty sample 95 after 828 steps.
Found uncertainty sample 96 after 838 steps.
Found uncertainty sample 97 after 327 steps.
Found uncertainty sample 98 after 772 steps.
Found uncertainty sample 99 after 274 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_191046-4686zs9f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/4686zs9f
Training model 19. Added 98 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3999690637721907, Training Loss Force: 2.097099627175968, time: 1.2709691524505615
Validation Loss Energy: 1.645389494231055, Validation Loss Force: 2.143238403421332, time: 0.09319210052490234
Test Loss Energy: 15.325824816691128, Test Loss Force: 9.277651414781875, time: 10.582898378372192


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5345231127417405, Training Loss Force: 1.8556384356493711, time: 1.357938289642334
Validation Loss Energy: 1.0126022475992411, Validation Loss Force: 2.131561967412598, time: 0.08553647994995117
Test Loss Energy: 14.33229926173626, Test Loss Force: 9.351889751040877, time: 10.562389850616455


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7935917373271257, Training Loss Force: 1.8463305102063947, time: 1.2824459075927734
Validation Loss Energy: 3.579643886098749, Validation Loss Force: 2.335955877192082, time: 0.08440518379211426
Test Loss Energy: 13.121568502626099, Test Loss Force: 9.314735732275523, time: 10.777623891830444


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6928903601908338, Training Loss Force: 1.8380719511646595, time: 1.2590882778167725
Validation Loss Energy: 3.6857134471071804, Validation Loss Force: 2.359865867412662, time: 0.08690261840820312
Test Loss Energy: 13.231915623031716, Test Loss Force: 9.280532217258939, time: 11.24109935760498


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2434048935434099, Training Loss Force: 1.8686223764272025, time: 1.2553415298461914
Validation Loss Energy: 0.9791555048604335, Validation Loss Force: 2.243697815298113, time: 0.08744215965270996
Test Loss Energy: 14.24940483613456, Test Loss Force: 9.367945157087279, time: 10.689807653427124


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.1761788629707388, Training Loss Force: 1.8966262784162065, time: 1.2858829498291016
Validation Loss Energy: 1.6121055226379206, Validation Loss Force: 2.2021407385898915, time: 0.09163093566894531
Test Loss Energy: 13.930278806357752, Test Loss Force: 9.258347179626668, time: 10.460420608520508


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6076095796125773, Training Loss Force: 1.8630591808900767, time: 1.2427408695220947
Validation Loss Energy: 1.728369322485218, Validation Loss Force: 2.0691052203348805, time: 0.0978546142578125
Test Loss Energy: 15.187878562126828, Test Loss Force: 9.258121829124532, time: 10.386907815933228


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5958036777024174, Training Loss Force: 1.8432478531827992, time: 1.3028013706207275
Validation Loss Energy: 3.277913387879549, Validation Loss Force: 2.1954205837657907, time: 0.09001040458679199
Test Loss Energy: 13.328367745724767, Test Loss Force: 9.260324672834862, time: 10.764145851135254


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8367135509934347, Training Loss Force: 1.8419276590909803, time: 1.2300317287445068
Validation Loss Energy: 2.260370724272321, Validation Loss Force: 2.2576438065767164, time: 0.07793211936950684
Test Loss Energy: 13.727557472370481, Test Loss Force: 9.250519200335102, time: 9.160814762115479


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7836142704250662, Training Loss Force: 1.865510449685305, time: 1.284651517868042
Validation Loss Energy: 3.6991832604172163, Validation Loss Force: 2.1606517986403233, time: 0.08923602104187012
Test Loss Energy: 13.022965540543465, Test Loss Force: 9.268579183619007, time: 10.552858829498291


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9437765891521295, Training Loss Force: 1.8287035428625962, time: 1.3949754238128662
Validation Loss Energy: 2.35659251963295, Validation Loss Force: 2.269948837584405, time: 0.07484722137451172
Test Loss Energy: 13.768804989419067, Test Loss Force: 9.217964947884319, time: 8.488280534744263


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.715175721090265, Training Loss Force: 1.830696406351279, time: 1.1754181385040283
Validation Loss Energy: 1.7816748686708819, Validation Loss Force: 2.372398466287488, time: 0.07266569137573242
Test Loss Energy: 13.932813340825794, Test Loss Force: 9.309995523517642, time: 8.420722723007202


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6964730556617456, Training Loss Force: 1.8684749018062756, time: 1.1974060535430908
Validation Loss Energy: 1.6889888923457268, Validation Loss Force: 2.3561849237613295, time: 0.07295918464660645
Test Loss Energy: 15.276600866481644, Test Loss Force: 9.27984915225734, time: 8.39132022857666


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4000209316607117, Training Loss Force: 1.8652306278523907, time: 1.1874959468841553
Validation Loss Energy: 3.644916674197728, Validation Loss Force: 2.1309628760754795, time: 0.07096219062805176
Test Loss Energy: 12.709866029050854, Test Loss Force: 9.245898939132648, time: 8.631763696670532


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8143406346128077, Training Loss Force: 1.8418049106103405, time: 1.1996774673461914
Validation Loss Energy: 1.4801488920622163, Validation Loss Force: 2.197653843964873, time: 0.07120275497436523
Test Loss Energy: 15.062875246618766, Test Loss Force: 9.3585921576185, time: 8.885876178741455


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.514613545662157, Training Loss Force: 1.8754769261738549, time: 1.1793203353881836
Validation Loss Energy: 2.106586171325035, Validation Loss Force: 2.4762112755019414, time: 0.07150936126708984
Test Loss Energy: 15.715964178050942, Test Loss Force: 9.551884113122513, time: 8.493189811706543


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7915336349496067, Training Loss Force: 1.9153186344746644, time: 1.1684539318084717
Validation Loss Energy: 1.9057016942872327, Validation Loss Force: 2.078000073372685, time: 0.07667207717895508
Test Loss Energy: 15.194310874527861, Test Loss Force: 9.285237046104564, time: 8.654266834259033


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7645778475525489, Training Loss Force: 1.8419629591971016, time: 1.2338974475860596
Validation Loss Energy: 2.464799927111434, Validation Loss Force: 2.059043079966836, time: 0.07252287864685059
Test Loss Energy: 16.027071875561596, Test Loss Force: 9.30142548938791, time: 8.439154624938965


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6960344446557643, Training Loss Force: 1.8472505340198198, time: 1.2533833980560303
Validation Loss Energy: 1.4501520180685545, Validation Loss Force: 2.2121987039114495, time: 0.07574343681335449
Test Loss Energy: 13.9466811798974, Test Loss Force: 9.364107795938677, time: 8.421123504638672


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.645086247040269, Training Loss Force: 1.8666158469720133, time: 1.2908680438995361
Validation Loss Energy: 1.4358813751751887, Validation Loss Force: 2.255709145702323, time: 0.07432413101196289
Test Loss Energy: 14.83461921290733, Test Loss Force: 9.354815618955142, time: 8.625780820846558

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–„â–‚â–‚â–„â–„â–†â–‚â–ƒâ–‚â–ƒâ–„â–†â–â–†â–‡â–†â–ˆâ–„â–…
wandb:   test_error_force â–‚â–„â–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–„â–ˆâ–‚â–ƒâ–„â–„
wandb:          test_loss â–â–ƒâ–„â–„â–„â–‚â–„â–„â–„â–ƒâ–„â–…â–„â–ƒâ–†â–ˆâ–„â–…â–„â–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–ƒâ–‚â–â–â–‚â–â–â–‚â–‚â–â–‚â–ƒâ–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–ƒâ–â–â–‚
wandb: valid_error_energy â–ƒâ–â–ˆâ–ˆâ–â–ƒâ–ƒâ–‡â–„â–ˆâ–…â–ƒâ–ƒâ–ˆâ–‚â–„â–ƒâ–…â–‚â–‚
wandb:  valid_error_force â–‚â–‚â–†â–†â–„â–ƒâ–â–ƒâ–„â–ƒâ–…â–†â–†â–‚â–ƒâ–ˆâ–â–â–„â–„
wandb:         valid_loss â–‚â–â–‡â–‡â–ƒâ–ƒâ–â–„â–…â–„â–…â–†â–†â–„â–ƒâ–ˆâ–â–â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2523
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.83462
wandb:   test_error_force 9.35482
wandb:          test_loss 7.98967
wandb: train_error_energy 1.64509
wandb:  train_error_force 1.86662
wandb:         train_loss -2.58982
wandb: valid_error_energy 1.43588
wandb:  valid_error_force 2.25571
wandb:         valid_loss -2.0771
wandb: 
wandb: ğŸš€ View run al_69_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/4686zs9f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_191046-4686zs9f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 102.48104095458984, Uncertainty Bias: -12.53385066986084
3.8146973e-06 0.0019454956
-3.929323 69.05624
(48745, 22, 3)
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 97 steps.
Found uncertainty sample 2 after 104 steps.
Found uncertainty sample 3 after 402 steps.
Found uncertainty sample 4 after 985 steps.
Found uncertainty sample 5 after 851 steps.
Did not find any uncertainty samples for sample 6.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1971 steps.
Found uncertainty sample 9 after 2613 steps.
Found uncertainty sample 10 after 2078 steps.
Found uncertainty sample 11 after 3572 steps.
Found uncertainty sample 12 after 345 steps.
Found uncertainty sample 13 after 114 steps.
Found uncertainty sample 14 after 15 steps.
Found uncertainty sample 15 after 379 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 307 steps.
Found uncertainty sample 18 after 1685 steps.
Found uncertainty sample 19 after 184 steps.
Found uncertainty sample 20 after 83 steps.
Found uncertainty sample 21 after 2031 steps.
Found uncertainty sample 22 after 2864 steps.
Found uncertainty sample 23 after 96 steps.
Found uncertainty sample 24 after 467 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 602 steps.
Found uncertainty sample 27 after 1623 steps.
Found uncertainty sample 28 after 466 steps.
Found uncertainty sample 29 after 126 steps.
Found uncertainty sample 30 after 1527 steps.
Found uncertainty sample 31 after 204 steps.
Found uncertainty sample 32 after 300 steps.
Found uncertainty sample 33 after 1698 steps.
Found uncertainty sample 34 after 150 steps.
Found uncertainty sample 35 after 1054 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 649 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 376 steps.
Found uncertainty sample 40 after 341 steps.
Found uncertainty sample 41 after 1003 steps.
Found uncertainty sample 42 after 3084 steps.
Found uncertainty sample 43 after 3457 steps.
Found uncertainty sample 44 after 1506 steps.
Found uncertainty sample 45 after 327 steps.
Found uncertainty sample 46 after 128 steps.
Found uncertainty sample 47 after 346 steps.
Found uncertainty sample 48 after 1134 steps.
Found uncertainty sample 49 after 2408 steps.
Found uncertainty sample 50 after 433 steps.
Found uncertainty sample 51 after 1150 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 284 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3516 steps.
Found uncertainty sample 56 after 2450 steps.
Found uncertainty sample 57 after 253 steps.
Found uncertainty sample 58 after 389 steps.
Found uncertainty sample 59 after 3098 steps.
Found uncertainty sample 60 after 2200 steps.
Found uncertainty sample 61 after 708 steps.
Found uncertainty sample 62 after 7 steps.
Found uncertainty sample 63 after 576 steps.
Found uncertainty sample 64 after 2483 steps.
Found uncertainty sample 65 after 2849 steps.
Found uncertainty sample 66 after 161 steps.
Found uncertainty sample 67 after 414 steps.
Found uncertainty sample 68 after 1323 steps.
Found uncertainty sample 69 after 1269 steps.
Found uncertainty sample 70 after 1077 steps.
Found uncertainty sample 71 after 1641 steps.
Found uncertainty sample 72 after 57 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 104 steps.
Found uncertainty sample 75 after 1156 steps.
Found uncertainty sample 76 after 929 steps.
Found uncertainty sample 77 after 1234 steps.
Found uncertainty sample 78 after 145 steps.
Found uncertainty sample 79 after 155 steps.
Found uncertainty sample 80 after 1358 steps.
Found uncertainty sample 81 after 2569 steps.
Found uncertainty sample 82 after 417 steps.
Found uncertainty sample 83 after 1906 steps.
Found uncertainty sample 84 after 236 steps.
Found uncertainty sample 85 after 601 steps.
Found uncertainty sample 86 after 2200 steps.
Found uncertainty sample 87 after 2990 steps.
Found uncertainty sample 88 after 272 steps.
Found uncertainty sample 89 after 923 steps.
Found uncertainty sample 90 after 385 steps.
Found uncertainty sample 91 after 869 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3815 steps.
Found uncertainty sample 94 after 342 steps.
Found uncertainty sample 95 after 143 steps.
Found uncertainty sample 96 after 717 steps.
Found uncertainty sample 97 after 762 steps.
Found uncertainty sample 98 after 2282 steps.
Found uncertainty sample 99 after 959 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_192942-6n42xs3i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6n42xs3i
Training model 20. Added 92 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.755151484126161, Training Loss Force: 2.146190806212918, time: 1.2193729877471924
Validation Loss Energy: 1.1281860715421614, Validation Loss Force: 2.2456262414364208, time: 0.07991838455200195
Test Loss Energy: 14.952620891811472, Test Loss Force: 9.293010796715546, time: 9.39276647567749


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7571454624437937, Training Loss Force: 1.8659055327058618, time: 1.230985164642334
Validation Loss Energy: 1.9884791719550337, Validation Loss Force: 2.2453063772082955, time: 0.0844564437866211
Test Loss Energy: 15.24116686078014, Test Loss Force: 9.299409622474966, time: 9.418296813964844


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1991888401982314, Training Loss Force: 1.8944524354575738, time: 1.2559583187103271
Validation Loss Energy: 1.6027085506760492, Validation Loss Force: 2.229057318953361, time: 0.08210468292236328
Test Loss Energy: 14.81066655065142, Test Loss Force: 9.36134004410255, time: 9.654303312301636


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0336937292322053, Training Loss Force: 1.8630127332852349, time: 1.2307329177856445
Validation Loss Energy: 1.533938242634695, Validation Loss Force: 2.146850764975719, time: 0.08215165138244629
Test Loss Energy: 14.878697234853753, Test Loss Force: 9.228558948954355, time: 9.474774599075317


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4483575389623013, Training Loss Force: 1.8617413494870119, time: 1.2618160247802734
Validation Loss Energy: 2.8242009547839206, Validation Loss Force: 2.13388685596523, time: 0.08260869979858398
Test Loss Energy: 16.451736304837628, Test Loss Force: 9.327528809167513, time: 9.640443563461304


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8321449011469244, Training Loss Force: 1.8465257747716957, time: 1.2063708305358887
Validation Loss Energy: 2.2928083861090705, Validation Loss Force: 2.1831204514793128, time: 0.0808875560760498
Test Loss Energy: 15.956407437385089, Test Loss Force: 9.353408918866716, time: 9.646410465240479


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.886332236158804, Training Loss Force: 1.8303037721757298, time: 1.2420649528503418
Validation Loss Energy: 3.140340262101535, Validation Loss Force: 2.2503707642632773, time: 0.08400654792785645
Test Loss Energy: 13.06005912387152, Test Loss Force: 9.274381610472684, time: 9.450588941574097


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.598373525912725, Training Loss Force: 1.8853481009897828, time: 1.2481029033660889
Validation Loss Energy: 1.4215498879376978, Validation Loss Force: 2.31032164844001, time: 0.07944989204406738
Test Loss Energy: 14.023904210694244, Test Loss Force: 9.21143933827695, time: 9.44137167930603


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7950019564893338, Training Loss Force: 1.860011829351998, time: 1.300708293914795
Validation Loss Energy: 1.4133176426108882, Validation Loss Force: 2.1143053312723405, time: 0.11812329292297363
Test Loss Energy: 13.743821152177398, Test Loss Force: 9.239000597696295, time: 9.624805212020874


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6959915023025676, Training Loss Force: 1.8650262271837188, time: 1.2108449935913086
Validation Loss Energy: 1.0297465471553782, Validation Loss Force: 2.1433025321353596, time: 0.08387899398803711
Test Loss Energy: 14.382461038429646, Test Loss Force: 9.335255619723563, time: 9.427234172821045


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4784657828301335, Training Loss Force: 1.8565247273386276, time: 1.2262217998504639
Validation Loss Energy: 3.2275157894051283, Validation Loss Force: 2.1869690649975286, time: 0.08249092102050781
Test Loss Energy: 16.44360053849604, Test Loss Force: 9.27943695552821, time: 10.168235301971436


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.580907039037556, Training Loss Force: 1.8421776396835352, time: 1.2098605632781982
Validation Loss Energy: 1.7362927813739124, Validation Loss Force: 2.056419480754942, time: 0.08324313163757324
Test Loss Energy: 15.501177324033414, Test Loss Force: 9.268813590110282, time: 9.442063808441162


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3031373233646344, Training Loss Force: 1.8453253925607729, time: 1.2326560020446777
Validation Loss Energy: 0.9693469846496008, Validation Loss Force: 2.0848858383740696, time: 0.09036850929260254
Test Loss Energy: 14.23775535999669, Test Loss Force: 9.241271757699563, time: 9.590502977371216


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6873307159481634, Training Loss Force: 1.8517245345098126, time: 1.2257976531982422
Validation Loss Energy: 1.3459150797983954, Validation Loss Force: 2.1824291751157796, time: 0.08015084266662598
Test Loss Energy: 13.824604837488682, Test Loss Force: 9.225813426726996, time: 9.628598690032959


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.472698753781006, Training Loss Force: 1.864243369987491, time: 1.2160711288452148
Validation Loss Energy: 1.0364248680136876, Validation Loss Force: 2.0786142505444403, time: 0.08151054382324219
Test Loss Energy: 14.481487132511512, Test Loss Force: 9.290030177839139, time: 9.502399206161499


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8335470324659673, Training Loss Force: 1.867355224253641, time: 1.2076764106750488
Validation Loss Energy: 1.818175296076943, Validation Loss Force: 2.0472335434761235, time: 0.08353328704833984
Test Loss Energy: 13.543361675053161, Test Loss Force: 9.244352990387332, time: 9.505269050598145


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5448780531286248, Training Loss Force: 1.8443935330469745, time: 1.1942005157470703
Validation Loss Energy: 1.4759629904552065, Validation Loss Force: 2.1201136559438667, time: 0.084625244140625
Test Loss Energy: 14.273854211467265, Test Loss Force: 9.186562284297535, time: 9.596169233322144


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.220529493788995, Training Loss Force: 1.8518541700426419, time: 1.2168350219726562
Validation Loss Energy: 1.454191403377544, Validation Loss Force: 2.1725005805680055, time: 0.07901310920715332
Test Loss Energy: 15.003525105727737, Test Loss Force: 9.366568907878914, time: 9.430243968963623


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3271583131361553, Training Loss Force: 1.7909793446841782, time: 1.2301630973815918
Validation Loss Energy: 1.4046705089979283, Validation Loss Force: 2.194191895418561, time: 0.08355140686035156
Test Loss Energy: 14.259926850951077, Test Loss Force: 9.275958709582287, time: 9.496014595031738


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2367662663296404, Training Loss Force: 1.8370170161098751, time: 1.2045319080352783
Validation Loss Energy: 1.0849153609205224, Validation Loss Force: 2.178328054786082, time: 0.07870173454284668
Test Loss Energy: 14.401803344179775, Test Loss Force: 9.21720873082215, time: 9.646743774414062

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–†â–…â–…â–ˆâ–‡â–â–ƒâ–‚â–„â–ˆâ–†â–ƒâ–ƒâ–„â–‚â–„â–…â–ƒâ–„
wandb:   test_error_force â–…â–…â–ˆâ–ƒâ–†â–‡â–„â–‚â–ƒâ–‡â–…â–„â–ƒâ–ƒâ–…â–ƒâ–â–ˆâ–„â–‚
wandb:          test_loss â–‚â–…â–…â–„â–ˆâ–ˆâ–†â–â–ƒâ–…â–‡â–‡â–…â–„â–„â–â–ƒâ–‡â–ˆâ–…
wandb: train_error_energy â–ˆâ–ƒâ–…â–…â–‚â–„â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–„â–‚â–â–â–†
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–ƒ
wandb: valid_error_energy â–â–„â–ƒâ–ƒâ–‡â–…â–ˆâ–‚â–‚â–â–ˆâ–ƒâ–â–‚â–â–„â–ƒâ–ƒâ–‚â–
wandb:  valid_error_force â–†â–†â–†â–„â–ƒâ–…â–†â–ˆâ–ƒâ–„â–…â–â–‚â–…â–‚â–â–ƒâ–„â–…â–„
wandb:         valid_loss â–…â–†â–…â–ƒâ–…â–…â–ˆâ–‡â–‚â–ƒâ–†â–â–â–„â–â–â–ƒâ–„â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2605
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.4018
wandb:   test_error_force 9.21721
wandb:          test_loss 7.85874
wandb: train_error_energy 2.23677
wandb:  train_error_force 1.83702
wandb:         train_loss -2.59039
wandb: valid_error_energy 1.08492
wandb:  valid_error_force 2.17833
wandb:         valid_loss -2.19895
wandb: 
wandb: ğŸš€ View run al_69_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6n42xs3i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_192942-6n42xs3i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 104.00167846679688, Uncertainty Bias: -12.53299617767334
5.531311e-05 0.0009460449
-3.750703 61.545395
(48745, 22, 3)
Found uncertainty sample 0 after 402 steps.
Found uncertainty sample 1 after 573 steps.
Found uncertainty sample 2 after 224 steps.
Found uncertainty sample 3 after 273 steps.
Found uncertainty sample 4 after 38 steps.
Found uncertainty sample 5 after 435 steps.
Found uncertainty sample 6 after 3276 steps.
Found uncertainty sample 7 after 36 steps.
Found uncertainty sample 8 after 145 steps.
Found uncertainty sample 9 after 2957 steps.
Found uncertainty sample 10 after 1408 steps.
Found uncertainty sample 11 after 41 steps.
Found uncertainty sample 12 after 114 steps.
Found uncertainty sample 13 after 3855 steps.
Found uncertainty sample 14 after 831 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 907 steps.
Found uncertainty sample 18 after 192 steps.
Found uncertainty sample 19 after 1131 steps.
Found uncertainty sample 20 after 625 steps.
Found uncertainty sample 21 after 744 steps.
Found uncertainty sample 22 after 1076 steps.
Found uncertainty sample 23 after 3807 steps.
Found uncertainty sample 24 after 849 steps.
Found uncertainty sample 25 after 211 steps.
Found uncertainty sample 26 after 2 steps.
Found uncertainty sample 27 after 62 steps.
Found uncertainty sample 28 after 584 steps.
Found uncertainty sample 29 after 906 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 820 steps.
Found uncertainty sample 32 after 642 steps.
Found uncertainty sample 33 after 623 steps.
Found uncertainty sample 34 after 42 steps.
Found uncertainty sample 35 after 13 steps.
Found uncertainty sample 36 after 286 steps.
Found uncertainty sample 37 after 146 steps.
Found uncertainty sample 38 after 216 steps.
Found uncertainty sample 39 after 178 steps.
Found uncertainty sample 40 after 4 steps.
Did not find any uncertainty samples for sample 41.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 376 steps.
Found uncertainty sample 44 after 691 steps.
Found uncertainty sample 45 after 1008 steps.
Found uncertainty sample 46 after 746 steps.
Found uncertainty sample 47 after 525 steps.
Found uncertainty sample 48 after 3071 steps.
Found uncertainty sample 49 after 2526 steps.
Found uncertainty sample 50 after 75 steps.
Found uncertainty sample 51 after 605 steps.
Found uncertainty sample 52 after 83 steps.
Found uncertainty sample 53 after 75 steps.
Found uncertainty sample 54 after 6 steps.
Found uncertainty sample 55 after 1147 steps.
Found uncertainty sample 56 after 930 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 48 steps.
Found uncertainty sample 59 after 643 steps.
Found uncertainty sample 60 after 133 steps.
Found uncertainty sample 61 after 916 steps.
Found uncertainty sample 62 after 622 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1433 steps.
Found uncertainty sample 65 after 1086 steps.
Found uncertainty sample 66 after 53 steps.
Found uncertainty sample 67 after 581 steps.
Found uncertainty sample 68 after 209 steps.
Found uncertainty sample 69 after 997 steps.
Found uncertainty sample 70 after 795 steps.
Found uncertainty sample 71 after 631 steps.
Found uncertainty sample 72 after 1660 steps.
Found uncertainty sample 73 after 281 steps.
Found uncertainty sample 74 after 1424 steps.
Found uncertainty sample 75 after 141 steps.
Found uncertainty sample 76 after 668 steps.
Found uncertainty sample 77 after 72 steps.
Found uncertainty sample 78 after 931 steps.
Found uncertainty sample 79 after 97 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 106 steps.
Found uncertainty sample 82 after 531 steps.
Found uncertainty sample 83 after 232 steps.
Found uncertainty sample 84 after 1145 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 603 steps.
Found uncertainty sample 87 after 1120 steps.
Found uncertainty sample 88 after 3599 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 457 steps.
Found uncertainty sample 91 after 1980 steps.
Found uncertainty sample 92 after 2050 steps.
Found uncertainty sample 93 after 1053 steps.
Found uncertainty sample 94 after 118 steps.
Found uncertainty sample 95 after 350 steps.
Found uncertainty sample 96 after 93 steps.
Found uncertainty sample 97 after 1143 steps.
Found uncertainty sample 98 after 112 steps.
Found uncertainty sample 99 after 1663 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_194520-27lsn1y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/27lsn1y7
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)
Training model 21. Added 94 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.8458219715675375, Training Loss Force: 2.086378258677373, time: 1.2766749858856201
Validation Loss Energy: 3.1018422141200688, Validation Loss Force: 2.1531578685341235, time: 0.092529296875
Test Loss Energy: 16.320146445319477, Test Loss Force: 9.334391994526563, time: 9.56399393081665


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9583966659569398, Training Loss Force: 1.8522195616452095, time: 1.3059964179992676
Validation Loss Energy: 3.239703919111205, Validation Loss Force: 2.213596954813303, time: 0.08534789085388184
Test Loss Energy: 16.63318198198459, Test Loss Force: 9.339214499935487, time: 10.275866508483887


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.625374193669167, Training Loss Force: 1.8553970372594135, time: 1.3205366134643555
Validation Loss Energy: 1.4444492942394844, Validation Loss Force: 2.2701510211689073, time: 0.09343194961547852
Test Loss Energy: 14.878085591855065, Test Loss Force: 9.233914475334732, time: 10.63490915298462


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4485915867491737, Training Loss Force: 1.8610974381253644, time: 1.3714749813079834
Validation Loss Energy: 1.822554084831613, Validation Loss Force: 2.380367461016525, time: 0.09741067886352539
Test Loss Energy: 15.22534531096409, Test Loss Force: 9.304779912635786, time: 10.461647987365723


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.585558443712113, Training Loss Force: 1.8650629568746473, time: 1.363806962966919
Validation Loss Energy: 3.746430981153342, Validation Loss Force: 2.2857435394470738, time: 0.0943138599395752
Test Loss Energy: 17.116415946406065, Test Loss Force: 9.379139735315515, time: 11.089780807495117


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5461505443863803, Training Loss Force: 1.8912618326666002, time: 1.3388278484344482
Validation Loss Energy: 1.9236554518561038, Validation Loss Force: 2.451440446363205, time: 0.08742713928222656
Test Loss Energy: 13.71799262244517, Test Loss Force: 9.479446132685796, time: 10.561425685882568


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5765501928097445, Training Loss Force: 1.8668209206130186, time: 1.3674187660217285
Validation Loss Energy: 3.9702415291231556, Validation Loss Force: 2.1026975886951247, time: 0.0848836898803711
Test Loss Energy: 17.376894635075136, Test Loss Force: 9.250045015313681, time: 10.332750082015991


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.936693043396799, Training Loss Force: 1.8681698149339487, time: 1.2907357215881348
Validation Loss Energy: 1.4507602945079427, Validation Loss Force: 2.315476773171957, time: 0.09278297424316406
Test Loss Energy: 15.16996987728145, Test Loss Force: 9.343007415856237, time: 10.834912776947021


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.199695045696205, Training Loss Force: 1.8500911432487595, time: 1.4100055694580078
Validation Loss Energy: 4.346252784405271, Validation Loss Force: 2.4819579208200455, time: 0.09836244583129883
Test Loss Energy: 12.816301773550087, Test Loss Force: 9.339204166221824, time: 10.596833229064941


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9282917299718507, Training Loss Force: 1.8800450853212678, time: 1.3725638389587402
Validation Loss Energy: 1.6517107372802262, Validation Loss Force: 2.3737516266872913, time: 0.09834003448486328
Test Loss Energy: 13.819130986356287, Test Loss Force: 9.35036320132482, time: 10.805320024490356


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2758839299851399, Training Loss Force: 1.8531504653748598, time: 1.3239190578460693
Validation Loss Energy: 1.2932825511062982, Validation Loss Force: 2.256651815531608, time: 0.08943867683410645
Test Loss Energy: 14.863119730421639, Test Loss Force: 9.26127719315079, time: 10.439309358596802


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3328604665113128, Training Loss Force: 1.8598452332966882, time: 1.3419442176818848
Validation Loss Energy: 3.2396354483488325, Validation Loss Force: 2.1922019012614045, time: 0.0862874984741211
Test Loss Energy: 12.994615281567798, Test Loss Force: 9.223607043626469, time: 10.44981074333191


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.707747887037198, Training Loss Force: 1.8566632283300915, time: 1.4609644412994385
Validation Loss Energy: 1.6593349288367936, Validation Loss Force: 2.353660857657665, time: 0.08631753921508789
Test Loss Energy: 13.741691483843777, Test Loss Force: 9.22917661684386, time: 10.647853374481201


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7140967757706544, Training Loss Force: 1.8579956281065835, time: 1.3337225914001465
Validation Loss Energy: 1.5657937916567026, Validation Loss Force: 2.0926577709089598, time: 0.09499120712280273
Test Loss Energy: 13.937895345556862, Test Loss Force: 9.181829298880116, time: 10.356598377227783


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3225074115237512, Training Loss Force: 1.8306847845140597, time: 1.2886903285980225
Validation Loss Energy: 1.1841966860134858, Validation Loss Force: 2.3845594303577613, time: 0.08343791961669922
Test Loss Energy: 14.832721712715458, Test Loss Force: 9.342171737385764, time: 10.448572635650635


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6677283381619703, Training Loss Force: 1.8646026656947339, time: 1.4986190795898438
Validation Loss Energy: 4.607736279836316, Validation Loss Force: 2.5664397081307784, time: 0.08346080780029297
Test Loss Energy: 17.687954949524183, Test Loss Force: 9.51324585411044, time: 10.957077026367188


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7556985827808376, Training Loss Force: 1.9029950388289982, time: 1.3070237636566162
Validation Loss Energy: 3.601224868387497, Validation Loss Force: 2.2606830177494848, time: 0.09628582000732422
Test Loss Energy: 16.969174772880056, Test Loss Force: 9.267629890256986, time: 10.436391115188599


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4607489488185568, Training Loss Force: 1.8526817389637709, time: 1.3178753852844238
Validation Loss Energy: 1.9078524555677494, Validation Loss Force: 2.3105178199575724, time: 0.08437228202819824
Test Loss Energy: 13.407444890038432, Test Loss Force: 9.212445359809864, time: 10.613725185394287


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.949566498960937, Training Loss Force: 1.884387888122318, time: 1.4714579582214355
Validation Loss Energy: 4.423687315916535, Validation Loss Force: 2.3151266259399854, time: 0.08941221237182617
Test Loss Energy: 17.86848507642829, Test Loss Force: 9.324904507556873, time: 9.754774808883667


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.743153893626297, Training Loss Force: 1.8734811499306756, time: 1.2682743072509766
Validation Loss Energy: 3.4406744021066213, Validation Loss Force: 2.1008092430030842, time: 0.07765078544616699
Test Loss Energy: 13.163568599418866, Test Loss Force: 9.185444196064829, time: 10.255411148071289

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–„â–„â–‡â–‚â–‡â–„â–â–‚â–„â–â–‚â–ƒâ–„â–ˆâ–‡â–‚â–ˆâ–
wandb:   test_error_force â–„â–„â–‚â–„â–…â–‡â–‚â–„â–„â–…â–ƒâ–‚â–‚â–â–„â–ˆâ–ƒâ–‚â–„â–
wandb:          test_loss â–‚â–„â–‚â–ƒâ–…â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–‚â–‚â–â–…â–ˆâ–…â–ƒâ–†â–
wandb: train_error_energy â–‡â–ˆâ–…â–ƒâ–…â–„â–„â–ˆâ–â–ˆâ–‚â–‚â–†â–†â–‚â–…â–†â–ƒâ–ˆâ–†
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb: valid_error_energy â–…â–…â–‚â–‚â–†â–ƒâ–‡â–‚â–‡â–‚â–â–…â–‚â–‚â–â–ˆâ–†â–‚â–ˆâ–†
wandb:  valid_error_force â–‚â–ƒâ–„â–…â–„â–†â–â–„â–‡â–…â–ƒâ–‚â–…â–â–…â–ˆâ–ƒâ–„â–„â–
wandb:         valid_loss â–‚â–ƒâ–ƒâ–„â–„â–…â–‚â–ƒâ–‡â–„â–ƒâ–ƒâ–„â–â–„â–ˆâ–„â–„â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2689
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.16357
wandb:   test_error_force 9.18544
wandb:          test_loss 7.65807
wandb: train_error_energy 1.74315
wandb:  train_error_force 1.87348
wandb:         train_loss -2.57439
wandb: valid_error_energy 3.44067
wandb:  valid_error_force 2.10081
wandb:         valid_loss -2.15249
wandb: 
wandb: ğŸš€ View run al_69_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/27lsn1y7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_194520-27lsn1y7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 102.4522705078125, Uncertainty Bias: -12.525317192077637
0.00012207031 0.528883
-4.321221 66.62812
(48745, 22, 3)
Found uncertainty sample 0 after 2871 steps.
Found uncertainty sample 1 after 1131 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 320 steps.
Found uncertainty sample 4 after 2372 steps.
Found uncertainty sample 5 after 604 steps.
Found uncertainty sample 6 after 122 steps.
Found uncertainty sample 7 after 487 steps.
Found uncertainty sample 8 after 7 steps.
Found uncertainty sample 9 after 683 steps.
Found uncertainty sample 10 after 245 steps.
Found uncertainty sample 11 after 271 steps.
Found uncertainty sample 12 after 636 steps.
Found uncertainty sample 13 after 1533 steps.
Found uncertainty sample 14 after 1106 steps.
Found uncertainty sample 15 after 31 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1628 steps.
Found uncertainty sample 18 after 554 steps.
Found uncertainty sample 19 after 120 steps.
Found uncertainty sample 20 after 559 steps.
Found uncertainty sample 21 after 128 steps.
Found uncertainty sample 22 after 438 steps.
Found uncertainty sample 23 after 490 steps.
Found uncertainty sample 24 after 1000 steps.
Found uncertainty sample 25 after 89 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 2862 steps.
Found uncertainty sample 28 after 698 steps.
Found uncertainty sample 29 after 107 steps.
Found uncertainty sample 30 after 2041 steps.
Found uncertainty sample 31 after 200 steps.
Found uncertainty sample 32 after 731 steps.
Found uncertainty sample 33 after 1226 steps.
Found uncertainty sample 34 after 100 steps.
Found uncertainty sample 35 after 97 steps.
Found uncertainty sample 36 after 351 steps.
Found uncertainty sample 37 after 1102 steps.
Found uncertainty sample 38 after 2891 steps.
Found uncertainty sample 39 after 191 steps.
Found uncertainty sample 40 after 1051 steps.
Found uncertainty sample 41 after 655 steps.
Found uncertainty sample 42 after 380 steps.
Found uncertainty sample 43 after 52 steps.
Found uncertainty sample 44 after 492 steps.
Found uncertainty sample 45 after 1888 steps.
Found uncertainty sample 46 after 1456 steps.
Found uncertainty sample 47 after 1209 steps.
Found uncertainty sample 48 after 1090 steps.
Found uncertainty sample 49 after 260 steps.
Found uncertainty sample 50 after 77 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 25 steps.
Found uncertainty sample 53 after 818 steps.
Found uncertainty sample 54 after 1113 steps.
Found uncertainty sample 55 after 84 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 178 steps.
Found uncertainty sample 58 after 1730 steps.
Found uncertainty sample 59 after 1708 steps.
Found uncertainty sample 60 after 423 steps.
Found uncertainty sample 61 after 592 steps.
Found uncertainty sample 62 after 2 steps.
Found uncertainty sample 63 after 346 steps.
Found uncertainty sample 64 after 464 steps.
Found uncertainty sample 65 after 297 steps.
Found uncertainty sample 66 after 22 steps.
Found uncertainty sample 67 after 216 steps.
Found uncertainty sample 68 after 3908 steps.
Found uncertainty sample 69 after 1125 steps.
Found uncertainty sample 70 after 1942 steps.
Found uncertainty sample 71 after 158 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 351 steps.
Found uncertainty sample 74 after 2294 steps.
Found uncertainty sample 75 after 8 steps.
Found uncertainty sample 76 after 115 steps.
Found uncertainty sample 77 after 87 steps.
Found uncertainty sample 78 after 2646 steps.
Found uncertainty sample 79 after 657 steps.
Found uncertainty sample 80 after 50 steps.
Found uncertainty sample 81 after 1815 steps.
Found uncertainty sample 82 after 1269 steps.
Found uncertainty sample 83 after 786 steps.
Found uncertainty sample 84 after 182 steps.
Found uncertainty sample 85 after 1373 steps.
Found uncertainty sample 86 after 858 steps.
Found uncertainty sample 87 after 3625 steps.
Found uncertainty sample 88 after 14 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 157 steps.
Found uncertainty sample 91 after 2183 steps.
Found uncertainty sample 92 after 1557 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2659 steps.
Found uncertainty sample 95 after 48 steps.
Found uncertainty sample 96 after 1413 steps.
Found uncertainty sample 97 after 245 steps.
Found uncertainty sample 98 after 375 steps.
Found uncertainty sample 99 after 1880 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_200131-g56zqha5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/g56zqha5
Training model 22. Added 96 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8710728880638916, Training Loss Force: 1.937072978867495, time: 1.2908637523651123
Validation Loss Energy: 1.188607260788737, Validation Loss Force: 2.151332816546813, time: 0.09238576889038086
Test Loss Energy: 13.669901575544342, Test Loss Force: 9.21527153256872, time: 9.961447715759277


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9593751058983164, Training Loss Force: 1.8662044421880095, time: 1.3200666904449463
Validation Loss Energy: 2.2496038917247017, Validation Loss Force: 2.1600833243107695, time: 0.0836646556854248
Test Loss Energy: 13.734186288544084, Test Loss Force: 9.235746172713663, time: 9.425620555877686


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8647662314523417, Training Loss Force: 1.8479535627170287, time: 1.369279146194458
Validation Loss Energy: 3.338085716521906, Validation Loss Force: 2.230168994664406, time: 0.08233761787414551
Test Loss Energy: 17.04168768206728, Test Loss Force: 9.210158568665715, time: 9.603541612625122


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9076276742642044, Training Loss Force: 1.8564294445611542, time: 1.2787895202636719
Validation Loss Energy: 2.1510477443727387, Validation Loss Force: 2.1995812680920244, time: 0.08259415626525879
Test Loss Energy: 15.68490107208782, Test Loss Force: 9.182229473806983, time: 9.443371295928955


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7942769652735382, Training Loss Force: 1.8871707271038076, time: 1.3243350982666016
Validation Loss Energy: 0.9968255819373926, Validation Loss Force: 2.202549113803523, time: 0.08291888236999512
Test Loss Energy: 14.503644242070173, Test Loss Force: 9.25913441181951, time: 9.543116807937622


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8909960659375886, Training Loss Force: 1.8651225862266103, time: 1.3128173351287842
Validation Loss Energy: 1.366851824580688, Validation Loss Force: 2.207408088571386, time: 0.08182740211486816
Test Loss Energy: 13.619467690159786, Test Loss Force: 9.189567879424109, time: 9.667859554290771


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5027363145761112, Training Loss Force: 1.865478945159928, time: 1.322174072265625
Validation Loss Energy: 2.582480793403416, Validation Loss Force: 2.163153709163968, time: 0.09292268753051758
Test Loss Energy: 15.979035780141727, Test Loss Force: 9.258469388847764, time: 9.519845008850098


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.837319997653247, Training Loss Force: 1.8542488584121606, time: 1.319199562072754
Validation Loss Energy: 1.8172131426973892, Validation Loss Force: 2.2859608645334992, time: 0.08218979835510254
Test Loss Energy: 15.43770096298697, Test Loss Force: 9.247032509282933, time: 9.535958051681519


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4803226757328052, Training Loss Force: 1.8607304513999694, time: 1.4816484451293945
Validation Loss Energy: 2.317506402437089, Validation Loss Force: 2.1325112616489745, time: 0.0878915786743164
Test Loss Energy: 16.149040735223835, Test Loss Force: 9.25715316937585, time: 9.529599666595459


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6965526196313665, Training Loss Force: 1.840380445575882, time: 1.3035809993743896
Validation Loss Energy: 1.8714486665710206, Validation Loss Force: 2.2238186932916912, time: 0.0871133804321289
Test Loss Energy: 13.705675302082499, Test Loss Force: 9.260684590112788, time: 9.40026044845581


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.751808676831505, Training Loss Force: 1.8772209546727234, time: 1.3026070594787598
Validation Loss Energy: 1.1377476516701601, Validation Loss Force: 2.1877056545322575, time: 0.08772850036621094
Test Loss Energy: 14.55822570985847, Test Loss Force: 9.191594658291013, time: 9.59765887260437


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7486376596011328, Training Loss Force: 1.8216680267131178, time: 1.313978910446167
Validation Loss Energy: 1.1925812648697534, Validation Loss Force: 2.256605389014682, time: 0.09064364433288574
Test Loss Energy: 14.40310482318739, Test Loss Force: 9.188090587387391, time: 10.027966022491455


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7096094495002172, Training Loss Force: 1.8494008379425104, time: 1.302659034729004
Validation Loss Energy: 2.5495865484829414, Validation Loss Force: 2.1285790915337497, time: 0.08229947090148926
Test Loss Energy: 16.318574834829448, Test Loss Force: 9.220216960672651, time: 9.393418312072754


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8867366975892084, Training Loss Force: 1.8256820462952348, time: 1.3290846347808838
Validation Loss Energy: 1.3430622983680551, Validation Loss Force: 2.1702470574766437, time: 0.08570241928100586
Test Loss Energy: 14.321189171876314, Test Loss Force: 9.208504824737627, time: 9.628432512283325


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4323327936144714, Training Loss Force: 1.8314259888706022, time: 1.350285530090332
Validation Loss Energy: 1.4759096055274705, Validation Loss Force: 2.5149925586370276, time: 0.08161282539367676
Test Loss Energy: 15.162822221013307, Test Loss Force: 9.35577178591551, time: 9.406065940856934


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7429558740300997, Training Loss Force: 1.926267766605189, time: 1.279815673828125
Validation Loss Energy: 2.827313758109418, Validation Loss Force: 2.18452465878082, time: 0.08809375762939453
Test Loss Energy: 16.103288796224188, Test Loss Force: 9.20689596904407, time: 9.406556129455566


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4615115786065793, Training Loss Force: 1.8382582230575681, time: 1.3589503765106201
Validation Loss Energy: 2.070431716104459, Validation Loss Force: 2.3065864848516444, time: 0.08462691307067871
Test Loss Energy: 15.479018377162847, Test Loss Force: 9.16858265309852, time: 9.601529121398926


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2580023464519425, Training Loss Force: 1.8603137414498585, time: 1.2987761497497559
Validation Loss Energy: 3.3120978891661013, Validation Loss Force: 2.077343589063203, time: 0.08266496658325195
Test Loss Energy: 13.25083419056295, Test Loss Force: 9.13152092894544, time: 9.499573707580566


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7457818558210494, Training Loss Force: 1.8427291968386523, time: 1.3541204929351807
Validation Loss Energy: 1.1796994651068256, Validation Loss Force: 2.286152137329851, time: 0.08602547645568848
Test Loss Energy: 14.572071655073742, Test Loss Force: 9.200304766469023, time: 9.487164974212646


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.1753346667569708, Training Loss Force: 1.84025760515067, time: 1.265336275100708
Validation Loss Energy: 1.04163268183229, Validation Loss Force: 2.1375227091145117, time: 0.08711957931518555
Test Loss Energy: 14.912246587557041, Test Loss Force: 9.153374275820003, time: 9.6544508934021

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ˆâ–…â–ƒâ–‚â–†â–…â–†â–‚â–ƒâ–ƒâ–‡â–ƒâ–…â–†â–…â–â–ƒâ–„
wandb:   test_error_force â–„â–„â–ƒâ–ƒâ–…â–ƒâ–…â–…â–…â–…â–ƒâ–ƒâ–„â–ƒâ–ˆâ–ƒâ–‚â–â–ƒâ–‚
wandb:          test_loss â–‚â–ƒâ–…â–…â–„â–‚â–„â–…â–„â–…â–ƒâ–„â–…â–…â–ˆâ–â–„â–‚â–„â–ƒ
wandb: train_error_energy â–ˆâ–„â–„â–„â–„â–„â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–…â–ƒâ–
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–‚â–„â–â–ƒâ–â–‚â–‡â–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–â–‚â–‚â–â–…â–â–„â–‚â–
wandb: valid_error_energy â–‚â–…â–ˆâ–„â–â–‚â–†â–ƒâ–…â–„â–â–‚â–†â–‚â–‚â–†â–„â–ˆâ–‚â–
wandb:  valid_error_force â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–„â–‚â–‚â–ˆâ–ƒâ–…â–â–„â–‚
wandb:         valid_loss â–â–‚â–„â–ƒâ–‚â–‚â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ˆâ–ƒâ–…â–‚â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2775
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.91225
wandb:   test_error_force 9.15337
wandb:          test_loss 7.77274
wandb: train_error_energy 1.17533
wandb:  train_error_force 1.84026
wandb:         train_loss -2.65724
wandb: valid_error_energy 1.04163
wandb:  valid_error_force 2.13752
wandb:         valid_loss -2.26109
wandb: 
wandb: ğŸš€ View run al_69_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/g56zqha5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_200131-g56zqha5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 106.13972473144531, Uncertainty Bias: -12.90178394317627
1.5258789e-05 0.0011942387
-3.9679427 44.38635
(48745, 22, 3)
Found uncertainty sample 0 after 3811 steps.
Found uncertainty sample 1 after 868 steps.
Found uncertainty sample 2 after 26 steps.
Found uncertainty sample 3 after 722 steps.
Found uncertainty sample 4 after 2366 steps.
Found uncertainty sample 5 after 1559 steps.
Found uncertainty sample 6 after 311 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2186 steps.
Found uncertainty sample 9 after 94 steps.
Found uncertainty sample 10 after 451 steps.
Found uncertainty sample 11 after 431 steps.
Found uncertainty sample 12 after 340 steps.
Found uncertainty sample 13 after 66 steps.
Found uncertainty sample 14 after 3489 steps.
Found uncertainty sample 15 after 571 steps.
Found uncertainty sample 16 after 1777 steps.
Found uncertainty sample 17 after 3776 steps.
Found uncertainty sample 18 after 559 steps.
Found uncertainty sample 19 after 1255 steps.
Found uncertainty sample 20 after 3734 steps.
Found uncertainty sample 21 after 43 steps.
Found uncertainty sample 22 after 647 steps.
Found uncertainty sample 23 after 601 steps.
Found uncertainty sample 24 after 368 steps.
Found uncertainty sample 25 after 63 steps.
Found uncertainty sample 26 after 2613 steps.
Found uncertainty sample 27 after 3873 steps.
Found uncertainty sample 28 after 420 steps.
Found uncertainty sample 29 after 536 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 694 steps.
Found uncertainty sample 32 after 586 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1153 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1207 steps.
Found uncertainty sample 37 after 2026 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 416 steps.
Found uncertainty sample 40 after 413 steps.
Found uncertainty sample 41 after 418 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 275 steps.
Found uncertainty sample 44 after 3505 steps.
Found uncertainty sample 45 after 1161 steps.
Found uncertainty sample 46 after 492 steps.
Found uncertainty sample 47 after 588 steps.
Found uncertainty sample 48 after 874 steps.
Found uncertainty sample 49 after 145 steps.
Found uncertainty sample 50 after 1526 steps.
Found uncertainty sample 51 after 778 steps.
Found uncertainty sample 52 after 1116 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3725 steps.
Found uncertainty sample 55 after 94 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1644 steps.
Found uncertainty sample 58 after 494 steps.
Found uncertainty sample 59 after 1380 steps.
Found uncertainty sample 60 after 327 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 904 steps.
Found uncertainty sample 63 after 1787 steps.
Found uncertainty sample 64 after 14 steps.
Found uncertainty sample 65 after 214 steps.
Found uncertainty sample 66 after 969 steps.
Found uncertainty sample 67 after 2234 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 92 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 774 steps.
Found uncertainty sample 72 after 52 steps.
Found uncertainty sample 73 after 64 steps.
Found uncertainty sample 74 after 1470 steps.
Found uncertainty sample 75 after 798 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3958 steps.
Found uncertainty sample 78 after 159 steps.
Found uncertainty sample 79 after 1949 steps.
Found uncertainty sample 80 after 46 steps.
Found uncertainty sample 81 after 73 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2756 steps.
Found uncertainty sample 84 after 1698 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 517 steps.
Found uncertainty sample 87 after 259 steps.
Found uncertainty sample 88 after 411 steps.
Found uncertainty sample 89 after 360 steps.
Found uncertainty sample 90 after 32 steps.
Found uncertainty sample 91 after 1010 steps.
Found uncertainty sample 92 after 1892 steps.
Found uncertainty sample 93 after 55 steps.
Found uncertainty sample 94 after 8 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1335 steps.
Found uncertainty sample 99 after 4 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_202233-m4ew7ejo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m4ew7ejo
Training model 23. Added 85 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.2715543507828646, Training Loss Force: 2.119605980187558, time: 1.3383803367614746
Validation Loss Energy: 1.6038118762941211, Validation Loss Force: 2.2976160356387973, time: 0.09301090240478516
Test Loss Energy: 15.022710531155198, Test Loss Force: 9.314616087829927, time: 9.463731527328491


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9179685288770387, Training Loss Force: 1.8414879144610312, time: 1.3146584033966064
Validation Loss Energy: 3.814439148375472, Validation Loss Force: 2.198249372595657, time: 0.08605647087097168
Test Loss Energy: 12.990201470803635, Test Loss Force: 9.109609184464292, time: 9.43386173248291


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9501041802214885, Training Loss Force: 1.861112424195491, time: 1.4044582843780518
Validation Loss Energy: 2.178648698356218, Validation Loss Force: 2.3782170337397277, time: 0.08978533744812012
Test Loss Energy: 13.469374598192104, Test Loss Force: 9.124942909316479, time: 9.66289210319519


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0959247723087495, Training Loss Force: 1.9154267840802384, time: 1.3603034019470215
Validation Loss Energy: 1.0121895860045504, Validation Loss Force: 2.209316585821133, time: 0.09043550491333008
Test Loss Energy: 14.610899464985163, Test Loss Force: 9.219684074934813, time: 9.429757833480835


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8925522607462466, Training Loss Force: 1.8612908390857172, time: 1.4456923007965088
Validation Loss Energy: 1.7977656648303482, Validation Loss Force: 2.0934601591763107, time: 0.08475804328918457
Test Loss Energy: 13.555511137854015, Test Loss Force: 9.154348787920055, time: 9.514147281646729


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3920121849380571, Training Loss Force: 1.8563702455799214, time: 1.3657147884368896
Validation Loss Energy: 4.924391177561326, Validation Loss Force: 2.0602180493826108, time: 0.08449172973632812
Test Loss Energy: 18.101018703345314, Test Loss Force: 9.144301214602514, time: 10.196757316589355


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8956423477984443, Training Loss Force: 1.8525105753015594, time: 1.395162582397461
Validation Loss Energy: 1.2882979631064886, Validation Loss Force: 2.0944023280000175, time: 0.08642363548278809
Test Loss Energy: 14.919161352883068, Test Loss Force: 9.15554096085897, time: 9.480732917785645


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.64311927342785, Training Loss Force: 1.8488168553894542, time: 1.352480173110962
Validation Loss Energy: 1.1835381698480476, Validation Loss Force: 2.271037467038846, time: 0.08722424507141113
Test Loss Energy: 14.704479934454847, Test Loss Force: 9.105531359291003, time: 9.554906845092773


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.989703127017006, Training Loss Force: 1.8698514768689412, time: 1.4004709720611572
Validation Loss Energy: 1.2845992894244116, Validation Loss Force: 2.3263016110320907, time: 0.09292817115783691
Test Loss Energy: 14.194928188389456, Test Loss Force: 9.087714894446252, time: 10.82271409034729


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4567289242643515, Training Loss Force: 1.8691516809364752, time: 1.5399069786071777
Validation Loss Energy: 1.1242308551703326, Validation Loss Force: 2.15282453282267, time: 0.0965120792388916
Test Loss Energy: 14.200382220802052, Test Loss Force: 9.097339359080706, time: 10.544964075088501


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.268265155783335, Training Loss Force: 1.8470472282266668, time: 1.483138084411621
Validation Loss Energy: 3.697860828359552, Validation Loss Force: 2.352365368566657, time: 0.10405421257019043
Test Loss Energy: 17.10385935580512, Test Loss Force: 9.255383609512513, time: 10.934109926223755


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6800596712530367, Training Loss Force: 1.8609546569203474, time: 1.4839529991149902
Validation Loss Energy: 1.5161372360999303, Validation Loss Force: 2.197229881911027, time: 0.10259509086608887
Test Loss Energy: 14.05981461645056, Test Loss Force: 9.178308818076506, time: 10.56224513053894


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2145183489345504, Training Loss Force: 1.8535480044599963, time: 1.4928345680236816
Validation Loss Energy: 1.246535891615797, Validation Loss Force: 2.1387276831977005, time: 0.09373283386230469
Test Loss Energy: 15.429129972895462, Test Loss Force: 9.20426127776103, time: 10.899116277694702


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4329666886296533, Training Loss Force: 1.8430719642093991, time: 1.4650654792785645
Validation Loss Energy: 1.1533641903824434, Validation Loss Force: 2.233100322635972, time: 0.09788179397583008
Test Loss Energy: 14.726195198479566, Test Loss Force: 9.148066193123197, time: 10.693930625915527


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.418674377554287, Training Loss Force: 1.8419085401888418, time: 1.5081167221069336
Validation Loss Energy: 1.3669271424192981, Validation Loss Force: 2.2973365858606583, time: 0.10529971122741699
Test Loss Energy: 14.428503039548978, Test Loss Force: 9.093024208235299, time: 10.681461095809937


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9068689649172865, Training Loss Force: 1.8405001046476634, time: 1.4176521301269531
Validation Loss Energy: 1.858539645505003, Validation Loss Force: 2.1880761759910814, time: 0.10301876068115234
Test Loss Energy: 15.448372084524767, Test Loss Force: 9.141568996565171, time: 10.916655540466309


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6078575439656528, Training Loss Force: 1.854328870517342, time: 1.433741807937622
Validation Loss Energy: 2.4130531206145514, Validation Loss Force: 2.2640624117099444, time: 0.09354233741760254
Test Loss Energy: 15.849025295388536, Test Loss Force: 9.182483130104211, time: 10.590513229370117


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5960938590725022, Training Loss Force: 1.8555447826037985, time: 1.3987922668457031
Validation Loss Energy: 2.8161847541959473, Validation Loss Force: 2.131259805381574, time: 0.0938725471496582
Test Loss Energy: 13.087726495048257, Test Loss Force: 9.108153417888886, time: 10.825228691101074


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5123339914201974, Training Loss Force: 1.8370210798519597, time: 1.4296002388000488
Validation Loss Energy: 1.8925491288428566, Validation Loss Force: 2.087554639422587, time: 0.10843062400817871
Test Loss Energy: 13.422137640186634, Test Loss Force: 9.090541962544917, time: 10.559542417526245


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4841650922556489, Training Loss Force: 1.8108916831643265, time: 1.581878900527954
Validation Loss Energy: 1.152525145206944, Validation Loss Force: 2.412164837724159, time: 0.10510540008544922
Test Loss Energy: 14.704039809652103, Test Loss Force: 9.069174081040762, time: 11.244305610656738

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–‚â–ƒâ–‚â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‡â–‚â–„â–ƒâ–ƒâ–„â–…â–â–‚â–ƒ
wandb:   test_error_force â–ˆâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–†â–„â–…â–ƒâ–‚â–ƒâ–„â–‚â–‚â–
wandb:          test_loss â–„â–‚â–„â–…â–„â–†â–…â–…â–ƒâ–â–ˆâ–„â–†â–…â–„â–†â–‡â–ƒâ–ƒâ–…
wandb: train_error_energy â–…â–„â–„â–„â–„â–‚â–„â–ƒâ–ˆâ–‚â–â–ƒâ–â–‚â–‚â–„â–ƒâ–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–†â–ƒâ–â–‚â–ˆâ–â–â–â–â–†â–‚â–â–â–‚â–ƒâ–„â–„â–ƒâ–
wandb:  valid_error_force â–†â–„â–‡â–„â–‚â–â–‚â–…â–†â–ƒâ–‡â–„â–ƒâ–„â–†â–„â–…â–‚â–‚â–ˆ
wandb:         valid_loss â–…â–…â–‡â–ƒâ–â–„â–â–„â–…â–‚â–ˆâ–ƒâ–‚â–ƒâ–…â–ƒâ–…â–ƒâ–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 2851
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.70404
wandb:   test_error_force 9.06917
wandb:          test_loss 7.76155
wandb: train_error_energy 1.48417
wandb:  train_error_force 1.81089
wandb:         train_loss -2.67659
wandb: valid_error_energy 1.15253
wandb:  valid_error_force 2.41216
wandb:         valid_loss -1.87083
wandb: 
wandb: ğŸš€ View run al_69_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m4ew7ejo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_202233-m4ew7ejo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 108.80210876464844, Uncertainty Bias: -13.061534881591797
1.7642975e-05 0.0007610321
-3.225774 52.0846
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 509 steps.
Found uncertainty sample 2 after 307 steps.
Found uncertainty sample 3 after 512 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 593 steps.
Found uncertainty sample 6 after 907 steps.
Found uncertainty sample 7 after 278 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 401 steps.
Found uncertainty sample 10 after 237 steps.
Found uncertainty sample 11 after 407 steps.
Found uncertainty sample 12 after 818 steps.
Found uncertainty sample 13 after 575 steps.
Found uncertainty sample 14 after 1008 steps.
Found uncertainty sample 15 after 1320 steps.
Found uncertainty sample 16 after 127 steps.
Found uncertainty sample 17 after 2580 steps.
Found uncertainty sample 18 after 2321 steps.
Found uncertainty sample 19 after 296 steps.
Found uncertainty sample 20 after 88 steps.
Found uncertainty sample 21 after 143 steps.
Found uncertainty sample 22 after 222 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 495 steps.
Found uncertainty sample 25 after 552 steps.
Found uncertainty sample 26 after 122 steps.
Found uncertainty sample 27 after 3507 steps.
Found uncertainty sample 28 after 712 steps.
Found uncertainty sample 29 after 62 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1038 steps.
Found uncertainty sample 32 after 1550 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 5 steps.
Found uncertainty sample 35 after 136 steps.
Found uncertainty sample 36 after 645 steps.
Found uncertainty sample 37 after 944 steps.
Found uncertainty sample 38 after 1221 steps.
Found uncertainty sample 39 after 1000 steps.
Found uncertainty sample 40 after 119 steps.
Found uncertainty sample 41 after 920 steps.
Found uncertainty sample 42 after 160 steps.
Found uncertainty sample 43 after 108 steps.
Found uncertainty sample 44 after 129 steps.
Found uncertainty sample 45 after 331 steps.
Found uncertainty sample 46 after 2853 steps.
Found uncertainty sample 47 after 1592 steps.
Found uncertainty sample 48 after 56 steps.
Found uncertainty sample 49 after 2173 steps.
Found uncertainty sample 50 after 61 steps.
Found uncertainty sample 51 after 708 steps.
Found uncertainty sample 52 after 1696 steps.
Found uncertainty sample 53 after 117 steps.
Found uncertainty sample 54 after 1311 steps.
Found uncertainty sample 55 after 3470 steps.
Found uncertainty sample 56 after 91 steps.
Found uncertainty sample 57 after 557 steps.
Found uncertainty sample 58 after 195 steps.
Found uncertainty sample 59 after 1766 steps.
Found uncertainty sample 60 after 910 steps.
Found uncertainty sample 61 after 343 steps.
Found uncertainty sample 62 after 48 steps.
Found uncertainty sample 63 after 1344 steps.
Found uncertainty sample 64 after 987 steps.
Found uncertainty sample 65 after 1309 steps.
Found uncertainty sample 66 after 374 steps.
Found uncertainty sample 67 after 49 steps.
Found uncertainty sample 68 after 229 steps.
Found uncertainty sample 69 after 856 steps.
Found uncertainty sample 70 after 188 steps.
Found uncertainty sample 71 after 633 steps.
Found uncertainty sample 72 after 879 steps.
Found uncertainty sample 73 after 900 steps.
Found uncertainty sample 74 after 543 steps.
Found uncertainty sample 75 after 180 steps.
Found uncertainty sample 76 after 262 steps.
Found uncertainty sample 77 after 161 steps.
Found uncertainty sample 78 after 3879 steps.
Found uncertainty sample 79 after 229 steps.
Found uncertainty sample 80 after 510 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 168 steps.
Found uncertainty sample 83 after 63 steps.
Found uncertainty sample 84 after 94 steps.
Found uncertainty sample 85 after 3031 steps.
Found uncertainty sample 86 after 2137 steps.
Found uncertainty sample 87 after 1430 steps.
Found uncertainty sample 88 after 581 steps.
Found uncertainty sample 89 after 2254 steps.
Found uncertainty sample 90 after 264 steps.
Found uncertainty sample 91 after 121 steps.
Found uncertainty sample 92 after 188 steps.
Found uncertainty sample 93 after 714 steps.
Found uncertainty sample 94 after 958 steps.
Found uncertainty sample 95 after 1260 steps.
Found uncertainty sample 96 after 919 steps.
Found uncertainty sample 97 after 13 steps.
Found uncertainty sample 98 after 270 steps.
Found uncertainty sample 99 after 3975 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_203754-u9g65kcg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/u9g65kcg
Training model 24. Added 97 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.7335416042379068, Training Loss Force: 1.9927031185218786, time: 1.3641250133514404
Validation Loss Energy: 1.1199624824783996, Validation Loss Force: 2.180174316009542, time: 0.09235906600952148
Test Loss Energy: 14.20148119446242, Test Loss Force: 9.077162675900771, time: 9.758000373840332


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3676665803643653, Training Loss Force: 1.8349597356697764, time: 1.372117042541504
Validation Loss Energy: 2.863764697297797, Validation Loss Force: 2.1738076484546016, time: 0.09129929542541504
Test Loss Energy: 16.191773938119873, Test Loss Force: 9.154774480031563, time: 10.29584789276123


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4290721399860538, Training Loss Force: 1.82575816798504, time: 1.380735158920288
Validation Loss Energy: 2.807841452632606, Validation Loss Force: 2.123048880625487, time: 0.08957695960998535
Test Loss Energy: 16.29022596549578, Test Loss Force: 9.063202565533024, time: 9.904194116592407


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6838916597764833, Training Loss Force: 1.8363030877357327, time: 1.4153568744659424
Validation Loss Energy: 1.2013177723111599, Validation Loss Force: 2.214284334466782, time: 0.09257650375366211
Test Loss Energy: 14.250236914592879, Test Loss Force: 9.070060458128083, time: 9.67586064338684


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3751939220364195, Training Loss Force: 1.8235723871406926, time: 1.3549232482910156
Validation Loss Energy: 1.655101487367128, Validation Loss Force: 2.212499307258452, time: 0.08808255195617676
Test Loss Energy: 15.229159225401366, Test Loss Force: 9.10073169437374, time: 9.799571752548218


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4522190224708464, Training Loss Force: 1.832456302766862, time: 1.5457849502563477
Validation Loss Energy: 1.2104561418936797, Validation Loss Force: 2.196251362349247, time: 0.09328103065490723
Test Loss Energy: 14.404935774449811, Test Loss Force: 9.304279622862975, time: 9.865980386734009


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6994141286406412, Training Loss Force: 1.887385678221105, time: 1.4250848293304443
Validation Loss Energy: 1.0462275153257963, Validation Loss Force: 2.0717426807011083, time: 0.09585690498352051
Test Loss Energy: 14.675114448733824, Test Loss Force: 9.059553062531936, time: 9.777052640914917


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3939454190491412, Training Loss Force: 1.8333398490972699, time: 1.3605620861053467
Validation Loss Energy: 1.8779809999705313, Validation Loss Force: 2.1388842196072875, time: 0.09017157554626465
Test Loss Energy: 13.768700006162891, Test Loss Force: 9.133869801646446, time: 9.98717737197876


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3012336112878204, Training Loss Force: 1.8337668559096554, time: 1.4182510375976562
Validation Loss Energy: 1.4301434139537754, Validation Loss Force: 2.102585029441858, time: 0.09223508834838867
Test Loss Energy: 13.811497645546018, Test Loss Force: 9.131847219684913, time: 9.786555290222168


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.545836564211792, Training Loss Force: 1.8305183611530411, time: 1.4185311794281006
Validation Loss Energy: 1.6383783108332268, Validation Loss Force: 2.1499064536652863, time: 0.08966422080993652
Test Loss Energy: 15.587381629727341, Test Loss Force: 9.1584049990307, time: 9.826541662216187


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.348710804377869, Training Loss Force: 1.8381816626088376, time: 1.423410177230835
Validation Loss Energy: 1.5146347203704962, Validation Loss Force: 2.067030389233125, time: 0.08964014053344727
Test Loss Energy: 13.941734963707907, Test Loss Force: 9.03204183022458, time: 9.927130699157715


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.251164449198565, Training Loss Force: 1.7810290797413555, time: 1.3683841228485107
Validation Loss Energy: 2.2474226247711933, Validation Loss Force: 2.101583686292621, time: 0.0922234058380127
Test Loss Energy: 15.88477839646842, Test Loss Force: 9.159944181431918, time: 9.87573766708374


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5785256322209573, Training Loss Force: 1.8111974174484902, time: 1.3289496898651123
Validation Loss Energy: 1.044204760970545, Validation Loss Force: 2.121256616669914, time: 0.09388899803161621
Test Loss Energy: 14.39553171729561, Test Loss Force: 9.101507758135071, time: 9.778945684432983


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4747643043550738, Training Loss Force: 1.8195461852973325, time: 1.3612449169158936
Validation Loss Energy: 1.4860943809276344, Validation Loss Force: 2.166624564476117, time: 0.08979463577270508
Test Loss Energy: 15.185213079548069, Test Loss Force: 9.185201428405415, time: 9.995993852615356


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6326952787016709, Training Loss Force: 1.8481267661375287, time: 1.3692114353179932
Validation Loss Energy: 1.3869913581532727, Validation Loss Force: 2.059720606510608, time: 0.09116649627685547
Test Loss Energy: 13.947692377613606, Test Loss Force: 9.09186224368858, time: 9.809213638305664


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7339741523656134, Training Loss Force: 1.8270162922252344, time: 1.4254441261291504
Validation Loss Energy: 1.8133351368519108, Validation Loss Force: 2.1577436839272197, time: 0.09572505950927734
Test Loss Energy: 13.576383919758332, Test Loss Force: 9.07600782277704, time: 10.466186046600342


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8789298966698729, Training Loss Force: 1.8117020982778944, time: 1.3662073612213135
Validation Loss Energy: 2.6821479484589856, Validation Loss Force: 2.147553508800267, time: 0.09175229072570801
Test Loss Energy: 16.316025886323082, Test Loss Force: 9.06636891612489, time: 9.773733377456665


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2330253012861703, Training Loss Force: 1.91716544737717, time: 1.4043214321136475
Validation Loss Energy: 4.569220529657748, Validation Loss Force: 2.4287558044526656, time: 0.09554338455200195
Test Loss Energy: 18.011576401221657, Test Loss Force: 9.282473262675623, time: 9.77008605003357


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9601711115259683, Training Loss Force: 1.8537676641840104, time: 1.397092580795288
Validation Loss Energy: 1.1299422352624506, Validation Loss Force: 2.1689609204897646, time: 0.09317493438720703
Test Loss Energy: 14.596349241743265, Test Loss Force: 9.067136352914074, time: 9.943369388580322


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2883513852465958, Training Loss Force: 1.8042247364503732, time: 1.417855978012085
Validation Loss Energy: 1.288120746299973, Validation Loss Force: 2.080048573847934, time: 0.09556818008422852
Test Loss Energy: 13.870074637193332, Test Loss Force: 9.094598593346097, time: 9.82870626449585

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–…â–‚â–„â–‚â–ƒâ–â–â–„â–‚â–…â–‚â–„â–‚â–â–…â–ˆâ–ƒâ–
wandb:   test_error_force â–‚â–„â–‚â–‚â–ƒâ–ˆâ–‚â–„â–„â–„â–â–„â–ƒâ–…â–ƒâ–‚â–‚â–‡â–‚â–ƒ
wandb:          test_loss â–â–…â–…â–ƒâ–†â–†â–ƒâ–…â–„â–†â–ƒâ–ˆâ–…â–‡â–ƒâ–ƒâ–†â–‡â–ƒâ–…
wandb: train_error_energy â–„â–‚â–‚â–„â–‚â–‚â–„â–‚â–â–ƒâ–‚â–â–ƒâ–ƒâ–„â–„â–…â–ˆâ–†â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–†â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–„â–ƒâ–ƒâ–†â–„â–‚
wandb: valid_error_energy â–â–…â–…â–â–‚â–â–â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–ˆâ–â–
wandb:  valid_error_force â–ƒâ–ƒâ–‚â–„â–„â–„â–â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–ˆâ–ƒâ–
wandb:         valid_loss â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–ˆâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2938
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.87007
wandb:   test_error_force 9.0946
wandb:          test_loss 7.88879
wandb: train_error_energy 1.28835
wandb:  train_error_force 1.80422
wandb:         train_loss -2.69908
wandb: valid_error_energy 1.28812
wandb:  valid_error_force 2.08005
wandb:         valid_loss -2.31564
wandb: 
wandb: ğŸš€ View run al_69_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/u9g65kcg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_203754-u9g65kcg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 119.49089050292969, Uncertainty Bias: -14.250096321105957
0.0001487732 0.005929947
-3.778079 49.379635
(48745, 22, 3)
Found uncertainty sample 0 after 1026 steps.
Found uncertainty sample 1 after 336 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 329 steps.
Found uncertainty sample 4 after 2598 steps.
Found uncertainty sample 5 after 1323 steps.
Found uncertainty sample 6 after 770 steps.
Found uncertainty sample 7 after 1341 steps.
Found uncertainty sample 8 after 449 steps.
Found uncertainty sample 9 after 614 steps.
Found uncertainty sample 10 after 91 steps.
Found uncertainty sample 11 after 513 steps.
Found uncertainty sample 12 after 187 steps.
Found uncertainty sample 13 after 2787 steps.
Found uncertainty sample 14 after 1496 steps.
Found uncertainty sample 15 after 103 steps.
Found uncertainty sample 16 after 232 steps.
Found uncertainty sample 17 after 3596 steps.
Found uncertainty sample 18 after 1360 steps.
Found uncertainty sample 19 after 365 steps.
Found uncertainty sample 20 after 158 steps.
Found uncertainty sample 21 after 3623 steps.
Found uncertainty sample 22 after 1506 steps.
Found uncertainty sample 23 after 1096 steps.
Found uncertainty sample 24 after 2656 steps.
Found uncertainty sample 25 after 2643 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 3421 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1037 steps.
Found uncertainty sample 30 after 1892 steps.
Found uncertainty sample 31 after 139 steps.
Found uncertainty sample 32 after 354 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2295 steps.
Found uncertainty sample 35 after 1170 steps.
Found uncertainty sample 36 after 112 steps.
Found uncertainty sample 37 after 895 steps.
Found uncertainty sample 38 after 218 steps.
Found uncertainty sample 39 after 466 steps.
Found uncertainty sample 40 after 489 steps.
Found uncertainty sample 41 after 1304 steps.
Found uncertainty sample 42 after 391 steps.
Found uncertainty sample 43 after 776 steps.
Found uncertainty sample 44 after 106 steps.
Found uncertainty sample 45 after 768 steps.
Found uncertainty sample 46 after 1584 steps.
Found uncertainty sample 47 after 3413 steps.
Found uncertainty sample 48 after 320 steps.
Found uncertainty sample 49 after 2547 steps.
Found uncertainty sample 50 after 354 steps.
Found uncertainty sample 51 after 1458 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 358 steps.
Found uncertainty sample 54 after 114 steps.
Found uncertainty sample 55 after 2316 steps.
Found uncertainty sample 56 after 1406 steps.
Found uncertainty sample 57 after 62 steps.
Found uncertainty sample 58 after 694 steps.
Found uncertainty sample 59 after 855 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2836 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1711 steps.
Found uncertainty sample 64 after 606 steps.
Found uncertainty sample 65 after 1314 steps.
Found uncertainty sample 66 after 73 steps.
Found uncertainty sample 67 after 1155 steps.
Found uncertainty sample 68 after 482 steps.
Found uncertainty sample 69 after 915 steps.
Found uncertainty sample 70 after 3122 steps.
Found uncertainty sample 71 after 1552 steps.
Found uncertainty sample 72 after 2675 steps.
Found uncertainty sample 73 after 10 steps.
Found uncertainty sample 74 after 992 steps.
Found uncertainty sample 75 after 744 steps.
Found uncertainty sample 76 after 1136 steps.
Found uncertainty sample 77 after 597 steps.
Found uncertainty sample 78 after 187 steps.
Found uncertainty sample 79 after 135 steps.
Found uncertainty sample 80 after 141 steps.
Found uncertainty sample 81 after 2058 steps.
Found uncertainty sample 82 after 335 steps.
Found uncertainty sample 83 after 219 steps.
Found uncertainty sample 84 after 153 steps.
Found uncertainty sample 85 after 754 steps.
Found uncertainty sample 86 after 3240 steps.
Found uncertainty sample 87 after 2748 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 333 steps.
Found uncertainty sample 90 after 513 steps.
Found uncertainty sample 91 after 3703 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 98 steps.
Found uncertainty sample 94 after 483 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 264 steps.
Found uncertainty sample 97 after 124 steps.
Found uncertainty sample 98 after 1827 steps.
Found uncertainty sample 99 after 554 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_205641-tvji0jdx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/tvji0jdx
Training model 25. Added 94 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7867471213799115, Training Loss Force: 1.9606225205456, time: 1.4605581760406494
Validation Loss Energy: 1.8771497760487827, Validation Loss Force: 2.136287396360191, time: 0.09604144096374512
Test Loss Energy: 13.65463275816529, Test Loss Force: 9.109359062894029, time: 9.476651430130005


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2458336071928549, Training Loss Force: 1.8288660238263132, time: 1.4451344013214111
Validation Loss Energy: 1.1184146257441259, Validation Loss Force: 2.1597642394246552, time: 0.09311103820800781
Test Loss Energy: 13.971689774217515, Test Loss Force: 9.074052503218875, time: 9.556070804595947


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3241923633245212, Training Loss Force: 1.8312566677496802, time: 1.4344956874847412
Validation Loss Energy: 1.7064601258753722, Validation Loss Force: 2.175676900267379, time: 0.08997607231140137
Test Loss Energy: 15.098217633876084, Test Loss Force: 9.088210544307016, time: 9.630707263946533


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2070826656587585, Training Loss Force: 1.855570101648281, time: 1.39158296585083
Validation Loss Energy: 0.9706398852117873, Validation Loss Force: 2.0789375661443277, time: 0.08989810943603516
Test Loss Energy: 14.488452423914946, Test Loss Force: 9.041953848161958, time: 9.503321170806885


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2563480885044087, Training Loss Force: 1.8224022045510617, time: 1.4451968669891357
Validation Loss Energy: 0.9829969094650499, Validation Loss Force: 2.11782127708654, time: 0.09264588356018066
Test Loss Energy: 14.39321122033812, Test Loss Force: 9.130031134793953, time: 9.481303930282593


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4775964426741035, Training Loss Force: 1.8212231784550317, time: 1.4428293704986572
Validation Loss Energy: 4.168244945749085, Validation Loss Force: 2.102124438313507, time: 0.1095576286315918
Test Loss Energy: 12.651068061009441, Test Loss Force: 9.026690514739254, time: 9.668972492218018


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4936364456574978, Training Loss Force: 1.8333052274080444, time: 1.3749380111694336
Validation Loss Energy: 1.0990752259137895, Validation Loss Force: 2.1312448308815104, time: 0.09092092514038086
Test Loss Energy: 14.42513356340052, Test Loss Force: 9.151948694320648, time: 9.447032451629639


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8406115552429714, Training Loss Force: 1.8431484728721845, time: 1.5011942386627197
Validation Loss Energy: 1.776888372710018, Validation Loss Force: 2.1726260546317357, time: 0.0944821834564209
Test Loss Energy: 15.397048413233076, Test Loss Force: 9.120055794881026, time: 9.703405618667603


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9598306428479086, Training Loss Force: 1.881463520802041, time: 1.419044017791748
Validation Loss Energy: 2.4713863691134055, Validation Loss Force: 2.18291526186134, time: 0.09976744651794434
Test Loss Energy: 16.241880581466408, Test Loss Force: 9.169404262609554, time: 9.542510271072388


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.674935927453045, Training Loss Force: 1.9569999806673588, time: 1.4188897609710693
Validation Loss Energy: 1.8744484653049598, Validation Loss Force: 2.1764164401682917, time: 0.09079337120056152
Test Loss Energy: 13.79721929783388, Test Loss Force: 9.139205425368921, time: 9.497463941574097


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.7377189076824333, Training Loss Force: 1.9528580181285256, time: 1.4647881984710693
Validation Loss Energy: 3.650927850461195, Validation Loss Force: 2.3002876200516393, time: 0.0924842357635498
Test Loss Energy: 13.165123100524676, Test Loss Force: 9.1132957321501, time: 9.6981360912323


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8207340575493716, Training Loss Force: 1.8509436497220244, time: 1.4613375663757324
Validation Loss Energy: 1.273702000590922, Validation Loss Force: 2.2057033335901632, time: 0.0900723934173584
Test Loss Energy: 14.09581716293262, Test Loss Force: 9.039714561323345, time: 9.486562252044678


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4900295676238153, Training Loss Force: 1.8281568823656196, time: 1.407043218612671
Validation Loss Energy: 2.6237885920027715, Validation Loss Force: 2.1653522329762858, time: 0.09654092788696289
Test Loss Energy: 13.316345472472712, Test Loss Force: 9.054575560744532, time: 9.52218508720398


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.007953481454159, Training Loss Force: 1.8487646024283182, time: 1.445908784866333
Validation Loss Energy: 3.3917074528947877, Validation Loss Force: 2.105903245054474, time: 0.08967351913452148
Test Loss Energy: 16.23768183878623, Test Loss Force: 8.969038101344573, time: 10.27037501335144


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9035604028911037, Training Loss Force: 1.8091445527471508, time: 1.4995090961456299
Validation Loss Energy: 4.402523949610975, Validation Loss Force: 2.08008186288525, time: 0.10228753089904785
Test Loss Energy: 13.197405701280655, Test Loss Force: 9.00585429720715, time: 9.49526834487915


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.726437852811268, Training Loss Force: 1.8218085381375035, time: 1.5082945823669434
Validation Loss Energy: 1.6216802959128156, Validation Loss Force: 2.0400804641650527, time: 0.08985018730163574
Test Loss Energy: 15.046754947088917, Test Loss Force: 8.999402086811445, time: 9.461625814437866


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3750419508666025, Training Loss Force: 1.8049343995402918, time: 1.3862125873565674
Validation Loss Energy: 2.2823854660573364, Validation Loss Force: 2.032264721475701, time: 0.12425923347473145
Test Loss Energy: 16.194057348423588, Test Loss Force: 9.04900623001501, time: 9.743328332901001


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3169626506689651, Training Loss Force: 1.8089893980582112, time: 1.4983625411987305
Validation Loss Energy: 0.9794577503923871, Validation Loss Force: 2.0773862858719347, time: 0.09192085266113281
Test Loss Energy: 14.443700947880219, Test Loss Force: 8.966144255818268, time: 9.595961332321167


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4261256070429407, Training Loss Force: 1.8469219613363927, time: 1.4629359245300293
Validation Loss Energy: 1.8058056353496492, Validation Loss Force: 2.348913662801057, time: 0.09074926376342773
Test Loss Energy: 13.487778965540844, Test Loss Force: 9.0678712543602, time: 9.70616340637207


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.116340912835326, Training Loss Force: 1.8471892990849366, time: 1.3997619152069092
Validation Loss Energy: 1.9010762437861612, Validation Loss Force: 2.349482248465184, time: 0.0984504222869873
Test Loss Energy: 15.817000160787213, Test Loss Force: 9.143772124732422, time: 9.478280305862427

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–†â–…â–„â–â–„â–†â–ˆâ–ƒâ–‚â–„â–‚â–ˆâ–‚â–†â–ˆâ–„â–ƒâ–‡
wandb:   test_error_force â–†â–…â–…â–„â–‡â–ƒâ–‡â–†â–ˆâ–‡â–†â–„â–„â–â–‚â–‚â–„â–â–…â–‡
wandb:          test_loss â–„â–…â–†â–„â–†â–…â–†â–‡â–‡â–ƒâ–â–„â–„â–„â–„â–…â–ˆâ–…â–…â–ˆ
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–‚â–„â–„â–ˆâ–ˆâ–„â–‚â–…â–„â–ƒâ–‚â–â–‚â–…
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–„â–ˆâ–ˆâ–ƒâ–‚â–ƒâ–â–‚â–â–â–ƒâ–ƒ
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–„â–ˆâ–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–â–ƒâ–â–â–ˆâ–â–ƒâ–„â–ƒâ–†â–‚â–„â–†â–ˆâ–‚â–„â–â–ƒâ–ƒ
wandb:  valid_error_force â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–‡â–…â–„â–ƒâ–‚â–â–â–‚â–ˆâ–ˆ
wandb:         valid_loss â–ƒâ–ƒâ–„â–â–‚â–…â–‚â–„â–…â–„â–ˆâ–„â–…â–„â–…â–â–‚â–â–ˆâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3022
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.817
wandb:   test_error_force 9.14377
wandb:          test_loss 7.98466
wandb: train_error_energy 2.11634
wandb:  train_error_force 1.84719
wandb:         train_loss -2.58443
wandb: valid_error_energy 1.90108
wandb:  valid_error_force 2.34948
wandb:         valid_loss -1.90665
wandb: 
wandb: ğŸš€ View run al_69_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/tvji0jdx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_205641-tvji0jdx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 110.36253356933594, Uncertainty Bias: -13.242496490478516
9.536743e-05 0.0057811737
-3.4323113 40.19586
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1925 steps.
Found uncertainty sample 3 after 470 steps.
Found uncertainty sample 4 after 49 steps.
Found uncertainty sample 5 after 994 steps.
Found uncertainty sample 6 after 1691 steps.
Found uncertainty sample 7 after 100 steps.
Found uncertainty sample 8 after 2736 steps.
Found uncertainty sample 9 after 804 steps.
Found uncertainty sample 10 after 3807 steps.
Found uncertainty sample 11 after 183 steps.
Found uncertainty sample 12 after 3902 steps.
Found uncertainty sample 13 after 1294 steps.
Found uncertainty sample 14 after 3883 steps.
Found uncertainty sample 15 after 174 steps.
Found uncertainty sample 16 after 2205 steps.
Found uncertainty sample 17 after 2476 steps.
Found uncertainty sample 18 after 3897 steps.
Found uncertainty sample 19 after 1853 steps.
Found uncertainty sample 20 after 3597 steps.
Found uncertainty sample 21 after 720 steps.
Found uncertainty sample 22 after 1177 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 2618 steps.
Found uncertainty sample 25 after 1844 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 994 steps.
Found uncertainty sample 28 after 85 steps.
Found uncertainty sample 29 after 3573 steps.
Found uncertainty sample 30 after 773 steps.
Found uncertainty sample 31 after 320 steps.
Found uncertainty sample 32 after 490 steps.
Found uncertainty sample 33 after 863 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1039 steps.
Found uncertainty sample 36 after 409 steps.
Found uncertainty sample 37 after 345 steps.
Found uncertainty sample 38 after 1439 steps.
Found uncertainty sample 39 after 3350 steps.
Found uncertainty sample 40 after 1832 steps.
Found uncertainty sample 41 after 150 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 697 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1321 steps.
Found uncertainty sample 46 after 132 steps.
Found uncertainty sample 47 after 666 steps.
Found uncertainty sample 48 after 3452 steps.
Found uncertainty sample 49 after 761 steps.
Found uncertainty sample 50 after 3755 steps.
Found uncertainty sample 51 after 192 steps.
Found uncertainty sample 52 after 2025 steps.
Found uncertainty sample 53 after 865 steps.
Found uncertainty sample 54 after 145 steps.
Found uncertainty sample 55 after 135 steps.
Found uncertainty sample 56 after 47 steps.
Found uncertainty sample 57 after 2456 steps.
Found uncertainty sample 58 after 3890 steps.
Found uncertainty sample 59 after 60 steps.
Found uncertainty sample 60 after 116 steps.
Found uncertainty sample 61 after 474 steps.
Found uncertainty sample 62 after 861 steps.
Found uncertainty sample 63 after 1125 steps.
Found uncertainty sample 64 after 143 steps.
Found uncertainty sample 65 after 2499 steps.
Found uncertainty sample 66 after 1684 steps.
Found uncertainty sample 67 after 36 steps.
Found uncertainty sample 68 after 1095 steps.
Found uncertainty sample 69 after 971 steps.
Found uncertainty sample 70 after 2453 steps.
Found uncertainty sample 71 after 506 steps.
Found uncertainty sample 72 after 9 steps.
Found uncertainty sample 73 after 954 steps.
Found uncertainty sample 74 after 987 steps.
Found uncertainty sample 75 after 382 steps.
Found uncertainty sample 76 after 384 steps.
Found uncertainty sample 77 after 110 steps.
Found uncertainty sample 78 after 323 steps.
Found uncertainty sample 79 after 153 steps.
Found uncertainty sample 80 after 2206 steps.
Found uncertainty sample 81 after 2787 steps.
Found uncertainty sample 82 after 3007 steps.
Found uncertainty sample 83 after 1029 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 84 after 1 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 412 steps.
Found uncertainty sample 87 after 815 steps.
Found uncertainty sample 88 after 1886 steps.
Found uncertainty sample 89 after 2272 steps.
Found uncertainty sample 90 after 1922 steps.
Found uncertainty sample 91 after 1834 steps.
Found uncertainty sample 92 after 205 steps.
Found uncertainty sample 93 after 1442 steps.
Found uncertainty sample 94 after 1429 steps.
Found uncertainty sample 95 after 2164 steps.
Found uncertainty sample 96 after 1137 steps.
Found uncertainty sample 97 after 247 steps.
Found uncertainty sample 98 after 1114 steps.
Found uncertainty sample 99 after 2316 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_211606-3nmmfxkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3nmmfxkc
Training model 26. Added 97 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.259040342585326, Training Loss Force: 2.046689418472104, time: 1.4978227615356445
Validation Loss Energy: 2.2189543744643254, Validation Loss Force: 2.1921049288483525, time: 0.0952761173248291
Test Loss Energy: 13.64433605654509, Test Loss Force: 8.987442799782512, time: 9.533069610595703


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.30334177178197, Training Loss Force: 1.8230218399989149, time: 1.481313705444336
Validation Loss Energy: 1.6915337780145352, Validation Loss Force: 2.134719749905573, time: 0.09378385543823242
Test Loss Energy: 15.295088085405581, Test Loss Force: 9.007045752008922, time: 9.546550989151001


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.395236859962718, Training Loss Force: 1.796615003841693, time: 1.4960737228393555
Validation Loss Energy: 1.9458023477792274, Validation Loss Force: 2.1160525047258627, time: 0.09604787826538086
Test Loss Energy: 13.270438261964124, Test Loss Force: 9.05615339664419, time: 9.833445310592651


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.429080259667336, Training Loss Force: 1.820922715238912, time: 1.4630513191223145
Validation Loss Energy: 1.3198259936484797, Validation Loss Force: 2.2483183114106877, time: 0.0985109806060791
Test Loss Energy: 14.015717876306196, Test Loss Force: 9.0962252579081, time: 9.560622692108154


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8992048879771684, Training Loss Force: 1.8288634105372088, time: 1.5416889190673828
Validation Loss Energy: 1.8777604461814894, Validation Loss Force: 2.099741822784793, time: 0.09922480583190918
Test Loss Energy: 13.671257572352689, Test Loss Force: 9.036533390992302, time: 9.549759864807129


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9035283076629623, Training Loss Force: 1.8204656345578103, time: 1.5610742568969727
Validation Loss Energy: 3.278524169346828, Validation Loss Force: 2.1167870902382786, time: 0.1372818946838379
Test Loss Energy: 16.903969081639847, Test Loss Force: 9.044660413781044, time: 9.702054977416992


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9469318046440343, Training Loss Force: 1.841841513569683, time: 1.4844534397125244
Validation Loss Energy: 3.0018471787471204, Validation Loss Force: 2.1603887150444097, time: 0.09387350082397461
Test Loss Energy: 13.370352150754682, Test Loss Force: 9.079787061449517, time: 9.574003219604492


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7337375205725771, Training Loss Force: 1.8327724162448553, time: 1.4735333919525146
Validation Loss Energy: 1.9209120566437006, Validation Loss Force: 2.08200360894918, time: 0.09577345848083496
Test Loss Energy: 13.942155917979571, Test Loss Force: 9.03413870673759, time: 9.733253717422485


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.851500442716968, Training Loss Force: 1.8437471967812955, time: 1.5030450820922852
Validation Loss Energy: 1.5253929244887108, Validation Loss Force: 2.1694364304508933, time: 0.09539198875427246
Test Loss Energy: 14.747183134140728, Test Loss Force: 9.019335284194828, time: 9.490414381027222


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6119203641545448, Training Loss Force: 1.8325868908118155, time: 1.4655225276947021
Validation Loss Energy: 2.034198046335219, Validation Loss Force: 2.159773146190492, time: 0.09366178512573242
Test Loss Energy: 15.517413117735769, Test Loss Force: 9.076196711497982, time: 9.601366996765137


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3979288217265964, Training Loss Force: 1.8216673674416446, time: 1.455949068069458
Validation Loss Energy: 1.1177417752524186, Validation Loss Force: 2.1433398292173025, time: 0.09634542465209961
Test Loss Energy: 14.564662293776522, Test Loss Force: 9.020666813044876, time: 10.327680349349976


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7750130082883655, Training Loss Force: 1.8596779710774, time: 1.452650785446167
Validation Loss Energy: 1.1695749495442782, Validation Loss Force: 2.1749925823146565, time: 0.09849214553833008
Test Loss Energy: 14.488970387322585, Test Loss Force: 9.052988743467386, time: 9.549548625946045


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.471276314459508, Training Loss Force: 1.8254558443855213, time: 1.4851160049438477
Validation Loss Energy: 1.2642893582879058, Validation Loss Force: 2.125524182186193, time: 0.09223723411560059
Test Loss Energy: 14.748753597476625, Test Loss Force: 9.052108573136781, time: 9.575484275817871


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5647951938135425, Training Loss Force: 1.8782140550416224, time: 1.4921975135803223
Validation Loss Energy: 1.7263557810658794, Validation Loss Force: 2.255972897305674, time: 0.09270977973937988
Test Loss Energy: 15.323624705632513, Test Loss Force: 9.08214921036117, time: 9.763198137283325


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4757988480765782, Training Loss Force: 1.811145999225734, time: 1.4482848644256592
Validation Loss Energy: 1.0109985844102691, Validation Loss Force: 2.112948051493338, time: 0.09505653381347656
Test Loss Energy: 14.107116323379403, Test Loss Force: 8.953919808308168, time: 9.58310317993164


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7787631389923584, Training Loss Force: 1.830795909475966, time: 1.457615852355957
Validation Loss Energy: 2.1035042076762482, Validation Loss Force: 2.0554450249050755, time: 0.09424543380737305
Test Loss Energy: 15.75026981310159, Test Loss Force: 9.023845530517896, time: 9.654175281524658


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.622003752953053, Training Loss Force: 1.8218679593961806, time: 1.5015873908996582
Validation Loss Energy: 1.3051056147476259, Validation Loss Force: 2.1212559486624762, time: 0.0972452163696289
Test Loss Energy: 14.974077192785282, Test Loss Force: 9.014982818197467, time: 9.614869594573975


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9839268523634606, Training Loss Force: 1.8673912405169424, time: 1.4618494510650635
Validation Loss Energy: 1.4277953121426803, Validation Loss Force: 2.1660376086074518, time: 0.09881138801574707
Test Loss Energy: 14.028803095117642, Test Loss Force: 9.038878859536732, time: 9.614120483398438


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.045906426277857, Training Loss Force: 1.831556463209492, time: 1.4736413955688477
Validation Loss Energy: 4.141544577126311, Validation Loss Force: 2.2042927245507102, time: 0.09365701675415039
Test Loss Energy: 13.19125164370554, Test Loss Force: 9.056311335519656, time: 9.780901670455933


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.666203536385237, Training Loss Force: 1.8408479002207976, time: 1.4958412647247314
Validation Loss Energy: 1.1705769885345965, Validation Loss Force: 2.1059859109749, time: 0.0965416431427002
Test Loss Energy: 14.113148754636951, Test Loss Force: 9.006627082719067, time: 9.53434157371521

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–â–ƒâ–‚â–ˆâ–â–‚â–„â–…â–„â–ƒâ–„â–…â–ƒâ–†â–„â–ƒâ–â–ƒ
wandb:   test_error_force â–ƒâ–„â–†â–ˆâ–…â–…â–‡â–…â–„â–‡â–„â–†â–†â–‡â–â–„â–„â–…â–†â–„
wandb:          test_loss â–â–†â–†â–…â–…â–ˆâ–„â–…â–…â–‡â–…â–…â–†â–…â–…â–‡â–†â–„â–…â–„
wandb: train_error_energy â–ˆâ–â–‚â–‚â–…â–…â–†â–„â–…â–ƒâ–‚â–„â–‚â–ƒâ–‚â–„â–ƒâ–†â–†â–„
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚
wandb: valid_error_energy â–„â–ƒâ–ƒâ–‚â–ƒâ–†â–…â–ƒâ–‚â–ƒâ–â–â–‚â–ƒâ–â–ƒâ–‚â–‚â–ˆâ–
wandb:  valid_error_force â–†â–„â–ƒâ–ˆâ–ƒâ–ƒâ–…â–‚â–…â–…â–„â–…â–ƒâ–ˆâ–ƒâ–â–ƒâ–…â–†â–ƒ
wandb:         valid_loss â–…â–ƒâ–ƒâ–…â–‚â–„â–…â–â–ƒâ–„â–‚â–ƒâ–‚â–†â–â–â–‚â–ƒâ–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3109
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.11315
wandb:   test_error_force 9.00663
wandb:          test_loss 7.66967
wandb: train_error_energy 1.6662
wandb:  train_error_force 1.84085
wandb:         train_loss -2.62338
wandb: valid_error_energy 1.17058
wandb:  valid_error_force 2.10599
wandb:         valid_loss -2.29282
wandb: 
wandb: ğŸš€ View run al_69_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3nmmfxkc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_211606-3nmmfxkc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 116.0875473022461, Uncertainty Bias: -14.031685829162598
6.1035156e-05 0.0007625818
-3.758869 39.42458
(48745, 22, 3)
Found uncertainty sample 0 after 396 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 664 steps.
Found uncertainty sample 3 after 649 steps.
Found uncertainty sample 4 after 411 steps.
Found uncertainty sample 5 after 60 steps.
Found uncertainty sample 6 after 1798 steps.
Found uncertainty sample 7 after 1114 steps.
Found uncertainty sample 8 after 128 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1293 steps.
Found uncertainty sample 11 after 58 steps.
Found uncertainty sample 12 after 2425 steps.
Found uncertainty sample 13 after 1118 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 662 steps.
Found uncertainty sample 16 after 1950 steps.
Found uncertainty sample 17 after 1903 steps.
Found uncertainty sample 18 after 675 steps.
Found uncertainty sample 19 after 8 steps.
Found uncertainty sample 20 after 1979 steps.
Found uncertainty sample 21 after 760 steps.
Found uncertainty sample 22 after 714 steps.
Found uncertainty sample 23 after 1121 steps.
Found uncertainty sample 24 after 306 steps.
Found uncertainty sample 25 after 1481 steps.
Found uncertainty sample 26 after 946 steps.
Found uncertainty sample 27 after 2598 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3017 steps.
Found uncertainty sample 30 after 2479 steps.
Found uncertainty sample 31 after 1534 steps.
Found uncertainty sample 32 after 921 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3043 steps.
Found uncertainty sample 35 after 2542 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 40 steps.
Found uncertainty sample 38 after 283 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 986 steps.
Found uncertainty sample 41 after 479 steps.
Found uncertainty sample 42 after 1736 steps.
Found uncertainty sample 43 after 1750 steps.
Found uncertainty sample 44 after 21 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3465 steps.
Found uncertainty sample 47 after 949 steps.
Found uncertainty sample 48 after 53 steps.
Found uncertainty sample 49 after 774 steps.
Found uncertainty sample 50 after 96 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 11 steps.
Found uncertainty sample 53 after 838 steps.
Found uncertainty sample 54 after 1545 steps.
Found uncertainty sample 55 after 17 steps.
Found uncertainty sample 56 after 1107 steps.
Found uncertainty sample 57 after 55 steps.
Found uncertainty sample 58 after 156 steps.
Found uncertainty sample 59 after 2350 steps.
Found uncertainty sample 60 after 2547 steps.
Found uncertainty sample 61 after 605 steps.
Found uncertainty sample 62 after 12 steps.
Found uncertainty sample 63 after 680 steps.
Found uncertainty sample 64 after 1841 steps.
Found uncertainty sample 65 after 2539 steps.
Found uncertainty sample 66 after 646 steps.
Found uncertainty sample 67 after 2091 steps.
Found uncertainty sample 68 after 157 steps.
Found uncertainty sample 69 after 400 steps.
Found uncertainty sample 70 after 118 steps.
Found uncertainty sample 71 after 92 steps.
Found uncertainty sample 72 after 388 steps.
Found uncertainty sample 73 after 389 steps.
Found uncertainty sample 74 after 1611 steps.
Found uncertainty sample 75 after 234 steps.
Found uncertainty sample 76 after 3402 steps.
Found uncertainty sample 77 after 26 steps.
Found uncertainty sample 78 after 1573 steps.
Found uncertainty sample 79 after 237 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 54 steps.
Found uncertainty sample 82 after 402 steps.
Found uncertainty sample 83 after 142 steps.
Found uncertainty sample 84 after 239 steps.
Found uncertainty sample 85 after 298 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 832 steps.
Found uncertainty sample 88 after 913 steps.
Found uncertainty sample 89 after 3 steps.
Found uncertainty sample 90 after 352 steps.
Found uncertainty sample 91 after 146 steps.
Found uncertainty sample 92 after 326 steps.
Found uncertainty sample 93 after 1142 steps.
Found uncertainty sample 94 after 1276 steps.
Found uncertainty sample 95 after 61 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 532 steps.
Found uncertainty sample 98 after 1295 steps.
Found uncertainty sample 99 after 333 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_213526-q2w99qow
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/q2w99qow
Training model 27. Added 88 samples to the dataset.
Epoch 0, Batch 100/100, Loss: 0.11352547258138657, Uncertainty: 0.12395892292261124

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.878514493533932, Training Loss Force: 1.929372769420998, time: 1.464902639389038
Validation Loss Energy: 1.978544509673033, Validation Loss Force: 2.0614734023600647, time: 0.0955965518951416
Test Loss Energy: 13.355826735886742, Test Loss Force: 8.928319273128457, time: 9.288154363632202

Epoch 1, Batch 100/100, Loss: 0.051126688718795776, Uncertainty: 0.12236545234918594

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.25325011457611, Training Loss Force: 1.8305738481259213, time: 1.503023386001587
Validation Loss Energy: 1.0571200446062918, Validation Loss Force: 2.1764917023396153, time: 0.09451556205749512
Test Loss Energy: 14.184597086134916, Test Loss Force: 9.103846530283823, time: 9.253094673156738

Epoch 2, Batch 100/100, Loss: 0.1387633979320526, Uncertainty: 0.12202266603708267

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3221630026393976, Training Loss Force: 1.83520924303105, time: 1.505826711654663
Validation Loss Energy: 1.4192548370506202, Validation Loss Force: 2.236008715685508, time: 0.09548807144165039
Test Loss Energy: 13.713400186725309, Test Loss Force: 9.081180550612489, time: 9.440458059310913

Epoch 3, Batch 100/100, Loss: 0.059179652482271194, Uncertainty: 0.12263498455286026

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9379814669993332, Training Loss Force: 1.863347505457073, time: 1.5481927394866943
Validation Loss Energy: 1.2626504298729475, Validation Loss Force: 2.0908938416022065, time: 0.09746313095092773
Test Loss Energy: 14.999585727136088, Test Loss Force: 8.962426870204462, time: 9.453996181488037

Epoch 4, Batch 100/100, Loss: 0.12223761528730392, Uncertainty: 0.12107038497924805

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4678822024547653, Training Loss Force: 1.8160542678074822, time: 1.5093541145324707
Validation Loss Energy: 3.2194587290288776, Validation Loss Force: 2.1575834178094384, time: 0.09554505348205566
Test Loss Energy: 12.961175724572175, Test Loss Force: 8.975323256253708, time: 9.225303888320923

Epoch 5, Batch 100/100, Loss: 0.10031532496213913, Uncertainty: 0.12168221920728683

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9369237072819383, Training Loss Force: 1.833274978507736, time: 1.4772460460662842
Validation Loss Energy: 2.842837916959785, Validation Loss Force: 2.1823895400078044, time: 0.09659934043884277
Test Loss Energy: 16.481472489220145, Test Loss Force: 9.08029987199001, time: 9.487012147903442

Epoch 6, Batch 100/100, Loss: 0.06131643056869507, Uncertainty: 0.1214834675192833

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7317393930102014, Training Loss Force: 1.8103527530718744, time: 1.5394096374511719
Validation Loss Energy: 1.060442546599967, Validation Loss Force: 2.1057180956596353, time: 0.09816718101501465
Test Loss Energy: 14.12782036637178, Test Loss Force: 8.923260509926669, time: 9.294861555099487

Epoch 7, Batch 100/100, Loss: 0.04586758837103844, Uncertainty: 0.12250840663909912

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3865996731054742, Training Loss Force: 1.8403049718816666, time: 1.4480812549591064
Validation Loss Energy: 1.5585593824400819, Validation Loss Force: 2.041356469705792, time: 0.09804153442382812
Test Loss Energy: 13.46898367510996, Test Loss Force: 8.929156984766422, time: 9.28772521018982

Epoch 8, Batch 100/100, Loss: 0.05817413330078125, Uncertainty: 0.12349977344274521

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3703610864237996, Training Loss Force: 1.858513270344668, time: 1.7126710414886475
Validation Loss Energy: 1.1591880183932548, Validation Loss Force: 2.1621691775352483, time: 0.1029820442199707
Test Loss Energy: 14.272074089392088, Test Loss Force: 8.938666235022062, time: 9.356881380081177

Epoch 9, Batch 100/100, Loss: 0.05977284908294678, Uncertainty: 0.12278886139392853

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.389526671832171, Training Loss Force: 1.8333784729000724, time: 1.4885976314544678
Validation Loss Energy: 1.2380984010037281, Validation Loss Force: 2.1683100585762176, time: 0.0962979793548584
Test Loss Energy: 14.692585181840792, Test Loss Force: 8.990620430723363, time: 9.30016803741455

Epoch 10, Batch 100/100, Loss: 0.08340968936681747, Uncertainty: 0.12210016697645187

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4765311241009669, Training Loss Force: 1.8528905949602135, time: 1.5349960327148438
Validation Loss Energy: 1.0325164121625034, Validation Loss Force: 2.1194483205358345, time: 0.09390664100646973
Test Loss Energy: 14.368525899648846, Test Loss Force: 8.892102031620668, time: 9.411656856536865

Epoch 11, Batch 100/100, Loss: 0.17401161789894104, Uncertainty: 0.1218259334564209

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3060867501151971, Training Loss Force: 1.8215120700495269, time: 1.5023019313812256
Validation Loss Energy: 2.0570223574675417, Validation Loss Force: 2.1830941765200933, time: 0.0973203182220459
Test Loss Energy: 13.57614660341267, Test Loss Force: 9.007574701982168, time: 9.87731647491455

Epoch 12, Batch 100/100, Loss: 0.14444497227668762, Uncertainty: 0.12198751419782639

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1388619749596094, Training Loss Force: 1.8210767607760039, time: 1.487417459487915
Validation Loss Energy: 1.1629397986666354, Validation Loss Force: 2.1869617169157127, time: 0.09584903717041016
Test Loss Energy: 14.551706325660732, Test Loss Force: 8.98067648366259, time: 9.238497495651245

Epoch 13, Batch 100/100, Loss: 0.06960611790418625, Uncertainty: 0.12116052210330963

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.308603442015681, Training Loss Force: 1.817707198771682, time: 1.4982762336730957
Validation Loss Energy: 3.0641320809114685, Validation Loss Force: 2.0623150360643856, time: 0.09977293014526367
Test Loss Energy: 16.656587139282298, Test Loss Force: 9.011506465522187, time: 9.541739463806152

Epoch 14, Batch 100/100, Loss: 0.09840293973684311, Uncertainty: 0.1213594451546669

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8442404881574823, Training Loss Force: 1.8172421086132373, time: 1.4977965354919434
Validation Loss Energy: 1.396063511498522, Validation Loss Force: 2.188487557238183, time: 0.09494853019714355
Test Loss Energy: 14.9647624924096, Test Loss Force: 9.03633851002314, time: 9.33052110671997

Epoch 15, Batch 100/100, Loss: 0.30734696984291077, Uncertainty: 0.12209649384021759

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8588301747431712, Training Loss Force: 1.8431313503180282, time: 1.516852855682373
Validation Loss Energy: 4.072300262140563, Validation Loss Force: 2.107319198153429, time: 0.09759020805358887
Test Loss Energy: 12.77260131920028, Test Loss Force: 8.913107016044087, time: 9.265979290008545

Epoch 16, Batch 100/100, Loss: 0.07176103442907333, Uncertainty: 0.12048862129449844

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3645648654903733, Training Loss Force: 1.792109449905788, time: 1.5434010028839111
Validation Loss Energy: 1.3038899525454333, Validation Loss Force: 2.189444143889089, time: 0.09534120559692383
Test Loss Energy: 14.32048044979323, Test Loss Force: 9.012618179121963, time: 9.444783687591553

Epoch 17, Batch 100/100, Loss: 0.04434357210993767, Uncertainty: 0.11973340809345245

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2416327604429507, Training Loss Force: 1.7814178450157747, time: 1.514225721359253
Validation Loss Energy: 1.797197134833508, Validation Loss Force: 2.0247440154047034, time: 0.09568452835083008
Test Loss Energy: 13.386398887859881, Test Loss Force: 8.936651352050262, time: 9.313909530639648

Epoch 18, Batch 100/100, Loss: 0.05717393383383751, Uncertainty: 0.11910749971866608

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3101480109977561, Training Loss Force: 1.7945265557718606, time: 1.5210955142974854
Validation Loss Energy: 1.1175410946846511, Validation Loss Force: 2.116249900923728, time: 0.09673357009887695
Test Loss Energy: 13.896844490830613, Test Loss Force: 8.948220149677276, time: 9.330011129379272

Epoch 19, Batch 100/100, Loss: 0.6958703994750977, Uncertainty: 0.12309630215167999

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5619402816439676, Training Loss Force: 1.8237058922028282, time: 1.7078497409820557
Validation Loss Energy: 1.7623303196165458, Validation Loss Force: 2.0620078083102915, time: 0.1030740737915039
Test Loss Energy: 13.516593929195027, Test Loss Force: 8.909958007997849, time: 9.239695072174072

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ƒâ–…â–â–ˆâ–ƒâ–‚â–„â–„â–„â–‚â–„â–ˆâ–…â–â–„â–‚â–ƒâ–‚
wandb:   test_error_force â–‚â–ˆâ–‡â–ƒâ–„â–‡â–‚â–‚â–ƒâ–„â–â–…â–„â–…â–†â–‚â–…â–‚â–ƒâ–‚
wandb:          test_loss â–â–†â–…â–„â–„â–ˆâ–„â–â–‚â–„â–ƒâ–„â–„â–‡â–‡â–‚â–†â–…â–†â–„
wandb: train_error_energy â–…â–ˆâ–‚â–†â–‚â–†â–„â–‚â–‚â–‚â–ƒâ–â–‡â–ˆâ–…â–…â–‚â–â–â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–„â–…â–ƒâ–ƒâ–‚â–„â–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–…â–ƒâ–†â–ƒâ–„â–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–„â–„â–…â–‚â–â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–â–‚â–‚â–†â–…â–â–‚â–â–â–â–ƒâ–â–†â–‚â–ˆâ–‚â–ƒâ–â–ƒ
wandb:  valid_error_force â–‚â–†â–ˆâ–ƒâ–…â–†â–„â–‚â–†â–†â–„â–†â–†â–‚â–†â–„â–†â–â–„â–‚
wandb:         valid_loss â–‚â–…â–‡â–‚â–ˆâ–ˆâ–‚â–â–„â–…â–ƒâ–‡â–…â–„â–†â–‡â–†â–â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3188
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.51659
wandb:   test_error_force 8.90996
wandb:          test_loss 7.66632
wandb: train_error_energy 1.56194
wandb:  train_error_force 1.82371
wandb:         train_loss -2.65373
wandb: valid_error_energy 1.76233
wandb:  valid_error_force 2.06201
wandb:         valid_loss -2.30791
wandb: 
wandb: ğŸš€ View run al_69_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/q2w99qow
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_213526-q2w99qow/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 113.97791290283203, Uncertainty Bias: -13.547152519226074
3.194809e-05 0.0030126572
-3.2672012 30.607437
(48745, 22, 3)
Found uncertainty sample 0 after 128 steps.
Found uncertainty sample 1 after 1042 steps.
Found uncertainty sample 2 after 3482 steps.
Found uncertainty sample 3 after 12 steps.
Found uncertainty sample 4 after 652 steps.
Found uncertainty sample 5 after 1057 steps.
Found uncertainty sample 6 after 2522 steps.
Found uncertainty sample 7 after 239 steps.
Found uncertainty sample 8 after 183 steps.
Found uncertainty sample 9 after 448 steps.
Found uncertainty sample 10 after 3293 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 184 steps.
Found uncertainty sample 13 after 58 steps.
Found uncertainty sample 14 after 1235 steps.
Found uncertainty sample 15 after 413 steps.
Found uncertainty sample 16 after 3 steps.
Found uncertainty sample 17 after 309 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 379 steps.
Found uncertainty sample 20 after 2222 steps.
Found uncertainty sample 21 after 394 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3528 steps.
Found uncertainty sample 24 after 2639 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1373 steps.
Found uncertainty sample 27 after 1645 steps.
Found uncertainty sample 28 after 1969 steps.
Found uncertainty sample 29 after 281 steps.
Found uncertainty sample 30 after 1716 steps.
Found uncertainty sample 31 after 3195 steps.
Found uncertainty sample 32 after 344 steps.
Found uncertainty sample 33 after 60 steps.
Found uncertainty sample 34 after 860 steps.
Found uncertainty sample 35 after 842 steps.
Found uncertainty sample 36 after 2320 steps.
Found uncertainty sample 37 after 1175 steps.
Found uncertainty sample 38 after 113 steps.
Found uncertainty sample 39 after 2048 steps.
Found uncertainty sample 40 after 1095 steps.
Found uncertainty sample 41 after 2660 steps.
Found uncertainty sample 42 after 540 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 3628 steps.
Found uncertainty sample 45 after 1389 steps.
Found uncertainty sample 46 after 2888 steps.
Found uncertainty sample 47 after 3 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1790 steps.
Found uncertainty sample 50 after 1668 steps.
Found uncertainty sample 51 after 441 steps.
Found uncertainty sample 52 after 77 steps.
Found uncertainty sample 53 after 1655 steps.
Found uncertainty sample 54 after 1439 steps.
Found uncertainty sample 55 after 2149 steps.
Found uncertainty sample 56 after 1917 steps.
Found uncertainty sample 57 after 3816 steps.
Found uncertainty sample 58 after 1138 steps.
Found uncertainty sample 59 after 3484 steps.
Found uncertainty sample 60 after 250 steps.
Found uncertainty sample 61 after 2123 steps.
Found uncertainty sample 62 after 317 steps.
Found uncertainty sample 63 after 1925 steps.
Found uncertainty sample 64 after 1127 steps.
Found uncertainty sample 65 after 1179 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 2149 steps.
Found uncertainty sample 68 after 1791 steps.
Found uncertainty sample 69 after 1030 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1148 steps.
Found uncertainty sample 73 after 3280 steps.
Found uncertainty sample 74 after 1628 steps.
Found uncertainty sample 75 after 2372 steps.
Found uncertainty sample 76 after 465 steps.
Found uncertainty sample 77 after 321 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 158 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 488 steps.
Found uncertainty sample 83 after 724 steps.
Found uncertainty sample 84 after 1401 steps.
Found uncertainty sample 85 after 1317 steps.
Found uncertainty sample 86 after 2574 steps.
Found uncertainty sample 87 after 1063 steps.
Found uncertainty sample 88 after 995 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 3025 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 85 steps.
Found uncertainty sample 93 after 455 steps.
Found uncertainty sample 94 after 56 steps.
Found uncertainty sample 95 after 267 steps.
Found uncertainty sample 96 after 186 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 223 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_215706-hpo90q7i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hpo90q7i
Training model 28. Added 88 samples to the dataset.
Epoch 0, Batch 100/103, Loss: 0.059934988617897034, Uncertainty: 0.12285734713077545

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.600190125645609, Training Loss Force: 1.9350130213241963, time: 1.531064748764038
Validation Loss Energy: 1.278366557360747, Validation Loss Force: 2.082684475530141, time: 0.10339879989624023
Test Loss Energy: 14.133196928574504, Test Loss Force: 8.91929017216309, time: 9.522870540618896

Epoch 1, Batch 100/103, Loss: 0.0731889009475708, Uncertainty: 0.12248555570840836

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3261142676121171, Training Loss Force: 1.8322790365553363, time: 1.6115713119506836
Validation Loss Energy: 1.1908294153641665, Validation Loss Force: 2.079859249406609, time: 0.09665846824645996
Test Loss Energy: 14.546040927767327, Test Loss Force: 9.001084183166908, time: 9.517576217651367

Epoch 2, Batch 100/103, Loss: 0.09951676428318024, Uncertainty: 0.12167853116989136

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2729118237265267, Training Loss Force: 1.8145487669279177, time: 1.5548086166381836
Validation Loss Energy: 1.512970157170113, Validation Loss Force: 2.1221419491941234, time: 0.09942626953125
Test Loss Energy: 13.4596015118121, Test Loss Force: 8.892973644927553, time: 9.841228485107422

Epoch 3, Batch 100/103, Loss: 0.07634514570236206, Uncertainty: 0.12318927049636841

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0904884637746997, Training Loss Force: 1.9034158868720066, time: 1.6554758548736572
Validation Loss Energy: 2.8954926012319016, Validation Loss Force: 2.090527829193588, time: 0.10173726081848145
Test Loss Energy: 16.371154224870548, Test Loss Force: 8.958168428877034, time: 9.588806629180908

Epoch 4, Batch 100/103, Loss: 0.0461588129401207, Uncertainty: 0.12246235460042953

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.280018970261503, Training Loss Force: 1.8767343402775722, time: 1.558905839920044
Validation Loss Energy: 3.6902386408252976, Validation Loss Force: 2.3518334119770357, time: 0.09711790084838867
Test Loss Energy: 12.654869156232433, Test Loss Force: 9.046924910031233, time: 9.543226718902588

Epoch 5, Batch 100/103, Loss: 0.13146625459194183, Uncertainty: 0.1232704371213913

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.469136610828628, Training Loss Force: 1.8464645355233393, time: 1.7892029285430908
Validation Loss Energy: 2.679994849152437, Validation Loss Force: 2.148715173734572, time: 0.10547637939453125
Test Loss Energy: 16.108195734042667, Test Loss Force: 8.944735878840536, time: 9.59820294380188

Epoch 6, Batch 100/103, Loss: 0.0450313501060009, Uncertainty: 0.12208837270736694

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.688703278901872, Training Loss Force: 1.8414122893414022, time: 1.5945253372192383
Validation Loss Energy: 1.08775592338148, Validation Loss Force: 2.1289594104349945, time: 0.1005251407623291
Test Loss Energy: 14.031630429020314, Test Loss Force: 8.943398082611802, time: 9.557574033737183

Epoch 7, Batch 100/103, Loss: 0.09155780076980591, Uncertainty: 0.12236173450946808

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3614042817546879, Training Loss Force: 1.8405039624446624, time: 1.592564582824707
Validation Loss Energy: 1.5535272267439733, Validation Loss Force: 2.1500490732532525, time: 0.09748268127441406
Test Loss Energy: 13.341779828852752, Test Loss Force: 9.002367093199881, time: 9.809620380401611

Epoch 8, Batch 100/103, Loss: 0.08369607478380203, Uncertainty: 0.12168194353580475

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6140514580294338, Training Loss Force: 1.8193849926916779, time: 1.5305685997009277
Validation Loss Energy: 1.1549894524785702, Validation Loss Force: 2.266583527447425, time: 0.09942984580993652
Test Loss Energy: 13.821634888078368, Test Loss Force: 8.944167118888256, time: 9.541805267333984

Epoch 9, Batch 100/103, Loss: 0.05975867435336113, Uncertainty: 0.12306256592273712

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7044731820693313, Training Loss Force: 1.8565648241963968, time: 1.5600230693817139
Validation Loss Energy: 0.9890257322583313, Validation Loss Force: 2.1966191004437468, time: 0.10400104522705078
Test Loss Energy: 13.816227893648492, Test Loss Force: 8.921561929059564, time: 9.591681241989136

Epoch 10, Batch 100/103, Loss: 0.39624691009521484, Uncertainty: 0.12438298761844635

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4347574353664267, Training Loss Force: 1.82157919823585, time: 1.5182933807373047
Validation Loss Energy: 1.0844530162726467, Validation Loss Force: 2.1196597448898933, time: 0.10228943824768066
Test Loss Energy: 13.902981485653786, Test Loss Force: 8.937091444210408, time: 9.745042562484741

Epoch 11, Batch 100/103, Loss: 0.10763005912303925, Uncertainty: 0.12265516072511673

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.453145007828622, Training Loss Force: 1.8554260747275946, time: 1.635530710220337
Validation Loss Energy: 1.0780716525540752, Validation Loss Force: 2.125767782231838, time: 0.10308575630187988
Test Loss Energy: 14.101615066454954, Test Loss Force: 8.903058813190738, time: 9.538162469863892

Epoch 12, Batch 100/103, Loss: 0.08579583466053009, Uncertainty: 0.12238721549510956

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7307575860816733, Training Loss Force: 1.8255492939869429, time: 1.5308802127838135
Validation Loss Energy: 1.747026157882356, Validation Loss Force: 2.1153576656559956, time: 0.1115107536315918
Test Loss Energy: 14.905458895199107, Test Loss Force: 8.918066806890835, time: 9.732315063476562

Epoch 13, Batch 100/103, Loss: 0.16758452355861664, Uncertainty: 0.1218239814043045

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.874082842026887, Training Loss Force: 1.827095265329674, time: 1.5718903541564941
Validation Loss Energy: 3.7557386627876967, Validation Loss Force: 2.2171601064864395, time: 0.09757328033447266
Test Loss Energy: 16.73028825766448, Test Loss Force: 9.075318975372488, time: 10.27499508857727

Epoch 14, Batch 100/103, Loss: 0.13558652997016907, Uncertainty: 0.12152918428182602

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8173218863094658, Training Loss Force: 1.8086542822679352, time: 1.5554301738739014
Validation Loss Energy: 0.9907405073511211, Validation Loss Force: 2.1529195012134075, time: 0.10084366798400879
Test Loss Energy: 13.969729045314654, Test Loss Force: 8.90109755734309, time: 9.561723232269287

Epoch 15, Batch 100/103, Loss: 0.18450826406478882, Uncertainty: 0.12123295664787292

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5470399784419224, Training Loss Force: 1.8288997966257179, time: 1.5274567604064941
Validation Loss Energy: 1.8378840761867306, Validation Loss Force: 2.1526723384614277, time: 0.09691739082336426
Test Loss Energy: 13.321858065704886, Test Loss Force: 8.846640532462192, time: 9.747256517410278

Epoch 16, Batch 100/103, Loss: 0.14492258429527283, Uncertainty: 0.12169972062110901

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8916270953630832, Training Loss Force: 1.823878047469427, time: 1.4878427982330322
Validation Loss Energy: 1.4685204412544297, Validation Loss Force: 2.0747855659147847, time: 0.10333585739135742
Test Loss Energy: 14.752452568002324, Test Loss Force: 8.956238155517461, time: 9.563987016677856

Epoch 17, Batch 100/103, Loss: 0.04100245237350464, Uncertainty: 0.12010312080383301

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2121696031304166, Training Loss Force: 1.806749405013187, time: 1.5168144702911377
Validation Loss Energy: 2.37651138808192, Validation Loss Force: 2.059497993031967, time: 0.09755897521972656
Test Loss Energy: 15.57502397244085, Test Loss Force: 8.805367591493535, time: 9.47970724105835

Epoch 18, Batch 100/103, Loss: 0.09247179329395294, Uncertainty: 0.12075731158256531

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3812812273323463, Training Loss Force: 1.807193009512275, time: 1.5477030277252197
Validation Loss Energy: 1.8748418103512412, Validation Loss Force: 2.1937188348180374, time: 0.10038518905639648
Test Loss Energy: 13.492574834590362, Test Loss Force: 8.811437072099022, time: 9.760871648788452

Epoch 19, Batch 100/103, Loss: 0.21778735518455505, Uncertainty: 0.12090091407299042

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.723743353143418, Training Loss Force: 1.8118609763087419, time: 1.5558192729949951
Validation Loss Energy: 3.783684531278218, Validation Loss Force: 2.080298631298811, time: 0.1041569709777832
Test Loss Energy: 12.546396905372298, Test Loss Force: 8.900688051296624, time: 9.589258432388306

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–ƒâ–‡â–â–‡â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–…â–ˆâ–ƒâ–‚â–…â–†â–ƒâ–
wandb:   test_error_force â–„â–†â–ƒâ–…â–‡â–…â–…â–†â–…â–„â–„â–„â–„â–ˆâ–ƒâ–‚â–…â–â–â–ƒ
wandb:          test_loss â–‚â–…â–ƒâ–„â–„â–‚â–â–‚â–‚â–â–ƒâ–â–ƒâ–ˆâ–ƒâ–‚â–…â–„â–‚â–ƒ
wandb: train_error_energy â–ˆâ–‚â–â–…â–†â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–„â–„â–ƒâ–„â–â–‚â–„
wandb:  train_error_force â–ˆâ–‚â–â–†â–…â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–„â–‚â–‚â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–†â–…â–ƒâ–ƒâ–‚â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–â–â–‚
wandb: valid_error_energy â–‚â–‚â–‚â–†â–ˆâ–…â–â–‚â–â–â–â–â–ƒâ–ˆâ–â–ƒâ–‚â–„â–ƒâ–ˆ
wandb:  valid_error_force â–‚â–â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–ƒâ–†â–„â–‚â–ƒâ–‚â–…â–ƒâ–ƒâ–â–â–„â–
wandb:         valid_loss â–â–â–‚â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–‚â–†â–‚â–ƒâ–â–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3267
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.5464
wandb:   test_error_force 8.90069
wandb:          test_loss 7.52721
wandb: train_error_energy 1.72374
wandb:  train_error_force 1.81186
wandb:         train_loss -2.6594
wandb: valid_error_energy 3.78368
wandb:  valid_error_force 2.0803
wandb:         valid_loss -2.14831
wandb: 
wandb: ğŸš€ View run al_69_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hpo90q7i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_215706-hpo90q7i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 113.59537506103516, Uncertainty Bias: -13.541214942932129
3.8146973e-06 0.27254915
-3.261216 35.423717
(48745, 22, 3)
Found uncertainty sample 0 after 443 steps.
Found uncertainty sample 1 after 240 steps.
Found uncertainty sample 2 after 1769 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 34 steps.
Found uncertainty sample 5 after 2701 steps.
Found uncertainty sample 6 after 71 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1099 steps.
Found uncertainty sample 9 after 2407 steps.
Found uncertainty sample 10 after 322 steps.
Found uncertainty sample 11 after 109 steps.
Found uncertainty sample 12 after 477 steps.
Found uncertainty sample 13 after 1051 steps.
Found uncertainty sample 14 after 368 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 2129 steps.
Found uncertainty sample 17 after 859 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 0 steps.
Found uncertainty sample 20 after 538 steps.
Found uncertainty sample 21 after 416 steps.
Found uncertainty sample 22 after 203 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 3619 steps.
Found uncertainty sample 25 after 28 steps.
Found uncertainty sample 26 after 1059 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3478 steps.
Found uncertainty sample 30 after 653 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 444 steps.
Found uncertainty sample 33 after 476 steps.
Found uncertainty sample 34 after 646 steps.
Found uncertainty sample 35 after 24 steps.
Found uncertainty sample 36 after 660 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1020 steps.
Found uncertainty sample 39 after 74 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 665 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3330 steps.
Found uncertainty sample 44 after 29 steps.
Found uncertainty sample 45 after 600 steps.
Found uncertainty sample 46 after 482 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1279 steps.
Found uncertainty sample 49 after 597 steps.
Found uncertainty sample 50 after 2185 steps.
Found uncertainty sample 51 after 1105 steps.
Found uncertainty sample 52 after 1492 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 3879 steps.
Found uncertainty sample 55 after 1103 steps.
Found uncertainty sample 56 after 50 steps.
Found uncertainty sample 57 after 681 steps.
Found uncertainty sample 58 after 1914 steps.
Found uncertainty sample 59 after 949 steps.
Found uncertainty sample 60 after 706 steps.
Found uncertainty sample 61 after 215 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 215 steps.
Found uncertainty sample 64 after 2355 steps.
Found uncertainty sample 65 after 2292 steps.
Found uncertainty sample 66 after 716 steps.
Found uncertainty sample 67 after 1699 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 135 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1241 steps.
Found uncertainty sample 73 after 119 steps.
Found uncertainty sample 74 after 3492 steps.
Found uncertainty sample 75 after 3135 steps.
Found uncertainty sample 76 after 92 steps.
Found uncertainty sample 77 after 778 steps.
Found uncertainty sample 78 after 2204 steps.
Found uncertainty sample 79 after 670 steps.
Found uncertainty sample 80 after 231 steps.
Found uncertainty sample 81 after 449 steps.
Found uncertainty sample 82 after 1455 steps.
Found uncertainty sample 83 after 1025 steps.
Found uncertainty sample 84 after 3821 steps.
Found uncertainty sample 85 after 3536 steps.
Found uncertainty sample 86 after 1012 steps.
Found uncertainty sample 87 after 1077 steps.
Found uncertainty sample 88 after 295 steps.
Found uncertainty sample 89 after 2152 steps.
Found uncertainty sample 90 after 2427 steps.
Found uncertainty sample 91 after 862 steps.
Found uncertainty sample 92 after 1397 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 402 steps.
Found uncertainty sample 95 after 606 steps.
Found uncertainty sample 96 after 1013 steps.
Found uncertainty sample 97 after 818 steps.
Found uncertainty sample 98 after 2513 steps.
Found uncertainty sample 99 after 1119 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_221843-n4m88se6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n4m88se6
Training model 29. Added 85 samples to the dataset.
Epoch 0, Batch 100/105, Loss: 0.06306564807891846, Uncertainty: 0.12296255677938461

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.151984458798927, Training Loss Force: 1.8898516193794532, time: 1.6479458808898926
Validation Loss Energy: 1.9170730178987596, Validation Loss Force: 2.1423002983095385, time: 0.12177205085754395
Test Loss Energy: 13.441515199941854, Test Loss Force: 8.816706370726997, time: 11.199986219406128

Epoch 1, Batch 100/105, Loss: 0.3130525052547455, Uncertainty: 0.12221965193748474

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5185598888664935, Training Loss Force: 1.837163684241874, time: 1.7743403911590576
Validation Loss Energy: 1.9936819478842094, Validation Loss Force: 2.0990663002633347, time: 0.11466002464294434
Test Loss Energy: 13.53133858107295, Test Loss Force: 8.790059108695527, time: 10.457352876663208

Epoch 2, Batch 100/105, Loss: 0.08450505882501602, Uncertainty: 0.12171891331672668

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3741624200455882, Training Loss Force: 1.8161423023870495, time: 1.6956977844238281
Validation Loss Energy: 2.0011621838379345, Validation Loss Force: 2.140214779088779, time: 0.11461138725280762
Test Loss Energy: 15.504107514760205, Test Loss Force: 8.933333026851786, time: 10.917141914367676

Epoch 3, Batch 100/105, Loss: 0.09159146994352341, Uncertainty: 0.12113438546657562

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8632542365620826, Training Loss Force: 1.8171903869710044, time: 1.808927059173584
Validation Loss Energy: 1.7787335762550354, Validation Loss Force: 2.1233805463183466, time: 0.11941957473754883
Test Loss Energy: 13.36531888608462, Test Loss Force: 8.869031209131055, time: 10.61466932296753

Epoch 4, Batch 100/105, Loss: 0.04620054364204407, Uncertainty: 0.12197254598140717

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3373943724248472, Training Loss Force: 1.826547150186768, time: 1.6593537330627441
Validation Loss Energy: 2.1455936863123837, Validation Loss Force: 2.0904577997471936, time: 0.1192784309387207
Test Loss Energy: 13.2052542407453, Test Loss Force: 8.867769451501136, time: 10.64798378944397

Epoch 5, Batch 100/105, Loss: 0.07792554795742035, Uncertainty: 0.12194710969924927

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6434699804253132, Training Loss Force: 1.8324328025510288, time: 1.6670207977294922
Validation Loss Energy: 4.588900919451429, Validation Loss Force: 2.2022236828467494, time: 0.1049644947052002
Test Loss Energy: 17.48203434721728, Test Loss Force: 8.99453756105333, time: 10.588844776153564

Epoch 6, Batch 100/105, Loss: 0.21359314024448395, Uncertainty: 0.12162711471319199

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.960362203962617, Training Loss Force: 1.8394471743589607, time: 1.6784143447875977
Validation Loss Energy: 1.0374681842969322, Validation Loss Force: 2.1763398419820925, time: 0.10960221290588379
Test Loss Energy: 14.416386508465584, Test Loss Force: 8.86936962892704, time: 10.504232168197632

Epoch 7, Batch 100/105, Loss: 0.20152392983436584, Uncertainty: 0.12095892429351807

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5245870005534217, Training Loss Force: 1.812675524040929, time: 1.822263479232788
Validation Loss Energy: 3.586978830434756, Validation Loss Force: 2.150831087293751, time: 0.12377429008483887
Test Loss Energy: 16.57826374518309, Test Loss Force: 8.877876247816655, time: 10.633565664291382

Epoch 8, Batch 100/105, Loss: 0.04236992821097374, Uncertainty: 0.1208651214838028

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9187451184497322, Training Loss Force: 1.818585778164827, time: 1.6588160991668701
Validation Loss Energy: 1.022794287580291, Validation Loss Force: 2.07410887438031, time: 0.10791969299316406
Test Loss Energy: 13.953392474587947, Test Loss Force: 8.970411440698546, time: 10.394924640655518

Epoch 9, Batch 100/105, Loss: 0.09101030230522156, Uncertainty: 0.1225883960723877

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7964512451507841, Training Loss Force: 1.8663769833903576, time: 1.6675822734832764
Validation Loss Energy: 2.2533399459896515, Validation Loss Force: 2.3576393986225295, time: 0.10729432106018066
Test Loss Energy: 15.460506592352822, Test Loss Force: 9.126033694348148, time: 10.639521360397339

Epoch 10, Batch 100/105, Loss: 0.1138715073466301, Uncertainty: 0.12124134600162506

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7683534150412952, Training Loss Force: 1.8329322695916008, time: 1.6833248138427734
Validation Loss Energy: 2.4833457062720408, Validation Loss Force: 2.1507410176242234, time: 0.10589003562927246
Test Loss Energy: 13.456880210391946, Test Loss Force: 8.952209914449483, time: 10.574112176895142

Epoch 11, Batch 100/105, Loss: 0.06781311333179474, Uncertainty: 0.12016557902097702

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3549996559613289, Training Loss Force: 1.7760785859952117, time: 1.6289277076721191
Validation Loss Energy: 2.0720421707023817, Validation Loss Force: 2.019275706519009, time: 0.11952924728393555
Test Loss Energy: 13.141957185485875, Test Loss Force: 8.868969957628817, time: 10.571260213851929

Epoch 12, Batch 100/105, Loss: 0.06297603249549866, Uncertainty: 0.12004444003105164

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8237579821504315, Training Loss Force: 1.8145016930851217, time: 1.933206558227539
Validation Loss Energy: 1.1411969359087977, Validation Loss Force: 2.086920923033276, time: 0.10891842842102051
Test Loss Energy: 13.628408306370309, Test Loss Force: 8.842463609026701, time: 9.712759256362915

Epoch 13, Batch 100/105, Loss: 0.05709655582904816, Uncertainty: 0.1195959746837616

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5647040175768183, Training Loss Force: 1.805777343114001, time: 1.5574865341186523
Validation Loss Energy: 3.2300846120071247, Validation Loss Force: 2.1652941163291985, time: 0.11013197898864746
Test Loss Energy: 12.949955237448131, Test Loss Force: 8.75684960273605, time: 10.66543436050415

Epoch 14, Batch 100/105, Loss: 0.11567756533622742, Uncertainty: 0.12207524478435516

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.631495696536484, Training Loss Force: 1.8283879835847139, time: 1.718864917755127
Validation Loss Energy: 1.3587965455576043, Validation Loss Force: 2.1488019033669112, time: 0.12273693084716797
Test Loss Energy: 13.714875683419175, Test Loss Force: 8.946857167353105, time: 9.223236322402954

Epoch 15, Batch 100/105, Loss: 0.08905407786369324, Uncertainty: 0.12000595033168793

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.312475748230995, Training Loss Force: 1.8029794183484178, time: 1.5847790241241455
Validation Loss Energy: 1.8033454196235796, Validation Loss Force: 2.0951111395587922, time: 0.09722065925598145
Test Loss Energy: 13.091794466820387, Test Loss Force: 8.853323824467475, time: 8.73236346244812

Epoch 16, Batch 100/105, Loss: 0.10683523863554001, Uncertainty: 0.12083320319652557

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4582358544096035, Training Loss Force: 1.810187528218246, time: 1.589250087738037
Validation Loss Energy: 1.054906518460267, Validation Loss Force: 2.1315849023346285, time: 0.09541082382202148
Test Loss Energy: 14.191380805422432, Test Loss Force: 8.828072863525573, time: 9.257052659988403

Epoch 17, Batch 100/105, Loss: 0.15243348479270935, Uncertainty: 0.12134461849927902

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8088170547621825, Training Loss Force: 1.8186360801852213, time: 1.630014181137085
Validation Loss Energy: 1.673437233855838, Validation Loss Force: 2.10835071297194, time: 0.09190130233764648
Test Loss Energy: 13.441185458413525, Test Loss Force: 8.924148094790093, time: 8.960435152053833

Epoch 18, Batch 100/105, Loss: 0.051541768014431, Uncertainty: 0.12029814720153809

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.334919669685094, Training Loss Force: 1.8075751345660387, time: 1.5980925559997559
Validation Loss Energy: 1.331191861865931, Validation Loss Force: 2.093936559814023, time: 0.09143900871276855
Test Loss Energy: 14.705857769160794, Test Loss Force: 8.795353001188959, time: 8.65538239479065

Epoch 19, Batch 100/105, Loss: 0.09856550395488739, Uncertainty: 0.12170298397541046

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4243702007604917, Training Loss Force: 1.817907923449147, time: 1.6430222988128662
Validation Loss Energy: 1.6223706815997647, Validation Loss Force: 2.070082904887363, time: 0.09488582611083984
Test Loss Energy: 13.554426289111827, Test Loss Force: 8.813820135589095, time: 8.615288496017456

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–…â–‚â–â–ˆâ–ƒâ–‡â–ƒâ–…â–‚â–â–‚â–â–‚â–â–ƒâ–‚â–„â–‚
wandb:   test_error_force â–‚â–‚â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–ˆâ–…â–ƒâ–ƒâ–â–…â–ƒâ–‚â–„â–‚â–‚
wandb:          test_loss â–â–â–†â–„â–ƒâ–ˆâ–…â–‡â–†â–‡â–…â–†â–…â–ƒâ–„â–„â–„â–„â–„â–‚
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–†â–â–‚â–ƒâ–â–
wandb:  train_error_force â–ˆâ–…â–ƒâ–„â–„â–„â–…â–ƒâ–„â–‡â–„â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–„â–â–ƒâ–‚â–…â–‚â–‚â–ƒâ–‚â–ƒ
wandb: valid_error_energy â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ˆâ–â–†â–â–ƒâ–„â–ƒâ–â–…â–‚â–ƒâ–â–‚â–‚â–‚
wandb:  valid_error_force â–„â–ƒâ–„â–ƒâ–‚â–…â–„â–„â–‚â–ˆâ–„â–â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:         valid_loss â–ƒâ–‚â–ƒâ–ƒâ–‚â–‡â–ƒâ–…â–â–ˆâ–„â–â–â–…â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3343
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.55443
wandb:   test_error_force 8.81382
wandb:          test_loss 7.40239
wandb: train_error_energy 1.42437
wandb:  train_error_force 1.81791
wandb:         train_loss -2.67085
wandb: valid_error_energy 1.62237
wandb:  valid_error_force 2.07008
wandb:         valid_loss -2.30999
wandb: 
wandb: ğŸš€ View run al_69_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n4m88se6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_221843-n4m88se6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 113.80330657958984, Uncertainty Bias: -13.675663948059082
7.6293945e-06 0.0029058456
-3.649223 33.615788
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1609 steps.
Found uncertainty sample 3 after 110 steps.
Found uncertainty sample 4 after 3649 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 433 steps.
Found uncertainty sample 7 after 1446 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3826 steps.
Found uncertainty sample 10 after 154 steps.
Found uncertainty sample 11 after 2483 steps.
Found uncertainty sample 12 after 679 steps.
Found uncertainty sample 13 after 2055 steps.
Found uncertainty sample 14 after 2885 steps.
Found uncertainty sample 15 after 161 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 244 steps.
Found uncertainty sample 18 after 593 steps.
Found uncertainty sample 19 after 1550 steps.
Found uncertainty sample 20 after 979 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2032 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 387 steps.
Found uncertainty sample 26 after 2278 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1020 steps.
Found uncertainty sample 29 after 380 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1168 steps.
Found uncertainty sample 32 after 1333 steps.
Found uncertainty sample 33 after 362 steps.
Found uncertainty sample 34 after 876 steps.
Found uncertainty sample 35 after 5 steps.
Found uncertainty sample 36 after 2081 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1728 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3414 steps.
Found uncertainty sample 41 after 1149 steps.
Found uncertainty sample 42 after 322 steps.
Found uncertainty sample 43 after 288 steps.
Found uncertainty sample 44 after 530 steps.
Found uncertainty sample 45 after 500 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1149 steps.
Found uncertainty sample 48 after 293 steps.
Found uncertainty sample 49 after 1525 steps.
Found uncertainty sample 50 after 1281 steps.
Found uncertainty sample 51 after 1480 steps.
Found uncertainty sample 52 after 1005 steps.
Found uncertainty sample 53 after 3058 steps.
Found uncertainty sample 54 after 448 steps.
Found uncertainty sample 55 after 916 steps.
Found uncertainty sample 56 after 3610 steps.
Found uncertainty sample 57 after 2454 steps.
Found uncertainty sample 58 after 2335 steps.
Found uncertainty sample 59 after 893 steps.
Found uncertainty sample 60 after 1103 steps.
Found uncertainty sample 61 after 3026 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1101 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3236 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 363 steps.
Found uncertainty sample 68 after 314 steps.
Found uncertainty sample 69 after 3531 steps.
Found uncertainty sample 70 after 1996 steps.
Did not find any uncertainty samples for sample 71.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 72 after 1 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 902 steps.
Found uncertainty sample 75 after 835 steps.
Found uncertainty sample 76 after 941 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1997 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 34 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 153 steps.
Found uncertainty sample 83 after 3701 steps.
Found uncertainty sample 84 after 3408 steps.
Found uncertainty sample 85 after 2218 steps.
Found uncertainty sample 86 after 342 steps.
Found uncertainty sample 87 after 1227 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3392 steps.
Found uncertainty sample 90 after 1973 steps.
Found uncertainty sample 91 after 1448 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 206 steps.
Found uncertainty sample 94 after 355 steps.
Found uncertainty sample 95 after 1309 steps.
Found uncertainty sample 96 after 2062 steps.
Found uncertainty sample 97 after 1387 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 533 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_224449-p2q9f7gu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p2q9f7gu
Training model 30. Added 77 samples to the dataset.
Epoch 0, Batch 100/107, Loss: 0.03949788212776184, Uncertainty: 0.12436564266681671

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.921121454188915, Training Loss Force: 1.950167103175154, time: 1.6306979656219482
Validation Loss Energy: 1.0180532161251965, Validation Loss Force: 2.0784529267482155, time: 0.10375690460205078
Test Loss Energy: 14.000248008507093, Test Loss Force: 8.865822026788292, time: 9.72116231918335

Epoch 1, Batch 100/107, Loss: 0.10845208168029785, Uncertainty: 0.12158825993537903

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5007684828848786, Training Loss Force: 1.8002250954916015, time: 1.6026043891906738
Validation Loss Energy: 1.1318277140892374, Validation Loss Force: 2.0503071570319378, time: 0.10723376274108887
Test Loss Energy: 13.578837906285905, Test Loss Force: 8.809599130657553, time: 9.683234930038452

Epoch 2, Batch 100/107, Loss: 0.07245291769504547, Uncertainty: 0.12234098464250565

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0334054347000885, Training Loss Force: 1.8255782002848997, time: 1.6421701908111572
Validation Loss Energy: 2.3945295527012513, Validation Loss Force: 2.1445849950813307, time: 0.10620760917663574
Test Loss Energy: 13.052846140439705, Test Loss Force: 8.8606293729788, time: 9.930563688278198

Epoch 3, Batch 100/107, Loss: 0.1741327941417694, Uncertainty: 0.1214689165353775

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6626155783956242, Training Loss Force: 1.8150160662345203, time: 1.66414475440979
Validation Loss Energy: 3.2367727024742114, Validation Loss Force: 2.0724681367785416, time: 0.11267757415771484
Test Loss Energy: 16.175563573000815, Test Loss Force: 8.782621651448478, time: 9.712011098861694

Epoch 4, Batch 100/107, Loss: 0.0817689374089241, Uncertainty: 0.11992514878511429

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3646721355606364, Training Loss Force: 1.7976929820833834, time: 1.701720952987671
Validation Loss Energy: 0.9878482856483084, Validation Loss Force: 2.0531826507151627, time: 0.10290098190307617
Test Loss Energy: 14.053088357460762, Test Loss Force: 8.797710892573274, time: 10.543915271759033

Epoch 5, Batch 100/107, Loss: 0.1582435667514801, Uncertainty: 0.11955343186855316

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8554224600715237, Training Loss Force: 1.8087877594600028, time: 1.702113151550293
Validation Loss Energy: 2.21092982378338, Validation Loss Force: 2.0789355064547275, time: 0.10487151145935059
Test Loss Energy: 15.578316551956512, Test Loss Force: 8.880833760397394, time: 9.826679468154907

Epoch 6, Batch 100/107, Loss: 0.06689402461051941, Uncertainty: 0.12266155332326889

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7666685669790068, Training Loss Force: 1.8321932469480422, time: 1.6714184284210205
Validation Loss Energy: 2.2556830934122494, Validation Loss Force: 2.0130185921838653, time: 0.10288119316101074
Test Loss Energy: 15.952387263701874, Test Loss Force: 8.769379911382932, time: 9.709160089492798

Epoch 7, Batch 100/107, Loss: 0.3405442237854004, Uncertainty: 0.12243351340293884

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.6592972713228162, Training Loss Force: 1.8347222502717881, time: 1.6532995700836182
Validation Loss Energy: 7.232185419860482, Validation Loss Force: 2.1522848941475137, time: 0.10791730880737305
Test Loss Energy: 12.048410576093485, Test Loss Force: 9.003937514566722, time: 9.868900775909424

Epoch 8, Batch 100/107, Loss: 0.07476245611906052, Uncertainty: 0.12334448099136353

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5832171333711755, Training Loss Force: 1.8354019239080024, time: 1.5912656784057617
Validation Loss Energy: 1.357288129095803, Validation Loss Force: 2.0776455284250814, time: 0.10536718368530273
Test Loss Energy: 14.940198975240566, Test Loss Force: 8.781963511401537, time: 9.820739269256592

Epoch 9, Batch 100/107, Loss: 0.09914083033800125, Uncertainty: 0.12249434739351273

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.974816175212107, Training Loss Force: 1.8285378457368702, time: 1.6070165634155273
Validation Loss Energy: 1.4312980091426977, Validation Loss Force: 2.0841757464677055, time: 0.10742998123168945
Test Loss Energy: 14.843256663326962, Test Loss Force: 8.868808255528208, time: 9.80539059638977

Epoch 10, Batch 100/107, Loss: 0.15876173973083496, Uncertainty: 0.12263260781764984

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6244001958885383, Training Loss Force: 1.84832185576217, time: 1.617565631866455
Validation Loss Energy: 2.7090122015731626, Validation Loss Force: 2.0872392285773804, time: 0.10553812980651855
Test Loss Energy: 15.5890833629367, Test Loss Force: 8.87349362005938, time: 9.950534105300903

Epoch 11, Batch 100/107, Loss: 0.20583780109882355, Uncertainty: 0.12067127227783203

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6855831844069218, Training Loss Force: 1.8222191456942065, time: 1.6283166408538818
Validation Loss Energy: 1.8815467680061322, Validation Loss Force: 2.114438654423465, time: 0.1079106330871582
Test Loss Energy: 13.42179723851867, Test Loss Force: 8.911153431206808, time: 9.757722854614258

Epoch 12, Batch 100/107, Loss: 0.07789179682731628, Uncertainty: 0.12174038589000702

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5731501606144356, Training Loss Force: 1.8214649757020496, time: 1.5735688209533691
Validation Loss Energy: 1.4515577283867966, Validation Loss Force: 2.0236233772605354, time: 0.10176658630371094
Test Loss Energy: 14.874812033647183, Test Loss Force: 8.840527021656161, time: 9.881354808807373

Epoch 13, Batch 100/107, Loss: 0.07778661698102951, Uncertainty: 0.11981016397476196

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.37010567112146, Training Loss Force: 1.7843588491999387, time: 1.6140758991241455
Validation Loss Energy: 1.1735345914653823, Validation Loss Force: 2.0873152700907145, time: 0.10461759567260742
Test Loss Energy: 13.771220597578653, Test Loss Force: 8.799969928183259, time: 9.710519552230835

Epoch 14, Batch 100/107, Loss: 0.14004556834697723, Uncertainty: 0.12044352293014526

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6263557496840333, Training Loss Force: 1.8113374179483084, time: 1.5625536441802979
Validation Loss Energy: 2.0323148777008213, Validation Loss Force: 2.04181617015756, time: 0.10450434684753418
Test Loss Energy: 13.500694741292891, Test Loss Force: 8.78543370861561, time: 9.694242000579834

Epoch 15, Batch 100/107, Loss: 0.26906731724739075, Uncertainty: 0.12008927762508392

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6704397065552892, Training Loss Force: 1.8145924309008217, time: 1.6532597541809082
Validation Loss Energy: 1.1602935707027864, Validation Loss Force: 2.112261673851015, time: 0.1037287712097168
Test Loss Energy: 14.963970648284086, Test Loss Force: 8.86471460335845, time: 9.872184991836548

Epoch 16, Batch 100/107, Loss: 0.07797543704509735, Uncertainty: 0.12191225588321686

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8247347368436952, Training Loss Force: 1.8461871818071918, time: 1.5475027561187744
Validation Loss Energy: 1.3698352571324015, Validation Loss Force: 2.127843170006458, time: 0.10386180877685547
Test Loss Energy: 13.396052119949024, Test Loss Force: 8.794867186076438, time: 10.35482144355774

Epoch 17, Batch 100/107, Loss: 0.06810638308525085, Uncertainty: 0.1201266422867775

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3523431077904342, Training Loss Force: 1.8022998849729561, time: 1.6462287902832031
Validation Loss Energy: 1.1455220613992991, Validation Loss Force: 2.0745125735418775, time: 0.10330533981323242
Test Loss Energy: 13.941993563027015, Test Loss Force: 8.765775790918562, time: 9.684784412384033

Epoch 18, Batch 100/107, Loss: 0.11817938089370728, Uncertainty: 0.12103500217199326

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4365078191797878, Training Loss Force: 1.8048341012519404, time: 1.7543785572052002
Validation Loss Energy: 1.0766604590081146, Validation Loss Force: 2.026785501801856, time: 0.11287379264831543
Test Loss Energy: 14.238232347618249, Test Loss Force: 8.847831035965413, time: 9.697109460830688

Epoch 19, Batch 100/107, Loss: 0.38081738352775574, Uncertainty: 0.12027964740991592

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.197643006272552, Training Loss Force: 1.8028754847151796, time: 1.6494429111480713
Validation Loss Energy: 4.9026702477143616, Validation Loss Force: 2.144259564124557, time: 0.10362362861633301
Test Loss Energy: 12.257329522207133, Test Loss Force: 8.874343083032375, time: 9.727208137512207

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–ƒâ–ˆâ–„â–‡â–ˆâ–â–†â–†â–‡â–ƒâ–†â–„â–ƒâ–†â–ƒâ–„â–…â–
wandb:   test_error_force â–„â–‚â–„â–â–‚â–„â–â–ˆâ–â–„â–„â–…â–ƒâ–‚â–‚â–„â–‚â–â–ƒâ–„
wandb:          test_loss â–â–„â–ƒâ–†â–…â–ˆâ–ƒâ–„â–‚â–„â–…â–†â–…â–†â–…â–ˆâ–‚â–„â–…â–…
wandb: train_error_energy â–ˆâ–‚â–„â–‚â–â–ƒâ–ƒâ–‡â–‚â–„â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–…
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–‚â–‚â–„â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–â–‚â–ƒ
wandb: valid_error_energy â–â–â–ƒâ–„â–â–‚â–‚â–ˆâ–â–â–ƒâ–‚â–‚â–â–‚â–â–â–â–â–…
wandb:  valid_error_force â–„â–ƒâ–ˆâ–„â–ƒâ–„â–â–ˆâ–„â–…â–…â–†â–‚â–…â–‚â–†â–‡â–„â–‚â–ˆ
wandb:         valid_loss â–‚â–â–„â–ƒâ–â–ƒâ–‚â–ˆâ–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 3412
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.25733
wandb:   test_error_force 8.87434
wandb:          test_loss 7.57708
wandb: train_error_energy 2.19764
wandb:  train_error_force 1.80288
wandb:         train_loss -2.64007
wandb: valid_error_energy 4.90267
wandb:  valid_error_force 2.14426
wandb:         valid_loss -1.98239
wandb: 
wandb: ğŸš€ View run al_69_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p2q9f7gu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_224449-p2q9f7gu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 123.10150146484375, Uncertainty Bias: -14.612852096557617
4.9591064e-05 1.3513136
-3.2388706 30.832003
(48745, 22, 3)
Found uncertainty sample 0 after 41 steps.
Found uncertainty sample 1 after 123 steps.
Found uncertainty sample 2 after 2446 steps.
Found uncertainty sample 3 after 122 steps.
Found uncertainty sample 4 after 1369 steps.
Found uncertainty sample 5 after 422 steps.
Found uncertainty sample 6 after 2472 steps.
Found uncertainty sample 7 after 945 steps.
Found uncertainty sample 8 after 419 steps.
Found uncertainty sample 9 after 2204 steps.
Found uncertainty sample 10 after 1156 steps.
Found uncertainty sample 11 after 555 steps.
Found uncertainty sample 12 after 117 steps.
Found uncertainty sample 13 after 234 steps.
Found uncertainty sample 14 after 290 steps.
Found uncertainty sample 15 after 1420 steps.
Found uncertainty sample 16 after 2552 steps.
Found uncertainty sample 17 after 1494 steps.
Found uncertainty sample 18 after 102 steps.
Found uncertainty sample 19 after 1804 steps.
Found uncertainty sample 20 after 663 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 24 steps.
Found uncertainty sample 23 after 875 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 148 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1872 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 681 steps.
Found uncertainty sample 31 after 3045 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1353 steps.
Found uncertainty sample 34 after 1206 steps.
Found uncertainty sample 35 after 1178 steps.
Found uncertainty sample 36 after 656 steps.
Found uncertainty sample 37 after 3000 steps.
Found uncertainty sample 38 after 1065 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 961 steps.
Found uncertainty sample 42 after 1840 steps.
Found uncertainty sample 43 after 1829 steps.
Found uncertainty sample 44 after 2303 steps.
Found uncertainty sample 45 after 173 steps.
Found uncertainty sample 46 after 745 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 201 steps.
Found uncertainty sample 49 after 1003 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1879 steps.
Found uncertainty sample 52 after 637 steps.
Found uncertainty sample 53 after 3 steps.
Found uncertainty sample 54 after 262 steps.
Found uncertainty sample 55 after 2310 steps.
Found uncertainty sample 56 after 148 steps.
Found uncertainty sample 57 after 274 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 475 steps.
Found uncertainty sample 60 after 1188 steps.
Found uncertainty sample 61 after 431 steps.
Found uncertainty sample 62 after 346 steps.
Found uncertainty sample 63 after 1748 steps.
Found uncertainty sample 64 after 696 steps.
Found uncertainty sample 65 after 3588 steps.
Found uncertainty sample 66 after 357 steps.
Found uncertainty sample 67 after 956 steps.
Found uncertainty sample 68 after 1674 steps.
Found uncertainty sample 69 after 258 steps.
Found uncertainty sample 70 after 1151 steps.
Found uncertainty sample 71 after 1301 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1767 steps.
Found uncertainty sample 74 after 101 steps.
Found uncertainty sample 75 after 657 steps.
Found uncertainty sample 76 after 239 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 128 steps.
Found uncertainty sample 79 after 1705 steps.
Found uncertainty sample 80 after 915 steps.
Found uncertainty sample 81 after 1241 steps.
Found uncertainty sample 82 after 1007 steps.
Found uncertainty sample 83 after 254 steps.
Found uncertainty sample 84 after 596 steps.
Found uncertainty sample 85 after 2239 steps.
Found uncertainty sample 86 after 817 steps.
Found uncertainty sample 87 after 468 steps.
Found uncertainty sample 88 after 2 steps.
Found uncertainty sample 89 after 1254 steps.
Found uncertainty sample 90 after 3151 steps.
Found uncertainty sample 91 after 227 steps.
Found uncertainty sample 92 after 2689 steps.
Found uncertainty sample 93 after 594 steps.
Found uncertainty sample 94 after 84 steps.
Found uncertainty sample 95 after 777 steps.
Found uncertainty sample 96 after 80 steps.
Found uncertainty sample 97 after 208 steps.
Found uncertainty sample 98 after 1221 steps.
Found uncertainty sample 99 after 1045 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_230439-0uvnqq4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0uvnqq4h
Training model 31. Added 88 samples to the dataset.
Epoch 0, Batch 100/110, Loss: 0.0414242222905159, Uncertainty: 0.12237530946731567

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.328324555162182, Training Loss Force: 1.923521375678413, time: 1.7157177925109863
Validation Loss Energy: 1.8253535926687903, Validation Loss Force: 2.1918160156315114, time: 0.10665178298950195
Test Loss Energy: 15.080985504165755, Test Loss Force: 8.86901946245925, time: 9.721402406692505

Epoch 1, Batch 100/110, Loss: 0.17617276310920715, Uncertainty: 0.12234862148761749

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8536070487265022, Training Loss Force: 1.8244333921805942, time: 1.6568043231964111
Validation Loss Energy: 1.321019444603366, Validation Loss Force: 2.042049304753346, time: 0.1082010269165039
Test Loss Energy: 14.371709704703813, Test Loss Force: 8.84039660049023, time: 9.726188898086548

Epoch 2, Batch 100/110, Loss: 0.14952754974365234, Uncertainty: 0.12059471011161804

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4570175773631449, Training Loss Force: 1.8015429503361955, time: 1.6503875255584717
Validation Loss Energy: 1.677847084956365, Validation Loss Force: 2.1786223120624255, time: 0.10526371002197266
Test Loss Energy: 13.494493249360655, Test Loss Force: 8.89641684205042, time: 9.944660902023315

Epoch 3, Batch 100/110, Loss: 0.0545843206346035, Uncertainty: 0.12093492597341537

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.495355070516039, Training Loss Force: 1.8278615962299736, time: 1.690049648284912
Validation Loss Energy: 4.310448921754959, Validation Loss Force: 2.087463846078335, time: 0.11025452613830566
Test Loss Energy: 17.264749187351494, Test Loss Force: 8.794142203316667, time: 10.403836727142334

Epoch 4, Batch 100/110, Loss: 0.0862262099981308, Uncertainty: 0.12131303548812866

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8567304146665766, Training Loss Force: 1.8472367390128273, time: 1.687096357345581
Validation Loss Energy: 3.9428722623860146, Validation Loss Force: 2.3425263983501186, time: 0.10674166679382324
Test Loss Energy: 17.44705516947699, Test Loss Force: 8.9575977243586, time: 9.827891826629639

Epoch 5, Batch 100/110, Loss: 0.1448669135570526, Uncertainty: 0.12224076688289642

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6996326440168683, Training Loss Force: 1.8194078052242901, time: 1.6891772747039795
Validation Loss Energy: 3.548770697681288, Validation Loss Force: 2.132743561235464, time: 0.1057741641998291
Test Loss Energy: 16.399270086681394, Test Loss Force: 8.899872219525314, time: 9.731198072433472

Epoch 6, Batch 100/110, Loss: 0.047078557312488556, Uncertainty: 0.12103271484375

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5174778430205653, Training Loss Force: 1.8362608120401223, time: 1.6537704467773438
Validation Loss Energy: 8.19911750195521, Validation Loss Force: 2.2072005609273813, time: 0.1051943302154541
Test Loss Energy: 11.868238529155398, Test Loss Force: 8.807405823248864, time: 9.81790018081665

Epoch 7, Batch 100/110, Loss: 0.23835940659046173, Uncertainty: 0.121279776096344

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1271019817212826, Training Loss Force: 1.819398427816849, time: 1.6557519435882568
Validation Loss Energy: 1.0239194626083075, Validation Loss Force: 2.1618005487641647, time: 0.10756397247314453
Test Loss Energy: 14.560644120618198, Test Loss Force: 8.768813552993171, time: 9.918000221252441

Epoch 8, Batch 100/110, Loss: 0.04396483674645424, Uncertainty: 0.12104232609272003

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.610598726600222, Training Loss Force: 1.8254217891432605, time: 1.6754024028778076
Validation Loss Energy: 1.4212109854975958, Validation Loss Force: 2.1721535507040772, time: 0.11794185638427734
Test Loss Energy: 13.63411462409105, Test Loss Force: 8.942784742198052, time: 9.6898832321167

Epoch 9, Batch 100/110, Loss: 0.03455185890197754, Uncertainty: 0.12055666744709015

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3960706938436438, Training Loss Force: 1.800297668076932, time: 1.6487963199615479
Validation Loss Energy: 1.495852800580633, Validation Loss Force: 2.040203154864459, time: 0.10557699203491211
Test Loss Energy: 14.624845170641036, Test Loss Force: 8.781067947754687, time: 9.704046964645386

Epoch 10, Batch 100/110, Loss: 0.03541291132569313, Uncertainty: 0.12020781636238098

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3714314105513938, Training Loss Force: 1.815967236964517, time: 1.659970998764038
Validation Loss Energy: 1.9267799453117624, Validation Loss Force: 2.1980898301526, time: 0.10514497756958008
Test Loss Energy: 15.161124512169879, Test Loss Force: 8.975409199549192, time: 10.030858278274536

Epoch 11, Batch 100/110, Loss: 0.13084614276885986, Uncertainty: 0.1197001039981842

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3651346689523018, Training Loss Force: 1.7910179385053193, time: 1.6308343410491943
Validation Loss Energy: 0.9887530182218561, Validation Loss Force: 2.0421827392390437, time: 0.10863995552062988
Test Loss Energy: 14.092685436810044, Test Loss Force: 8.825671473548727, time: 9.761693000793457

Epoch 12, Batch 100/110, Loss: 0.08082056045532227, Uncertainty: 0.11896392703056335

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7216159813552485, Training Loss Force: 1.7715744565373148, time: 1.7361106872558594
Validation Loss Energy: 2.0054653207502757, Validation Loss Force: 2.039176538767159, time: 0.10905623435974121
Test Loss Energy: 13.054790813847921, Test Loss Force: 8.73752842140961, time: 9.970798015594482

Epoch 13, Batch 100/110, Loss: 0.04479037597775459, Uncertainty: 0.11900679767131805

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4182234350848812, Training Loss Force: 1.7889628460112184, time: 1.682344675064087
Validation Loss Energy: 1.5469485781621097, Validation Loss Force: 2.060739818858806, time: 0.11081457138061523
Test Loss Energy: 14.761539395069414, Test Loss Force: 8.763689831022736, time: 9.782539129257202

Epoch 14, Batch 100/110, Loss: 0.10822988301515579, Uncertainty: 0.11945879459381104

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2978806112781553, Training Loss Force: 1.7928197934282866, time: 1.6816470623016357
Validation Loss Energy: 1.8276984101099827, Validation Loss Force: 2.0569094642105563, time: 0.10523033142089844
Test Loss Energy: 13.316432283128641, Test Loss Force: 8.727487591120026, time: 9.77863359451294

Epoch 15, Batch 100/110, Loss: 0.12479731440544128, Uncertainty: 0.11907050013542175

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3674447692372464, Training Loss Force: 1.773172808055024, time: 1.6407012939453125
Validation Loss Energy: 1.7348815599943086, Validation Loss Force: 2.147784305370021, time: 0.10523080825805664
Test Loss Energy: 13.342999892559448, Test Loss Force: 8.786045407573035, time: 9.978724241256714

Epoch 16, Batch 100/110, Loss: 0.12295586615800858, Uncertainty: 0.11972572654485703

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8832213943337128, Training Loss Force: 1.8089834054348684, time: 1.649094820022583
Validation Loss Energy: 4.052023119035795, Validation Loss Force: 2.117873938339552, time: 0.11423802375793457
Test Loss Energy: 16.82881629099661, Test Loss Force: 8.84895881438629, time: 9.75653076171875

Epoch 17, Batch 100/110, Loss: 0.1787106990814209, Uncertainty: 0.12072782963514328

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7271854918495684, Training Loss Force: 1.8166773076160987, time: 1.6720764636993408
Validation Loss Energy: 1.0306858769474745, Validation Loss Force: 2.22590042713697, time: 0.10871720314025879
Test Loss Energy: 13.867044205713432, Test Loss Force: 8.919854133653565, time: 9.77642560005188

Epoch 18, Batch 100/110, Loss: 0.05631646513938904, Uncertainty: 0.12098623067140579

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.807368021751761, Training Loss Force: 1.8294499883640647, time: 1.912198781967163
Validation Loss Energy: 1.1140888322461868, Validation Loss Force: 2.237811222421793, time: 0.11562967300415039
Test Loss Energy: 13.63463431289312, Test Loss Force: 8.7044929844319, time: 9.718305587768555

Epoch 19, Batch 100/110, Loss: 0.06144479662179947, Uncertainty: 0.12088857591152191

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.607818090985295, Training Loss Force: 1.8105114916793152, time: 1.7429921627044678
Validation Loss Energy: 2.313935234674699, Validation Loss Force: 2.043382647599162, time: 0.10858368873596191
Test Loss Energy: 15.383096155741597, Test Loss Force: 8.751191931811753, time: 9.773859739303589

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–ƒâ–ˆâ–ˆâ–‡â–â–„â–ƒâ–„â–…â–„â–‚â–…â–ƒâ–ƒâ–‡â–„â–ƒâ–…
wandb:   test_error_force â–…â–…â–†â–ƒâ–ˆâ–†â–„â–ƒâ–‡â–ƒâ–ˆâ–„â–‚â–ƒâ–‚â–ƒâ–…â–‡â–â–‚
wandb:          test_loss â–ƒâ–‚â–„â–…â–‡â–‡â–â–‚â–…â–„â–†â–…â–„â–„â–ƒâ–…â–ˆâ–…â–â–„
wandb: train_error_energy â–ˆâ–…â–‚â–‚â–…â–„â–‚â–‡â–ƒâ–‚â–â–â–„â–‚â–â–â–…â–„â–„â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–â–ƒâ–ƒâ–„â–ƒ
wandb:         train_loss â–ˆâ–„â–‚â–ƒâ–„â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–ƒâ–„â–ƒ
wandb: valid_error_energy â–‚â–â–‚â–„â–„â–ƒâ–ˆâ–â–â–â–‚â–â–‚â–‚â–‚â–‚â–„â–â–â–‚
wandb:  valid_error_force â–…â–â–„â–‚â–ˆâ–ƒâ–…â–„â–„â–â–…â–â–â–â–â–„â–ƒâ–…â–†â–
wandb:         valid_loss â–„â–â–ƒâ–„â–‡â–„â–ˆâ–ƒâ–ƒâ–â–„â–â–‚â–‚â–‚â–ƒâ–„â–„â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3491
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.3831
wandb:   test_error_force 8.75119
wandb:          test_loss 7.58586
wandb: train_error_energy 1.60782
wandb:  train_error_force 1.81051
wandb:         train_loss -2.66865
wandb: valid_error_energy 2.31394
wandb:  valid_error_force 2.04338
wandb:         valid_loss -2.29835
wandb: 
wandb: ğŸš€ View run al_69_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0uvnqq4h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_230439-0uvnqq4h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 101.63157653808594, Uncertainty Bias: -12.101195335388184
0.00015830994 0.0014400482
-2.640507 19.563732
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3617 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 675 steps.
Found uncertainty sample 4 after 866 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 9 steps.
Found uncertainty sample 7 after 160 steps.
Found uncertainty sample 8 after 1217 steps.
Found uncertainty sample 9 after 2271 steps.
Found uncertainty sample 10 after 1282 steps.
Found uncertainty sample 11 after 82 steps.
Found uncertainty sample 12 after 2251 steps.
Found uncertainty sample 13 after 3506 steps.
Found uncertainty sample 14 after 2815 steps.
Found uncertainty sample 15 after 625 steps.
Found uncertainty sample 16 after 31 steps.
Found uncertainty sample 17 after 819 steps.
Found uncertainty sample 18 after 904 steps.
Found uncertainty sample 19 after 750 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 34 steps.
Found uncertainty sample 22 after 358 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1064 steps.
Found uncertainty sample 25 after 1550 steps.
Found uncertainty sample 26 after 2180 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3727 steps.
Found uncertainty sample 29 after 794 steps.
Found uncertainty sample 30 after 1366 steps.
Found uncertainty sample 31 after 166 steps.
Found uncertainty sample 32 after 107 steps.
Found uncertainty sample 33 after 2339 steps.
Found uncertainty sample 34 after 966 steps.
Found uncertainty sample 35 after 92 steps.
Found uncertainty sample 36 after 1463 steps.
Found uncertainty sample 37 after 1510 steps.
Found uncertainty sample 38 after 872 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2645 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 32 steps.
Found uncertainty sample 43 after 868 steps.
Found uncertainty sample 44 after 1270 steps.
Found uncertainty sample 45 after 18 steps.
Found uncertainty sample 46 after 2008 steps.
Found uncertainty sample 47 after 1974 steps.
Found uncertainty sample 48 after 2010 steps.
Found uncertainty sample 49 after 1359 steps.
Found uncertainty sample 50 after 1677 steps.
Found uncertainty sample 51 after 3506 steps.
Found uncertainty sample 52 after 1931 steps.
Found uncertainty sample 53 after 3053 steps.
Found uncertainty sample 54 after 1586 steps.
Found uncertainty sample 55 after 3593 steps.
Found uncertainty sample 56 after 558 steps.
Found uncertainty sample 57 after 3082 steps.
Found uncertainty sample 58 after 883 steps.
Found uncertainty sample 59 after 1411 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 705 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2468 steps.
Found uncertainty sample 65 after 1701 steps.
Found uncertainty sample 66 after 2050 steps.
Found uncertainty sample 67 after 206 steps.
Found uncertainty sample 68 after 1715 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1702 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1470 steps.
Found uncertainty sample 74 after 2236 steps.
Found uncertainty sample 75 after 42 steps.
Found uncertainty sample 76 after 775 steps.
Found uncertainty sample 77 after 19 steps.
Found uncertainty sample 78 after 801 steps.
Found uncertainty sample 79 after 102 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1591 steps.
Found uncertainty sample 82 after 1987 steps.
Found uncertainty sample 83 after 1068 steps.
Found uncertainty sample 84 after 428 steps.
Found uncertainty sample 85 after 891 steps.
Found uncertainty sample 86 after 81 steps.
Found uncertainty sample 87 after 2551 steps.
Found uncertainty sample 88 after 3300 steps.
Found uncertainty sample 89 after 1028 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1585 steps.
Found uncertainty sample 92 after 942 steps.
Found uncertainty sample 93 after 1538 steps.
Found uncertainty sample 94 after 6 steps.
Found uncertainty sample 95 after 1851 steps.
Found uncertainty sample 96 after 1655 steps.
Found uncertainty sample 97 after 1943 steps.
Found uncertainty sample 98 after 484 steps.
Found uncertainty sample 99 after 1246 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_232821-3nmtazya
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3nmtazya
Training model 32. Added 85 samples to the dataset.
Epoch 0, Batch 100/112, Loss: 0.0604536309838295, Uncertainty: 0.12336347997188568

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2193506897604616, Training Loss Force: 1.9658144758320526, time: 1.6501038074493408
Validation Loss Energy: 1.7641919821225995, Validation Loss Force: 2.038277437867427, time: 0.11253142356872559
Test Loss Energy: 13.39254331586879, Test Loss Force: 8.800480952707355, time: 9.744171380996704

Epoch 1, Batch 100/112, Loss: 0.19569477438926697, Uncertainty: 0.12278091162443161

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6654442524906798, Training Loss Force: 1.8463471976079895, time: 1.6918230056762695
Validation Loss Energy: 1.6504300556874225, Validation Loss Force: 2.0550041214403763, time: 0.11183595657348633
Test Loss Energy: 12.549692404068802, Test Loss Force: 8.669810970907825, time: 9.73398756980896

Epoch 2, Batch 100/112, Loss: 0.1494409143924713, Uncertainty: 0.12237690389156342

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6170567651875838, Training Loss Force: 1.832534745191246, time: 1.7329158782958984
Validation Loss Energy: 1.244544134661235, Validation Loss Force: 2.1440627988226058, time: 0.11969542503356934
Test Loss Energy: 14.368200849328073, Test Loss Force: 8.6722920741073, time: 9.842443227767944

Epoch 3, Batch 100/112, Loss: 0.09997276961803436, Uncertainty: 0.12205536663532257

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6200755616256084, Training Loss Force: 1.8185751263621, time: 1.705113172531128
Validation Loss Energy: 0.9105441454777474, Validation Loss Force: 1.9756963486274708, time: 0.11168575286865234
Test Loss Energy: 14.183899364607125, Test Loss Force: 8.816331601067294, time: 9.761984825134277

Epoch 4, Batch 100/112, Loss: 0.09737332910299301, Uncertainty: 0.12043534219264984

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6824109592376035, Training Loss Force: 1.7992962120207021, time: 1.6845693588256836
Validation Loss Energy: 1.344687690354517, Validation Loss Force: 2.0558652572507277, time: 0.11887931823730469
Test Loss Energy: 14.755878180091697, Test Loss Force: 8.753724349174197, time: 9.968745708465576

Epoch 5, Batch 100/112, Loss: 0.048725809901952744, Uncertainty: 0.12136973440647125

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8092339002173468, Training Loss Force: 1.8302266383373704, time: 1.7197039127349854
Validation Loss Energy: 1.0002493056136539, Validation Loss Force: 2.091132487259354, time: 0.11464333534240723
Test Loss Energy: 13.91328315361201, Test Loss Force: 8.662855845341838, time: 9.796053647994995

Epoch 6, Batch 100/112, Loss: 0.1800820678472519, Uncertainty: 0.12172937393188477

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4205616087077275, Training Loss Force: 1.8166148645002766, time: 1.6544084548950195
Validation Loss Energy: 0.713058095973441, Validation Loss Force: 2.0626891758968307, time: 0.11262845993041992
Test Loss Energy: 13.589528203018002, Test Loss Force: 8.712010472001092, time: 10.403306722640991

Epoch 7, Batch 100/112, Loss: 0.12757937610149384, Uncertainty: 0.12135793268680573

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2792540837724786, Training Loss Force: 1.8063779676209677, time: 1.6741094589233398
Validation Loss Energy: 1.0637743635862464, Validation Loss Force: 2.0278241977003226, time: 0.11352276802062988
Test Loss Energy: 14.670976915586827, Test Loss Force: 8.73700650358447, time: 9.937291860580444

Epoch 8, Batch 100/112, Loss: 0.06345845013856888, Uncertainty: 0.11929763108491898

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.364144498787749, Training Loss Force: 1.7973098561183405, time: 1.6883199214935303
Validation Loss Energy: 0.8106935296016954, Validation Loss Force: 1.965515766829555, time: 0.11812806129455566
Test Loss Energy: 14.114089127243446, Test Loss Force: 8.656226884608163, time: 9.772926092147827

Epoch 9, Batch 100/112, Loss: 0.12973229587078094, Uncertainty: 0.12060500681400299

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2874858792877324, Training Loss Force: 1.8275927784517074, time: 1.729301929473877
Validation Loss Energy: 0.8523656520353134, Validation Loss Force: 2.112168561036493, time: 0.11341047286987305
Test Loss Energy: 13.787605698521098, Test Loss Force: 8.687488970518022, time: 9.716234683990479

Epoch 10, Batch 100/112, Loss: 0.10833956301212311, Uncertainty: 0.1209404319524765

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7765903931809202, Training Loss Force: 1.8195470225108468, time: 1.757842779159546
Validation Loss Energy: 2.9552085694596806, Validation Loss Force: 2.311091378565958, time: 0.16342401504516602
Test Loss Energy: 15.95008956526699, Test Loss Force: 8.764144868829224, time: 9.976295471191406

Epoch 11, Batch 100/112, Loss: 0.19287198781967163, Uncertainty: 0.1197187751531601

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9574216780985598, Training Loss Force: 1.7903922613577927, time: 1.6872360706329346
Validation Loss Energy: 1.5936320181709298, Validation Loss Force: 1.924741112388599, time: 0.11734747886657715
Test Loss Energy: 13.208719900638343, Test Loss Force: 8.669487352198106, time: 9.779780626296997

Epoch 12, Batch 100/112, Loss: 0.062063731253147125, Uncertainty: 0.11874906718730927

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5508053896823188, Training Loss Force: 1.7914002189735345, time: 1.6548278331756592
Validation Loss Energy: 1.0583132172247458, Validation Loss Force: 2.0767598618971537, time: 0.11224675178527832
Test Loss Energy: 14.04646965116587, Test Loss Force: 8.778296302123024, time: 10.029731512069702

Epoch 13, Batch 100/112, Loss: 0.07845195382833481, Uncertainty: 0.11904268711805344

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4566096559101933, Training Loss Force: 1.792230421002952, time: 1.7055861949920654
Validation Loss Energy: 2.0986379961611425, Validation Loss Force: 2.1099639880457106, time: 0.11115789413452148
Test Loss Energy: 12.893226917330344, Test Loss Force: 8.788320535983493, time: 9.838676929473877

Epoch 14, Batch 100/112, Loss: 0.1887119561433792, Uncertainty: 0.1206471249461174

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7255611176285868, Training Loss Force: 1.8177698831581994, time: 1.7178280353546143
Validation Loss Energy: 3.2852698568996623, Validation Loss Force: 2.13139099462005, time: 0.11426806449890137
Test Loss Energy: 12.755508125710554, Test Loss Force: 8.70263410043264, time: 9.900611639022827

Epoch 15, Batch 100/112, Loss: 0.05986838415265083, Uncertainty: 0.12003795802593231

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9714753656953314, Training Loss Force: 1.7980285178046462, time: 1.686349868774414
Validation Loss Energy: 0.8979746206362211, Validation Loss Force: 2.1181911676494507, time: 0.11106300354003906
Test Loss Energy: 13.813901166618148, Test Loss Force: 8.777856704265067, time: 9.932651996612549

Epoch 16, Batch 100/112, Loss: 0.09254412353038788, Uncertainty: 0.11986249685287476

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.458357738430385, Training Loss Force: 1.819517999973416, time: 1.7134044170379639
Validation Loss Energy: 1.4734278280057698, Validation Loss Force: 2.0786197430500395, time: 0.11346769332885742
Test Loss Energy: 13.00557432480354, Test Loss Force: 8.668318719235081, time: 9.813391208648682

Epoch 17, Batch 100/112, Loss: 0.10434985160827637, Uncertainty: 0.12179162353277206

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9472903244063031, Training Loss Force: 1.849345886972434, time: 1.6816132068634033
Validation Loss Energy: 2.3724195085217783, Validation Loss Force: 1.9474860976376849, time: 0.1114346981048584
Test Loss Energy: 15.206251587918924, Test Loss Force: 8.671032820630918, time: 10.013397693634033

Epoch 18, Batch 100/112, Loss: 0.0720866397023201, Uncertainty: 0.12059441208839417

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7775290330962878, Training Loss Force: 1.8190835138202484, time: 1.727539300918579
Validation Loss Energy: 3.32982550766152, Validation Loss Force: 1.7999404372671008, time: 0.11829447746276855
Test Loss Energy: 12.729472590615877, Test Loss Force: 8.665580774753526, time: 9.808714389801025

Epoch 19, Batch 100/112, Loss: 0.0657029002904892, Uncertainty: 0.12082690000534058

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0878544057721746, Training Loss Force: 1.8055075310661863, time: 1.67313814163208
Validation Loss Energy: 2.164524237757153, Validation Loss Force: 2.0093833699304966, time: 0.11172366142272949
Test Loss Energy: 15.363844596411992, Test Loss Force: 8.80615262264267, time: 9.789918184280396

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–…â–„â–†â–„â–ƒâ–…â–„â–„â–ˆâ–‚â–„â–‚â–â–„â–‚â–†â–â–‡
wandb:   test_error_force â–‡â–‚â–‚â–ˆâ–…â–â–ƒâ–…â–â–‚â–†â–‚â–†â–‡â–ƒâ–†â–‚â–‚â–â–ˆ
wandb:          test_loss â–ƒâ–â–ƒâ–…â–†â–ƒâ–ƒâ–…â–„â–ƒâ–†â–„â–ˆâ–†â–„â–‡â–ƒâ–ƒâ–ƒâ–‡
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–â–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–â–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–‚
wandb: valid_error_energy â–„â–„â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–‡â–ƒâ–‚â–…â–ˆâ–â–ƒâ–…â–ˆâ–…
wandb:  valid_error_force â–„â–„â–†â–ƒâ–…â–…â–…â–„â–ƒâ–…â–ˆâ–ƒâ–…â–…â–†â–…â–…â–ƒâ–â–„
wandb:         valid_loss â–ƒâ–ƒâ–„â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–„â–ˆâ–‚â–ƒâ–…â–†â–„â–„â–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3567
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.36384
wandb:   test_error_force 8.80615
wandb:          test_loss 7.67193
wandb: train_error_energy 2.08785
wandb:  train_error_force 1.80551
wandb:         train_loss -2.64386
wandb: valid_error_energy 2.16452
wandb:  valid_error_force 2.00938
wandb:         valid_loss -2.35387
wandb: 
wandb: ğŸš€ View run al_69_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3nmtazya
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_232821-3nmtazya/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 98.5692367553711, Uncertainty Bias: -11.665703773498535
5.531311e-05 0.020845413
-2.2393746 20.019588
(48745, 22, 3)
Found uncertainty sample 0 after 1371 steps.
Found uncertainty sample 1 after 1369 steps.
Found uncertainty sample 2 after 267 steps.
Found uncertainty sample 3 after 1517 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 638 steps.
Found uncertainty sample 7 after 948 steps.
Found uncertainty sample 8 after 180 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3255 steps.
Found uncertainty sample 11 after 752 steps.
Found uncertainty sample 12 after 3943 steps.
Found uncertainty sample 13 after 3727 steps.
Found uncertainty sample 14 after 2666 steps.
Found uncertainty sample 15 after 1783 steps.
Found uncertainty sample 16 after 1441 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1313 steps.
Found uncertainty sample 19 after 79 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 235 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1928 steps.
Found uncertainty sample 24 after 3761 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1314 steps.
Found uncertainty sample 27 after 1851 steps.
Found uncertainty sample 28 after 1324 steps.
Found uncertainty sample 29 after 3648 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2020 steps.
Found uncertainty sample 32 after 68 steps.
Found uncertainty sample 33 after 504 steps.
Found uncertainty sample 34 after 1809 steps.
Found uncertainty sample 35 after 889 steps.
Found uncertainty sample 36 after 152 steps.
Found uncertainty sample 37 after 500 steps.
Found uncertainty sample 38 after 3048 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2091 steps.
Found uncertainty sample 41 after 1965 steps.
Found uncertainty sample 42 after 2230 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1622 steps.
Found uncertainty sample 45 after 362 steps.
Found uncertainty sample 46 after 2823 steps.
Found uncertainty sample 47 after 2 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3937 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 316 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2323 steps.
Found uncertainty sample 55 after 896 steps.
Found uncertainty sample 56 after 461 steps.
Found uncertainty sample 57 after 2586 steps.
Found uncertainty sample 58 after 454 steps.
Found uncertainty sample 59 after 637 steps.
Found uncertainty sample 60 after 2801 steps.
Found uncertainty sample 61 after 949 steps.
Found uncertainty sample 62 after 782 steps.
Found uncertainty sample 63 after 842 steps.
Found uncertainty sample 64 after 63 steps.
Found uncertainty sample 65 after 70 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 335 steps.
Found uncertainty sample 68 after 1109 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1986 steps.
Found uncertainty sample 71 after 2153 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2256 steps.
Found uncertainty sample 74 after 3243 steps.
Found uncertainty sample 75 after 370 steps.
Found uncertainty sample 76 after 3990 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2321 steps.
Found uncertainty sample 79 after 1783 steps.
Found uncertainty sample 80 after 2402 steps.
Found uncertainty sample 81 after 211 steps.
Found uncertainty sample 82 after 3147 steps.
Found uncertainty sample 83 after 572 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 610 steps.
Found uncertainty sample 86 after 2383 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2087 steps.
Found uncertainty sample 89 after 364 steps.
Did not find any uncertainty samples for sample 90.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 219 steps.
Found uncertainty sample 93 after 2818 steps.
Found uncertainty sample 94 after 2188 steps.
Found uncertainty sample 95 after 967 steps.
Found uncertainty sample 96 after 3503 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_235505-hq31sdch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hq31sdch
Training model 33. Added 78 samples to the dataset.
Epoch 0, Batch 100/114, Loss: 0.04461543262004852, Uncertainty: 0.12173710763454437

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9463383042716678, Training Loss Force: 1.8794921665916084, time: 1.775679111480713
Validation Loss Energy: 5.2993993083410365, Validation Loss Force: 4.34699597979133, time: 0.11554384231567383
Test Loss Energy: 14.972484126782364, Test Loss Force: 8.744841897408852, time: 9.830907106399536

Epoch 1, Batch 100/114, Loss: 0.09430490434169769, Uncertainty: 0.121101975440979

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6685375912053426, Training Loss Force: 1.8039306888711268, time: 1.679938554763794
Validation Loss Energy: 2.5736853250277445, Validation Loss Force: 2.0201010297083903, time: 0.11197853088378906
Test Loss Energy: 15.722294309795942, Test Loss Force: 8.78509869763943, time: 9.764265298843384

Epoch 2, Batch 100/114, Loss: 0.1404860019683838, Uncertainty: 0.12022753059864044

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.96545569254956, Training Loss Force: 1.7855367183072324, time: 1.7319526672363281
Validation Loss Energy: 1.5381927077828887, Validation Loss Force: 1.9761301081237381, time: 0.12024116516113281
Test Loss Energy: 13.47888614275601, Test Loss Force: 8.656300824754297, time: 9.952552080154419

Epoch 3, Batch 100/114, Loss: 0.05430912226438522, Uncertainty: 0.12152612954378128

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6817179810150786, Training Loss Force: 1.8583854168462572, time: 1.7594544887542725
Validation Loss Energy: 1.9272495174289999, Validation Loss Force: 2.023045420936518, time: 0.12661027908325195
Test Loss Energy: 15.253359491084318, Test Loss Force: 8.84289183327111, time: 9.775430679321289

Epoch 4, Batch 100/114, Loss: 0.05462357774376869, Uncertainty: 0.12089325487613678

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.691068507171798, Training Loss Force: 1.81513317750923, time: 1.7011175155639648
Validation Loss Energy: 1.918830025906227, Validation Loss Force: 1.933219722569616, time: 0.11239337921142578
Test Loss Energy: 15.236232778310386, Test Loss Force: 8.714495301119888, time: 9.985238790512085

Epoch 5, Batch 100/114, Loss: 0.09693314135074615, Uncertainty: 0.12048430740833282

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.543058345534296, Training Loss Force: 1.802528077365165, time: 1.7687268257141113
Validation Loss Energy: 1.3926600878260647, Validation Loss Force: 2.067477156318667, time: 0.11114692687988281
Test Loss Energy: 13.323174704867332, Test Loss Force: 8.813682122687673, time: 9.85453462600708

Epoch 6, Batch 100/114, Loss: 0.4545411467552185, Uncertainty: 0.12119469046592712

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.2904814076763484, Training Loss Force: 1.8109179431487201, time: 1.7050988674163818
Validation Loss Energy: 6.175714511481856, Validation Loss Force: 5.054588944553346, time: 0.11603021621704102
Test Loss Energy: 15.358969088751493, Test Loss Force: 8.772013129085867, time: 9.867642879486084

Epoch 7, Batch 100/114, Loss: 0.046944353729486465, Uncertainty: 0.12119842320680618

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5194884270109892, Training Loss Force: 1.8186270409898393, time: 1.7323288917541504
Validation Loss Energy: 2.4458070283058047, Validation Loss Force: 2.01887456805262, time: 0.11374330520629883
Test Loss Energy: 12.860548954098991, Test Loss Force: 8.665319312212311, time: 9.921095609664917

Epoch 8, Batch 100/114, Loss: 0.1118139773607254, Uncertainty: 0.12189123034477234

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5433997520256706, Training Loss Force: 1.81665979815033, time: 1.6759979724884033
Validation Loss Energy: 1.5112576458803069, Validation Loss Force: 2.063236941995813, time: 0.11512970924377441
Test Loss Energy: 14.77043270282998, Test Loss Force: 8.631240878965388, time: 9.82478380203247

Epoch 9, Batch 100/114, Loss: 0.10794460028409958, Uncertainty: 0.11989209800958633

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3921937107180855, Training Loss Force: 1.8119620358441186, time: 1.7114462852478027
Validation Loss Energy: 1.273130473838493, Validation Loss Force: 2.0733808576076993, time: 0.12155723571777344
Test Loss Energy: 13.537576138411982, Test Loss Force: 8.639253815876533, time: 10.465235710144043

Epoch 10, Batch 100/114, Loss: 0.044849179685115814, Uncertainty: 0.11894328892230988

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5486350293488897, Training Loss Force: 1.7899246150112664, time: 1.9544799327850342
Validation Loss Energy: 1.5070280454534082, Validation Loss Force: 1.9878970962518163, time: 0.11436080932617188
Test Loss Energy: 14.601299193178539, Test Loss Force: 8.77895131314385, time: 9.7965407371521

Epoch 11, Batch 100/114, Loss: 0.07851895689964294, Uncertainty: 0.12039650231599808

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3315218726777915, Training Loss Force: 1.807576725227359, time: 1.7717883586883545
Validation Loss Energy: 1.358885112210397, Validation Loss Force: 2.1110870569947218, time: 0.11924290657043457
Test Loss Energy: 13.144662977009077, Test Loss Force: 8.709810011200366, time: 9.767281532287598

Epoch 12, Batch 100/114, Loss: 0.14887043833732605, Uncertainty: 0.11962725222110748

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4841119584980584, Training Loss Force: 1.797433042050809, time: 1.7214760780334473
Validation Loss Energy: 2.3633775082900406, Validation Loss Force: 2.0088419870136978, time: 0.11539912223815918
Test Loss Energy: 15.00576830035157, Test Loss Force: 8.67837219619951, time: 10.083373308181763

Epoch 13, Batch 100/114, Loss: 0.14407610893249512, Uncertainty: 0.12047027051448822

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6141589596783692, Training Loss Force: 1.8043248962720393, time: 1.670393466949463
Validation Loss Energy: 3.8651468507471205, Validation Loss Force: 2.05771934900582, time: 0.11181116104125977
Test Loss Energy: 16.92254045784287, Test Loss Force: 8.747968200197047, time: 9.800572872161865

Epoch 14, Batch 100/114, Loss: 0.05137145519256592, Uncertainty: 0.12002735584974289

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5098661390213794, Training Loss Force: 1.7832549836210527, time: 1.7084026336669922
Validation Loss Energy: 1.9097464607672487, Validation Loss Force: 1.8970743967840225, time: 0.11199831962585449
Test Loss Energy: 15.004311810975791, Test Loss Force: 8.694347618556046, time: 9.717691659927368

Epoch 15, Batch 100/114, Loss: 0.0565040297806263, Uncertainty: 0.11939021944999695

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.809159816424118, Training Loss Force: 1.8094766838966545, time: 1.7278196811676025
Validation Loss Energy: 1.684364573746147, Validation Loss Force: 1.9008063316697725, time: 0.1134791374206543
Test Loss Energy: 14.500361250151668, Test Loss Force: 8.722836575927678, time: 10.022518634796143

Epoch 16, Batch 100/114, Loss: 0.13297709822654724, Uncertainty: 0.12060075998306274

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5283075771781187, Training Loss Force: 1.8162658104887064, time: 1.7371940612792969
Validation Loss Energy: 1.868942859337322, Validation Loss Force: 2.178236871770824, time: 0.11243677139282227
Test Loss Energy: 12.975450365017904, Test Loss Force: 8.628467713121335, time: 9.745651483535767

Epoch 17, Batch 100/114, Loss: 0.12039773911237717, Uncertainty: 0.11991585791110992

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9097510455054312, Training Loss Force: 1.790891203217977, time: 1.7109761238098145
Validation Loss Energy: 2.2766958240405897, Validation Loss Force: 2.0857385498684, time: 0.11908888816833496
Test Loss Energy: 13.165996215391035, Test Loss Force: 8.658176477722114, time: 9.970001459121704

Epoch 18, Batch 100/114, Loss: 0.09862379729747772, Uncertainty: 0.12030912190675735

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8132121209383576, Training Loss Force: 1.808373400273202, time: 1.716846227645874
Validation Loss Energy: 0.8119239065232815, Validation Loss Force: 1.9588292350464898, time: 0.11449551582336426
Test Loss Energy: 14.115814115971776, Test Loss Force: 8.697199205908518, time: 9.864464282989502

Epoch 19, Batch 100/114, Loss: 0.09180242568254471, Uncertainty: 0.11863115429878235

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6953896961550186, Training Loss Force: 1.7879206981727749, time: 1.7475216388702393
Validation Loss Energy: 1.4908139091428605, Validation Loss Force: 2.0679531487296123, time: 0.12166166305541992
Test Loss Energy: 13.748920881838808, Test Loss Force: 8.617949899873418, time: 9.815956830978394

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–†â–‚â–…â–…â–‚â–…â–â–„â–‚â–„â–â–…â–ˆâ–…â–„â–â–‚â–ƒâ–ƒ
wandb:   test_error_force â–…â–†â–‚â–ˆâ–„â–‡â–†â–‚â–â–‚â–†â–„â–ƒâ–…â–ƒâ–„â–â–‚â–ƒâ–
wandb:          test_loss â–„â–ˆâ–„â–…â–…â–†â–‡â–‚â–‚â–ƒâ–‡â–„â–…â–ˆâ–†â–†â–â–ƒâ–„â–‚
wandb: train_error_energy â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–â–†â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–‚â–…â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚
wandb: valid_error_energy â–‡â–ƒâ–‚â–‚â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–…â–‚â–‚â–‚â–ƒâ–â–‚
wandb:  valid_error_force â–†â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–â–â–â–‚â–â–â–
wandb:         valid_loss â–†â–â–â–â–â–â–ˆâ–â–â–â–â–â–â–‚â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3637
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.74892
wandb:   test_error_force 8.61795
wandb:          test_loss 7.33076
wandb: train_error_energy 1.69539
wandb:  train_error_force 1.78792
wandb:         train_loss -2.69444
wandb: valid_error_energy 1.49081
wandb:  valid_error_force 2.06795
wandb:         valid_loss -2.31551
wandb: 
wandb: ğŸš€ View run al_69_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hq31sdch
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_235505-hq31sdch/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 69.00206756591797, Uncertainty Bias: -8.093361854553223
1.335144e-05 0.0037822723
-1.4310678 10.22672
(48745, 22, 3)
Found uncertainty sample 0 after 1954 steps.
Found uncertainty sample 1 after 3932 steps.
Found uncertainty sample 2 after 678 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1113 steps.
Found uncertainty sample 10 after 3257 steps.
Found uncertainty sample 11 after 637 steps.
Found uncertainty sample 12 after 1357 steps.
Found uncertainty sample 13 after 37 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1823 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3585 steps.
Found uncertainty sample 19 after 150 steps.
Found uncertainty sample 20 after 2544 steps.
Found uncertainty sample 21 after 672 steps.
Found uncertainty sample 22 after 516 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 52 steps.
Found uncertainty sample 25 after 3993 steps.
Found uncertainty sample 26 after 832 steps.
Found uncertainty sample 27 after 2037 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1445 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 86 steps.
Found uncertainty sample 32 after 501 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 183 steps.
Found uncertainty sample 35 after 2208 steps.
Found uncertainty sample 36 after 3047 steps.
Found uncertainty sample 37 after 2966 steps.
Found uncertainty sample 38 after 1509 steps.
Found uncertainty sample 39 after 2351 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2277 steps.
Found uncertainty sample 42 after 1314 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1674 steps.
Found uncertainty sample 47 after 1072 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1645 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 525 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 5 steps.
Found uncertainty sample 58 after 2922 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1613 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 97 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3053 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3752 steps.
Found uncertainty sample 70 after 1319 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1158 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 101 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2136 steps.
Found uncertainty sample 78 after 179 steps.
Found uncertainty sample 79 after 1286 steps.
Found uncertainty sample 80 after 34 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3812 steps.
Found uncertainty sample 83 after 984 steps.
Found uncertainty sample 84 after 100 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 899 steps.
Found uncertainty sample 89 after 3751 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 235 steps.
Found uncertainty sample 92 after 211 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 324 steps.
Found uncertainty sample 95 after 807 steps.
Found uncertainty sample 96 after 2203 steps.
Found uncertainty sample 97 after 2187 steps.
Found uncertainty sample 98 after 1134 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_002622-lytvonds
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lytvonds
Training model 34. Added 58 samples to the dataset.
Epoch 0, Batch 100/116, Loss: 0.1278320550918579, Uncertainty: 0.12207593768835068

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.043604019912335, Training Loss Force: 1.9610454732131324, time: 1.794595718383789
Validation Loss Energy: 0.9511135360776825, Validation Loss Force: 2.065876313605544, time: 0.11540079116821289
Test Loss Energy: 13.809026973987999, Test Loss Force: 8.716495681452026, time: 9.638871669769287

Epoch 1, Batch 100/116, Loss: 0.0606515109539032, Uncertainty: 0.12086623162031174

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6187409547313383, Training Loss Force: 1.8188758247274017, time: 1.7481014728546143
Validation Loss Energy: 1.3022689582746032, Validation Loss Force: 1.992763159320825, time: 0.115753173828125
Test Loss Energy: 13.440544036039634, Test Loss Force: 8.649063923625112, time: 9.72173523902893

Epoch 2, Batch 100/116, Loss: 0.17351391911506653, Uncertainty: 0.12098442018032074

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8449051597235255, Training Loss Force: 1.7994476269370994, time: 1.8202769756317139
Validation Loss Energy: 0.8459910797256928, Validation Loss Force: 1.959405317238529, time: 0.119720458984375
Test Loss Energy: 13.856353978929755, Test Loss Force: 8.61790130437248, time: 9.889569759368896

Epoch 3, Batch 100/116, Loss: 0.08197816461324692, Uncertainty: 0.12261137366294861

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5795692987511674, Training Loss Force: 1.8404932134215088, time: 1.7495465278625488
Validation Loss Energy: 1.0118677734213983, Validation Loss Force: 2.1849342401189915, time: 0.11459851264953613
Test Loss Energy: 13.545109364376303, Test Loss Force: 8.786536077106096, time: 9.758646011352539

Epoch 4, Batch 100/116, Loss: 0.04301392287015915, Uncertainty: 0.12180106341838837

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.741303566110806, Training Loss Force: 1.8256080123234095, time: 1.7494597434997559
Validation Loss Energy: 2.513301609142852, Validation Loss Force: 1.910726910128293, time: 0.11412882804870605
Test Loss Energy: 12.883911941824204, Test Loss Force: 8.682050825723856, time: 9.942927598953247

Epoch 5, Batch 100/116, Loss: 0.059001147747039795, Uncertainty: 0.12077727913856506

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.412109922594827, Training Loss Force: 1.812336559790943, time: 1.8325364589691162
Validation Loss Energy: 1.4976810812705599, Validation Loss Force: 2.4601753487311844, time: 0.11764240264892578
Test Loss Energy: 13.324652677735369, Test Loss Force: 8.636129989262505, time: 9.752935886383057

Epoch 6, Batch 100/116, Loss: 0.498364120721817, Uncertainty: 0.12124498188495636

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5424009164553216, Training Loss Force: 1.8093552253200618, time: 1.75618577003479
Validation Loss Energy: 1.4305301345929653, Validation Loss Force: 1.9520586827723605, time: 0.11446738243103027
Test Loss Energy: 14.502674747603645, Test Loss Force: 8.6250166631222, time: 9.770942687988281

Epoch 7, Batch 100/116, Loss: 0.04796673357486725, Uncertainty: 0.11935962736606598

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.2960085495718403, Training Loss Force: 1.76698739009612, time: 1.726412296295166
Validation Loss Energy: 3.4051882512160234, Validation Loss Force: 3.511311772380818, time: 0.1141970157623291
Test Loss Energy: 14.137204115167222, Test Loss Force: 8.656663437378114, time: 9.917859315872192

Epoch 8, Batch 100/116, Loss: 0.08685599267482758, Uncertainty: 0.1201230138540268

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6116934717037648, Training Loss Force: 1.7831961394769564, time: 1.7098190784454346
Validation Loss Energy: 2.067714929854994, Validation Loss Force: 1.993954476363063, time: 0.11351656913757324
Test Loss Energy: 14.770805845023046, Test Loss Force: 8.595624326533276, time: 9.724704504013062

Epoch 9, Batch 100/116, Loss: 0.037172555923461914, Uncertainty: 0.12073122709989548

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1106272487275772, Training Loss Force: 1.810824793694145, time: 1.721928358078003
Validation Loss Energy: 0.851291421852309, Validation Loss Force: 2.020813051414019, time: 0.11342573165893555
Test Loss Energy: 13.7150029102738, Test Loss Force: 8.698310593082319, time: 9.731544256210327

Epoch 10, Batch 100/116, Loss: 0.1661238670349121, Uncertainty: 0.12082146108150482

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.474616321532854, Training Loss Force: 1.8094602723689954, time: 1.8194599151611328
Validation Loss Energy: 5.776787001265912, Validation Loss Force: 2.001801448400131, time: 0.16288113594055176
Test Loss Energy: 18.562193970975784, Test Loss Force: 8.732417546632833, time: 9.924071311950684

Epoch 11, Batch 100/116, Loss: 0.1733737736940384, Uncertainty: 0.12202243506908417

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.768445813495537, Training Loss Force: 1.8340700061393387, time: 1.7017862796783447
Validation Loss Energy: 1.7091570760150876, Validation Loss Force: 1.950389925969729, time: 0.11358499526977539
Test Loss Energy: 13.16965102980903, Test Loss Force: 8.58883759480035, time: 9.765798330307007

Epoch 12, Batch 100/116, Loss: 0.0844184160232544, Uncertainty: 0.12048935890197754

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9527882879821976, Training Loss Force: 1.7894885555097568, time: 1.720268964767456
Validation Loss Energy: 3.6033429344150867, Validation Loss Force: 1.9738632619951446, time: 0.11411690711975098
Test Loss Energy: 16.43884951571199, Test Loss Force: 8.677877763441302, time: 10.578498363494873

Epoch 13, Batch 100/116, Loss: 0.15951316058635712, Uncertainty: 0.1211216002702713

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.174407097789959, Training Loss Force: 1.817333301495041, time: 1.712998628616333
Validation Loss Energy: 1.0903807843852011, Validation Loss Force: 2.0433434207179544, time: 0.11421918869018555
Test Loss Energy: 12.90699695918042, Test Loss Force: 8.657319856693853, time: 9.694091796875

Epoch 14, Batch 100/116, Loss: 0.04162484407424927, Uncertainty: 0.12063395977020264

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2699130187337884, Training Loss Force: 1.8120517409990007, time: 1.776174545288086
Validation Loss Energy: 1.6463567690009653, Validation Loss Force: 2.079658346169696, time: 0.11417508125305176
Test Loss Energy: 14.161755773746979, Test Loss Force: 8.680396363658629, time: 9.806828498840332

Epoch 15, Batch 100/116, Loss: 0.21828919649124146, Uncertainty: 0.11953631043434143

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4761713435107007, Training Loss Force: 1.7954303060289531, time: 1.7432892322540283
Validation Loss Energy: 1.0016613991140793, Validation Loss Force: 2.119263319587093, time: 0.11469125747680664
Test Loss Energy: 14.006765830523387, Test Loss Force: 8.553894398528751, time: 9.986813306808472

Epoch 16, Batch 100/116, Loss: 0.12914156913757324, Uncertainty: 0.11946317553520203

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4191196192921938, Training Loss Force: 1.8170162762985265, time: 1.7533481121063232
Validation Loss Energy: 1.6783722501370357, Validation Loss Force: 2.149741901166445, time: 0.11652207374572754
Test Loss Energy: 12.976774899025672, Test Loss Force: 8.804044218629583, time: 9.84517216682434

Epoch 17, Batch 100/116, Loss: 0.060045648366212845, Uncertainty: 0.12027043104171753

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.6279827285290573, Training Loss Force: 1.8122409224329867, time: 1.7291135787963867
Validation Loss Energy: 0.8622979577355195, Validation Loss Force: 2.051395137034703, time: 0.12517333030700684
Test Loss Energy: 13.573456554947825, Test Loss Force: 8.619285672261118, time: 9.93789792060852

Epoch 18, Batch 100/116, Loss: 0.14471834897994995, Uncertainty: 0.11914981156587601

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6023239461135812, Training Loss Force: 1.7939132265856386, time: 1.7990241050720215
Validation Loss Energy: 2.1394839418403198, Validation Loss Force: 1.9462642749224548, time: 0.11438655853271484
Test Loss Energy: 15.237022822429825, Test Loss Force: 8.654585414296665, time: 9.766611337661743

Epoch 19, Batch 100/116, Loss: 0.16145403683185577, Uncertainty: 0.11865679174661636

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.76628824281018, Training Loss Force: 1.7854616003219266, time: 1.8271911144256592
Validation Loss Energy: 1.870697009757417, Validation Loss Force: 1.9317603489872048, time: 0.1130533218383789
Test Loss Energy: 15.055737495047294, Test Loss Force: 8.590013082708806, time: 9.796486377716064

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–â–…â–â–ƒâ–‚â–â–‚â–„â–„
wandb:   test_error_force â–†â–„â–ƒâ–ˆâ–…â–ƒâ–ƒâ–„â–‚â–…â–†â–‚â–„â–„â–…â–â–ˆâ–ƒâ–„â–‚
wandb:          test_loss â–‚â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–†â–„â–„â–ˆâ–â–†â–ƒâ–„â–ƒâ–…â–„â–†â–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–„â–‚â–ƒâ–„â–…â–â–‚â–‚â–†â–‚â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–„â–‚â–‚
wandb: valid_error_energy â–â–‚â–â–â–ƒâ–‚â–‚â–…â–ƒâ–â–ˆâ–‚â–…â–â–‚â–â–‚â–â–ƒâ–‚
wandb:  valid_error_force â–‚â–â–â–‚â–â–ƒâ–â–ˆâ–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–
wandb:         valid_loss â–â–â–â–‚â–â–ƒâ–â–ˆâ–â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3689
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.05574
wandb:   test_error_force 8.59001
wandb:          test_loss 7.43924
wandb: train_error_energy 1.76629
wandb:  train_error_force 1.78546
wandb:         train_loss -2.69306
wandb: valid_error_energy 1.8707
wandb:  valid_error_force 1.93176
wandb:         valid_loss -2.47986
wandb: 
wandb: ğŸš€ View run al_69_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lytvonds
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_002622-lytvonds/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 59.55712127685547, Uncertainty Bias: -6.935791015625
1.5258789e-05 0.0043144226
-0.85248435 8.070656
(48745, 22, 3)
Found uncertainty sample 0 after 3258 steps.
Found uncertainty sample 1 after 3362 steps.
Found uncertainty sample 2 after 2121 steps.
Found uncertainty sample 3 after 2776 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 153 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3278 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3490 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3610 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3467 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 669 steps.
Found uncertainty sample 22 after 385 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 123 steps.
Found uncertainty sample 25 after 364 steps.
Found uncertainty sample 26 after 971 steps.
Found uncertainty sample 27 after 1219 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2382 steps.
Found uncertainty sample 30 after 3327 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 3280 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 167 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1645 steps.
Found uncertainty sample 43 after 2039 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1506 steps.
Found uncertainty sample 46 after 852 steps.
Found uncertainty sample 47 after 467 steps.
Found uncertainty sample 48 after 3925 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 128 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1324 steps.
Found uncertainty sample 54 after 1399 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2962 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2258 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 638 steps.
Found uncertainty sample 64 after 1641 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1696 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3022 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1789 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1700 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 415 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3221 steps.
Found uncertainty sample 79 after 2917 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 424 steps.
Found uncertainty sample 82 after 589 steps.
Found uncertainty sample 83 after 1562 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 236 steps.
Found uncertainty sample 87 after 2494 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 49 steps.
Found uncertainty sample 91 after 3436 steps.
Found uncertainty sample 92 after 2979 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2342 steps.
Found uncertainty sample 95 after 896 steps.
Found uncertainty sample 96 after 21 steps.
Found uncertainty sample 97 after 501 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2460 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_010037-dgz4dcul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/dgz4dcul
Training model 35. Added 53 samples to the dataset.
Epoch 0, Batch 100/117, Loss: 0.05122463405132294, Uncertainty: 0.12163437902927399

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5048219036960786, Training Loss Force: 1.945499146625522, time: 1.7572705745697021
Validation Loss Energy: 2.4071502543348164, Validation Loss Force: 2.039044161959905, time: 0.12167096138000488
Test Loss Energy: 12.87080848512732, Test Loss Force: 8.603929978940945, time: 9.765552043914795

Epoch 1, Batch 100/117, Loss: 0.08870525658130646, Uncertainty: 0.1193360835313797

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4592029022282684, Training Loss Force: 1.7956254004017493, time: 1.7394168376922607
Validation Loss Energy: 0.8917955703924871, Validation Loss Force: 1.9937190037412442, time: 0.11323213577270508
Test Loss Energy: 13.268999987157649, Test Loss Force: 8.591657374273359, time: 10.502151727676392

Epoch 2, Batch 100/117, Loss: 0.06268031895160675, Uncertainty: 0.12004566937685013

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6850184578699823, Training Loss Force: 1.7869068175886955, time: 1.804487705230713
Validation Loss Energy: 1.236850804334857, Validation Loss Force: 2.0108142418622283, time: 0.12294983863830566
Test Loss Energy: 14.425603518873972, Test Loss Force: 8.661745670607369, time: 9.950096130371094

Epoch 3, Batch 100/117, Loss: 0.10949265956878662, Uncertainty: 0.1194969043135643

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4726673491167308, Training Loss Force: 1.804871497840436, time: 1.8801782131195068
Validation Loss Energy: 0.9827761237289813, Validation Loss Force: 2.0421216722257727, time: 0.12924623489379883
Test Loss Energy: 13.361826692423188, Test Loss Force: 8.571706130196892, time: 9.711047172546387

Epoch 4, Batch 100/117, Loss: 0.05923416465520859, Uncertainty: 0.12228960543870926

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8544280387907404, Training Loss Force: 1.8277713275942316, time: 1.7344951629638672
Validation Loss Energy: 2.1008524408173943, Validation Loss Force: 1.9373075569736065, time: 0.11679196357727051
Test Loss Energy: 12.881896914292332, Test Loss Force: 8.55960440486299, time: 9.827053308486938

Epoch 5, Batch 100/117, Loss: 0.05603615194559097, Uncertainty: 0.11916962265968323

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2892323420785037, Training Loss Force: 1.794377992621021, time: 1.798546314239502
Validation Loss Energy: 2.0924807489379473, Validation Loss Force: 1.9634354432222005, time: 0.11355781555175781
Test Loss Energy: 13.047391543776497, Test Loss Force: 8.478520235117019, time: 10.173311471939087

Epoch 6, Batch 100/117, Loss: 0.15108689665794373, Uncertainty: 0.120020791888237

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.80601152390133, Training Loss Force: 1.799470615836546, time: 1.8816897869110107
Validation Loss Energy: 1.8592923043297631, Validation Loss Force: 1.977018001343125, time: 0.12350988388061523
Test Loss Energy: 13.074872511732917, Test Loss Force: 8.551112568406726, time: 10.839679956436157

Epoch 7, Batch 100/117, Loss: 0.04227128252387047, Uncertainty: 0.11990673840045929

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3031292762040534, Training Loss Force: 1.8176425829831724, time: 1.8899600505828857
Validation Loss Energy: 1.1117817386694668, Validation Loss Force: 2.0873356072060427, time: 0.13152813911437988
Test Loss Energy: 13.421071705497972, Test Loss Force: 8.519991689709597, time: 10.948487281799316

Epoch 8, Batch 100/117, Loss: 0.4191916584968567, Uncertainty: 0.12125236541032791

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2484527258743248, Training Loss Force: 1.7977125144664772, time: 1.8100471496582031
Validation Loss Energy: 1.6571874704819418, Validation Loss Force: 1.9396869252439426, time: 0.12455630302429199
Test Loss Energy: 12.935366719776367, Test Loss Force: 8.63881079054586, time: 11.172828674316406

Epoch 9, Batch 100/117, Loss: 0.09349161386489868, Uncertainty: 0.1195513978600502

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6373925730799663, Training Loss Force: 1.8003232654783359, time: 1.880850076675415
Validation Loss Energy: 1.736925588530877, Validation Loss Force: 1.9491077228044282, time: 0.12592720985412598
Test Loss Energy: 14.545079057678887, Test Loss Force: 8.576072128882453, time: 11.29786992073059

Epoch 10, Batch 100/117, Loss: 0.0711018294095993, Uncertainty: 0.12017277628183365

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4101601022943986, Training Loss Force: 1.7974817730882209, time: 1.8962063789367676
Validation Loss Energy: 0.8436231789163723, Validation Loss Force: 2.1770463340705972, time: 0.1330571174621582
Test Loss Energy: 13.901405086028412, Test Loss Force: 8.727243503767035, time: 10.903589010238647

Epoch 11, Batch 100/117, Loss: 0.08199276775121689, Uncertainty: 0.11892661452293396

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.651916371284913, Training Loss Force: 1.8025769512894587, time: 1.8916473388671875
Validation Loss Energy: 1.3396875804596597, Validation Loss Force: 2.0001123544821717, time: 0.11855101585388184
Test Loss Energy: 14.507459839932828, Test Loss Force: 8.573901489425982, time: 10.905478715896606

Epoch 12, Batch 100/117, Loss: 0.09883973747491837, Uncertainty: 0.1205129325389862

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9453176774568453, Training Loss Force: 1.8025288947201952, time: 1.9118969440460205
Validation Loss Energy: 3.2076435330307063, Validation Loss Force: 1.9763946761806246, time: 0.13285207748413086
Test Loss Energy: 12.371245597673367, Test Loss Force: 8.54599909154862, time: 11.227278470993042

Epoch 13, Batch 100/117, Loss: 0.3509765565395355, Uncertainty: 0.11893575638532639

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9080138902227581, Training Loss Force: 1.8055013831785438, time: 1.8408677577972412
Validation Loss Energy: 2.382610407323455, Validation Loss Force: 2.249547445096209, time: 0.12250208854675293
Test Loss Energy: 14.741772744880732, Test Loss Force: 8.533224112645222, time: 10.985002040863037

Epoch 14, Batch 100/117, Loss: 0.08982765674591064, Uncertainty: 0.12011072039604187

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6642282898108842, Training Loss Force: 1.7746522725277476, time: 1.9634625911712646
Validation Loss Energy: 0.8131278414837887, Validation Loss Force: 1.9758097985573209, time: 0.13550949096679688
Test Loss Energy: 13.605296163015728, Test Loss Force: 8.525092431291524, time: 11.146681785583496

Epoch 15, Batch 100/117, Loss: 0.08280204981565475, Uncertainty: 0.11993464827537537

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5197498169929413, Training Loss Force: 1.8096587055813051, time: 1.9650893211364746
Validation Loss Energy: 1.0673902692912056, Validation Loss Force: 1.9764515681474093, time: 0.1243438720703125
Test Loss Energy: 14.045907363774313, Test Loss Force: 8.567279234414437, time: 11.064653873443604

Epoch 16, Batch 100/117, Loss: 0.059699513018131256, Uncertainty: 0.11915978789329529

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4162063256346993, Training Loss Force: 1.7959349038535461, time: 1.9159560203552246
Validation Loss Energy: 2.5337577782409464, Validation Loss Force: 1.9583121972896451, time: 0.14128661155700684
Test Loss Energy: 15.551136040455404, Test Loss Force: 8.543514523570602, time: 11.130374431610107

Epoch 17, Batch 100/117, Loss: 0.10270103812217712, Uncertainty: 0.11945540457963943

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5389085905144126, Training Loss Force: 1.7876100933450925, time: 1.9416489601135254
Validation Loss Energy: 2.814998911103547, Validation Loss Force: 3.107823701164078, time: 0.13144373893737793
Test Loss Energy: 13.826105413023742, Test Loss Force: 8.441509358804089, time: 11.139088153839111

Epoch 18, Batch 100/117, Loss: 0.03479599952697754, Uncertainty: 0.11967050284147263

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3111888732481496, Training Loss Force: 1.792670859647509, time: 1.8259503841400146
Validation Loss Energy: 2.667220542919706, Validation Loss Force: 1.9364576659551247, time: 0.11989688873291016
Test Loss Energy: 15.524813161903078, Test Loss Force: 8.488834754932125, time: 11.777507543563843

Epoch 19, Batch 100/117, Loss: 0.05575127154588699, Uncertainty: 0.12094731628894806

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6247753366160373, Training Loss Force: 1.7972829961513355, time: 1.9147045612335205
Validation Loss Energy: 1.894643035268113, Validation Loss Force: 1.9824622990725838, time: 0.1217491626739502
Test Loss Energy: 12.971837617581386, Test Loss Force: 8.477543797103722, time: 11.091231107711792

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–†â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–†â–„â–†â–â–†â–„â–…â–ˆâ–„â–ˆâ–‚
wandb:   test_error_force â–…â–…â–†â–„â–„â–‚â–„â–ƒâ–†â–„â–ˆâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–â–‚â–‚
wandb:          test_loss â–‚â–„â–ˆâ–…â–â–ƒâ–„â–ƒâ–†â–…â–ˆâ–†â–‚â–…â–…â–…â–†â–ƒâ–†â–‚
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–„â–â–„â–â–â–ƒâ–‚â–ƒâ–…â–…â–ƒâ–ƒâ–‚â–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–â–‚â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–‚
wandb: valid_error_energy â–†â–â–‚â–â–…â–…â–„â–‚â–ƒâ–„â–â–ƒâ–ˆâ–†â–â–‚â–†â–‡â–†â–„
wandb:  valid_error_force â–‚â–â–â–‚â–â–â–â–‚â–â–â–‚â–â–â–ƒâ–â–â–â–ˆâ–â–
wandb:         valid_loss â–‚â–â–â–â–â–â–â–‚â–â–â–‚â–â–‚â–ƒâ–â–â–â–ˆâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3736
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.97184
wandb:   test_error_force 8.47754
wandb:          test_loss 7.10663
wandb: train_error_energy 1.62478
wandb:  train_error_force 1.79728
wandb:         train_loss -2.68621
wandb: valid_error_energy 1.89464
wandb:  valid_error_force 1.98246
wandb:         valid_loss -2.40905
wandb: 
wandb: ğŸš€ View run al_69_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/dgz4dcul
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_010037-dgz4dcul/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 68.35397338867188, Uncertainty Bias: -8.040947914123535
6.1035156e-05 0.015956879
-1.073935 9.028838
(48745, 22, 3)
Found uncertainty sample 0 after 686 steps.
Found uncertainty sample 1 after 334 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1110 steps.
Found uncertainty sample 6 after 2115 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3042 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1001 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 271 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1670 steps.
Found uncertainty sample 16 after 967 steps.
Found uncertainty sample 17 after 1314 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 463 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 566 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1009 steps.
Found uncertainty sample 26 after 28 steps.
Found uncertainty sample 27 after 547 steps.
Found uncertainty sample 28 after 980 steps.
Found uncertainty sample 29 after 2124 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2632 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2983 steps.
Found uncertainty sample 35 after 389 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 705 steps.
Found uncertainty sample 38 after 3376 steps.
Found uncertainty sample 39 after 2419 steps.
Found uncertainty sample 40 after 1219 steps.
Found uncertainty sample 41 after 1849 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 677 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1604 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3859 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1535 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1336 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1715 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1753 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 926 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1039 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1292 steps.
Found uncertainty sample 70 after 3012 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1429 steps.
Found uncertainty sample 74 after 1884 steps.
Found uncertainty sample 75 after 762 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2649 steps.
Found uncertainty sample 78 after 1434 steps.
Found uncertainty sample 79 after 656 steps.
Found uncertainty sample 80 after 2824 steps.
Found uncertainty sample 81 after 2101 steps.
Found uncertainty sample 82 after 215 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 149 steps.
Found uncertainty sample 86 after 3070 steps.
Found uncertainty sample 87 after 3531 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1408 steps.
Found uncertainty sample 90 after 835 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1672 steps.
Found uncertainty sample 96 after 3024 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1358 steps.
Found uncertainty sample 99 after 1720 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_013356-qq1q3tlt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_36
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qq1q3tlt
Training model 36. Added 54 samples to the dataset.
Epoch 0, Batch 100/119, Loss: 0.35372161865234375, Uncertainty: 0.12271618843078613

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7028257926443207, Training Loss Force: 1.9963056224106681, time: 1.8408288955688477
Validation Loss Energy: 2.8587737539494475, Validation Loss Force: 1.967554636864243, time: 0.11525249481201172
Test Loss Energy: 15.450308741843722, Test Loss Force: 8.5241005533297, time: 9.639152765274048

Epoch 1, Batch 100/119, Loss: 0.12335672974586487, Uncertainty: 0.1212104856967926

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.611769175279489, Training Loss Force: 1.79660688056117, time: 1.8139419555664062
Validation Loss Energy: 1.8669736476337855, Validation Loss Force: 2.012012053421223, time: 0.11915111541748047
Test Loss Energy: 12.938546924819175, Test Loss Force: 8.649238328359303, time: 9.638777017593384

Epoch 2, Batch 100/119, Loss: 0.07088562846183777, Uncertainty: 0.12089629471302032

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6505044042603383, Training Loss Force: 1.8278433967271062, time: 1.747420072555542
Validation Loss Energy: 1.7851300443640055, Validation Loss Force: 1.9252413386249259, time: 0.1189420223236084
Test Loss Energy: 14.894884437718403, Test Loss Force: 8.557729082984372, time: 9.838263988494873

Epoch 3, Batch 100/119, Loss: 0.05693496763706207, Uncertainty: 0.12108375877141953

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.658591533391552, Training Loss Force: 1.8232469601093073, time: 1.7772536277770996
Validation Loss Energy: 2.5610728250410535, Validation Loss Force: 1.9886777000543905, time: 0.1253345012664795
Test Loss Energy: 12.747781315154503, Test Loss Force: 8.406590569868822, time: 9.746941804885864

Epoch 4, Batch 100/119, Loss: 0.06389357149600983, Uncertainty: 0.12072548270225525

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.3234555447605527, Training Loss Force: 1.8105468494814025, time: 1.7777845859527588
Validation Loss Energy: 1.269138943840116, Validation Loss Force: 1.9804646970529414, time: 0.11697053909301758
Test Loss Energy: 14.13002945414465, Test Loss Force: 8.468025565470594, time: 9.879901647567749

Epoch 5, Batch 100/119, Loss: 0.16091808676719666, Uncertainty: 0.12089492380619049

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.395080793968432, Training Loss Force: 1.8102083381156826, time: 1.8591368198394775
Validation Loss Energy: 1.1122802392199127, Validation Loss Force: 1.964760955536384, time: 0.11733174324035645
Test Loss Energy: 14.294492083251667, Test Loss Force: 8.489903142478815, time: 9.79880976676941

Epoch 6, Batch 100/119, Loss: 0.15421044826507568, Uncertainty: 0.12024703621864319

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7150154173536905, Training Loss Force: 1.7962699896280587, time: 1.821747064590454
Validation Loss Energy: 1.0583721503253682, Validation Loss Force: 2.0819798204620903, time: 0.11367368698120117
Test Loss Energy: 14.21163254326004, Test Loss Force: 8.482241701055488, time: 9.745375871658325

Epoch 7, Batch 100/119, Loss: 0.10326728969812393, Uncertainty: 0.12076017260551453

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3848893006027125, Training Loss Force: 1.810380967516779, time: 1.7716779708862305
Validation Loss Energy: 2.10998399115732, Validation Loss Force: 1.9413916060021166, time: 0.11808443069458008
Test Loss Energy: 13.029255610495108, Test Loss Force: 8.494180157444111, time: 10.576964616775513

Epoch 8, Batch 100/119, Loss: 0.35987383127212524, Uncertainty: 0.12029886245727539

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8500654996220591, Training Loss Force: 1.7969682024161622, time: 1.7756080627441406
Validation Loss Energy: 1.1739893004171291, Validation Loss Force: 1.9939752959282073, time: 0.11568689346313477
Test Loss Energy: 13.375979776499769, Test Loss Force: 8.484151610097571, time: 9.659493923187256

Epoch 9, Batch 100/119, Loss: 0.02784915268421173, Uncertainty: 0.11961282044649124

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3860328947195657, Training Loss Force: 1.7881381432930694, time: 1.7743926048278809
Validation Loss Energy: 1.9912959552067824, Validation Loss Force: 1.9241695206910023, time: 0.11443567276000977
Test Loss Energy: 12.65981760610823, Test Loss Force: 8.550388550935189, time: 9.657520771026611

Epoch 10, Batch 100/119, Loss: 0.07640416920185089, Uncertainty: 0.1197589561343193

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4808475880797902, Training Loss Force: 1.8222444212828914, time: 1.9713082313537598
Validation Loss Energy: 1.2370326879155555, Validation Loss Force: 2.079367317595968, time: 0.11417841911315918
Test Loss Energy: 14.113525440883434, Test Loss Force: 8.566494940055357, time: 9.685831785202026

Epoch 11, Batch 100/119, Loss: 0.18501949310302734, Uncertainty: 0.12039327621459961

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.680445358359664, Training Loss Force: 1.8183863864272825, time: 1.827862024307251
Validation Loss Energy: 2.1722737178198295, Validation Loss Force: 2.236080897600313, time: 0.1212759017944336
Test Loss Energy: 12.80627146816652, Test Loss Force: 8.47088686632738, time: 9.70680022239685

Epoch 12, Batch 100/119, Loss: 0.13556039333343506, Uncertainty: 0.12021157145500183

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6703150283724328, Training Loss Force: 1.8127403286213057, time: 1.8007497787475586
Validation Loss Energy: 1.6675149025815967, Validation Loss Force: 1.9893468208379037, time: 0.11494588851928711
Test Loss Energy: 12.777598126752379, Test Loss Force: 8.457618065548669, time: 9.87044882774353

Epoch 13, Batch 100/119, Loss: 0.08876035362482071, Uncertainty: 0.11964397132396698

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3716068208098726, Training Loss Force: 1.7798147023206095, time: 1.790329933166504
Validation Loss Energy: 2.1650529285326345, Validation Loss Force: 1.9042947778444503, time: 0.11536765098571777
Test Loss Energy: 14.89762863092573, Test Loss Force: 8.425929075087975, time: 9.750808954238892

Epoch 14, Batch 100/119, Loss: 0.12897038459777832, Uncertainty: 0.11882574111223221

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.499717604391161, Training Loss Force: 1.787119824896001, time: 1.7598435878753662
Validation Loss Energy: 1.6582245149175758, Validation Loss Force: 1.953541251057472, time: 0.11480021476745605
Test Loss Energy: 12.742872190282007, Test Loss Force: 8.444464054795004, time: 9.671969652175903

Epoch 15, Batch 100/119, Loss: 0.1485428512096405, Uncertainty: 0.11908550560474396

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9302878310642302, Training Loss Force: 1.791835039598213, time: 1.7927186489105225
Validation Loss Energy: 3.3185638671601256, Validation Loss Force: 1.9940666273895618, time: 0.1172022819519043
Test Loss Energy: 12.35578152160367, Test Loss Force: 8.482743259226368, time: 9.84515643119812

Epoch 16, Batch 100/119, Loss: 0.15427345037460327, Uncertainty: 0.11868619918823242

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7452178472467144, Training Loss Force: 1.7773064157875966, time: 1.7664568424224854
Validation Loss Energy: 0.9431179880529937, Validation Loss Force: 2.0436854776376236, time: 0.12511277198791504
Test Loss Energy: 13.65164402527184, Test Loss Force: 8.4564719746307, time: 9.757530212402344

Epoch 17, Batch 100/119, Loss: 0.18012894690036774, Uncertainty: 0.11924254894256592

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7081469798477567, Training Loss Force: 1.8169330847892293, time: 1.7784092426300049
Validation Loss Energy: 2.6053538505229343, Validation Loss Force: 1.9300203009463524, time: 0.11444997787475586
Test Loss Energy: 12.5354782363662, Test Loss Force: 8.484964555330633, time: 9.883398294448853

Epoch 18, Batch 100/119, Loss: 0.10691133886575699, Uncertainty: 0.12047120928764343

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8443618963434212, Training Loss Force: 1.798648242057772, time: 1.7564036846160889
Validation Loss Energy: 2.214837444625267, Validation Loss Force: 2.088695521903272, time: 0.11445450782775879
Test Loss Energy: 12.500905085904153, Test Loss Force: 8.446447740770234, time: 9.748204946517944

Epoch 19, Batch 100/119, Loss: 0.19894012808799744, Uncertainty: 0.11923062801361084

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.951198308839773, Training Loss Force: 1.7735458557539954, time: 1.8212432861328125
Validation Loss Energy: 1.7294733346664903, Validation Loss Force: 1.965669519874818, time: 0.11668944358825684
Test Loss Energy: 12.940265580883624, Test Loss Force: 8.394262542734232, time: 9.641549825668335

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–‡â–‚â–…â–…â–…â–ƒâ–ƒâ–‚â–…â–‚â–‚â–‡â–‚â–â–„â–â–â–‚
wandb:   test_error_force â–…â–ˆâ–…â–â–ƒâ–„â–ƒâ–„â–ƒâ–…â–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–
wandb:          test_loss â–„â–ˆâ–‡â–â–†â–†â–‡â–„â–…â–‡â–‡â–‚â–ƒâ–ˆâ–…â–…â–ˆâ–…â–ƒâ–„
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–†â–â–ƒâ–â–„â–â–‚â–ƒâ–ƒâ–â–‚â–„â–ƒâ–ƒâ–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–‡â–„â–ƒâ–†â–‚â–â–â–„â–‚â–„â–‚â–…â–ƒâ–…â–ƒâ–ˆâ–â–†â–…â–ƒ
wandb:  valid_error_force â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–…â–‚â–ƒâ–â–…â–ˆâ–ƒâ–â–‚â–ƒâ–„â–‚â–…â–‚
wandb:         valid_loss â–ƒâ–ƒâ–â–ƒâ–‚â–â–„â–‚â–‚â–â–„â–ˆâ–‚â–â–‚â–„â–ƒâ–‚â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3784
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.94027
wandb:   test_error_force 8.39426
wandb:          test_loss 7.09095
wandb: train_error_energy 1.9512
wandb:  train_error_force 1.77355
wandb:         train_loss -2.69762
wandb: valid_error_energy 1.72947
wandb:  valid_error_force 1.96567
wandb:         valid_loss -2.44101
wandb: 
wandb: ğŸš€ View run al_69_36 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qq1q3tlt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_013356-qq1q3tlt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 60.66166687011719, Uncertainty Bias: -7.0481109619140625
6.1035156e-05 0.033483505
-0.8282081 8.005074
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3507 steps.
Found uncertainty sample 2 after 3728 steps.
Found uncertainty sample 3 after 3287 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1582 steps.
Found uncertainty sample 7 after 862 steps.
Found uncertainty sample 8 after 2267 steps.
Found uncertainty sample 9 after 1806 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 377 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3797 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 29 steps.
Found uncertainty sample 18 after 2680 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 832 steps.
Found uncertainty sample 21 after 1032 steps.
Found uncertainty sample 22 after 1575 steps.
Found uncertainty sample 23 after 1083 steps.
Found uncertainty sample 24 after 795 steps.
Found uncertainty sample 25 after 51 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1233 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 133 steps.
Found uncertainty sample 32 after 1630 steps.
Found uncertainty sample 33 after 932 steps.
Found uncertainty sample 34 after 2110 steps.
Found uncertainty sample 35 after 1891 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2594 steps.
Found uncertainty sample 41 after 2056 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2919 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1389 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 178 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 634 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2410 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 837 steps.
Found uncertainty sample 56 after 1009 steps.
Found uncertainty sample 57 after 970 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1045 steps.
Found uncertainty sample 60 after 2296 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 278 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1305 steps.
Found uncertainty sample 67 after 2028 steps.
Found uncertainty sample 68 after 2235 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 23 steps.
Found uncertainty sample 76 after 3490 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 601 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1066 steps.
Found uncertainty sample 82 after 2503 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3329 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3038 steps.
Found uncertainty sample 88 after 1068 steps.
Found uncertainty sample 89 after 3908 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 349 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1300 steps.
Found uncertainty sample 94 after 2209 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 126 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_020731-63a4g4vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_37
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/63a4g4vt
Training model 37. Added 52 samples to the dataset.
Epoch 0, Batch 100/120, Loss: 0.04825775325298309, Uncertainty: 0.12287642061710358

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4944410792582774, Training Loss Force: 1.9585586011109526, time: 1.767392635345459
Validation Loss Energy: 2.3160537831521046, Validation Loss Force: 2.126972125419113, time: 0.11808395385742188
Test Loss Energy: 12.674504685770955, Test Loss Force: 8.433549176993422, time: 9.869288444519043

Epoch 1, Batch 100/120, Loss: 0.034197159111499786, Uncertainty: 0.12061268091201782

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5281967233458877, Training Loss Force: 1.816180127645508, time: 1.7814490795135498
Validation Loss Energy: 0.8740244943020876, Validation Loss Force: 2.005036534198267, time: 0.1181793212890625
Test Loss Energy: 13.497652544488275, Test Loss Force: 8.58576315177282, time: 9.841065168380737

Epoch 2, Batch 100/120, Loss: 0.0671156719326973, Uncertainty: 0.12002937495708466

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7510060469233417, Training Loss Force: 1.7948793253041404, time: 1.8351407051086426
Validation Loss Energy: 1.2735646415615276, Validation Loss Force: 1.9768900779187895, time: 0.11708974838256836
Test Loss Energy: 13.839472911027029, Test Loss Force: 8.453119729110389, time: 10.044599294662476

Epoch 3, Batch 100/120, Loss: 0.05429155379533768, Uncertainty: 0.11972644925117493

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.364576616761771, Training Loss Force: 1.8048210619704648, time: 1.8146336078643799
Validation Loss Energy: 2.342407270357047, Validation Loss Force: 1.9991857168313931, time: 0.11617565155029297
Test Loss Energy: 12.386317071898771, Test Loss Force: 8.542426853575362, time: 9.891093254089355

Epoch 4, Batch 100/120, Loss: 0.06714436411857605, Uncertainty: 0.11985233426094055

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9450633784680014, Training Loss Force: 1.7972100320159976, time: 1.7931947708129883
Validation Loss Energy: 0.9632583937464001, Validation Loss Force: 1.9309928826642404, time: 0.12459135055541992
Test Loss Energy: 13.159357746335086, Test Loss Force: 8.428399639391747, time: 10.077104091644287

Epoch 5, Batch 100/120, Loss: 0.046970486640930176, Uncertainty: 0.12106484174728394

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6635490458718507, Training Loss Force: 1.8209250670492247, time: 1.779303789138794
Validation Loss Energy: 1.225082702861049, Validation Loss Force: 1.9133353307267402, time: 0.11842155456542969
Test Loss Energy: 14.177229759176567, Test Loss Force: 8.453662556850722, time: 9.841635465621948

Epoch 6, Batch 100/120, Loss: 0.04258514940738678, Uncertainty: 0.11934123933315277

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3790358052183456, Training Loss Force: 1.805771228327663, time: 1.7503702640533447
Validation Loss Energy: 2.1200233636051933, Validation Loss Force: 1.9983177153890423, time: 0.1165626049041748
Test Loss Energy: 14.918397842532016, Test Loss Force: 8.447892772594352, time: 9.9213228225708

Epoch 7, Batch 100/120, Loss: 0.042140498757362366, Uncertainty: 0.1204652488231659

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.503470365874533, Training Loss Force: 1.8058788099977297, time: 1.8091833591461182
Validation Loss Energy: 1.015563784351605, Validation Loss Force: 1.9293307688244627, time: 0.1238255500793457
Test Loss Energy: 13.251972983528809, Test Loss Force: 8.54963514113639, time: 10.034704446792603

Epoch 8, Batch 100/120, Loss: 0.13405878841876984, Uncertainty: 0.12112793326377869

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6109355720919167, Training Loss Force: 1.8403520454380191, time: 1.7713935375213623
Validation Loss Energy: 1.3633638794115885, Validation Loss Force: 2.0241739081680796, time: 0.11541199684143066
Test Loss Energy: 12.462072845925956, Test Loss Force: 8.369197374129756, time: 9.896787643432617

Epoch 9, Batch 100/120, Loss: 0.12561270594596863, Uncertainty: 0.12080429494380951

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7860784822519586, Training Loss Force: 1.8191492230875883, time: 1.8575160503387451
Validation Loss Energy: 4.580177855659708, Validation Loss Force: 2.750866764260344, time: 0.12088203430175781
Test Loss Energy: 16.070395205321468, Test Loss Force: 8.490247843643166, time: 9.830308437347412

Epoch 10, Batch 100/120, Loss: 0.08794795721769333, Uncertainty: 0.12191998213529587

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.733926805261022, Training Loss Force: 1.832064962267296, time: 2.016317367553711
Validation Loss Energy: 1.5155065442998523, Validation Loss Force: 1.9910875368861938, time: 0.12184882164001465
Test Loss Energy: 13.065413111386597, Test Loss Force: 8.396626165225992, time: 9.846902847290039

Epoch 11, Batch 100/120, Loss: 0.13219133019447327, Uncertainty: 0.12080372869968414

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.956959902980041, Training Loss Force: 1.8108890930891914, time: 1.8187429904937744
Validation Loss Energy: 1.856624208400208, Validation Loss Force: 2.0021300709479966, time: 0.11896991729736328
Test Loss Energy: 14.41884513024197, Test Loss Force: 8.439943791857791, time: 9.880017757415771

Epoch 12, Batch 100/120, Loss: 0.05300317704677582, Uncertainty: 0.12065714597702026

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6412505155076087, Training Loss Force: 1.812699409017982, time: 1.7702956199645996
Validation Loss Energy: 2.3670656515770907, Validation Loss Force: 1.9408797638586774, time: 0.11499619483947754
Test Loss Energy: 12.491240363620756, Test Loss Force: 8.39578758156436, time: 10.803953409194946

Epoch 13, Batch 100/120, Loss: 0.05532122403383255, Uncertainty: 0.1200411468744278

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3303981075947138, Training Loss Force: 1.7926825726393207, time: 1.8068580627441406
Validation Loss Energy: 1.1853469298761812, Validation Loss Force: 1.9162954572411792, time: 0.11763691902160645
Test Loss Energy: 13.760996926775087, Test Loss Force: 8.385558650639394, time: 9.838912725448608

Epoch 14, Batch 100/120, Loss: 0.06436948478221893, Uncertainty: 0.1200108528137207

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8554161944192837, Training Loss Force: 1.836852876816177, time: 1.86651611328125
Validation Loss Energy: 1.8964060924540451, Validation Loss Force: 1.9932178497168096, time: 0.11572980880737305
Test Loss Energy: 12.527600374522718, Test Loss Force: 8.437615250831682, time: 9.866308450698853

Epoch 15, Batch 100/120, Loss: 0.07956226170063019, Uncertainty: 0.11932691931724548

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4491004166375052, Training Loss Force: 1.7820715398375309, time: 2.005474805831909
Validation Loss Energy: 2.0200438037378867, Validation Loss Force: 1.9957876001069135, time: 0.11737346649169922
Test Loss Energy: 14.83130881519677, Test Loss Force: 8.459883555066462, time: 9.910744190216064

Epoch 16, Batch 100/120, Loss: 0.07483898848295212, Uncertainty: 0.11893273890018463

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3871944157141731, Training Loss Force: 1.7938859397935056, time: 1.8531460762023926
Validation Loss Energy: 4.008459013980754, Validation Loss Force: 1.9928603172914983, time: 0.11569643020629883
Test Loss Energy: 11.791735636024244, Test Loss Force: 8.384029097804385, time: 9.92035722732544

Epoch 17, Batch 100/120, Loss: 0.19191789627075195, Uncertainty: 0.12068916112184525

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7902406468641183, Training Loss Force: 1.82520767943304, time: 1.829721212387085
Validation Loss Energy: 2.622454989376286, Validation Loss Force: 2.078627462247099, time: 0.116607666015625
Test Loss Energy: 15.094910626332416, Test Loss Force: 8.446995851948099, time: 10.070707321166992

Epoch 18, Batch 100/120, Loss: 0.14617273211479187, Uncertainty: 0.1196342259645462

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.976910360294619, Training Loss Force: 1.7780315236326276, time: 1.8054451942443848
Validation Loss Energy: 3.3437591036910006, Validation Loss Force: 1.993075823913232, time: 0.11867809295654297
Test Loss Energy: 15.531643438860808, Test Loss Force: 8.439940602209711, time: 9.91107726097107

Epoch 19, Batch 100/120, Loss: 0.08113360404968262, Uncertainty: 0.11753953993320465

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8075721374128264, Training Loss Force: 1.7654223089436276, time: 1.9079725742340088
Validation Loss Energy: 1.0216177873141383, Validation Loss Force: 1.9318399903183987, time: 0.11995267868041992
Test Loss Energy: 13.596642312022562, Test Loss Force: 8.422332826152783, time: 9.879936456680298

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–„â–‚â–ƒâ–…â–†â–ƒâ–‚â–ˆâ–ƒâ–…â–‚â–„â–‚â–†â–â–†â–‡â–„
wandb:   test_error_force â–ƒâ–ˆâ–„â–‡â–ƒâ–„â–„â–‡â–â–…â–‚â–ƒâ–‚â–‚â–ƒâ–„â–â–„â–ƒâ–ƒ
wandb:          test_loss â–‚â–ˆâ–†â–†â–…â–…â–†â–‡â–â–ˆâ–ƒâ–ˆâ–…â–†â–„â–‡â–„â–…â–ˆâ–‡
wandb: train_error_energy â–ˆâ–‚â–„â–â–…â–ƒâ–â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–â–„â–‚â–â–„â–…â–„
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–â–â–ƒâ–‚â–
wandb: valid_error_energy â–„â–â–‚â–„â–â–‚â–ƒâ–â–‚â–ˆâ–‚â–ƒâ–„â–‚â–ƒâ–ƒâ–‡â–„â–†â–
wandb:  valid_error_force â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–‚â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–
wandb:         valid_loss â–ƒâ–‚â–â–‚â–â–â–‚â–â–‚â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3830
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.59664
wandb:   test_error_force 8.42233
wandb:          test_loss 7.27839
wandb: train_error_energy 1.80757
wandb:  train_error_force 1.76542
wandb:         train_loss -2.71869
wandb: valid_error_energy 1.02162
wandb:  valid_error_force 1.93184
wandb:         valid_loss -2.53462
wandb: 
wandb: ğŸš€ View run al_69_37 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/63a4g4vt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_020731-63a4g4vt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 50.51691436767578, Uncertainty Bias: -5.813558578491211
5.722046e-05 0.0005083084
-0.22207773 5.462284
(48745, 22, 3)
Found uncertainty sample 0 after 1163 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1830 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1540 steps.
Found uncertainty sample 6 after 580 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1182 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 882 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 911 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2097 steps.
Found uncertainty sample 21 after 481 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1922 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1975 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 722 steps.
Found uncertainty sample 29 after 2922 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1825 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 59 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1194 steps.
Found uncertainty sample 42 after 3466 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 3655 steps.
Found uncertainty sample 45 after 1029 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3254 steps.
Found uncertainty sample 48 after 356 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2351 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1173 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3936 steps.
Found uncertainty sample 57 after 3695 steps.
Found uncertainty sample 58 after 457 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1003 steps.
Found uncertainty sample 62 after 1170 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 475 steps.
Found uncertainty sample 67 after 2145 steps.
Found uncertainty sample 68 after 2070 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3627 steps.
Found uncertainty sample 72 after 3050 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2137 steps.
Found uncertainty sample 75 after 1277 steps.
Found uncertainty sample 76 after 756 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 586 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2628 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 367 steps.
Found uncertainty sample 87 after 1816 steps.
Found uncertainty sample 88 after 715 steps.
Found uncertainty sample 89 after 150 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1803 steps.
Found uncertainty sample 92 after 2231 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3453 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1381 steps.
Found uncertainty sample 97 after 144 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_024207-scldpu51
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_38
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/scldpu51
Training model 38. Added 48 samples to the dataset.
Epoch 0, Batch 100/122, Loss: 0.21646633744239807, Uncertainty: 0.12124409526586533
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.243538873331687, Training Loss Force: 2.0034744988844495, time: 1.8807263374328613
Validation Loss Energy: 2.1376696707508245, Validation Loss Force: 1.9997744169417018, time: 0.11967015266418457
Test Loss Energy: 14.765216173292169, Test Loss Force: 8.492444825675665, time: 9.616528272628784

Epoch 1, Batch 100/122, Loss: 0.11654078960418701, Uncertainty: 0.12192807346582413

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.864461313790988, Training Loss Force: 1.8340895712709753, time: 1.899005651473999
Validation Loss Energy: 3.662048096054926, Validation Loss Force: 2.203368573372061, time: 0.11623525619506836
Test Loss Energy: 16.303728543229962, Test Loss Force: 8.446657525416677, time: 9.597683906555176

Epoch 2, Batch 100/122, Loss: 0.20076057314872742, Uncertainty: 0.12318440526723862

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8890961404482218, Training Loss Force: 1.868290990849726, time: 1.8574225902557373
Validation Loss Energy: 1.7587269761625697, Validation Loss Force: 2.0567117711204967, time: 0.12341475486755371
Test Loss Energy: 12.692190869346623, Test Loss Force: 8.332761324628978, time: 9.782683372497559

Epoch 3, Batch 100/122, Loss: 0.21812354028224945, Uncertainty: 0.12314207851886749

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8641270814711903, Training Loss Force: 1.8437278572694318, time: 1.8608911037445068
Validation Loss Energy: 1.7224616688188457, Validation Loss Force: 2.128797789746575, time: 0.11950182914733887
Test Loss Energy: 12.580761143211571, Test Loss Force: 8.431364501220111, time: 10.357176542282104

Epoch 4, Batch 100/122, Loss: 0.07662073522806168, Uncertainty: 0.12244081497192383

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.740685111880453, Training Loss Force: 1.8086147444248768, time: 1.9043526649475098
Validation Loss Energy: 3.21328084779816, Validation Loss Force: 2.1384492354307176, time: 0.116424560546875
Test Loss Energy: 15.928400923611996, Test Loss Force: 8.49989366119949, time: 9.82489562034607

Epoch 5, Batch 100/122, Loss: 0.04411490634083748, Uncertainty: 0.12164303660392761

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5829401723480334, Training Loss Force: 1.8283785767432592, time: 1.8493578433990479
Validation Loss Energy: 2.466696140446631, Validation Loss Force: 1.9271098667629787, time: 0.12320351600646973
Test Loss Energy: 14.778770153790658, Test Loss Force: 8.404860255733904, time: 9.736806631088257

Epoch 6, Batch 100/122, Loss: 0.07222870737314224, Uncertainty: 0.12049775570631027

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3037155747705287, Training Loss Force: 1.7895055265426967, time: 1.8765099048614502
Validation Loss Energy: 2.22296108307615, Validation Loss Force: 2.0478980067633343, time: 0.11825919151306152
Test Loss Energy: 12.775250480480386, Test Loss Force: 8.402475723326956, time: 9.711317539215088

Epoch 7, Batch 100/122, Loss: 0.0604734942317009, Uncertainty: 0.12081141024827957

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.644901233267297, Training Loss Force: 1.8229628889571243, time: 1.8033289909362793
Validation Loss Energy: 0.9460406133721068, Validation Loss Force: 2.1157874542191606, time: 0.1151432991027832
Test Loss Energy: 12.99654733161731, Test Loss Force: 8.466626536392535, time: 9.830899000167847

Epoch 8, Batch 100/122, Loss: 0.0738845244050026, Uncertainty: 0.12281174212694168

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8127567208925384, Training Loss Force: 1.8075039493520528, time: 1.810734510421753
Validation Loss Energy: 1.095612451636061, Validation Loss Force: 1.9996463821827934, time: 0.11528682708740234
Test Loss Energy: 13.511294916477047, Test Loss Force: 8.373359636375827, time: 9.697392225265503

Epoch 9, Batch 100/122, Loss: 0.043860841542482376, Uncertainty: 0.12165853381156921

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5878896954328305, Training Loss Force: 1.8200331908506997, time: 1.77665114402771
Validation Loss Energy: 7.017787913142571, Validation Loss Force: 2.069873150551899, time: 0.1143796443939209
Test Loss Energy: 11.29841668986871, Test Loss Force: 8.385149433713076, time: 9.611554145812988

Epoch 10, Batch 100/122, Loss: 0.06409290432929993, Uncertainty: 0.12174005806446075

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.815926379048634, Training Loss Force: 1.8284548153735423, time: 2.0123238563537598
Validation Loss Energy: 1.1351177249433693, Validation Loss Force: 2.3449070284122815, time: 0.11943340301513672
Test Loss Energy: 13.317894242471082, Test Loss Force: 8.565263875793365, time: 9.785628318786621

Epoch 11, Batch 100/122, Loss: 0.1369665563106537, Uncertainty: 0.12282009422779083

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6639752698807098, Training Loss Force: 1.8537452301882036, time: 1.8322629928588867
Validation Loss Energy: 1.7418596028009181, Validation Loss Force: 2.0091461530670354, time: 0.11688804626464844
Test Loss Energy: 12.434523048721495, Test Loss Force: 8.385374108047124, time: 9.61482310295105

Epoch 12, Batch 100/122, Loss: 0.10974470525979996, Uncertainty: 0.12018953263759613

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.457331809692075, Training Loss Force: 1.8019504220639602, time: 1.8435935974121094
Validation Loss Energy: 2.494016308637095, Validation Loss Force: 2.03430746966468, time: 0.11785459518432617
Test Loss Energy: 14.7970181817512, Test Loss Force: 8.456140493718257, time: 10.052736520767212

Epoch 13, Batch 100/122, Loss: 0.12227742373943329, Uncertainty: 0.12110546231269836

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6632171891230847, Training Loss Force: 1.8219013886353477, time: 1.894256591796875
Validation Loss Energy: 2.088202161298945, Validation Loss Force: 2.0412621693224917, time: 0.11661815643310547
Test Loss Energy: 12.505889372688564, Test Loss Force: 8.344217855037389, time: 9.781213998794556

Epoch 14, Batch 100/122, Loss: 0.07098858058452606, Uncertainty: 0.12101511657238007

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.341803658967397, Training Loss Force: 1.8102924925589499, time: 1.8742315769195557
Validation Loss Energy: 1.6414515161622736, Validation Loss Force: 2.268829071561058, time: 0.13318443298339844
Test Loss Energy: 12.546292309164064, Test Loss Force: 8.626994636642896, time: 9.796288967132568

Epoch 15, Batch 100/122, Loss: 0.155708909034729, Uncertainty: 0.11974912136793137

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3786057170556696, Training Loss Force: 1.812908144124976, time: 1.8248112201690674
Validation Loss Energy: 2.0777351156447934, Validation Loss Force: 2.261166803580537, time: 0.12082290649414062
Test Loss Energy: 12.569172083858087, Test Loss Force: 8.38358113411506, time: 9.996128559112549

Epoch 16, Batch 100/122, Loss: 0.17683881521224976, Uncertainty: 0.12015235424041748

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.087460207627987, Training Loss Force: 1.8368635433374911, time: 1.8658149242401123
Validation Loss Energy: 0.9711292284936069, Validation Loss Force: 2.1050628174746944, time: 0.11591386795043945
Test Loss Energy: 13.196898850345784, Test Loss Force: 8.399316833900189, time: 9.789751768112183

Epoch 17, Batch 100/122, Loss: 0.12144377827644348, Uncertainty: 0.12069088220596313

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7871213856390757, Training Loss Force: 1.7971065440816758, time: 1.8627159595489502
Validation Loss Energy: 0.8918833948147936, Validation Loss Force: 2.118149454296114, time: 0.11911201477050781
Test Loss Energy: 13.18354901665087, Test Loss Force: 8.48893986409546, time: 9.961474895477295

Epoch 18, Batch 100/122, Loss: 0.10675579309463501, Uncertainty: 0.11953450739383698

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6057907880983757, Training Loss Force: 1.7872389106880702, time: 1.8124208450317383
Validation Loss Energy: 3.04014875831883, Validation Loss Force: 1.9987712182162483, time: 0.1171727180480957
Test Loss Energy: 15.549640174780816, Test Loss Force: 8.350435365158445, time: 9.787975788116455

Epoch 19, Batch 100/122, Loss: 0.05056656152009964, Uncertainty: 0.11910420656204224

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5285342084755824, Training Loss Force: 1.7941649231375811, time: 1.8568129539489746
Validation Loss Energy: 4.2632862606325785, Validation Loss Force: 2.341621322494971, time: 0.1235959529876709
Test Loss Energy: 11.667573786052834, Test Loss Force: 8.366483944238778, time: 9.857339143753052

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.057 MB uploadedwandb: / 0.039 MB of 0.057 MB uploadedwandb: - 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–ˆâ–ƒâ–ƒâ–‡â–†â–ƒâ–ƒâ–„â–â–„â–ƒâ–†â–ƒâ–ƒâ–ƒâ–„â–„â–‡â–‚
wandb:   test_error_force â–…â–„â–â–ƒâ–…â–ƒâ–ƒâ–„â–‚â–‚â–‡â–‚â–„â–â–ˆâ–‚â–ƒâ–…â–â–‚
wandb:          test_loss â–†â–†â–â–‚â–ˆâ–†â–„â–„â–„â–‚â–…â–â–‡â–ƒâ–ˆâ–…â–„â–…â–†â–„
wandb: train_error_energy â–…â–„â–„â–„â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–‚â–ƒâ–â–â–…â–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–ƒâ–â–â–
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–
wandb: valid_error_energy â–‚â–„â–‚â–‚â–„â–ƒâ–ƒâ–â–â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–…
wandb:  valid_error_force â–‚â–†â–ƒâ–„â–…â–â–ƒâ–„â–‚â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‡â–‡â–„â–„â–‚â–ˆ
wandb:         valid_loss â–‚â–†â–‚â–ƒâ–„â–â–ƒâ–ƒâ–â–†â–†â–‚â–ƒâ–‚â–…â–…â–‚â–ƒâ–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3873
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 11.66757
wandb:   test_error_force 8.36648
wandb:          test_loss 6.98162
wandb: train_error_energy 1.52853
wandb:  train_error_force 1.79416
wandb:         train_loss -2.69686
wandb: valid_error_energy 4.26329
wandb:  valid_error_force 2.34162
wandb:         valid_loss -1.74152
wandb: 
wandb: ğŸš€ View run al_69_38 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/scldpu51
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_024207-scldpu51/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 48.50044250488281, Uncertainty Bias: -5.593509197235107
5.531311e-05 1.1503296
0.235274 6.720176
(48745, 22, 3)
Found uncertainty sample 0 after 2556 steps.
Found uncertainty sample 1 after 1059 steps.
Found uncertainty sample 2 after 1228 steps.
Found uncertainty sample 3 after 1215 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1459 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1998 steps.
Found uncertainty sample 11 after 31 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3088 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1160 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2122 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2352 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 789 steps.
Found uncertainty sample 22 after 1392 steps.
Found uncertainty sample 23 after 1325 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1779 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 951 steps.
Found uncertainty sample 29 after 1600 steps.
Found uncertainty sample 30 after 1652 steps.
Found uncertainty sample 31 after 505 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 438 steps.
Found uncertainty sample 34 after 3118 steps.
Found uncertainty sample 35 after 1404 steps.
Found uncertainty sample 36 after 1489 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 201 steps.
Found uncertainty sample 39 after 1139 steps.
Found uncertainty sample 40 after 1797 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 261 steps.
Found uncertainty sample 44 after 1887 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 605 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 578 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1601 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 354 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 149 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1588 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1638 steps.
Found uncertainty sample 63 after 3116 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3117 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 949 steps.
Found uncertainty sample 70 after 72 steps.
Found uncertainty sample 71 after 1164 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2226 steps.
Found uncertainty sample 75 after 977 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1735 steps.
Found uncertainty sample 80 after 514 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3033 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1751 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 398 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3048 steps.
Found uncertainty sample 99 after 1016 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_031533-lqqwjchf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_39
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lqqwjchf
Training model 39. Added 49 samples to the dataset.
Epoch 0, Batch 100/123, Loss: 0.08463506400585175, Uncertainty: 0.12374942004680634

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.461832330318696, Training Loss Force: 1.9765428308166697, time: 1.8526208400726318
Validation Loss Energy: 1.3359755744624708, Validation Loss Force: 2.121358339358079, time: 0.11642265319824219
Test Loss Energy: 13.78007470157985, Test Loss Force: 8.34603708061253, time: 9.673988580703735

Epoch 1, Batch 100/123, Loss: 0.04640066623687744, Uncertainty: 0.12249035388231277

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8968433128262452, Training Loss Force: 1.829547452887449, time: 1.80922269821167
Validation Loss Energy: 4.359901660820158, Validation Loss Force: 2.5782097765153753, time: 0.12104487419128418
Test Loss Energy: 15.894148202211586, Test Loss Force: 8.308125942450353, time: 9.731290340423584

Epoch 2, Batch 100/123, Loss: 0.0483989380300045, Uncertainty: 0.12108714878559113

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2481615212065305, Training Loss Force: 1.807786091392476, time: 1.8587524890899658
Validation Loss Energy: 3.661298443263636, Validation Loss Force: 1.9902053588415523, time: 0.1201786994934082
Test Loss Energy: 16.059180206817, Test Loss Force: 8.412243516942965, time: 9.91994857788086

Epoch 3, Batch 100/123, Loss: 0.15477466583251953, Uncertainty: 0.12010426074266434

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.685123451466708, Training Loss Force: 1.8004187052480978, time: 1.8619024753570557
Validation Loss Energy: 0.9598761050870435, Validation Loss Force: 1.960108840405088, time: 0.1159200668334961
Test Loss Energy: 13.23471045423393, Test Loss Force: 8.373515313585623, time: 9.68352460861206

Epoch 4, Batch 100/123, Loss: 0.16361084580421448, Uncertainty: 0.12398770451545715

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6719015467597744, Training Loss Force: 1.8409281643568907, time: 1.8359553813934326
Validation Loss Energy: 1.3572539864934274, Validation Loss Force: 1.9534556347708627, time: 0.1201634407043457
Test Loss Energy: 14.058568704470023, Test Loss Force: 8.250759907225087, time: 9.893849849700928

Epoch 5, Batch 100/123, Loss: 0.052487291395664215, Uncertainty: 0.12053889036178589

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4312292034714467, Training Loss Force: 1.8090334160610284, time: 1.96907639503479
Validation Loss Energy: 1.2279796098938072, Validation Loss Force: 2.1077305422890062, time: 0.11769223213195801
Test Loss Energy: 12.833970013023688, Test Loss Force: 8.351072474046262, time: 9.649015426635742

Epoch 6, Batch 100/123, Loss: 0.4356989562511444, Uncertainty: 0.12160950899124146

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6604225386294746, Training Loss Force: 1.857355580597713, time: 1.8636410236358643
Validation Loss Energy: 1.5306328676094942, Validation Loss Force: 2.0833749539959006, time: 0.1320352554321289
Test Loss Energy: 12.7749434115675, Test Loss Force: 8.315950920954581, time: 9.750351905822754

Epoch 7, Batch 100/123, Loss: 0.20515356957912445, Uncertainty: 0.12181678414344788

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2537071894146865, Training Loss Force: 1.8416160527098002, time: 1.859926462173462
Validation Loss Energy: 4.517203161592801, Validation Loss Force: 2.0320362443762168, time: 0.11792659759521484
Test Loss Energy: 16.981747941257204, Test Loss Force: 8.28308752445437, time: 9.879782676696777

Epoch 8, Batch 100/123, Loss: 0.08002962917089462, Uncertainty: 0.12123033404350281

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8512829150642416, Training Loss Force: 1.8289709552273687, time: 1.8423967361450195
Validation Loss Energy: 4.536706603638519, Validation Loss Force: 2.0656580978425345, time: 0.11499214172363281
Test Loss Energy: 11.609703562595993, Test Loss Force: 8.232246021630761, time: 9.66005802154541

Epoch 9, Batch 100/123, Loss: 0.1669008880853653, Uncertainty: 0.12036185711622238

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6121163691597726, Training Loss Force: 1.8089570722245447, time: 1.8991739749908447
Validation Loss Energy: 2.470104833955542, Validation Loss Force: 1.9717585932278354, time: 0.11807489395141602
Test Loss Energy: 12.413416923541929, Test Loss Force: 8.255466302915384, time: 10.412342548370361

Epoch 10, Batch 100/123, Loss: 0.08204574882984161, Uncertainty: 0.12069276720285416

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.027068225993147, Training Loss Force: 1.7909529194685434, time: 1.9996848106384277
Validation Loss Energy: 0.9989667127773476, Validation Loss Force: 2.0176397191923527, time: 0.11668109893798828
Test Loss Energy: 13.116029622776638, Test Loss Force: 8.346941450765813, time: 9.732567071914673

Epoch 11, Batch 100/123, Loss: 0.16929781436920166, Uncertainty: 0.11976365745067596

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.01655279777319, Training Loss Force: 1.7929296050710148, time: 1.817117691040039
Validation Loss Energy: 1.2777467392372948, Validation Loss Force: 2.0651608034166293, time: 0.12239289283752441
Test Loss Energy: 13.868166700696774, Test Loss Force: 8.286749900296869, time: 9.725515127182007

Epoch 12, Batch 100/123, Loss: 0.05485578626394272, Uncertainty: 0.11912135034799576

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5097743077573553, Training Loss Force: 1.8014786882263993, time: 1.869056224822998
Validation Loss Energy: 2.424239294831239, Validation Loss Force: 2.5112073687138765, time: 0.1168673038482666
Test Loss Energy: 12.756846420904704, Test Loss Force: 8.289742669214316, time: 9.817363977432251

Epoch 13, Batch 100/123, Loss: 0.07824057340621948, Uncertainty: 0.11957249045372009

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3661429781732872, Training Loss Force: 1.8196285299649768, time: 1.816758632659912
Validation Loss Energy: 3.0466025266213514, Validation Loss Force: 2.0356014000716667, time: 0.12007594108581543
Test Loss Energy: 15.607298995451028, Test Loss Force: 8.398576294611185, time: 9.73582148551941

Epoch 14, Batch 100/123, Loss: 0.041703108698129654, Uncertainty: 0.12014332413673401

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.445059948531907, Training Loss Force: 1.8186238857003934, time: 1.8922960758209229
Validation Loss Energy: 1.7422013257168685, Validation Loss Force: 2.052328417648335, time: 0.1323683261871338
Test Loss Energy: 14.806976729379425, Test Loss Force: 8.256252889251119, time: 9.739614009857178

Epoch 15, Batch 100/123, Loss: 0.08002118021249771, Uncertainty: 0.1198994368314743

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4799126500551374, Training Loss Force: 1.8175852309866667, time: 1.8023600578308105
Validation Loss Energy: 1.201031466178902, Validation Loss Force: 1.9117288099503955, time: 0.11679577827453613
Test Loss Energy: 13.962432109785793, Test Loss Force: 8.254474900602835, time: 9.873398542404175

Epoch 16, Batch 100/123, Loss: 0.04526694491505623, Uncertainty: 0.11989563703536987

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2935632002202848, Training Loss Force: 1.8001686305991977, time: 1.8625445365905762
Validation Loss Energy: 2.138280897556396, Validation Loss Force: 1.9781369509129367, time: 0.1216268539428711
Test Loss Energy: 12.413827026481604, Test Loss Force: 8.314005471118874, time: 9.725099802017212

Epoch 17, Batch 100/123, Loss: 0.06570182740688324, Uncertainty: 0.12270678579807281

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2286342919288953, Training Loss Force: 1.8425825065003798, time: 1.8150355815887451
Validation Loss Energy: 0.8667239337933642, Validation Loss Force: 1.9477874803266977, time: 0.11762714385986328
Test Loss Energy: 13.180390798728961, Test Loss Force: 8.24382785531217, time: 9.912479162216187

Epoch 18, Batch 100/123, Loss: 0.10302543640136719, Uncertainty: 0.1202961727976799

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.64197861023705, Training Loss Force: 1.7967261990940413, time: 1.8766515254974365
Validation Loss Energy: 0.9842923336108903, Validation Loss Force: 2.0218165470316665, time: 0.11957693099975586
Test Loss Energy: 13.814331652528226, Test Loss Force: 8.20131399434875, time: 9.782098531723022

Epoch 19, Batch 100/123, Loss: 0.050125602632761, Uncertainty: 0.11946915835142136

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4343058904950863, Training Loss Force: 1.801909962155696, time: 1.8611767292022705
Validation Loss Energy: 2.2752285828150227, Validation Loss Force: 2.046721942557592, time: 0.11588454246520996
Test Loss Energy: 15.083663936529188, Test Loss Force: 8.417820103655547, time: 9.658987045288086

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‡â–‡â–ƒâ–„â–ƒâ–ƒâ–ˆâ–â–‚â–ƒâ–„â–‚â–†â–…â–„â–‚â–ƒâ–„â–†
wandb:   test_error_force â–†â–„â–ˆâ–‡â–ƒâ–†â–…â–„â–‚â–ƒâ–†â–„â–„â–‡â–ƒâ–ƒâ–…â–‚â–â–ˆ
wandb:          test_loss â–ƒâ–…â–‡â–†â–‚â–„â–‚â–…â–‚â–ƒâ–†â–…â–…â–‡â–„â–„â–„â–â–ƒâ–ˆ
wandb: train_error_energy â–ˆâ–…â–â–„â–ƒâ–‚â–ƒâ–‡â–„â–ƒâ–…â–…â–ƒâ–‚â–‚â–‚â–â–‡â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–ƒâ–‚â–„â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–‚â–â–ƒâ–â–
wandb:         train_loss â–ˆâ–ƒâ–â–‚â–ƒâ–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–„â–â–
wandb: valid_error_energy â–‚â–ˆâ–†â–â–‚â–‚â–‚â–ˆâ–ˆâ–„â–â–‚â–„â–…â–ƒâ–‚â–ƒâ–â–â–„
wandb:  valid_error_force â–ƒâ–ˆâ–‚â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‡â–‚â–‚â–â–‚â–â–‚â–‚
wandb:         valid_loss â–ƒâ–ˆâ–ƒâ–â–â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–‡â–ƒâ–‚â–â–‚â–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3917
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 15.08366
wandb:   test_error_force 8.41782
wandb:          test_loss 7.23739
wandb: train_error_energy 1.43431
wandb:  train_error_force 1.80191
wandb:         train_loss -2.69251
wandb: valid_error_energy 2.27523
wandb:  valid_error_force 2.04672
wandb:         valid_loss -2.29291
wandb: 
wandb: ğŸš€ View run al_69_39 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lqqwjchf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_031533-lqqwjchf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.579254150390625, Uncertainty Bias: -4.705247402191162
0.00019073486 0.041988373
0.48010316 5.302903
(48745, 22, 3)
Found uncertainty sample 0 after 1789 steps.
Found uncertainty sample 1 after 1795 steps.
Found uncertainty sample 2 after 1242 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 535 steps.
Found uncertainty sample 5 after 406 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1516 steps.
Found uncertainty sample 13 after 1808 steps.
Found uncertainty sample 14 after 884 steps.
Found uncertainty sample 15 after 3224 steps.
Found uncertainty sample 16 after 3635 steps.
Found uncertainty sample 17 after 1113 steps.
Found uncertainty sample 18 after 2218 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1351 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 708 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1387 steps.
Found uncertainty sample 33 after 3052 steps.
Found uncertainty sample 34 after 3627 steps.
Found uncertainty sample 35 after 1114 steps.
Found uncertainty sample 36 after 2431 steps.
Found uncertainty sample 37 after 1632 steps.
Found uncertainty sample 38 after 2445 steps.
Found uncertainty sample 39 after 1982 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1111 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2668 steps.
Found uncertainty sample 51 after 2857 steps.
Found uncertainty sample 52 after 3716 steps.
Found uncertainty sample 53 after 1469 steps.
Found uncertainty sample 54 after 476 steps.
Found uncertainty sample 55 after 403 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 539 steps.
Found uncertainty sample 58 after 735 steps.
Found uncertainty sample 59 after 3622 steps.
Found uncertainty sample 60 after 1751 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1191 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1744 steps.
Found uncertainty sample 70 after 1962 steps.
Found uncertainty sample 71 after 3736 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 774 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 476 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1407 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2289 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3302 steps.
Found uncertainty sample 90 after 2133 steps.
Found uncertainty sample 91 after 2550 steps.
Found uncertainty sample 92 after 316 steps.
Found uncertainty sample 93 after 1877 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1379 steps.
Found uncertainty sample 98 after 1367 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_035110-8lbzilz6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_40
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8lbzilz6
Training model 40. Added 48 samples to the dataset.
Epoch 0, Batch 100/124, Loss: 0.04624303802847862, Uncertainty: 0.12223555147647858

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.393705810642378, Training Loss Force: 2.011080813043569, time: 2.0553677082061768
Validation Loss Energy: 2.636287679171136, Validation Loss Force: 2.4399566191656983, time: 0.1403336524963379
Test Loss Energy: 14.303712805589694, Test Loss Force: 8.309640185907226, time: 11.407323598861694

Epoch 1, Batch 100/124, Loss: 0.09446292370557785, Uncertainty: 0.12165172398090363

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.283792919599288, Training Loss Force: 1.8248510194278367, time: 1.974987506866455
Validation Loss Energy: 1.1774725138668773, Validation Loss Force: 2.1091220017819095, time: 0.12941884994506836
Test Loss Energy: 13.130066242729248, Test Loss Force: 8.24446738674703, time: 11.226385593414307

Epoch 2, Batch 100/124, Loss: 0.1252652406692505, Uncertainty: 0.12057772278785706

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8606282762577193, Training Loss Force: 1.8096107700235442, time: 2.1942636966705322
Validation Loss Energy: 1.7656057827531437, Validation Loss Force: 2.0106115016048616, time: 0.14426326751708984
Test Loss Energy: 12.59844907549781, Test Loss Force: 8.278226864512423, time: 11.492100715637207

Epoch 3, Batch 100/124, Loss: 0.03943023830652237, Uncertainty: 0.12142115831375122

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7239335147166497, Training Loss Force: 1.8261085120043827, time: 1.998065710067749
Validation Loss Energy: 2.181984022381546, Validation Loss Force: 1.9316887979683137, time: 0.14224863052368164
Test Loss Energy: 12.483940667460809, Test Loss Force: 8.222074763180402, time: 11.364861726760864

Epoch 4, Batch 100/124, Loss: 0.0819762796163559, Uncertainty: 0.12216027081012726

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8632124603372058, Training Loss Force: 1.8573765574634546, time: 1.950263500213623
Validation Loss Energy: 4.002989591749329, Validation Loss Force: 2.0459149895727498, time: 0.13395309448242188
Test Loss Energy: 11.898673959941327, Test Loss Force: 8.22271945447725, time: 11.45374584197998

Epoch 5, Batch 100/124, Loss: 0.16668152809143066, Uncertainty: 0.12145169079303741

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9772190190571195, Training Loss Force: 1.8113271801184097, time: 2.038469076156616
Validation Loss Energy: 2.3763279458172, Validation Loss Force: 2.0837453641201518, time: 0.14041471481323242
Test Loss Energy: 12.3240475682968, Test Loss Force: 8.316168644747016, time: 11.327023983001709

Epoch 6, Batch 100/124, Loss: 0.1967897117137909, Uncertainty: 0.122417151927948

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.207959864735179, Training Loss Force: 1.843740887962642, time: 2.0595703125
Validation Loss Energy: 1.6283603888464115, Validation Loss Force: 2.1093698325413266, time: 0.14575886726379395
Test Loss Energy: 12.675422175916742, Test Loss Force: 8.274176496426698, time: 11.251307249069214

Epoch 7, Batch 100/124, Loss: 0.04203609749674797, Uncertainty: 0.12145097553730011

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.432489483459984, Training Loss Force: 1.8112357717404284, time: 2.140442132949829
Validation Loss Energy: 0.933929248854089, Validation Loss Force: 2.0780666328915554, time: 0.14322710037231445
Test Loss Energy: 12.902158538173694, Test Loss Force: 8.110795381853714, time: 11.150352954864502

Epoch 8, Batch 100/124, Loss: 0.22071582078933716, Uncertainty: 0.12003076821565628

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.663437184060848, Training Loss Force: 1.8056648500885581, time: 1.9602601528167725
Validation Loss Energy: 1.5055950952763144, Validation Loss Force: 2.0259593436031773, time: 0.13800573348999023
Test Loss Energy: 13.942192197894867, Test Loss Force: 8.265830318234467, time: 11.573163747787476

Epoch 9, Batch 100/124, Loss: 0.07522940635681152, Uncertainty: 0.12040181457996368

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9966104565770735, Training Loss Force: 1.7985425547869118, time: 2.0353474617004395
Validation Loss Energy: 2.8491928943845637, Validation Loss Force: 1.9491574893585433, time: 0.13909697532653809
Test Loss Energy: 15.325463048111608, Test Loss Force: 8.238639039339477, time: 11.500665426254272

Epoch 10, Batch 100/124, Loss: 0.11169466376304626, Uncertainty: 0.120780348777771

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5537677552124076, Training Loss Force: 1.82376095429612, time: 2.1521153450012207
Validation Loss Energy: 1.634561910118122, Validation Loss Force: 2.0896083911785275, time: 0.13904070854187012
Test Loss Energy: 12.3296804401736, Test Loss Force: 8.224264204772924, time: 11.2900710105896

Epoch 11, Batch 100/124, Loss: 0.06576107442378998, Uncertainty: 0.12113773077726364

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.761485138918431, Training Loss Force: 1.814777376582258, time: 2.1212146282196045
Validation Loss Energy: 2.1526255408292587, Validation Loss Force: 1.9331236408331478, time: 0.1250753402709961
Test Loss Energy: 14.64642677255623, Test Loss Force: 8.24465408608234, time: 11.357487916946411

Epoch 12, Batch 100/124, Loss: 0.23003990948200226, Uncertainty: 0.12018904834985733

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.695580762805989, Training Loss Force: 1.8231572623271313, time: 2.051692008972168
Validation Loss Energy: 1.3788620230834059, Validation Loss Force: 2.0213459729032723, time: 0.13967561721801758
Test Loss Energy: 13.7396948853897, Test Loss Force: 8.22113679913126, time: 11.352699279785156

Epoch 13, Batch 100/124, Loss: 0.1089920848608017, Uncertainty: 0.12181004136800766

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7300899493770343, Training Loss Force: 1.8288423979872515, time: 1.9732468128204346
Validation Loss Energy: 1.8000807744963214, Validation Loss Force: 2.4528904307299624, time: 0.14698219299316406
Test Loss Energy: 13.099572787394992, Test Loss Force: 8.136009454329043, time: 11.661988258361816

Epoch 14, Batch 100/124, Loss: 0.044908713549375534, Uncertainty: 0.12123526632785797

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.734751027839314, Training Loss Force: 1.8422465283885372, time: 1.929753065109253
Validation Loss Energy: 0.9091330539884788, Validation Loss Force: 1.9742253962494718, time: 0.13819313049316406
Test Loss Energy: 13.446008994395877, Test Loss Force: 8.26254916595948, time: 10.89340090751648

Epoch 15, Batch 100/124, Loss: 0.06701287627220154, Uncertainty: 0.12104880809783936

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9053575088420716, Training Loss Force: 1.8201855872450392, time: 1.9536082744598389
Validation Loss Energy: 2.3649356727501942, Validation Loss Force: 2.2455734317373115, time: 0.10937786102294922
Test Loss Energy: 14.886038084002456, Test Loss Force: 8.455538060595238, time: 11.8110671043396

Epoch 16, Batch 100/124, Loss: 0.5077108144760132, Uncertainty: 0.12357714772224426

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1412091108534974, Training Loss Force: 1.862937744523066, time: 1.9804506301879883
Validation Loss Energy: 1.2375374788693738, Validation Loss Force: 1.976638090668648, time: 0.1513819694519043
Test Loss Energy: 12.614707574458206, Test Loss Force: 8.175454815549262, time: 9.423372507095337

Epoch 17, Batch 100/124, Loss: 0.15967479348182678, Uncertainty: 0.12094105035066605

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0130353624028476, Training Loss Force: 1.794513412258635, time: 1.9725680351257324
Validation Loss Energy: 3.0837547993963548, Validation Loss Force: 2.037214341141719, time: 0.11482691764831543
Test Loss Energy: 15.337949191324334, Test Loss Force: 8.250282917271914, time: 8.860573053359985

Epoch 18, Batch 100/124, Loss: 0.14227907359600067, Uncertainty: 0.1195460706949234

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0147618720698417, Training Loss Force: 1.7933813174277653, time: 1.877244234085083
Validation Loss Energy: 3.2689844293508927, Validation Loss Force: 1.9450181441587944, time: 0.14814496040344238
Test Loss Energy: 11.849492841482741, Test Loss Force: 8.187374374205657, time: 8.939984321594238

Epoch 19, Batch 100/124, Loss: 0.15947307646274567, Uncertainty: 0.11989825963973999

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0211419294029, Training Loss Force: 1.805983049685246, time: 1.9036848545074463
Validation Loss Energy: 2.3855486751500696, Validation Loss Force: 1.9621536482836672, time: 0.12003016471862793
Test Loss Energy: 12.138575314854322, Test Loss Force: 8.196403510145236, time: 8.949838876724243

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–…â–ˆâ–‚â–‡â–…â–„â–„â–‡â–ƒâ–ˆâ–â–‚
wandb:   test_error_force â–…â–„â–„â–ƒâ–ƒâ–…â–„â–â–„â–„â–ƒâ–„â–ƒâ–‚â–„â–ˆâ–‚â–„â–ƒâ–ƒ
wandb:          test_loss â–„â–ƒâ–ƒâ–‚â–â–„â–â–â–„â–…â–‚â–ƒâ–‚â–â–ƒâ–ˆâ–â–…â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–â–…â–„â–…â–…â–‡â–‚â–ƒâ–…â–ƒâ–„â–„â–„â–„â–…â–†â–†â–†â–†
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–ƒâ–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚
wandb: valid_error_energy â–…â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–â–‚â–…â–ƒâ–„â–‚â–ƒâ–â–„â–‚â–†â–†â–„
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–â–‚â–ˆâ–‚â–…â–‚â–‚â–â–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–â–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–ˆâ–â–…â–â–ƒâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3960
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.13858
wandb:   test_error_force 8.1964
wandb:          test_loss 6.70572
wandb: train_error_energy 2.02114
wandb:  train_error_force 1.80598
wandb:         train_loss -2.6475
wandb: valid_error_energy 2.38555
wandb:  valid_error_force 1.96215
wandb:         valid_loss -2.40521
wandb: 
wandb: ğŸš€ View run al_69_40 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8lbzilz6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_035110-8lbzilz6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 29.942367553710938, Uncertainty Bias: -3.454580068588257
3.8146973e-05 0.0032157898
0.73698497 5.637473
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 768 steps.
Found uncertainty sample 3 after 276 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1249 steps.
Found uncertainty sample 7 after 3232 steps.
Found uncertainty sample 8 after 2936 steps.
Found uncertainty sample 9 after 2963 steps.
Found uncertainty sample 10 after 714 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 934 steps.
Found uncertainty sample 14 after 879 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1689 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3137 steps.
Found uncertainty sample 21 after 2469 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3693 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2179 steps.
Found uncertainty sample 27 after 2046 steps.
Found uncertainty sample 28 after 3617 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2447 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2379 steps.
Found uncertainty sample 39 after 1304 steps.
Found uncertainty sample 40 after 1975 steps.
Found uncertainty sample 41 after 1410 steps.
Found uncertainty sample 42 after 2735 steps.
Found uncertainty sample 43 after 1051 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 261 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1798 steps.
Found uncertainty sample 51 after 1277 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1336 steps.
Found uncertainty sample 59 after 648 steps.
Found uncertainty sample 60 after 3571 steps.
Found uncertainty sample 61 after 1865 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2300 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1153 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1394 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 770 steps.
Found uncertainty sample 73 after 3114 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2606 steps.
Found uncertainty sample 77 after 2911 steps.
Found uncertainty sample 78 after 2759 steps.
Found uncertainty sample 79 after 1479 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1413 steps.
Found uncertainty sample 86 after 3834 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1117 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 974 steps.
Found uncertainty sample 92 after 985 steps.
Found uncertainty sample 93 after 1825 steps.
Found uncertainty sample 94 after 1843 steps.
Found uncertainty sample 95 after 3043 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1208 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_042713-v771ppky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_41
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v771ppky
Training model 41. Added 48 samples to the dataset.
Epoch 0, Batch 100/126, Loss: 0.05472816526889801, Uncertainty: 0.12299211323261261

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5141342888083225, Training Loss Force: 1.981723024253988, time: 1.9057409763336182
Validation Loss Energy: 1.8148100972745365, Validation Loss Force: 2.0146477138785213, time: 0.1224055290222168
Test Loss Energy: 14.147274099959432, Test Loss Force: 8.186263015011225, time: 9.658681869506836

Epoch 1, Batch 100/126, Loss: 0.1759612262248993, Uncertainty: 0.12194474041461945

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6986902185693802, Training Loss Force: 1.8545947160942726, time: 1.893657922744751
Validation Loss Energy: 2.261505260682348, Validation Loss Force: 1.9464248564881927, time: 0.11971902847290039
Test Loss Energy: 14.153714349174837, Test Loss Force: 8.097891303809575, time: 9.713488578796387

Epoch 2, Batch 100/126, Loss: 0.16011615097522736, Uncertainty: 0.12301266193389893

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.910267918771722, Training Loss Force: 1.8476016130776511, time: 1.957120656967163
Validation Loss Energy: 2.9085148495586233, Validation Loss Force: 2.2499715184846285, time: 0.12150073051452637
Test Loss Energy: 15.243442292300427, Test Loss Force: 8.347649969998471, time: 9.907867908477783

Epoch 3, Batch 100/126, Loss: 0.13175638020038605, Uncertainty: 0.12272414565086365

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9199313315970468, Training Loss Force: 1.8538307735989037, time: 1.9105055332183838
Validation Loss Energy: 3.9276338251613976, Validation Loss Force: 2.1715772087313674, time: 0.11771941184997559
Test Loss Energy: 16.254376158389757, Test Loss Force: 8.149059258254026, time: 9.658351182937622

Epoch 4, Batch 100/126, Loss: 0.12577728927135468, Uncertainty: 0.12393544614315033

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8385532994687395, Training Loss Force: 1.8505354637492635, time: 1.9354004859924316
Validation Loss Energy: 4.880659031524156, Validation Loss Force: 1.9197761471072743, time: 0.12169575691223145
Test Loss Energy: 11.329151719075965, Test Loss Force: 8.133821374399155, time: 9.867905139923096

Epoch 5, Batch 100/126, Loss: 0.1584826111793518, Uncertainty: 0.12254215776920319

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5994613934710198, Training Loss Force: 1.8505532825825837, time: 1.8892810344696045
Validation Loss Energy: 3.1132419094919395, Validation Loss Force: 2.2272727741948475, time: 0.12015104293823242
Test Loss Energy: 11.756103741571396, Test Loss Force: 8.243309402265572, time: 9.740449666976929

Epoch 6, Batch 100/126, Loss: 0.12223756313323975, Uncertainty: 0.12100304663181305

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7413750725303594, Training Loss Force: 1.8328802940181812, time: 1.911945104598999
Validation Loss Energy: 1.803558328438611, Validation Loss Force: 2.166442384003224, time: 0.12003731727600098
Test Loss Energy: 14.46051519638626, Test Loss Force: 8.252415756600698, time: 9.707593202590942

Epoch 7, Batch 100/126, Loss: 0.07559943199157715, Uncertainty: 0.12228628993034363

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.103265779828404, Training Loss Force: 1.8549023768161508, time: 1.8955628871917725
Validation Loss Energy: 2.4291754244581663, Validation Loss Force: 2.0169337095536646, time: 0.11791086196899414
Test Loss Energy: 14.711300982884, Test Loss Force: 8.12602568096794, time: 9.934156656265259

Epoch 8, Batch 100/126, Loss: 0.09668879210948944, Uncertainty: 0.12097673118114471

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6618825315993473, Training Loss Force: 1.7978676499500068, time: 1.9278044700622559
Validation Loss Energy: 4.588368962861808, Validation Loss Force: 2.2241321001145846, time: 0.1251511573791504
Test Loss Energy: 11.339104241813374, Test Loss Force: 8.18332243461203, time: 10.436336517333984

Epoch 9, Batch 100/126, Loss: 0.13155177235603333, Uncertainty: 0.12192186713218689

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7911193455929038, Training Loss Force: 1.8506017979481646, time: 1.911651849746704
Validation Loss Energy: 2.229923724600166, Validation Loss Force: 1.979453964688051, time: 0.11877965927124023
Test Loss Energy: 14.460174025285644, Test Loss Force: 8.072508758226306, time: 10.008975744247437

Epoch 10, Batch 100/126, Loss: 0.06562527269124985, Uncertainty: 0.12225751578807831

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6815739543399468, Training Loss Force: 1.8318604693298315, time: 1.981727123260498
Validation Loss Energy: 1.1701117027984183, Validation Loss Force: 1.944536473684628, time: 0.12027144432067871
Test Loss Energy: 13.378410269683732, Test Loss Force: 8.120862626999365, time: 9.826293468475342

Epoch 11, Batch 100/126, Loss: 0.10344738513231277, Uncertainty: 0.12131765484809875

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9289132314823627, Training Loss Force: 1.8189374740076918, time: 1.914952039718628
Validation Loss Energy: 2.1642541771946675, Validation Loss Force: 2.4431813137370244, time: 0.12300252914428711
Test Loss Energy: 13.999427825943885, Test Loss Force: 8.143698816831138, time: 9.811737775802612

Epoch 12, Batch 100/126, Loss: 0.13078895211219788, Uncertainty: 0.12201495468616486

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9378919176863934, Training Loss Force: 1.8484722335332897, time: 2.020721673965454
Validation Loss Energy: 1.0063127905706513, Validation Loss Force: 1.9864387617920862, time: 0.11717033386230469
Test Loss Energy: 13.384842917837192, Test Loss Force: 8.04522045154243, time: 9.912681818008423

Epoch 13, Batch 100/126, Loss: 0.07891994714736938, Uncertainty: 0.12198039889335632

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6823673278204165, Training Loss Force: 1.8335440725094074, time: 1.8937599658966064
Validation Loss Energy: 3.760224332732412, Validation Loss Force: 2.044380947603405, time: 0.12358975410461426
Test Loss Energy: 15.780953448870996, Test Loss Force: 8.161109482895833, time: 9.744224786758423

Epoch 14, Batch 100/126, Loss: 0.1139233261346817, Uncertainty: 0.12439339607954025

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3748214802483008, Training Loss Force: 1.828392615633114, time: 1.9576284885406494
Validation Loss Energy: 1.0321629527269864, Validation Loss Force: 2.0129450371426603, time: 0.11821818351745605
Test Loss Energy: 13.3766910866745, Test Loss Force: 8.125362803081163, time: 9.631746768951416

Epoch 15, Batch 100/126, Loss: 0.16705891489982605, Uncertainty: 0.12291108071804047

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6605758816592038, Training Loss Force: 1.8429894847302029, time: 2.0659327507019043
Validation Loss Energy: 0.9882854779605754, Validation Loss Force: 2.0270926182213764, time: 0.1194906234741211
Test Loss Energy: 13.157758114506883, Test Loss Force: 8.147535968134472, time: 9.764155864715576

Epoch 16, Batch 100/126, Loss: 0.22983306646347046, Uncertainty: 0.12257648259401321

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2710332504627972, Training Loss Force: 1.8284469919687143, time: 1.8803796768188477
Validation Loss Energy: 2.2730802708951114, Validation Loss Force: 1.9608646908209397, time: 0.11912703514099121
Test Loss Energy: 12.308031701762195, Test Loss Force: 8.008799732404318, time: 9.725742101669312

Epoch 17, Batch 100/126, Loss: 0.11075067520141602, Uncertainty: 0.1213226467370987

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5933337828926226, Training Loss Force: 1.8155509148722153, time: 1.9189486503601074
Validation Loss Energy: 1.4404426969622328, Validation Loss Force: 2.0365627369976855, time: 0.11834573745727539
Test Loss Energy: 13.892744062990298, Test Loss Force: 8.12921273862457, time: 9.928009033203125

Epoch 18, Batch 100/126, Loss: 0.21787893772125244, Uncertainty: 0.12045508623123169

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7114715804097715, Training Loss Force: 1.8153434738217673, time: 1.872727870941162
Validation Loss Energy: 8.241176586252926, Validation Loss Force: 2.131125721444201, time: 0.12497568130493164
Test Loss Energy: 20.118701971648502, Test Loss Force: 8.273404778794035, time: 9.746710777282715

Epoch 19, Batch 100/126, Loss: 0.15564149618148804, Uncertainty: 0.12266869843006134

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.971459706730636, Training Loss Force: 1.8701050977330393, time: 1.914970874786377
Validation Loss Energy: 1.1578908407278905, Validation Loss Force: 2.2385111086589684, time: 0.11712360382080078
Test Loss Energy: 12.570219356307545, Test Loss Force: 8.218125664089598, time: 9.66341781616211

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–…â–â–â–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–ƒâ–ˆâ–‚
wandb:   test_error_force â–…â–ƒâ–ˆâ–„â–„â–†â–†â–ƒâ–…â–‚â–ƒâ–„â–‚â–„â–ƒâ–„â–â–ƒâ–†â–…
wandb:          test_loss â–‚â–â–…â–ƒâ–‚â–‚â–…â–ƒâ–„â–‚â–‚â–ƒâ–â–„â–‚â–‚â–â–„â–ˆâ–‚
wandb: train_error_energy â–ˆâ–ƒâ–„â–„â–„â–‚â–ƒâ–…â–ƒâ–„â–ƒâ–„â–„â–ƒâ–â–ƒâ–‡â–‚â–ƒâ–…
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–„
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–„
wandb: valid_error_energy â–‚â–‚â–ƒâ–„â–…â–ƒâ–‚â–‚â–„â–‚â–â–‚â–â–„â–â–â–‚â–â–ˆâ–
wandb:  valid_error_force â–‚â–â–…â–„â–â–…â–„â–‚â–…â–‚â–â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–„â–…
wandb:         valid_loss â–‚â–‚â–†â–†â–ƒâ–†â–„â–ƒâ–‡â–‚â–â–ˆâ–â–„â–‚â–‚â–‚â–‚â–ˆâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4003
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.57022
wandb:   test_error_force 8.21813
wandb:          test_loss 6.50989
wandb: train_error_energy 1.97146
wandb:  train_error_force 1.87011
wandb:         train_loss -2.56275
wandb: valid_error_energy 1.15789
wandb:  valid_error_force 2.23851
wandb:         valid_loss -2.11833
wandb: 
wandb: ğŸš€ View run al_69_41 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v771ppky
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_042713-v771ppky/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 36.7302360534668, Uncertainty Bias: -4.382381916046143
3.2424927e-05 0.00012588501
0.5725554 6.5924387
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1903 steps.
Found uncertainty sample 4 after 2291 steps.
Found uncertainty sample 5 after 3643 steps.
Found uncertainty sample 6 after 3456 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1550 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1677 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2366 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1158 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1457 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 630 steps.
Found uncertainty sample 28 after 802 steps.
Found uncertainty sample 29 after 1946 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3010 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1325 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3372 steps.
Found uncertainty sample 40 after 3764 steps.
Found uncertainty sample 41 after 1411 steps.
Found uncertainty sample 42 after 899 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3250 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1116 steps.
Found uncertainty sample 52 after 2010 steps.
Found uncertainty sample 53 after 376 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 776 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 872 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 487 steps.
Found uncertainty sample 68 after 1039 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2515 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 971 steps.
Found uncertainty sample 80 after 3463 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1192 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2349 steps.
Found uncertainty sample 87 after 1872 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3087 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3295 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3127 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_050555-7v3puny5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_42
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7v3puny5
Training model 42. Added 35 samples to the dataset.
Epoch 0, Batch 100/127, Loss: 0.058513104915618896, Uncertainty: 0.1255492866039276

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.9207342509474261, Training Loss Force: 2.02390452467175, time: 1.9412925243377686
Validation Loss Energy: 1.6038575791363232, Validation Loss Force: 2.5701804384477924, time: 0.12523508071899414
Test Loss Energy: 13.077299376925348, Test Loss Force: 8.03505187677989, time: 9.754164218902588

Epoch 1, Batch 100/127, Loss: 0.1319764405488968, Uncertainty: 0.12426911294460297

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8470245012947615, Training Loss Force: 1.8434519497400612, time: 1.90995454788208
Validation Loss Energy: 3.6835292112317255, Validation Loss Force: 2.2319771794639123, time: 0.12257981300354004
Test Loss Energy: 15.762129400311887, Test Loss Force: 8.149524247389461, time: 9.723571062088013

Epoch 2, Batch 100/127, Loss: 0.16077932715415955, Uncertainty: 0.12223987281322479

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.866128974875505, Training Loss Force: 1.8333181594377637, time: 1.8895013332366943
Validation Loss Energy: 5.114650606630178, Validation Loss Force: 2.0529669585358072, time: 0.12180876731872559
Test Loss Energy: 11.566772797374584, Test Loss Force: 8.073432075075713, time: 9.925406455993652

Epoch 3, Batch 100/127, Loss: 0.14659401774406433, Uncertainty: 0.12295182049274445

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.355731719725726, Training Loss Force: 1.839014596370062, time: 1.8966057300567627
Validation Loss Energy: 1.0267852516279223, Validation Loss Force: 2.1390943079464706, time: 0.1230320930480957
Test Loss Energy: 12.73009754713104, Test Loss Force: 8.030439281924577, time: 9.720455169677734

Epoch 4, Batch 100/127, Loss: 0.1339574009180069, Uncertainty: 0.12414219975471497

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0010463847047624, Training Loss Force: 1.8719973443861908, time: 1.8736951351165771
Validation Loss Energy: 3.0371960912207783, Validation Loss Force: 2.3778563468348484, time: 0.1250472068786621
Test Loss Energy: 15.310166311985405, Test Loss Force: 8.131172875297452, time: 9.93217945098877

Epoch 5, Batch 100/127, Loss: 0.05590811371803284, Uncertainty: 0.12247983366250992

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7038839893809181, Training Loss Force: 1.8184351798996972, time: 1.8949644565582275
Validation Loss Energy: 2.5534408400643787, Validation Loss Force: 2.1273338143351483, time: 0.11765146255493164
Test Loss Energy: 11.911539680602015, Test Loss Force: 8.037807874949374, time: 9.694356918334961

Epoch 6, Batch 100/127, Loss: 0.07252821326255798, Uncertainty: 0.12062080949544907

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5184745068980412, Training Loss Force: 1.8086105385303641, time: 1.9006800651550293
Validation Loss Energy: 1.0565376163435933, Validation Loss Force: 2.0270877195001664, time: 0.12086915969848633
Test Loss Energy: 12.467101517316252, Test Loss Force: 7.985803167160352, time: 9.756149768829346

Epoch 7, Batch 100/127, Loss: 0.3792608380317688, Uncertainty: 0.12176503241062164

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1000452213308973, Training Loss Force: 1.8302134528533363, time: 1.9873249530792236
Validation Loss Energy: 3.4710972792879677, Validation Loss Force: 2.1676531845957308, time: 0.11743950843811035
Test Loss Energy: 15.331011417630434, Test Loss Force: 8.159894250293537, time: 9.90470838546753

Epoch 8, Batch 100/127, Loss: 0.045792657881975174, Uncertainty: 0.1212855875492096

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6598009047888809, Training Loss Force: 1.8283844011495753, time: 1.8609161376953125
Validation Loss Energy: 1.0701534820575966, Validation Loss Force: 2.0397862440002332, time: 0.12167024612426758
Test Loss Energy: 13.292388011754996, Test Loss Force: 8.104034078704093, time: 9.72387957572937

Epoch 9, Batch 100/127, Loss: 0.09263227880001068, Uncertainty: 0.12096060067415237

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.729671488144003, Training Loss Force: 1.8442526399360117, time: 1.884371042251587
Validation Loss Energy: 1.8677482022578955, Validation Loss Force: 2.0839781276006946, time: 0.12304997444152832
Test Loss Energy: 14.293026160165265, Test Loss Force: 8.194366059480627, time: 9.759835481643677

Epoch 10, Batch 100/127, Loss: 0.060612354427576065, Uncertainty: 0.12241519242525101

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7675670797666314, Training Loss Force: 1.8294325959910767, time: 2.096839427947998
Validation Loss Energy: 1.145937311522811, Validation Loss Force: 1.9560345888189985, time: 0.12385702133178711
Test Loss Energy: 12.656545022515036, Test Loss Force: 7.945594890150674, time: 9.751744031906128

Epoch 11, Batch 100/127, Loss: 0.25678372383117676, Uncertainty: 0.12309278547763824

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.855646020504413, Training Loss Force: 1.853856894956488, time: 1.9673662185668945
Validation Loss Energy: 1.0431232105393684, Validation Loss Force: 2.0661405476587116, time: 0.12067270278930664
Test Loss Energy: 12.698707436954535, Test Loss Force: 8.016835824575027, time: 9.75732970237732

Epoch 12, Batch 100/127, Loss: 0.1255735456943512, Uncertainty: 0.12169376015663147

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9355907183923993, Training Loss Force: 1.8330787813393896, time: 1.9357655048370361
Validation Loss Energy: 1.1727275642574913, Validation Loss Force: 2.0667041974901035, time: 0.1259453296661377
Test Loss Energy: 13.127120439514485, Test Loss Force: 8.013691400482095, time: 9.952008247375488

Epoch 13, Batch 100/127, Loss: 0.13400296866893768, Uncertainty: 0.12346619367599487

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3840761480161294, Training Loss Force: 1.8336739768431043, time: 1.8816540241241455
Validation Loss Energy: 4.803813385680823, Validation Loss Force: 1.972909013370271, time: 0.1173095703125
Test Loss Energy: 16.77083561431693, Test Loss Force: 8.107025138548408, time: 9.786885023117065

Epoch 14, Batch 100/127, Loss: 0.16140669584274292, Uncertainty: 0.12002044916152954

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7894131742198118, Training Loss Force: 1.8265087616252556, time: 1.892866611480713
Validation Loss Energy: 1.0579712901954117, Validation Loss Force: 2.227184968328303, time: 0.12505722045898438
Test Loss Energy: 12.9590104944604, Test Loss Force: 8.038808074441897, time: 9.675970554351807

Epoch 15, Batch 100/127, Loss: 0.19540849328041077, Uncertainty: 0.12067652493715286

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5303349951739131, Training Loss Force: 1.8382669189638459, time: 1.9096052646636963
Validation Loss Energy: 2.865600047733107, Validation Loss Force: 2.5307103283097785, time: 0.12230205535888672
Test Loss Energy: 12.462458261735607, Test Loss Force: 8.116959250860937, time: 10.686331748962402

Epoch 16, Batch 100/127, Loss: 0.09198574721813202, Uncertainty: 0.1216978132724762

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8781018650459356, Training Loss Force: 1.8388820196865663, time: 1.9396142959594727
Validation Loss Energy: 3.5814471350655204, Validation Loss Force: 2.454552062119924, time: 0.12557506561279297
Test Loss Energy: 15.099911551515001, Test Loss Force: 8.120121810248284, time: 9.732246160507202

Epoch 17, Batch 100/127, Loss: 0.12093523144721985, Uncertainty: 0.12136058509349823

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6648587395412484, Training Loss Force: 1.8172551395009517, time: 1.9845349788665771
Validation Loss Energy: 1.6737593618869469, Validation Loss Force: 2.013614009480076, time: 0.12688016891479492
Test Loss Energy: 14.25267234613549, Test Loss Force: 8.06727310945293, time: 10.042036533355713

Epoch 18, Batch 100/127, Loss: 0.05304098129272461, Uncertainty: 0.12185343354940414

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5499697386693299, Training Loss Force: 1.8191096841919703, time: 1.887380599975586
Validation Loss Energy: 0.8843568622344775, Validation Loss Force: 1.9563213495674292, time: 0.1186060905456543
Test Loss Energy: 13.13904576425253, Test Loss Force: 7.950808043511278, time: 9.777926921844482

Epoch 19, Batch 100/127, Loss: 0.03491932153701782, Uncertainty: 0.12121669948101044

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4552722293304006, Training Loss Force: 1.8300631915057433, time: 1.9279794692993164
Validation Loss Energy: 1.8928891446286882, Validation Loss Force: 2.056143148344846, time: 0.11860179901123047
Test Loss Energy: 11.94985135509124, Test Loss Force: 8.06538142663822, time: 9.741682052612305

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‡â–â–ƒâ–†â–â–‚â–†â–ƒâ–…â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–†â–…â–ƒâ–‚
wandb:   test_error_force â–„â–‡â–…â–ƒâ–†â–„â–‚â–‡â–…â–ˆâ–â–ƒâ–ƒâ–†â–„â–†â–†â–„â–â–„
wandb:          test_loss â–â–‡â–„â–ƒâ–…â–ƒâ–„â–ˆâ–…â–ˆâ–‚â–‚â–ƒâ–‡â–…â–…â–‡â–…â–„â–ƒ
wandb: train_error_energy â–…â–„â–„â–ˆâ–…â–ƒâ–â–†â–ƒâ–ƒâ–ƒâ–„â–…â–ˆâ–„â–‚â–„â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–„â–‚â–â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb: valid_error_energy â–‚â–†â–ˆâ–â–…â–„â–â–…â–â–ƒâ–â–â–â–‡â–â–„â–…â–‚â–â–ƒ
wandb:  valid_error_force â–ˆâ–„â–‚â–ƒâ–†â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–„â–ˆâ–‡â–‚â–â–‚
wandb:         valid_loss â–ˆâ–…â–„â–ƒâ–†â–„â–‚â–…â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–ˆâ–ˆâ–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4034
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 11.94985
wandb:   test_error_force 8.06538
wandb:          test_loss 6.39813
wandb: train_error_energy 1.45527
wandb:  train_error_force 1.83006
wandb:         train_loss -2.65208
wandb: valid_error_energy 1.89289
wandb:  valid_error_force 2.05614
wandb:         valid_loss -2.31137
wandb: 
wandb: ğŸš€ View run al_69_42 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7v3puny5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_050555-7v3puny5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 24.877565383911133, Uncertainty Bias: -2.8809866905212402
0.00015068054 0.026732445
0.9625399 5.084523
(48745, 22, 3)
Found uncertainty sample 0 after 1482 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3890 steps.
Found uncertainty sample 7 after 1052 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2926 steps.
Found uncertainty sample 11 after 3465 steps.
Found uncertainty sample 12 after 2052 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1834 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1366 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1520 steps.
Found uncertainty sample 20 after 2490 steps.
Found uncertainty sample 21 after 382 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 980 steps.
Found uncertainty sample 24 after 2589 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3269 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1692 steps.
Found uncertainty sample 31 after 1845 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2975 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3585 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1086 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1954 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1316 steps.
Found uncertainty sample 49 after 1346 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1606 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 378 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3891 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3220 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1427 steps.
Found uncertainty sample 71 after 629 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1290 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2731 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3942 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1896 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2052 steps.
Found uncertainty sample 87 after 1698 steps.
Found uncertainty sample 88 after 3160 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1230 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 924 steps.
Found uncertainty sample 95 after 3646 steps.
Found uncertainty sample 96 after 1284 steps.
Found uncertainty sample 97 after 1573 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_054352-1lp6ex8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_43
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1lp6ex8u
Training model 43. Added 40 samples to the dataset.
Epoch 0, Batch 100/128, Loss: 0.0730065405368805, Uncertainty: 0.12416679412126541

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0290944758501754, Training Loss Force: 1.9572996682050967, time: 1.9828319549560547
Validation Loss Energy: 2.201047321748813, Validation Loss Force: 2.072467394548055, time: 0.12789368629455566
Test Loss Energy: 11.983773579520358, Test Loss Force: 7.848045966861595, time: 9.820603847503662

Epoch 1, Batch 100/128, Loss: 0.38576072454452515, Uncertainty: 0.12290238589048386

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5058942079287676, Training Loss Force: 1.8575518190687648, time: 1.90144681930542
Validation Loss Energy: 0.9568924498661842, Validation Loss Force: 2.1057734289423986, time: 0.11961555480957031
Test Loss Energy: 12.93189856039301, Test Loss Force: 8.04845049017326, time: 9.788433313369751

Epoch 2, Batch 100/128, Loss: 0.047096386551856995, Uncertainty: 0.12302111089229584

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4783189052569394, Training Loss Force: 1.8600461579716463, time: 1.9433722496032715
Validation Loss Energy: 2.5997390253392196, Validation Loss Force: 2.102543984095959, time: 0.139817476272583
Test Loss Energy: 14.237292086929225, Test Loss Force: 8.09667671473277, time: 9.891924619674683

Epoch 3, Batch 100/128, Loss: 0.07956619560718536, Uncertainty: 0.12283635139465332

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.080805797245219, Training Loss Force: 1.8180288458838254, time: 1.8978393077850342
Validation Loss Energy: 1.549870201470066, Validation Loss Force: 2.3057846161456337, time: 0.13451099395751953
Test Loss Energy: 12.90331376901891, Test Loss Force: 7.911416563561145, time: 9.973016023635864

Epoch 4, Batch 100/128, Loss: 0.12142941355705261, Uncertainty: 0.12144584953784943

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7292097797832109, Training Loss Force: 1.8291522369691764, time: 1.9042317867279053
Validation Loss Energy: 1.8960052508798502, Validation Loss Force: 2.0647075232585688, time: 0.12714505195617676
Test Loss Energy: 12.309199560629343, Test Loss Force: 8.007096196857265, time: 9.958979606628418

Epoch 5, Batch 100/128, Loss: 0.10041267424821854, Uncertainty: 0.12252278625965118

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5467504843835609, Training Loss Force: 1.8388705248576285, time: 1.909632682800293
Validation Loss Energy: 2.263207417856868, Validation Loss Force: 2.141142270304617, time: 0.12797832489013672
Test Loss Energy: 14.072389855301024, Test Loss Force: 7.912944262762952, time: 9.82631778717041

Epoch 6, Batch 100/128, Loss: 0.09731430560350418, Uncertainty: 0.12205755710601807

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.70996676916412, Training Loss Force: 1.8470886698347326, time: 1.9063606262207031
Validation Loss Energy: 1.1743663535042332, Validation Loss Force: 2.0247189280142623, time: 0.12282299995422363
Test Loss Energy: 13.625057902825132, Test Loss Force: 8.001413426107252, time: 9.817252159118652

Epoch 7, Batch 100/128, Loss: 0.0960167869925499, Uncertainty: 0.12169873714447021

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8689475784445535, Training Loss Force: 1.8525307837829321, time: 1.8879141807556152
Validation Loss Energy: 1.5771205443275196, Validation Loss Force: 2.1020278370156986, time: 0.12300419807434082
Test Loss Energy: 13.492399865605561, Test Loss Force: 7.968450056989555, time: 10.671501874923706

Epoch 8, Batch 100/128, Loss: 0.12099502235651016, Uncertainty: 0.12282779812812805

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5528804807304206, Training Loss Force: 1.8370127709489137, time: 1.9946951866149902
Validation Loss Energy: 4.643856184227748, Validation Loss Force: 2.450027647743817, time: 0.12568426132202148
Test Loss Energy: 15.874687870156048, Test Loss Force: 8.001916171069704, time: 9.826965808868408

Epoch 9, Batch 100/128, Loss: 0.19212061166763306, Uncertainty: 0.12418220937252045

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7482399852385984, Training Loss Force: 1.8524986768056524, time: 1.9404737949371338
Validation Loss Energy: 1.604439042499389, Validation Loss Force: 2.0908603855630306, time: 0.11920475959777832
Test Loss Energy: 11.844048074904551, Test Loss Force: 7.938397927239298, time: 9.96521782875061

Epoch 10, Batch 100/128, Loss: 0.10524684190750122, Uncertainty: 0.1220552921295166

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4220016192694853, Training Loss Force: 1.8217292165483385, time: 1.9363715648651123
Validation Loss Energy: 0.9912155070287905, Validation Loss Force: 2.098134244330005, time: 0.12435173988342285
Test Loss Energy: 12.94550251204475, Test Loss Force: 7.999409462084254, time: 9.731382846832275

Epoch 11, Batch 100/128, Loss: 0.18526074290275574, Uncertainty: 0.12333105504512787

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7837988648591174, Training Loss Force: 1.842298922556418, time: 1.9795210361480713
Validation Loss Energy: 2.7724843385120734, Validation Loss Force: 2.1930773992316683, time: 0.12499284744262695
Test Loss Energy: 11.762785993676788, Test Loss Force: 7.886541482127253, time: 9.72405219078064

Epoch 12, Batch 100/128, Loss: 0.05551806837320328, Uncertainty: 0.12188368290662766

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.556739674077373, Training Loss Force: 1.8299988894272938, time: 1.9790267944335938
Validation Loss Energy: 1.6764243404484596, Validation Loss Force: 1.9742972441605577, time: 0.12141013145446777
Test Loss Energy: 12.129800513711675, Test Loss Force: 7.8419447786360506, time: 9.899035930633545

Epoch 13, Batch 100/128, Loss: 0.060749806463718414, Uncertainty: 0.12210254371166229

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4051924159027371, Training Loss Force: 1.8320121455517893, time: 1.9390850067138672
Validation Loss Energy: 1.6846986887996118, Validation Loss Force: 1.9205239443223483, time: 0.12753677368164062
Test Loss Energy: 12.090295225346024, Test Loss Force: 7.788473853977253, time: 9.872493743896484

Epoch 14, Batch 100/128, Loss: 0.040460005402565, Uncertainty: 0.12258191406726837

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5042784571104169, Training Loss Force: 1.839580099232188, time: 1.9048514366149902
Validation Loss Energy: 0.9000499712993167, Validation Loss Force: 2.0438036778425865, time: 0.12188315391540527
Test Loss Energy: 12.848528975155205, Test Loss Force: 7.891415642114803, time: 9.69296145439148

Epoch 15, Batch 100/128, Loss: 0.08108910918235779, Uncertainty: 0.12107928097248077

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.433165470469393, Training Loss Force: 1.8182487081807928, time: 2.0862362384796143
Validation Loss Energy: 0.8874531323758897, Validation Loss Force: 1.9433116449359276, time: 0.1236732006072998
Test Loss Energy: 12.796072988121615, Test Loss Force: 7.816075347729394, time: 9.850432634353638

Epoch 16, Batch 100/128, Loss: 0.07599832117557526, Uncertainty: 0.12091794610023499

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3950436681094438, Training Loss Force: 1.8104812603416693, time: 1.960057258605957
Validation Loss Energy: 1.9800841925940753, Validation Loss Force: 1.9524522133762636, time: 0.12055802345275879
Test Loss Energy: 11.77095033628071, Test Loss Force: 7.86757304137056, time: 9.814798593521118

Epoch 17, Batch 100/128, Loss: 0.1458197683095932, Uncertainty: 0.12215150892734528

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.821749470307704, Training Loss Force: 1.8247792097786575, time: 1.9052026271820068
Validation Loss Energy: 1.2147261011032773, Validation Loss Force: 1.9892115493317524, time: 0.12351155281066895
Test Loss Energy: 13.020305900989625, Test Loss Force: 7.846623777860748, time: 9.977225542068481

Epoch 18, Batch 100/128, Loss: 0.15205463767051697, Uncertainty: 0.12175758183002472

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.449182857134414, Training Loss Force: 1.8207613503135094, time: 1.951937198638916
Validation Loss Energy: 1.7172063986385175, Validation Loss Force: 2.3056044768065784, time: 0.1203157901763916
Test Loss Energy: 13.017383572465553, Test Loss Force: 7.844358586789559, time: 9.849539995193481

Epoch 19, Batch 100/128, Loss: 0.19460342824459076, Uncertainty: 0.12033309042453766

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8508847456117286, Training Loss Force: 1.8359824068775912, time: 1.9436733722686768
Validation Loss Energy: 2.9622643609097428, Validation Loss Force: 2.530641820435881, time: 0.12709593772888184
Test Loss Energy: 13.63993541473733, Test Loss Force: 7.9178912367270256, time: 9.727225065231323

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–…â–ƒâ–‚â–…â–„â–„â–ˆâ–â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–„
wandb:   test_error_force â–‚â–‡â–ˆâ–„â–†â–„â–†â–…â–†â–„â–†â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–‚â–‚â–„
wandb:          test_loss â–â–…â–‡â–†â–‡â–…â–‡â–†â–ˆâ–ƒâ–†â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–„â–…â–†
wandb: train_error_energy â–ˆâ–â–â–„â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–â–â–â–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–‚
wandb: valid_error_energy â–ƒâ–â–„â–‚â–ƒâ–„â–‚â–‚â–ˆâ–‚â–â–…â–‚â–‚â–â–â–ƒâ–‚â–ƒâ–…
wandb:  valid_error_force â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‡â–ƒâ–ƒâ–„â–‚â–â–‚â–â–â–‚â–…â–ˆ
wandb:         valid_loss â–ƒâ–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–‚â–â–‚â–â–‚â–‚â–…â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4070
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.63994
wandb:   test_error_force 7.91789
wandb:          test_loss 6.35723
wandb: train_error_energy 1.85088
wandb:  train_error_force 1.83598
wandb:         train_loss -2.61744
wandb: valid_error_energy 2.96226
wandb:  valid_error_force 2.53064
wandb:         valid_loss -1.58483
wandb: 
wandb: ğŸš€ View run al_69_43 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1lp6ex8u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_054352-1lp6ex8u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.726158142089844, Uncertainty Bias: -5.037014007568359
0.0 0.08113432
0.06330929 6.890694
(48745, 22, 3)
Found uncertainty sample 0 after 1427 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2343 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2062 steps.
Found uncertainty sample 6 after 1189 steps.
Found uncertainty sample 7 after 2375 steps.
Found uncertainty sample 8 after 1734 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2421 steps.
Found uncertainty sample 12 after 573 steps.
Found uncertainty sample 13 after 3476 steps.
Found uncertainty sample 14 after 832 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 676 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1667 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1894 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2415 steps.
Found uncertainty sample 24 after 244 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 613 steps.
Found uncertainty sample 30 after 1063 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 249 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1072 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 571 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3021 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3910 steps.
Found uncertainty sample 43 after 1459 steps.
Found uncertainty sample 44 after 1607 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1492 steps.
Found uncertainty sample 48 after 3606 steps.
Found uncertainty sample 49 after 2206 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3664 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2715 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1514 steps.
Found uncertainty sample 56 after 540 steps.
Found uncertainty sample 57 after 1216 steps.
Found uncertainty sample 58 after 684 steps.
Found uncertainty sample 59 after 1389 steps.
Found uncertainty sample 60 after 3223 steps.
Found uncertainty sample 61 after 1306 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3578 steps.
Found uncertainty sample 64 after 1377 steps.
Found uncertainty sample 65 after 2745 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2708 steps.
Found uncertainty sample 68 after 2011 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 581 steps.
Found uncertainty sample 72 after 2014 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3098 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 343 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 477 steps.
Found uncertainty sample 84 after 746 steps.
Found uncertainty sample 85 after 977 steps.
Found uncertainty sample 86 after 588 steps.
Found uncertainty sample 87 after 2813 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2026 steps.
Found uncertainty sample 90 after 1874 steps.
Found uncertainty sample 91 after 2592 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 948 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 690 steps.
Found uncertainty sample 98 after 2855 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_061715-i2lsar2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_44
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/i2lsar2h
Training model 44. Added 56 samples to the dataset.
Epoch 0, Batch 100/129, Loss: 0.1578759253025055, Uncertainty: 0.12329618632793427

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.758005935164617, Training Loss Force: 1.9842690020002935, time: 1.9773423671722412
Validation Loss Energy: 0.9873270542892157, Validation Loss Force: 2.038040814788354, time: 0.12441492080688477
Test Loss Energy: 11.954499702917067, Test Loss Force: 7.865675671749075, time: 9.739083528518677

Epoch 1, Batch 100/129, Loss: 0.07033704221248627, Uncertainty: 0.12340997159481049

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6612399453707827, Training Loss Force: 1.84310955832738, time: 1.9210524559020996
Validation Loss Energy: 1.2372532045930729, Validation Loss Force: 2.209072763106342, time: 0.1209871768951416
Test Loss Energy: 11.995901540176042, Test Loss Force: 7.9253118060931955, time: 9.71674108505249

Epoch 2, Batch 100/129, Loss: 0.20021164417266846, Uncertainty: 0.12325919419527054

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7797621031643087, Training Loss Force: 1.857589543014149, time: 1.9003722667694092
Validation Loss Energy: 2.0262998789503492, Validation Loss Force: 2.056987658192301, time: 0.12184882164001465
Test Loss Energy: 11.973942855639963, Test Loss Force: 7.852073492124047, time: 9.807924032211304

Epoch 3, Batch 100/129, Loss: 0.12874725461006165, Uncertainty: 0.12343709170818329

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.927792710611433, Training Loss Force: 1.850616097721262, time: 1.9419772624969482
Validation Loss Energy: 2.3588844160404605, Validation Loss Force: 2.046337392942575, time: 0.1179039478302002
Test Loss Energy: 14.028148555082863, Test Loss Force: 7.862709119500495, time: 9.701813459396362

Epoch 4, Batch 100/129, Loss: 0.10378976911306381, Uncertainty: 0.12401457130908966

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6309655362947189, Training Loss Force: 1.85456696211957, time: 1.922121524810791
Validation Loss Energy: 1.9718554543063138, Validation Loss Force: 1.9613708920126822, time: 0.12462759017944336
Test Loss Energy: 11.887888827137592, Test Loss Force: 7.768901455221926, time: 9.886103391647339

Epoch 5, Batch 100/129, Loss: 0.08906413614749908, Uncertainty: 0.12256478518247604

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6247909105214366, Training Loss Force: 1.8450614648408197, time: 1.9173557758331299
Validation Loss Energy: 2.7461836981177634, Validation Loss Force: 1.9993812945645661, time: 0.12353730201721191
Test Loss Energy: 11.630275384416354, Test Loss Force: 7.847911250862504, time: 9.690422296524048

Epoch 6, Batch 100/129, Loss: 0.05354166775941849, Uncertainty: 0.12356726825237274

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1354919419064773, Training Loss Force: 1.8473447850339773, time: 1.9106881618499756
Validation Loss Energy: 2.7965439623987165, Validation Loss Force: 2.1043568078360058, time: 0.12289571762084961
Test Loss Energy: 14.297531314243153, Test Loss Force: 7.84444330831926, time: 9.711355924606323

Epoch 7, Batch 100/129, Loss: 0.050679195672273636, Uncertainty: 0.12163984775543213

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3782226471866363, Training Loss Force: 1.8344408137244432, time: 1.9166483879089355
Validation Loss Energy: 2.056756750287974, Validation Loss Force: 2.3091898582827834, time: 0.12130355834960938
Test Loss Energy: 12.25657378079424, Test Loss Force: 7.785840190936027, time: 9.936694383621216

Epoch 8, Batch 100/129, Loss: 0.0772903636097908, Uncertainty: 0.12395396828651428

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9725811006881908, Training Loss Force: 1.8797163486567343, time: 1.9150097370147705
Validation Loss Energy: 1.2011403699470231, Validation Loss Force: 2.068660568606225, time: 0.11999011039733887
Test Loss Energy: 12.82478826128362, Test Loss Force: 7.802738333248762, time: 9.789172172546387

Epoch 9, Batch 100/129, Loss: 0.14747905731201172, Uncertainty: 0.12453708797693253

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1429442246833306, Training Loss Force: 1.864163240228221, time: 1.9636802673339844
Validation Loss Energy: 2.874359555041712, Validation Loss Force: 2.1933327265189986, time: 0.1223139762878418
Test Loss Energy: 14.318127576042443, Test Loss Force: 7.844665683681812, time: 9.827550649642944

Epoch 10, Batch 100/129, Loss: 0.18874669075012207, Uncertainty: 0.12211276590824127

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8880959729087405, Training Loss Force: 1.8400561843612604, time: 2.157698392868042
Validation Loss Energy: 2.9766285990674475, Validation Loss Force: 2.0820073572131363, time: 0.11999106407165527
Test Loss Energy: 11.531623873465064, Test Loss Force: 7.803529018562074, time: 9.794090032577515

Epoch 11, Batch 100/129, Loss: 0.08082994818687439, Uncertainty: 0.12375009059906006

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8592044889695734, Training Loss Force: 1.869536095684185, time: 1.9245531558990479
Validation Loss Energy: 2.3700094861323535, Validation Loss Force: 2.051803326690713, time: 0.12334275245666504
Test Loss Energy: 14.049063515886134, Test Loss Force: 7.7605070685767, time: 9.832045316696167

Epoch 12, Batch 100/129, Loss: 0.04607398062944412, Uncertainty: 0.1235513761639595

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9742554678039352, Training Loss Force: 1.8500157454553752, time: 1.9556105136871338
Validation Loss Energy: 2.320309138976882, Validation Loss Force: 1.9598696937423614, time: 0.12538957595825195
Test Loss Energy: 14.097066819485393, Test Loss Force: 7.750556460094462, time: 9.972562789916992

Epoch 13, Batch 100/129, Loss: 0.05620424076914787, Uncertainty: 0.12218501418828964

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.523412932318888, Training Loss Force: 1.8275603612809186, time: 1.891486406326294
Validation Loss Energy: 3.2715735519566924, Validation Loss Force: 2.3923012654464277, time: 0.12873125076293945
Test Loss Energy: 14.584999396669318, Test Loss Force: 7.818286529291722, time: 9.887588739395142

Epoch 14, Batch 100/129, Loss: 0.0376775786280632, Uncertainty: 0.12193703651428223

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3749377585859197, Training Loss Force: 1.8118872807879205, time: 1.9314861297607422
Validation Loss Energy: 1.4068029928527166, Validation Loss Force: 1.967766840560312, time: 0.12249636650085449
Test Loss Energy: 13.44648809445981, Test Loss Force: 7.749567312452741, time: 9.834859371185303

Epoch 15, Batch 100/129, Loss: 0.06322237104177475, Uncertainty: 0.12096960842609406

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4057874454833101, Training Loss Force: 1.8227475256314325, time: 2.1184353828430176
Validation Loss Energy: 1.1741114158879082, Validation Loss Force: 1.9909011999225765, time: 0.15132737159729004
Test Loss Energy: 12.99803367964317, Test Loss Force: 7.74034106885254, time: 10.567764520645142

Epoch 16, Batch 100/129, Loss: 0.13164405524730682, Uncertainty: 0.1237245500087738

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8027239573732943, Training Loss Force: 1.8613596527125449, time: 1.9517109394073486
Validation Loss Energy: 1.2556109396599433, Validation Loss Force: 1.96439455345676, time: 0.1208031177520752
Test Loss Energy: 12.650699148364344, Test Loss Force: 7.7507635960273, time: 9.779045343399048

Epoch 17, Batch 100/129, Loss: 0.13092325627803802, Uncertainty: 0.12140747904777527

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5824352650121638, Training Loss Force: 1.8279796878464598, time: 1.901977300643921
Validation Loss Energy: 1.2059906235066709, Validation Loss Force: 2.116899167041729, time: 0.12108469009399414
Test Loss Energy: 12.091150596629133, Test Loss Force: 7.75572601460313, time: 10.11617398262024

Epoch 18, Batch 100/129, Loss: 0.07141119241714478, Uncertainty: 0.12132318317890167

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6893231165761178, Training Loss Force: 1.8467897606112846, time: 1.8844404220581055
Validation Loss Energy: 3.311444318111279, Validation Loss Force: 2.3783960226215286, time: 0.11978626251220703
Test Loss Energy: 14.244273900150125, Test Loss Force: 7.774951357263871, time: 9.774717092514038

Epoch 19, Batch 100/129, Loss: 0.0927128940820694, Uncertainty: 0.12197883427143097

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.035404339603638, Training Loss Force: 1.838124736654426, time: 1.9847474098205566
Validation Loss Energy: 1.0954807242804827, Validation Loss Force: 1.987937696259424, time: 0.11989188194274902
Test Loss Energy: 12.69871138204558, Test Loss Force: 7.7505161581448565, time: 9.716282606124878

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–‡â–‚â–â–‡â–ƒâ–„â–‡â–â–‡â–‡â–ˆâ–…â–„â–„â–‚â–‡â–„
wandb:   test_error_force â–†â–ˆâ–…â–†â–‚â–…â–…â–ƒâ–ƒâ–…â–ƒâ–‚â–â–„â–â–â–â–‚â–‚â–
wandb:          test_loss â–„â–†â–ƒâ–…â–‚â–…â–‡â–ƒâ–„â–†â–„â–‚â–…â–ˆâ–†â–„â–â–„â–†â–ƒ
wandb: train_error_energy â–ˆâ–‚â–ƒâ–„â–‚â–‚â–…â–â–„â–…â–„â–ƒâ–„â–‚â–â–â–ƒâ–‚â–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–â–ƒâ–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–‚â–â–â–ƒâ–‚â–‚â–ƒ
wandb: valid_error_energy â–â–‚â–„â–…â–„â–†â–†â–„â–‚â–‡â–‡â–…â–…â–ˆâ–‚â–‚â–‚â–‚â–ˆâ–
wandb:  valid_error_force â–‚â–…â–ƒâ–‚â–â–‚â–ƒâ–‡â–ƒâ–…â–ƒâ–‚â–â–ˆâ–â–‚â–â–„â–ˆâ–
wandb:         valid_loss â–‚â–„â–ƒâ–ƒâ–â–‚â–„â–†â–‚â–…â–„â–ƒâ–‚â–ˆâ–â–â–â–ƒâ–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4120
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.69871
wandb:   test_error_force 7.75052
wandb:          test_loss 5.99913
wandb: train_error_energy 2.0354
wandb:  train_error_force 1.83812
wandb:         train_loss -2.60238
wandb: valid_error_energy 1.09548
wandb:  valid_error_force 1.98794
wandb:         valid_loss -2.46107
wandb: 
wandb: ğŸš€ View run al_69_44 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/i2lsar2h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_061715-i2lsar2h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 45.63010787963867, Uncertainty Bias: -5.4607744216918945
2.670288e-05 0.0003709793
0.12334089 6.856357
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2118 steps.
Found uncertainty sample 4 after 3572 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2672 steps.
Found uncertainty sample 7 after 2591 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 433 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2902 steps.
Found uncertainty sample 13 after 1247 steps.
Found uncertainty sample 14 after 1535 steps.
Found uncertainty sample 15 after 2843 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2252 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 724 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3881 steps.
Found uncertainty sample 26 after 2611 steps.
Found uncertainty sample 27 after 2177 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2732 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2512 steps.
Found uncertainty sample 33 after 755 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2643 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 657 steps.
Found uncertainty sample 42 after 46 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1032 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1751 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1705 steps.
Found uncertainty sample 58 after 2932 steps.
Found uncertainty sample 59 after 964 steps.
Found uncertainty sample 60 after 3176 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3619 steps.
Found uncertainty sample 65 after 3132 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 561 steps.
Found uncertainty sample 68 after 1865 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1012 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2922 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1559 steps.
Found uncertainty sample 77 after 1891 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3241 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1661 steps.
Found uncertainty sample 83 after 3098 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 961 steps.
Found uncertainty sample 90 after 1658 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 990 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_065505-o0cs26k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_45
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/o0cs26k9
Training model 45. Added 40 samples to the dataset.
Epoch 0, Batch 100/130, Loss: 0.10713381320238113, Uncertainty: 0.12527886033058167

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3547453210580276, Training Loss Force: 2.0235306150071812, time: 2.008620262145996
Validation Loss Energy: 2.1492620491569707, Validation Loss Force: 2.051150126751134, time: 0.1276845932006836
Test Loss Energy: 13.824264454473632, Test Loss Force: 7.783320492528464, time: 9.768843173980713

Epoch 1, Batch 100/130, Loss: 0.2107294201850891, Uncertainty: 0.12466888129711151

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.881623643672344, Training Loss Force: 1.8484871415724584, time: 1.9595005512237549
Validation Loss Energy: 0.9843787477952723, Validation Loss Force: 2.0227687916342267, time: 0.12058115005493164
Test Loss Energy: 12.328468317944504, Test Loss Force: 7.790588096352031, time: 9.77876091003418

Epoch 2, Batch 100/130, Loss: 0.06012103706598282, Uncertainty: 0.12201419472694397

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7343799339398314, Training Loss Force: 1.8282172343585132, time: 1.9811954498291016
Validation Loss Energy: 3.777761383550441, Validation Loss Force: 1.997594820006788, time: 0.12249112129211426
Test Loss Energy: 15.263856711516564, Test Loss Force: 7.769000101150992, time: 9.983798265457153

Epoch 3, Batch 100/130, Loss: 0.16880306601524353, Uncertainty: 0.12337879836559296

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.5021341254317058, Training Loss Force: 1.8432919852101726, time: 1.9793097972869873
Validation Loss Energy: 2.450800235457138, Validation Loss Force: 1.951109963764611, time: 0.12230825424194336
Test Loss Energy: 11.262845664533387, Test Loss Force: 7.706341420845837, time: 9.816251039505005

Epoch 4, Batch 100/130, Loss: 0.06924954056739807, Uncertainty: 0.122063547372818

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9423417926279167, Training Loss Force: 1.8313823024146592, time: 1.9839625358581543
Validation Loss Energy: 1.6754666775633484, Validation Loss Force: 1.9909924200493585, time: 0.12033915519714355
Test Loss Energy: 11.352759092600772, Test Loss Force: 7.652853498720296, time: 9.969022274017334

Epoch 5, Batch 100/130, Loss: 0.06559545546770096, Uncertainty: 0.12303470075130463

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6972942896254926, Training Loss Force: 1.8560594435102469, time: 1.9774439334869385
Validation Loss Energy: 1.0356936318163417, Validation Loss Force: 2.1460145681097114, time: 0.12928128242492676
Test Loss Energy: 11.676366139586376, Test Loss Force: 7.8598336867306875, time: 10.604585409164429

Epoch 6, Batch 100/130, Loss: 0.16676367819309235, Uncertainty: 0.12185902148485184

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7948414430020063, Training Loss Force: 1.8389169167430792, time: 1.95599365234375
Validation Loss Energy: 3.1007552175726985, Validation Loss Force: 2.3935779761061284, time: 0.1212458610534668
Test Loss Energy: 13.794187052358216, Test Loss Force: 7.68058118642202, time: 9.793282270431519

Epoch 7, Batch 100/130, Loss: 0.1408691108226776, Uncertainty: 0.12409915775060654

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.809898112690806, Training Loss Force: 1.8740868985714814, time: 1.914480447769165
Validation Loss Energy: 1.8287117402815758, Validation Loss Force: 2.008444337030595, time: 0.12194943428039551
Test Loss Energy: 11.21838616720513, Test Loss Force: 7.642591822607004, time: 10.037376403808594

Epoch 8, Batch 100/130, Loss: 0.2350071668624878, Uncertainty: 0.12227778881788254

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.156549695997124, Training Loss Force: 1.8443270259089668, time: 1.9787256717681885
Validation Loss Energy: 2.624673367854116, Validation Loss Force: 2.297108238651509, time: 0.12981462478637695
Test Loss Energy: 11.13346107826745, Test Loss Force: 7.775696102784699, time: 9.854477405548096

Epoch 9, Batch 100/130, Loss: 0.10510225594043732, Uncertainty: 0.12319361418485641

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6428813917923142, Training Loss Force: 1.839684886355408, time: 1.8940646648406982
Validation Loss Energy: 2.9757242654427856, Validation Loss Force: 2.0023757863505276, time: 0.12209820747375488
Test Loss Energy: 14.034780696138164, Test Loss Force: 7.697625845032777, time: 9.996284246444702

Epoch 10, Batch 100/130, Loss: 0.14461496472358704, Uncertainty: 0.12235049903392792

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8287975521173714, Training Loss Force: 1.847386292720425, time: 1.980828046798706
Validation Loss Energy: 1.2006844363149736, Validation Loss Force: 2.0080547773597943, time: 0.11992120742797852
Test Loss Energy: 11.447453891741244, Test Loss Force: 7.702099459366821, time: 9.845530033111572

Epoch 11, Batch 100/130, Loss: 0.06363877654075623, Uncertainty: 0.12380175292491913

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6878320503394801, Training Loss Force: 1.8376962958702905, time: 1.9324116706848145
Validation Loss Energy: 1.3062290548118805, Validation Loss Force: 1.9764612913667812, time: 0.12718415260314941
Test Loss Energy: 11.683673837845896, Test Loss Force: 7.6477782486752535, time: 9.856162309646606

Epoch 12, Batch 100/130, Loss: 0.12280827760696411, Uncertainty: 0.12378212064504623

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7212113328912695, Training Loss Force: 1.8661265065792556, time: 1.9296984672546387
Validation Loss Energy: 2.381495131794552, Validation Loss Force: 1.9337005394787223, time: 0.12237024307250977
Test Loss Energy: 11.30410054015605, Test Loss Force: 7.622471921225087, time: 9.957451581954956

Epoch 13, Batch 100/130, Loss: 0.12570279836654663, Uncertainty: 0.1220502257347107

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4259972939025252, Training Loss Force: 1.81106118215357, time: 2.046036958694458
Validation Loss Energy: 1.7017971556232119, Validation Loss Force: 1.9575438031785726, time: 0.1235647201538086
Test Loss Energy: 12.916099230859269, Test Loss Force: 7.737487728126268, time: 9.94401502609253

Epoch 14, Batch 100/130, Loss: 0.0738685205578804, Uncertainty: 0.12274063378572464

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4816732589144344, Training Loss Force: 1.83848909480523, time: 2.06461763381958
Validation Loss Energy: 1.7862543751048436, Validation Loss Force: 2.0944707430951044, time: 0.12280106544494629
Test Loss Energy: 12.93816218517761, Test Loss Force: 7.7601323781918765, time: 9.990615367889404

Epoch 15, Batch 100/130, Loss: 0.044162653386592865, Uncertainty: 0.1217743456363678

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6152596285207284, Training Loss Force: 1.8405823029628825, time: 1.9415638446807861
Validation Loss Energy: 1.6270968898893683, Validation Loss Force: 1.924826134890819, time: 0.12480854988098145
Test Loss Energy: 11.43473500214648, Test Loss Force: 7.664859341087833, time: 9.781420946121216

Epoch 16, Batch 100/130, Loss: 0.038707345724105835, Uncertainty: 0.12215353548526764

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6880844834988604, Training Loss Force: 1.8213922126437183, time: 1.9549598693847656
Validation Loss Energy: 1.938267706330847, Validation Loss Force: 2.0382490104397966, time: 0.1213066577911377
Test Loss Energy: 11.27092543483091, Test Loss Force: 7.705768240153236, time: 9.910851001739502

Epoch 17, Batch 100/130, Loss: 0.083493173122406, Uncertainty: 0.12120269238948822

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5292208683152457, Training Loss Force: 1.8169710542326771, time: 1.98714017868042
Validation Loss Energy: 1.1455356720508438, Validation Loss Force: 2.1123838078775568, time: 0.12024331092834473
Test Loss Energy: 11.750768001268213, Test Loss Force: 7.763721669590615, time: 9.948088884353638

Epoch 18, Batch 100/130, Loss: 0.17268171906471252, Uncertainty: 0.1239052563905716

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6635138287837938, Training Loss Force: 1.842940664683086, time: 1.9253947734832764
Validation Loss Energy: 4.095266506297652, Validation Loss Force: 1.9301039503221726, time: 0.12511396408081055
Test Loss Energy: 15.343466988719166, Test Loss Force: 7.634511467074347, time: 9.849314212799072

Epoch 19, Batch 100/130, Loss: 0.0963621735572815, Uncertainty: 0.12320755422115326

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3756328735156758, Training Loss Force: 1.8614770797496865, time: 1.956134557723999
Validation Loss Energy: 2.4966488517263503, Validation Loss Force: 2.07750235216425, time: 0.13003110885620117
Test Loss Energy: 14.248118913656182, Test Loss Force: 7.7544462056169, time: 10.810137271881104

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–ˆâ–â–â–‚â–…â–â–â–†â–‚â–‚â–â–„â–„â–‚â–â–‚â–ˆâ–†
wandb:   test_error_force â–†â–†â–…â–ƒâ–‚â–ˆâ–ƒâ–‚â–†â–ƒâ–ƒâ–‚â–â–„â–…â–‚â–ƒâ–…â–â–…
wandb:          test_loss â–„â–…â–ˆâ–ƒâ–ƒâ–…â–…â–â–ƒâ–†â–ƒâ–ƒâ–â–‡â–†â–„â–„â–…â–…â–…
wandb: train_error_energy â–‡â–„â–ƒâ–ˆâ–„â–ƒâ–ƒâ–ƒâ–†â–‚â–„â–ƒâ–ƒâ–â–â–‚â–ƒâ–‚â–ƒâ–‡
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–â–‚â–„
wandb: valid_error_energy â–„â–â–‡â–„â–ƒâ–â–†â–ƒâ–…â–…â–â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–â–ˆâ–„
wandb:  valid_error_force â–ƒâ–‚â–‚â–â–‚â–„â–ˆâ–‚â–‡â–‚â–‚â–‚â–â–â–„â–â–ƒâ–„â–â–ƒ
wandb:         valid_loss â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–ˆâ–‚â–†â–ƒâ–‚â–â–‚â–â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4156
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 14.24812
wandb:   test_error_force 7.75445
wandb:          test_loss 5.9917
wandb: train_error_energy 2.37563
wandb:  train_error_force 1.86148
wandb:         train_loss -2.54796
wandb: valid_error_energy 2.49665
wandb:  valid_error_force 2.0775
wandb:         valid_loss -2.24863
wandb: 
wandb: ğŸš€ View run al_69_45 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/o0cs26k9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_065505-o0cs26k9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 41.263343811035156, Uncertainty Bias: -4.981055736541748
1.5258789e-05 0.07443905
0.37093472 6.6996193
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2727 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3090 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 660 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2195 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 659 steps.
Found uncertainty sample 12 after 3568 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2866 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2097 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 511 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2514 steps.
Found uncertainty sample 29 after 3346 steps.
Found uncertainty sample 30 after 1485 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1051 steps.
Found uncertainty sample 34 after 1283 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 197 steps.
Found uncertainty sample 37 after 1750 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3038 steps.
Found uncertainty sample 42 after 3905 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1907 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3886 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 327 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2242 steps.
Found uncertainty sample 61 after 2717 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3689 steps.
Found uncertainty sample 64 after 1328 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2595 steps.
Found uncertainty sample 68 after 661 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3608 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1367 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1765 steps.
Found uncertainty sample 80 after 1145 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3554 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1808 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1019 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1673 steps.
Found uncertainty sample 89 after 699 steps.
Found uncertainty sample 90 after 1223 steps.
Found uncertainty sample 91 after 992 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3120 steps.
Found uncertainty sample 99 after 1359 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_073301-lh03guj7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_46
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lh03guj7
Training model 46. Added 40 samples to the dataset.
Epoch 0, Batch 100/131, Loss: 0.0782734602689743, Uncertainty: 0.12502089142799377

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.380055516416019, Training Loss Force: 1.9984021687534579, time: 1.9896106719970703
Validation Loss Energy: 3.4033644424647775, Validation Loss Force: 2.255841670955674, time: 0.13356590270996094
Test Loss Energy: 14.480243090485482, Test Loss Force: 7.908875901611267, time: 9.981464624404907

Epoch 1, Batch 100/131, Loss: 0.10785221308469772, Uncertainty: 0.12387172877788544

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0435700351588704, Training Loss Force: 1.8420977073264078, time: 1.9796864986419678
Validation Loss Energy: 2.9948323213083845, Validation Loss Force: 2.3214576664315776, time: 0.12071347236633301
Test Loss Energy: 13.811181413389745, Test Loss Force: 7.663983903933839, time: 9.90062665939331

Epoch 2, Batch 100/131, Loss: 0.10840784758329391, Uncertainty: 0.12275484949350357

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.385680311568249, Training Loss Force: 1.8465403579320827, time: 1.9311411380767822
Validation Loss Energy: 1.4654632495481277, Validation Loss Force: 2.0819430058299635, time: 0.12479758262634277
Test Loss Energy: 12.8017533876201, Test Loss Force: 7.718926886155715, time: 10.140237808227539

Epoch 3, Batch 100/131, Loss: 0.08488002419471741, Uncertainty: 0.12213189899921417

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5518022930088122, Training Loss Force: 1.8405770903801622, time: 1.981903314590454
Validation Loss Energy: 1.117464366608117, Validation Loss Force: 2.0814825260361847, time: 0.12573933601379395
Test Loss Energy: 12.497162071188228, Test Loss Force: 7.754417326244738, time: 9.95621132850647

Epoch 4, Batch 100/131, Loss: 0.12437418848276138, Uncertainty: 0.12205009907484055

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.010032780811772, Training Loss Force: 1.8220282405950357, time: 1.9415156841278076
Validation Loss Energy: 1.27580339426621, Validation Loss Force: 1.972038339898169, time: 0.13258147239685059
Test Loss Energy: 11.654482043385151, Test Loss Force: 7.643261795595471, time: 10.063467979431152

Epoch 5, Batch 100/131, Loss: 0.12262094020843506, Uncertainty: 0.12180259078741074

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.998180203734963, Training Loss Force: 1.8296539372930436, time: 2.064126491546631
Validation Loss Energy: 2.1596297472605146, Validation Loss Force: 2.072487063655945, time: 0.12403178215026855
Test Loss Energy: 10.899894359777884, Test Loss Force: 7.6254584600696775, time: 9.959386110305786

Epoch 6, Batch 100/131, Loss: 0.1087176501750946, Uncertainty: 0.1228279322385788

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7777361710351403, Training Loss Force: 1.835226942321554, time: 2.016162395477295
Validation Loss Energy: 1.9669849749659107, Validation Loss Force: 1.9925110607361105, time: 0.1221609115600586
Test Loss Energy: 11.31398155228921, Test Loss Force: 7.613934233577676, time: 9.954242467880249

Epoch 7, Batch 100/131, Loss: 0.09312096238136292, Uncertainty: 0.12417915463447571

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.312255343822921, Training Loss Force: 1.8512839662856526, time: 1.9241738319396973
Validation Loss Energy: 1.022117289875741, Validation Loss Force: 1.9633025097420813, time: 0.12625813484191895
Test Loss Energy: 11.544232888077286, Test Loss Force: 7.694013696821079, time: 10.262795448303223

Epoch 8, Batch 100/131, Loss: 0.44836437702178955, Uncertainty: 0.1222853884100914

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3662284100641675, Training Loss Force: 1.8480497938276266, time: 2.017988681793213
Validation Loss Energy: 2.941978682154381, Validation Loss Force: 2.275989814401901, time: 0.12276315689086914
Test Loss Energy: 14.297298926929683, Test Loss Force: 7.606710925758658, time: 10.054731607437134

Epoch 9, Batch 100/131, Loss: 0.06673989444971085, Uncertainty: 0.12115369737148285

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5799014670815987, Training Loss Force: 1.854379726072782, time: 2.020216941833496
Validation Loss Energy: 1.8604970557438054, Validation Loss Force: 2.3566128938598023, time: 0.12156486511230469
Test Loss Energy: 12.608853152610243, Test Loss Force: 7.743763474972536, time: 10.053642511367798

Epoch 10, Batch 100/131, Loss: 0.057040803134441376, Uncertainty: 0.12347643077373505

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6087564983692955, Training Loss Force: 1.8531098821782566, time: 1.982409954071045
Validation Loss Energy: 0.9372019842936492, Validation Loss Force: 2.2096047939190124, time: 0.12546229362487793
Test Loss Energy: 11.943097680982932, Test Loss Force: 7.7505794311565115, time: 9.856001615524292

Epoch 11, Batch 100/131, Loss: 0.09387123584747314, Uncertainty: 0.12298813462257385

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5846822837044179, Training Loss Force: 1.836163289876883, time: 1.9521172046661377
Validation Loss Energy: 5.776388423494701, Validation Loss Force: 2.3900788047009223, time: 0.1230783462524414
Test Loss Energy: 10.351938001085498, Test Loss Force: 7.539672327031804, time: 9.871736288070679

Epoch 12, Batch 100/131, Loss: 0.12094525247812271, Uncertainty: 0.1233755350112915

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7443379790939084, Training Loss Force: 1.849849057413298, time: 1.9889254570007324
Validation Loss Energy: 2.5294665726836745, Validation Loss Force: 1.9926525669783475, time: 0.13040518760681152
Test Loss Energy: 10.894912964194946, Test Loss Force: 7.609798206653385, time: 10.208933115005493

Epoch 13, Batch 100/131, Loss: 0.05279393121600151, Uncertainty: 0.12281478196382523

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9206993060484123, Training Loss Force: 1.8358367124289725, time: 2.0434083938598633
Validation Loss Energy: 1.586570993995938, Validation Loss Force: 1.9801752642747594, time: 0.12160420417785645
Test Loss Energy: 11.958820183832295, Test Loss Force: 7.574069181820631, time: 9.869375944137573

Epoch 14, Batch 100/131, Loss: 0.10849815607070923, Uncertainty: 0.12407855689525604

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0761855365786057, Training Loss Force: 1.8460406628721535, time: 1.9707393646240234
Validation Loss Energy: 5.377702880417332, Validation Loss Force: 2.3341884779578046, time: 0.1295320987701416
Test Loss Energy: 16.50069973914122, Test Loss Force: 7.919516152578462, time: 10.92072081565857

Epoch 15, Batch 100/131, Loss: 0.057366132736206055, Uncertainty: 0.12228365987539291

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9006392674856296, Training Loss Force: 1.8438299474991549, time: 1.9865517616271973
Validation Loss Energy: 1.136082383350815, Validation Loss Force: 2.00390095866556, time: 0.12547731399536133
Test Loss Energy: 11.747207691832655, Test Loss Force: 7.58393599209235, time: 10.0077543258667

Epoch 16, Batch 100/131, Loss: 0.13140709698200226, Uncertainty: 0.12261675298213959

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.422130301837849, Training Loss Force: 1.82975913146685, time: 2.0001842975616455
Validation Loss Energy: 1.0102684893922962, Validation Loss Force: 1.961466825303053, time: 0.12644743919372559
Test Loss Energy: 11.796743607344617, Test Loss Force: 7.622724311455866, time: 9.977417707443237

Epoch 17, Batch 100/131, Loss: 0.07413072884082794, Uncertainty: 0.12050604820251465

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9283193790756623, Training Loss Force: 1.8012158561058025, time: 2.0488858222961426
Validation Loss Energy: 5.335825642588791, Validation Loss Force: 2.1982279592461236, time: 0.12408113479614258
Test Loss Energy: 15.571811642419064, Test Loss Force: 7.701599885399537, time: 10.068617820739746

Epoch 18, Batch 100/131, Loss: 0.32177287340164185, Uncertainty: 0.12070946395397186

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.778071247730355, Training Loss Force: 1.8237376104368022, time: 1.9533352851867676
Validation Loss Energy: 1.2686710417414728, Validation Loss Force: 2.071846296077014, time: 0.12206172943115234
Test Loss Energy: 12.636823633619136, Test Loss Force: 7.715885402825013, time: 10.016385555267334

Epoch 19, Batch 100/131, Loss: 0.17043226957321167, Uncertainty: 0.12096157670021057

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0352741383269093, Training Loss Force: 1.8211496527362543, time: 1.9590420722961426
Validation Loss Energy: 0.9601419534915192, Validation Loss Force: 2.1029436752128996, time: 0.13006973266601562
Test Loss Energy: 12.111725724678273, Test Loss Force: 7.572883472115986, time: 10.062263250350952

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–…â–„â–ƒâ–â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–‡â–„â–ƒ
wandb:   test_error_force â–ˆâ–ƒâ–„â–…â–ƒâ–ƒâ–‚â–„â–‚â–…â–…â–â–‚â–‚â–ˆâ–‚â–ƒâ–„â–„â–‚
wandb:          test_loss â–†â–„â–…â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–„â–â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–‡â–…â–ƒ
wandb: train_error_energy â–…â–„â–…â–‚â–„â–„â–ƒâ–â–…â–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–â–ƒâ–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–‚â–â–â–â–‚
wandb: valid_error_energy â–…â–„â–‚â–â–â–ƒâ–‚â–â–„â–‚â–â–ˆâ–ƒâ–‚â–‡â–â–â–‡â–â–
wandb:  valid_error_force â–†â–‡â–ƒâ–ƒâ–â–ƒâ–‚â–â–†â–‡â–…â–ˆâ–‚â–â–‡â–‚â–â–…â–ƒâ–ƒ
wandb:         valid_loss â–…â–†â–ƒâ–‚â–â–ƒâ–‚â–â–…â–†â–„â–ˆâ–‚â–‚â–‡â–‚â–â–†â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4192
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.11173
wandb:   test_error_force 7.57288
wandb:          test_loss 5.87225
wandb: train_error_energy 2.03527
wandb:  train_error_force 1.82115
wandb:         train_loss -2.62571
wandb: valid_error_energy 0.96014
wandb:  valid_error_force 2.10294
wandb:         valid_loss -2.30749
wandb: 
wandb: ğŸš€ View run al_69_46 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lh03guj7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_073301-lh03guj7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.51936340332031, Uncertainty Bias: -4.63818883895874
2.2888184e-05 0.0018348694
0.45181528 5.214028
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 697 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1222 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1789 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3725 steps.
Found uncertainty sample 13 after 279 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 593 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 943 steps.
Found uncertainty sample 22 after 1216 steps.
Found uncertainty sample 23 after 2154 steps.
Found uncertainty sample 24 after 2474 steps.
Found uncertainty sample 25 after 488 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2097 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2019 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1942 steps.
Found uncertainty sample 34 after 3369 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2961 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1001 steps.
Found uncertainty sample 43 after 3253 steps.
Found uncertainty sample 44 after 1409 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1741 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1169 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2917 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1219 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1740 steps.
Found uncertainty sample 60 after 680 steps.
Found uncertainty sample 61 after 1425 steps.
Found uncertainty sample 62 after 905 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1206 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1085 steps.
Found uncertainty sample 70 after 1030 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1085 steps.
Found uncertainty sample 74 after 3454 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2223 steps.
Found uncertainty sample 78 after 2804 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 673 steps.
Found uncertainty sample 83 after 407 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3639 steps.
Found uncertainty sample 86 after 3247 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 474 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3399 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 871 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2919 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_080954-smw4beu9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_47
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/smw4beu9
Training model 47. Added 42 samples to the dataset.
Epoch 0, Batch 100/133, Loss: 0.12165133655071259, Uncertainty: 0.1245713010430336

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.324719569352029, Training Loss Force: 2.0228122316500636, time: 2.0530693531036377
Validation Loss Energy: 3.4086362829407157, Validation Loss Force: 2.115792278717322, time: 0.12212514877319336
Test Loss Energy: 14.604375417559236, Test Loss Force: 7.593060407110245, time: 9.732134819030762

Epoch 1, Batch 100/133, Loss: 0.0617457814514637, Uncertainty: 0.1234755665063858

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5557154077418833, Training Loss Force: 1.8536669690507466, time: 1.9746179580688477
Validation Loss Energy: 1.0911824304220654, Validation Loss Force: 2.0727604271440963, time: 0.1276257038116455
Test Loss Energy: 12.19496918358331, Test Loss Force: 7.596031958339441, time: 9.69497013092041

Epoch 2, Batch 100/133, Loss: 0.17529764771461487, Uncertainty: 0.12205938249826431

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.024436522289259, Training Loss Force: 1.8314070484456153, time: 1.9808588027954102
Validation Loss Energy: 3.953231202169819, Validation Loss Force: 2.3528589889516547, time: 0.12144327163696289
Test Loss Energy: 10.75037589410354, Test Loss Force: 7.568634923827158, time: 9.906497955322266

Epoch 3, Batch 100/133, Loss: 0.14237046241760254, Uncertainty: 0.12217487394809723

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7975109065830743, Training Loss Force: 1.8460165695031239, time: 2.038677930831909
Validation Loss Energy: 2.491562643095068, Validation Loss Force: 2.1780237031751226, time: 0.12245535850524902
Test Loss Energy: 10.806251841393943, Test Loss Force: 7.5550011368414784, time: 9.697560548782349

Epoch 4, Batch 100/133, Loss: 0.07295873761177063, Uncertainty: 0.12474696338176727

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.420437375284055, Training Loss Force: 1.8629677948192924, time: 2.0401668548583984
Validation Loss Energy: 2.3429293181696753, Validation Loss Force: 2.3501321083675744, time: 0.12532472610473633
Test Loss Energy: 12.830677839208882, Test Loss Force: 7.5463430236577524, time: 9.865202188491821

Epoch 5, Batch 100/133, Loss: 0.14864212274551392, Uncertainty: 0.122047558426857

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.892793614542473, Training Loss Force: 1.8276612377562458, time: 2.0059468746185303
Validation Loss Energy: 1.872646478130015, Validation Loss Force: 2.1000464527321845, time: 0.12194252014160156
Test Loss Energy: 12.545432796934326, Test Loss Force: 7.584550502976372, time: 9.717163324356079

Epoch 6, Batch 100/133, Loss: 0.14210227131843567, Uncertainty: 0.12145726382732391

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5101707405770597, Training Loss Force: 1.8235324252535539, time: 2.0994982719421387
Validation Loss Energy: 1.8995646542890305, Validation Loss Force: 2.108527475162282, time: 0.12277674674987793
Test Loss Energy: 12.856715873793867, Test Loss Force: 7.627630601085624, time: 9.82706594467163

Epoch 7, Batch 100/133, Loss: 0.12606430053710938, Uncertainty: 0.1233941838145256

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7770328104836428, Training Loss Force: 1.847030091650121, time: 1.9827196598052979
Validation Loss Energy: 2.6171076640598785, Validation Loss Force: 2.233016784594725, time: 0.12501287460327148
Test Loss Energy: 13.434230332847537, Test Loss Force: 7.619369372921276, time: 9.907727003097534

Epoch 8, Batch 100/133, Loss: 0.09985756874084473, Uncertainty: 0.12193642556667328

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0452256144074954, Training Loss Force: 1.8196372328658383, time: 1.9871442317962646
Validation Loss Energy: 2.675086850060945, Validation Loss Force: 2.1400971355566805, time: 0.125410795211792
Test Loss Energy: 13.833592934688602, Test Loss Force: 7.647550498942217, time: 10.56723403930664

Epoch 9, Batch 100/133, Loss: 0.11928457766771317, Uncertainty: 0.12231098115444183

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7414572942053768, Training Loss Force: 1.8402425869432961, time: 2.030733823776245
Validation Loss Energy: 3.8648149994966396, Validation Loss Force: 2.2950885923864197, time: 0.1345818042755127
Test Loss Energy: 14.070781988211841, Test Loss Force: 7.566608343147453, time: 9.916231155395508

Epoch 10, Batch 100/133, Loss: 0.06444992125034332, Uncertainty: 0.1236419528722763

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3469646693244204, Training Loss Force: 1.8464882714870166, time: 1.9799089431762695
Validation Loss Energy: 2.344944733720992, Validation Loss Force: 1.9871025385160976, time: 0.12630057334899902
Test Loss Energy: 11.10512456648848, Test Loss Force: 7.526016720801438, time: 9.8185453414917

Epoch 11, Batch 100/133, Loss: 0.048238180577754974, Uncertainty: 0.12163303792476654

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5614508572385886, Training Loss Force: 1.824479703329637, time: 2.0081140995025635
Validation Loss Energy: 2.156678787292582, Validation Loss Force: 2.062955339749263, time: 0.12239456176757812
Test Loss Energy: 10.917120996205409, Test Loss Force: 7.6425888591254925, time: 9.83340835571289

Epoch 12, Batch 100/133, Loss: 0.10008353739976883, Uncertainty: 0.12275078892707825

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6210963247315175, Training Loss Force: 1.8607628027194159, time: 1.9710791110992432
Validation Loss Energy: 1.6335294118442167, Validation Loss Force: 2.4153950248010845, time: 0.1323230266571045
Test Loss Energy: 10.889928971193907, Test Loss Force: 7.613268401535842, time: 9.904616117477417

Epoch 13, Batch 100/133, Loss: 0.04897084832191467, Uncertainty: 0.12307853996753693

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6770978267191754, Training Loss Force: 1.8547616248028627, time: 2.019228935241699
Validation Loss Energy: 1.1430999313750643, Validation Loss Force: 2.0845685719526466, time: 0.12838530540466309
Test Loss Energy: 11.810809866775584, Test Loss Force: 7.589223381714073, time: 9.908060073852539

Epoch 14, Batch 100/133, Loss: 0.07801821827888489, Uncertainty: 0.1227342039346695

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9724917834306468, Training Loss Force: 1.8639904639804155, time: 1.9902760982513428
Validation Loss Energy: 4.924602935919103, Validation Loss Force: 2.153767239763479, time: 0.1265239715576172
Test Loss Energy: 10.19096106043659, Test Loss Force: 7.586843151135125, time: 9.961498498916626

Epoch 15, Batch 100/133, Loss: 0.23534807562828064, Uncertainty: 0.12297815084457397

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8032320952590373, Training Loss Force: 1.8668725736997116, time: 2.101409435272217
Validation Loss Energy: 1.2732432186493812, Validation Loss Force: 2.0513516794397226, time: 0.133544921875
Test Loss Energy: 12.477284496790661, Test Loss Force: 7.597982887468267, time: 9.822931051254272

Epoch 16, Batch 100/133, Loss: 0.07987099885940552, Uncertainty: 0.12241619825363159

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0270331337495366, Training Loss Force: 1.821114052492122, time: 2.1007864475250244
Validation Loss Energy: 3.5093940714730394, Validation Loss Force: 2.1084827186639505, time: 0.12828397750854492
Test Loss Energy: 14.31264912696705, Test Loss Force: 7.634253494959429, time: 9.908161640167236

Epoch 17, Batch 100/133, Loss: 0.09305861592292786, Uncertainty: 0.12205249071121216

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7461678884489487, Training Loss Force: 1.8398781185694122, time: 2.0407228469848633
Validation Loss Energy: 1.00832358573719, Validation Loss Force: 2.14262227789455, time: 0.12153744697570801
Test Loss Energy: 11.773973633021484, Test Loss Force: 7.647403451036184, time: 10.050012111663818

Epoch 18, Batch 100/133, Loss: 0.5512444376945496, Uncertainty: 0.12120814621448517

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.5405308056863265, Training Loss Force: 1.8383743902976555, time: 2.053598642349243
Validation Loss Energy: 1.0936608307950526, Validation Loss Force: 2.2459759433301003, time: 0.12242960929870605
Test Loss Energy: 12.069399015383294, Test Loss Force: 7.769616724477384, time: 9.777738332748413

Epoch 19, Batch 100/133, Loss: 0.06414952874183655, Uncertainty: 0.12250284105539322

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4891560611751413, Training Loss Force: 1.8450207328111872, time: 1.958019733428955
Validation Loss Energy: 3.071997052037832, Validation Loss Force: 2.162688553318125, time: 0.12158322334289551
Test Loss Energy: 10.650750896962396, Test Loss Force: 7.544141522957141, time: 9.868289470672607

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.059 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–‚â–‚â–…â–…â–…â–†â–‡â–‡â–‚â–‚â–‚â–„â–â–…â–ˆâ–„â–„â–‚
wandb:   test_error_force â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–„â–„â–„â–‚â–â–„â–„â–ƒâ–ƒâ–ƒâ–„â–„â–ˆâ–‚
wandb:          test_loss â–…â–„â–ƒâ–‚â–â–…â–†â–…â–ˆâ–†â–â–„â–ƒâ–…â–â–‚â–‡â–ƒâ–ˆâ–
wandb: train_error_energy â–†â–‚â–„â–ˆâ–†â–„â–‚â–ƒâ–„â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–‡â–‚
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚
wandb: valid_error_energy â–…â–â–†â–„â–ƒâ–ƒâ–ƒâ–„â–„â–†â–ƒâ–ƒâ–‚â–â–ˆâ–â–…â–â–â–…
wandb:  valid_error_force â–ƒâ–‚â–‡â–„â–‡â–ƒâ–ƒâ–…â–„â–†â–â–‚â–ˆâ–ƒâ–„â–‚â–ƒâ–„â–…â–„
wandb:         valid_loss â–„â–â–ˆâ–„â–‡â–‚â–ƒâ–…â–„â–‡â–â–‚â–‡â–‚â–†â–â–„â–‚â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4229
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 10.65075
wandb:   test_error_force 7.54414
wandb:          test_loss 5.61532
wandb: train_error_energy 1.48916
wandb:  train_error_force 1.84502
wandb:         train_loss -2.62956
wandb: valid_error_energy 3.072
wandb:  valid_error_force 2.16269
wandb:         valid_loss -2.08969
wandb: 
wandb: ğŸš€ View run al_69_47 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/smw4beu9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_080954-smw4beu9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 44.983638763427734, Uncertainty Bias: -5.361354827880859
0.000118255615 0.163661
0.24472941 6.70755
(48745, 22, 3)
Found uncertainty sample 0 after 2463 steps.
Found uncertainty sample 1 after 456 steps.
Found uncertainty sample 2 after 1489 steps.
Found uncertainty sample 3 after 1081 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2397 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2033 steps.
Found uncertainty sample 8 after 2923 steps.
Found uncertainty sample 9 after 2755 steps.
Found uncertainty sample 10 after 1824 steps.
Found uncertainty sample 11 after 1927 steps.
Found uncertainty sample 12 after 3669 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3525 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1511 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1951 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1314 steps.
Found uncertainty sample 25 after 1774 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 333 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3604 steps.
Found uncertainty sample 37 after 3656 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1584 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1565 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 690 steps.
Found uncertainty sample 50 after 1553 steps.
Found uncertainty sample 51 after 3228 steps.
Found uncertainty sample 52 after 1034 steps.
Found uncertainty sample 53 after 2360 steps.
Found uncertainty sample 54 after 1597 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 847 steps.
Found uncertainty sample 57 after 3894 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2311 steps.
Found uncertainty sample 60 after 1967 steps.
Found uncertainty sample 61 after 529 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1115 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3482 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2725 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1850 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3635 steps.
Found uncertainty sample 79 after 1458 steps.
Found uncertainty sample 80 after 1119 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3438 steps.
Found uncertainty sample 83 after 1560 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3244 steps.
Found uncertainty sample 87 after 1759 steps.
Found uncertainty sample 88 after 1007 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 759 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1549 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 920 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2532 steps.
Found uncertainty sample 98 after 2361 steps.
Found uncertainty sample 99 after 775 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_084552-aoi22llu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_48
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/aoi22llu
Training model 48. Added 50 samples to the dataset.
Epoch 0, Batch 100/134, Loss: 0.03653012961149216, Uncertainty: 0.12385386228561401

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.689413279191537, Training Loss Force: 1.9441902854768374, time: 2.2254114151000977
Validation Loss Energy: 1.200201541160505, Validation Loss Force: 2.01203187097521, time: 0.13759088516235352
Test Loss Energy: 11.88110516847204, Test Loss Force: 7.501766330078699, time: 11.226982116699219

Epoch 1, Batch 100/134, Loss: 0.23472581803798676, Uncertainty: 0.1228947564959526

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.6044752747887174, Training Loss Force: 1.8302410857044324, time: 2.1905517578125
Validation Loss Energy: 3.7418715706098005, Validation Loss Force: 2.0143100732302464, time: 0.14734411239624023
Test Loss Energy: 10.129213875697385, Test Loss Force: 7.477302016094501, time: 11.354919910430908

Epoch 2, Batch 100/134, Loss: 0.10949550569057465, Uncertainty: 0.12223714590072632

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4119147169032522, Training Loss Force: 1.8313886817706486, time: 2.2263641357421875
Validation Loss Energy: 2.2313846568665987, Validation Loss Force: 2.0194612641406153, time: 0.1279277801513672
Test Loss Energy: 13.068103178504353, Test Loss Force: 7.4416035447328275, time: 11.998644828796387

Epoch 3, Batch 100/134, Loss: 0.11252430081367493, Uncertainty: 0.12203119695186615

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3489645478764118, Training Loss Force: 1.8202790907847695, time: 2.17871356010437
Validation Loss Energy: 1.1718853924360684, Validation Loss Force: 2.0331420193548944, time: 0.13130974769592285
Test Loss Energy: 11.38220083609234, Test Loss Force: 7.411656193056703, time: 11.224224328994751

Epoch 4, Batch 100/134, Loss: 0.061293333768844604, Uncertainty: 0.12387990951538086

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7568755274957784, Training Loss Force: 1.8827818431359167, time: 2.1751863956451416
Validation Loss Energy: 1.1560150387310706, Validation Loss Force: 2.088174476101801, time: 0.14220023155212402
Test Loss Energy: 11.127595944984346, Test Loss Force: 7.4601508540151835, time: 11.22581171989441

Epoch 5, Batch 100/134, Loss: 0.11986753344535828, Uncertainty: 0.12259378284215927

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.900971426439991, Training Loss Force: 1.8398185484570342, time: 2.13988995552063
Validation Loss Energy: 2.924564322035758, Validation Loss Force: 2.118512627673122, time: 0.15261316299438477
Test Loss Energy: 10.588669997624448, Test Loss Force: 7.454618754499504, time: 11.185466289520264

Epoch 6, Batch 100/134, Loss: 0.14962953329086304, Uncertainty: 0.1227700412273407

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.06332660953151, Training Loss Force: 1.816516963458371, time: 2.2422056198120117
Validation Loss Energy: 1.3155144324201178, Validation Loss Force: 1.9858706956893004, time: 0.12791752815246582
Test Loss Energy: 12.12368330496569, Test Loss Force: 7.531610263011707, time: 11.439544677734375

Epoch 7, Batch 100/134, Loss: 0.04350217059254646, Uncertainty: 0.12384897470474243

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1698286567508878, Training Loss Force: 1.8780864628910539, time: 2.3297135829925537
Validation Loss Energy: 1.5130446399994257, Validation Loss Force: 2.057177743419875, time: 0.13801932334899902
Test Loss Energy: 12.215179996930344, Test Loss Force: 7.489011067304079, time: 11.145776510238647

Epoch 8, Batch 100/134, Loss: 0.06738567352294922, Uncertainty: 0.12515534460544586

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8581629948286809, Training Loss Force: 1.8704122746335303, time: 2.1205670833587646
Validation Loss Energy: 3.3773546079750503, Validation Loss Force: 1.9886096004072609, time: 0.1481914520263672
Test Loss Energy: 14.275758277484428, Test Loss Force: 7.493597524765405, time: 9.837666511535645

Epoch 9, Batch 100/134, Loss: 0.057750094681978226, Uncertainty: 0.12387925386428833

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0882655538754227, Training Loss Force: 1.830386855894643, time: 2.012204647064209
Validation Loss Energy: 1.0343193549591998, Validation Loss Force: 2.1301325057187905, time: 0.13236117362976074
Test Loss Energy: 11.304513436369406, Test Loss Force: 7.469975224247171, time: 11.806519269943237

Epoch 10, Batch 100/134, Loss: 0.23724365234375, Uncertainty: 0.1218535527586937

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7645980856401247, Training Loss Force: 1.8611082736869236, time: 2.125537157058716
Validation Loss Energy: 1.3855394254314886, Validation Loss Force: 2.1904336484620672, time: 0.11651420593261719
Test Loss Energy: 10.954657730771297, Test Loss Force: 7.401356271477437, time: 8.856662034988403

Epoch 11, Batch 100/134, Loss: 0.08561795949935913, Uncertainty: 0.12216182798147202

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7086533168447307, Training Loss Force: 1.8151457294692717, time: 2.08475661277771
Validation Loss Energy: 1.406827189566574, Validation Loss Force: 2.2679821123529975, time: 0.11674880981445312
Test Loss Energy: 12.22587004184812, Test Loss Force: 7.4331689330812605, time: 9.016573429107666

Epoch 12, Batch 100/134, Loss: 0.23854254186153412, Uncertainty: 0.12203021347522736

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.560213786360682, Training Loss Force: 1.8374239802479722, time: 2.0620055198669434
Validation Loss Energy: 1.5176013785132163, Validation Loss Force: 2.19940869950393, time: 0.11424565315246582
Test Loss Energy: 12.221213687259498, Test Loss Force: 7.446569164614808, time: 8.992862701416016

Epoch 13, Batch 100/134, Loss: 0.323555052280426, Uncertainty: 0.12335449457168579

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.137832308959694, Training Loss Force: 1.8427362736701782, time: 2.06025767326355
Validation Loss Energy: 1.040219716211043, Validation Loss Force: 1.9582585711370009, time: 0.12050104141235352
Test Loss Energy: 11.250801110377056, Test Loss Force: 7.398649384095607, time: 9.061763763427734

Epoch 14, Batch 100/134, Loss: 0.16535818576812744, Uncertainty: 0.12151352316141129

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.693133471793639, Training Loss Force: 1.8139939616799898, time: 2.0747437477111816
Validation Loss Energy: 2.896418867767437, Validation Loss Force: 2.1991265405845155, time: 0.11968159675598145
Test Loss Energy: 13.332570755258734, Test Loss Force: 7.42474882640097, time: 8.905062198638916

Epoch 15, Batch 100/134, Loss: 0.1643657386302948, Uncertainty: 0.12155089527368546

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3421876068291625, Training Loss Force: 1.8387104429300198, time: 2.1199100017547607
Validation Loss Energy: 1.5702956978933085, Validation Loss Force: 2.0924483134656904, time: 0.1145331859588623
Test Loss Energy: 10.67657593859994, Test Loss Force: 7.499463252610107, time: 8.84276795387268

Epoch 16, Batch 100/134, Loss: 0.06187905743718147, Uncertainty: 0.1221788227558136

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.93516714634648, Training Loss Force: 1.8264899913018726, time: 2.234243869781494
Validation Loss Energy: 2.54666427572331, Validation Loss Force: 2.086348811774339, time: 0.12025165557861328
Test Loss Energy: 13.032060840696177, Test Loss Force: 7.388169949215667, time: 9.016279458999634

Epoch 17, Batch 100/134, Loss: 0.2688339352607727, Uncertainty: 0.12206103652715683

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9124261404775225, Training Loss Force: 1.8368818382066343, time: 2.0543363094329834
Validation Loss Energy: 1.4381695789860292, Validation Loss Force: 2.30201107924112, time: 0.11388683319091797
Test Loss Energy: 11.031027735888811, Test Loss Force: 7.526877953762378, time: 9.699349880218506

Epoch 18, Batch 100/134, Loss: 0.15658679604530334, Uncertainty: 0.1219390407204628

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.695989567296949, Training Loss Force: 1.834219379905356, time: 2.1107702255249023
Validation Loss Energy: 1.760500053460068, Validation Loss Force: 2.272563901145705, time: 0.11739182472229004
Test Loss Energy: 12.083585483510463, Test Loss Force: 7.430959157482231, time: 8.902653694152832

Epoch 19, Batch 100/134, Loss: 0.05881643667817116, Uncertainty: 0.12183906137943268

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7773130588540165, Training Loss Force: 1.8209248163525698, time: 2.094345808029175
Validation Loss Energy: 2.782982669181228, Validation Loss Force: 1.9896823832408168, time: 0.11842036247253418
Test Loss Energy: 10.731247262132168, Test Loss Force: 7.449652393164241, time: 9.176685571670532

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–†â–ƒâ–ƒâ–‚â–„â–…â–ˆâ–ƒâ–‚â–…â–…â–ƒâ–†â–‚â–†â–ƒâ–„â–‚
wandb:   test_error_force â–‡â–…â–„â–‚â–…â–„â–ˆâ–†â–†â–…â–‚â–ƒâ–„â–‚â–ƒâ–†â–â–ˆâ–ƒâ–„
wandb:          test_loss â–†â–„â–†â–…â–„â–„â–ˆâ–…â–‡â–…â–â–†â–†â–ƒâ–ˆâ–„â–…â–†â–…â–ƒ
wandb: train_error_energy â–ˆâ–ˆâ–â–â–ƒâ–„â–…â–…â–„â–…â–ƒâ–ƒâ–‚â–…â–ƒâ–†â–„â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–…â–‚â–â–„â–„â–‚â–„â–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–„â–‚â–â–„â–ƒâ–‚â–…â–„â–ƒâ–ƒâ–â–‚â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–‚
wandb: valid_error_energy â–â–ˆâ–„â–â–â–†â–‚â–‚â–‡â–â–‚â–‚â–‚â–â–†â–‚â–…â–‚â–ƒâ–†
wandb:  valid_error_force â–‚â–‚â–‚â–ƒâ–„â–„â–‚â–ƒâ–‚â–„â–†â–‡â–†â–â–†â–„â–„â–ˆâ–‡â–‚
wandb:         valid_loss â–‚â–…â–ƒâ–ƒâ–„â–†â–‚â–ƒâ–„â–„â–†â–‡â–†â–â–‡â–„â–…â–ˆâ–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4274
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 10.73125
wandb:   test_error_force 7.44965
wandb:          test_loss 5.47454
wandb: train_error_energy 1.77731
wandb:  train_error_force 1.82092
wandb:         train_loss -2.64338
wandb: valid_error_energy 2.78298
wandb:  valid_error_force 1.98968
wandb:         valid_loss -2.34498
wandb: 
wandb: ğŸš€ View run al_69_48 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/aoi22llu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_084552-aoi22llu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.892709732055664, Uncertainty Bias: -2.5407872200012207
3.4332275e-05 0.051979065
0.86568063 4.5523477
(48745, 22, 3)
Found uncertainty sample 0 after 3314 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2839 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1141 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3245 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3814 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 667 steps.
Found uncertainty sample 26 after 2812 steps.
Found uncertainty sample 27 after 699 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1595 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2462 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2214 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 948 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2288 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1260 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2207 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3100 steps.
Found uncertainty sample 66 after 2941 steps.
Found uncertainty sample 67 after 774 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3435 steps.
Found uncertainty sample 70 after 3912 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 582 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3767 steps.
Found uncertainty sample 79 after 3497 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 265 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 677 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3171 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1156 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_092521-yukqs9dq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_49
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yukqs9dq
Training model 49. Added 27 samples to the dataset.
Epoch 0, Batch 100/135, Loss: 0.12796562910079956, Uncertainty: 0.1238555759191513

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9480828611348473, Training Loss Force: 1.9106621538171549, time: 1.9969651699066162
Validation Loss Energy: 1.4672560701765651, Validation Loss Force: 1.9700779978489453, time: 0.12966179847717285
Test Loss Energy: 10.858497945853289, Test Loss Force: 7.42818239862086, time: 10.28905463218689

Epoch 1, Batch 100/135, Loss: 0.0755477026104927, Uncertainty: 0.12206582725048065

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5923819845119613, Training Loss Force: 1.8247211116808895, time: 2.0508415699005127
Validation Loss Energy: 2.4074861878529727, Validation Loss Force: 2.0237950366162836, time: 0.13124561309814453
Test Loss Energy: 13.092883106767092, Test Loss Force: 7.397783655782694, time: 10.295300960540771

Epoch 2, Batch 100/135, Loss: 0.15487366914749146, Uncertainty: 0.1227838397026062

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7877927504631788, Training Loss Force: 1.8522760490236112, time: 2.0176830291748047
Validation Loss Energy: 1.6733371811862678, Validation Loss Force: 1.9802065121782382, time: 0.1800539493560791
Test Loss Energy: 10.626217322381548, Test Loss Force: 7.368651179916102, time: 10.390724420547485

Epoch 3, Batch 100/135, Loss: 0.06617669016122818, Uncertainty: 0.122992604970932

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.303563432159246, Training Loss Force: 1.8286947695938542, time: 2.031493663787842
Validation Loss Energy: 1.792166463598372, Validation Loss Force: 2.047432108687005, time: 0.12809324264526367
Test Loss Energy: 10.511475174694906, Test Loss Force: 7.4298120499805185, time: 10.347522020339966

Epoch 4, Batch 100/135, Loss: 0.12632468342781067, Uncertainty: 0.12178290635347366

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6819154795192157, Training Loss Force: 1.8328116483014796, time: 2.038118839263916
Validation Loss Energy: 1.7187413869517327, Validation Loss Force: 2.0748094286249237, time: 0.13309717178344727
Test Loss Energy: 12.481256933006927, Test Loss Force: 7.478326641576268, time: 10.5643892288208

Epoch 5, Batch 100/135, Loss: 0.14503709971904755, Uncertainty: 0.12306293845176697

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.393438607610373, Training Loss Force: 1.8247753769764528, time: 2.0245375633239746
Validation Loss Energy: 1.8132990644502704, Validation Loss Force: 2.014127818534304, time: 0.12891435623168945
Test Loss Energy: 10.516539132732895, Test Loss Force: 7.382848569323688, time: 10.214821100234985

Epoch 6, Batch 100/135, Loss: 0.056362513452768326, Uncertainty: 0.1229076012969017

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7059388549306533, Training Loss Force: 1.8531855320784472, time: 2.116220474243164
Validation Loss Energy: 2.549459070396898, Validation Loss Force: 2.5514987197735963, time: 0.13175344467163086
Test Loss Energy: 10.22484158161603, Test Loss Force: 7.34454890264704, time: 10.34998631477356

Epoch 7, Batch 100/135, Loss: 0.08701007813215256, Uncertainty: 0.12203182280063629

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6237575172029122, Training Loss Force: 1.8364001661138396, time: 2.221675157546997
Validation Loss Energy: 2.78206170959367, Validation Loss Force: 2.256225589674778, time: 0.12952470779418945
Test Loss Energy: 10.353344080964572, Test Loss Force: 7.352580044801029, time: 10.30887746810913

Epoch 8, Batch 100/135, Loss: 0.10906615853309631, Uncertainty: 0.12193217873573303

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6691251316239217, Training Loss Force: 1.841554552738803, time: 2.0121307373046875
Validation Loss Energy: 2.3638654506118164, Validation Loss Force: 2.0107297018098245, time: 0.12674665451049805
Test Loss Energy: 13.260688706233555, Test Loss Force: 7.391929583676847, time: 10.324902534484863

Epoch 9, Batch 100/135, Loss: 0.1051584854722023, Uncertainty: 0.1227928027510643

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7225544591754565, Training Loss Force: 1.856264390729699, time: 1.9767742156982422
Validation Loss Energy: 2.418043822737993, Validation Loss Force: 2.3605727677279336, time: 0.13200092315673828
Test Loss Energy: 12.385287981376015, Test Loss Force: 7.46062392685668, time: 10.545037984848022

Epoch 10, Batch 100/135, Loss: 0.19689345359802246, Uncertainty: 0.12162177264690399

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.930553444692402, Training Loss Force: 1.8250431704371528, time: 2.05184006690979
Validation Loss Energy: 0.9483027463371115, Validation Loss Force: 2.0101091971231724, time: 0.1332545280456543
Test Loss Energy: 11.20996305274266, Test Loss Force: 7.417014785509614, time: 10.25199294090271

Epoch 11, Batch 100/135, Loss: 0.08233127743005753, Uncertainty: 0.12304481863975525

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.773653662562978, Training Loss Force: 1.844401277156024, time: 2.0535783767700195
Validation Loss Energy: 5.686291885223302, Validation Loss Force: 2.021482580424299, time: 0.12923502922058105
Test Loss Energy: 9.587448815120416, Test Loss Force: 7.3945055462641, time: 11.247942686080933

Epoch 12, Batch 100/135, Loss: 0.25281521677970886, Uncertainty: 0.12247762084007263

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.428162897132549, Training Loss Force: 1.8404250362809664, time: 2.0083861351013184
Validation Loss Energy: 4.424120778520607, Validation Loss Force: 2.148492281919499, time: 0.1349020004272461
Test Loss Energy: 10.113027889935296, Test Loss Force: 7.436684023193087, time: 10.261637210845947

Epoch 13, Batch 100/135, Loss: 0.36464154720306396, Uncertainty: 0.12099052965641022

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.157600451380577, Training Loss Force: 1.8669885994545843, time: 2.0711171627044678
Validation Loss Energy: 1.813721838935339, Validation Loss Force: 2.248423485470614, time: 0.1318066120147705
Test Loss Energy: 10.487267820905107, Test Loss Force: 7.237360275293794, time: 10.304482460021973

Epoch 14, Batch 100/135, Loss: 0.06261759996414185, Uncertainty: 0.12331198155879974

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.617653528109745, Training Loss Force: 1.8329258990155544, time: 2.039393424987793
Validation Loss Energy: 4.791758820350779, Validation Loss Force: 2.21027309824899, time: 0.13639044761657715
Test Loss Energy: 9.676943210166147, Test Loss Force: 7.3733585315681776, time: 10.463438987731934

Epoch 15, Batch 100/135, Loss: 0.05766855180263519, Uncertainty: 0.1218862384557724

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4943221728715257, Training Loss Force: 1.8017454477942267, time: 2.001934051513672
Validation Loss Energy: 1.2704711362286776, Validation Loss Force: 2.0021001961709177, time: 0.13570570945739746
Test Loss Energy: 10.528465805143886, Test Loss Force: 7.290645144142773, time: 10.346634864807129

Epoch 16, Batch 100/135, Loss: 0.06032687425613403, Uncertainty: 0.12189127504825592

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7804835796684622, Training Loss Force: 1.8513588838832404, time: 2.071911573410034
Validation Loss Energy: 3.1210104648781165, Validation Loss Force: 1.9674794118044436, time: 0.1397559642791748
Test Loss Energy: 10.054434730875855, Test Loss Force: 7.287578069015778, time: 10.458046197891235

Epoch 17, Batch 100/135, Loss: 0.1093822568655014, Uncertainty: 0.12163868546485901

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7938528430145029, Training Loss Force: 1.8300394512474008, time: 2.030198335647583
Validation Loss Energy: 2.3162868435248423, Validation Loss Force: 2.206449572121216, time: 0.14342665672302246
Test Loss Energy: 9.89583355110168, Test Loss Force: 7.26408623163253, time: 10.38077449798584

Epoch 18, Batch 100/135, Loss: 0.21906860172748566, Uncertainty: 0.1227150559425354

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1430290472100544, Training Loss Force: 1.8583343577476663, time: 2.081364631652832
Validation Loss Energy: 3.7080364001016846, Validation Loss Force: 2.4582819187603118, time: 0.1487739086151123
Test Loss Energy: 9.73410030478927, Test Loss Force: 7.478608009107, time: 10.295701742172241

Epoch 19, Batch 100/135, Loss: 0.05356937646865845, Uncertainty: 0.12215913087129593

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0175617833418773, Training Loss Force: 1.8297815005876508, time: 2.336960554122925
Validation Loss Energy: 1.9280234411571964, Validation Loss Force: 2.104112020221583, time: 0.13135528564453125
Test Loss Energy: 12.258641540110453, Test Loss Force: 7.363019497162492, time: 10.280231952667236

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–ƒâ–‡â–ƒâ–‚â–‚â–ˆâ–†â–„â–â–‚â–ƒâ–â–ƒâ–‚â–‚â–â–†
wandb:   test_error_force â–‡â–†â–…â–‡â–ˆâ–…â–„â–„â–…â–‡â–†â–†â–‡â–â–…â–ƒâ–‚â–‚â–ˆâ–…
wandb:          test_loss â–…â–‡â–„â–…â–ˆâ–…â–ƒâ–„â–‡â–ˆâ–‡â–„â–…â–â–„â–„â–‚â–‚â–…â–†
wandb: train_error_energy â–ˆâ–‚â–ƒâ–â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–†â–…â–‚â–‚â–ƒâ–ƒâ–…â–„
wandb:  train_error_force â–ˆâ–‚â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–…â–‚â–„â–ƒâ–…â–ƒâ–â–„â–ƒâ–…â–ƒ
wandb:         train_loss â–ˆâ–‚â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–…â–‚â–â–ƒâ–ƒâ–„â–ƒ
wandb: valid_error_energy â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–â–ˆâ–†â–‚â–‡â–â–„â–ƒâ–…â–‚
wandb:  valid_error_force â–â–‚â–â–‚â–‚â–‚â–ˆâ–„â–‚â–†â–‚â–‚â–ƒâ–„â–„â–â–â–„â–‡â–ƒ
wandb:         valid_loss â–â–‚â–â–‚â–‚â–‚â–ˆâ–…â–‚â–†â–â–„â–…â–„â–…â–â–‚â–„â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4298
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.25864
wandb:   test_error_force 7.36302
wandb:          test_loss 5.52975
wandb: train_error_energy 2.01756
wandb:  train_error_force 1.82978
wandb:         train_loss -2.61499
wandb: valid_error_energy 1.92802
wandb:  valid_error_force 2.10411
wandb:         valid_loss -2.24352
wandb: 
wandb: ğŸš€ View run al_69_49 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yukqs9dq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_092521-yukqs9dq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 35.54013442993164, Uncertainty Bias: -4.1822638511657715
1.2397766e-05 0.011390686
0.55756354 5.321265
(48745, 22, 3)
Found uncertainty sample 0 after 2588 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2479 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2247 steps.
Found uncertainty sample 6 after 3613 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1116 steps.
Found uncertainty sample 15 after 3073 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2869 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1584 steps.
Found uncertainty sample 20 after 3922 steps.
Found uncertainty sample 21 after 3312 steps.
Found uncertainty sample 22 after 1253 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3716 steps.
Found uncertainty sample 26 after 2388 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1939 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2044 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1601 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 474 steps.
Found uncertainty sample 44 after 3117 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2030 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2020 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2156 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1943 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2289 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2080 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3946 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1854 steps.
Found uncertainty sample 91 after 3728 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3303 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1866 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 414 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_100620-m27rp20t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_50
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m27rp20t
Training model 50. Added 30 samples to the dataset.
Epoch 0, Batch 100/136, Loss: 0.13884098827838898, Uncertainty: 0.12436564266681671

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3842690276316882, Training Loss Force: 1.9805479769507912, time: 2.154003858566284
Validation Loss Energy: 2.518143252828857, Validation Loss Force: 2.3513847707595157, time: 0.1261425018310547
Test Loss Energy: 12.395188588394019, Test Loss Force: 7.268518445826732, time: 10.12062120437622

Epoch 1, Batch 100/136, Loss: 0.04152483865618706, Uncertainty: 0.12234435975551605

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5178649542461458, Training Loss Force: 1.8322483593978536, time: 2.040666103363037
Validation Loss Energy: 3.4455827352018322, Validation Loss Force: 2.2217598572569184, time: 0.12558913230895996
Test Loss Energy: 9.708332163862062, Test Loss Force: 7.250982369234793, time: 10.160502910614014

Epoch 2, Batch 100/136, Loss: 0.059298139065504074, Uncertainty: 0.12205503135919571

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.08337036526507, Training Loss Force: 1.8403512838877096, time: 2.0255167484283447
Validation Loss Energy: 1.1866192057087261, Validation Loss Force: 2.20812144629189, time: 0.14286398887634277
Test Loss Energy: 11.687352458043783, Test Loss Force: 7.416317770460895, time: 10.362507104873657

Epoch 3, Batch 100/136, Loss: 0.0732216089963913, Uncertainty: 0.12167725712060928

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9084194897109241, Training Loss Force: 1.826440811612428, time: 2.0359203815460205
Validation Loss Energy: 2.5245548624397505, Validation Loss Force: 2.020975933894265, time: 0.12615084648132324
Test Loss Energy: 10.009377589559929, Test Loss Force: 7.294072833700304, time: 10.224942684173584

Epoch 4, Batch 100/136, Loss: 0.14257413148880005, Uncertainty: 0.12162259221076965

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.120716555168972, Training Loss Force: 1.815712976454899, time: 2.060614824295044
Validation Loss Energy: 2.8378825635632587, Validation Loss Force: 2.1749198437269865, time: 0.12760090827941895
Test Loss Energy: 12.907206333462788, Test Loss Force: 7.409957250789416, time: 10.256442070007324

Epoch 5, Batch 100/136, Loss: 0.16165299713611603, Uncertainty: 0.12307101488113403

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7293420346391992, Training Loss Force: 1.8614346202825869, time: 2.0760936737060547
Validation Loss Energy: 1.5466261532388064, Validation Loss Force: 2.047309789102842, time: 0.12630319595336914
Test Loss Energy: 11.205757044752966, Test Loss Force: 7.320816713156581, time: 10.295405149459839

Epoch 6, Batch 100/136, Loss: 0.09784513711929321, Uncertainty: 0.12377122044563293

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7505216795328729, Training Loss Force: 1.8438309943915927, time: 2.050356149673462
Validation Loss Energy: 2.54288751011618, Validation Loss Force: 2.2432999055343403, time: 0.14771509170532227
Test Loss Energy: 9.93538757020188, Test Loss Force: 7.322071107549192, time: 10.201268911361694

Epoch 7, Batch 100/136, Loss: 0.1544499397277832, Uncertainty: 0.1231197714805603

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1067800789031743, Training Loss Force: 1.8658235707729494, time: 2.2661194801330566
Validation Loss Energy: 1.3122498800716704, Validation Loss Force: 2.1572678956296585, time: 0.1362447738647461
Test Loss Energy: 11.444563832756227, Test Loss Force: 7.334727237087401, time: 10.120810508728027

Epoch 8, Batch 100/136, Loss: 0.3624160885810852, Uncertainty: 0.12390930950641632

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.895932711971283, Training Loss Force: 1.8661582736074682, time: 2.0195741653442383
Validation Loss Energy: 0.9901700568328974, Validation Loss Force: 2.1443668164298457, time: 0.12977242469787598
Test Loss Energy: 10.643983233169525, Test Loss Force: 7.315068209542044, time: 10.932749509811401

Epoch 9, Batch 100/136, Loss: 0.08329886198043823, Uncertainty: 0.12276060879230499

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0078179136015715, Training Loss Force: 1.8337404890851758, time: 2.0434203147888184
Validation Loss Energy: 1.678243250478495, Validation Loss Force: 2.0381940111607526, time: 0.13139772415161133
Test Loss Energy: 11.751048135375088, Test Loss Force: 7.300486612100908, time: 10.282885074615479

Epoch 10, Batch 100/136, Loss: 0.09052015095949173, Uncertainty: 0.12248871475458145

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9351866584634991, Training Loss Force: 1.843896638401903, time: 2.117604970932007
Validation Loss Energy: 3.6964116604463295, Validation Loss Force: 1.9972504250610859, time: 0.12546920776367188
Test Loss Energy: 9.67706411834658, Test Loss Force: 7.301862928926081, time: 10.16762924194336

Epoch 11, Batch 100/136, Loss: 0.0686955600976944, Uncertainty: 0.12314446270465851

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6972877554510424, Training Loss Force: 1.8372857191666114, time: 2.0406787395477295
Validation Loss Energy: 1.9446566779119046, Validation Loss Force: 2.1133596925211093, time: 0.12648892402648926
Test Loss Energy: 12.298316187597393, Test Loss Force: 7.308410420731715, time: 10.393589973449707

Epoch 12, Batch 100/136, Loss: 0.5323929786682129, Uncertainty: 0.12429896742105484

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3328484559926865, Training Loss Force: 1.8812795527514703, time: 2.0220625400543213
Validation Loss Energy: 2.9402918149278805, Validation Loss Force: 2.016807010809632, time: 0.12676620483398438
Test Loss Energy: 12.71368962901307, Test Loss Force: 7.369892057941814, time: 10.12228798866272

Epoch 13, Batch 100/136, Loss: 0.10138115286827087, Uncertainty: 0.12121380865573883

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8693524891114908, Training Loss Force: 1.8193419956261287, time: 2.052396297454834
Validation Loss Energy: 2.537067309756871, Validation Loss Force: 2.2944779222537126, time: 0.1345221996307373
Test Loss Energy: 12.06595971671919, Test Loss Force: 7.3172894683404825, time: 10.147413730621338

Epoch 14, Batch 100/136, Loss: 0.3421480357646942, Uncertainty: 0.12059888243675232

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4464939471228737, Training Loss Force: 1.7817711321446674, time: 2.0800609588623047
Validation Loss Energy: 1.3608343208023248, Validation Loss Force: 2.1730157256371094, time: 0.12667083740234375
Test Loss Energy: 10.532105188939811, Test Loss Force: 7.251606155279678, time: 10.324981212615967

Epoch 15, Batch 100/136, Loss: 0.08679620176553726, Uncertainty: 0.12199269235134125

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0909617483239855, Training Loss Force: 1.8343847838961913, time: 2.0130953788757324
Validation Loss Energy: 1.7209528255745148, Validation Loss Force: 2.194681767539602, time: 0.1311049461364746
Test Loss Energy: 11.507443286605053, Test Loss Force: 7.280694384105618, time: 10.242090463638306

Epoch 16, Batch 100/136, Loss: 0.07266997545957565, Uncertainty: 0.12087894231081009

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.839432514152966, Training Loss Force: 1.8153485079948437, time: 2.0285375118255615
Validation Loss Energy: 1.510852592148102, Validation Loss Force: 2.2106248412765077, time: 0.12517714500427246
Test Loss Energy: 10.631721596414636, Test Loss Force: 7.293661271170207, time: 10.25235366821289

Epoch 17, Batch 100/136, Loss: 0.16518042981624603, Uncertainty: 0.12168355286121368

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7794526821686265, Training Loss Force: 1.838616397350405, time: 2.008913993835449
Validation Loss Energy: 0.9590501881132729, Validation Loss Force: 2.027056954046504, time: 0.13390564918518066
Test Loss Energy: 10.771574845503396, Test Loss Force: 7.258434100623321, time: 10.104164361953735

Epoch 18, Batch 100/136, Loss: 0.09573429822921753, Uncertainty: 0.12176492810249329

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.72091092570848, Training Loss Force: 1.8418828472984121, time: 2.0005998611450195
Validation Loss Energy: 2.712582181766774, Validation Loss Force: 1.964550496081958, time: 0.12984251976013184
Test Loss Energy: 12.63707563913359, Test Loss Force: 7.254923855605578, time: 10.142477035522461

Epoch 19, Batch 100/136, Loss: 0.05603112280368805, Uncertainty: 0.12123912572860718

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5659135651447063, Training Loss Force: 1.8242237579614409, time: 2.1121692657470703
Validation Loss Energy: 2.7613603075428608, Validation Loss Force: 2.065844100802433, time: 0.12970924377441406
Test Loss Energy: 12.869313244325307, Test Loss Force: 7.356107462156569, time: 10.270158290863037

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–â–…â–‚â–ˆâ–„â–‚â–…â–ƒâ–…â–â–‡â–ˆâ–†â–ƒâ–…â–ƒâ–ƒâ–‡â–ˆ
wandb:   test_error_force â–‚â–â–ˆâ–ƒâ–ˆâ–„â–„â–…â–„â–ƒâ–ƒâ–ƒâ–†â–„â–â–‚â–ƒâ–â–â–…
wandb:          test_loss â–‚â–â–†â–‚â–ˆâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–…â–„â–…â–„â–ƒâ–ƒâ–ƒâ–ƒâ–†
wandb: train_error_energy â–ˆâ–‚â–†â–„â–†â–ƒâ–ƒâ–†â–„â–…â–…â–ƒâ–ˆâ–„â–â–†â–„â–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–…â–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb: valid_error_energy â–…â–‡â–‚â–…â–†â–ƒâ–…â–‚â–â–ƒâ–ˆâ–„â–†â–…â–‚â–ƒâ–‚â–â–…â–†
wandb:  valid_error_force â–ˆâ–†â–…â–‚â–…â–‚â–†â–„â–„â–‚â–‚â–„â–‚â–‡â–…â–…â–…â–‚â–â–ƒ
wandb:         valid_loss â–ˆâ–‡â–„â–‚â–…â–‚â–†â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‡â–„â–…â–…â–â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4325
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 12.86931
wandb:   test_error_force 7.35611
wandb:          test_loss 5.57385
wandb: train_error_energy 1.56591
wandb:  train_error_force 1.82422
wandb:         train_loss -2.65287
wandb: valid_error_energy 2.76136
wandb:  valid_error_force 2.06584
wandb:         valid_loss -2.24014
wandb: 
wandb: ğŸš€ View run al_69_50 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m27rp20t
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_100620-m27rp20t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.40878677368164, Uncertainty Bias: -4.649154186248779
3.8146973e-06 0.029799461
0.4981732 5.5229645
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2219 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2435 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1440 steps.
Found uncertainty sample 13 after 3962 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2382 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1916 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2455 steps.
Found uncertainty sample 24 after 3382 steps.
Found uncertainty sample 25 after 2432 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 422 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 823 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 794 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2203 steps.
Found uncertainty sample 39 after 3675 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1459 steps.
Found uncertainty sample 42 after 2356 steps.
Found uncertainty sample 43 after 681 steps.
Found uncertainty sample 44 after 825 steps.
Found uncertainty sample 45 after 1990 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2851 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1455 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1395 steps.
Found uncertainty sample 55 after 3100 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1276 steps.
Found uncertainty sample 60 after 1795 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2029 steps.
Found uncertainty sample 68 after 966 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1760 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1676 steps.
Found uncertainty sample 78 after 1852 steps.
Found uncertainty sample 79 after 1838 steps.
Found uncertainty sample 80 after 2746 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2431 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1966 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 858 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1853 steps.
Found uncertainty sample 95 after 3461 steps.
Found uncertainty sample 96 after 3956 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1305 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_104355-q1xg3vyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_51
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/q1xg3vyw
Training model 51. Added 39 samples to the dataset.
Epoch 0, Batch 100/137, Loss: 0.14181695878505707, Uncertainty: 0.12326480448246002

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6011508906173146, Training Loss Force: 1.979920474156427, time: 2.1449661254882812
Validation Loss Energy: 2.545834536262534, Validation Loss Force: 2.0454386260465616, time: 0.1480565071105957
Test Loss Energy: 9.529763460681819, Test Loss Force: 7.288152282613423, time: 10.991005182266235

Epoch 1, Batch 100/137, Loss: 0.15645140409469604, Uncertainty: 0.12195345759391785

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5407979244648835, Training Loss Force: 1.8165922801689587, time: 2.159827709197998
Validation Loss Energy: 1.7277753710942179, Validation Loss Force: 1.9883679301608808, time: 0.15057730674743652
Test Loss Energy: 11.574986919939398, Test Loss Force: 7.1994469500775935, time: 11.137061595916748

Epoch 2, Batch 100/137, Loss: 0.11380423605442047, Uncertainty: 0.12365700304508209

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0493097711360075, Training Loss Force: 1.8367797599347575, time: 2.349604368209839
Validation Loss Energy: 1.4899391905146073, Validation Loss Force: 1.9271363272798199, time: 0.15141749382019043
Test Loss Energy: 11.409756760778636, Test Loss Force: 7.21474048023442, time: 11.088810443878174

Epoch 3, Batch 100/137, Loss: 0.09535254538059235, Uncertainty: 0.12248258292675018

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5295159240936491, Training Loss Force: 1.8355768491981443, time: 2.155989646911621
Validation Loss Energy: 1.4668997995430806, Validation Loss Force: 2.1060395185717824, time: 0.13690400123596191
Test Loss Energy: 10.272706853660956, Test Loss Force: 7.27060776791008, time: 11.127450466156006

Epoch 4, Batch 100/137, Loss: 0.04580753669142723, Uncertainty: 0.12126630544662476

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5460712267827261, Training Loss Force: 1.8181969543083596, time: 2.1390419006347656
Validation Loss Energy: 2.8572360008276703, Validation Loss Force: 2.1077299485046175, time: 0.13923883438110352
Test Loss Energy: 12.804268952075871, Test Loss Force: 7.2466631543860185, time: 12.00679349899292

Epoch 5, Batch 100/137, Loss: 0.04622562974691391, Uncertainty: 0.12244163453578949

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.750339392288658, Training Loss Force: 1.8779726263103866, time: 2.116213083267212
Validation Loss Energy: 2.3565575234655154, Validation Loss Force: 2.107358016807869, time: 0.13835954666137695
Test Loss Energy: 12.145579525560201, Test Loss Force: 7.3164681316283, time: 11.072431564331055

Epoch 6, Batch 100/137, Loss: 0.1282014101743698, Uncertainty: 0.12402848154306412

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6552415885182945, Training Loss Force: 1.844933353887057, time: 2.143663167953491
Validation Loss Energy: 2.039130928703768, Validation Loss Force: 2.158270426347674, time: 0.13842463493347168
Test Loss Energy: 10.34285506781394, Test Loss Force: 7.192333298069392, time: 11.223014116287231

Epoch 7, Batch 100/137, Loss: 0.13701923191547394, Uncertainty: 0.12135367095470428

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9044928332459246, Training Loss Force: 1.8185238399285317, time: 2.132570743560791
Validation Loss Energy: 3.325649496275742, Validation Loss Force: 2.0872616810495948, time: 0.1415562629699707
Test Loss Energy: 9.571073455661649, Test Loss Force: 7.244656497348742, time: 11.000179529190063

Epoch 8, Batch 100/137, Loss: 0.13802284002304077, Uncertainty: 0.12137448042631149

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.070900272530744, Training Loss Force: 1.808146000626915, time: 2.092742919921875
Validation Loss Energy: 1.7242003437332987, Validation Loss Force: 1.9867029216222056, time: 0.14562201499938965
Test Loss Energy: 9.838976866301593, Test Loss Force: 7.155708921766669, time: 11.182791471481323

Epoch 9, Batch 100/137, Loss: 0.1489807814359665, Uncertainty: 0.12172424793243408

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6043918168656985, Training Loss Force: 1.8385055847807488, time: 2.1558828353881836
Validation Loss Energy: 1.7090094834828615, Validation Loss Force: 2.0343398309138885, time: 0.13595867156982422
Test Loss Energy: 11.554184939828646, Test Loss Force: 7.190176338192808, time: 11.017427206039429

Epoch 10, Batch 100/137, Loss: 0.08658740669488907, Uncertainty: 0.12142084538936615

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7986272306738738, Training Loss Force: 1.8341808062965441, time: 2.1445188522338867
Validation Loss Energy: 1.0250745588028076, Validation Loss Force: 1.9862225129398663, time: 0.14541339874267578
Test Loss Energy: 10.709059664387622, Test Loss Force: 7.284284920586283, time: 11.16726803779602

Epoch 11, Batch 100/137, Loss: 0.08482826501131058, Uncertainty: 0.12270998954772949

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6556124797379266, Training Loss Force: 1.854594608119989, time: 2.451138734817505
Validation Loss Energy: 3.874952531926343, Validation Loss Force: 2.092657214236095, time: 0.1355597972869873
Test Loss Energy: 13.515544171244947, Test Loss Force: 7.299089191836574, time: 11.138712644577026

Epoch 12, Batch 100/137, Loss: 0.12536577880382538, Uncertainty: 0.1211528405547142

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.75449020562664, Training Loss Force: 1.819816075124429, time: 2.2057878971099854
Validation Loss Energy: 1.2070549449126813, Validation Loss Force: 1.9648058233692887, time: 0.14696073532104492
Test Loss Energy: 11.229904382795995, Test Loss Force: 7.1957112799460665, time: 11.136338710784912

Epoch 13, Batch 100/137, Loss: 0.08710530400276184, Uncertainty: 0.12178213149309158

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8226491608999493, Training Loss Force: 1.8050071368847327, time: 2.1836740970611572
Validation Loss Energy: 3.428697288527836, Validation Loss Force: 2.205985640955675, time: 0.13717865943908691
Test Loss Energy: 12.858502990711328, Test Loss Force: 7.161603580279042, time: 11.110801935195923

Epoch 14, Batch 100/137, Loss: 0.060275472700595856, Uncertainty: 0.12001405656337738

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8627741544050451, Training Loss Force: 1.8089307192036093, time: 2.2730042934417725
Validation Loss Energy: 2.2552658114327806, Validation Loss Force: 2.1922052784101176, time: 0.14547514915466309
Test Loss Energy: 10.113926783127072, Test Loss Force: 7.158997143495586, time: 11.082218408584595

Epoch 15, Batch 100/137, Loss: 0.06520383059978485, Uncertainty: 0.12194983661174774

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.535605805367259, Training Loss Force: 1.8254106894261761, time: 2.0917975902557373
Validation Loss Energy: 2.153212088471157, Validation Loss Force: 2.0006922591612164, time: 0.13536882400512695
Test Loss Energy: 9.716330243728205, Test Loss Force: 7.213051974271814, time: 11.2282395362854

Epoch 16, Batch 100/137, Loss: 0.05024271458387375, Uncertainty: 0.12087289988994598

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6734978368396114, Training Loss Force: 1.799972488350649, time: 2.1934046745300293
Validation Loss Energy: 2.9641369342039474, Validation Loss Force: 2.001776323898165, time: 0.1426239013671875
Test Loss Energy: 13.151198127581317, Test Loss Force: 7.300629913103093, time: 10.987348318099976

Epoch 17, Batch 100/137, Loss: 0.15108352899551392, Uncertainty: 0.12164957821369171

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4462191636926691, Training Loss Force: 1.8295037944792818, time: 2.1310834884643555
Validation Loss Energy: 3.463800559822012, Validation Loss Force: 2.3527915944234867, time: 0.1428234577178955
Test Loss Energy: 12.976615910923869, Test Loss Force: 7.275602558615985, time: 11.171788930892944

Epoch 18, Batch 100/137, Loss: 0.14191487431526184, Uncertainty: 0.12133044004440308

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0804690093588656, Training Loss Force: 1.8105437840690384, time: 2.0794668197631836
Validation Loss Energy: 1.686446307591426, Validation Loss Force: 1.9390921017321203, time: 0.13725495338439941
Test Loss Energy: 11.69949879648175, Test Loss Force: 7.218645360263942, time: 11.117809534072876

Epoch 19, Batch 100/137, Loss: 0.0582074299454689, Uncertainty: 0.12017969787120819

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.5211463829315996, Training Loss Force: 1.7987639873182153, time: 2.172274589538574
Validation Loss Energy: 4.329708912201128, Validation Loss Force: 2.2300702408981867, time: 0.14040803909301758
Test Loss Energy: 13.52521311374985, Test Loss Force: 7.2055257804555986, time: 10.994812488555908

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–„â–‚â–‡â–†â–‚â–â–‚â–…â–ƒâ–ˆâ–„â–‡â–‚â–â–‡â–‡â–…â–ˆ
wandb:   test_error_force â–‡â–ƒâ–„â–†â–…â–ˆâ–ƒâ–…â–â–ƒâ–‡â–‡â–ƒâ–â–â–ƒâ–‡â–†â–„â–ƒ
wandb:          test_loss â–â–ƒâ–„â–ƒâ–…â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–ˆâ–ƒâ–…â–‚â–ƒâ–ˆâ–†â–…â–†
wandb: train_error_energy â–ˆâ–‚â–…â–‚â–‚â–ƒâ–‚â–„â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–‚â–â–…â–ˆ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–„â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–ƒâ–‚â–â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–„â–‚â–‚â–‚â–…â–„â–ƒâ–†â–‚â–‚â–â–‡â–â–†â–„â–ƒâ–…â–†â–‚â–ˆ
wandb:  valid_error_force â–ƒâ–‚â–â–„â–„â–„â–…â–„â–‚â–ƒâ–‚â–„â–‚â–†â–…â–‚â–‚â–ˆâ–â–†
wandb:         valid_loss â–ƒâ–‚â–â–ƒâ–„â–„â–„â–„â–‚â–ƒâ–â–…â–â–†â–…â–‚â–ƒâ–ˆâ–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 4360
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 13.52521
wandb:   test_error_force 7.20553
wandb:          test_loss 5.50365
wandb: train_error_energy 2.52115
wandb:  train_error_force 1.79876
wandb:         train_loss -2.62422
wandb: valid_error_energy 4.32971
wandb:  valid_error_force 2.23007
wandb:         valid_loss -1.90341
wandb: 
wandb: ğŸš€ View run al_69_51 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/q1xg3vyw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_104355-q1xg3vyw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 30.179227828979492, Uncertainty Bias: -3.4942619800567627
1.1444092e-05 0.01408577
0.9902934 4.3900843
(48745, 22, 3)
Found uncertainty sample 0 after 2187 steps.
Found uncertainty sample 1 after 2950 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2160 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 729 steps.
Found uncertainty sample 20 after 1458 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1960 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2007 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2212 steps.
Found uncertainty sample 35 after 2538 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3656 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2392 steps.
Found uncertainty sample 42 after 2503 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 732 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2630 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2354 steps.
Found uncertainty sample 50 after 3057 steps.
Found uncertainty sample 51 after 1808 steps.
Found uncertainty sample 52 after 2153 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2601 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1778 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3124 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2472 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1512 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2822 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1348 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 668 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2996 steps.
Found uncertainty sample 98 after 3540 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_112358-hfe28xuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_52
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hfe28xuy
Training model 52. Added 28 samples to the dataset.
Epoch 0, Batch 100/138, Loss: 0.10421237349510193, Uncertainty: 0.12383915483951569
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3162606061550632, Training Loss Force: 1.9005762821711383, time: 2.098151922225952
Validation Loss Energy: 1.0041274784609915, Validation Loss Force: 2.1112455974266227, time: 0.13615822792053223
Test Loss Energy: 10.132649980050182, Test Loss Force: 7.262617785739684, time: 10.716590881347656

Epoch 1, Batch 100/138, Loss: 0.03982077166438103, Uncertainty: 0.12254738807678223

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2747993932057364, Training Loss Force: 1.8256392424918082, time: 2.138401746749878
Validation Loss Energy: 1.0513186226782893, Validation Loss Force: 2.11293372644495, time: 0.13890385627746582
Test Loss Energy: 10.369639065022307, Test Loss Force: 7.220558018279037, time: 11.5633065700531

Epoch 2, Batch 100/138, Loss: 0.10814455151557922, Uncertainty: 0.12336838990449905

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8472630413949698, Training Loss Force: 1.8550313462783579, time: 2.2712254524230957
Validation Loss Energy: 1.4224579512705535, Validation Loss Force: 2.1292425342540415, time: 0.1323103904724121
Test Loss Energy: 10.814956927275194, Test Loss Force: 7.1827223777812055, time: 10.217902660369873

Epoch 3, Batch 100/138, Loss: 0.14966243505477905, Uncertainty: 0.12419597804546356

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1484754994427826, Training Loss Force: 1.8853295061483615, time: 2.1278250217437744
Validation Loss Energy: 1.7192468088014647, Validation Loss Force: 2.0876333900771966, time: 0.13957977294921875
Test Loss Energy: 11.112064256769168, Test Loss Force: 7.1634208076609065, time: 10.943288803100586

Epoch 4, Batch 100/138, Loss: 0.05168776959180832, Uncertainty: 0.12279099225997925

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6351856987712903, Training Loss Force: 1.8305849702884058, time: 2.1410903930664062
Validation Loss Energy: 4.066663021596157, Validation Loss Force: 2.056099802084438, time: 0.1336803436279297
Test Loss Energy: 13.612367486901672, Test Loss Force: 7.243184458438575, time: 10.61265516281128

Epoch 5, Batch 100/138, Loss: 0.07116448879241943, Uncertainty: 0.12302456796169281

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.185004772184509, Training Loss Force: 1.8801829444972646, time: 2.185720205307007
Validation Loss Energy: 6.19238025793187, Validation Loss Force: 2.122877165602452, time: 0.13555383682250977
Test Loss Energy: 8.984016576810244, Test Loss Force: 7.284963881947076, time: 11.199963808059692

Epoch 6, Batch 100/138, Loss: 0.03731479495763779, Uncertainty: 0.12318132817745209

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0819981704973225, Training Loss Force: 1.8631935234337043, time: 2.122512102127075
Validation Loss Energy: 3.5177690291666264, Validation Loss Force: 2.078992862315566, time: 0.14117717742919922
Test Loss Energy: 9.094223758401201, Test Loss Force: 7.1707913102776475, time: 11.492345809936523

Epoch 7, Batch 100/138, Loss: 0.08021463453769684, Uncertainty: 0.12394074350595474

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9458312548329706, Training Loss Force: 1.8614046438877958, time: 2.1611618995666504
Validation Loss Energy: 2.7163674088014496, Validation Loss Force: 2.4268866825302235, time: 0.13733196258544922
Test Loss Energy: 9.897862232565682, Test Loss Force: 7.392678810559962, time: 11.494254112243652

Epoch 8, Batch 100/138, Loss: 0.14140957593917847, Uncertainty: 0.12330088019371033

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7058004628831551, Training Loss Force: 1.8381842148329073, time: 2.1637074947357178
Validation Loss Energy: 1.0359908765703931, Validation Loss Force: 2.1555334514289783, time: 0.14681077003479004
Test Loss Energy: 10.2126242595186, Test Loss Force: 7.293431656145895, time: 11.18452262878418

Epoch 9, Batch 100/138, Loss: 0.10006244480609894, Uncertainty: 0.12366631627082825

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8698516681277535, Training Loss Force: 1.8467212191906708, time: 2.071838140487671
Validation Loss Energy: 3.4930275181321035, Validation Loss Force: 2.1894456283500614, time: 0.14946556091308594
Test Loss Energy: 12.741422593157493, Test Loss Force: 7.1526121581974245, time: 11.164040327072144

Epoch 10, Batch 100/138, Loss: 0.08506416529417038, Uncertainty: 0.12116637825965881

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8306981390581207, Training Loss Force: 1.8257516282890367, time: 2.122166872024536
Validation Loss Energy: 0.9756975272472236, Validation Loss Force: 2.125554539413088, time: 0.14153647422790527
Test Loss Energy: 10.64717590302128, Test Loss Force: 7.262156723042381, time: 11.084754705429077

Epoch 11, Batch 100/138, Loss: 0.06907057017087936, Uncertainty: 0.12200801819562912

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.534194171169058, Training Loss Force: 1.8522008043323532, time: 2.30283260345459
Validation Loss Energy: 3.4537283436751136, Validation Loss Force: 1.9980106175252839, time: 0.1848280429840088
Test Loss Energy: 9.310167965032766, Test Loss Force: 7.134083795611194, time: 11.11314845085144

Epoch 12, Batch 100/138, Loss: 0.16522467136383057, Uncertainty: 0.12226477265357971

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7622913392042663, Training Loss Force: 1.8495622491761574, time: 2.1436383724212646
Validation Loss Energy: 1.2144186321242754, Validation Loss Force: 2.043473199718506, time: 0.14546799659729004
Test Loss Energy: 10.85324857786259, Test Loss Force: 7.2220316147074195, time: 11.128116846084595

Epoch 13, Batch 100/138, Loss: 0.12304584681987762, Uncertainty: 0.12242361158132553

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8634257798578775, Training Loss Force: 1.8250277155669528, time: 2.127561569213867
Validation Loss Energy: 1.7680913642060867, Validation Loss Force: 2.0193973952072586, time: 0.156022310256958
Test Loss Energy: 9.662828345907789, Test Loss Force: 7.103826068793401, time: 11.305049419403076

Epoch 14, Batch 100/138, Loss: 0.08318774402141571, Uncertainty: 0.12257318198680878

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.897846562958834, Training Loss Force: 1.829108580265322, time: 2.134127616882324
Validation Loss Energy: 1.0197356392466592, Validation Loss Force: 2.3481539156751516, time: 0.13697433471679688
Test Loss Energy: 10.213090988038148, Test Loss Force: 7.186911129494994, time: 11.110808849334717

Epoch 15, Batch 100/138, Loss: 0.23298577964305878, Uncertainty: 0.1213579922914505

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6539389962980204, Training Loss Force: 1.8301257232426529, time: 2.129000663757324
Validation Loss Energy: 2.255622416069984, Validation Loss Force: 2.2736143057300953, time: 0.14769673347473145
Test Loss Energy: 9.648081427700967, Test Loss Force: 7.246553209455054, time: 11.41151237487793

Epoch 16, Batch 100/138, Loss: 0.09369920194149017, Uncertainty: 0.12078006565570831

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.073382695838312, Training Loss Force: 1.8258030204892715, time: 2.1433424949645996
Validation Loss Energy: 2.412055804065703, Validation Loss Force: 1.9877593011620114, time: 0.14386487007141113
Test Loss Energy: 11.759178100660812, Test Loss Force: 7.194616307335483, time: 11.181947946548462

Epoch 17, Batch 100/138, Loss: 0.13298603892326355, Uncertainty: 0.12168771028518677

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8876029068982445, Training Loss Force: 1.8258211276860512, time: 2.1452906131744385
Validation Loss Energy: 1.7295726451055742, Validation Loss Force: 2.5897396962260895, time: 0.13782072067260742
Test Loss Energy: 11.209916551031178, Test Loss Force: 7.193446077216807, time: 11.264904499053955

Epoch 18, Batch 100/138, Loss: 0.045323748141527176, Uncertainty: 0.12220124900341034

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6080971448142738, Training Loss Force: 1.8518800260312485, time: 2.0880675315856934
Validation Loss Energy: 1.0780986326322568, Validation Loss Force: 2.2174782264729216, time: 0.13715410232543945
Test Loss Energy: 10.576130348531505, Test Loss Force: 7.235278512303338, time: 12.056834936141968

Epoch 19, Batch 100/138, Loss: 0.0524747297167778, Uncertainty: 0.1215057522058487

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.003797156118489, Training Loss Force: 1.854650749040681, time: 2.077704668045044
Validation Loss Energy: 1.4501704810519043, Validation Loss Force: 2.0672279153213253, time: 0.1367168426513672
Test Loss Energy: 9.657603982146625, Test Loss Force: 7.227899354735081, time: 11.186405897140503

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.057 MB uploadedwandb: / 0.039 MB of 0.057 MB uploadedwandb: - 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–„â–„â–ˆâ–â–â–‚â–ƒâ–‡â–„â–â–„â–‚â–ƒâ–‚â–…â–„â–ƒâ–‚
wandb:   test_error_force â–…â–„â–ƒâ–‚â–„â–…â–ƒâ–ˆâ–†â–‚â–…â–‚â–„â–â–ƒâ–„â–ƒâ–ƒâ–„â–„
wandb:          test_loss â–…â–…â–„â–„â–ˆâ–ƒâ–â–†â–†â–…â–†â–ƒâ–…â–‚â–„â–…â–†â–†â–…â–„
wandb: train_error_energy â–ˆâ–â–ƒâ–„â–‚â–„â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–â–„â–‡â–‚â–†â–…â–„â–‚â–ƒâ–â–„â–ƒâ–â–â–â–â–â–ƒâ–„
wandb:         train_loss â–ˆâ–â–ƒâ–…â–‚â–…â–„â–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–„
wandb: valid_error_energy â–â–â–‚â–‚â–…â–ˆâ–„â–ƒâ–â–„â–â–„â–â–‚â–â–ƒâ–ƒâ–‚â–â–‚
wandb:  valid_error_force â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–ƒâ–â–‚â–â–…â–„â–â–ˆâ–„â–‚
wandb:         valid_loss â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–†â–‚â–„â–‚â–‚â–â–â–…â–„â–â–ˆâ–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4385
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 9.6576
wandb:   test_error_force 7.2279
wandb:          test_loss 5.14781
wandb: train_error_energy 2.0038
wandb:  train_error_force 1.85465
wandb:         train_loss -2.5821
wandb: valid_error_energy 1.45017
wandb:  valid_error_force 2.06723
wandb:         valid_loss -2.32725
wandb: 
wandb: ğŸš€ View run al_69_52 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hfe28xuy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_112358-hfe28xuy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.484235763549805, Uncertainty Bias: -2.113441228866577
7.6293945e-06 0.0005722046
1.3533938 4.162018
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2683 steps.
Found uncertainty sample 9 after 2666 steps.
Found uncertainty sample 10 after 2647 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3275 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3168 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1886 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2794 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3719 steps.
Found uncertainty sample 62 after 3113 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3969 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1361 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1942 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1580 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_120702-0jtvta28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_53
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0jtvta28
Training model 53. Added 13 samples to the dataset.
Epoch 0, Batch 100/138, Loss: 0.19044014811515808, Uncertainty: 0.12436556816101074

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.2803119846855857, Training Loss Force: 2.005695314581623, time: 2.1444809436798096
Validation Loss Energy: 3.017144957299127, Validation Loss Force: 2.1750870682555785, time: 0.14433598518371582
Test Loss Energy: 9.47471144052686, Test Loss Force: 7.114159115614095, time: 11.146448612213135

Epoch 1, Batch 100/138, Loss: 0.18000423908233643, Uncertainty: 0.12263929098844528

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5583113132794593, Training Loss Force: 1.835327039720796, time: 2.210817813873291
Validation Loss Energy: 3.240187445161587, Validation Loss Force: 1.9740851146875371, time: 0.1391589641571045
Test Loss Energy: 12.787286333052917, Test Loss Force: 7.077860831863645, time: 11.109336376190186

Epoch 2, Batch 100/138, Loss: 0.07172746956348419, Uncertainty: 0.12186020612716675

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5520445406701109, Training Loss Force: 1.815988244566274, time: 2.3951785564422607
Validation Loss Energy: 1.8620851692040867, Validation Loss Force: 1.9878466616902637, time: 0.14889287948608398
Test Loss Energy: 11.408528084089479, Test Loss Force: 7.152098335736417, time: 10.764985084533691

Epoch 3, Batch 100/138, Loss: 0.043580375611782074, Uncertainty: 0.12035508453845978

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.897452035587794, Training Loss Force: 1.8047952563510121, time: 2.1316473484039307
Validation Loss Energy: 1.1988632624819546, Validation Loss Force: 2.1236853803791216, time: 0.135453462600708
Test Loss Energy: 10.608724382981952, Test Loss Force: 7.114612211186039, time: 10.601624250411987

Epoch 4, Batch 100/138, Loss: 0.29200616478919983, Uncertainty: 0.12046393752098083

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.590239147483122, Training Loss Force: 1.823053136407518, time: 2.1359918117523193
Validation Loss Energy: 1.209680232698932, Validation Loss Force: 1.9885183431689548, time: 0.13126349449157715
Test Loss Energy: 9.96858248958359, Test Loss Force: 7.145866108467201, time: 10.30728268623352

Epoch 5, Batch 100/138, Loss: 0.2129814326763153, Uncertainty: 0.12456951290369034

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.5844474073002504, Training Loss Force: 1.9552034423473874, time: 2.1641993522644043
Validation Loss Energy: 2.914368079174578, Validation Loss Force: 2.181636472956277, time: 0.15138959884643555
Test Loss Energy: 9.506775126035604, Test Loss Force: 7.114321573157672, time: 10.717926502227783

Epoch 6, Batch 100/138, Loss: 0.1575101912021637, Uncertainty: 0.12201084196567535

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7989721504013803, Training Loss Force: 1.808999464427552, time: 2.0797719955444336
Validation Loss Energy: 2.210704111492458, Validation Loss Force: 2.1307970617848118, time: 0.1294562816619873
Test Loss Energy: 11.669864391717642, Test Loss Force: 7.267730518812893, time: 10.458519458770752

Epoch 7, Batch 100/138, Loss: 0.17280977964401245, Uncertainty: 0.12299846112728119

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.940031690498115, Training Loss Force: 1.8676341738723288, time: 2.2847719192504883
Validation Loss Energy: 1.6213958175231307, Validation Loss Force: 1.9523112638068911, time: 0.13816308975219727
Test Loss Energy: 9.481272313465778, Test Loss Force: 7.03338177695637, time: 11.42177438735962

Epoch 8, Batch 100/138, Loss: 0.08816675841808319, Uncertainty: 0.12296472489833832

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9078983992314724, Training Loss Force: 1.8338790238783718, time: 2.1342227458953857
Validation Loss Energy: 2.911887025327603, Validation Loss Force: 2.111833369748823, time: 0.1508777141571045
Test Loss Energy: 12.646225951389221, Test Loss Force: 7.197774494946409, time: 11.635715007781982

Epoch 9, Batch 100/138, Loss: 0.0764298290014267, Uncertainty: 0.12148036807775497

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.880099260833623, Training Loss Force: 1.8269560295639151, time: 2.232971429824829
Validation Loss Energy: 1.4337715293502364, Validation Loss Force: 1.9997124778076099, time: 0.14792394638061523
Test Loss Energy: 9.654882801970402, Test Loss Force: 7.05644233101752, time: 11.660800457000732

Epoch 10, Batch 100/138, Loss: 0.045443095266819, Uncertainty: 0.12152624130249023

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9181070466196566, Training Loss Force: 1.8466159273419929, time: 2.2067840099334717
Validation Loss Energy: 2.6184387059911867, Validation Loss Force: 1.9946307967822943, time: 0.13674449920654297
Test Loss Energy: 9.553218929548436, Test Loss Force: 7.036399662020831, time: 10.89610505104065

Epoch 11, Batch 100/138, Loss: 0.06424769014120102, Uncertainty: 0.12178905308246613

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9283770885706517, Training Loss Force: 1.8257127128219248, time: 2.2150514125823975
Validation Loss Energy: 1.7496702797671997, Validation Loss Force: 2.2653658241113948, time: 0.14331364631652832
Test Loss Energy: 9.897637017297164, Test Loss Force: 7.1264201205015665, time: 12.255221366882324

Epoch 12, Batch 100/138, Loss: 0.12352599948644638, Uncertainty: 0.12002372741699219

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4233441635799204, Training Loss Force: 1.785743090441041, time: 2.098106622695923
Validation Loss Energy: 1.487748682791543, Validation Loss Force: 2.088141521068204, time: 0.14801931381225586
Test Loss Energy: 9.849641976938253, Test Loss Force: 7.109415724202976, time: 11.324854612350464

Epoch 13, Batch 100/138, Loss: 0.065403513610363, Uncertainty: 0.1204400286078453

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9874814161186856, Training Loss Force: 1.8289762276612358, time: 2.1817150115966797
Validation Loss Energy: 1.1011985524999515, Validation Loss Force: 2.0027762568094785, time: 0.1416478157043457
Test Loss Energy: 10.913851709514548, Test Loss Force: 7.061958048612577, time: 11.432589292526245

Epoch 14, Batch 100/138, Loss: 0.2644335627555847, Uncertainty: 0.12055910378694534

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8282202864835035, Training Loss Force: 1.8218087442380946, time: 2.194490432739258
Validation Loss Energy: 3.21957013782489, Validation Loss Force: 2.078372060736719, time: 0.14081692695617676
Test Loss Energy: 12.616003718732776, Test Loss Force: 7.131426676532187, time: 11.445388078689575

Epoch 15, Batch 100/138, Loss: 0.20340362191200256, Uncertainty: 0.12082792818546295

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.299076888639854, Training Loss Force: 1.8356863470450961, time: 2.2764503955841064
Validation Loss Energy: 1.0468600627020908, Validation Loss Force: 2.0343618009362867, time: 0.14139485359191895
Test Loss Energy: 9.649518993696763, Test Loss Force: 7.132926496624276, time: 11.384102582931519

Epoch 16, Batch 100/138, Loss: 0.10489706695079803, Uncertainty: 0.12363988906145096

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7445602249646102, Training Loss Force: 1.8747048284878822, time: 2.216176748275757
Validation Loss Energy: 1.7971325422254267, Validation Loss Force: 2.0566720246779484, time: 0.15193748474121094
Test Loss Energy: 11.107596986757068, Test Loss Force: 7.065650838029308, time: 11.283852577209473

Epoch 17, Batch 100/138, Loss: 0.07847216725349426, Uncertainty: 0.12272205948829651

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6170794678996658, Training Loss Force: 1.8325737163688642, time: 2.1470108032226562
Validation Loss Energy: 1.2377791862272784, Validation Loss Force: 2.224447176956072, time: 0.14556384086608887
Test Loss Energy: 10.206818670996213, Test Loss Force: 7.066067364565812, time: 11.443712711334229

Epoch 18, Batch 100/138, Loss: 0.054015275090932846, Uncertainty: 0.12275653332471848

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8113595980368637, Training Loss Force: 1.851522691265143, time: 2.1458399295806885
Validation Loss Energy: 0.9693199117926086, Validation Loss Force: 2.0886015184121667, time: 0.15278148651123047
Test Loss Energy: 10.531382752302628, Test Loss Force: 7.112352606662219, time: 11.287636995315552

Epoch 19, Batch 100/138, Loss: 0.17537915706634521, Uncertainty: 0.12175857275724411

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5758105244611953, Training Loss Force: 1.8264863178750754, time: 2.1474149227142334
Validation Loss Energy: 1.6086278573610582, Validation Loss Force: 2.106716210106257, time: 0.14516973495483398
Test Loss Energy: 11.018688433068466, Test Loss Force: 7.113577909505781, time: 11.338146448135376

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–…â–ƒâ–‚â–â–†â–â–ˆâ–â–â–‚â–‚â–„â–ˆâ–â–„â–ƒâ–ƒâ–„
wandb:   test_error_force â–ƒâ–‚â–…â–ƒâ–„â–ƒâ–ˆâ–â–†â–‚â–â–„â–ƒâ–‚â–„â–„â–‚â–‚â–ƒâ–ƒ
wandb:          test_loss â–‚â–…â–†â–…â–…â–â–ˆâ–‚â–ˆâ–„â–ƒâ–…â–†â–…â–‡â–„â–‚â–‚â–ƒâ–…
wandb: train_error_energy â–†â–‚â–‚â–„â–‚â–ˆâ–ƒâ–„â–„â–„â–„â–„â–â–„â–ƒâ–†â–ƒâ–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–†â–‚â–„â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–ƒâ–„â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‡â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–‚
wandb: valid_error_energy â–‡â–ˆâ–„â–‚â–‚â–‡â–…â–ƒâ–‡â–‚â–†â–ƒâ–ƒâ–â–ˆâ–â–„â–‚â–â–ƒ
wandb:  valid_error_force â–†â–â–‚â–…â–‚â–†â–…â–â–…â–‚â–‚â–ˆâ–„â–‚â–„â–ƒâ–ƒâ–‡â–„â–„
wandb:         valid_loss â–‡â–ƒâ–‚â–„â–â–‡â–†â–â–†â–‚â–ƒâ–ˆâ–„â–‚â–†â–‚â–ƒâ–†â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4396
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 11.01869
wandb:   test_error_force 7.11358
wandb:          test_loss 5.15499
wandb: train_error_energy 1.57581
wandb:  train_error_force 1.82649
wandb:         train_loss -2.64916
wandb: valid_error_energy 1.60863
wandb:  valid_error_force 2.10672
wandb:         valid_loss -2.2607
wandb: 
wandb: ğŸš€ View run al_69_53 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0jtvta28
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_120702-0jtvta28/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 44.2593994140625, Uncertainty Bias: -5.23422384262085
1.5258789e-05 0.041172028
0.45168704 8.141482
(48745, 22, 3)
Found uncertainty sample 0 after 1731 steps.
Found uncertainty sample 1 after 2432 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2287 steps.
Found uncertainty sample 8 after 2703 steps.
Found uncertainty sample 9 after 1291 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3171 steps.
Found uncertainty sample 12 after 3666 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 262 steps.
Found uncertainty sample 17 after 3242 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1116 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2693 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3272 steps.
Found uncertainty sample 27 after 212 steps.
Found uncertainty sample 28 after 2326 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2853 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1289 steps.
Found uncertainty sample 34 after 1863 steps.
Found uncertainty sample 35 after 2573 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2527 steps.
Found uncertainty sample 40 after 3041 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1268 steps.
Found uncertainty sample 43 after 1844 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3854 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2002 steps.
Found uncertainty sample 48 after 2970 steps.
Found uncertainty sample 49 after 1607 steps.
Found uncertainty sample 50 after 3561 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2742 steps.
Found uncertainty sample 53 after 1824 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 610 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2752 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1922 steps.
Found uncertainty sample 71 after 1878 steps.
Found uncertainty sample 72 after 3917 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1477 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2895 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2079 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 420 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2947 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 940 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2297 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 356 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_124419-nyrwgvf2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_54
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nyrwgvf2
Training model 54. Added 42 samples to the dataset.
Epoch 0, Batch 100/139, Loss: 0.05296185612678528, Uncertainty: 0.12461545318365097

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.871449084814771, Training Loss Force: 1.9976328414309283, time: 2.3957161903381348
Validation Loss Energy: 1.58573290444219, Validation Loss Force: 2.0549733188751897, time: 0.16337060928344727
Test Loss Energy: 9.442426652716863, Test Loss Force: 7.152486556477823, time: 12.067797660827637

Epoch 1, Batch 100/139, Loss: 0.1637450009584427, Uncertainty: 0.12334880232810974

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6818414490470492, Training Loss Force: 1.839209472627522, time: 2.425757646560669
Validation Loss Energy: 2.5101630875309997, Validation Loss Force: 2.1009449969590515, time: 0.1594529151916504
Test Loss Energy: 9.248319219846879, Test Loss Force: 6.972897107621663, time: 12.222141742706299

Epoch 2, Batch 100/139, Loss: 0.06765294075012207, Uncertainty: 0.12190161645412445

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6162378014296535, Training Loss Force: 1.832074412296456, time: 2.5651252269744873
Validation Loss Energy: 1.7277065663281261, Validation Loss Force: 2.209167360381837, time: 0.15535593032836914
Test Loss Energy: 10.633398656483656, Test Loss Force: 7.058503349637382, time: 11.498221397399902

Epoch 3, Batch 100/139, Loss: 0.09040015190839767, Uncertainty: 0.12177804112434387

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.044318521213688, Training Loss Force: 1.8364967560972312, time: 2.308087110519409
Validation Loss Energy: 1.2594827849923842, Validation Loss Force: 2.1315948111116225, time: 0.14722847938537598
Test Loss Energy: 9.949254770411232, Test Loss Force: 7.21557586025829, time: 11.398979902267456

Epoch 4, Batch 100/139, Loss: 0.2025192677974701, Uncertainty: 0.12217824906110764

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8761134049603736, Training Loss Force: 1.8344620174562654, time: 2.33323335647583
Validation Loss Energy: 1.5184233616654088, Validation Loss Force: 1.985474567278695, time: 0.14269232749938965
Test Loss Energy: 9.290047096031001, Test Loss Force: 7.091749375668405, time: 11.430623769760132

Epoch 5, Batch 100/139, Loss: 0.09457296133041382, Uncertainty: 0.12153446674346924

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6505798557546194, Training Loss Force: 1.8382982359923472, time: 2.175807476043701
Validation Loss Energy: 1.1571708771560574, Validation Loss Force: 1.988114569784339, time: 0.14970064163208008
Test Loss Energy: 10.016138612915858, Test Loss Force: 7.058892992663388, time: 11.385817766189575

Epoch 6, Batch 100/139, Loss: 0.1535128355026245, Uncertainty: 0.12164515256881714

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7386738478302224, Training Loss Force: 1.8301040634851347, time: 2.2444212436676025
Validation Loss Energy: 1.3800730463450586, Validation Loss Force: 2.1205429620572156, time: 0.1493990421295166
Test Loss Energy: 9.961170773356134, Test Loss Force: 7.068404471942101, time: 11.524623155593872

Epoch 7, Batch 100/139, Loss: 0.241656094789505, Uncertainty: 0.1232282817363739

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2105206367885275, Training Loss Force: 1.8403486631964832, time: 2.3288722038269043
Validation Loss Energy: 4.055480725533761, Validation Loss Force: 2.063905394771888, time: 0.14583492279052734
Test Loss Energy: 8.73028606430345, Test Loss Force: 7.103635559600665, time: 11.438562393188477

Epoch 8, Batch 100/139, Loss: 0.0638243705034256, Uncertainty: 0.12110437452793121

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8199207170121516, Training Loss Force: 1.819693184387612, time: 2.1681387424468994
Validation Loss Energy: 1.3157795942613937, Validation Loss Force: 2.0543000044894284, time: 0.1410083770751953
Test Loss Energy: 10.686739966714999, Test Loss Force: 7.112601040143878, time: 11.619790077209473

Epoch 9, Batch 100/139, Loss: 0.20784226059913635, Uncertainty: 0.12048110365867615

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9979804588049952, Training Loss Force: 1.8291347766832293, time: 2.082716941833496
Validation Loss Energy: 1.6471651322237317, Validation Loss Force: 2.050441036855927, time: 0.13989782333374023
Test Loss Energy: 11.165042446084815, Test Loss Force: 6.939414676906088, time: 11.495468139648438

Epoch 10, Batch 100/139, Loss: 0.16189998388290405, Uncertainty: 0.12124064564704895

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7011352988198587, Training Loss Force: 1.823545266898889, time: 2.126725435256958
Validation Loss Energy: 0.9611511642839125, Validation Loss Force: 2.0941881759489216, time: 0.1423792839050293
Test Loss Energy: 10.0608684842144, Test Loss Force: 7.050256444578413, time: 11.501523733139038

Epoch 11, Batch 100/139, Loss: 0.10357391834259033, Uncertainty: 0.12359361350536346

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.095087223450777, Training Loss Force: 1.882055047576731, time: 2.212400197982788
Validation Loss Energy: 1.5344978844214598, Validation Loss Force: 2.0368661608205367, time: 0.15458083152770996
Test Loss Energy: 9.424516927971597, Test Loss Force: 6.985738556179636, time: 12.30285382270813

Epoch 12, Batch 100/139, Loss: 0.0907520279288292, Uncertainty: 0.12265084683895111

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7397234761429798, Training Loss Force: 1.8328817521489151, time: 2.2123262882232666
Validation Loss Energy: 2.959118416993027, Validation Loss Force: 2.0987868875967197, time: 0.14142608642578125
Test Loss Energy: 12.287394977131934, Test Loss Force: 7.078268465623993, time: 11.621733665466309

Epoch 13, Batch 100/139, Loss: 0.07916863262653351, Uncertainty: 0.12017101049423218

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.72190177379265, Training Loss Force: 1.8071987868877706, time: 2.1357076168060303
Validation Loss Energy: 2.1966003220124404, Validation Loss Force: 2.108316087919748, time: 0.14435219764709473
Test Loss Energy: 11.637647887557984, Test Loss Force: 7.123579755207724, time: 11.42350172996521

Epoch 14, Batch 100/139, Loss: 0.10296177864074707, Uncertainty: 0.12020383775234222

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8069249635104063, Training Loss Force: 1.8104450202936406, time: 2.213487386703491
Validation Loss Energy: 3.1088143561943107, Validation Loss Force: 2.052797247535086, time: 0.14379358291625977
Test Loss Energy: 12.11859587690024, Test Loss Force: 7.088090805020108, time: 11.64976978302002

Epoch 15, Batch 100/139, Loss: 0.2238197922706604, Uncertainty: 0.12050352990627289

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.056116380790214, Training Loss Force: 1.8189448222230022, time: 2.1726157665252686
Validation Loss Energy: 1.1602487585371686, Validation Loss Force: 2.0832730828616386, time: 0.1439220905303955
Test Loss Energy: 10.435527989140335, Test Loss Force: 7.116867343674029, time: 11.461421728134155

Epoch 16, Batch 100/139, Loss: 0.059001319110393524, Uncertainty: 0.12138768285512924

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.817720236434641, Training Loss Force: 1.8453721095654037, time: 2.211190938949585
Validation Loss Energy: 3.104864428214698, Validation Loss Force: 2.0384109651319346, time: 0.1419978141784668
Test Loss Energy: 12.17983906926345, Test Loss Force: 7.0569467757266455, time: 11.435909032821655

Epoch 17, Batch 100/139, Loss: 0.20427413284778595, Uncertainty: 0.12087497115135193

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2541604481517328, Training Loss Force: 1.8147642899059913, time: 2.190016031265259
Validation Loss Energy: 3.338760626703214, Validation Loss Force: 2.036852095552819, time: 0.19043850898742676
Test Loss Energy: 9.063207825654418, Test Loss Force: 6.944018581835678, time: 11.492182970046997

Epoch 18, Batch 100/139, Loss: 0.08900055289268494, Uncertainty: 0.12343503534793854

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.188926238683737, Training Loss Force: 1.8316260855924296, time: 2.2159335613250732
Validation Loss Energy: 1.6562376381284623, Validation Loss Force: 2.1016876727837692, time: 0.1485903263092041
Test Loss Energy: 10.911440773909598, Test Loss Force: 7.12786738601199, time: 11.44765830039978

Epoch 19, Batch 100/139, Loss: 0.14019279181957245, Uncertainty: 0.12239310145378113

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1410677789316432, Training Loss Force: 1.8329579923023513, time: 2.2486486434936523
Validation Loss Energy: 1.032763528525078, Validation Loss Force: 1.9793608147620043, time: 0.14768719673156738
Test Loss Energy: 10.172534901822534, Test Loss Force: 6.996542719617604, time: 11.616101026535034

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–…â–ƒâ–‚â–„â–ƒâ–â–…â–†â–„â–‚â–ˆâ–‡â–ˆâ–„â–ˆâ–‚â–…â–„
wandb:   test_error_force â–†â–‚â–„â–ˆâ–…â–„â–„â–…â–…â–â–„â–‚â–…â–†â–…â–…â–„â–â–†â–‚
wandb:          test_loss â–„â–â–…â–ˆâ–…â–„â–„â–ƒâ–†â–ƒâ–…â–â–ˆâ–ˆâ–ˆâ–‡â–†â–‚â–†â–„
wandb: train_error_energy â–ˆâ–â–â–ƒâ–‚â–â–‚â–„â–‚â–ƒâ–â–„â–‚â–‚â–‚â–ƒâ–‚â–…â–„â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–„â–‚â–â–â–â–‚â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–„â–‚â–â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–…â–ƒâ–‚â–‚â–â–‚â–ˆâ–‚â–ƒâ–â–‚â–†â–„â–†â–â–†â–†â–ƒâ–
wandb:  valid_error_force â–ƒâ–…â–ˆâ–†â–â–â–…â–„â–ƒâ–ƒâ–„â–ƒâ–…â–…â–ƒâ–„â–ƒâ–ƒâ–…â–
wandb:         valid_loss â–„â–†â–ˆâ–…â–‚â–â–…â–‡â–ƒâ–„â–„â–ƒâ–‡â–†â–†â–„â–…â–†â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4433
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 10.17253
wandb:   test_error_force 6.99654
wandb:          test_loss 4.95086
wandb: train_error_energy 2.14107
wandb:  train_error_force 1.83296
wandb:         train_loss -2.60256
wandb: valid_error_energy 1.03276
wandb:  valid_error_force 1.97936
wandb:         valid_loss -2.47399
wandb: 
wandb: ğŸš€ View run al_69_54 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/nyrwgvf2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_124419-nyrwgvf2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.74275207519531, Uncertainty Bias: -4.798079013824463
1.9073486e-06 0.0026168823
0.4555989 7.9186063
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1857 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1868 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1324 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3462 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 538 steps.
Found uncertainty sample 19 after 2893 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2387 steps.
Found uncertainty sample 22 after 1500 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1702 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2898 steps.
Found uncertainty sample 29 after 2397 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2293 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2046 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3556 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1750 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 733 steps.
Found uncertainty sample 48 after 1953 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1229 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2506 steps.
Found uncertainty sample 56 after 3071 steps.
Found uncertainty sample 57 after 3207 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2371 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2778 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3686 steps.
Found uncertainty sample 71 after 2302 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2077 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2343 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2147 steps.
Found uncertainty sample 81 after 1781 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2063 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2153 steps.
Found uncertainty sample 89 after 2259 steps.
Found uncertainty sample 90 after 585 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 450 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1539 steps.
Found uncertainty sample 96 after 3412 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_132410-s2le21co
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s2le21co
Training model 55. Added 36 samples to the dataset.
Epoch 0, Batch 100/140, Loss: 0.08471201360225677, Uncertainty: 0.12325582653284073

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.163597701897984, Training Loss Force: 1.9661390723759637, time: 2.0876784324645996
Validation Loss Energy: 3.516429006246433, Validation Loss Force: 2.0077519473213323, time: 0.1409447193145752
Test Loss Energy: 12.680716031104348, Test Loss Force: 7.018725087551737, time: 10.523240089416504

Epoch 1, Batch 100/140, Loss: 0.058113038539886475, Uncertainty: 0.12289493530988693

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7584626438326305, Training Loss Force: 1.841484289548713, time: 2.098801374435425
Validation Loss Energy: 0.996276646825394, Validation Loss Force: 1.946996151293595, time: 0.14740276336669922
Test Loss Energy: 9.676275198065136, Test Loss Force: 6.981220587550692, time: 10.602227926254272

Epoch 2, Batch 100/140, Loss: 0.059586502611637115, Uncertainty: 0.12234482169151306

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7612799940266861, Training Loss Force: 1.8430641573584547, time: 2.30354905128479
Validation Loss Energy: 0.9685272281888677, Validation Loss Force: 2.021749152503499, time: 0.13639402389526367
Test Loss Energy: 9.787925345670127, Test Loss Force: 7.002068549422985, time: 10.580957889556885

Epoch 3, Batch 100/140, Loss: 0.08513632416725159, Uncertainty: 0.12210920453071594

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.605720718283421, Training Loss Force: 1.8298880255659697, time: 2.1722686290740967
Validation Loss Energy: 1.4364647868932814, Validation Loss Force: 2.1651192839381213, time: 0.13408350944519043
Test Loss Energy: 10.38919934404758, Test Loss Force: 6.982365200225325, time: 10.534252643585205

Epoch 4, Batch 100/140, Loss: 0.05347694456577301, Uncertainty: 0.12242479622364044

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5362529874148598, Training Loss Force: 1.841889605447329, time: 2.1242172718048096
Validation Loss Energy: 1.6937737553995202, Validation Loss Force: 2.0511941781305034, time: 0.13805842399597168
Test Loss Energy: 9.2424982799773, Test Loss Force: 6.979978737241904, time: 10.722086906433105

Epoch 5, Batch 100/140, Loss: 0.11819107830524445, Uncertainty: 0.12129756063222885

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8435764196573656, Training Loss Force: 1.8148979847864342, time: 2.0776638984680176
Validation Loss Energy: 2.2170141839728084, Validation Loss Force: 2.143667486865535, time: 0.14602255821228027
Test Loss Energy: 11.570505809466045, Test Loss Force: 7.1241575898020555, time: 10.44746470451355

Epoch 6, Batch 100/140, Loss: 0.16427141427993774, Uncertainty: 0.12243260443210602

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.753844423515517, Training Loss Force: 1.8289865375999772, time: 2.1656904220581055
Validation Loss Energy: 2.3559950240913774, Validation Loss Force: 2.1370701711869384, time: 0.1312711238861084
Test Loss Energy: 11.418571465164879, Test Loss Force: 7.022966808874502, time: 10.594600200653076

Epoch 7, Batch 100/140, Loss: 0.1384364366531372, Uncertainty: 0.12121789157390594

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4397073953299386, Training Loss Force: 1.8305849617020442, time: 2.120021343231201
Validation Loss Energy: 2.1527936560344343, Validation Loss Force: 2.036738868292115, time: 0.14612770080566406
Test Loss Energy: 11.420804633848109, Test Loss Force: 6.928138032856605, time: 10.530216455459595

Epoch 8, Batch 100/140, Loss: 0.09881141781806946, Uncertainty: 0.12177062034606934

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6909861761340477, Training Loss Force: 1.8343097489082092, time: 2.129256248474121
Validation Loss Energy: 2.589456906410761, Validation Loss Force: 1.9953392186700636, time: 0.15318918228149414
Test Loss Energy: 11.710647465228487, Test Loss Force: 6.930373747662424, time: 10.535680294036865

Epoch 9, Batch 100/140, Loss: 0.05197638273239136, Uncertainty: 0.12103984504938126

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4015023982351937, Training Loss Force: 1.8040764694680567, time: 2.0879335403442383
Validation Loss Energy: 1.0372381021240213, Validation Loss Force: 2.0609263784915695, time: 0.1363849639892578
Test Loss Energy: 10.29357025781339, Test Loss Force: 7.114346465469735, time: 10.672305583953857

Epoch 10, Batch 100/140, Loss: 0.1111723780632019, Uncertainty: 0.122266985476017

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5010811417111256, Training Loss Force: 1.8303182645039908, time: 2.1902873516082764
Validation Loss Energy: 2.177542737819919, Validation Loss Force: 1.9639389352726673, time: 1.01655912399292
Test Loss Energy: 11.180359117511523, Test Loss Force: 6.991721447632537, time: 10.464393377304077

Epoch 11, Batch 100/140, Loss: 0.11958673596382141, Uncertainty: 0.12133648991584778

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8349460894136425, Training Loss Force: 1.8116090111994072, time: 2.129779100418091
Validation Loss Energy: 2.630097217133674, Validation Loss Force: 2.046034266011919, time: 0.13495135307312012
Test Loss Energy: 8.99539606136255, Test Loss Force: 7.016286354443571, time: 10.667375802993774

Epoch 12, Batch 100/140, Loss: 0.0879506915807724, Uncertainty: 0.12234045565128326

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6795021030064219, Training Loss Force: 1.8381193364776136, time: 2.0961380004882812
Validation Loss Energy: 5.613485457687099, Validation Loss Force: 2.0112077724661312, time: 0.14049410820007324
Test Loss Energy: 8.542903225650802, Test Loss Force: 6.89200270095192, time: 10.60074758529663

Epoch 13, Batch 100/140, Loss: 0.06646247208118439, Uncertainty: 0.12294861674308777

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7679650064904544, Training Loss Force: 1.858617796013248, time: 2.0944056510925293
Validation Loss Energy: 2.0035105083181755, Validation Loss Force: 2.262703406245061, time: 0.1414487361907959
Test Loss Energy: 10.414739420473843, Test Loss Force: 7.058706071824742, time: 10.668050050735474

Epoch 14, Batch 100/140, Loss: 0.07916390895843506, Uncertainty: 0.12273065745830536

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1641911764058976, Training Loss Force: 1.8285995942916409, time: 2.19632625579834
Validation Loss Energy: 1.275701931358716, Validation Loss Force: 2.287686290633769, time: 0.13390254974365234
Test Loss Energy: 9.838871509987165, Test Loss Force: 6.960735534417209, time: 10.47623085975647

Epoch 15, Batch 100/140, Loss: 0.21022960543632507, Uncertainty: 0.12206663191318512

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0235952533521577, Training Loss Force: 1.8683926144535974, time: 2.1251285076141357
Validation Loss Energy: 3.064193908710988, Validation Loss Force: 2.1675888332125575, time: 0.13380098342895508
Test Loss Energy: 9.030659514156348, Test Loss Force: 7.02200762713711, time: 10.451454877853394

Epoch 16, Batch 100/140, Loss: 0.5971739888191223, Uncertainty: 0.12317369878292084

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2084981884374373, Training Loss Force: 1.8472305038429706, time: 2.125837564468384
Validation Loss Energy: 2.4648181488698757, Validation Loss Force: 2.06878222018295, time: 0.1339583396911621
Test Loss Energy: 8.81741874411775, Test Loss Force: 7.0831878915675555, time: 10.633866786956787

Epoch 17, Batch 100/140, Loss: 0.07907853275537491, Uncertainty: 0.12240567803382874

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6244329899478023, Training Loss Force: 1.8441939742429163, time: 2.1124093532562256
Validation Loss Energy: 2.576618991025343, Validation Loss Force: 2.2447610604699184, time: 0.13883113861083984
Test Loss Energy: 9.14007681950408, Test Loss Force: 7.0285572453748, time: 10.344887495040894

Epoch 18, Batch 100/140, Loss: 0.28439176082611084, Uncertainty: 0.12238412350416183

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.047748622937354, Training Loss Force: 1.8266489402058412, time: 2.052037239074707
Validation Loss Energy: 1.0570655092213017, Validation Loss Force: 2.1037061314800805, time: 0.13614702224731445
Test Loss Energy: 10.313951866556001, Test Loss Force: 7.09804170728572, time: 10.580881357192993

Epoch 19, Batch 100/140, Loss: 0.07010151445865631, Uncertainty: 0.12193529307842255

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4892515944214166, Training Loss Force: 1.8137326927307915, time: 2.145890951156616
Validation Loss Energy: 1.1446270334893611, Validation Loss Force: 2.097058529686028, time: 0.13814449310302734
Test Loss Energy: 9.628838084979424, Test Loss Force: 7.012801472723939, time: 10.491299867630005

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–ƒâ–ƒâ–„â–‚â–†â–†â–†â–†â–„â–…â–‚â–â–„â–ƒâ–‚â–â–‚â–„â–ƒ
wandb:   test_error_force â–…â–„â–„â–„â–„â–ˆâ–…â–‚â–‚â–ˆâ–„â–…â–â–†â–ƒâ–…â–‡â–…â–‡â–…
wandb:          test_loss â–†â–„â–ƒâ–…â–ƒâ–ˆâ–†â–„â–…â–ˆâ–…â–ƒâ–â–„â–„â–ƒâ–„â–„â–†â–…
wandb: train_error_energy â–…â–ˆâ–ƒâ–‚â–‚â–ƒâ–ƒâ–â–‚â–â–‚â–ƒâ–‚â–ƒâ–…â–„â–…â–‚â–„â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–
wandb:         train_loss â–ˆâ–…â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–
wandb: valid_error_energy â–…â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–„â–ˆâ–ƒâ–â–„â–ƒâ–ƒâ–â–
wandb:  valid_error_force â–‚â–â–ƒâ–…â–ƒâ–…â–…â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‡â–ˆâ–†â–„â–‡â–„â–„
wandb:         valid_loss â–„â–â–‚â–…â–„â–†â–†â–„â–ƒâ–ƒâ–‚â–„â–†â–ˆâ–ˆâ–‡â–…â–ˆâ–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4465
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 9.62884
wandb:   test_error_force 7.0128
wandb:          test_loss 4.941
wandb: train_error_energy 1.48925
wandb:  train_error_force 1.81373
wandb:         train_loss -2.6725
wandb: valid_error_energy 1.14463
wandb:  valid_error_force 2.09706
wandb:         valid_loss -2.30422
wandb: 
wandb: ğŸš€ View run al_69_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s2le21co
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_132410-s2le21co/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 30.84653663635254, Uncertainty Bias: -3.595862627029419
4.5776367e-05 0.0012807846
0.9295243 6.3072906
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2222 steps.
Found uncertainty sample 2 after 3999 steps.
Found uncertainty sample 3 after 2007 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1382 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2631 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3184 steps.
Found uncertainty sample 17 after 431 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2009 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2639 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3661 steps.
Found uncertainty sample 30 after 1345 steps.
Found uncertainty sample 31 after 2927 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3143 steps.
Found uncertainty sample 37 after 3555 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2505 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3135 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2143 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1075 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2668 steps.
Found uncertainty sample 58 after 712 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3084 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3349 steps.
Found uncertainty sample 66 after 1129 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1599 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3999 steps.
Found uncertainty sample 82 after 2918 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2137 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2016 steps.
Found uncertainty sample 90 after 2774 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3079 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1592 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_140518-qtot54g7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_56
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qtot54g7
Training model 56. Added 31 samples to the dataset.
Epoch 0, Batch 100/141, Loss: 0.08556131273508072, Uncertainty: 0.1251850724220276

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.836578662000334, Training Loss Force: 2.061145710758736, time: 2.157515287399292
Validation Loss Energy: 3.7466121225035547, Validation Loss Force: 1.9805035528189059, time: 0.14258289337158203
Test Loss Energy: 8.406915944283952, Test Loss Force: 6.861306574725816, time: 10.439744472503662

Epoch 1, Batch 100/141, Loss: 0.06540986895561218, Uncertainty: 0.12328435480594635

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8400638942115772, Training Loss Force: 1.8467463610983186, time: 2.1168251037597656
Validation Loss Energy: 1.9550896922982541, Validation Loss Force: 2.0267865965918235, time: 0.1330881118774414
Test Loss Energy: 10.894010219176687, Test Loss Force: 6.971721561422854, time: 10.327683925628662

Epoch 2, Batch 100/141, Loss: 0.2859467566013336, Uncertainty: 0.12357992678880692

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5753430543118576, Training Loss Force: 1.8205888480092134, time: 2.3281826972961426
Validation Loss Energy: 1.484306551799218, Validation Loss Force: 2.074543376107064, time: 0.13607048988342285
Test Loss Energy: 9.222407903824648, Test Loss Force: 6.845652257599005, time: 10.552149295806885

Epoch 3, Batch 100/141, Loss: 0.0930410772562027, Uncertainty: 0.12280526012182236

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2073225457182186, Training Loss Force: 1.8764163086197378, time: 2.1378796100616455
Validation Loss Energy: 1.3104700855882696, Validation Loss Force: 1.9591928908733138, time: 0.13982534408569336
Test Loss Energy: 9.02417965081749, Test Loss Force: 6.9206159240282785, time: 10.389869451522827

Epoch 4, Batch 100/141, Loss: 0.08095245063304901, Uncertainty: 0.12266460806131363

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8825586595139527, Training Loss Force: 1.825884144547736, time: 2.112666130065918
Validation Loss Energy: 2.376508307825402, Validation Loss Force: 1.9773437663036173, time: 0.14548182487487793
Test Loss Energy: 8.810511561200755, Test Loss Force: 6.901027162005243, time: 10.572149515151978

Epoch 5, Batch 100/141, Loss: 0.05808956176042557, Uncertainty: 0.12269403040409088

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8040666915740466, Training Loss Force: 1.8353673502688124, time: 2.120089054107666
Validation Loss Energy: 2.619041026030921, Validation Loss Force: 2.024724754523581, time: 0.142747163772583
Test Loss Energy: 8.572194808531519, Test Loss Force: 6.973566588639554, time: 10.302543640136719

Epoch 6, Batch 100/141, Loss: 0.12757599353790283, Uncertainty: 0.12203441560268402

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0444306450669156, Training Loss Force: 1.8329494286519559, time: 2.1983304023742676
Validation Loss Energy: 1.7679029118855834, Validation Loss Force: 2.1005009946820716, time: 0.13274693489074707
Test Loss Energy: 8.885996926283447, Test Loss Force: 6.960213996645164, time: 10.565363645553589

Epoch 7, Batch 100/141, Loss: 0.061051029711961746, Uncertainty: 0.12121757864952087

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4555150210299703, Training Loss Force: 1.8331948637440372, time: 2.123746633529663
Validation Loss Energy: 2.439529688189906, Validation Loss Force: 2.2565456023490005, time: 0.14230751991271973
Test Loss Energy: 9.068373470046252, Test Loss Force: 6.86196351632311, time: 10.344108581542969

Epoch 8, Batch 100/141, Loss: 0.3409990966320038, Uncertainty: 0.12536248564720154

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5372830458908628, Training Loss Force: 1.8750620806714051, time: 2.0963308811187744
Validation Loss Energy: 1.6084442295387165, Validation Loss Force: 1.9689123619815376, time: 0.13919997215270996
Test Loss Energy: 8.977743203547123, Test Loss Force: 6.898323415307597, time: 11.408652544021606

Epoch 9, Batch 100/141, Loss: 0.09746865928173065, Uncertainty: 0.12312041968107224

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.693586117163731, Training Loss Force: 1.835836679976732, time: 2.177927017211914
Validation Loss Energy: 1.659968051441715, Validation Loss Force: 1.986999813816776, time: 0.1337292194366455
Test Loss Energy: 9.023030964813037, Test Loss Force: 6.847265545690956, time: 10.647635459899902

Epoch 10, Batch 100/141, Loss: 0.1432075798511505, Uncertainty: 0.12172937393188477

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0652267403304587, Training Loss Force: 1.8284943236007498, time: 2.2111656665802
Validation Loss Energy: 4.029624087416432, Validation Loss Force: 2.0243037613916797, time: 0.14809060096740723
Test Loss Energy: 12.641602300019876, Test Loss Force: 6.835344772263618, time: 10.385874509811401

Epoch 11, Batch 100/141, Loss: 0.11887390166521072, Uncertainty: 0.12311442941427231

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9482213136512108, Training Loss Force: 1.8645331977424515, time: 2.1595802307128906
Validation Loss Energy: 3.0393052875940554, Validation Loss Force: 1.990081963023184, time: 0.13540959358215332
Test Loss Energy: 8.608434981463917, Test Loss Force: 6.841823744925888, time: 10.597244501113892

Epoch 12, Batch 100/141, Loss: 0.06578240543603897, Uncertainty: 0.12207476794719696

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.844165028754199, Training Loss Force: 1.8295652800735451, time: 2.1565608978271484
Validation Loss Energy: 3.4022934038728647, Validation Loss Force: 2.1178163412538056, time: 0.1322779655456543
Test Loss Energy: 8.497166936444954, Test Loss Force: 6.864468674785187, time: 10.305356502532959

Epoch 13, Batch 100/141, Loss: 0.10560829937458038, Uncertainty: 0.122780941426754

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.6133756059954525, Training Loss Force: 1.8449842530198812, time: 2.1825203895568848
Validation Loss Energy: 2.2909412310974173, Validation Loss Force: 1.9515131062533129, time: 0.13161230087280273
Test Loss Energy: 11.131386436026437, Test Loss Force: 6.83356802403403, time: 10.56476879119873

Epoch 14, Batch 100/141, Loss: 0.10557695478200912, Uncertainty: 0.12111374735832214

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2072009375698727, Training Loss Force: 1.8222021072908463, time: 2.3034749031066895
Validation Loss Energy: 3.172428481825275, Validation Loss Force: 2.1217952904454376, time: 0.13524270057678223
Test Loss Energy: 8.575865067561267, Test Loss Force: 6.8034750327467854, time: 10.538124799728394

Epoch 15, Batch 100/141, Loss: 0.13306526839733124, Uncertainty: 0.12185408174991608

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.149736655413002, Training Loss Force: 1.8194993815714577, time: 2.1308434009552
Validation Loss Energy: 0.9970944549311004, Validation Loss Force: 2.0489911638237426, time: 0.1376800537109375
Test Loss Energy: 9.301364415088347, Test Loss Force: 6.8895975757292955, time: 10.415058135986328

Epoch 16, Batch 100/141, Loss: 0.09862811863422394, Uncertainty: 0.12267597019672394

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.103014031556551, Training Loss Force: 1.8258671885291555, time: 2.135361433029175
Validation Loss Energy: 1.35280617030352, Validation Loss Force: 2.03593722225525, time: 0.1371443271636963
Test Loss Energy: 10.12631594518319, Test Loss Force: 6.835097336712789, time: 10.542359352111816

Epoch 17, Batch 100/141, Loss: 0.07643342018127441, Uncertainty: 0.12146508693695068

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.710512302026542, Training Loss Force: 1.8231836131459234, time: 2.120264768600464
Validation Loss Energy: 1.4138735175779347, Validation Loss Force: 2.021940647968997, time: 0.14163947105407715
Test Loss Energy: 10.011220320136747, Test Loss Force: 6.852369029251056, time: 10.46036672592163

Epoch 18, Batch 100/141, Loss: 0.19190309941768646, Uncertainty: 0.12270437180995941

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6382643749003296, Training Loss Force: 1.8691061658364738, time: 2.1187474727630615
Validation Loss Energy: 1.0205654158189592, Validation Loss Force: 2.0145124052608456, time: 0.13495159149169922
Test Loss Energy: 9.411184856512845, Test Loss Force: 6.884365291475056, time: 10.495766639709473

Epoch 19, Batch 100/141, Loss: 0.061475060880184174, Uncertainty: 0.12295383214950562

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8706591903505094, Training Loss Force: 1.8670356357235056, time: 2.093637228012085
Validation Loss Energy: 1.1196552268906625, Validation Loss Force: 2.18521866284139, time: 0.14704680442810059
Test Loss Energy: 9.282531646292526, Test Loss Force: 7.00392094920345, time: 10.397079467773438

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ˆâ–â–â–†â–â–‚â–„â–„â–ƒâ–‚
wandb:   test_error_force â–ƒâ–‡â–‚â–…â–„â–‡â–†â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–‚â–â–„â–‚â–ƒâ–„â–ˆ
wandb:          test_loss â–â–ˆâ–…â–ƒâ–„â–‡â–†â–ƒâ–„â–ƒâ–ˆâ–‚â–ƒâ–…â–ƒâ–†â–…â–‡â–„â–„
wandb: train_error_energy â–ˆâ–ƒâ–‚â–…â–ƒâ–ƒâ–„â–â–â–‚â–„â–ƒâ–ƒâ–‡â–…â–…â–„â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–ƒâ–â–â–â–â–ƒâ–â–â–‚â–â–‚â–â–â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚
wandb: valid_error_energy â–‡â–ƒâ–‚â–‚â–„â–…â–ƒâ–„â–‚â–ƒâ–ˆâ–†â–‡â–„â–†â–â–‚â–‚â–â–
wandb:  valid_error_force â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–ˆâ–â–‚â–ƒâ–‚â–…â–â–…â–ƒâ–ƒâ–ƒâ–‚â–†
wandb:         valid_loss â–„â–ƒâ–„â–â–‚â–„â–„â–ˆâ–â–‚â–…â–ƒâ–†â–‚â–†â–ƒâ–ƒâ–‚â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4492
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 9.28253
wandb:   test_error_force 7.00392
wandb:          test_loss 4.6165
wandb: train_error_energy 1.87066
wandb:  train_error_force 1.86704
wandb:         train_loss -2.57446
wandb: valid_error_energy 1.11966
wandb:  valid_error_force 2.18522
wandb:         valid_loss -2.19891
wandb: 
wandb: ğŸš€ View run al_69_56 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qtot54g7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_140518-qtot54g7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 20.10165023803711, Uncertainty Bias: -2.367405652999878
2.4795532e-05 0.00038528442
1.1962998 6.019392
(48745, 22, 3)
Found uncertainty sample 0 after 2279 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1878 steps.
Found uncertainty sample 5 after 3667 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3084 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2369 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1815 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3032 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3706 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2674 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3615 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3030 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 957 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1707 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2180 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2581 steps.
Found uncertainty sample 71 after 1787 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1396 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1126 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2208 steps.
Found uncertainty sample 85 after 1489 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2606 steps.
Found uncertainty sample 90 after 2474 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3672 steps.
Found uncertainty sample 97 after 2792 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_144714-bfpozfkc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_57
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bfpozfkc
Training model 57. Added 24 samples to the dataset.
Epoch 0, Batch 100/142, Loss: 0.054885201156139374, Uncertainty: 0.1257055103778839
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.1517439045606026, Training Loss Force: 1.9680439267002403, time: 2.196514844894409
Validation Loss Energy: 3.400367464206687, Validation Loss Force: 2.124028736202142, time: 0.13759064674377441
Test Loss Energy: 11.972150431968826, Test Loss Force: 6.8624991440391225, time: 10.822771787643433

Epoch 1, Batch 100/142, Loss: 0.0996294692158699, Uncertainty: 0.12407147139310837

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6094798947062554, Training Loss Force: 1.8232898409251372, time: 2.1689252853393555
Validation Loss Energy: 2.133473210915145, Validation Loss Force: 1.9741454209145595, time: 0.1356675624847412
Test Loss Energy: 11.08937655111771, Test Loss Force: 6.83911727490298, time: 10.80825924873352

Epoch 2, Batch 100/142, Loss: 0.18452252447605133, Uncertainty: 0.1232430711388588

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2784385974263417, Training Loss Force: 1.8487069343299858, time: 2.300478458404541
Validation Loss Energy: 1.1271383018759984, Validation Loss Force: 2.0693862473528033, time: 0.1475527286529541
Test Loss Energy: 9.64733704591194, Test Loss Force: 6.918329037287949, time: 10.82141399383545

Epoch 3, Batch 100/142, Loss: 0.08870595693588257, Uncertainty: 0.12253772467374802

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3713894407282006, Training Loss Force: 1.8395610524079535, time: 2.18125319480896
Validation Loss Energy: 1.8218192766500512, Validation Loss Force: 2.102403850980122, time: 0.1438746452331543
Test Loss Energy: 10.40076652819764, Test Loss Force: 6.952004245856773, time: 10.881878137588501

Epoch 4, Batch 100/142, Loss: 0.11380133032798767, Uncertainty: 0.12327244877815247

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8310297051827829, Training Loss Force: 1.8526459601459575, time: 2.135287284851074
Validation Loss Energy: 2.867185229382967, Validation Loss Force: 2.2603557683280195, time: 0.13456988334655762
Test Loss Energy: 11.193642775335237, Test Loss Force: 6.860068081941321, time: 11.026267290115356

Epoch 5, Batch 100/142, Loss: 0.08680979162454605, Uncertainty: 0.12259230017662048

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.768727619859977, Training Loss Force: 1.830097460816996, time: 2.198167562484741
Validation Loss Energy: 1.9824213650612574, Validation Loss Force: 2.022637528172702, time: 0.1468658447265625
Test Loss Energy: 10.8494694697605, Test Loss Force: 6.8239231018175195, time: 11.742817163467407

Epoch 6, Batch 100/142, Loss: 0.05106339603662491, Uncertainty: 0.12085825949907303

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8440741478998162, Training Loss Force: 1.8512761230815982, time: 2.1256825923919678
Validation Loss Energy: 3.985048915992781, Validation Loss Force: 2.1079290889441253, time: 0.14123058319091797
Test Loss Energy: 8.508076453865733, Test Loss Force: 6.8124486995870805, time: 10.908560991287231

Epoch 7, Batch 100/142, Loss: 0.11628150939941406, Uncertainty: 0.12262633442878723

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1049052854569954, Training Loss Force: 1.8448263450519866, time: 2.1670408248901367
Validation Loss Energy: 1.1024618102320862, Validation Loss Force: 2.108639329296586, time: 0.13863730430603027
Test Loss Energy: 9.161636872641822, Test Loss Force: 6.931734092931056, time: 10.8864266872406

Epoch 8, Batch 100/142, Loss: 0.045511092990636826, Uncertainty: 0.12154196947813034

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4353337102181773, Training Loss Force: 1.82846881634518, time: 2.132267713546753
Validation Loss Energy: 2.0562413083266753, Validation Loss Force: 2.267073919129807, time: 0.14447021484375
Test Loss Energy: 8.514821433385086, Test Loss Force: 6.91267904436886, time: 10.984243631362915

Epoch 9, Batch 100/142, Loss: 0.11866214126348495, Uncertainty: 0.12324894964694977

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0124102475324497, Training Loss Force: 1.8623331272403518, time: 2.201225519180298
Validation Loss Energy: 3.136906221421512, Validation Loss Force: 2.083964915898036, time: 0.14546608924865723
Test Loss Energy: 8.450068856369732, Test Loss Force: 6.774231394846674, time: 10.996475219726562

Epoch 10, Batch 100/142, Loss: 0.09419596195220947, Uncertainty: 0.12302521616220474

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8603824377156601, Training Loss Force: 1.860426205923645, time: 2.1526875495910645
Validation Loss Energy: 3.114020731941346, Validation Loss Force: 2.325629447103583, time: 0.14503955841064453
Test Loss Energy: 8.58021601334624, Test Loss Force: 6.876443954355188, time: 10.894567728042603

Epoch 11, Batch 100/142, Loss: 0.13605907559394836, Uncertainty: 0.12403564155101776

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.2201702220259585, Training Loss Force: 1.8395098988759542, time: 2.0940804481506348
Validation Loss Energy: 8.450800882935681, Validation Loss Force: 2.414085730223029, time: 0.14672017097473145
Test Loss Energy: 8.254272194736775, Test Loss Force: 7.017703057156457, time: 11.069657802581787

Epoch 12, Batch 100/142, Loss: 0.06509841978549957, Uncertainty: 0.12357189506292343

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0745599440505345, Training Loss Force: 1.841755494475293, time: 2.126469135284424
Validation Loss Energy: 2.652919765468591, Validation Loss Force: 2.4063723225619937, time: 0.14469194412231445
Test Loss Energy: 11.007639636679812, Test Loss Force: 6.813496230845703, time: 10.781346082687378

Epoch 13, Batch 100/142, Loss: 0.19917640089988708, Uncertainty: 0.12268080562353134

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6958792738116575, Training Loss Force: 1.8283563645062555, time: 2.1617605686187744
Validation Loss Energy: 1.0474767263459757, Validation Loss Force: 2.0995040306927044, time: 0.1456146240234375
Test Loss Energy: 9.070033346119406, Test Loss Force: 6.767482141478687, time: 11.039943218231201

Epoch 14, Batch 100/142, Loss: 0.1007663756608963, Uncertainty: 0.12127728760242462

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.720101439118412, Training Loss Force: 1.8445126261786708, time: 2.1198980808258057
Validation Loss Energy: 1.1659553976320545, Validation Loss Force: 2.0520571695170706, time: 0.1375563144683838
Test Loss Energy: 9.461503658088974, Test Loss Force: 6.784928010252964, time: 10.82876992225647

Epoch 15, Batch 100/142, Loss: 0.05219336599111557, Uncertainty: 0.12140484154224396

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4433924935361473, Training Loss Force: 1.8273603528717797, time: 2.216003656387329
Validation Loss Energy: 2.735098263133846, Validation Loss Force: 2.236416831118469, time: 0.1490311622619629
Test Loss Energy: 11.072917705884715, Test Loss Force: 6.891316758738529, time: 11.036184549331665

Epoch 16, Batch 100/142, Loss: 0.11518487334251404, Uncertainty: 0.12283554673194885

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.137461727170264, Training Loss Force: 1.848602694591886, time: 2.1854162216186523
Validation Loss Energy: 3.638640373204511, Validation Loss Force: 2.0441149693085943, time: 0.14579272270202637
Test Loss Energy: 12.01112876155966, Test Loss Force: 6.890650842758588, time: 10.84220552444458

Epoch 17, Batch 100/142, Loss: 0.09965918213129044, Uncertainty: 0.1216723769903183

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8978434080701985, Training Loss Force: 1.8342368308448767, time: 2.241227865219116
Validation Loss Energy: 0.9975220910258545, Validation Loss Force: 2.1628047123892506, time: 0.14693307876586914
Test Loss Energy: 9.689220711223332, Test Loss Force: 6.748957903517787, time: 10.94785451889038

Epoch 18, Batch 100/142, Loss: 0.0808134377002716, Uncertainty: 0.12279859185218811

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8024431215137575, Training Loss Force: 1.8298336017993027, time: 2.363217830657959
Validation Loss Energy: 3.193059817318165, Validation Loss Force: 2.0070624894224913, time: 0.13793158531188965
Test Loss Energy: 8.663140498116828, Test Loss Force: 6.781877247098169, time: 10.898558855056763

Epoch 19, Batch 100/142, Loss: 0.1528777927160263, Uncertainty: 0.12135247886180878

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9409404990896941, Training Loss Force: 1.8203183423419813, time: 2.1179325580596924
Validation Loss Energy: 3.0164701213408684, Validation Loss Force: 2.0336241722788766, time: 0.14322662353515625
Test Loss Energy: 8.523027390637349, Test Loss Force: 6.810325942157634, time: 10.972505331039429

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.057 MB uploadedwandb: | 0.039 MB of 0.057 MB uploadedwandb: / 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–„â–…â–†â–†â–â–ƒâ–â–â–‚â–â–†â–ƒâ–ƒâ–†â–ˆâ–„â–‚â–‚
wandb:   test_error_force â–„â–ƒâ–…â–†â–„â–ƒâ–ƒâ–†â–…â–‚â–„â–ˆâ–ƒâ–â–‚â–…â–…â–â–‚â–ƒ
wandb:          test_loss â–…â–†â–‡â–ˆâ–†â–†â–ƒâ–†â–…â–â–ƒâ–‡â–…â–ƒâ–ƒâ–‡â–ˆâ–„â–‚â–„
wandb: train_error_energy â–„â–‚â–„â–â–ƒâ–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–â–„â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–â–‚â–‚â–ƒâ–â–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–„â–â–ƒâ–‚â–ƒâ–ƒâ–â–„â–ƒâ–…â–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–‚â–â–‚â–ƒâ–‚â–„â–â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–â–â–ƒâ–ƒâ–â–ƒâ–ƒ
wandb:  valid_error_force â–ƒâ–â–ƒâ–ƒâ–†â–‚â–ƒâ–ƒâ–†â–ƒâ–‡â–ˆâ–ˆâ–ƒâ–‚â–…â–‚â–„â–‚â–‚
wandb:         valid_loss â–ƒâ–â–â–‚â–„â–â–ƒâ–‚â–„â–‚â–…â–ˆâ–…â–‚â–â–„â–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4513
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 8.52303
wandb:   test_error_force 6.81033
wandb:          test_loss 4.60825
wandb: train_error_energy 1.94094
wandb:  train_error_force 1.82032
wandb:         train_loss -2.63328
wandb: valid_error_energy 3.01647
wandb:  valid_error_force 2.03362
wandb:         valid_loss -2.26633
wandb: 
wandb: ğŸš€ View run al_69_57 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bfpozfkc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_144714-bfpozfkc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.82953643798828, Uncertainty Bias: -5.171510219573975
1.5258789e-05 0.04534793
0.3989376 7.1660843
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2508 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3584 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 794 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2934 steps.
Found uncertainty sample 16 after 2965 steps.
Found uncertainty sample 17 after 3610 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1123 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3449 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3067 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3048 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2702 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2201 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1930 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1312 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1761 steps.
Found uncertainty sample 50 after 1261 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3481 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2760 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 885 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1897 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3215 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3812 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3912 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1174 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3043 steps.
Found uncertainty sample 84 after 3319 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2280 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3103 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_152740-wdlptriv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_58
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wdlptriv
Training model 58. Added 28 samples to the dataset.
Epoch 0, Batch 100/142, Loss: 0.20346784591674805, Uncertainty: 0.1242719516158104

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0860915266559195, Training Loss Force: 1.9131445359372752, time: 2.0940518379211426
Validation Loss Energy: 2.068878190584845, Validation Loss Force: 2.0255169371217434, time: 0.12000870704650879
Test Loss Energy: 8.40239133055484, Test Loss Force: 6.750963422727383, time: 8.762199401855469

Epoch 1, Batch 100/142, Loss: 0.11905797570943832, Uncertainty: 0.12362281233072281

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3643163603365984, Training Loss Force: 1.8488961897752376, time: 2.1810154914855957
Validation Loss Energy: 2.3480300374069674, Validation Loss Force: 2.146585937138162, time: 0.1238563060760498
Test Loss Energy: 10.767294916020484, Test Loss Force: 6.718955786889834, time: 8.698158502578735

Epoch 2, Batch 100/142, Loss: 0.17720729112625122, Uncertainty: 0.12243355065584183

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.681331907857132, Training Loss Force: 1.8319840776869702, time: 2.116122245788574
Validation Loss Energy: 1.3710452598271354, Validation Loss Force: 2.066547512634419, time: 0.11767816543579102
Test Loss Energy: 8.87770097105879, Test Loss Force: 6.674333207145422, time: 8.89881706237793

Epoch 3, Batch 100/142, Loss: 0.062005311250686646, Uncertainty: 0.12324424088001251

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.097182299755825, Training Loss Force: 1.8648110498678006, time: 2.136718511581421
Validation Loss Energy: 1.648331621656199, Validation Loss Force: 2.0002140400588115, time: 0.11931681632995605
Test Loss Energy: 10.185485250748355, Test Loss Force: 6.732511250294885, time: 8.688089847564697

Epoch 4, Batch 100/142, Loss: 0.11733117699623108, Uncertainty: 0.12115056812763214

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4444672951582218, Training Loss Force: 1.820959381723626, time: 2.1731784343719482
Validation Loss Energy: 1.4084164534841095, Validation Loss Force: 2.0606836691225077, time: 0.12121200561523438
Test Loss Energy: 8.958083679367965, Test Loss Force: 6.760297713324676, time: 8.70864987373352

Epoch 5, Batch 100/142, Loss: 0.06216073036193848, Uncertainty: 0.12224211543798447

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5899689867104299, Training Loss Force: 1.8231122019096957, time: 2.2040603160858154
Validation Loss Energy: 2.9453645891873586, Validation Loss Force: 2.132529019513363, time: 0.11898970603942871
Test Loss Energy: 8.292091070929272, Test Loss Force: 6.699282688053423, time: 8.96320104598999

Epoch 6, Batch 100/142, Loss: 0.15893614292144775, Uncertainty: 0.12231715023517609

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.231961354665649, Training Loss Force: 1.8640494555288394, time: 2.1738178730010986
Validation Loss Energy: 2.8218732457554405, Validation Loss Force: 2.1301107212540136, time: 0.11987709999084473
Test Loss Energy: 8.373195378826168, Test Loss Force: 6.760476328953922, time: 8.835978269577026

Epoch 7, Batch 100/142, Loss: 0.11967939138412476, Uncertainty: 0.12196281552314758

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.149955305629405, Training Loss Force: 1.8466986624857518, time: 2.109980344772339
Validation Loss Energy: 1.300922125389697, Validation Loss Force: 2.1793166686824765, time: 0.11958146095275879
Test Loss Energy: 9.594627673048356, Test Loss Force: 6.740766218075391, time: 9.001219749450684

Epoch 8, Batch 100/142, Loss: 0.24292536079883575, Uncertainty: 0.12291866540908813

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.857328320646878, Training Loss Force: 1.8448343446762683, time: 2.0971686840057373
Validation Loss Energy: 2.043242588706373, Validation Loss Force: 2.024779902248722, time: 0.12494015693664551
Test Loss Energy: 10.48315964277955, Test Loss Force: 6.788371671367038, time: 8.78071665763855

Epoch 9, Batch 100/142, Loss: 0.391353577375412, Uncertainty: 0.12314040213823318

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.08209219402706, Training Loss Force: 1.8236316898111915, time: 2.149564743041992
Validation Loss Energy: 2.264769367692503, Validation Loss Force: 2.1020016362795277, time: 0.12086915969848633
Test Loss Energy: 8.56676394769978, Test Loss Force: 6.679982694104252, time: 8.778603792190552

Epoch 10, Batch 100/142, Loss: 0.03180704265832901, Uncertainty: 0.12153321504592896

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.07033073055048, Training Loss Force: 1.8193290562565678, time: 2.143733024597168
Validation Loss Energy: 0.9947160886719213, Validation Loss Force: 2.0836741099934546, time: 0.12255382537841797
Test Loss Energy: 9.293783806062414, Test Loss Force: 6.776369792743459, time: 8.980366945266724

Epoch 11, Batch 100/142, Loss: 0.17051726579666138, Uncertainty: 0.12262724339962006

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.468061397373922, Training Loss Force: 1.8682655366455856, time: 2.1728360652923584
Validation Loss Energy: 1.5330001004113771, Validation Loss Force: 2.2582896213229557, time: 0.11861896514892578
Test Loss Energy: 9.100230574546313, Test Loss Force: 6.843749091584882, time: 8.757558345794678

Epoch 12, Batch 100/142, Loss: 0.06385889649391174, Uncertainty: 0.12252543866634369

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0151728267894398, Training Loss Force: 1.8537054371913007, time: 2.147937774658203
Validation Loss Energy: 1.2882362373636613, Validation Loss Force: 2.047632325360718, time: 0.11983585357666016
Test Loss Energy: 9.524970268325278, Test Loss Force: 6.669497278634163, time: 8.801603555679321

Epoch 13, Batch 100/142, Loss: 0.06986813247203827, Uncertainty: 0.12252629548311234

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.7409600430359258, Training Loss Force: 1.833380642889304, time: 2.163370132446289
Validation Loss Energy: 0.9572013661946346, Validation Loss Force: 2.041754119688895, time: 0.12214016914367676
Test Loss Energy: 9.027998531592788, Test Loss Force: 6.756752433473568, time: 9.01084852218628

Epoch 14, Batch 100/142, Loss: 0.21224671602249146, Uncertainty: 0.12203913927078247

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0656180780291806, Training Loss Force: 1.840798270394755, time: 2.1021835803985596
Validation Loss Energy: 1.9332287406700257, Validation Loss Force: 2.146356587917856, time: 0.11871790885925293
Test Loss Energy: 9.957276012531777, Test Loss Force: 6.740638035258987, time: 8.684733629226685

Epoch 15, Batch 100/142, Loss: 0.13019868731498718, Uncertainty: 0.1214437410235405

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7405932113664424, Training Loss Force: 1.830890183361702, time: 2.1590371131896973
Validation Loss Energy: 2.476836344906085, Validation Loss Force: 2.0523733597042884, time: 0.11927223205566406
Test Loss Energy: 10.703767944958528, Test Loss Force: 6.697758850004557, time: 8.650894403457642

Epoch 16, Batch 100/142, Loss: 0.19741691648960114, Uncertainty: 0.12156136333942413

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.95715102656585, Training Loss Force: 1.816593455248318, time: 2.117802858352661
Validation Loss Energy: 1.8126072314138728, Validation Loss Force: 2.2383716064390446, time: 0.15390515327453613
Test Loss Energy: 8.775502587763965, Test Loss Force: 6.806718641371638, time: 8.844919919967651

Epoch 17, Batch 100/142, Loss: 0.05581693351268768, Uncertainty: 0.12192466855049133

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.87834267229092, Training Loss Force: 1.8443943825898128, time: 2.185124397277832
Validation Loss Energy: 2.644640852399947, Validation Loss Force: 2.0439572082187047, time: 0.11851382255554199
Test Loss Energy: 8.22461991348741, Test Loss Force: 6.648285494030335, time: 8.849122524261475

Epoch 18, Batch 100/142, Loss: 0.06421258300542831, Uncertainty: 0.12237605452537537

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.6645618909583697, Training Loss Force: 1.8496641842840518, time: 2.1230404376983643
Validation Loss Energy: 5.112359638010775, Validation Loss Force: 2.229408542419538, time: 0.1257917881011963
Test Loss Energy: 13.32068439645542, Test Loss Force: 6.854801560265735, time: 8.985743284225464

Epoch 19, Batch 100/142, Loss: 0.1557348668575287, Uncertainty: 0.12294930219650269

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9938216316108488, Training Loss Force: 1.8341431365293577, time: 2.199537992477417
Validation Loss Energy: 1.1459074367457325, Validation Loss Force: 1.9928120723098803, time: 0.11909747123718262
Test Loss Energy: 9.34966979794633, Test Loss Force: 6.764506463292544, time: 8.760658979415894

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–‚â–„â–‚â–â–â–ƒâ–„â–â–‚â–‚â–ƒâ–‚â–ƒâ–„â–‚â–â–ˆâ–ƒ
wandb:   test_error_force â–„â–ƒâ–‚â–„â–…â–ƒâ–…â–„â–†â–‚â–…â–ˆâ–‚â–…â–„â–ƒâ–†â–â–ˆâ–…
wandb:          test_loss â–â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–‚â–„â–‚â–„â–„â–â–„â–„â–ƒâ–„â–â–ˆâ–ƒ
wandb: train_error_energy â–ˆâ–…â–‚â–„â–â–‚â–„â–„â–ƒâ–„â–„â–…â–ƒâ–‡â–„â–‚â–ƒâ–ƒâ–†â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–„â–â–â–„â–ƒâ–ƒâ–‚â–â–…â–„â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚
wandb:         train_loss â–ˆâ–„â–‚â–„â–â–â–„â–ƒâ–ƒâ–‚â–‚â–…â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–…â–ƒ
wandb: valid_error_energy â–ƒâ–ƒâ–‚â–‚â–‚â–„â–„â–‚â–ƒâ–ƒâ–â–‚â–‚â–â–ƒâ–„â–‚â–„â–ˆâ–
wandb:  valid_error_force â–‚â–…â–ƒâ–â–ƒâ–…â–…â–†â–‚â–„â–ƒâ–ˆâ–‚â–‚â–…â–ƒâ–‡â–‚â–‡â–
wandb:         valid_loss â–‚â–„â–‚â–‚â–‚â–…â–…â–„â–‚â–„â–‚â–†â–‚â–‚â–„â–ƒâ–†â–ƒâ–ˆâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4538
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 9.34967
wandb:   test_error_force 6.76451
wandb:          test_loss 4.47681
wandb: train_error_energy 1.99382
wandb:  train_error_force 1.83414
wandb:         train_loss -2.61076
wandb: valid_error_energy 1.14591
wandb:  valid_error_force 1.99281
wandb:         valid_loss -2.4502
wandb: 
wandb: ğŸš€ View run al_69_58 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wdlptriv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_152740-wdlptriv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 23.49872589111328, Uncertainty Bias: -2.7396082878112793
4.196167e-05 0.0019607544
1.0027558 5.7970753
(48745, 22, 3)
Found uncertainty sample 0 after 1068 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2258 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3833 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3618 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1336 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2171 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2968 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3436 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3396 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3626 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3198 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2769 steps.
Found uncertainty sample 65 after 3991 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1799 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2734 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2342 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3268 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2369 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_160821-xnt82rv3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_59
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xnt82rv3
Training model 59. Added 18 samples to the dataset.
Epoch 0, Batch 100/143, Loss: 0.1480008214712143, Uncertainty: 0.125315859913826

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.994062405759029, Training Loss Force: 2.0307544076547788, time: 2.178144931793213
Validation Loss Energy: 0.9747633002897214, Validation Loss Force: 2.019079572112971, time: 0.11945629119873047
Test Loss Energy: 8.964344967875238, Test Loss Force: 6.715222289822641, time: 8.606062412261963

Epoch 1, Batch 100/143, Loss: 0.2393849641084671, Uncertainty: 0.1226411759853363

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6920565732480728, Training Loss Force: 1.8156673213226078, time: 2.1663625240325928
Validation Loss Energy: 1.2588123281939956, Validation Loss Force: 2.0747031412192674, time: 0.11821866035461426
Test Loss Energy: 8.936299621069418, Test Loss Force: 6.683381870353035, time: 8.627989530563354

Epoch 2, Batch 100/143, Loss: 0.16368111968040466, Uncertainty: 0.12169745564460754

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7634201920475305, Training Loss Force: 1.820814039126451, time: 2.1858391761779785
Validation Loss Energy: 1.5253577984309408, Validation Loss Force: 2.13917417194681, time: 0.12412381172180176
Test Loss Energy: 9.99661972470398, Test Loss Force: 6.759996951427915, time: 9.63578200340271

Epoch 3, Batch 100/143, Loss: 0.17306864261627197, Uncertainty: 0.12123928964138031

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8357368090989656, Training Loss Force: 1.8249181475826595, time: 2.108828544616699
Validation Loss Energy: 2.5727380904809674, Validation Loss Force: 1.9721847448616165, time: 0.11758995056152344
Test Loss Energy: 8.220466788836971, Test Loss Force: 6.628296568738507, time: 8.6222825050354

Epoch 4, Batch 100/143, Loss: 0.3470489978790283, Uncertainty: 0.12215550243854523

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7533631621699544, Training Loss Force: 1.8666851794957149, time: 2.119065999984741
Validation Loss Energy: 1.3720908770248876, Validation Loss Force: 1.9894114691132714, time: 0.12117576599121094
Test Loss Energy: 9.607698281965893, Test Loss Force: 6.65788074820343, time: 8.678563117980957

Epoch 5, Batch 100/143, Loss: 0.18236695230007172, Uncertainty: 0.12309140712022781

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7496879440742132, Training Loss Force: 1.8406181216306956, time: 2.3714475631713867
Validation Loss Energy: 1.4340356891803552, Validation Loss Force: 2.164904556658398, time: 0.1202845573425293
Test Loss Energy: 9.344694562487827, Test Loss Force: 6.713120938942187, time: 8.616714715957642

Epoch 6, Batch 100/143, Loss: 0.12646079063415527, Uncertainty: 0.12082485854625702

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0907478963804746, Training Loss Force: 1.818413850252886, time: 2.1685917377471924
Validation Loss Energy: 1.1894804300108495, Validation Loss Force: 2.0378434928135376, time: 0.12466955184936523
Test Loss Energy: 9.227393486986497, Test Loss Force: 6.735693887211193, time: 8.644118547439575

Epoch 7, Batch 100/143, Loss: 0.05228039249777794, Uncertainty: 0.12357908487319946

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.442096163293348, Training Loss Force: 1.8651694604980595, time: 2.1486644744873047
Validation Loss Energy: 1.016496378402037, Validation Loss Force: 1.9524283877776494, time: 0.12392282485961914
Test Loss Energy: 9.492034764327613, Test Loss Force: 6.648687944612557, time: 8.747749328613281

Epoch 8, Batch 100/143, Loss: 0.19395361840724945, Uncertainty: 0.12140567600727081

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5376280510094384, Training Loss Force: 1.82071210492855, time: 2.1423051357269287
Validation Loss Energy: 3.7680385352935044, Validation Loss Force: 2.1561228566582495, time: 0.12364053726196289
Test Loss Energy: 11.962756647906323, Test Loss Force: 6.7203026367760925, time: 8.655320644378662

Epoch 9, Batch 100/143, Loss: 0.11799260973930359, Uncertainty: 0.12171020358800888

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9462198349101647, Training Loss Force: 1.8507856238222178, time: 2.1568498611450195
Validation Loss Energy: 1.7832750248208054, Validation Loss Force: 2.201037004745052, time: 0.11702322959899902
Test Loss Energy: 8.520538278343462, Test Loss Force: 6.703571092953567, time: 8.618494987487793

Epoch 10, Batch 100/143, Loss: 0.12391766160726547, Uncertainty: 0.12144538760185242

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9060064637272416, Training Loss Force: 1.835297105270778, time: 2.172466278076172
Validation Loss Energy: 1.1926266708197606, Validation Loss Force: 2.040928314049697, time: 0.11859369277954102
Test Loss Energy: 8.768926410110138, Test Loss Force: 6.702105680490654, time: 8.749030351638794

Epoch 11, Batch 100/143, Loss: 0.22024302184581757, Uncertainty: 0.12173160910606384

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0946069963697616, Training Loss Force: 1.8438420532098427, time: 2.163844347000122
Validation Loss Energy: 2.6752700325449954, Validation Loss Force: 2.037028560850967, time: 0.1168680191040039
Test Loss Energy: 11.086827826446294, Test Loss Force: 6.750804189806097, time: 8.593239784240723

Epoch 12, Batch 100/143, Loss: 0.1114264726638794, Uncertainty: 0.12224618345499039

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1380065236226513, Training Loss Force: 1.817773491938807, time: 2.1900811195373535
Validation Loss Energy: 2.0793166232537454, Validation Loss Force: 2.1144222696854773, time: 0.11938071250915527
Test Loss Energy: 10.285831971052772, Test Loss Force: 6.74310346768014, time: 8.600707769393921

Epoch 13, Batch 100/143, Loss: 0.09329995512962341, Uncertainty: 0.12111053615808487

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.157053552441236, Training Loss Force: 1.8171461262915356, time: 2.1741819381713867
Validation Loss Energy: 1.4977396989232252, Validation Loss Force: 1.9852182008686834, time: 0.12035989761352539
Test Loss Energy: 9.861995250790244, Test Loss Force: 6.679575109307797, time: 8.779327630996704

Epoch 14, Batch 100/143, Loss: 0.06868202984333038, Uncertainty: 0.12183840572834015

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6395109065441003, Training Loss Force: 1.8191275328938692, time: 2.1528756618499756
Validation Loss Energy: 2.8444069922080892, Validation Loss Force: 2.0679135878446857, time: 0.12122988700866699
Test Loss Energy: 8.09168052505841, Test Loss Force: 6.712594157370047, time: 8.587254285812378

Epoch 15, Batch 100/143, Loss: 0.06967689096927643, Uncertainty: 0.12156426161527634

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7313824019544413, Training Loss Force: 1.8272646965489592, time: 2.2300875186920166
Validation Loss Energy: 1.2612813950186161, Validation Loss Force: 2.0494050315429733, time: 0.1180722713470459
Test Loss Energy: 9.759403078859558, Test Loss Force: 6.728587523828646, time: 8.583030223846436

Epoch 16, Batch 100/143, Loss: 0.1744186282157898, Uncertainty: 0.12208223342895508

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6563299549916202, Training Loss Force: 1.8114427146016603, time: 2.2164018154144287
Validation Loss Energy: 2.577361518403963, Validation Loss Force: 2.1159158229817874, time: 0.11624860763549805
Test Loss Energy: 8.292262362958652, Test Loss Force: 6.693842684962824, time: 8.761454105377197

Epoch 17, Batch 100/143, Loss: 0.04713618755340576, Uncertainty: 0.12322723120450974

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5896090034560255, Training Loss Force: 1.834631576779011, time: 2.149939775466919
Validation Loss Energy: 1.2836548939092456, Validation Loss Force: 2.073700981616495, time: 0.12262868881225586
Test Loss Energy: 8.626005682525145, Test Loss Force: 6.732085446265903, time: 8.542539596557617

Epoch 18, Batch 100/143, Loss: 0.0690663605928421, Uncertainty: 0.12252762913703918

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5496422375736543, Training Loss Force: 1.842593041242385, time: 2.144024133682251
Validation Loss Energy: 1.6278625748591653, Validation Loss Force: 2.059278701034752, time: 0.11825108528137207
Test Loss Energy: 9.715817969458953, Test Loss Force: 6.76886130287305, time: 8.637032508850098

Epoch 19, Batch 100/143, Loss: 0.07535780966281891, Uncertainty: 0.12086369842290878

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5816121532839713, Training Loss Force: 1.8055942051563654, time: 2.3761425018310547
Validation Loss Energy: 3.191714227669324, Validation Loss Force: 2.0253465210020596, time: 0.11795759201049805
Test Loss Energy: 7.852936968097744, Test Loss Force: 6.5932110577374825, time: 8.550522327423096

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–…â–‚â–„â–„â–ƒâ–„â–ˆâ–‚â–ƒâ–‡â–…â–„â–â–„â–‚â–‚â–„â–
wandb:   test_error_force â–†â–…â–ˆâ–‚â–„â–†â–‡â–ƒâ–†â–…â–…â–‡â–‡â–„â–†â–†â–…â–‡â–ˆâ–
wandb:          test_loss â–â–„â–ˆâ–ƒâ–‚â–„â–†â–‚â–‡â–ƒâ–„â–‡â–†â–…â–„â–†â–…â–…â–†â–
wandb: train_error_energy â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ˆâ–â–„â–„â–…â–†â–†â–‚â–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–â–â–‚â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–‚â–„â–â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–â–‚â–‚â–…â–‚â–‚â–‚â–â–ˆâ–ƒâ–‚â–…â–„â–‚â–†â–‚â–…â–‚â–ƒâ–‡
wandb:  valid_error_force â–ƒâ–„â–†â–‚â–‚â–‡â–ƒâ–â–‡â–ˆâ–ƒâ–ƒâ–†â–‚â–„â–„â–†â–„â–„â–ƒ
wandb:         valid_loss â–‚â–„â–…â–ƒâ–‚â–†â–ƒâ–â–ˆâ–‡â–ƒâ–„â–…â–‚â–…â–ƒâ–†â–„â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4554
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 7.85294
wandb:   test_error_force 6.59321
wandb:          test_loss 4.23792
wandb: train_error_energy 1.58161
wandb:  train_error_force 1.80559
wandb:         train_loss -2.67761
wandb: valid_error_energy 3.19171
wandb:  valid_error_force 2.02535
wandb:         valid_loss -2.26633
wandb: 
wandb: ğŸš€ View run al_69_59 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xnt82rv3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_160821-xnt82rv3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 34.816165924072266, Uncertainty Bias: -4.084427833557129
0.0 0.26522636
0.871552 6.661035
(48745, 22, 3)
Found uncertainty sample 0 after 2551 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3143 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2490 steps.
Found uncertainty sample 10 after 3619 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3980 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3715 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2538 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3740 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1371 steps.
Found uncertainty sample 31 after 1282 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2618 steps.
Found uncertainty sample 34 after 2841 steps.
Found uncertainty sample 35 after 1605 steps.
Found uncertainty sample 36 after 1487 steps.
Found uncertainty sample 37 after 2086 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1432 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3324 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1107 steps.
Found uncertainty sample 55 after 3855 steps.
Found uncertainty sample 56 after 2965 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2248 steps.
Found uncertainty sample 59 after 1696 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2226 steps.
Found uncertainty sample 62 after 2609 steps.
Found uncertainty sample 63 after 3027 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3278 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 297 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2274 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3480 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2308 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3090 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3097 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2808 steps.
Found uncertainty sample 95 after 1491 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2626 steps.
Found uncertainty sample 99 after 528 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_164610-n2nqqmv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_60
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n2nqqmv1
Training model 60. Added 36 samples to the dataset.
Epoch 0, Batch 100/144, Loss: 0.0391518734395504, Uncertainty: 0.1232549324631691

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.001664598165606, Training Loss Force: 1.9329796635819163, time: 2.112029790878296
Validation Loss Energy: 1.2331470742075912, Validation Loss Force: 2.294275404665491, time: 0.12129664421081543
Test Loss Energy: 9.57374819941159, Test Loss Force: 6.792336147452787, time: 8.657952785491943

Epoch 1, Batch 100/144, Loss: 0.12178979068994522, Uncertainty: 0.1224878653883934

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8338475797779625, Training Loss Force: 1.846015878399808, time: 2.1253397464752197
Validation Loss Energy: 2.200226340607777, Validation Loss Force: 2.20289458498343, time: 0.12137293815612793
Test Loss Energy: 10.133060456048112, Test Loss Force: 6.621574868054261, time: 8.560632944107056

Epoch 2, Batch 100/144, Loss: 0.09568243473768234, Uncertainty: 0.12111362814903259

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5032230372031132, Training Loss Force: 1.8203233111046597, time: 2.118316650390625
Validation Loss Energy: 1.7364013882498386, Validation Loss Force: 2.121978176037293, time: 0.11894464492797852
Test Loss Energy: 8.759009432829584, Test Loss Force: 6.628703691875371, time: 8.696876764297485

Epoch 3, Batch 100/144, Loss: 0.1649886667728424, Uncertainty: 0.12176749110221863

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.308373190196715, Training Loss Force: 1.8522019829257899, time: 2.1125648021698
Validation Loss Energy: 2.8068204403754784, Validation Loss Force: 2.0158229616307284, time: 0.11840057373046875
Test Loss Energy: 8.16113474826615, Test Loss Force: 6.5670506973507, time: 8.5553719997406

Epoch 4, Batch 100/144, Loss: 0.0741824060678482, Uncertainty: 0.12248252332210541

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.126409083288932, Training Loss Force: 1.8206857059128139, time: 2.1552412509918213
Validation Loss Energy: 2.0643025251936504, Validation Loss Force: 2.0226149643659146, time: 0.12725472450256348
Test Loss Energy: 8.300945058349765, Test Loss Force: 6.5987769283516915, time: 8.56984543800354

Epoch 5, Batch 100/144, Loss: 0.1300247609615326, Uncertainty: 0.12280872464179993

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8707121895305994, Training Loss Force: 1.82988776582948, time: 2.2225584983825684
Validation Loss Energy: 1.9604815514438467, Validation Loss Force: 2.0159544106498744, time: 0.12284445762634277
Test Loss Energy: 8.455372077651152, Test Loss Force: 6.6505120362663135, time: 9.719467401504517

Epoch 6, Batch 100/144, Loss: 0.16359436511993408, Uncertainty: 0.12281152606010437

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.524155314743388, Training Loss Force: 1.8538316187696893, time: 2.219752073287964
Validation Loss Energy: 1.7329599623764758, Validation Loss Force: 2.178995691108622, time: 0.1226046085357666
Test Loss Energy: 9.38317314790355, Test Loss Force: 6.681338038060653, time: 8.607839107513428

Epoch 7, Batch 100/144, Loss: 0.14579880237579346, Uncertainty: 0.12267247587442398

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.4445878718216503, Training Loss Force: 1.8386519863016733, time: 2.2238826751708984
Validation Loss Energy: 1.3463565213801971, Validation Loss Force: 2.1826700660201492, time: 0.12578392028808594
Test Loss Energy: 9.732472679602257, Test Loss Force: 6.735020120686598, time: 8.668276309967041

Epoch 8, Batch 100/144, Loss: 0.12847167253494263, Uncertainty: 0.1231657862663269

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9108271738696583, Training Loss Force: 1.8452009332935715, time: 2.1911840438842773
Validation Loss Energy: 2.516834774704337, Validation Loss Force: 2.1128551242364373, time: 0.12090516090393066
Test Loss Energy: 8.185487907211671, Test Loss Force: 6.655290791268386, time: 8.493119478225708

Epoch 9, Batch 100/144, Loss: 0.1721039116382599, Uncertainty: 0.12247207015752792

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.055405772123117, Training Loss Force: 1.8330247040162948, time: 2.1796913146972656
Validation Loss Energy: 1.0226306907032015, Validation Loss Force: 1.9778764651237253, time: 0.11948323249816895
Test Loss Energy: 8.434122593179048, Test Loss Force: 6.603138706815742, time: 8.520103931427002

Epoch 10, Batch 100/144, Loss: 0.051711805164813995, Uncertainty: 0.1218012124300003

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6882477048477655, Training Loss Force: 1.83756771745134, time: 2.196985960006714
Validation Loss Energy: 0.9890352977537251, Validation Loss Force: 2.049732652079682, time: 0.11870646476745605
Test Loss Energy: 9.095604824724282, Test Loss Force: 6.548784960781115, time: 8.828561544418335

Epoch 11, Batch 100/144, Loss: 0.5113779306411743, Uncertainty: 0.12119950354099274

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7799784780860308, Training Loss Force: 1.8228758347890677, time: 2.1901636123657227
Validation Loss Energy: 3.5283918318883547, Validation Loss Force: 2.273306799639569, time: 0.12137460708618164
Test Loss Energy: 11.618659460205281, Test Loss Force: 6.601247749133013, time: 8.555148124694824

Epoch 12, Batch 100/144, Loss: 0.10940490663051605, Uncertainty: 0.12236972153186798

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.289685111535039, Training Loss Force: 1.8801014635572229, time: 2.1549618244171143
Validation Loss Energy: 3.1033011423641876, Validation Loss Force: 2.2895007843924104, time: 0.1207418441772461
Test Loss Energy: 10.825433093232178, Test Loss Force: 6.904869461512493, time: 8.629383563995361

Epoch 13, Batch 100/144, Loss: 0.3634065091609955, Uncertainty: 0.12281376123428345

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1005568425006564, Training Loss Force: 1.8484768927968074, time: 2.1496832370758057
Validation Loss Energy: 2.7920764771009186, Validation Loss Force: 1.9738971448168499, time: 0.12518572807312012
Test Loss Energy: 8.030724995583979, Test Loss Force: 6.557319288572619, time: 8.668830633163452

Epoch 14, Batch 100/144, Loss: 0.08526885509490967, Uncertainty: 0.12227047979831696

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9759860535568312, Training Loss Force: 1.8395725562182252, time: 2.110720157623291
Validation Loss Energy: 4.230079610900367, Validation Loss Force: 2.040827964487933, time: 0.11711645126342773
Test Loss Energy: 7.939567387925325, Test Loss Force: 6.612280578628357, time: 8.476954698562622

Epoch 15, Batch 100/144, Loss: 0.20775675773620605, Uncertainty: 0.12248405069112778

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.233791146702802, Training Loss Force: 1.8287169273902566, time: 2.2021191120147705
Validation Loss Energy: 1.1675791938229707, Validation Loss Force: 2.1196420798043163, time: 0.11830973625183105
Test Loss Energy: 9.334328234207563, Test Loss Force: 6.752438077708564, time: 8.503599643707275

Epoch 16, Batch 100/144, Loss: 0.08363765478134155, Uncertainty: 0.12050855904817581

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.509862439669761, Training Loss Force: 1.7725164975230665, time: 2.1299259662628174
Validation Loss Energy: 1.2143820401612946, Validation Loss Force: 2.1184478309516566, time: 0.1197500228881836
Test Loss Energy: 9.208009342753078, Test Loss Force: 6.557939204138109, time: 8.690920352935791

Epoch 17, Batch 100/144, Loss: 0.3080766797065735, Uncertainty: 0.12147171050310135

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7872438398602495, Training Loss Force: 1.8526323668196578, time: 2.153986692428589
Validation Loss Energy: 3.552366544607351, Validation Loss Force: 2.289756111679741, time: 0.12070202827453613
Test Loss Energy: 11.519424108421754, Test Loss Force: 6.6270926048271255, time: 8.548776388168335

Epoch 18, Batch 100/144, Loss: 0.15838733315467834, Uncertainty: 0.12265591323375702

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.848206792803327, Training Loss Force: 1.8301682763786897, time: 2.149402379989624
Validation Loss Energy: 3.100282639421991, Validation Loss Force: 2.0102102518038993, time: 0.1239168643951416
Test Loss Energy: 7.837963512597215, Test Loss Force: 6.62797445625149, time: 8.581270694732666

Epoch 19, Batch 100/144, Loss: 0.15212494134902954, Uncertainty: 0.12324003875255585

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0588483148214145, Training Loss Force: 1.8354078916810082, time: 2.3561885356903076
Validation Loss Energy: 2.3054519855531423, Validation Loss Force: 2.122232983763283, time: 0.11856245994567871
Test Loss Energy: 8.287738863741076, Test Loss Force: 6.608606628653497, time: 8.561733722686768

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–ƒâ–‚â–‚â–‚â–„â–…â–‚â–‚â–ƒâ–ˆâ–‡â–â–â–„â–„â–ˆâ–â–‚
wandb:   test_error_force â–†â–‚â–ƒâ–â–‚â–ƒâ–„â–…â–ƒâ–‚â–â–‚â–ˆâ–â–‚â–…â–â–ƒâ–ƒâ–‚
wandb:          test_loss â–…â–„â–ƒâ–â–ƒâ–„â–ƒâ–…â–ƒâ–‚â–‚â–„â–ˆâ–â–‚â–…â–„â–„â–‚â–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–â–…â–„â–ƒâ–†â–…â–ƒâ–„â–‚â–‚â–…â–„â–ƒâ–„â–â–‚â–ƒâ–„
wandb:  train_error_force â–ˆâ–„â–ƒâ–„â–ƒâ–„â–…â–„â–„â–„â–„â–ƒâ–†â–„â–„â–ƒâ–â–„â–„â–„
wandb:         train_loss â–ˆâ–„â–‚â–…â–ƒâ–ƒâ–…â–„â–„â–„â–ƒâ–ƒâ–…â–„â–„â–„â–â–„â–ƒâ–„
wandb: valid_error_energy â–‚â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–‚â–„â–â–â–†â–†â–…â–ˆâ–â–â–‡â–†â–„
wandb:  valid_error_force â–ˆâ–†â–„â–‚â–‚â–‚â–…â–†â–„â–â–ƒâ–ˆâ–ˆâ–â–‚â–„â–„â–ˆâ–‚â–„
wandb:         valid_loss â–†â–†â–„â–ƒâ–ƒâ–‚â–…â–…â–„â–â–‚â–ˆâ–ˆâ–‚â–…â–ƒâ–„â–ˆâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4586
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 8.28774
wandb:   test_error_force 6.60861
wandb:          test_loss 4.2756
wandb: train_error_energy 2.05885
wandb:  train_error_force 1.83541
wandb:         train_loss -2.60467
wandb: valid_error_energy 2.30545
wandb:  valid_error_force 2.12223
wandb:         valid_loss -2.19408
wandb: 
wandb: ğŸš€ View run al_69_60 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n2nqqmv1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_164610-n2nqqmv1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.57192611694336, Uncertainty Bias: -4.679872989654541
4.4822693e-05 0.019107819
0.661787 6.5450406
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3150 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3414 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2116 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3604 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1953 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1581 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1933 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2699 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2046 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2894 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3234 steps.
Found uncertainty sample 39 after 1687 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1067 steps.
Found uncertainty sample 42 after 1727 steps.
Found uncertainty sample 43 after 1822 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1402 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2227 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2936 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3294 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1249 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2185 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2639 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1438 steps.
Found uncertainty sample 73 after 1403 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1068 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3946 steps.
Found uncertainty sample 84 after 2460 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1887 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2581 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_172404-1xpa52b7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_61
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1xpa52b7
Training model 61. Added 29 samples to the dataset.
Epoch 0, Batch 100/145, Loss: 0.12857922911643982, Uncertainty: 0.12462007254362106

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6812701690257716, Training Loss Force: 1.898572011360802, time: 2.2000980377197266
Validation Loss Energy: 1.19973319372357, Validation Loss Force: 1.9838179088329921, time: 0.11929559707641602
Test Loss Energy: 8.492533765095262, Test Loss Force: 6.531091430289441, time: 8.409122705459595

Epoch 1, Batch 100/145, Loss: 0.10261085629463196, Uncertainty: 0.12330101430416107

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9487758872943521, Training Loss Force: 1.8658900269554202, time: 2.1924657821655273
Validation Loss Energy: 1.194699497899202, Validation Loss Force: 2.1011130379411784, time: 0.11706352233886719
Test Loss Energy: 9.419384261929503, Test Loss Force: 6.557816645174899, time: 9.323747396469116

Epoch 2, Batch 100/145, Loss: 0.2013281285762787, Uncertainty: 0.12255780398845673

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.78293816172295, Training Loss Force: 1.8296696624354747, time: 2.223092555999756
Validation Loss Energy: 1.4350162127644481, Validation Loss Force: 2.1812447608170653, time: 0.11620235443115234
Test Loss Energy: 8.383063898171018, Test Loss Force: 6.554591780395745, time: 8.658047437667847

Epoch 3, Batch 100/145, Loss: 0.06746383011341095, Uncertainty: 0.12266337871551514

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6381836711258235, Training Loss Force: 1.8653143627159265, time: 2.1999223232269287
Validation Loss Energy: 2.1040458132621933, Validation Loss Force: 2.367836086822001, time: 0.11782956123352051
Test Loss Energy: 9.378350591199117, Test Loss Force: 6.537892004815242, time: 8.413119554519653

Epoch 4, Batch 100/145, Loss: 0.165130615234375, Uncertainty: 0.12269975244998932

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6579215448790878, Training Loss Force: 1.86058345879473, time: 2.1365556716918945
Validation Loss Energy: 2.203640897737531, Validation Loss Force: 2.0671585167708444, time: 0.12177491188049316
Test Loss Energy: 8.121098740232155, Test Loss Force: 6.666526858237802, time: 8.390243768692017

Epoch 5, Batch 100/145, Loss: 0.10673218965530396, Uncertainty: 0.12647634744644165

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4099676963801073, Training Loss Force: 1.9326734509133263, time: 2.1570632457733154
Validation Loss Energy: 1.5311361369908152, Validation Loss Force: 2.020652878075048, time: 0.17646551132202148
Test Loss Energy: 9.43649959176343, Test Loss Force: 6.602894134487021, time: 8.537196397781372

Epoch 6, Batch 100/145, Loss: 0.0748654156923294, Uncertainty: 0.12501060962677002

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4368784693019037, Training Loss Force: 1.8994294465123247, time: 2.1927146911621094
Validation Loss Energy: 1.103975477974579, Validation Loss Force: 2.048856337655883, time: 0.11629199981689453
Test Loss Energy: 8.942265202619287, Test Loss Force: 6.514101130929662, time: 8.364478826522827

Epoch 7, Batch 100/145, Loss: 0.05479350686073303, Uncertainty: 0.12358688563108444

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7036408576871434, Training Loss Force: 1.8152150909884486, time: 2.2229883670806885
Validation Loss Energy: 1.9661575735311676, Validation Loss Force: 2.202004761964778, time: 0.12543177604675293
Test Loss Energy: 7.992939149036727, Test Loss Force: 6.595169608912783, time: 8.285228729248047

Epoch 8, Batch 100/145, Loss: 0.11330512166023254, Uncertainty: 0.12241413444280624

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7066166027785499, Training Loss Force: 1.8620675962574669, time: 2.3773581981658936
Validation Loss Energy: 1.39454297812403, Validation Loss Force: 1.9816654404223568, time: 0.13385844230651855
Test Loss Energy: 8.235430477206062, Test Loss Force: 6.5466943889526155, time: 8.347210884094238

Epoch 9, Batch 100/145, Loss: 0.17415402829647064, Uncertainty: 0.12235818803310394

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8035286398590078, Training Loss Force: 1.82671621727512, time: 2.106369733810425
Validation Loss Energy: 1.3148061218669214, Validation Loss Force: 2.0558805843102723, time: 0.12653183937072754
Test Loss Energy: 8.307882071937472, Test Loss Force: 6.631961194588604, time: 8.340040922164917

Epoch 10, Batch 100/145, Loss: 0.19771435856819153, Uncertainty: 0.12176091223955154

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9306677816161215, Training Loss Force: 1.852447363924694, time: 2.186542272567749
Validation Loss Energy: 1.1384059173328092, Validation Loss Force: 2.097130006481871, time: 0.11885690689086914
Test Loss Energy: 8.335202823031459, Test Loss Force: 6.571596274622126, time: 8.490206956863403

Epoch 11, Batch 100/145, Loss: 0.0791662186384201, Uncertainty: 0.12201939523220062

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.536250440197746, Training Loss Force: 1.8316047210430317, time: 2.147494316101074
Validation Loss Energy: 1.2695258314811653, Validation Loss Force: 2.1474927943464777, time: 0.11834168434143066
Test Loss Energy: 9.178151359513544, Test Loss Force: 6.632081627119761, time: 8.409543991088867

Epoch 12, Batch 100/145, Loss: 0.08250617980957031, Uncertainty: 0.12301799654960632

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7279027338785944, Training Loss Force: 1.8335683588515566, time: 2.169741153717041
Validation Loss Energy: 2.792336925778605, Validation Loss Force: 2.170709281512065, time: 0.11778759956359863
Test Loss Energy: 10.75137807779966, Test Loss Force: 6.4598719117405405, time: 8.363366842269897

Epoch 13, Batch 100/145, Loss: 0.0488181933760643, Uncertainty: 0.12219881266355515

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9862549601854342, Training Loss Force: 1.8403038348485465, time: 2.1986186504364014
Validation Loss Energy: 2.511775212147517, Validation Loss Force: 2.136736687029387, time: 0.126023530960083
Test Loss Energy: 10.41309256413379, Test Loss Force: 6.637902240563369, time: 8.544808864593506

Epoch 14, Batch 100/145, Loss: 0.1038351058959961, Uncertainty: 0.12230302393436432

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7461542822528078, Training Loss Force: 1.8177921469740712, time: 2.1505374908447266
Validation Loss Energy: 1.0309709305657864, Validation Loss Force: 2.0936468672551714, time: 0.12070775032043457
Test Loss Energy: 8.558257806791053, Test Loss Force: 6.560353035607758, time: 8.351182222366333

Epoch 15, Batch 100/145, Loss: 0.07793226838111877, Uncertainty: 0.12248406559228897

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7149218494170273, Training Loss Force: 1.8209983369715461, time: 2.120173931121826
Validation Loss Energy: 2.0362843263422272, Validation Loss Force: 2.079143089766019, time: 0.14133501052856445
Test Loss Energy: 10.001253970927765, Test Loss Force: 6.487542717384838, time: 8.309045791625977

Epoch 16, Batch 100/145, Loss: 0.20874449610710144, Uncertainty: 0.1220790296792984

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.050949756768434, Training Loss Force: 1.8446370071412874, time: 2.17117977142334
Validation Loss Energy: 2.0024553534586724, Validation Loss Force: 1.9675334090723309, time: 0.11985349655151367
Test Loss Energy: 10.066607990130148, Test Loss Force: 6.463245384275558, time: 8.564000368118286

Epoch 17, Batch 100/145, Loss: 0.1284816414117813, Uncertainty: 0.12308482080698013

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.406700688144545, Training Loss Force: 1.8900317259214277, time: 2.191272258758545
Validation Loss Energy: 1.4864959090650285, Validation Loss Force: 2.134578466332482, time: 0.11699509620666504
Test Loss Energy: 9.050501209676243, Test Loss Force: 6.515257760743332, time: 8.400803327560425

Epoch 18, Batch 100/145, Loss: 0.12889595329761505, Uncertainty: 0.12257775664329529

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7876014233645616, Training Loss Force: 1.8157423208495793, time: 2.186741590499878
Validation Loss Energy: 1.002111747461718, Validation Loss Force: 2.114557207187909, time: 0.12133646011352539
Test Loss Energy: 8.950542297417542, Test Loss Force: 6.535304405142047, time: 8.335432767868042

Epoch 19, Batch 100/145, Loss: 0.05480197072029114, Uncertainty: 0.12111092358827591

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8461887196989528, Training Loss Force: 1.8450492913501668, time: 2.1550283432006836
Validation Loss Energy: 2.1681016773671535, Validation Loss Force: 2.28079464345578, time: 0.11688446998596191
Test Loss Energy: 9.882791961453147, Test Loss Force: 6.570426228700962, time: 8.56933069229126

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‚â–…â–â–…â–ƒâ–â–‚â–‚â–‚â–„â–ˆâ–‡â–‚â–†â–†â–„â–ƒâ–†
wandb:   test_error_force â–ƒâ–„â–„â–„â–ˆâ–†â–ƒâ–†â–„â–‡â–…â–‡â–â–‡â–„â–‚â–â–ƒâ–„â–…
wandb:          test_loss â–ƒâ–„â–…â–ƒâ–…â–ƒâ–â–…â–ƒâ–†â–ƒâ–†â–„â–ˆâ–„â–…â–ƒâ–‚â–…â–†
wandb: train_error_energy â–ˆâ–„â–ƒâ–‚â–‚â–†â–‡â–‚â–‚â–ƒâ–ƒâ–â–‚â–„â–‚â–‚â–„â–†â–ƒâ–ƒ
wandb:  train_error_force â–†â–„â–‚â–„â–„â–ˆâ–†â–â–„â–‚â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–…â–â–ƒ
wandb:         train_loss â–‡â–„â–‚â–ƒâ–ƒâ–ˆâ–‡â–â–ƒâ–‚â–ƒâ–â–‚â–ƒâ–â–â–ƒâ–†â–â–ƒ
wandb: valid_error_energy â–‚â–‚â–ƒâ–…â–†â–ƒâ–â–…â–ƒâ–‚â–‚â–‚â–ˆâ–‡â–â–…â–…â–ƒâ–â–†
wandb:  valid_error_force â–â–ƒâ–…â–ˆâ–ƒâ–‚â–‚â–…â–â–ƒâ–ƒâ–„â–…â–„â–ƒâ–ƒâ–â–„â–„â–†
wandb:         valid_loss â–â–ƒâ–„â–ˆâ–ƒâ–‚â–‚â–…â–â–‚â–ƒâ–„â–…â–…â–ƒâ–ƒâ–â–„â–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 4612
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 9.88279
wandb:   test_error_force 6.57043
wandb:          test_loss 4.2995
wandb: train_error_energy 1.84619
wandb:  train_error_force 1.84505
wandb:         train_loss -2.60553
wandb: valid_error_energy 2.1681
wandb:  valid_error_force 2.28079
wandb:         valid_loss -1.98622
wandb: 
wandb: ğŸš€ View run al_69_61 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1xpa52b7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_172404-1xpa52b7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.37753677368164, Uncertainty Bias: -4.406858921051025
3.8146973e-05 0.010360718
0.8262272 7.21986
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1071 steps.
Found uncertainty sample 2 after 1053 steps.
Found uncertainty sample 3 after 3015 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1741 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2349 steps.
Found uncertainty sample 10 after 3413 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2103 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1660 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2262 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1930 steps.
Found uncertainty sample 22 after 2018 steps.
Found uncertainty sample 23 after 1921 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2650 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1440 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2079 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2649 steps.
Found uncertainty sample 43 after 1177 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3696 steps.
Found uncertainty sample 47 after 1749 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3073 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3499 steps.
Found uncertainty sample 60 after 2416 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3478 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1139 steps.
Found uncertainty sample 65 after 1659 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3362 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2829 steps.
Found uncertainty sample 72 after 1750 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3479 steps.
Found uncertainty sample 76 after 2940 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3228 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2860 steps.
Found uncertainty sample 95 after 733 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2809 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_180124-erk0nq0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_62
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/erk0nq0h
Training model 62. Added 34 samples to the dataset.
Epoch 0, Batch 100/146, Loss: 0.18584802746772766, Uncertainty: 0.12466026097536087

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3709933246413986, Training Loss Force: 2.058500737996741, time: 2.164797067642212
Validation Loss Energy: 5.95238418663676, Validation Loss Force: 2.12680497511357, time: 0.11875629425048828
Test Loss Energy: 13.611209961748195, Test Loss Force: 6.510330048243284, time: 8.456166505813599

Epoch 1, Batch 100/146, Loss: 0.17624232172966003, Uncertainty: 0.12304234504699707

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.304492577409634, Training Loss Force: 1.8655741824733592, time: 2.24263072013855
Validation Loss Energy: 0.9600314353720903, Validation Loss Force: 2.037493271358518, time: 0.12138509750366211
Test Loss Energy: 8.251729609205269, Test Loss Force: 6.4030838743225935, time: 8.499342203140259

Epoch 2, Batch 100/146, Loss: 0.07301700115203857, Uncertainty: 0.1230752170085907

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8591297988110962, Training Loss Force: 1.843987441289439, time: 2.2213306427001953
Validation Loss Energy: 1.419906144302459, Validation Loss Force: 2.0382776605365724, time: 0.12246990203857422
Test Loss Energy: 7.863035643401373, Test Loss Force: 6.396420678499181, time: 8.612844228744507

Epoch 3, Batch 100/146, Loss: 0.09808873385190964, Uncertainty: 0.1227027028799057

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5898306838450393, Training Loss Force: 1.818474710584225, time: 2.1295971870422363
Validation Loss Energy: 1.2149902609333962, Validation Loss Force: 2.1871263436376025, time: 0.11907052993774414
Test Loss Energy: 8.031615641856705, Test Loss Force: 6.478886233999363, time: 8.561500072479248

Epoch 4, Batch 100/146, Loss: 0.05313467979431152, Uncertainty: 0.12223303318023682

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.686727722246846, Training Loss Force: 1.8662884845042247, time: 2.170654296875
Validation Loss Energy: 3.159621962789433, Validation Loss Force: 2.174468196475997, time: 0.11830353736877441
Test Loss Energy: 7.952333721203663, Test Loss Force: 6.477141128104638, time: 8.465214490890503

Epoch 5, Batch 100/146, Loss: 0.06041907146573067, Uncertainty: 0.12161611020565033

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8377591176173242, Training Loss Force: 1.8192060651063278, time: 2.1268234252929688
Validation Loss Energy: 2.0744840718911988, Validation Loss Force: 2.078613953652246, time: 0.12065434455871582
Test Loss Energy: 8.243284689487796, Test Loss Force: 6.490228979308397, time: 8.676637649536133

Epoch 6, Batch 100/146, Loss: 0.05871562287211418, Uncertainty: 0.12035088986158371

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9522302203718058, Training Loss Force: 1.8289590911330627, time: 2.1537766456604004
Validation Loss Energy: 3.763196000930915, Validation Loss Force: 2.033352887036088, time: 0.11875629425048828
Test Loss Energy: 11.777442291370251, Test Loss Force: 6.438697220785328, time: 8.484611988067627

Epoch 7, Batch 100/146, Loss: 0.17953629791736603, Uncertainty: 0.12264953553676605

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2165049177758585, Training Loss Force: 1.8432794380501671, time: 2.1767115592956543
Validation Loss Energy: 0.990681936087861, Validation Loss Force: 2.1949784741765512, time: 0.1164851188659668
Test Loss Energy: 8.667353214160268, Test Loss Force: 6.554060051138497, time: 9.483890533447266

Epoch 8, Batch 100/146, Loss: 0.1402481198310852, Uncertainty: 0.12261416018009186

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.907285836739744, Training Loss Force: 1.8440747855496262, time: 2.3660027980804443
Validation Loss Energy: 7.096916363069956, Validation Loss Force: 2.0666881653115965, time: 0.12284994125366211
Test Loss Energy: 7.706757814480335, Test Loss Force: 6.475752847767552, time: 8.44638705253601

Epoch 9, Batch 100/146, Loss: 0.09878865629434586, Uncertainty: 0.12226005643606186

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8418310476996356, Training Loss Force: 1.845796793576831, time: 2.1696832180023193
Validation Loss Energy: 2.359301920689075, Validation Loss Force: 2.1118999478234555, time: 0.12142109870910645
Test Loss Energy: 7.6629439923900735, Test Loss Force: 6.449278498237255, time: 8.471802711486816

Epoch 10, Batch 100/146, Loss: 0.0606943815946579, Uncertainty: 0.12308348715305328

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3582645662705373, Training Loss Force: 1.839861886833803, time: 2.2160823345184326
Validation Loss Energy: 1.118997926127646, Validation Loss Force: 2.050991771876855, time: 0.11782717704772949
Test Loss Energy: 8.137265117119721, Test Loss Force: 6.523312769299182, time: 8.621404886245728

Epoch 11, Batch 100/146, Loss: 0.19648966193199158, Uncertainty: 0.1221439391374588

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.6978829860477465, Training Loss Force: 1.8374262981627603, time: 2.2042269706726074
Validation Loss Energy: 1.1367987099932646, Validation Loss Force: 2.1033835952222044, time: 0.12779951095581055
Test Loss Energy: 8.795190587946049, Test Loss Force: 6.412443222776549, time: 8.509592771530151

Epoch 12, Batch 100/146, Loss: 0.04531057924032211, Uncertainty: 0.12186737358570099

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7421532190138072, Training Loss Force: 1.8525215131184227, time: 2.309706926345825
Validation Loss Energy: 1.0417326973903358, Validation Loss Force: 2.143648559988131, time: 0.12519598007202148
Test Loss Energy: 8.70599039596663, Test Loss Force: 6.467083918226046, time: 8.475268363952637

Epoch 13, Batch 100/146, Loss: 0.1318676918745041, Uncertainty: 0.12260925769805908

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.567246074141894, Training Loss Force: 1.8343474473066232, time: 2.1745755672454834
Validation Loss Energy: 3.330934845346533, Validation Loss Force: 2.1489823024866372, time: 0.11736726760864258
Test Loss Energy: 11.067186705697177, Test Loss Force: 6.449322099420803, time: 8.686252355575562

Epoch 14, Batch 100/146, Loss: 0.11155140399932861, Uncertainty: 0.12245629727840424

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7668323868180338, Training Loss Force: 1.8412088849412502, time: 2.1308023929595947
Validation Loss Energy: 2.7053707445837083, Validation Loss Force: 2.2541179148739987, time: 0.12403059005737305
Test Loss Energy: 10.548926777367015, Test Loss Force: 6.668207219872379, time: 8.450418710708618

Epoch 15, Batch 100/146, Loss: 0.07082610577344894, Uncertainty: 0.12132936716079712

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5831610001856384, Training Loss Force: 1.8456693299795333, time: 2.1327972412109375
Validation Loss Energy: 1.9985532993454338, Validation Loss Force: 2.0205266246693068, time: 0.11986875534057617
Test Loss Energy: 8.100899106974698, Test Loss Force: 6.345167256408519, time: 8.606025218963623

Epoch 16, Batch 100/146, Loss: 0.08268734812736511, Uncertainty: 0.12261340022087097

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.288274580928632, Training Loss Force: 1.8452554574307198, time: 2.1200790405273438
Validation Loss Energy: 2.7654482161699008, Validation Loss Force: 2.0414505474199465, time: 0.11812376976013184
Test Loss Energy: 7.88754249768471, Test Loss Force: 6.3915997306084735, time: 8.699227333068848

Epoch 17, Batch 100/146, Loss: 0.0607982762157917, Uncertainty: 0.12181153148412704

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7501474333113167, Training Loss Force: 1.8232088038018044, time: 2.2147250175476074
Validation Loss Energy: 2.7934054407868643, Validation Loss Force: 2.292054057265716, time: 0.11974263191223145
Test Loss Energy: 7.630644576033252, Test Loss Force: 6.57139918095119, time: 8.528442621231079

Epoch 18, Batch 100/146, Loss: 0.08953044563531876, Uncertainty: 0.12306617200374603

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5486882025977895, Training Loss Force: 1.8624767433189302, time: 2.154592275619507
Validation Loss Energy: 1.040819067328832, Validation Loss Force: 2.230879123682294, time: 0.1198728084564209
Test Loss Energy: 8.478690846315082, Test Loss Force: 6.5007496417887385, time: 8.478721380233765

Epoch 19, Batch 100/146, Loss: 0.051410846412181854, Uncertainty: 0.12131649255752563

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6779460640607093, Training Loss Force: 1.8098533432992507, time: 2.147217273712158
Validation Loss Energy: 3.4670954693973535, Validation Loss Force: 2.1222992649457213, time: 0.133864164352417
Test Loss Energy: 11.15302948996268, Test Loss Force: 6.464529623328563, time: 8.619030952453613

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–â–â–â–‚â–†â–‚â–â–â–‚â–‚â–‚â–…â–„â–‚â–â–â–‚â–…
wandb:   test_error_force â–…â–‚â–‚â–„â–„â–„â–ƒâ–†â–„â–ƒâ–…â–‚â–„â–ƒâ–ˆâ–â–‚â–†â–„â–„
wandb:          test_loss â–†â–â–â–ƒâ–‚â–„â–…â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–ˆâ–â–‚â–„â–„â–†
wandb: train_error_energy â–ˆâ–„â–‚â–â–‚â–‚â–ƒâ–„â–†â–‚â–„â–…â–‚â–â–‚â–â–„â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–
wandb: valid_error_energy â–‡â–â–‚â–â–„â–‚â–„â–â–ˆâ–ƒâ–â–â–â–„â–ƒâ–‚â–ƒâ–ƒâ–â–„
wandb:  valid_error_force â–„â–â–â–…â–…â–‚â–â–…â–‚â–ƒâ–‚â–ƒâ–„â–„â–‡â–â–‚â–ˆâ–†â–„
wandb:         valid_loss â–ˆâ–â–â–„â–†â–ƒâ–„â–„â–ˆâ–„â–â–ƒâ–ƒâ–†â–‡â–‚â–ƒâ–ˆâ–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4642
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 11.15303
wandb:   test_error_force 6.46453
wandb:          test_loss 4.35024
wandb: train_error_energy 1.67795
wandb:  train_error_force 1.80985
wandb:         train_loss -2.66542
wandb: valid_error_energy 3.4671
wandb:  valid_error_force 2.1223
wandb:         valid_loss -2.11156
wandb: 
wandb: ğŸš€ View run al_69_62 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/erk0nq0h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_180124-erk0nq0h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 35.982177734375, Uncertainty Bias: -4.193580627441406
0.00010681152 0.09453201
0.9102358 5.7678933
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1984 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2090 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3262 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1911 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1193 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1297 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2468 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3925 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2557 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1530 steps.
Found uncertainty sample 67 after 2795 steps.
Found uncertainty sample 68 after 3510 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2470 steps.
Found uncertainty sample 76 after 3204 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2694 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2521 steps.
Found uncertainty sample 93 after 3624 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2257 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_184125-ptothwbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_63
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ptothwbb
Training model 63. Added 18 samples to the dataset.
Epoch 0, Batch 100/146, Loss: 0.19288796186447144, Uncertainty: 0.12335863709449768

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3282801447708437, Training Loss Force: 1.9603937074490236, time: 2.1963891983032227
Validation Loss Energy: 2.4828565021584375, Validation Loss Force: 2.1788552982121145, time: 0.11991381645202637
Test Loss Energy: 9.994427587765564, Test Loss Force: 6.590379944288367, time: 8.53779673576355

Epoch 1, Batch 100/146, Loss: 0.19752219319343567, Uncertainty: 0.12283344566822052

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9665136675036288, Training Loss Force: 1.8379766493590188, time: 2.180152177810669
Validation Loss Energy: 2.599220800013597, Validation Loss Force: 2.21998978599289, time: 0.11995220184326172
Test Loss Energy: 10.309851200891053, Test Loss Force: 6.369212509391699, time: 8.586745500564575

Epoch 2, Batch 100/146, Loss: 0.32751476764678955, Uncertainty: 0.12324376404285431

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8858216450010792, Training Loss Force: 1.879556174472439, time: 2.2113394737243652
Validation Loss Energy: 1.904594490514869, Validation Loss Force: 2.127146401137326, time: 0.12128758430480957
Test Loss Energy: 8.10100754801457, Test Loss Force: 6.50279563315577, time: 8.723618745803833

Epoch 3, Batch 100/146, Loss: 0.3204125165939331, Uncertainty: 0.12255917489528656

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.969804900114895, Training Loss Force: 1.8417571787356048, time: 2.235454559326172
Validation Loss Energy: 1.318257011178986, Validation Loss Force: 1.9713091726683043, time: 0.1223459243774414
Test Loss Energy: 7.86239633113824, Test Loss Force: 6.432984903821521, time: 8.610055923461914

Epoch 4, Batch 100/146, Loss: 0.10795509815216064, Uncertainty: 0.12389399111270905

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9855634216728955, Training Loss Force: 1.8584107963260672, time: 2.181766986846924
Validation Loss Energy: 1.8705199135633557, Validation Loss Force: 2.010966844450238, time: 0.12134051322937012
Test Loss Energy: 9.466084962683155, Test Loss Force: 6.397947127955835, time: 9.49759030342102

Epoch 5, Batch 100/146, Loss: 0.05086062103509903, Uncertainty: 0.12219737470149994

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2047279805819056, Training Loss Force: 1.8367946178235173, time: 2.384244918823242
Validation Loss Energy: 3.497041500602695, Validation Loss Force: 2.0197441281789925, time: 0.12022542953491211
Test Loss Energy: 7.628489066420634, Test Loss Force: 6.346679184572598, time: 8.55026364326477

Epoch 6, Batch 100/146, Loss: 0.14493495225906372, Uncertainty: 0.1227254644036293

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0534156129711305, Training Loss Force: 1.8371068952868035, time: 2.203927516937256
Validation Loss Energy: 2.274984537431086, Validation Loss Force: 2.1979701083751393, time: 0.12286901473999023
Test Loss Energy: 7.98423801990459, Test Loss Force: 6.413828721498021, time: 8.561806678771973

Epoch 7, Batch 100/146, Loss: 0.39554640650749207, Uncertainty: 0.12229037284851074

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9206688975404753, Training Loss Force: 1.8442178985175153, time: 2.2291364669799805
Validation Loss Energy: 1.090606236895453, Validation Loss Force: 2.1028578733686687, time: 0.12236881256103516
Test Loss Energy: 8.562250672610004, Test Loss Force: 6.3183813892456495, time: 8.771001815795898

Epoch 8, Batch 100/146, Loss: 0.2044396847486496, Uncertainty: 0.1228673905134201

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0545263675029686, Training Loss Force: 1.8638005853603312, time: 2.163069248199463
Validation Loss Energy: 2.278944930860558, Validation Loss Force: 2.109634215040592, time: 0.12304210662841797
Test Loss Energy: 7.875094448383046, Test Loss Force: 6.405357876563444, time: 8.621881246566772

Epoch 9, Batch 100/146, Loss: 0.16001608967781067, Uncertainty: 0.12288840115070343

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0404456976129435, Training Loss Force: 1.8183822700983454, time: 2.2960314750671387
Validation Loss Energy: 3.0017942948249625, Validation Loss Force: 2.039111890491791, time: 0.12098169326782227
Test Loss Energy: 10.5579386756836, Test Loss Force: 6.365954675589262, time: 8.599103927612305

Epoch 10, Batch 100/146, Loss: 0.03896456956863403, Uncertainty: 0.12128344178199768

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4761113132710582, Training Loss Force: 1.820262012525645, time: 2.252999782562256
Validation Loss Energy: 1.819926292017471, Validation Loss Force: 2.0021323718625044, time: 0.12359952926635742
Test Loss Energy: 7.6456721319755925, Test Loss Force: 6.277615014754939, time: 8.76228141784668

Epoch 11, Batch 100/146, Loss: 0.060416776686906815, Uncertainty: 0.12293323874473572

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.373894680937632, Training Loss Force: 1.8373193918080513, time: 2.223973274230957
Validation Loss Energy: 4.083947046041364, Validation Loss Force: 2.0529159301898656, time: 0.13083577156066895
Test Loss Energy: 11.671668249624293, Test Loss Force: 6.421738705988869, time: 8.588741779327393

Epoch 12, Batch 100/146, Loss: 0.05483251065015793, Uncertainty: 0.12288404256105423

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.886010052076026, Training Loss Force: 1.845612934442933, time: 2.1742730140686035
Validation Loss Energy: 3.0403793693309624, Validation Loss Force: 1.996756878899137, time: 0.12334299087524414
Test Loss Energy: 7.584998664852893, Test Loss Force: 6.346483494533346, time: 8.617142677307129

Epoch 13, Batch 100/146, Loss: 0.141963392496109, Uncertainty: 0.12162235379219055

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.167729261568364, Training Loss Force: 1.816286462342939, time: 2.198916435241699
Validation Loss Energy: 4.119343275708531, Validation Loss Force: 1.9871868558993553, time: 0.12028002738952637
Test Loss Energy: 11.593083509564572, Test Loss Force: 6.316091070369376, time: 8.682141065597534

Epoch 14, Batch 100/146, Loss: 0.06252933293581009, Uncertainty: 0.12168942391872406

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9162774000698062, Training Loss Force: 1.833165267833401, time: 2.1580610275268555
Validation Loss Energy: 2.411905205500007, Validation Loss Force: 2.00270181109169, time: 0.12120676040649414
Test Loss Energy: 7.963772752848304, Test Loss Force: 6.2811750677129465, time: 8.584611654281616

Epoch 15, Batch 100/146, Loss: 0.08155810832977295, Uncertainty: 0.12130134552717209

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7382800558409701, Training Loss Force: 1.847422699278297, time: 2.2484683990478516
Validation Loss Energy: 2.0389327902754166, Validation Loss Force: 2.127870075861591, time: 0.11907577514648438
Test Loss Energy: 8.10046359876786, Test Loss Force: 6.329407410427838, time: 8.570680618286133

Epoch 16, Batch 100/146, Loss: 0.10446745157241821, Uncertainty: 0.12254320085048676

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.464372141374307, Training Loss Force: 1.8163610374426855, time: 2.1332523822784424
Validation Loss Energy: 1.7937366521924065, Validation Loss Force: 2.1731994276825, time: 0.12330317497253418
Test Loss Energy: 7.981757219814948, Test Loss Force: 6.386359495550174, time: 8.78178095817566

Epoch 17, Batch 100/146, Loss: 0.2951526641845703, Uncertainty: 0.12154346704483032

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9581211061109927, Training Loss Force: 1.821554545149945, time: 2.1796460151672363
Validation Loss Energy: 0.8917918406842927, Validation Loss Force: 1.948082962283344, time: 0.12110066413879395
Test Loss Energy: 8.174367642187821, Test Loss Force: 6.323537585937175, time: 8.623531341552734

Epoch 18, Batch 100/146, Loss: 0.06563392281532288, Uncertainty: 0.11963069438934326

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5510660749686687, Training Loss Force: 1.7939069076649437, time: 2.149479627609253
Validation Loss Energy: 4.443952731779618, Validation Loss Force: 2.0431987971076744, time: 0.12256979942321777
Test Loss Energy: 11.751372756678863, Test Loss Force: 6.36265757041065, time: 8.518211841583252

Epoch 19, Batch 100/146, Loss: 0.1371426284313202, Uncertainty: 0.11939739435911179

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9036997968628384, Training Loss Force: 1.8015737426506528, time: 2.37888765335083
Validation Loss Energy: 1.1539002385176211, Validation Loss Force: 2.0352569309029165, time: 0.1211848258972168
Test Loss Energy: 7.85866175919695, Test Loss Force: 6.410677913445702, time: 8.578569173812866

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–†â–‚â–â–„â–â–‚â–ƒâ–â–†â–â–ˆâ–â–ˆâ–‚â–‚â–‚â–‚â–ˆâ–
wandb:   test_error_force â–ˆâ–ƒâ–†â–„â–„â–ƒâ–„â–‚â–„â–ƒâ–â–„â–ƒâ–‚â–â–‚â–ƒâ–‚â–ƒâ–„
wandb:          test_loss â–ˆâ–„â–„â–„â–…â–‚â–„â–‚â–ƒâ–†â–‚â–†â–‚â–…â–â–‚â–ƒâ–ƒâ–‡â–…
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–â–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–…â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚
wandb: valid_error_energy â–„â–„â–ƒâ–‚â–ƒâ–†â–„â–â–„â–…â–ƒâ–‡â–…â–‡â–„â–ƒâ–ƒâ–â–ˆâ–‚
wandb:  valid_error_force â–‡â–ˆâ–†â–‚â–ƒâ–ƒâ–‡â–…â–…â–ƒâ–‚â–„â–‚â–‚â–‚â–†â–‡â–â–ƒâ–ƒ
wandb:         valid_loss â–‡â–ˆâ–…â–‚â–ƒâ–…â–‡â–„â–†â–…â–ƒâ–†â–„â–…â–„â–†â–†â–â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4658
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 7.85866
wandb:   test_error_force 6.41068
wandb:          test_loss 4.04061
wandb: train_error_energy 1.9037
wandb:  train_error_force 1.80157
wandb:         train_loss -2.66149
wandb: valid_error_energy 1.1539
wandb:  valid_error_force 2.03526
wandb:         valid_loss -2.38633
wandb: 
wandb: ğŸš€ View run al_69_63 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ptothwbb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_184125-ptothwbb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.44894027709961, Uncertainty Bias: -1.9602272510528564
1.9073486e-06 0.0017352104
1.2209039 4.155683
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 64.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2730 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241202_195949-h4bxud65
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_69_65
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/h4bxud65
Training model 65. Added 1 samples to the dataset.
Epoch 0, Batch 100/146, Loss: 0.07610271871089935, Uncertainty: 0.12336264550685883

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.9021812089202053, Training Loss Force: 1.9680893109833608, time: 2.218170404434204
Validation Loss Energy: 1.3268505557508259, Validation Loss Force: 2.0349071547861883, time: 0.12146258354187012
Test Loss Energy: 8.805933527861148, Test Loss Force: 6.329799562270608, time: 8.773075580596924

Epoch 1, Batch 100/146, Loss: 0.052540019154548645, Uncertainty: 0.12201256304979324

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5473766885726474, Training Loss Force: 1.834385840195288, time: 2.184548854827881
Validation Loss Energy: 1.4507571771398997, Validation Loss Force: 1.9710477219794604, time: 0.11970829963684082
Test Loss Energy: 7.973787179939893, Test Loss Force: 6.275354820332754, time: 8.733902931213379

Epoch 2, Batch 100/146, Loss: 0.04224654287099838, Uncertainty: 0.12141731381416321

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9029533164714068, Training Loss Force: 1.8262247239344218, time: 2.215379238128662
Validation Loss Energy: 2.350026711638502, Validation Loss Force: 2.074401127634341, time: 0.11996650695800781
Test Loss Energy: 10.112813264857989, Test Loss Force: 6.4073149471637905, time: 8.943289518356323

Epoch 3, Batch 100/146, Loss: 0.1974247694015503, Uncertainty: 0.12089885771274567

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.037577860088024, Training Loss Force: 1.8474959376006026, time: 2.207937002182007
Validation Loss Energy: 1.6119078852151476, Validation Loss Force: 2.324824943479346, time: 0.12364983558654785
Test Loss Energy: 8.129400326304848, Test Loss Force: 6.409041101699165, time: 8.686607599258423

Epoch 4, Batch 100/146, Loss: 0.06298519670963287, Uncertainty: 0.12356926500797272

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.414383790107246, Training Loss Force: 1.8335702198901969, time: 2.196089267730713
Validation Loss Energy: 1.245272856552808, Validation Loss Force: 1.9828867064647226, time: 0.12036538124084473
Test Loss Energy: 8.86403645806259, Test Loss Force: 6.295226952743027, time: 8.719129800796509

Epoch 5, Batch 100/146, Loss: 0.054125718772411346, Uncertainty: 0.12045755982398987

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.862825242646709, Training Loss Force: 1.8055182853922231, time: 2.353534460067749
Validation Loss Energy: 4.369295923640755, Validation Loss Force: 2.0805260136083272, time: 0.14373493194580078
Test Loss Energy: 7.416967784832719, Test Loss Force: 6.3416922490745735, time: 9.649764060974121

Epoch 6, Batch 100/146, Loss: 0.14615729451179504, Uncertainty: 0.12309561669826508

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0384390684691986, Training Loss Force: 1.83523413948524, time: 2.189016342163086
Validation Loss Energy: 2.39848597519762, Validation Loss Force: 2.1598078454657323, time: 0.12608838081359863
Test Loss Energy: 7.457463242087062, Test Loss Force: 6.323877721801133, time: 8.72225832939148

Epoch 7, Batch 100/146, Loss: 0.07343915849924088, Uncertainty: 0.12166543304920197

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6758777624266326, Training Loss Force: 1.824265684601377, time: 2.1711771488189697
Validation Loss Energy: 0.9691596642305891, Validation Loss Force: 2.209336700267315, time: 0.12388277053833008
Test Loss Energy: 8.199733829166611, Test Loss Force: 6.38254502385713, time: 8.841145992279053

Epoch 8, Batch 100/146, Loss: 0.2380128800868988, Uncertainty: 0.12213415652513504

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8923649795527606, Training Loss Force: 1.805117461102848, time: 2.19370436668396
Validation Loss Energy: 1.1440004796242447, Validation Loss Force: 2.096330846917136, time: 0.12273383140563965
Test Loss Energy: 8.854340284636688, Test Loss Force: 6.2629820914927645, time: 8.671305179595947

Epoch 9, Batch 100/146, Loss: 0.09153059124946594, Uncertainty: 0.12102503329515457

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6905714545828596, Training Loss Force: 1.8234803800904518, time: 2.1665172576904297
Validation Loss Energy: 2.334692378235039, Validation Loss Force: 2.050889826519544, time: 0.12670469284057617
Test Loss Energy: 9.693260610361776, Test Loss Force: 6.264657981091512, time: 8.683218479156494

Epoch 10, Batch 100/146, Loss: 0.16046053171157837, Uncertainty: 0.12126056849956512

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.402164565825797, Training Loss Force: 1.808070856959394, time: 2.1695356369018555
Validation Loss Energy: 3.4201842759637735, Validation Loss Force: 2.177576286637905, time: 0.1243748664855957
Test Loss Energy: 11.028229836282458, Test Loss Force: 6.409928271535279, time: 8.947402000427246

Epoch 11, Batch 100/146, Loss: 0.1729394793510437, Uncertainty: 0.12105987221002579

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1792044466102856, Training Loss Force: 1.8000116476733716, time: 2.255800724029541
Validation Loss Energy: 2.2612643326664537, Validation Loss Force: 2.1542399663602843, time: 0.11993193626403809
Test Loss Energy: 9.616193294080551, Test Loss Force: 6.2833716580342776, time: 8.82260775566101

Epoch 12, Batch 100/146, Loss: 0.05045181140303612, Uncertainty: 0.12018951028585434

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8571290646804766, Training Loss Force: 1.8490281407701745, time: 2.267678737640381
Validation Loss Energy: 1.065573400395008, Validation Loss Force: 2.008046204597676, time: 0.12199211120605469
Test Loss Energy: 8.090298523758074, Test Loss Force: 6.285024800405927, time: 8.735913038253784

Epoch 13, Batch 100/146, Loss: 0.09978029131889343, Uncertainty: 0.12116355448961258

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1883174742325586, Training Loss Force: 1.7975610425611581, time: 2.215942144393921
Validation Loss Energy: 0.9344424270124039, Validation Loss Force: 1.9089813695818407, time: 0.12098884582519531
Test Loss Energy: 8.657159637499802, Test Loss Force: 6.238621557651864, time: 8.92672324180603

Epoch 14, Batch 100/146, Loss: 0.09010321646928787, Uncertainty: 0.12088091671466827

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.6248990468463416, Training Loss Force: 1.8180589392471467, time: 2.2126102447509766
Validation Loss Energy: 3.0641314871270793, Validation Loss Force: 2.0782312967249688, time: 0.12238097190856934
Test Loss Energy: 10.310266382086223, Test Loss Force: 6.26347739394303, time: 8.708720922470093

Epoch 15, Batch 100/146, Loss: 0.08213429898023605, Uncertainty: 0.1212158203125

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7496582006015047, Training Loss Force: 1.8196676498576148, time: 2.160552978515625
Validation Loss Energy: 1.0252838492442178, Validation Loss Force: 1.977496257557054, time: 0.12101316452026367
Test Loss Energy: 8.567084006034777, Test Loss Force: 6.226502380186472, time: 8.662920475006104

Epoch 16, Batch 100/146, Loss: 0.17262712121009827, Uncertainty: 0.12104932963848114

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.115093216686432, Training Loss Force: 1.8142652960304837, time: 2.394818067550659
Validation Loss Energy: 1.4430312257836435, Validation Loss Force: 2.2325302896223973, time: 0.12130403518676758
Test Loss Energy: 8.691365738276417, Test Loss Force: 6.2923698930922765, time: 8.744353532791138

Epoch 17, Batch 100/146, Loss: 0.15279647707939148, Uncertainty: 0.11976993083953857

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8292346741318468, Training Loss Force: 1.8042186220172942, time: 2.2348761558532715
Validation Loss Energy: 3.086607859163127, Validation Loss Force: 1.984511597445606, time: 0.12331390380859375
Test Loss Energy: 10.357497077376237, Test Loss Force: 6.273079213941408, time: 8.69004201889038

Epoch 18, Batch 100/146, Loss: 0.24699881672859192, Uncertainty: 0.11995406448841095

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6960157929824822, Training Loss Force: 1.8000031618437278, time: 2.2055230140686035
Validation Loss Energy: 4.08624439784295, Validation Loss Force: 2.1508775880337256, time: 0.12386751174926758
Test Loss Energy: 11.594702442494244, Test Loss Force: 6.307795021880155, time: 8.80123233795166

Epoch 19, Batch 100/146, Loss: 0.14715448021888733, Uncertainty: 0.1200282871723175

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7818994575756277, Training Loss Force: 1.8098076793478926, time: 2.184758424758911
Validation Loss Energy: 1.0377854043289496, Validation Loss Force: 2.28532544101407, time: 0.12087225914001465
Test Loss Energy: 8.364071099041892, Test Loss Force: 6.334523433408536, time: 8.647221326828003

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.039 MB of 0.049 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–†â–‚â–ƒâ–â–â–‚â–ƒâ–…â–‡â–…â–‚â–ƒâ–†â–ƒâ–ƒâ–†â–ˆâ–ƒ
wandb:   test_error_force â–…â–ƒâ–ˆâ–ˆâ–„â–…â–…â–‡â–‚â–‚â–ˆâ–ƒâ–ƒâ–â–‚â–â–„â–ƒâ–„â–…
wandb:          test_loss â–ƒâ–â–‡â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ˆâ–…â–â–‚â–ƒâ–‚â–‚â–…â–‡â–„
wandb: train_error_energy â–„â–‚â–„â–…â–â–„â–…â–ƒâ–„â–ƒâ–‡â–…â–„â–…â–ˆâ–ƒâ–…â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–â–‚â–â–â–ƒâ–â–‚â–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚
wandb: valid_error_energy â–‚â–‚â–„â–‚â–‚â–ˆâ–„â–â–â–„â–†â–„â–â–â–…â–â–‚â–…â–‡â–
wandb:  valid_error_force â–ƒâ–‚â–„â–ˆâ–‚â–„â–…â–†â–„â–ƒâ–†â–…â–ƒâ–â–„â–‚â–†â–‚â–…â–‡
wandb:         valid_loss â–ƒâ–‚â–…â–ˆâ–‚â–†â–†â–†â–„â–„â–‡â–†â–ƒâ–â–…â–‚â–†â–„â–‡â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 4659
wandb:                 lr 0.0001
wandb:    max_uncertainty 5
wandb:  test_error_energy 8.36407
wandb:   test_error_force 6.33452
wandb:          test_loss 3.97046
wandb: train_error_energy 1.7819
wandb:  train_error_force 1.80981
wandb:         train_loss -2.65843
wandb: valid_error_energy 1.03779
wandb:  valid_error_force 2.28533
wandb:         valid_loss -2.0465
wandb: 
wandb: ğŸš€ View run al_69_65 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/h4bxud65
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241202_195949-h4bxud65/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.77260398864746, Uncertainty Bias: -1.9829990863800049
7.6293945e-06 0.0039463043
1.5064796 4.3354397
(48745, 22, 3)
Traceback (most recent call last):
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 948, in <module>
    al.improve_model(
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 627, in improve_model
    get_al_animation(f"al/run{run_idx}/data/train/")
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 331, in get_al_animation
    animate_active_learning(paths[0], paths[1:], fps=1)
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 318, in animate_active_learning
    ani.save(save_path + "animation.gif", writer=PillowWriter(fps=fps))
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/matplotlib/animation.py", line 1105, in save
    anim._draw_next_frame(d, blit=False)
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/matplotlib/animation.py", line 1140, in _draw_next_frame
    self._draw_frame(framedata)
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/matplotlib/animation.py", line 1768, in _draw_frame
    self._drawn_artists = self._func(framedata, *self._args)
                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 268, in update
    molecules, energies = read_xyz(path)
                          ^^^^^^^^^^^^^^
  File "/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py", line 75, in read_xyz
    with open(file_path, "r") as f:
         ^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'al/run69/data/train/train64.xyz'
