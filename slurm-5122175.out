/home/ws/fq0795/git/gnn_uncertainty/active_learning.py:173: DeprecationWarning: Please use atoms.calc = calc
  self.atoms.set_calculator(self.calc)
wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_191059-ek8tevfu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sky-49
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ek8tevfu
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
Uncertainty Slope: 0.6569403409957886, Uncertainty Bias: 0.02670024335384369

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.426708415589, Test Loss Force: 10.718343088491853, time: 13.744916200637817

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ
wandb:  test_error_energy ‚ñÅ
wandb:   test_error_force ‚ñÅ
wandb:   test_error_total ‚ñÅ
wandb: train_error_energy ‚ñÅ
wandb:  train_error_force ‚ñÅ
wandb:  train_error_total ‚ñÅ
wandb: valid_error_energy ‚ñÅ
wandb:  valid_error_force ‚ñÅ
wandb:  valid_error_total ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:  test_error_energy 12.42671
wandb:   test_error_force 10.71834
wandb:   test_error_total 6.04249
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:  train_error_total 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:  valid_error_total 0.0
wandb: 
wandb: üöÄ View run ruby-sky-49 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ek8tevfu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_191059-ek8tevfu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample after 128 steps.
Found uncertainty sample after 1223 steps.
Found uncertainty sample after 230 steps.
Found uncertainty sample after 100 steps.
Found uncertainty sample after 1706 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 3516 steps.
Found uncertainty sample after 2625 steps.
Found uncertainty sample after 43 steps.
Found uncertainty sample after 766 steps.
Found uncertainty sample after 737 steps.
Found uncertainty sample after 3029 steps.
Found uncertainty sample after 502 steps.
Found uncertainty sample after 495 steps.
Found uncertainty sample after 3184 steps.
Found uncertainty sample after 1975 steps.
Found uncertainty sample after 2874 steps.
Found uncertainty sample after 2121 steps.
Found uncertainty sample after 1379 steps.
Found uncertainty sample after 64 steps.
Found uncertainty sample after 148 steps.
Found uncertainty sample after 2117 steps.
Found uncertainty sample after 202 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_193559-gc9pa3nv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gc9pa3nv
Training model 0. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.913787618536352, Training Loss Force: 2.7261136544471043, time: 0.9880111217498779
Validation Loss Energy: 1.053877480836005, Validation Loss Force: 2.710545946650313, time: 0.05960416793823242
Test Loss Energy: 12.373575630932493, Test Loss Force: 10.675397424256387, time: 14.201956510543823


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2910055407021397, Training Loss Force: 2.385640814500762, time: 0.9232118129730225
Validation Loss Energy: 1.0369457189796558, Validation Loss Force: 2.611284494778624, time: 0.06088709831237793
Test Loss Energy: 12.063961257637065, Test Loss Force: 10.518818630588163, time: 14.257172346115112


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.158936689158987, Training Loss Force: 2.322683742698442, time: 0.8868317604064941
Validation Loss Energy: 1.357501557472175, Validation Loss Force: 2.6047589527880644, time: 0.059865474700927734
Test Loss Energy: 12.728691989533523, Test Loss Force: 10.510117158708754, time: 14.1490957736969


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2262102901381462, Training Loss Force: 2.3189559614486828, time: 0.9004507064819336
Validation Loss Energy: 1.0936471923098645, Validation Loss Force: 2.6154982856961615, time: 0.0596160888671875
Test Loss Energy: 12.023659820986284, Test Loss Force: 10.630017345062056, time: 14.43550181388855


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.0107002912556557, Training Loss Force: 2.3027881089184286, time: 0.9127838611602783
Validation Loss Energy: 1.1279740905152382, Validation Loss Force: 2.5966297476085325, time: 0.060953617095947266
Test Loss Energy: 12.497050163038198, Test Loss Force: 10.542348809033562, time: 14.670897483825684


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3605996731982388, Training Loss Force: 2.304334443366522, time: 0.8923025131225586
Validation Loss Energy: 1.3807620217940835, Validation Loss Force: 2.609689293017197, time: 0.06135272979736328
Test Loss Energy: 11.903959533235671, Test Loss Force: 10.514749045339077, time: 14.508378744125366


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3328114844377272, Training Loss Force: 2.2981609498598727, time: 0.8817427158355713
Validation Loss Energy: 1.2769601233677808, Validation Loss Force: 2.5997188366699886, time: 0.06156730651855469
Test Loss Energy: 12.535208561880149, Test Loss Force: 10.545259223009614, time: 14.395976066589355


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5638029367976547, Training Loss Force: 2.315909419322495, time: 0.8990004062652588
Validation Loss Energy: 1.0298395671910894, Validation Loss Force: 2.5973572077082787, time: 0.06105852127075195
Test Loss Energy: 12.048114535715262, Test Loss Force: 10.504293281005415, time: 14.504124164581299


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.0111625609667994, Training Loss Force: 2.29955424209113, time: 0.9055142402648926
Validation Loss Energy: 1.088736335631, Validation Loss Force: 2.5999617687081957, time: 0.06096363067626953
Test Loss Energy: 12.481221114751223, Test Loss Force: 10.384615917684572, time: 14.378138780593872


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2460090050313442, Training Loss Force: 2.307215756422234, time: 0.8966529369354248
Validation Loss Energy: 1.2512707840020918, Validation Loss Force: 2.6081384024158103, time: 0.0596928596496582
Test Loss Energy: 12.481074610111271, Test Loss Force: 10.515491459245816, time: 14.547790288925171


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2029321300422848, Training Loss Force: 2.327282168872975, time: 0.9001150131225586
Validation Loss Energy: 1.104576684668584, Validation Loss Force: 2.591398136024959, time: 0.06025195121765137
Test Loss Energy: 12.034272610202684, Test Loss Force: 10.483360585945354, time: 14.427088737487793


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.093846879430673, Training Loss Force: 2.294569587718786, time: 0.9133827686309814
Validation Loss Energy: 1.0634135096795083, Validation Loss Force: 2.591419734932114, time: 0.0612945556640625
Test Loss Energy: 12.000939617297592, Test Loss Force: 10.538842695635994, time: 14.59501338005066


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5760840372953047, Training Loss Force: 2.2938222501156673, time: 0.9060640335083008
Validation Loss Energy: 1.0621682324809072, Validation Loss Force: 2.5871052975606172, time: 0.06217813491821289
Test Loss Energy: 12.16158840191575, Test Loss Force: 10.483252366408818, time: 14.395684242248535


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.566194611106719, Training Loss Force: 2.3066827036152793, time: 0.8833098411560059
Validation Loss Energy: 2.3461663708786005, Validation Loss Force: 2.584176084945937, time: 0.06653094291687012
Test Loss Energy: 13.235545251354274, Test Loss Force: 10.398875537872309, time: 14.58263611793518


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.327285803990165, Training Loss Force: 2.3232604900431864, time: 0.9001705646514893
Validation Loss Energy: 1.2415777734107092, Validation Loss Force: 2.5882489262941024, time: 0.059531211853027344
Test Loss Energy: 11.80135812811317, Test Loss Force: 10.508734110513693, time: 14.492339134216309


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.1402068311282814, Training Loss Force: 2.3071155124855767, time: 0.9244372844696045
Validation Loss Energy: 1.0786760322834097, Validation Loss Force: 2.597522873552849, time: 0.059621572494506836
Test Loss Energy: 12.09736251087636, Test Loss Force: 10.432374527711177, time: 14.613234519958496


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.320605590444115, Training Loss Force: 2.3066837441653263, time: 0.9015069007873535
Validation Loss Energy: 1.4083654251381676, Validation Loss Force: 2.5830683059449466, time: 0.06099557876586914
Test Loss Energy: 11.636132599537996, Test Loss Force: 10.491872935942409, time: 14.471774578094482


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.1345195613943586, Training Loss Force: 2.2852674385562883, time: 0.882124662399292
Validation Loss Energy: 1.7247300736314608, Validation Loss Force: 2.5792542061443493, time: 0.061885833740234375
Test Loss Energy: 12.755563767349281, Test Loss Force: 10.377299704370383, time: 14.872567653656006


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2913278371624746, Training Loss Force: 2.2789160966335262, time: 0.895099401473999
Validation Loss Energy: 1.2054097353722317, Validation Loss Force: 2.576158882346807, time: 0.06166362762451172
Test Loss Energy: 11.843753629350369, Test Loss Force: 10.422203877812095, time: 14.448385953903198


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2746105121168019, Training Loss Force: 2.288440546681442, time: 0.9044358730316162
Validation Loss Energy: 1.32285457236953, Validation Loss Force: 2.5836842088025826, time: 0.060875892639160156
Test Loss Energy: 11.919628278390496, Test Loss Force: 10.436796433839472, time: 14.579621076583862

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.045 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: - 0.045 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: \ 0.045 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÇ
wandb:   test_error_force ‚ñà‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ
wandb:   test_error_total ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÇ‚ñÉ
wandb:  valid_error_force ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÅ‚ñÖ‚ñÇ‚ñÑ‚ñÅ‚ñÑ
wandb: 
wandb: Run summary:
wandb:       dataset_size 821
wandb:                 lr 0.0001
wandb:  test_error_energy 11.91963
wandb:   test_error_force 10.4368
wandb:   test_error_total 5.8401
wandb: train_error_energy 1.27461
wandb:  train_error_force 2.28844
wandb:  train_error_total 1.02178
wandb: valid_error_energy 1.32285
wandb:  valid_error_force 2.58368
wandb:  valid_error_total 1.30142
wandb: 
wandb: üöÄ View run al_40_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gc9pa3nv
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_193559-gc9pa3nv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.1226084232330322, Uncertainty Bias: -0.015603646636009216
Found uncertainty sample after 242 steps.
Found uncertainty sample after 2832 steps.
Found uncertainty sample after 19 steps.
Found uncertainty sample after 1403 steps.
Found uncertainty sample after 1715 steps.
Found uncertainty sample after 260 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 2067 steps.
Found uncertainty sample after 165 steps.
Found uncertainty sample after 527 steps.
Found uncertainty sample after 19 steps.
Found uncertainty sample after 177 steps.
Found uncertainty sample after 1443 steps.
Found uncertainty sample after 143 steps.
Found uncertainty sample after 254 steps.
Found uncertainty sample after 2796 steps.
Found uncertainty sample after 814 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 277 steps.
Found uncertainty sample after 186 steps.
Found uncertainty sample after 102 steps.
Found uncertainty sample after 653 steps.
Found uncertainty sample after 66 steps.
Found uncertainty sample after 1731 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 537 steps.
Found uncertainty sample after 51 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 675 steps.
Found uncertainty sample after 890 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_194958-zq3pom8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/zq3pom8p
Training model 1. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6505106695075424, Training Loss Force: 2.6376505669138144, time: 0.9449045658111572
Validation Loss Energy: 1.8380757943213744, Validation Loss Force: 2.6743847000207865, time: 0.06415700912475586
Test Loss Energy: 12.820643975782206, Test Loss Force: 10.401070621970938, time: 14.266834497451782


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2049801406136935, Training Loss Force: 2.3928482480798965, time: 0.9344086647033691
Validation Loss Energy: 1.1918510770729698, Validation Loss Force: 2.6068248771239824, time: 0.0612943172454834
Test Loss Energy: 12.344478234199944, Test Loss Force: 10.320559189910892, time: 14.367238998413086


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.0617337431246616, Training Loss Force: 2.3694225220166825, time: 0.9226841926574707
Validation Loss Energy: 1.2668369159864656, Validation Loss Force: 2.6270416768902036, time: 0.0614933967590332
Test Loss Energy: 11.844339055680189, Test Loss Force: 10.34110482304175, time: 14.20359992980957


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.0991175052178725, Training Loss Force: 2.3299770580543204, time: 0.9311099052429199
Validation Loss Energy: 1.0401222056808888, Validation Loss Force: 2.613590456453852, time: 0.06277608871459961
Test Loss Energy: 12.125309036882056, Test Loss Force: 10.293468804620954, time: 14.659539222717285


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.1152957526226503, Training Loss Force: 2.3255885749447973, time: 0.94978928565979
Validation Loss Energy: 1.3056384620138313, Validation Loss Force: 2.594635077399311, time: 0.06372880935668945
Test Loss Energy: 12.53211999859767, Test Loss Force: 10.349164737313654, time: 14.236716032028198


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.0498122906471041, Training Loss Force: 2.3411032043804187, time: 0.9133198261260986
Validation Loss Energy: 1.0032334989516158, Validation Loss Force: 2.590139610012175, time: 0.06332564353942871
Test Loss Energy: 12.039592416255152, Test Loss Force: 10.406323212252316, time: 14.43533730506897


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4174619050876094, Training Loss Force: 2.3279006723920466, time: 0.933117151260376
Validation Loss Energy: 2.8407174386831144, Validation Loss Force: 2.584976580525548, time: 0.06295371055603027
Test Loss Energy: 13.761054331114066, Test Loss Force: 10.431659202496979, time: 14.272007942199707


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9435018662390906, Training Loss Force: 2.3558247770353047, time: 0.9248373508453369
Validation Loss Energy: 2.4703830219418546, Validation Loss Force: 2.5958599803710602, time: 0.06123948097229004
Test Loss Energy: 13.412200352215711, Test Loss Force: 10.357402917472685, time: 14.393424987792969


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5373169953904846, Training Loss Force: 2.3499455528583137, time: 0.9611687660217285
Validation Loss Energy: 1.2752577064125898, Validation Loss Force: 2.5930363129315497, time: 0.06180548667907715
Test Loss Energy: 12.62659677783072, Test Loss Force: 10.370036218177306, time: 14.256238460540771


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.359657170053621, Training Loss Force: 2.322447269968621, time: 0.94852614402771
Validation Loss Energy: 1.1343889659402717, Validation Loss Force: 2.5842767313998967, time: 0.06691527366638184
Test Loss Energy: 11.932131834097268, Test Loss Force: 10.356202336733352, time: 14.458608150482178


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4234842581051508, Training Loss Force: 2.3382277539939715, time: 0.9381556510925293
Validation Loss Energy: 1.2713858239686244, Validation Loss Force: 2.5978448531378606, time: 0.06574749946594238
Test Loss Energy: 11.694134507895608, Test Loss Force: 10.400008291957663, time: 14.314318656921387


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.338732801964689, Training Loss Force: 2.3342590723240684, time: 0.9520564079284668
Validation Loss Energy: 1.7245482642738108, Validation Loss Force: 2.585178541440904, time: 0.0625143051147461
Test Loss Energy: 12.774584590148194, Test Loss Force: 10.281369466859882, time: 14.70998239517212


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.259576388503728, Training Loss Force: 2.338225824194707, time: 0.932175874710083
Validation Loss Energy: 1.0359630800386765, Validation Loss Force: 2.5877721916526712, time: 0.06154513359069824
Test Loss Energy: 11.853874326749107, Test Loss Force: 10.415659265549865, time: 14.269748449325562


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.364104062578923, Training Loss Force: 2.3353194227969767, time: 0.9322843551635742
Validation Loss Energy: 1.5910565526060805, Validation Loss Force: 2.5849177958710228, time: 0.061994314193725586
Test Loss Energy: 11.600974866790429, Test Loss Force: 10.388034754103394, time: 14.474337339401245


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.384667733454219, Training Loss Force: 2.3226824374512396, time: 0.948169469833374
Validation Loss Energy: 1.0736418168977013, Validation Loss Force: 2.5855760058663853, time: 0.06521391868591309
Test Loss Energy: 12.02112387822333, Test Loss Force: 10.385622153725983, time: 14.241238355636597


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.0936922539473959, Training Loss Force: 2.318337947992048, time: 0.9611098766326904
Validation Loss Energy: 1.3645170829183486, Validation Loss Force: 2.588336212599306, time: 0.06293869018554688
Test Loss Energy: 12.551057601426363, Test Loss Force: 10.358994230101805, time: 14.431269645690918


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.261465317671401, Training Loss Force: 2.3001080085209296, time: 0.9346730709075928
Validation Loss Energy: 1.143852181973057, Validation Loss Force: 2.579104127139994, time: 0.06266927719116211
Test Loss Energy: 12.356583918614575, Test Loss Force: 10.349362957154197, time: 14.280106782913208


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5104331494532173, Training Loss Force: 2.318032924250149, time: 0.9207379817962646
Validation Loss Energy: 1.2516967500782517, Validation Loss Force: 2.5961082564687694, time: 0.06167888641357422
Test Loss Energy: 11.823152806913914, Test Loss Force: 10.414355291715172, time: 14.472260475158691


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4073783719875455, Training Loss Force: 2.3370824841064115, time: 0.920325517654419
Validation Loss Energy: 1.1572784634650648, Validation Loss Force: 2.600748681469905, time: 0.06630277633666992
Test Loss Energy: 11.831695262712147, Test Loss Force: 10.371136171115591, time: 14.32036018371582


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.131778953669782, Training Loss Force: 2.332270323464728, time: 0.9408843517303467
Validation Loss Energy: 1.0372328508433297, Validation Loss Force: 2.607840916436851, time: 0.06369352340698242
Test Loss Energy: 11.993363918650942, Test Loss Force: 10.32865254419212, time: 14.400762557983398

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:   test_error_force ‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñá‚ñà‚ñÖ‚ñÖ‚ñÑ‚ñá‚ñÅ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñá‚ñÖ‚ñÉ
wandb:   test_error_total ‚ñá‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñà‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:  valid_error_force ‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ
wandb:  valid_error_total ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 848
wandb:                 lr 0.0001
wandb:  test_error_energy 11.99336
wandb:   test_error_force 10.32865
wandb:   test_error_total 5.79805
wandb: train_error_energy 1.13178
wandb:  train_error_force 2.33227
wandb:  train_error_total 1.04642
wandb: valid_error_energy 1.03723
wandb:  valid_error_force 2.60784
wandb:  valid_error_total 1.26219
wandb: 
wandb: üöÄ View run al_40_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/zq3pom8p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_194958-zq3pom8p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6401230692863464, Uncertainty Bias: 0.02972753345966339
Found uncertainty sample after 1998 steps.
Found uncertainty sample after 375 steps.
Found uncertainty sample after 151 steps.
Found uncertainty sample after 1328 steps.
Found uncertainty sample after 945 steps.
Found uncertainty sample after 3768 steps.
Found uncertainty sample after 2150 steps.
Found uncertainty sample after 741 steps.
Found uncertainty sample after 1577 steps.
Found uncertainty sample after 501 steps.
Found uncertainty sample after 1492 steps.
Found uncertainty sample after 1902 steps.
Found uncertainty sample after 1264 steps.
Found uncertainty sample after 1681 steps.
Found uncertainty sample after 3731 steps.
Found uncertainty sample after 1602 steps.
Found uncertainty sample after 3933 steps.
Found uncertainty sample after 2230 steps.
Found uncertainty sample after 1752 steps.
Found uncertainty sample after 1325 steps.
Found uncertainty sample after 2149 steps.
Found uncertainty sample after 804 steps.
Found uncertainty sample after 455 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_202427-lvijzdoa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/lvijzdoa
Training model 2. Added 23 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.382076016286607, Training Loss Force: 2.8364645534255275, time: 0.9320085048675537
Validation Loss Energy: 2.2330308498624425, Validation Loss Force: 2.657663583176485, time: 0.06600165367126465
Test Loss Energy: 13.02457944184992, Test Loss Force: 10.313514824147092, time: 14.412963390350342


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6247722896137557, Training Loss Force: 2.4571142311557743, time: 0.9592249393463135
Validation Loss Energy: 1.663089241971709, Validation Loss Force: 2.625629286497584, time: 0.06527137756347656
Test Loss Energy: 12.606810141046024, Test Loss Force: 10.316875533426561, time: 14.979124069213867


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.782962091169847, Training Loss Force: 2.41726910641367, time: 0.9509544372558594
Validation Loss Energy: 2.3371440397547523, Validation Loss Force: 2.6056425039591056, time: 0.06327486038208008
Test Loss Energy: 13.149493643067329, Test Loss Force: 10.295932201543003, time: 14.507667541503906


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3409180084095922, Training Loss Force: 2.3716041935152594, time: 0.9428932666778564
Validation Loss Energy: 1.7720696453902813, Validation Loss Force: 2.5958003050399516, time: 0.06993865966796875
Test Loss Energy: 12.561710382487698, Test Loss Force: 10.275933485803595, time: 14.694094181060791


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2729161991868254, Training Loss Force: 2.3888110670776372, time: 0.9537532329559326
Validation Loss Energy: 1.033365087778564, Validation Loss Force: 2.5998453127448755, time: 0.06370997428894043
Test Loss Energy: 11.83132852779461, Test Loss Force: 10.222503098587424, time: 14.543288230895996


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3213719378138393, Training Loss Force: 2.3874580259648766, time: 0.9598207473754883
Validation Loss Energy: 1.1722669916849018, Validation Loss Force: 2.5923685281629125, time: 0.06550741195678711
Test Loss Energy: 12.167298851256671, Test Loss Force: 10.25572243463192, time: 14.670337677001953


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8037547829315457, Training Loss Force: 2.3962379737709125, time: 0.9624149799346924
Validation Loss Energy: 2.394055378754998, Validation Loss Force: 2.6116095917316784, time: 0.06412148475646973
Test Loss Energy: 11.378042299765584, Test Loss Force: 10.300951341294885, time: 14.551008701324463


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8425849797183933, Training Loss Force: 2.39979493842278, time: 0.9546244144439697
Validation Loss Energy: 1.116359445194499, Validation Loss Force: 2.6064227366464365, time: 0.06324076652526855
Test Loss Energy: 11.710722221439552, Test Loss Force: 10.288537226304737, time: 14.722489833831787


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.1753883876536915, Training Loss Force: 2.381523940940718, time: 0.9712469577789307
Validation Loss Energy: 1.0822705803061219, Validation Loss Force: 2.598163715354829, time: 0.06850075721740723
Test Loss Energy: 12.042670338050907, Test Loss Force: 10.283253079958216, time: 14.428406476974487


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.1537349941539345, Training Loss Force: 2.3737326998098878, time: 0.9612505435943604
Validation Loss Energy: 1.1022696096476263, Validation Loss Force: 2.5890091187583, time: 0.06560730934143066
Test Loss Energy: 12.028653793295645, Test Loss Force: 10.238730559101013, time: 14.994408130645752


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2893443351261376, Training Loss Force: 2.376169980613927, time: 0.9931550025939941
Validation Loss Energy: 1.1250407585213584, Validation Loss Force: 2.617398766856655, time: 0.06545448303222656
Test Loss Energy: 11.604886643734439, Test Loss Force: 10.232750290713968, time: 14.559564113616943


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.2625184606297553, Training Loss Force: 2.4286567962074224, time: 0.9510877132415771
Validation Loss Energy: 1.5806959799152063, Validation Loss Force: 2.586551519394695, time: 0.06589102745056152
Test Loss Energy: 11.495690813746217, Test Loss Force: 10.280118560561956, time: 14.713224411010742


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5354933420805637, Training Loss Force: 2.4028199862473736, time: 0.9715547561645508
Validation Loss Energy: 1.5431300249785942, Validation Loss Force: 2.63968995238634, time: 0.06432199478149414
Test Loss Energy: 11.455095672994537, Test Loss Force: 10.252009735562442, time: 14.592478036880493


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3583853770390617, Training Loss Force: 2.3757137474388594, time: 0.9646005630493164
Validation Loss Energy: 1.120873060117028, Validation Loss Force: 2.5990031780349767, time: 0.06340646743774414
Test Loss Energy: 11.565582447757894, Test Loss Force: 10.219274050892588, time: 14.672135353088379


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.1668230213321045, Training Loss Force: 2.3793565868325954, time: 0.9497098922729492
Validation Loss Energy: 1.1988997802218868, Validation Loss Force: 2.606843804001386, time: 0.06270718574523926
Test Loss Energy: 11.640619818840277, Test Loss Force: 10.142299658759445, time: 14.57567834854126


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3311685293204256, Training Loss Force: 2.411288881161488, time: 0.9835784435272217
Validation Loss Energy: 1.4050905186744347, Validation Loss Force: 2.6044131476044385, time: 0.06341671943664551
Test Loss Energy: 12.296314627468528, Test Loss Force: 10.17920961348795, time: 14.66857099533081


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.553976066110525, Training Loss Force: 2.392030934499979, time: 0.9593877792358398
Validation Loss Energy: 1.279737586959511, Validation Loss Force: 2.602474144681699, time: 0.06536364555358887
Test Loss Energy: 11.678125174543698, Test Loss Force: 10.282841368204817, time: 14.558674097061157


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4950730271484154, Training Loss Force: 2.3692597538163684, time: 0.9815032482147217
Validation Loss Energy: 2.681081474584565, Validation Loss Force: 2.6031243385878082, time: 0.06486749649047852
Test Loss Energy: 13.272000144960158, Test Loss Force: 10.200815991134503, time: 14.65545129776001


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.516240640072688, Training Loss Force: 2.381179503581845, time: 0.9645748138427734
Validation Loss Energy: 1.141557465089698, Validation Loss Force: 2.5715943875244336, time: 0.0637826919555664
Test Loss Energy: 12.087917193479166, Test Loss Force: 10.190746290799211, time: 14.4964120388031


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.1478231402582557, Training Loss Force: 2.3970924189035934, time: 0.9297106266021729
Validation Loss Energy: 1.1341563880173502, Validation Loss Force: 2.583202798109087, time: 0.06314587593078613
Test Loss Energy: 11.612400256161004, Test Loss Force: 10.132092682312786, time: 14.715069055557251

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñá‚ñÜ‚ñà‚ñÖ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÇ
wandb:   test_error_force ‚ñà‚ñà‚ñá‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñá‚ñÑ‚ñÉ‚ñÅ
wandb:   test_error_total ‚ñà‚ñá‚ñá‚ñÖ‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÜ‚ñÑ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÅ
wandb:  valid_error_force ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÇ‚ñá‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÅ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÖ‚ñá‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñá‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 868
wandb:                 lr 0.0001
wandb:  test_error_energy 11.6124
wandb:   test_error_force 10.13209
wandb:   test_error_total 5.68468
wandb: train_error_energy 1.14782
wandb:  train_error_force 2.39709
wandb:  train_error_total 1.06456
wandb: valid_error_energy 1.13416
wandb:  valid_error_force 2.5832
wandb:  valid_error_total 1.28076
wandb: 
wandb: üöÄ View run al_40_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/lvijzdoa
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_202427-lvijzdoa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0482640266418457, Uncertainty Bias: -0.0019555091857910156
Found uncertainty sample after 488 steps.
Found uncertainty sample after 157 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 144 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 637 steps.
Found uncertainty sample after 457 steps.
Found uncertainty sample after 2172 steps.
Found uncertainty sample after 378 steps.
Found uncertainty sample after 373 steps.
Found uncertainty sample after 1848 steps.
Found uncertainty sample after 382 steps.
Found uncertainty sample after 240 steps.
Found uncertainty sample after 1413 steps.
Found uncertainty sample after 3789 steps.
Found uncertainty sample after 179 steps.
Found uncertainty sample after 1377 steps.
Found uncertainty sample after 259 steps.
Found uncertainty sample after 1952 steps.
Found uncertainty sample after 67 steps.
Found uncertainty sample after 221 steps.
Found uncertainty sample after 1630 steps.
Found uncertainty sample after 1527 steps.
Found uncertainty sample after 588 steps.
Found uncertainty sample after 54 steps.
Found uncertainty sample after 64 steps.
Found uncertainty sample after 2079 steps.
Found uncertainty sample after 2390 steps.
Found uncertainty sample after 58 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_204217-fb34etf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fb34etf4
Training model 3. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.897526116274939, Training Loss Force: 2.9298714449680325, time: 0.9310777187347412
Validation Loss Energy: 1.055807242989188, Validation Loss Force: 2.6374247391648167, time: 0.06521296501159668
Test Loss Energy: 11.856118230183625, Test Loss Force: 10.081717082617336, time: 14.291114807128906


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.223768029100084, Training Loss Force: 2.4749623242624326, time: 0.9602193832397461
Validation Loss Energy: 1.1632239523304826, Validation Loss Force: 2.580612042596217, time: 0.06438398361206055
Test Loss Energy: 11.402442021044555, Test Loss Force: 10.177771194121398, time: 14.463951349258423


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.1860590629163827, Training Loss Force: 2.427286466425975, time: 0.9595451354980469
Validation Loss Energy: 1.6521044163302263, Validation Loss Force: 2.581512516622349, time: 0.06528592109680176
Test Loss Energy: 11.283954942055203, Test Loss Force: 10.221431423464866, time: 14.260978698730469


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.482693793635964, Training Loss Force: 2.406851331609701, time: 0.9679698944091797
Validation Loss Energy: 1.2307544942345972, Validation Loss Force: 2.573673449339961, time: 0.06614923477172852
Test Loss Energy: 11.507120213493035, Test Loss Force: 10.180436704679527, time: 14.386120557785034


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2327841016304375, Training Loss Force: 2.418603538747807, time: 0.9741568565368652
Validation Loss Energy: 1.0866560491351698, Validation Loss Force: 2.5810319966054367, time: 0.06822800636291504
Test Loss Energy: 11.961695796136384, Test Loss Force: 10.120547881658023, time: 14.358902215957642


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2791392789406377, Training Loss Force: 2.430656587807, time: 0.9623544216156006
Validation Loss Energy: 1.0366688298966946, Validation Loss Force: 2.5924974535984044, time: 0.06528878211975098
Test Loss Energy: 11.863790560244768, Test Loss Force: 10.083808624397301, time: 14.483123779296875


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.457010613457901, Training Loss Force: 2.4119762210526186, time: 0.9445128440856934
Validation Loss Energy: 1.8289406812751139, Validation Loss Force: 2.587658185049956, time: 0.06871199607849121
Test Loss Energy: 12.381271002004109, Test Loss Force: 10.083249470695087, time: 14.320512533187866


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5782743436067859, Training Loss Force: 2.442993206023533, time: 0.9620342254638672
Validation Loss Energy: 1.1941709555698183, Validation Loss Force: 2.5802401851225176, time: 0.0636894702911377
Test Loss Energy: 11.557514200297222, Test Loss Force: 10.202749407509872, time: 14.485290288925171


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5468463750122459, Training Loss Force: 2.4429417376409446, time: 0.9724719524383545
Validation Loss Energy: 1.168272863879822, Validation Loss Force: 2.569760707107718, time: 0.06492471694946289
Test Loss Energy: 11.895362102640341, Test Loss Force: 10.09631509928492, time: 14.359434366226196


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2763221802409324, Training Loss Force: 2.4274444024701936, time: 0.9561035633087158
Validation Loss Energy: 1.0402731753618277, Validation Loss Force: 2.5706237727173344, time: 0.06519341468811035
Test Loss Energy: 11.437602285925031, Test Loss Force: 10.098133133405259, time: 14.483531475067139


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5606782423892092, Training Loss Force: 2.4459955177378325, time: 1.0277814865112305
Validation Loss Energy: 1.0802983996806395, Validation Loss Force: 2.5923104115158253, time: 0.07341361045837402
Test Loss Energy: 11.564445669306616, Test Loss Force: 10.17338651454372, time: 14.6991548538208


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5576740837138685, Training Loss Force: 2.438004733242373, time: 0.9552569389343262
Validation Loss Energy: 1.4775166644209177, Validation Loss Force: 2.6011332310849222, time: 0.06428742408752441
Test Loss Energy: 12.104561719132109, Test Loss Force: 10.067078854933097, time: 14.583939790725708


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4036413302173327, Training Loss Force: 2.4357548046672237, time: 0.9708278179168701
Validation Loss Energy: 1.0381334362040346, Validation Loss Force: 2.5735779242763583, time: 0.0639796257019043
Test Loss Energy: 11.744608902743426, Test Loss Force: 10.110514810980142, time: 14.358891248703003


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3966025139761182, Training Loss Force: 2.414195405380691, time: 0.9704666137695312
Validation Loss Energy: 1.2871415587307558, Validation Loss Force: 2.5717197502535907, time: 0.0645301342010498
Test Loss Energy: 11.340283726108389, Test Loss Force: 10.140945904963855, time: 14.493786811828613


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4074860887759597, Training Loss Force: 2.4126930487006466, time: 0.9651920795440674
Validation Loss Energy: 1.2065915518642434, Validation Loss Force: 2.5703766099653547, time: 0.06506872177124023
Test Loss Energy: 11.411346473920485, Test Loss Force: 10.114301590092598, time: 14.302453994750977


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.1861710376631414, Training Loss Force: 2.4209756490643146, time: 0.9830217361450195
Validation Loss Energy: 1.0387776180432038, Validation Loss Force: 2.569461885113883, time: 0.06502413749694824
Test Loss Energy: 11.626276391115564, Test Loss Force: 10.135972590755365, time: 14.476422548294067


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4707352278668695, Training Loss Force: 2.421855550051857, time: 0.9604015350341797
Validation Loss Energy: 1.051333374509207, Validation Loss Force: 2.572215857110718, time: 0.06889462471008301
Test Loss Energy: 11.7592061406519, Test Loss Force: 10.06821989557494, time: 14.35980772972107


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.2087810734810902, Training Loss Force: 2.425134146461437, time: 0.9864156246185303
Validation Loss Energy: 1.4596119497314373, Validation Loss Force: 2.5776296120556603, time: 0.06352019309997559
Test Loss Energy: 12.220064761098794, Test Loss Force: 10.040112996488668, time: 14.50413727760315


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3655098254718243, Training Loss Force: 2.4229098725528857, time: 0.9598269462585449
Validation Loss Energy: 1.0998605521578335, Validation Loss Force: 2.5891335908108735, time: 0.0643770694732666
Test Loss Energy: 11.880070929745365, Test Loss Force: 10.042149838601997, time: 14.403593301773071


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.491266597504649, Training Loss Force: 2.4205060318830833, time: 0.9729361534118652
Validation Loss Energy: 1.349819805941385, Validation Loss Force: 2.580760562916551, time: 0.06544923782348633
Test Loss Energy: 12.025663120499265, Test Loss Force: 10.085559130310266, time: 14.519400835037231

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÖ‚ñÖ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÜ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÖ‚ñÜ
wandb:   test_error_force ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÉ
wandb:   test_error_total ‚ñÖ‚ñÑ‚ñà‚ñÖ‚ñá‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÅ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÑ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:  valid_error_total ‚ñÜ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÉ‚ñà‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÖ‚ñÑ
wandb: 
wandb: Run summary:
wandb:       dataset_size 894
wandb:                 lr 0.0001
wandb:  test_error_energy 12.02566
wandb:   test_error_force 10.08556
wandb:   test_error_total 5.66973
wandb: train_error_energy 1.49127
wandb:  train_error_force 2.42051
wandb:  train_error_total 1.09708
wandb: valid_error_energy 1.34982
wandb:  valid_error_force 2.58076
wandb:  valid_error_total 1.29471
wandb: 
wandb: üöÄ View run al_40_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fb34etf4
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_204217-fb34etf4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6129093170166016, Uncertainty Bias: 0.03665052354335785
Found uncertainty sample after 3225 steps.
Found uncertainty sample after 1515 steps.
Found uncertainty sample after 3415 steps.
Found uncertainty sample after 620 steps.
Found uncertainty sample after 978 steps.
Found uncertainty sample after 2446 steps.
Found uncertainty sample after 1213 steps.
Found uncertainty sample after 1497 steps.
Found uncertainty sample after 222 steps.
Found uncertainty sample after 984 steps.
Found uncertainty sample after 2723 steps.
Found uncertainty sample after 2858 steps.
Found uncertainty sample after 1252 steps.
Found uncertainty sample after 2910 steps.
Found uncertainty sample after 133 steps.
Found uncertainty sample after 2569 steps.
Found uncertainty sample after 2521 steps.
Found uncertainty sample after 3539 steps.
Found uncertainty sample after 1676 steps.
Found uncertainty sample after 995 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_212044-somlwcup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/somlwcup
Training model 4. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.828044645248622, Training Loss Force: 2.7884566522910204, time: 1.0103743076324463
Validation Loss Energy: 1.369807701825593, Validation Loss Force: 2.6626152996436274, time: 0.06624722480773926
Test Loss Energy: 11.19467295705339, Test Loss Force: 10.06525186741464, time: 14.476935148239136


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4254039107805103, Training Loss Force: 2.5336033687056143, time: 0.9746549129486084
Validation Loss Energy: 1.323234000594191, Validation Loss Force: 2.614413886955493, time: 0.06541824340820312
Test Loss Energy: 11.264157444612065, Test Loss Force: 9.969862848830743, time: 14.587385892868042


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2602557201463553, Training Loss Force: 2.4582274518396856, time: 0.9879715442657471
Validation Loss Energy: 1.195923473082843, Validation Loss Force: 2.5801415426908716, time: 0.06528258323669434
Test Loss Energy: 11.281280846493987, Test Loss Force: 9.935729827834665, time: 14.468660593032837


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4143051438014071, Training Loss Force: 2.4503101662611058, time: 1.0086555480957031
Validation Loss Energy: 1.0470091396952894, Validation Loss Force: 2.5771076755776057, time: 0.06466293334960938
Test Loss Energy: 11.439178937364726, Test Loss Force: 9.97623825585821, time: 14.638193845748901


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3105858959390375, Training Loss Force: 2.4653762985174215, time: 0.9936573505401611
Validation Loss Energy: 1.699730563279856, Validation Loss Force: 2.5886383746303303, time: 0.06583404541015625
Test Loss Energy: 12.31683126930975, Test Loss Force: 9.940208233635673, time: 14.485141515731812


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.421944616987895, Training Loss Force: 2.46665683038442, time: 0.9892337322235107
Validation Loss Energy: 1.1165023987861844, Validation Loss Force: 2.584001066997238, time: 0.06584453582763672
Test Loss Energy: 11.737708318294313, Test Loss Force: 10.0015299127925, time: 14.605801582336426


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3620820595187546, Training Loss Force: 2.4701262767383536, time: 0.9874532222747803
Validation Loss Energy: 1.1648780500810072, Validation Loss Force: 2.5886161077157372, time: 0.06603598594665527
Test Loss Energy: 11.744974798279888, Test Loss Force: 9.932098413495714, time: 14.785135746002197


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.42260524947, Training Loss Force: 2.462325915496125, time: 0.9808456897735596
Validation Loss Energy: 1.4668291020892488, Validation Loss Force: 2.585715396751736, time: 0.0650641918182373
Test Loss Energy: 11.12568300950717, Test Loss Force: 10.018088737637825, time: 14.624311685562134


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3535602636806512, Training Loss Force: 2.4707151137773895, time: 0.97206711769104
Validation Loss Energy: 1.2355827406603224, Validation Loss Force: 2.569419800645303, time: 0.06451296806335449
Test Loss Energy: 11.155529661102213, Test Loss Force: 10.021642346014476, time: 14.51103138923645


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2451595582683244, Training Loss Force: 2.4465890884157817, time: 0.9716918468475342
Validation Loss Energy: 1.277351019053457, Validation Loss Force: 2.5778480504878156, time: 0.06502199172973633
Test Loss Energy: 11.732366277969854, Test Loss Force: 9.955322819405668, time: 14.573043584823608


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.1683370885719295, Training Loss Force: 2.442158294898168, time: 0.9959471225738525
Validation Loss Energy: 1.1462890731060906, Validation Loss Force: 2.5745917368977675, time: 0.06670165061950684
Test Loss Energy: 11.6946852537974, Test Loss Force: 9.9602886631226, time: 14.474607229232788


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.255441169792666, Training Loss Force: 2.46373594098885, time: 1.0032947063446045
Validation Loss Energy: 1.2819906647125812, Validation Loss Force: 2.5759843097363997, time: 0.06712198257446289
Test Loss Energy: 11.790919958139462, Test Loss Force: 9.899593913026456, time: 14.628810405731201


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3582368340267674, Training Loss Force: 2.451587335056176, time: 0.9837701320648193
Validation Loss Energy: 1.1754381343266325, Validation Loss Force: 2.574130589096551, time: 0.06528067588806152
Test Loss Energy: 11.713115558021318, Test Loss Force: 9.964027951919201, time: 14.501083374023438


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3732371694700236, Training Loss Force: 2.447689688256378, time: 1.0010871887207031
Validation Loss Energy: 1.3108429079616013, Validation Loss Force: 2.5892941352650873, time: 0.06722807884216309
Test Loss Energy: 11.153868787098228, Test Loss Force: 9.974994829378296, time: 14.694075345993042


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.510275428603026, Training Loss Force: 2.4418930882671215, time: 0.982147216796875
Validation Loss Energy: 1.2427170600958488, Validation Loss Force: 2.5749150524976545, time: 0.06456398963928223
Test Loss Energy: 11.17265481635793, Test Loss Force: 9.934610820946007, time: 14.504047632217407


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.466024938227415, Training Loss Force: 2.4468830193666524, time: 1.0021395683288574
Validation Loss Energy: 1.2610081057535139, Validation Loss Force: 2.5710553055221426, time: 0.06562066078186035
Test Loss Energy: 11.746240827426826, Test Loss Force: 9.919766767696052, time: 14.62946105003357


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3380587211050894, Training Loss Force: 2.4596351661802407, time: 1.0100290775299072
Validation Loss Energy: 1.0925272778404207, Validation Loss Force: 2.5897530563748448, time: 0.06611394882202148
Test Loss Energy: 11.55194186178552, Test Loss Force: 9.946306309156403, time: 14.589998483657837


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9763978140239915, Training Loss Force: 2.469781876673821, time: 0.9830832481384277
Validation Loss Energy: 1.0411809974697754, Validation Loss Force: 2.5898000395646354, time: 0.06785202026367188
Test Loss Energy: 11.427828425449146, Test Loss Force: 9.992521255419504, time: 14.694414854049683


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6101615672462462, Training Loss Force: 2.47156905763027, time: 0.9845438003540039
Validation Loss Energy: 1.175325463738793, Validation Loss Force: 2.5807554415261946, time: 0.06568503379821777
Test Loss Energy: 11.192589748462197, Test Loss Force: 9.95187151292898, time: 14.55457854270935


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.2952177571361874, Training Loss Force: 2.428440800554518, time: 0.9726581573486328
Validation Loss Energy: 1.3573431283748472, Validation Loss Force: 2.5638488412833356, time: 0.06476783752441406
Test Loss Energy: 11.787247446770499, Test Loss Force: 9.861291793491784, time: 15.01869511604309

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÖ
wandb:   test_error_force ‚ñà‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÜ‚ñÉ‚ñÜ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñà‚ñÇ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb: valid_error_energy ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ
wandb:  valid_error_force ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÖ‚ñÖ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 912
wandb:                 lr 0.0001
wandb:  test_error_energy 11.78725
wandb:   test_error_force 9.86129
wandb:   test_error_total 5.52771
wandb: train_error_energy 1.29522
wandb:  train_error_force 2.42844
wandb:  train_error_total 1.10841
wandb: valid_error_energy 1.35734
wandb:  valid_error_force 2.56385
wandb:  valid_error_total 1.28568
wandb: 
wandb: üöÄ View run al_40_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/somlwcup
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_212044-somlwcup/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0682437419891357, Uncertainty Bias: -0.008312448859214783
Found uncertainty sample after 7 steps.
Found uncertainty sample after 192 steps.
Found uncertainty sample after 89 steps.
Found uncertainty sample after 1021 steps.
Found uncertainty sample after 2513 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 408 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 143 steps.
Found uncertainty sample after 659 steps.
Found uncertainty sample after 1356 steps.
Found uncertainty sample after 711 steps.
Found uncertainty sample after 3932 steps.
Found uncertainty sample after 3798 steps.
Found uncertainty sample after 1159 steps.
Found uncertainty sample after 1259 steps.
Found uncertainty sample after 122 steps.
Found uncertainty sample after 1277 steps.
Found uncertainty sample after 348 steps.
Found uncertainty sample after 78 steps.
Found uncertainty sample after 153 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 974 steps.
Found uncertainty sample after 356 steps.
Found uncertainty sample after 1268 steps.
Found uncertainty sample after 1999 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_214130-hr8c44jx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/hr8c44jx
Training model 5. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.194810057710317, Training Loss Force: 2.8194533368559354, time: 1.0248544216156006
Validation Loss Energy: 1.530398359887308, Validation Loss Force: 2.6766561479783957, time: 0.07402348518371582
Test Loss Energy: 11.752703576718234, Test Loss Force: 9.93871130008183, time: 14.325191020965576


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4824414805996555, Training Loss Force: 2.540848343189298, time: 1.039806842803955
Validation Loss Energy: 1.243302457280493, Validation Loss Force: 2.597849974528217, time: 0.06603050231933594
Test Loss Energy: 11.056419004040405, Test Loss Force: 9.865169995192845, time: 14.435875415802002


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5628558244334354, Training Loss Force: 2.5177586735246202, time: 1.0269231796264648
Validation Loss Energy: 1.5648487281340986, Validation Loss Force: 2.5847332031490486, time: 0.06580519676208496
Test Loss Energy: 10.94299972558907, Test Loss Force: 9.942402510995823, time: 14.311805009841919


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4873454215459627, Training Loss Force: 2.4919856476715867, time: 1.0337140560150146
Validation Loss Energy: 1.4035062277011585, Validation Loss Force: 2.5914589247017976, time: 0.06559610366821289
Test Loss Energy: 10.904108603028558, Test Loss Force: 9.854690536996765, time: 14.49569845199585


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.471825513820707, Training Loss Force: 2.4947415643122963, time: 1.0130724906921387
Validation Loss Energy: 1.098347515311254, Validation Loss Force: 2.5984607559954966, time: 0.07114624977111816
Test Loss Energy: 11.47936790161487, Test Loss Force: 9.830886515139314, time: 14.356184720993042


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.2489833632444145, Training Loss Force: 2.4596871169395182, time: 1.050940752029419
Validation Loss Energy: 1.1323927370470293, Validation Loss Force: 2.5924328795460854, time: 0.06713318824768066
Test Loss Energy: 11.553347396066897, Test Loss Force: 9.882531389588516, time: 14.787450790405273


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.234059592778942, Training Loss Force: 2.476396521386744, time: 1.029198408126831
Validation Loss Energy: 1.1834710351005504, Validation Loss Force: 2.6008936390839037, time: 0.06684565544128418
Test Loss Energy: 11.215675912972545, Test Loss Force: 9.828988273494158, time: 14.351962566375732


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7306901139255653, Training Loss Force: 2.479985866373746, time: 1.0506019592285156
Validation Loss Energy: 1.347096896290407, Validation Loss Force: 2.5817521086233675, time: 0.07059454917907715
Test Loss Energy: 11.744739170022832, Test Loss Force: 9.812404775508496, time: 14.402880907058716


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.405033422594266, Training Loss Force: 2.4790834551260446, time: 1.0514106750488281
Validation Loss Energy: 1.4695232874204018, Validation Loss Force: 2.5848267241903384, time: 0.06486153602600098
Test Loss Energy: 11.910418514638703, Test Loss Force: 9.831627618678928, time: 14.368121147155762


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3312001154689403, Training Loss Force: 2.481193690622002, time: 1.0464468002319336
Validation Loss Energy: 1.14905072718846, Validation Loss Force: 2.59920313492802, time: 0.06910181045532227
Test Loss Energy: 11.24227450955466, Test Loss Force: 9.804263086867108, time: 14.585049867630005


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3146714682676501, Training Loss Force: 2.492553899331995, time: 1.0240793228149414
Validation Loss Energy: 1.3894012506523628, Validation Loss Force: 2.6115601591812827, time: 0.06799507141113281
Test Loss Energy: 10.988700462343221, Test Loss Force: 9.907350969280527, time: 14.399280548095703


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.458529204309177, Training Loss Force: 2.493472446670471, time: 1.044797420501709
Validation Loss Energy: 1.4429078670767994, Validation Loss Force: 2.596868226263821, time: 0.06684231758117676
Test Loss Energy: 10.971687718866177, Test Loss Force: 9.881789866358368, time: 14.492176532745361


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.661544064689491, Training Loss Force: 2.5034233675112763, time: 1.035327434539795
Validation Loss Energy: 1.2217366164936678, Validation Loss Force: 2.582625862351988, time: 0.06563878059387207
Test Loss Energy: 11.131471400044006, Test Loss Force: 9.801422532712525, time: 14.32240891456604


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4663795293724675, Training Loss Force: 2.490790738233795, time: 1.034611463546753
Validation Loss Energy: 1.2097917528295175, Validation Loss Force: 2.580371559918615, time: 0.06557369232177734
Test Loss Energy: 11.119391354057942, Test Loss Force: 9.837832286269554, time: 14.614223957061768


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2329587072435935, Training Loss Force: 2.4663943346862407, time: 1.0265815258026123
Validation Loss Energy: 1.151687463879964, Validation Loss Force: 2.5854833755016795, time: 0.07185888290405273
Test Loss Energy: 11.461950385267967, Test Loss Force: 9.779123782260916, time: 14.418057680130005


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.2663139533747634, Training Loss Force: 2.515878640814028, time: 1.0400547981262207
Validation Loss Energy: 1.1028764944048524, Validation Loss Force: 2.583967221287057, time: 0.06765508651733398
Test Loss Energy: 11.515237159045661, Test Loss Force: 9.861125064431187, time: 14.563815116882324


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.1524832796963576, Training Loss Force: 2.4664506402909407, time: 1.0560286045074463
Validation Loss Energy: 1.1083246517328404, Validation Loss Force: 2.6000443789613352, time: 0.06811022758483887
Test Loss Energy: 11.255568706274076, Test Loss Force: 9.80970294306602, time: 14.42077922821045


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.1426264439920109, Training Loss Force: 2.4898225134088623, time: 1.0291731357574463
Validation Loss Energy: 1.1684996524049496, Validation Loss Force: 2.5814463838860084, time: 0.06834864616394043
Test Loss Energy: 11.165176481252594, Test Loss Force: 9.870452113035105, time: 14.551069736480713


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3410140205619518, Training Loss Force: 2.487385080447573, time: 1.03413724899292
Validation Loss Energy: 1.3070099926181733, Validation Loss Force: 2.577097210127747, time: 0.06608986854553223
Test Loss Energy: 11.025075409565067, Test Loss Force: 9.882767404893517, time: 14.666231870651245


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.447416330919753, Training Loss Force: 2.477983335943674, time: 1.0180258750915527
Validation Loss Energy: 1.7580123195387143, Validation Loss Force: 2.5863531211856734, time: 0.06594729423522949
Test Loss Energy: 10.86428289492772, Test Loss Force: 9.822875117093469, time: 14.485852241516113

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñá‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:   test_error_force ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ
wandb:   test_error_total ‚ñà‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÜ‚ñÉ‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñà
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:       dataset_size 936
wandb:                 lr 0.0001
wandb:  test_error_energy 10.86428
wandb:   test_error_force 9.82288
wandb:   test_error_total 5.4389
wandb: train_error_energy 1.44742
wandb:  train_error_force 2.47798
wandb:  train_error_total 1.11329
wandb: valid_error_energy 1.75801
wandb:  valid_error_force 2.58635
wandb:  valid_error_total 1.2999
wandb: 
wandb: üöÄ View run al_40_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/hr8c44jx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_214130-hr8c44jx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6006492376327515, Uncertainty Bias: 0.04088485240936279
Found uncertainty sample after 1605 steps.
Found uncertainty sample after 378 steps.
Found uncertainty sample after 2047 steps.
Found uncertainty sample after 2681 steps.
Found uncertainty sample after 2366 steps.
Found uncertainty sample after 2079 steps.
Found uncertainty sample after 1168 steps.
Found uncertainty sample after 1228 steps.
Found uncertainty sample after 217 steps.
Found uncertainty sample after 964 steps.
Found uncertainty sample after 170 steps.
Found uncertainty sample after 3424 steps.
Found uncertainty sample after 3281 steps.
Found uncertainty sample after 2320 steps.
Found uncertainty sample after 3411 steps.
Found uncertainty sample after 331 steps.
Found uncertainty sample after 306 steps.
Found uncertainty sample after 2213 steps.
Found uncertainty sample after 413 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_221856-qjfjky1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qjfjky1b
Training model 6. Added 19 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 7.216025967381023, Training Loss Force: 3.1427016461271844, time: 1.0179574489593506
Validation Loss Energy: 1.6744320082652706, Validation Loss Force: 2.8624824570209717, time: 0.07050800323486328
Test Loss Energy: 10.711649919769272, Test Loss Force: 9.753083010360983, time: 14.668513059616089


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6614084276348255, Training Loss Force: 2.6626712489776945, time: 1.0172784328460693
Validation Loss Energy: 1.953481538614839, Validation Loss Force: 2.6052074084479626, time: 0.06823110580444336
Test Loss Energy: 11.95648751584924, Test Loss Force: 9.739916968478601, time: 14.871222734451294


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5324557912508852, Training Loss Force: 2.5320257759785663, time: 1.0301117897033691
Validation Loss Energy: 1.0467344773037874, Validation Loss Force: 2.5898857671858178, time: 0.06647896766662598
Test Loss Energy: 11.083518883662927, Test Loss Force: 9.748390389846755, time: 14.680492162704468


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.1458310556619506, Training Loss Force: 2.5181692383181873, time: 1.0473835468292236
Validation Loss Energy: 1.0648154346222698, Validation Loss Force: 2.5799380230914934, time: 0.06715822219848633
Test Loss Energy: 11.008352765513532, Test Loss Force: 9.705854651348291, time: 14.678216457366943


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.2787857171833463, Training Loss Force: 2.519524076158889, time: 1.0316061973571777
Validation Loss Energy: 1.0565333670740586, Validation Loss Force: 2.591287246790287, time: 0.07201933860778809
Test Loss Energy: 11.13505769765025, Test Loss Force: 9.692153699887037, time: 14.98083209991455


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3611164017875386, Training Loss Force: 2.5242934711293454, time: 1.0295865535736084
Validation Loss Energy: 1.0876827765670427, Validation Loss Force: 2.601779862284696, time: 0.06827712059020996
Test Loss Energy: 11.04218616943537, Test Loss Force: 9.732985014493476, time: 14.81550645828247


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.296429886705177, Training Loss Force: 2.5316817001919736, time: 1.021972417831421
Validation Loss Energy: 1.0503539642708435, Validation Loss Force: 2.601414462216229, time: 0.06840252876281738
Test Loss Energy: 11.120217057883325, Test Loss Force: 9.737763466385717, time: 14.731419324874878


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.671561344646936, Training Loss Force: 2.531043463619001, time: 1.0603761672973633
Validation Loss Energy: 1.071755809231693, Validation Loss Force: 2.578517839278766, time: 0.06774234771728516
Test Loss Energy: 11.185698700314727, Test Loss Force: 9.737720158985542, time: 14.843498706817627


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3368091122877606, Training Loss Force: 2.519005078913561, time: 1.059366226196289
Validation Loss Energy: 1.461222292994787, Validation Loss Force: 2.5921371749202935, time: 0.0659327507019043
Test Loss Energy: 11.413583573705077, Test Loss Force: 9.719997345752471, time: 14.671675205230713


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4307574612351954, Training Loss Force: 2.527746408997553, time: 1.041264295578003
Validation Loss Energy: 1.067836052921353, Validation Loss Force: 2.5962915131758684, time: 0.06605076789855957
Test Loss Energy: 11.142642410316983, Test Loss Force: 9.741872012906303, time: 14.83612871170044


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4589323931872853, Training Loss Force: 2.519032556286169, time: 1.0045063495635986
Validation Loss Energy: 1.1331923419500558, Validation Loss Force: 2.585256252972833, time: 0.06790375709533691
Test Loss Energy: 11.444475016912182, Test Loss Force: 9.715787882310691, time: 14.603808641433716


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4543539796877147, Training Loss Force: 2.5155919542886465, time: 1.017430067062378
Validation Loss Energy: 1.8367435648212884, Validation Loss Force: 2.588259169074815, time: 0.07471156120300293
Test Loss Energy: 11.981228762634162, Test Loss Force: 9.75676014765231, time: 14.877184867858887


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.423213102134172, Training Loss Force: 2.5362150732900517, time: 1.064906120300293
Validation Loss Energy: 1.0677709221961693, Validation Loss Force: 2.5875858175775295, time: 0.06818437576293945
Test Loss Energy: 11.341547885300821, Test Loss Force: 9.678114379925306, time: 14.623921632766724


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4755251616802976, Training Loss Force: 2.5196630439728627, time: 1.0642306804656982
Validation Loss Energy: 1.0951281647994302, Validation Loss Force: 2.6058237566438907, time: 0.07087278366088867
Test Loss Energy: 10.95127499240187, Test Loss Force: 9.723650061717782, time: 14.790463209152222


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.26437738496802, Training Loss Force: 2.5265837940082254, time: 1.0549561977386475
Validation Loss Energy: 1.0496621312344458, Validation Loss Force: 2.582191657517429, time: 0.0658254623413086
Test Loss Energy: 11.065039904663198, Test Loss Force: 9.627347395488126, time: 14.687875509262085


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.331560423836271, Training Loss Force: 2.507825952175342, time: 1.050844669342041
Validation Loss Energy: 1.6341717566629321, Validation Loss Force: 2.597091118078895, time: 0.06643962860107422
Test Loss Energy: 10.688747575050822, Test Loss Force: 9.725427791556902, time: 14.738033294677734


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.2992474010539543, Training Loss Force: 2.537258248549504, time: 1.0295205116271973
Validation Loss Energy: 1.0535648533551223, Validation Loss Force: 2.582934259119098, time: 0.06787681579589844
Test Loss Energy: 10.982462853708675, Test Loss Force: 9.679993241194117, time: 14.696841478347778


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.38413144759911, Training Loss Force: 2.5070870246145804, time: 1.0498461723327637
Validation Loss Energy: 1.2159486660489938, Validation Loss Force: 2.5660570512035012, time: 0.06875252723693848
Test Loss Energy: 11.40302798364562, Test Loss Force: 9.664272594309576, time: 15.118210554122925


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.451088393783315, Training Loss Force: 2.5229880361498194, time: 1.0472514629364014
Validation Loss Energy: 1.1563243261747642, Validation Loss Force: 2.5842272988495005, time: 0.06729722023010254
Test Loss Energy: 11.403133088145722, Test Loss Force: 9.637357756244736, time: 14.572329759597778


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3962550385088157, Training Loss Force: 2.5082262964551103, time: 1.2536160945892334
Validation Loss Energy: 1.2704852386079195, Validation Loss Force: 2.590753063509206, time: 0.06853747367858887
Test Loss Energy: 11.35867018666089, Test Loss Force: 9.588402132848362, time: 14.665408372879028

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÅ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÖ‚ñÖ‚ñÖ
wandb:   test_error_force ‚ñà‚ñá‚ñà‚ñÜ‚ñÖ‚ñá‚ñá‚ñá‚ñÜ‚ñá‚ñÜ‚ñà‚ñÖ‚ñá‚ñÉ‚ñá‚ñÖ‚ñÑ‚ñÉ‚ñÅ
wandb:   test_error_total ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÉ‚ñÑ‚ñÖ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÜ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÉ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 953
wandb:                 lr 0.0001
wandb:  test_error_energy 11.35867
wandb:   test_error_force 9.5884
wandb:   test_error_total 5.36738
wandb: train_error_energy 1.39626
wandb:  train_error_force 2.50823
wandb:  train_error_total 1.12305
wandb: valid_error_energy 1.27049
wandb:  valid_error_force 2.59075
wandb:  valid_error_total 1.26481
wandb: 
wandb: üöÄ View run al_40_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qjfjky1b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_221856-qjfjky1b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.073553204536438, Uncertainty Bias: -0.008161410689353943
Found uncertainty sample after 10 steps.
Found uncertainty sample after 1470 steps.
Found uncertainty sample after 1060 steps.
Found uncertainty sample after 1790 steps.
Found uncertainty sample after 55 steps.
Found uncertainty sample after 140 steps.
Found uncertainty sample after 203 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 417 steps.
Found uncertainty sample after 309 steps.
Found uncertainty sample after 523 steps.
Found uncertainty sample after 32 steps.
Found uncertainty sample after 968 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 598 steps.
Found uncertainty sample after 1280 steps.
Found uncertainty sample after 1405 steps.
Found uncertainty sample after 3478 steps.
Found uncertainty sample after 1302 steps.
Found uncertainty sample after 363 steps.
Found uncertainty sample after 3810 steps.
Found uncertainty sample after 3048 steps.
Found uncertainty sample after 811 steps.
Found uncertainty sample after 1756 steps.
Found uncertainty sample after 25 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 2817 steps.
Found uncertainty sample after 663 steps.
Found uncertainty sample after 703 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_223832-ihasjv1d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_7
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ihasjv1d
Training model 7. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.702461806773629, Training Loss Force: 2.9776103066288804, time: 1.0508313179016113
Validation Loss Energy: 1.2307906779708104, Validation Loss Force: 2.723124304034628, time: 0.06920981407165527
Test Loss Energy: 10.789870373106252, Test Loss Force: 9.761260759745943, time: 14.421274900436401


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3070256028027338, Training Loss Force: 2.6324758599335665, time: 1.060779333114624
Validation Loss Energy: 1.2460534232438578, Validation Loss Force: 2.589881091133753, time: 0.06794881820678711
Test Loss Energy: 10.831336562914204, Test Loss Force: 9.605577096044346, time: 14.521963357925415


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3888027519024873, Training Loss Force: 2.555259213773031, time: 1.0361404418945312
Validation Loss Energy: 2.2073261463256846, Validation Loss Force: 2.6043274199832562, time: 0.06689786911010742
Test Loss Energy: 12.145446931329936, Test Loss Force: 9.573983151500563, time: 14.358482360839844


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4494777381845882, Training Loss Force: 2.5350414658672196, time: 1.0872890949249268
Validation Loss Energy: 1.1650782296431963, Validation Loss Force: 2.581515411321246, time: 0.06834745407104492
Test Loss Energy: 11.31659201343859, Test Loss Force: 9.60751668187061, time: 14.865665674209595


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3810703898296908, Training Loss Force: 2.5454121951442983, time: 1.0680971145629883
Validation Loss Energy: 1.2767637291810723, Validation Loss Force: 2.593850836667354, time: 0.06924080848693848
Test Loss Energy: 11.467345772922888, Test Loss Force: 9.61579645802507, time: 14.390962362289429


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4111220260674997, Training Loss Force: 2.53627244555179, time: 1.0621521472930908
Validation Loss Energy: 1.7659828729517724, Validation Loss Force: 2.5712033805041843, time: 0.0692901611328125
Test Loss Energy: 11.700569646212921, Test Loss Force: 9.57746156065947, time: 14.516433000564575


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.821997842939334, Training Loss Force: 2.5360127486817565, time: 1.0605323314666748
Validation Loss Energy: 1.9562949632736366, Validation Loss Force: 2.6031668683946805, time: 0.06861090660095215
Test Loss Energy: 10.614364011876395, Test Loss Force: 9.606283346616491, time: 14.395621061325073


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6597950045938152, Training Loss Force: 2.550510449458088, time: 1.0566561222076416
Validation Loss Energy: 1.1204892898440215, Validation Loss Force: 2.5766670133378144, time: 0.06659269332885742
Test Loss Energy: 10.99218841713023, Test Loss Force: 9.592277340756928, time: 14.527849674224854


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.526992283339434, Training Loss Force: 2.54733898717839, time: 1.0960156917572021
Validation Loss Energy: 1.1864461175592915, Validation Loss Force: 2.5790045940317645, time: 0.06719970703125
Test Loss Energy: 10.773952154569884, Test Loss Force: 9.626451985727805, time: 14.407202243804932


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6070366768128637, Training Loss Force: 2.545444740753982, time: 1.053699016571045
Validation Loss Energy: 1.0924393235277792, Validation Loss Force: 2.581796642452553, time: 0.0696263313293457
Test Loss Energy: 11.137815395566403, Test Loss Force: 9.52359740462058, time: 14.49398136138916


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.711512059619652, Training Loss Force: 2.55433477049077, time: 1.0401153564453125
Validation Loss Energy: 1.0941960717545764, Validation Loss Force: 2.583251562652045, time: 0.07422733306884766
Test Loss Energy: 10.731302320867375, Test Loss Force: 9.583121670452108, time: 14.416780471801758


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3679960189656328, Training Loss Force: 2.5376696369794813, time: 1.0881493091583252
Validation Loss Energy: 1.916920600868372, Validation Loss Force: 2.608027290511992, time: 0.06903386116027832
Test Loss Energy: 11.771718057526817, Test Loss Force: 9.595346393092672, time: 14.854091882705688


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1443465343832315, Training Loss Force: 2.5611027776326187, time: 1.0588493347167969
Validation Loss Energy: 1.4484108010146857, Validation Loss Force: 2.5955938907416765, time: 0.07144808769226074
Test Loss Energy: 11.481918361007168, Test Loss Force: 9.58431706101847, time: 14.404643535614014


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6649497109232543, Training Loss Force: 2.5457424494020877, time: 1.0567233562469482
Validation Loss Energy: 1.5118825297268288, Validation Loss Force: 2.605262630396153, time: 0.07070469856262207
Test Loss Energy: 10.66563780527939, Test Loss Force: 9.566831391591615, time: 14.558533430099487


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4383443365554849, Training Loss Force: 2.5478105645150864, time: 1.103095293045044
Validation Loss Energy: 1.214174549628814, Validation Loss Force: 2.6220216009952617, time: 0.06925082206726074
Test Loss Energy: 10.711051772152954, Test Loss Force: 9.587683524721522, time: 14.419770002365112


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6845623464464123, Training Loss Force: 2.567303574631032, time: 1.0798254013061523
Validation Loss Energy: 1.2504670597198655, Validation Loss Force: 2.6024385176183507, time: 0.06941056251525879
Test Loss Energy: 11.122983154273445, Test Loss Force: 9.522613230311718, time: 14.58613133430481


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8148169299850225, Training Loss Force: 2.5395341175670905, time: 1.0561556816101074
Validation Loss Energy: 1.3260377391451406, Validation Loss Force: 2.5945604832354254, time: 0.06934046745300293
Test Loss Energy: 10.632911251210329, Test Loss Force: 9.594055620856974, time: 14.46079397201538


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7397196254110816, Training Loss Force: 2.5661582435560124, time: 1.065192461013794
Validation Loss Energy: 1.1602184755333222, Validation Loss Force: 2.577330790061825, time: 0.06788277626037598
Test Loss Energy: 10.76762002696322, Test Loss Force: 9.55599847468865, time: 14.66768217086792


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.558737072418532, Training Loss Force: 2.5412393107037308, time: 1.0756199359893799
Validation Loss Energy: 1.3162210358431952, Validation Loss Force: 2.574146621275058, time: 0.0667426586151123
Test Loss Energy: 10.71758338799823, Test Loss Force: 9.560663255730603, time: 14.478059768676758


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4530115621763429, Training Loss Force: 2.5313701400864166, time: 1.0666234493255615
Validation Loss Energy: 1.0772059705819945, Validation Loss Force: 2.5813942793058615, time: 0.06823348999023438
Test Loss Energy: 10.905448912737283, Test Loss Force: 9.563224431221277, time: 14.566314935684204

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:   test_error_force ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:   test_error_total ‚ñà‚ñÉ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñá‚ñá‚ñÅ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñÉ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ
wandb: valid_error_energy ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:  valid_error_total ‚ñá‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÑ‚ñÖ‚ñÉ‚ñÜ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 980
wandb:                 lr 0.0001
wandb:  test_error_energy 10.90545
wandb:   test_error_force 9.56322
wandb:   test_error_total 5.30337
wandb: train_error_energy 1.45301
wandb:  train_error_force 2.53137
wandb:  train_error_total 1.14659
wandb: valid_error_energy 1.07721
wandb:  valid_error_force 2.58139
wandb:  valid_error_total 1.26113
wandb: 
wandb: üöÄ View run al_40_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ihasjv1d
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_223832-ihasjv1d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.596850574016571, Uncertainty Bias: 0.03986583650112152
Found uncertainty sample after 1614 steps.
Found uncertainty sample after 2213 steps.
Found uncertainty sample after 1023 steps.
Found uncertainty sample after 1671 steps.
Found uncertainty sample after 2344 steps.
Found uncertainty sample after 1170 steps.
Found uncertainty sample after 217 steps.
Found uncertainty sample after 3204 steps.
Found uncertainty sample after 589 steps.
Found uncertainty sample after 1267 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_232447-lzbs3u4u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_8
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/lzbs3u4u
Training model 8. Added 10 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.0386335133069835, Training Loss Force: 2.989784814011239, time: 1.0780043601989746
Validation Loss Energy: 1.1060369489275785, Validation Loss Force: 2.660318244734236, time: 0.0701899528503418
Test Loss Energy: 10.872765526171547, Test Loss Force: 9.652678955666012, time: 14.882914066314697


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2886165837992625, Training Loss Force: 2.6064869443720955, time: 1.0634565353393555
Validation Loss Energy: 1.0822547707967611, Validation Loss Force: 2.5873337561043392, time: 0.06942439079284668
Test Loss Energy: 10.875702735056759, Test Loss Force: 9.529342865478723, time: 14.754661560058594


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4471490983751343, Training Loss Force: 2.5613707491754294, time: 1.0785365104675293
Validation Loss Energy: 1.5885409479299613, Validation Loss Force: 2.591093079295038, time: 0.06770110130310059
Test Loss Energy: 11.427169501979872, Test Loss Force: 9.496419611781507, time: 14.548169374465942


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.28528407965121, Training Loss Force: 2.5522418313594386, time: 1.0853447914123535
Validation Loss Energy: 1.1442071165916659, Validation Loss Force: 2.5829542993422314, time: 0.0668022632598877
Test Loss Energy: 10.822903986761743, Test Loss Force: 9.483935907437123, time: 14.797980546951294


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3545099023235323, Training Loss Force: 2.5450830829637416, time: 1.0531773567199707
Validation Loss Energy: 1.064515610617278, Validation Loss Force: 2.572826415908852, time: 0.06854081153869629
Test Loss Energy: 10.828276906983259, Test Loss Force: 9.53731665458924, time: 14.611679792404175


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4253878815742285, Training Loss Force: 2.5396848286645053, time: 1.0670011043548584
Validation Loss Energy: 1.7179957793165936, Validation Loss Force: 2.5828463048064565, time: 0.07041549682617188
Test Loss Energy: 10.54173810800697, Test Loss Force: 9.540694268070888, time: 14.770068168640137


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3612596308425062, Training Loss Force: 2.5508648309952697, time: 1.0755834579467773
Validation Loss Energy: 1.1386085462556035, Validation Loss Force: 2.5776904007324988, time: 0.07006669044494629
Test Loss Energy: 10.953537525432994, Test Loss Force: 9.48040727997387, time: 14.633904457092285


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3685745331596613, Training Loss Force: 2.544203819969478, time: 1.0666074752807617
Validation Loss Energy: 1.0771285930537846, Validation Loss Force: 2.5723289730368495, time: 0.06881356239318848
Test Loss Energy: 10.921322989155634, Test Loss Force: 9.478208320732618, time: 14.814767837524414


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4132020108825516, Training Loss Force: 2.541596313990534, time: 1.0811197757720947
Validation Loss Energy: 1.382387951897648, Validation Loss Force: 2.573104529672116, time: 0.06891536712646484
Test Loss Energy: 10.628266326193991, Test Loss Force: 9.473778822868836, time: 14.597615242004395


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3140875457872392, Training Loss Force: 2.543580181154739, time: 1.0783588886260986
Validation Loss Energy: 1.1174117795781535, Validation Loss Force: 2.586902223299531, time: 0.0674588680267334
Test Loss Energy: 10.810516284296048, Test Loss Force: 9.423126302030733, time: 14.78186583518982


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3859300757022457, Training Loss Force: 2.5637966720573075, time: 1.0636513233184814
Validation Loss Energy: 1.98605335861201, Validation Loss Force: 2.57537954033606, time: 0.06916975975036621
Test Loss Energy: 11.708343723249875, Test Loss Force: 9.430284972843854, time: 14.544817686080933


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.51297911421608, Training Loss Force: 2.5613003498109377, time: 1.0648455619812012
Validation Loss Energy: 1.0761698910459925, Validation Loss Force: 2.5732624020965784, time: 0.07052946090698242
Test Loss Energy: 11.080407312012577, Test Loss Force: 9.43329185035818, time: 14.74628758430481


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5042768825595356, Training Loss Force: 2.5581657644149556, time: 1.0596916675567627
Validation Loss Energy: 1.6750449050894367, Validation Loss Force: 2.5694823706753085, time: 0.0696871280670166
Test Loss Energy: 11.6148804360413, Test Loss Force: 9.50479544577339, time: 14.576496124267578


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6542431822083654, Training Loss Force: 2.5520988705848775, time: 1.0676934719085693
Validation Loss Energy: 1.1474777923416262, Validation Loss Force: 2.587005541783242, time: 0.06852149963378906
Test Loss Energy: 11.0256027693775, Test Loss Force: 9.435008902272132, time: 15.146761417388916


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.568261306980177, Training Loss Force: 2.565594165146371, time: 1.0690531730651855
Validation Loss Energy: 1.0622409339570527, Validation Loss Force: 2.5769237508630694, time: 0.06681203842163086
Test Loss Energy: 10.823056203856225, Test Loss Force: 9.43820032237873, time: 14.629944086074829


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4514350933546767, Training Loss Force: 2.5580702968143587, time: 1.0630428791046143
Validation Loss Energy: 1.5183252387951034, Validation Loss Force: 2.5872985743792825, time: 0.0673377513885498
Test Loss Energy: 11.422274068345333, Test Loss Force: 9.414677250693085, time: 14.755845785140991


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5565866828518318, Training Loss Force: 2.5580832188076967, time: 1.0475013256072998
Validation Loss Energy: 1.1005277802536062, Validation Loss Force: 2.5852021443703723, time: 0.0707697868347168
Test Loss Energy: 10.870899717278432, Test Loss Force: 9.458840031475034, time: 14.63931918144226


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4242678934803086, Training Loss Force: 2.5493844905987637, time: 1.0533456802368164
Validation Loss Energy: 1.4448321738359073, Validation Loss Force: 2.5713136017314184, time: 0.07032036781311035
Test Loss Energy: 10.557999195059011, Test Loss Force: 9.430234605316205, time: 14.77387523651123


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.951734871554052, Training Loss Force: 2.563573270258061, time: 1.089977502822876
Validation Loss Energy: 1.293501880215037, Validation Loss Force: 2.6265371086055316, time: 0.06961321830749512
Test Loss Energy: 10.543787237726571, Test Loss Force: 9.511844861813316, time: 14.651623725891113


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6020465157993895, Training Loss Force: 2.583421128798107, time: 1.291029453277588
Validation Loss Energy: 2.0058012171569075, Validation Loss Force: 2.5854165747579008, time: 0.06783270835876465
Test Loss Energy: 11.647939939939683, Test Loss Force: 9.411404508550135, time: 14.658791303634644

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÉ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñÅ‚ñà
wandb:   test_error_force ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÖ‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÉ‚ñÉ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: valid_error_energy ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÅ‚ñÜ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñà
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÜ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÜ‚ñÖ
wandb: 
wandb: Run summary:
wandb:       dataset_size 989
wandb:                 lr 0.0001
wandb:  test_error_energy 11.64794
wandb:   test_error_force 9.4114
wandb:   test_error_total 5.25553
wandb: train_error_energy 1.60205
wandb:  train_error_force 2.58342
wandb:  train_error_total 1.19219
wandb: valid_error_energy 2.0058
wandb:  valid_error_force 2.58542
wandb:  valid_error_total 1.30563
wandb: 
wandb: üöÄ View run al_40_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/lzbs3u4u
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_232447-lzbs3u4u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0771586894989014, Uncertainty Bias: -0.005984455347061157
Found uncertainty sample after 1742 steps.
Found uncertainty sample after 1532 steps.
Found uncertainty sample after 37 steps.
Found uncertainty sample after 863 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 548 steps.
Found uncertainty sample after 1020 steps.
Found uncertainty sample after 722 steps.
Found uncertainty sample after 2588 steps.
Found uncertainty sample after 188 steps.
Found uncertainty sample after 1919 steps.
Found uncertainty sample after 116 steps.
Found uncertainty sample after 1133 steps.
Found uncertainty sample after 708 steps.
Found uncertainty sample after 658 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 204 steps.
Found uncertainty sample after 710 steps.
Found uncertainty sample after 796 steps.
Found uncertainty sample after 1567 steps.
Found uncertainty sample after 3816 steps.
Found uncertainty sample after 815 steps.
Found uncertainty sample after 2923 steps.
Found uncertainty sample after 32 steps.
Found uncertainty sample after 2081 steps.
Found uncertainty sample after 119 steps.
Found uncertainty sample after 491 steps.
Found uncertainty sample after 8 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_234529-6oi1ct6t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_9
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6oi1ct6t
Training model 9. Added 28 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.652500933676283, Training Loss Force: 3.0982557448123074, time: 1.0735595226287842
Validation Loss Energy: 1.3778314731645278, Validation Loss Force: 2.6435485860161227, time: 0.07416749000549316
Test Loss Energy: 10.52939493470723, Test Loss Force: 9.50253148579444, time: 14.452400922775269


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6487716628578253, Training Loss Force: 2.6338783503033216, time: 1.071418285369873
Validation Loss Energy: 1.4026761171251396, Validation Loss Force: 2.5855604190261703, time: 0.06875205039978027
Test Loss Energy: 10.547114842749142, Test Loss Force: 9.4109100384861, time: 14.564852952957153


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4319113199923068, Training Loss Force: 2.5749951368476696, time: 1.1201105117797852
Validation Loss Energy: 1.0757482670181782, Validation Loss Force: 2.577569268717114, time: 0.06803464889526367
Test Loss Energy: 10.823682727216054, Test Loss Force: 9.402063400313232, time: 14.366292953491211


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3364062687787763, Training Loss Force: 2.5663451154942236, time: 1.1037707328796387
Validation Loss Energy: 1.5931694601317892, Validation Loss Force: 2.58268152963847, time: 0.06849241256713867
Test Loss Energy: 10.469597133236705, Test Loss Force: 9.425202725624914, time: 14.538992404937744


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4201086932035287, Training Loss Force: 2.57921118229031, time: 1.132753849029541
Validation Loss Energy: 1.3566251317138032, Validation Loss Force: 2.5847091548812884, time: 0.06976485252380371
Test Loss Energy: 11.318316330662057, Test Loss Force: 9.406069630944168, time: 14.390535593032837


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4200844622774849, Training Loss Force: 2.5850134461860206, time: 1.1020965576171875
Validation Loss Energy: 1.8064689110680816, Validation Loss Force: 2.5933854581523645, time: 0.07023143768310547
Test Loss Energy: 10.427494123661083, Test Loss Force: 9.421310473617325, time: 14.56798768043518


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7587371006502983, Training Loss Force: 2.5857803535166495, time: 1.105001449584961
Validation Loss Energy: 1.2571364459786945, Validation Loss Force: 2.6102831516293867, time: 0.07229495048522949
Test Loss Energy: 11.107915583170033, Test Loss Force: 9.393726700132294, time: 14.730658531188965


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3529859246105107, Training Loss Force: 2.5807681615011555, time: 1.107306718826294
Validation Loss Energy: 1.1497965574927451, Validation Loss Force: 2.5831638310085494, time: 0.0730443000793457
Test Loss Energy: 10.725610981435567, Test Loss Force: 9.37796040490703, time: 14.530533790588379


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4636481776615216, Training Loss Force: 2.575267405545853, time: 1.1042413711547852
Validation Loss Energy: 1.8074094655404807, Validation Loss Force: 2.5946589029979257, time: 0.06802988052368164
Test Loss Energy: 10.431339664111924, Test Loss Force: 9.46437707401259, time: 14.37276291847229


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.480656729060367, Training Loss Force: 2.5777565960945363, time: 1.0782454013824463
Validation Loss Energy: 1.148363013531262, Validation Loss Force: 2.575543202158317, time: 0.06964731216430664
Test Loss Energy: 10.905627509713616, Test Loss Force: 9.425893111894766, time: 14.541083335876465


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6925661104463159, Training Loss Force: 2.5867063718688663, time: 1.1090724468231201
Validation Loss Energy: 1.1937148178243853, Validation Loss Force: 2.5977729310037256, time: 0.0707547664642334
Test Loss Energy: 10.899558350870874, Test Loss Force: 9.435317477407718, time: 14.488059282302856


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6029250320551638, Training Loss Force: 2.5785962396933653, time: 1.0774412155151367
Validation Loss Energy: 1.2718829328369081, Validation Loss Force: 2.5787351643651917, time: 0.0733633041381836
Test Loss Energy: 10.89922751348392, Test Loss Force: 9.377416504624215, time: 14.627623081207275


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4514852547986052, Training Loss Force: 2.570980586106862, time: 1.0873186588287354
Validation Loss Energy: 1.5710566325879924, Validation Loss Force: 2.577756756137985, time: 0.06928157806396484
Test Loss Energy: 11.462756755349286, Test Loss Force: 9.368302248448924, time: 14.456764221191406


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.217543093687218, Training Loss Force: 2.570063460603661, time: 1.1258621215820312
Validation Loss Energy: 1.2332926998290281, Validation Loss Force: 2.600090248805396, time: 0.06789326667785645
Test Loss Energy: 11.058012228593077, Test Loss Force: 9.356289837924486, time: 14.587155818939209


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2483614324314667, Training Loss Force: 2.5760208483515643, time: 1.1120648384094238
Validation Loss Energy: 1.1314271322957135, Validation Loss Force: 2.5937094417596898, time: 0.06876325607299805
Test Loss Energy: 10.817665334869414, Test Loss Force: 9.420091356545948, time: 14.448071956634521


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.504787111286937, Training Loss Force: 2.5697838368652515, time: 1.101473093032837
Validation Loss Energy: 1.1845286022091344, Validation Loss Force: 2.5668003208126082, time: 0.06954073905944824
Test Loss Energy: 11.037899296405687, Test Loss Force: 9.369181462817751, time: 14.8988778591156


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3790143299389557, Training Loss Force: 2.5694995788252424, time: 1.1189239025115967
Validation Loss Energy: 1.2895236732538913, Validation Loss Force: 2.5934012676617253, time: 0.07061457633972168
Test Loss Energy: 11.121203116136375, Test Loss Force: 9.320701446727394, time: 14.492552995681763


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5827358693570779, Training Loss Force: 2.57851065819881, time: 1.10256028175354
Validation Loss Energy: 1.219977641575411, Validation Loss Force: 2.598743323141679, time: 0.06948995590209961
Test Loss Energy: 10.616462217409437, Test Loss Force: 9.334370907408701, time: 14.583962440490723


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1969213372776872, Training Loss Force: 2.5985158526922922, time: 1.1092848777770996
Validation Loss Energy: 2.11379219022555, Validation Loss Force: 2.625508599820491, time: 0.07044458389282227
Test Loss Energy: 10.320788947163663, Test Loss Force: 9.374560543163703, time: 14.528614044189453


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1490477301040154, Training Loss Force: 2.607232598246998, time: 1.1074888706207275
Validation Loss Energy: 1.1744135222516459, Validation Loss Force: 2.598016085711079, time: 0.06878113746643066
Test Loss Energy: 10.958574889080634, Test Loss Force: 9.331170944268065, time: 14.650701761245728

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñá‚ñÇ‚ñÜ‚ñÉ‚ñÇ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñÉ‚ñÅ‚ñÖ
wandb:   test_error_force ‚ñà‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñá‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ
wandb:   test_error_total ‚ñÖ‚ñÉ‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÜ‚ñÖ‚ñá‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ
wandb: valid_error_energy ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÇ
wandb:  valid_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÜ‚ñÑ
wandb:  valid_error_total ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÉ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1014
wandb:                 lr 0.0001
wandb:  test_error_energy 10.95857
wandb:   test_error_force 9.33117
wandb:   test_error_total 5.20335
wandb: train_error_energy 2.14905
wandb:  train_error_force 2.60723
wandb:  train_error_total 1.24855
wandb: valid_error_energy 1.17441
wandb:  valid_error_force 2.59802
wandb:  valid_error_total 1.31028
wandb: 
wandb: üöÄ View run al_40_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6oi1ct6t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_234529-6oi1ct6t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6129181981086731, Uncertainty Bias: 0.03810851275920868
Found uncertainty sample after 1923 steps.
Found uncertainty sample after 1887 steps.
Found uncertainty sample after 2336 steps.
Found uncertainty sample after 3946 steps.
Found uncertainty sample after 1493 steps.
Found uncertainty sample after 2472 steps.
Found uncertainty sample after 69 steps.
Found uncertainty sample after 3336 steps.
Found uncertainty sample after 3587 steps.
Found uncertainty sample after 419 steps.
Found uncertainty sample after 731 steps.
Found uncertainty sample after 208 steps.
Found uncertainty sample after 1456 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_003018-yz1zvsww
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_10
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/yz1zvsww
Training model 10. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.159756045554507, Training Loss Force: 2.9492077473114993, time: 1.1159496307373047
Validation Loss Energy: 1.3138418160189569, Validation Loss Force: 2.6133586578729413, time: 0.07156848907470703
Test Loss Energy: 10.398515895724847, Test Loss Force: 9.396194158726093, time: 14.515671014785767


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6779643860503073, Training Loss Force: 2.6633084889375502, time: 1.10640287399292
Validation Loss Energy: 1.1591328521123514, Validation Loss Force: 2.6086774844181013, time: 0.07066226005554199
Test Loss Energy: 10.71338372199887, Test Loss Force: 9.281272210950243, time: 14.696045398712158


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4444224929713747, Training Loss Force: 2.6223012194621482, time: 1.1126699447631836
Validation Loss Energy: 1.2255263340227858, Validation Loss Force: 2.665733113024908, time: 0.06901359558105469
Test Loss Energy: 10.842485483475265, Test Loss Force: 9.334178199503876, time: 14.557371377944946


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3832217247063627, Training Loss Force: 2.7275859257115833, time: 1.1279807090759277
Validation Loss Energy: 1.2635381839241184, Validation Loss Force: 2.635900568860941, time: 0.07409858703613281
Test Loss Energy: 10.396714196892843, Test Loss Force: 9.352625706376573, time: 15.032018661499023


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4818364391043668, Training Loss Force: 2.628979478749065, time: 1.1545395851135254
Validation Loss Energy: 2.4614700213686573, Validation Loss Force: 2.618839213561662, time: 0.0693824291229248
Test Loss Energy: 11.861208899192668, Test Loss Force: 9.299935877102323, time: 14.512544870376587


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8463102545314314, Training Loss Force: 2.627319311577427, time: 1.1243388652801514
Validation Loss Energy: 1.1855054517523196, Validation Loss Force: 2.60226795305257, time: 0.07150959968566895
Test Loss Energy: 10.844194309454696, Test Loss Force: 9.312160366581477, time: 14.704026460647583


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3928213407730154, Training Loss Force: 2.6061915048597157, time: 1.1266570091247559
Validation Loss Energy: 2.623776233865173, Validation Loss Force: 2.6167619330993017, time: 0.07097411155700684
Test Loss Energy: 10.177983394320044, Test Loss Force: 9.348844014846069, time: 14.54964804649353


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9487903011893584, Training Loss Force: 2.6149770847010436, time: 1.1440868377685547
Validation Loss Energy: 2.489657040544218, Validation Loss Force: 2.633759605022845, time: 0.06982016563415527
Test Loss Energy: 10.233925111780797, Test Loss Force: 9.390764016031495, time: 14.648738622665405


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4827384043390215, Training Loss Force: 2.6724503191697124, time: 1.1390211582183838
Validation Loss Energy: 2.6126251857062552, Validation Loss Force: 2.7043154412781076, time: 0.0686497688293457
Test Loss Energy: 10.080848197298945, Test Loss Force: 9.374833542531452, time: 14.573844194412231


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7770821454735997, Training Loss Force: 2.7156089909428696, time: 1.1207358837127686
Validation Loss Energy: 1.2431988047930635, Validation Loss Force: 2.6223286617474963, time: 0.06856918334960938
Test Loss Energy: 10.769743110818641, Test Loss Force: 9.239834298958016, time: 14.617010116577148


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3665328037962976, Training Loss Force: 2.6129246149795793, time: 1.1224656105041504
Validation Loss Energy: 1.4684695056872987, Validation Loss Force: 2.6103882514662646, time: 0.07039022445678711
Test Loss Energy: 10.37395948065234, Test Loss Force: 9.289110780433022, time: 14.671224355697632


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.549092021724785, Training Loss Force: 2.598539418931958, time: 1.1321008205413818
Validation Loss Energy: 1.6544731707046063, Validation Loss Force: 2.617047617613527, time: 0.07049989700317383
Test Loss Energy: 11.126027076472488, Test Loss Force: 9.28736052633438, time: 14.674366235733032


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.827400296608885, Training Loss Force: 2.5996549137562326, time: 1.1112942695617676
Validation Loss Energy: 1.8413999106663574, Validation Loss Force: 2.6041980492094723, time: 0.0709846019744873
Test Loss Energy: 11.267314188953867, Test Loss Force: 9.283324777469023, time: 14.540893077850342


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5265807749771996, Training Loss Force: 2.6443126448263996, time: 1.0947704315185547
Validation Loss Energy: 3.9264590969705315, Validation Loss Force: 2.613044249038891, time: 0.07356452941894531
Test Loss Energy: 10.20238854825985, Test Loss Force: 9.273881124844287, time: 14.705373525619507


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.084911269889554, Training Loss Force: 2.625840957137213, time: 1.1283161640167236
Validation Loss Energy: 1.1511529465951642, Validation Loss Force: 2.60592551644358, time: 0.06855201721191406
Test Loss Energy: 10.567402935113693, Test Loss Force: 9.236403506022128, time: 14.833513736724854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8633646396116876, Training Loss Force: 2.656030170040107, time: 1.147249698638916
Validation Loss Energy: 1.3751584414022378, Validation Loss Force: 2.6097282601177345, time: 0.06857967376708984
Test Loss Energy: 10.356074904696689, Test Loss Force: 9.259665632784882, time: 14.70509386062622


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9347628804788444, Training Loss Force: 2.630426160190158, time: 1.1069154739379883
Validation Loss Energy: 1.6643234970475866, Validation Loss Force: 2.6112114592987594, time: 0.07049107551574707
Test Loss Energy: 10.288193499755076, Test Loss Force: 9.322654014980927, time: 14.523405313491821


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.493743192606814, Training Loss Force: 2.569837312041467, time: 1.107720136642456
Validation Loss Energy: 1.195976245670428, Validation Loss Force: 2.620401460289491, time: 0.07103371620178223
Test Loss Energy: 10.50763761769072, Test Loss Force: 9.20615457172108, time: 14.662878513336182


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8326953284137484, Training Loss Force: 2.6635438232345963, time: 1.103844165802002
Validation Loss Energy: 2.364727180206557, Validation Loss Force: 2.606203184868552, time: 0.07047247886657715
Test Loss Energy: 10.129939562604614, Test Loss Force: 9.266868636908374, time: 14.531676530838013


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6092613966271847, Training Loss Force: 2.5976414819845797, time: 1.263376235961914
Validation Loss Energy: 1.6442232645792583, Validation Loss Force: 2.58504315860018, time: 0.09359169006347656
Test Loss Energy: 10.317631839090064, Test Loss Force: 9.224644565265788, time: 14.557228803634644

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñà‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÖ‚ñÜ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ
wandb:   test_error_force ‚ñà‚ñÑ‚ñÜ‚ñÜ‚ñÑ‚ñÖ‚ñÜ‚ñà‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÇ
wandb:   test_error_total ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñà‚ñÑ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñÜ‚ñÉ‚ñÑ‚ñÅ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb: valid_error_energy ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÑ‚ñÇ
wandb:  valid_error_force ‚ñÉ‚ñÇ‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:  valid_error_total ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñá‚ñÇ‚ñÜ‚ñÉ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1025
wandb:                 lr 0.0001
wandb:  test_error_energy 10.31763
wandb:   test_error_force 9.22464
wandb:   test_error_total 5.09659
wandb: train_error_energy 1.60926
wandb:  train_error_force 2.59764
wandb:  train_error_total 1.18038
wandb: valid_error_energy 1.64422
wandb:  valid_error_force 2.58504
wandb:  valid_error_total 1.31359
wandb: 
wandb: üöÄ View run al_40_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/yz1zvsww
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_003018-yz1zvsww/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0790983438491821, Uncertainty Bias: -0.0119265615940094
Found uncertainty sample after 1235 steps.
Found uncertainty sample after 1216 steps.
Found uncertainty sample after 3424 steps.
Found uncertainty sample after 3784 steps.
Found uncertainty sample after 1264 steps.
Found uncertainty sample after 38 steps.
Found uncertainty sample after 252 steps.
Found uncertainty sample after 341 steps.
Found uncertainty sample after 45 steps.
Found uncertainty sample after 436 steps.
Found uncertainty sample after 1463 steps.
Found uncertainty sample after 71 steps.
Found uncertainty sample after 446 steps.
Found uncertainty sample after 511 steps.
Found uncertainty sample after 69 steps.
Found uncertainty sample after 660 steps.
Found uncertainty sample after 1700 steps.
Found uncertainty sample after 1845 steps.
Found uncertainty sample after 161 steps.
Found uncertainty sample after 245 steps.
Found uncertainty sample after 1080 steps.
Found uncertainty sample after 582 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 1795 steps.
Found uncertainty sample after 2466 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 1528 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_005221-9lp2kzqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_11
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9lp2kzqx
Training model 11. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4792696283014104, Training Loss Force: 3.0181877978801053, time: 1.1344354152679443
Validation Loss Energy: 1.207277150164555, Validation Loss Force: 2.6507341193552123, time: 0.07236933708190918
Test Loss Energy: 10.202474402954003, Test Loss Force: 9.240756778757962, time: 14.479419708251953


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6333718498070484, Training Loss Force: 2.6743898956341914, time: 1.13246750831604
Validation Loss Energy: 1.1905511345990434, Validation Loss Force: 2.6240262913160497, time: 0.07176065444946289
Test Loss Energy: 10.528988921418675, Test Loss Force: 9.214966007184366, time: 14.708520412445068


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2611442223902871, Training Loss Force: 2.635743735559159, time: 1.1306073665618896
Validation Loss Energy: 1.3088412236742835, Validation Loss Force: 2.613643006372291, time: 0.07013940811157227
Test Loss Energy: 10.320739801401801, Test Loss Force: 9.195292351092185, time: 14.838104248046875


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4319007795813865, Training Loss Force: 2.6293896218207644, time: 1.141636610031128
Validation Loss Energy: 1.3236693187744797, Validation Loss Force: 2.65605680261947, time: 0.07159304618835449
Test Loss Energy: 10.318535190327987, Test Loss Force: 9.246529780641781, time: 14.652768611907959


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3652104763256552, Training Loss Force: 2.6360834342101467, time: 1.1363515853881836
Validation Loss Energy: 1.1584485898269152, Validation Loss Force: 2.619221981823512, time: 0.07358884811401367
Test Loss Energy: 10.501023891723532, Test Loss Force: 9.217904265295921, time: 14.63013243675232


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6066844904604363, Training Loss Force: 2.635377782191602, time: 1.1487717628479004
Validation Loss Energy: 1.1992016082491919, Validation Loss Force: 2.5983870525081945, time: 0.0726935863494873
Test Loss Energy: 10.708994379193005, Test Loss Force: 9.15764387625248, time: 14.70350432395935


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4306713051445963, Training Loss Force: 2.619372054080317, time: 1.1325414180755615
Validation Loss Energy: 1.1919449321179783, Validation Loss Force: 2.600103608954152, time: 0.07207894325256348
Test Loss Energy: 10.673371256272379, Test Loss Force: 9.154271219782395, time: 14.512468338012695


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3852158230607317, Training Loss Force: 2.6241088138510404, time: 1.1304867267608643
Validation Loss Energy: 1.1491530436610138, Validation Loss Force: 2.608188280304498, time: 0.07198143005371094
Test Loss Energy: 10.58266319546902, Test Loss Force: 9.220463281711943, time: 14.641289710998535


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4544292916222186, Training Loss Force: 2.6334709178489244, time: 1.1290714740753174
Validation Loss Energy: 3.149179670522003, Validation Loss Force: 2.6290880063412803, time: 0.07034707069396973
Test Loss Energy: 12.076160654285344, Test Loss Force: 9.132062213157244, time: 14.591362953186035


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.661348674369516, Training Loss Force: 2.6189648124550646, time: 1.1325640678405762
Validation Loss Energy: 1.1968896345070237, Validation Loss Force: 2.5955206325926663, time: 0.07153820991516113
Test Loss Energy: 10.297346344143614, Test Loss Force: 9.191539077274253, time: 14.639927387237549


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6901736271530603, Training Loss Force: 2.643530833212397, time: 1.1480305194854736
Validation Loss Energy: 1.137715308976714, Validation Loss Force: 2.5959512747208904, time: 0.07311677932739258
Test Loss Energy: 10.487103260245615, Test Loss Force: 9.13856441802234, time: 14.914935827255249


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5362958230664792, Training Loss Force: 2.625701971104854, time: 1.1236233711242676
Validation Loss Energy: 2.509380182813918, Validation Loss Force: 2.6275003753308153, time: 0.07269406318664551
Test Loss Energy: 10.076291752374228, Test Loss Force: 9.187681626938623, time: 14.6439688205719


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7243426293175463, Training Loss Force: 2.621261030668271, time: 1.1344990730285645
Validation Loss Energy: 1.4789954102190241, Validation Loss Force: 2.601662738313938, time: 0.07214522361755371
Test Loss Energy: 10.292547905655361, Test Loss Force: 9.184663996020095, time: 14.53200078010559


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5054820805634312, Training Loss Force: 2.6322820805312666, time: 1.1257729530334473
Validation Loss Energy: 1.374707313712588, Validation Loss Force: 2.608752523920279, time: 0.07229232788085938
Test Loss Energy: 10.760482116841992, Test Loss Force: 9.157720073401057, time: 14.652658939361572


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4718227157804622, Training Loss Force: 2.5970186561407695, time: 1.118298053741455
Validation Loss Energy: 1.3019210006225668, Validation Loss Force: 2.596825028449511, time: 0.06960773468017578
Test Loss Energy: 10.327001309080797, Test Loss Force: 9.146054159383821, time: 14.502987623214722


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3629135850443488, Training Loss Force: 2.6076388205704966, time: 1.139237880706787
Validation Loss Energy: 1.2003466843321255, Validation Loss Force: 2.6009475250172183, time: 0.0739908218383789
Test Loss Energy: 10.60934117418456, Test Loss Force: 9.187213228983383, time: 14.690393209457397


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.840140318540693, Training Loss Force: 2.6234905358558476, time: 1.1421966552734375
Validation Loss Energy: 1.1363336469262322, Validation Loss Force: 2.611261782525739, time: 0.07254505157470703
Test Loss Energy: 10.509835760867041, Test Loss Force: 9.1771039238511, time: 14.56272029876709


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3683103209816148, Training Loss Force: 2.6074699766299347, time: 1.13187837600708
Validation Loss Energy: 1.5618063995932874, Validation Loss Force: 2.6164562083619427, time: 0.0728597640991211
Test Loss Energy: 10.18056902844256, Test Loss Force: 9.191039272477171, time: 14.65285611152649


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6703967119715062, Training Loss Force: 2.622138826179268, time: 1.1254701614379883
Validation Loss Energy: 1.8342652572271123, Validation Loss Force: 2.6558209959939325, time: 0.07114958763122559
Test Loss Energy: 10.239604354798686, Test Loss Force: 9.223583270489174, time: 14.515035390853882


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7633622122978494, Training Loss Force: 2.645978351736487, time: 1.35685133934021
Validation Loss Energy: 1.360723134675458, Validation Loss Force: 2.592879553852817, time: 0.06993675231933594
Test Loss Energy: 10.781709215487187, Test Loss Force: 9.113597858041107, time: 14.538444519042969

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ
wandb:   test_error_force ‚ñà‚ñÜ‚ñÖ‚ñà‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÇ‚ñÖ‚ñÇ‚ñÖ‚ñÖ‚ñÉ‚ñÉ‚ñÖ‚ñÑ‚ñÖ‚ñá‚ñÅ
wandb:   test_error_total ‚ñá‚ñÑ‚ñÇ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÖ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb: valid_error_energy ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÜ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ
wandb:  valid_error_force ‚ñá‚ñÑ‚ñÉ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñà‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÜ‚ñÇ‚ñÅ‚ñÖ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1049
wandb:                 lr 0.0001
wandb:  test_error_energy 10.78171
wandb:   test_error_force 9.1136
wandb:   test_error_total 5.05416
wandb: train_error_energy 1.76336
wandb:  train_error_force 2.64598
wandb:  train_error_total 1.24273
wandb: valid_error_energy 1.36072
wandb:  valid_error_force 2.59288
wandb:  valid_error_total 1.30606
wandb: 
wandb: üöÄ View run al_40_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9lp2kzqx
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_005221-9lp2kzqx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.634247899055481, Uncertainty Bias: 0.03394535183906555
Found uncertainty sample after 3760 steps.
Found uncertainty sample after 34 steps.
Found uncertainty sample after 2744 steps.
Found uncertainty sample after 3562 steps.
Found uncertainty sample after 2622 steps.
Found uncertainty sample after 1906 steps.
Found uncertainty sample after 1320 steps.
Found uncertainty sample after 1006 steps.
Found uncertainty sample after 2568 steps.
Found uncertainty sample after 524 steps.
Found uncertainty sample after 1148 steps.
Found uncertainty sample after 812 steps.
Found uncertainty sample after 255 steps.
Found uncertainty sample after 545 steps.
Found uncertainty sample after 602 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_013340-33y3lfuy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_12
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/33y3lfuy
Training model 12. Added 15 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2176955937995935, Training Loss Force: 2.933493055712237, time: 1.1402037143707275
Validation Loss Energy: 1.187933881457808, Validation Loss Force: 2.6673570391061596, time: 0.07269692420959473
Test Loss Energy: 10.483285466002489, Test Loss Force: 9.12433250207326, time: 14.884911060333252


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.316279692790416, Training Loss Force: 2.6795782875731464, time: 1.1550915241241455
Validation Loss Energy: 1.2823565101193406, Validation Loss Force: 2.618416364853545, time: 0.07503390312194824
Test Loss Energy: 10.288074186398683, Test Loss Force: 9.121011546814085, time: 14.81883692741394


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.459561665799013, Training Loss Force: 2.6464874847386506, time: 1.1980772018432617
Validation Loss Energy: 1.2283271778748384, Validation Loss Force: 2.6179480916396587, time: 0.07050204277038574
Test Loss Energy: 10.393757915404343, Test Loss Force: 9.169960315265026, time: 14.625920057296753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.560080723535986, Training Loss Force: 2.636174975837834, time: 1.1903367042541504
Validation Loss Energy: 2.19598738807675, Validation Loss Force: 2.6570646031739393, time: 0.06968235969543457
Test Loss Energy: 11.216890646609425, Test Loss Force: 9.121241910286523, time: 14.786366939544678


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5139131462676587, Training Loss Force: 2.678569910698535, time: 1.1799919605255127
Validation Loss Energy: 1.1960479451354167, Validation Loss Force: 2.633870494257517, time: 0.07258486747741699
Test Loss Energy: 10.345579167171007, Test Loss Force: 9.134603444020959, time: 14.699198484420776


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3873855644052218, Training Loss Force: 2.6434169689036016, time: 1.1769697666168213
Validation Loss Energy: 1.3376835581463098, Validation Loss Force: 2.630226736353555, time: 0.07592511177062988
Test Loss Energy: 10.229160159934157, Test Loss Force: 9.119822759378836, time: 14.836094379425049


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.486033602074435, Training Loss Force: 2.6317539585345484, time: 1.1561040878295898
Validation Loss Energy: 1.1937905253340007, Validation Loss Force: 2.616390298294748, time: 0.07330965995788574
Test Loss Energy: 10.49601010069438, Test Loss Force: 9.118504865808006, time: 14.722180843353271


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6229869053629347, Training Loss Force: 2.647224310040711, time: 1.1646685600280762
Validation Loss Energy: 1.2860725241611566, Validation Loss Force: 2.6238844510700936, time: 0.07204246520996094
Test Loss Energy: 10.205281591710907, Test Loss Force: 9.063242436134024, time: 14.792405128479004


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.537704684688971, Training Loss Force: 2.6338228627075657, time: 1.1354737281799316
Validation Loss Energy: 1.4198419042538588, Validation Loss Force: 2.631213383339161, time: 0.07050013542175293
Test Loss Energy: 10.668574356649428, Test Loss Force: 9.106097181409526, time: 15.025318384170532


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7587118543079239, Training Loss Force: 2.64834807537656, time: 1.1490561962127686
Validation Loss Energy: 2.4730773186075807, Validation Loss Force: 2.608512263911823, time: 0.07045459747314453
Test Loss Energy: 11.446119485679402, Test Loss Force: 9.066297983760938, time: 14.814963579177856


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.566002173957282, Training Loss Force: 2.62338687721624, time: 1.1873319149017334
Validation Loss Energy: 1.1453045414773708, Validation Loss Force: 2.6106759400028032, time: 0.0720527172088623
Test Loss Energy: 10.33078424103, Test Loss Force: 9.076661859183176, time: 14.662245750427246


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.55008421817325, Training Loss Force: 2.6278258259348664, time: 1.2157926559448242
Validation Loss Energy: 1.8322273892035812, Validation Loss Force: 2.6204197191594574, time: 0.07288813591003418
Test Loss Energy: 9.995977019942336, Test Loss Force: 9.098514511236734, time: 14.831403493881226


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5000542300860253, Training Loss Force: 2.632837198085839, time: 1.1903705596923828
Validation Loss Energy: 1.416658626143675, Validation Loss Force: 2.6342423517312166, time: 0.07263803482055664
Test Loss Energy: 10.126571858482864, Test Loss Force: 9.09210453103549, time: 14.729735612869263


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3320868248307016, Training Loss Force: 2.6466374000156927, time: 1.1643474102020264
Validation Loss Energy: 1.1747681228665359, Validation Loss Force: 2.6260002532946998, time: 0.07454752922058105
Test Loss Energy: 10.29962054923489, Test Loss Force: 9.102475438605834, time: 14.793369054794312


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.469717081617377, Training Loss Force: 2.6508920441724153, time: 1.17887544631958
Validation Loss Energy: 1.693261245248643, Validation Loss Force: 2.6335734536168496, time: 0.0700979232788086
Test Loss Energy: 10.904192098129242, Test Loss Force: 9.122034603119568, time: 14.707436084747314


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5245871012223295, Training Loss Force: 2.6540267411142318, time: 1.3648276329040527
Validation Loss Energy: 1.4616778740673553, Validation Loss Force: 2.637759188222, time: 0.07082986831665039
Test Loss Energy: 10.70771626295861, Test Loss Force: 9.075841256929428, time: 14.686614036560059


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7934825517684094, Training Loss Force: 2.662510317690415, time: 1.168940782546997
Validation Loss Energy: 2.765469963523153, Validation Loss Force: 2.691410428256717, time: 0.07295918464660645
Test Loss Energy: 10.11639269819234, Test Loss Force: 9.107135062117417, time: 14.77525281906128


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3449953309183424, Training Loss Force: 2.6793947165096066, time: 1.1537275314331055
Validation Loss Energy: 2.0892433622253033, Validation Loss Force: 2.6809892895581506, time: 0.07360529899597168
Test Loss Energy: 10.03974312788179, Test Loss Force: 9.112836609355725, time: 14.664716720581055


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.967494415775424, Training Loss Force: 2.644276144352257, time: 1.1739592552185059
Validation Loss Energy: 1.2118493270724633, Validation Loss Force: 2.614050713578485, time: 0.07238936424255371
Test Loss Energy: 10.449891384808144, Test Loss Force: 9.037546617212767, time: 14.774913549423218


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4520129705438267, Training Loss Force: 2.6548367852707466, time: 1.206620454788208
Validation Loss Energy: 2.34532267748468, Validation Loss Force: 2.645922016442567, time: 0.0726931095123291
Test Loss Energy: 11.35610696867627, Test Loss Force: 9.057330535335428, time: 14.725035667419434

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÉ‚ñÇ‚ñÉ‚ñá‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñà
wandb:   test_error_force ‚ñÜ‚ñÖ‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÇ
wandb:   test_error_total ‚ñÖ‚ñÖ‚ñá‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÇ‚ñÑ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÉ‚ñÑ‚ñÇ‚ñÅ‚ñÜ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÖ‚ñÉ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ
wandb: valid_error_energy ‚ñÅ‚ñÇ‚ñÅ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñà‚ñÖ‚ñÅ‚ñÜ
wandb:  valid_error_force ‚ñÜ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñà‚ñá‚ñÅ‚ñÑ
wandb:  valid_error_total ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñà‚ñÖ‚ñÑ‚ñÜ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1062
wandb:                 lr 0.0001
wandb:  test_error_energy 11.35611
wandb:   test_error_force 9.05733
wandb:   test_error_total 5.06076
wandb: train_error_energy 1.45201
wandb:  train_error_force 2.65484
wandb:  train_error_total 1.19944
wandb: valid_error_energy 2.34532
wandb:  valid_error_force 2.64592
wandb:  valid_error_total 1.38351
wandb: 
wandb: üöÄ View run al_40_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/33y3lfuy
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_013340-33y3lfuy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0370516777038574, Uncertainty Bias: 0.0006914585828781128
Found uncertainty sample after 888 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 1613 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 2230 steps.
Found uncertainty sample after 761 steps.
Found uncertainty sample after 1067 steps.
Found uncertainty sample after 148 steps.
Found uncertainty sample after 1005 steps.
Found uncertainty sample after 3508 steps.
Found uncertainty sample after 179 steps.
Found uncertainty sample after 358 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 230 steps.
Found uncertainty sample after 602 steps.
Found uncertainty sample after 179 steps.
Found uncertainty sample after 1117 steps.
Found uncertainty sample after 687 steps.
Found uncertainty sample after 2099 steps.
Found uncertainty sample after 745 steps.
Found uncertainty sample after 311 steps.
Found uncertainty sample after 2634 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_020142-16zzqdhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_13
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/16zzqdhz
Training model 13. Added 22 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.6933761997205483, Training Loss Force: 2.8966606711786977, time: 1.1447865962982178
Validation Loss Energy: 2.103740236970932, Validation Loss Force: 2.680713402486346, time: 0.07372236251831055
Test Loss Energy: 11.145105713974466, Test Loss Force: 9.038777434323665, time: 14.460885524749756


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5634783927391427, Training Loss Force: 2.6834689200690174, time: 1.122509241104126
Validation Loss Energy: 1.465659866403982, Validation Loss Force: 2.6397596478290155, time: 0.07573485374450684
Test Loss Energy: 10.180253141365174, Test Loss Force: 9.078571567706442, time: 14.733412981033325


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4153422880166067, Training Loss Force: 2.6524896625489847, time: 1.157883644104004
Validation Loss Energy: 2.013090514318, Validation Loss Force: 2.626876901722217, time: 0.07097840309143066
Test Loss Energy: 10.012794099027882, Test Loss Force: 9.051938118156862, time: 14.536520719528198


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3601414066199025, Training Loss Force: 2.6553002907452727, time: 1.1797254085540771
Validation Loss Energy: 1.1556292644357506, Validation Loss Force: 2.6099544919699973, time: 0.07074761390686035
Test Loss Energy: 10.359708128368176, Test Loss Force: 9.055040316718559, time: 14.777704000473022


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4220061452040695, Training Loss Force: 2.6486032411196083, time: 1.1545360088348389
Validation Loss Energy: 1.1653537827112819, Validation Loss Force: 2.6100771826694036, time: 0.07274270057678223
Test Loss Energy: 10.396526916985625, Test Loss Force: 9.078704493025914, time: 14.65553903579712


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6021454302296365, Training Loss Force: 2.6515510859025286, time: 1.1851420402526855
Validation Loss Energy: 2.381255020232193, Validation Loss Force: 2.6328800618964303, time: 0.0735330581665039
Test Loss Energy: 11.41756486539167, Test Loss Force: 9.069449771091172, time: 14.719801902770996


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4009525007574377, Training Loss Force: 2.649824188439471, time: 1.1992969512939453
Validation Loss Energy: 1.1547893564173108, Validation Loss Force: 2.6364267360527682, time: 0.07414674758911133
Test Loss Energy: 10.395173937285918, Test Loss Force: 9.07382341747096, time: 14.600342512130737


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4187118501519096, Training Loss Force: 2.6397867086793383, time: 1.163097620010376
Validation Loss Energy: 1.2287924450552545, Validation Loss Force: 2.6119032923351573, time: 0.07257485389709473
Test Loss Energy: 10.465494975338737, Test Loss Force: 9.0821774555343, time: 15.040039777755737


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3210149028076985, Training Loss Force: 2.6369549596596493, time: 1.1848578453063965
Validation Loss Energy: 1.680524013428709, Validation Loss Force: 2.616588251165478, time: 0.07098937034606934
Test Loss Energy: 11.020432942069984, Test Loss Force: 9.049674591858135, time: 14.560380220413208


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.400346365871306, Training Loss Force: 2.634853650576806, time: 1.1622791290283203
Validation Loss Energy: 1.1585002490687706, Validation Loss Force: 2.6305395865035837, time: 0.07113194465637207
Test Loss Energy: 10.309506924080464, Test Loss Force: 8.984871896797841, time: 14.759104013442993


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6715239230230834, Training Loss Force: 2.6416378293294542, time: 1.1962790489196777
Validation Loss Energy: 2.6744955892554585, Validation Loss Force: 2.6201756737755204, time: 0.07366466522216797
Test Loss Energy: 11.400964341959897, Test Loss Force: 9.021793579545239, time: 14.605218648910522


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8403366294745434, Training Loss Force: 2.655823013114431, time: 1.1824798583984375
Validation Loss Energy: 2.072776756214797, Validation Loss Force: 2.6674864098799436, time: 0.07352781295776367
Test Loss Energy: 11.021441090034953, Test Loss Force: 9.064199969420251, time: 14.735602617263794


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.690513468693339, Training Loss Force: 2.663606871546814, time: 1.164069414138794
Validation Loss Energy: 1.4477234213612067, Validation Loss Force: 2.6228866706271914, time: 0.0736088752746582
Test Loss Energy: 10.097603768404705, Test Loss Force: 9.009366188344442, time: 14.55678653717041


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3946977915765248, Training Loss Force: 2.6418630395232823, time: 1.1777842044830322
Validation Loss Energy: 1.1446001276342284, Validation Loss Force: 2.6212990396167264, time: 0.07148933410644531
Test Loss Energy: 10.258089689778435, Test Loss Force: 9.02688934546269, time: 14.700661182403564


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4529554831948917, Training Loss Force: 2.6432751548540154, time: 1.1894893646240234
Validation Loss Energy: 1.1391294807225014, Validation Loss Force: 2.6057504984948805, time: 0.07050728797912598
Test Loss Energy: 10.266037425433074, Test Loss Force: 9.002370786476606, time: 14.598088502883911


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6179206076102082, Training Loss Force: 2.6514837088386085, time: 1.1984045505523682
Validation Loss Energy: 1.2555247667004692, Validation Loss Force: 2.620587389026341, time: 0.07207775115966797
Test Loss Energy: 10.46335681526659, Test Loss Force: 9.014522870011701, time: 15.040510892868042


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.550446157046317, Training Loss Force: 2.6525995956161474, time: 1.1630899906158447
Validation Loss Energy: 1.4113132306265326, Validation Loss Force: 2.6110912179599586, time: 0.0733332633972168
Test Loss Energy: 10.014852182145605, Test Loss Force: 8.981407001674219, time: 14.51987338066101


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.335603957667922, Training Loss Force: 2.644097262438966, time: 1.399092674255371
Validation Loss Energy: 1.2734058784604814, Validation Loss Force: 2.6281746175046843, time: 0.07342982292175293
Test Loss Energy: 10.026845361517, Test Loss Force: 9.00227041515311, time: 14.566218614578247


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3772927906568808, Training Loss Force: 2.635352632485553, time: 1.1896867752075195
Validation Loss Energy: 2.1135960187079874, Validation Loss Force: 2.6043594843402698, time: 0.07342791557312012
Test Loss Energy: 11.06579012015069, Test Loss Force: 8.982497996551158, time: 14.721425294876099


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5573205217148842, Training Loss Force: 2.64643868745023, time: 1.1913199424743652
Validation Loss Energy: 1.9771147510870308, Validation Loss Force: 2.6223522646769646, time: 0.07151269912719727
Test Loss Energy: 11.136513044535121, Test Loss Force: 9.030211321968839, time: 14.587381839752197

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÜ‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÜ‚ñá
wandb:   test_error_force ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñà‚ñá‚ñá‚ñà‚ñÜ‚ñÅ‚ñÑ‚ñá‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÑ
wandb:   test_error_total ‚ñÜ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñà‚ñÜ‚ñÜ‚ñÜ‚ñÑ‚ñá‚ñÜ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÜ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: valid_error_energy ‚ñÖ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñà‚ñÖ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÖ
wandb:  valid_error_force ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ
wandb:  valid_error_total ‚ñà‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÖ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1081
wandb:                 lr 0.0001
wandb:  test_error_energy 11.13651
wandb:   test_error_force 9.03021
wandb:   test_error_total 5.01028
wandb: train_error_energy 1.55732
wandb:  train_error_force 2.64644
wandb:  train_error_total 1.21413
wandb: valid_error_energy 1.97711
wandb:  valid_error_force 2.62235
wandb:  valid_error_total 1.33144
wandb: 
wandb: üöÄ View run al_40_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/16zzqdhz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_020142-16zzqdhz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6522732973098755, Uncertainty Bias: 0.028472915291786194
Found uncertainty sample after 2879 steps.
Found uncertainty sample after 1602 steps.
Found uncertainty sample after 2146 steps.
Found uncertainty sample after 3936 steps.
Found uncertainty sample after 2479 steps.
Found uncertainty sample after 2298 steps.
Found uncertainty sample after 3798 steps.
Found uncertainty sample after 1618 steps.
Found uncertainty sample after 2069 steps.
Found uncertainty sample after 663 steps.
Found uncertainty sample after 716 steps.
Found uncertainty sample after 1946 steps.
Found uncertainty sample after 1664 steps.
Found uncertainty sample after 2442 steps.
Found uncertainty sample after 1765 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_024647-dbgzps5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_14
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/dbgzps5b
Training model 14. Added 15 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.584905504936786, Training Loss Force: 3.0490169175673545, time: 1.1832537651062012
Validation Loss Energy: 1.3540686672494062, Validation Loss Force: 2.739105268637865, time: 0.07555413246154785
Test Loss Energy: 10.558616140148148, Test Loss Force: 9.014294749552022, time: 14.595722436904907


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5050055776521412, Training Loss Force: 2.7075024920398203, time: 1.1898219585418701
Validation Loss Energy: 1.1501961372751126, Validation Loss Force: 2.622800497667717, time: 0.07534241676330566
Test Loss Energy: 10.181362490708256, Test Loss Force: 8.945127478090765, time: 14.74602222442627


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5113296199705755, Training Loss Force: 2.667041147931795, time: 1.198021650314331
Validation Loss Energy: 1.4375202757565035, Validation Loss Force: 2.649548183484001, time: 0.07305073738098145
Test Loss Energy: 10.501017223307226, Test Loss Force: 8.89402886351784, time: 14.551403045654297


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.56693602234605, Training Loss Force: 2.688525399562564, time: 1.1893610954284668
Validation Loss Energy: 1.264822316888684, Validation Loss Force: 2.656805638957225, time: 0.07244873046875
Test Loss Energy: 9.987097879069005, Test Loss Force: 8.986602831142106, time: 15.060485601425171


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5935343385182577, Training Loss Force: 2.662668453949748, time: 1.2157697677612305
Validation Loss Energy: 1.654038854535474, Validation Loss Force: 2.6426351971795268, time: 0.07459521293640137
Test Loss Energy: 10.736218487214433, Test Loss Force: 8.937005757392475, time: 14.556634187698364


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5008780710286507, Training Loss Force: 2.685947883320914, time: 1.2075281143188477
Validation Loss Energy: 1.1472515604893634, Validation Loss Force: 2.617935176829195, time: 0.07722616195678711
Test Loss Energy: 10.216589882758482, Test Loss Force: 8.905471819268998, time: 14.83355975151062


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4494781194413673, Training Loss Force: 2.6856661559555106, time: 1.207401990890503
Validation Loss Energy: 1.7234088662540983, Validation Loss Force: 2.6428787972251717, time: 0.07451605796813965
Test Loss Energy: 10.607567510680417, Test Loss Force: 8.91799636882907, time: 14.640075206756592


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6047115630257731, Training Loss Force: 2.6755267764322253, time: 1.2059521675109863
Validation Loss Energy: 1.2925942807762354, Validation Loss Force: 2.6554482478436494, time: 0.07457160949707031
Test Loss Energy: 10.272716226749612, Test Loss Force: 8.936228080154189, time: 14.711204528808594


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6145357989068265, Training Loss Force: 2.6930506346335235, time: 1.2283921241760254
Validation Loss Energy: 1.1698435720351967, Validation Loss Force: 2.6336941402939424, time: 0.07347750663757324
Test Loss Energy: 10.122431989058544, Test Loss Force: 8.986920322369988, time: 14.60284161567688


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8167951131857878, Training Loss Force: 2.6930555206307822, time: 1.219764232635498
Validation Loss Energy: 1.4251010154769541, Validation Loss Force: 2.616122872650489, time: 0.07319355010986328
Test Loss Energy: 9.965873527065215, Test Loss Force: 8.949853408043936, time: 14.792497873306274


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5153264945586198, Training Loss Force: 2.6668901273550514, time: 1.224259853363037
Validation Loss Energy: 1.1571713596058735, Validation Loss Force: 2.6415064872788188, time: 0.07547807693481445
Test Loss Energy: 10.085151764685536, Test Loss Force: 8.930713547019092, time: 14.711971282958984


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.674959535329382, Training Loss Force: 2.671336136743889, time: 1.2322585582733154
Validation Loss Energy: 1.1624013011708523, Validation Loss Force: 2.6276729439189093, time: 0.07528972625732422
Test Loss Energy: 10.323753034896148, Test Loss Force: 8.92081458145741, time: 14.810220003128052


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.352952224828145, Training Loss Force: 2.653889436582643, time: 1.2362229824066162
Validation Loss Energy: 1.2879762340242662, Validation Loss Force: 2.6144711129259965, time: 0.07768559455871582
Test Loss Energy: 10.005513615368065, Test Loss Force: 8.91261792734538, time: 14.618863344192505


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7432578881634726, Training Loss Force: 2.669681628645938, time: 1.1895246505737305
Validation Loss Energy: 2.0736335870883273, Validation Loss Force: 2.6538519327364933, time: 0.07293009757995605
Test Loss Energy: 9.783784431682696, Test Loss Force: 8.939453467214902, time: 14.761729001998901


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.46643539918184, Training Loss Force: 2.6387881550692835, time: 1.1914658546447754
Validation Loss Energy: 1.1389858591233781, Validation Loss Force: 2.613732074030662, time: 0.07593131065368652
Test Loss Energy: 10.048156440238612, Test Loss Force: 8.870227681566353, time: 14.953876972198486


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.372866585817404, Training Loss Force: 2.6657301992400844, time: 1.4357106685638428
Validation Loss Energy: 1.1702055207319024, Validation Loss Force: 2.6127821674541343, time: 0.07405376434326172
Test Loss Energy: 10.026534692591955, Test Loss Force: 8.921367798870143, time: 14.605581045150757


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3714442707428511, Training Loss Force: 2.6549266358263495, time: 1.2091529369354248
Validation Loss Energy: 1.1642905375394768, Validation Loss Force: 2.6440687411410098, time: 0.07457256317138672
Test Loss Energy: 9.946280306996034, Test Loss Force: 8.893771733115612, time: 14.795341968536377


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7519839611696515, Training Loss Force: 2.669006565777217, time: 1.1882903575897217
Validation Loss Energy: 2.6737932907692024, Validation Loss Force: 2.641391812668666, time: 0.07498311996459961
Test Loss Energy: 11.35163973130677, Test Loss Force: 8.859101498905938, time: 14.684404611587524


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5265157670574234, Training Loss Force: 2.675112649992653, time: 1.212134838104248
Validation Loss Energy: 1.346872111787593, Validation Loss Force: 2.641834033592479, time: 0.07736730575561523
Test Loss Energy: 10.38407815421005, Test Loss Force: 8.937388925526141, time: 14.828715324401855


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3135497583956763, Training Loss Force: 2.6549808144105427, time: 1.2118840217590332
Validation Loss Energy: 1.2948812042394868, Validation Loss Force: 2.617707163623765, time: 0.07306027412414551
Test Loss Energy: 10.409357239081148, Test Loss Force: 8.892028842254273, time: 14.621604919433594

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÉ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÑ
wandb:   test_error_force ‚ñà‚ñÖ‚ñÉ‚ñá‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñá‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÇ
wandb:   test_error_total ‚ñá‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÖ‚ñÑ‚ñà‚ñÇ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÖ‚ñÉ‚ñÉ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb: valid_error_energy ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÇ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ
wandb:  valid_error_total ‚ñÜ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1094
wandb:                 lr 0.0001
wandb:  test_error_energy 10.40936
wandb:   test_error_force 8.89203
wandb:   test_error_total 4.90546
wandb: train_error_energy 1.31355
wandb:  train_error_force 2.65498
wandb:  train_error_total 1.19572
wandb: valid_error_energy 1.29488
wandb:  valid_error_force 2.61771
wandb:  valid_error_total 1.28162
wandb: 
wandb: üöÄ View run al_40_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/dbgzps5b
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_024647-dbgzps5b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0102615356445312, Uncertainty Bias: 0.005810484290122986
Found uncertainty sample after 13 steps.
Found uncertainty sample after 216 steps.
Found uncertainty sample after 2612 steps.
Found uncertainty sample after 2525 steps.
Found uncertainty sample after 3930 steps.
Found uncertainty sample after 678 steps.
Found uncertainty sample after 857 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 3774 steps.
Found uncertainty sample after 1611 steps.
Found uncertainty sample after 1259 steps.
Found uncertainty sample after 595 steps.
Found uncertainty sample after 2117 steps.
Found uncertainty sample after 1690 steps.
Found uncertainty sample after 1505 steps.
Found uncertainty sample after 772 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 1142 steps.
Found uncertainty sample after 382 steps.
Found uncertainty sample after 3245 steps.
Found uncertainty sample after 426 steps.
Found uncertainty sample after 2142 steps.
Found uncertainty sample after 14 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_031617-ig7isqho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_15
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ig7isqho
Training model 15. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.11172630028656, Training Loss Force: 3.064230799686822, time: 1.2048943042755127
Validation Loss Energy: 1.1788585550772293, Validation Loss Force: 2.6890194069677444, time: 0.07566523551940918
Test Loss Energy: 10.272100965085851, Test Loss Force: 8.986589088608639, time: 14.491592407226562


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6967162846894563, Training Loss Force: 2.7514711614851115, time: 1.2085046768188477
Validation Loss Energy: 1.5986068180061999, Validation Loss Force: 2.653000891260757, time: 0.07459712028503418
Test Loss Energy: 10.424247472279838, Test Loss Force: 8.8462195735273, time: 14.756096124649048


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4342418829301427, Training Loss Force: 2.6790959974300823, time: 1.2052373886108398
Validation Loss Energy: 1.259974809581836, Validation Loss Force: 2.6232678802050198, time: 0.07368755340576172
Test Loss Energy: 9.871318522179331, Test Loss Force: 8.846975930486312, time: 14.550694704055786


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4527045571940074, Training Loss Force: 2.6702025662938245, time: 1.2007148265838623
Validation Loss Energy: 1.1590916583203548, Validation Loss Force: 2.6244618321654847, time: 0.07304620742797852
Test Loss Energy: 10.115441991872178, Test Loss Force: 8.862125066113943, time: 14.68888545036316


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5014112045837578, Training Loss Force: 2.6704684014441833, time: 1.2114601135253906
Validation Loss Energy: 1.2252737158767306, Validation Loss Force: 2.6380595688998567, time: 0.07535839080810547
Test Loss Energy: 10.24902301252034, Test Loss Force: 8.874515906932212, time: 14.547307014465332


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4654438518845294, Training Loss Force: 2.689681854038855, time: 1.2049891948699951
Validation Loss Energy: 1.1734018249871228, Validation Loss Force: 2.615046044660782, time: 0.07544875144958496
Test Loss Energy: 10.185193216083148, Test Loss Force: 8.903352060295276, time: 14.667194366455078


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4217909129737194, Training Loss Force: 2.6891326310474604, time: 1.200993537902832
Validation Loss Energy: 1.5055501532203612, Validation Loss Force: 2.635523589996885, time: 0.07533407211303711
Test Loss Energy: 9.772010745798832, Test Loss Force: 8.86159163477841, time: 14.54805874824524


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7187053495409585, Training Loss Force: 2.702963260622546, time: 1.1743838787078857
Validation Loss Energy: 1.1866202448314072, Validation Loss Force: 2.644065178434675, time: 0.07325339317321777
Test Loss Energy: 9.966861012266087, Test Loss Force: 8.876546658869529, time: 14.734997034072876


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3681530219543012, Training Loss Force: 2.668489063596154, time: 1.20033860206604
Validation Loss Energy: 1.2277686123222786, Validation Loss Force: 2.61670515246709, time: 0.07672953605651855
Test Loss Energy: 10.166514058687035, Test Loss Force: 8.860193267878754, time: 14.522255659103394


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4874453448553626, Training Loss Force: 2.6803781263723345, time: 1.213135004043579
Validation Loss Energy: 1.2287906637020871, Validation Loss Force: 2.6215938535659347, time: 0.07249283790588379
Test Loss Energy: 9.7978975332408, Test Loss Force: 8.888815663524955, time: 14.651895761489868


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6203194104841427, Training Loss Force: 2.6741018783955797, time: 1.1911344528198242
Validation Loss Energy: 1.2843220106704452, Validation Loss Force: 2.6271066962808147, time: 0.07761764526367188
Test Loss Energy: 10.247746976085713, Test Loss Force: 8.858684928068767, time: 14.635669946670532


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5880526329024478, Training Loss Force: 2.6960640925290713, time: 1.1768944263458252
Validation Loss Energy: 1.8720558853319655, Validation Loss Force: 2.6348152794436888, time: 0.0755312442779541
Test Loss Energy: 9.761496052250571, Test Loss Force: 8.850837489125976, time: 14.713603734970093


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.531770033636101, Training Loss Force: 2.673321295799591, time: 1.19175386428833
Validation Loss Energy: 1.1323013313626258, Validation Loss Force: 2.6318226061224195, time: 0.0743401050567627
Test Loss Energy: 10.071741495553317, Test Loss Force: 8.855355709569244, time: 14.866744756698608


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8420044653500205, Training Loss Force: 2.679363174957294, time: 1.2042179107666016
Validation Loss Energy: 1.2664597144532639, Validation Loss Force: 2.6440538223082326, time: 0.0737752914428711
Test Loss Energy: 10.246960839751496, Test Loss Force: 8.833578224090827, time: 14.719167709350586


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6421325619388802, Training Loss Force: 2.6892122130002156, time: 1.2424085140228271
Validation Loss Energy: 2.3457902826911283, Validation Loss Force: 2.654292594976284, time: 0.07398223876953125
Test Loss Energy: 9.776116750860057, Test Loss Force: 8.8319608533426, time: 14.580319881439209


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9191838816398075, Training Loss Force: 2.686999562421082, time: 1.2120609283447266
Validation Loss Energy: 2.0714590002091966, Validation Loss Force: 2.622184149471789, time: 0.07439756393432617
Test Loss Energy: 9.769586515330326, Test Loss Force: 8.808209078293753, time: 14.713812828063965


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5629276071342713, Training Loss Force: 2.6836543529460046, time: 1.2261638641357422
Validation Loss Energy: 1.1801796511200189, Validation Loss Force: 2.6186207751295068, time: 0.0748434066772461
Test Loss Energy: 10.102032781292756, Test Loss Force: 8.832556128410353, time: 14.593950748443604


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3081353036334182, Training Loss Force: 2.6803190872387854, time: 1.4478700160980225
Validation Loss Energy: 1.551625409568604, Validation Loss Force: 2.6208076088116634, time: 0.07558941841125488
Test Loss Energy: 10.54118640148017, Test Loss Force: 8.79649751127257, time: 14.581026315689087


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6618281966165884, Training Loss Force: 2.68175514418063, time: 1.2220325469970703
Validation Loss Energy: 1.3863461186356605, Validation Loss Force: 2.646597817300458, time: 0.07473373413085938
Test Loss Energy: 10.3592375573486, Test Loss Force: 8.804235746737678, time: 14.67863130569458


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6186416620893327, Training Loss Force: 2.6729281066217125, time: 1.1780309677124023
Validation Loss Energy: 1.1952003550314425, Validation Loss Force: 2.6226321597933957, time: 0.07845830917358398
Test Loss Energy: 10.100897569686147, Test Loss Force: 8.783810121784208, time: 14.5616774559021

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÜ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÅ‚ñÖ‚ñÅ‚ñÑ‚ñÖ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÜ‚ñÑ
wandb:   test_error_force ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb: valid_error_energy ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÅ‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÇ‚ñÅ
wandb:  valid_error_force ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÜ‚ñÉ‚ñÉ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñà‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1115
wandb:                 lr 0.0001
wandb:  test_error_energy 10.1009
wandb:   test_error_force 8.78381
wandb:   test_error_total 4.83794
wandb: train_error_energy 1.61864
wandb:  train_error_force 2.67293
wandb:  train_error_total 1.20703
wandb: valid_error_energy 1.1952
wandb:  valid_error_force 2.62263
wandb:  valid_error_total 1.2817
wandb: 
wandb: üöÄ View run al_40_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ig7isqho
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_031617-ig7isqho/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.648952305316925, Uncertainty Bias: 0.030357003211975098
Found uncertainty sample after 3782 steps.
Found uncertainty sample after 381 steps.
Found uncertainty sample after 1040 steps.
Found uncertainty sample after 2312 steps.
Found uncertainty sample after 2712 steps.
Found uncertainty sample after 3382 steps.
Found uncertainty sample after 3606 steps.
Found uncertainty sample after 1723 steps.
Found uncertainty sample after 1845 steps.
Found uncertainty sample after 11 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_040509-v8bgvvf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_16
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/v8bgvvf7
Training model 16. Added 10 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4456450701921835, Training Loss Force: 3.004582465091459, time: 1.207226037979126
Validation Loss Energy: 1.3412865675965675, Validation Loss Force: 2.7206680406858985, time: 0.0805826187133789
Test Loss Energy: 9.994892119904637, Test Loss Force: 8.798170523659525, time: 14.697484493255615


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5990764751706805, Training Loss Force: 2.711033585894641, time: 1.2217974662780762
Validation Loss Energy: 1.2787241083418206, Validation Loss Force: 2.626235614581945, time: 0.07539033889770508
Test Loss Energy: 10.048981621782437, Test Loss Force: 8.783783574026142, time: 14.86171841621399


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4846857913736302, Training Loss Force: 2.7211265721246503, time: 1.2477519512176514
Validation Loss Energy: 1.3774651824194766, Validation Loss Force: 2.6201968273443836, time: 0.0728909969329834
Test Loss Energy: 9.754794102669313, Test Loss Force: 8.799246624185635, time: 14.661324977874756


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4700541414884882, Training Loss Force: 2.7321585541430373, time: 1.2187457084655762
Validation Loss Energy: 1.183623118127219, Validation Loss Force: 2.6421125926940343, time: 0.0727531909942627
Test Loss Energy: 10.020079931410432, Test Loss Force: 8.849529626158974, time: 14.793787002563477


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.369755860118743, Training Loss Force: 2.6960972302927457, time: 1.2074155807495117
Validation Loss Energy: 1.2697263821585976, Validation Loss Force: 2.6390188275805135, time: 0.07524371147155762
Test Loss Energy: 10.213612504825665, Test Loss Force: 8.787126441794568, time: 14.747159719467163


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8798350901793097, Training Loss Force: 2.7166606145846037, time: 1.2325780391693115
Validation Loss Energy: 1.1684080240514003, Validation Loss Force: 2.6319542035876626, time: 0.07781004905700684
Test Loss Energy: 10.11013026719416, Test Loss Force: 8.755540051680445, time: 14.867446899414062


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6151565600164395, Training Loss Force: 2.6983231609657747, time: 1.2279002666473389
Validation Loss Energy: 3.7123233007221343, Validation Loss Force: 2.643871678946864, time: 0.07619810104370117
Test Loss Energy: 11.977096396344, Test Loss Force: 8.744094745662283, time: 14.990103960037231


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8585688522746437, Training Loss Force: 2.7256740203868524, time: 1.20908784866333
Validation Loss Energy: 1.8119372199537762, Validation Loss Force: 2.6355589943910878, time: 0.07497286796569824
Test Loss Energy: 9.784941094138965, Test Loss Force: 8.805651680017913, time: 14.833394527435303


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7964748486987778, Training Loss Force: 2.709948543887551, time: 1.2437536716461182
Validation Loss Energy: 1.3363556706945696, Validation Loss Force: 2.656868654325523, time: 0.07796645164489746
Test Loss Energy: 10.395985562825404, Test Loss Force: 8.719723358157777, time: 14.688865661621094


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4738297272584076, Training Loss Force: 2.7130185143287275, time: 1.204113483428955
Validation Loss Energy: 1.199262730929749, Validation Loss Force: 2.629196223546201, time: 0.07309603691101074
Test Loss Energy: 9.76147468533902, Test Loss Force: 8.727607715878122, time: 14.864634037017822


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6508216441215524, Training Loss Force: 2.7058202084400174, time: 1.210193395614624
Validation Loss Energy: 1.1645660906075623, Validation Loss Force: 2.635415372791964, time: 0.07480192184448242
Test Loss Energy: 10.070896266791515, Test Loss Force: 8.77245410725937, time: 14.724501371383667


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4914583909668508, Training Loss Force: 2.700301836108014, time: 1.2664544582366943
Validation Loss Energy: 1.9291295501395924, Validation Loss Force: 2.64401351919282, time: 0.0764017105102539
Test Loss Energy: 10.451139441873648, Test Loss Force: 8.757627811582347, time: 14.839237451553345


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4438185653278817, Training Loss Force: 2.7048753552160516, time: 1.2419164180755615
Validation Loss Energy: 1.3892073058262595, Validation Loss Force: 2.6309715646466834, time: 0.07802796363830566
Test Loss Energy: 9.721455042904347, Test Loss Force: 8.74845004690238, time: 14.753729343414307


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8494118805405582, Training Loss Force: 2.737332636678658, time: 1.3461201190948486
Validation Loss Energy: 2.4547805948866945, Validation Loss Force: 2.6697549631386557, time: 0.1010141372680664
Test Loss Energy: 10.944278270840458, Test Loss Force: 8.785524702187221, time: 14.74283504486084


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.95513537967732, Training Loss Force: 2.69848251785121, time: 1.2345757484436035
Validation Loss Energy: 1.6660583123635102, Validation Loss Force: 2.647451085467653, time: 0.07353353500366211
Test Loss Energy: 9.733391391513829, Test Loss Force: 8.714147615489496, time: 14.832388401031494


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.432291311461665, Training Loss Force: 2.68339651002749, time: 1.1962049007415771
Validation Loss Energy: 3.8982642843748634, Validation Loss Force: 2.633122103258054, time: 0.07322287559509277
Test Loss Energy: 11.718003357951316, Test Loss Force: 8.753016401186994, time: 14.67389988899231


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8430238862296409, Training Loss Force: 2.6959221814177763, time: 1.2115859985351562
Validation Loss Energy: 1.1388491402677783, Validation Loss Force: 2.635039729942784, time: 0.07523894309997559
Test Loss Energy: 9.6815959134471, Test Loss Force: 8.765072436211119, time: 14.849172830581665


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8086048942303508, Training Loss Force: 2.716024108645715, time: 1.2606480121612549
Validation Loss Energy: 2.8452712453864835, Validation Loss Force: 2.6676291408024833, time: 0.07943153381347656
Test Loss Energy: 9.619836385142884, Test Loss Force: 8.84980147370936, time: 14.669875621795654


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.100561913249245, Training Loss Force: 2.7516296040132766, time: 1.2516419887542725
Validation Loss Energy: 1.2233903802404735, Validation Loss Force: 2.719615483633098, time: 0.08266186714172363
Test Loss Energy: 9.777977686679717, Test Loss Force: 8.761181867628908, time: 14.897785663604736


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.715165668388673, Training Loss Force: 2.7090031772874985, time: 1.2436339855194092
Validation Loss Energy: 1.681614758240036, Validation Loss Force: 2.6233389116625707, time: 0.07770180702209473
Test Loss Energy: 10.302362270931274, Test Loss Force: 8.743344954528554, time: 15.050963163375854

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÖ‚ñÅ‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:   test_error_force ‚ñÖ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÜ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÉ
wandb:   test_error_total ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÅ‚ñÖ‚ñÅ‚ñá‚ñÅ‚ñÉ‚ñÅ‚ñÉ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
wandb: valid_error_energy ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñà‚ñÅ‚ñÖ‚ñÅ‚ñÇ
wandb:  valid_error_force ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÑ‚ñà‚ñÅ
wandb:  valid_error_total ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÉ‚ñÜ‚ñÉ‚ñÑ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1124
wandb:                 lr 0.0001
wandb:  test_error_energy 10.30236
wandb:   test_error_force 8.74334
wandb:   test_error_total 4.8119
wandb: train_error_energy 1.71517
wandb:  train_error_force 2.709
wandb:  train_error_total 1.24037
wandb: valid_error_energy 1.68161
wandb:  valid_error_force 2.62334
wandb:  valid_error_total 1.34564
wandb: 
wandb: üöÄ View run al_40_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/v8bgvvf7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_040509-v8bgvvf7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0613880157470703, Uncertainty Bias: -0.009799391031265259
Found uncertainty sample after 11 steps.
Found uncertainty sample after 3021 steps.
Found uncertainty sample after 2890 steps.
Found uncertainty sample after 331 steps.
Found uncertainty sample after 95 steps.
Found uncertainty sample after 778 steps.
Found uncertainty sample after 2717 steps.
Found uncertainty sample after 2530 steps.
Found uncertainty sample after 1130 steps.
Found uncertainty sample after 677 steps.
Found uncertainty sample after 2452 steps.
Found uncertainty sample after 489 steps.
Found uncertainty sample after 801 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1197 steps.
Found uncertainty sample after 2678 steps.
Found uncertainty sample after 235 steps.
Found uncertainty sample after 2451 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1025 steps.
Found uncertainty sample after 36 steps.
Found uncertainty sample after 1588 steps.
Found uncertainty sample after 2908 steps.
Found uncertainty sample after 217 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_043404-6jaaky2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_17
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6jaaky2k
Training model 17. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.628889811587931, Training Loss Force: 2.9926295544117854, time: 1.2229728698730469
Validation Loss Energy: 1.7606274573230631, Validation Loss Force: 2.7317411546437413, time: 0.07671284675598145
Test Loss Energy: 9.778292207431244, Test Loss Force: 8.74606616268415, time: 14.693070650100708


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8339324704569557, Training Loss Force: 2.7538516132352355, time: 1.2106783390045166
Validation Loss Energy: 1.1724198540535813, Validation Loss Force: 2.6266448804721607, time: 0.07503080368041992
Test Loss Energy: 9.794106510590693, Test Loss Force: 8.723402356077148, time: 14.828379154205322


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4311426726723966, Training Loss Force: 2.69667000955912, time: 1.2430450916290283
Validation Loss Energy: 1.1759835623995827, Validation Loss Force: 2.63614995830438, time: 0.07429122924804688
Test Loss Energy: 9.827212362314029, Test Loss Force: 8.704553051474175, time: 14.651246070861816


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3117572555125756, Training Loss Force: 2.7030896723707913, time: 1.2640297412872314
Validation Loss Energy: 1.3765907606834182, Validation Loss Force: 2.6478997637966977, time: 0.07583117485046387
Test Loss Energy: 9.65100624172566, Test Loss Force: 8.674103882818011, time: 14.866522789001465


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.462974148685628, Training Loss Force: 2.718700857745691, time: 1.238412618637085
Validation Loss Energy: 1.2146609703780935, Validation Loss Force: 2.6149420581696337, time: 0.07470011711120605
Test Loss Energy: 9.85661371292304, Test Loss Force: 8.715268361762268, time: 14.698124885559082


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.665541753963855, Training Loss Force: 2.70950513539496, time: 1.2016286849975586
Validation Loss Energy: 1.605698718969427, Validation Loss Force: 2.6328123704760684, time: 0.07593655586242676
Test Loss Energy: 9.692141402954308, Test Loss Force: 8.76237138252775, time: 15.173521280288696


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5788820057179054, Training Loss Force: 2.7193878972101975, time: 1.249927043914795
Validation Loss Energy: 1.1514307263547092, Validation Loss Force: 2.6254179734780982, time: 0.07735824584960938
Test Loss Energy: 9.820497201807317, Test Loss Force: 8.723421727127034, time: 14.744982242584229


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3985628211228374, Training Loss Force: 2.720257531559618, time: 1.222423791885376
Validation Loss Energy: 1.7777372431615814, Validation Loss Force: 2.6217697621912177, time: 0.07526707649230957
Test Loss Energy: 9.643392766267466, Test Loss Force: 8.725914166634231, time: 14.79004979133606


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5305610444394244, Training Loss Force: 2.712950000269576, time: 1.223700761795044
Validation Loss Energy: 1.232873302492673, Validation Loss Force: 2.6215940762350805, time: 0.07938838005065918
Test Loss Energy: 9.65466150381356, Test Loss Force: 8.732983261497107, time: 14.685302972793579


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5210371402401794, Training Loss Force: 2.7079148137989817, time: 1.239325761795044
Validation Loss Energy: 1.1886365139477832, Validation Loss Force: 2.6240349754127408, time: 0.0740964412689209
Test Loss Energy: 9.894294457301799, Test Loss Force: 8.715961312807623, time: 14.816959619522095


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8125505234583963, Training Loss Force: 2.717137578080435, time: 1.2225744724273682
Validation Loss Energy: 1.6779663242840093, Validation Loss Force: 2.6180467340713047, time: 0.07848691940307617
Test Loss Energy: 9.56548105594229, Test Loss Force: 8.709360005017095, time: 14.709973573684692


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6627823992496802, Training Loss Force: 2.721579697651359, time: 1.2286903858184814
Validation Loss Energy: 1.4087832637905011, Validation Loss Force: 2.6161179739292786, time: 0.0770273208618164
Test Loss Energy: 9.547341914359908, Test Loss Force: 8.702285617390228, time: 14.859873533248901


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4947899760061034, Training Loss Force: 2.7270053963218794, time: 1.2422692775726318
Validation Loss Energy: 1.229641927846969, Validation Loss Force: 2.6275943417103966, time: 0.07688665390014648
Test Loss Energy: 9.71339522189701, Test Loss Force: 8.699811224576116, time: 14.68447232246399


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3494743316688511, Training Loss Force: 2.7217152474939432, time: 1.4570727348327637
Validation Loss Energy: 1.8102153194483166, Validation Loss Force: 2.637239255766259, time: 0.09399294853210449
Test Loss Energy: 9.547838748680633, Test Loss Force: 8.695489871637216, time: 14.703774452209473


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2593574497680144, Training Loss Force: 2.7261056150442005, time: 1.241070032119751
Validation Loss Energy: 1.859128828065128, Validation Loss Force: 2.625259433046198, time: 0.07753729820251465
Test Loss Energy: 9.512096785721274, Test Loss Force: 8.69543582482253, time: 14.895289421081543


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.789220148756234, Training Loss Force: 2.713072251815945, time: 1.2289042472839355
Validation Loss Energy: 1.3057774075608901, Validation Loss Force: 2.6150725422891474, time: 0.07409477233886719
Test Loss Energy: 9.558983612233169, Test Loss Force: 8.693018481942055, time: 14.68233060836792


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.097761126610792, Training Loss Force: 2.6997421633949776, time: 1.2403790950775146
Validation Loss Energy: 2.192837733007601, Validation Loss Force: 2.6265092749622907, time: 0.0750722885131836
Test Loss Energy: 10.760184966615464, Test Loss Force: 8.694690631631795, time: 14.876399755477905


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7736730116870585, Training Loss Force: 2.704608622320246, time: 1.245558261871338
Validation Loss Energy: 1.1729994618404314, Validation Loss Force: 2.6242202361421527, time: 0.07982587814331055
Test Loss Energy: 9.628798685364474, Test Loss Force: 8.686901268532845, time: 14.754410982131958


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5144859835662705, Training Loss Force: 2.6996795253271784, time: 1.2457771301269531
Validation Loss Energy: 1.3643514170737785, Validation Loss Force: 2.6035656688350373, time: 0.07671475410461426
Test Loss Energy: 9.868196719406336, Test Loss Force: 8.698760795121176, time: 14.867613077163696


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4385264434039025, Training Loss Force: 2.693938384885181, time: 1.2282333374023438
Validation Loss Energy: 1.2588798340567362, Validation Loss Force: 2.6243692018007785, time: 0.07631468772888184
Test Loss Energy: 9.879690019369, Test Loss Force: 8.702904670258503, time: 15.033439636230469

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÉ
wandb:   test_error_force ‚ñá‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ
wandb:   test_error_total ‚ñÖ‚ñÖ‚ñÑ‚ñÅ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÑ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñà‚ñÅ‚ñÖ‚ñÑ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÖ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÅ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÇ‚ñÖ‚ñÜ‚ñÇ‚ñà‚ñÅ‚ñÇ‚ñÇ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñà‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÜ‚ñÉ‚ñá‚ñÅ‚ñÑ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1147
wandb:                 lr 0.0001
wandb:  test_error_energy 9.87969
wandb:   test_error_force 8.7029
wandb:   test_error_total 4.76457
wandb: train_error_energy 1.43853
wandb:  train_error_force 2.69394
wandb:  train_error_total 1.21408
wandb: valid_error_energy 1.25888
wandb:  valid_error_force 2.62437
wandb:  valid_error_total 1.28642
wandb: 
wandb: üöÄ View run al_40_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/6jaaky2k
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_043404-6jaaky2k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6297203302383423, Uncertainty Bias: 0.038926541805267334
Found uncertainty sample after 564 steps.
Found uncertainty sample after 439 steps.
Found uncertainty sample after 2454 steps.
Found uncertainty sample after 1014 steps.
Found uncertainty sample after 1027 steps.
Found uncertainty sample after 2534 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 2434 steps.
Found uncertainty sample after 1710 steps.
Found uncertainty sample after 2041 steps.
Found uncertainty sample after 2765 steps.
Found uncertainty sample after 2027 steps.
Found uncertainty sample after 1592 steps.
Found uncertainty sample after 1169 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_051632-ilbq0uhg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_18
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ilbq0uhg
Training model 18. Added 14 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3486255213255185, Training Loss Force: 3.127402008187508, time: 1.2768774032592773
Validation Loss Energy: 1.2661394048868468, Validation Loss Force: 2.7487504053628733, time: 0.07785940170288086
Test Loss Energy: 9.897072188446245, Test Loss Force: 8.686870971539316, time: 14.72373104095459


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6491724158376582, Training Loss Force: 2.7652341268071905, time: 1.2514634132385254
Validation Loss Energy: 1.8403197426394617, Validation Loss Force: 2.6473571190880714, time: 0.08023810386657715
Test Loss Energy: 9.386652401106762, Test Loss Force: 8.688026137099335, time: 14.859564542770386


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8026871705106642, Training Loss Force: 2.7277068531120774, time: 1.2867271900177002
Validation Loss Energy: 1.5343816882388102, Validation Loss Force: 2.6398462661267814, time: 0.07619261741638184
Test Loss Energy: 10.146506296284942, Test Loss Force: 8.683397482086143, time: 14.665083408355713


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.374280389256388, Training Loss Force: 2.720575548737149, time: 1.2683610916137695
Validation Loss Energy: 1.3513820526692144, Validation Loss Force: 2.632345210607912, time: 0.07597970962524414
Test Loss Energy: 9.570558122314711, Test Loss Force: 8.67768236951704, time: 14.813415050506592


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5253058232396217, Training Loss Force: 2.715629946644391, time: 1.2660000324249268
Validation Loss Energy: 1.5346914210207958, Validation Loss Force: 2.636899239980427, time: 0.07596445083618164
Test Loss Energy: 10.094084495377192, Test Loss Force: 8.65521347185857, time: 14.673953533172607


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6931600661941593, Training Loss Force: 2.7251425771733175, time: 1.2690422534942627
Validation Loss Energy: 1.4685041307394904, Validation Loss Force: 2.652089061108183, time: 0.07794427871704102
Test Loss Energy: 9.474625497231376, Test Loss Force: 8.666411160460006, time: 14.819252014160156


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5140865435372108, Training Loss Force: 2.7188358106276738, time: 1.2523460388183594
Validation Loss Energy: 1.4305896985895012, Validation Loss Force: 2.6336538371785294, time: 0.07743096351623535
Test Loss Energy: 9.507665588110818, Test Loss Force: 8.633578993598963, time: 15.044570207595825


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5398542940372126, Training Loss Force: 2.7340074270482293, time: 1.2593634128570557
Validation Loss Energy: 1.2462490380885554, Validation Loss Force: 2.6210396300617202, time: 0.07870268821716309
Test Loss Energy: 9.872080493665083, Test Loss Force: 8.651317307402532, time: 14.791876554489136


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5966283710496851, Training Loss Force: 2.71446320846441, time: 1.288189172744751
Validation Loss Energy: 1.3170592738430404, Validation Loss Force: 2.6466443551519565, time: 0.07550716400146484
Test Loss Energy: 10.072313841528073, Test Loss Force: 8.661329598735614, time: 14.645735025405884


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6138953477645368, Training Loss Force: 2.721132691012599, time: 1.2493324279785156
Validation Loss Energy: 1.1603504070022845, Validation Loss Force: 2.6199563446667815, time: 0.07611727714538574
Test Loss Energy: 9.841142492787762, Test Loss Force: 8.639883048571942, time: 14.763352870941162


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.49492384596712, Training Loss Force: 2.724517274066872, time: 1.2616243362426758
Validation Loss Energy: 1.4797557140177946, Validation Loss Force: 2.632917692982092, time: 0.07581257820129395
Test Loss Energy: 10.001347552591021, Test Loss Force: 8.646569712091205, time: 14.763978004455566


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.78732123012465, Training Loss Force: 2.722073720913716, time: 1.255429983139038
Validation Loss Energy: 2.584901095685078, Validation Loss Force: 2.6551144667939037, time: 0.07777142524719238
Test Loss Energy: 9.474133158262624, Test Loss Force: 8.659601201187481, time: 14.847391843795776


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.181793125214001, Training Loss Force: 2.7215370641996897, time: 1.313575029373169
Validation Loss Energy: 2.4807329065137242, Validation Loss Force: 2.6651205502044606, time: 0.07803082466125488
Test Loss Energy: 9.412654626762498, Test Loss Force: 8.640239249257004, time: 14.662870645523071


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.88323139700651, Training Loss Force: 2.7131808568530125, time: 1.5142793655395508
Validation Loss Energy: 1.3199617661602092, Validation Loss Force: 2.6269285609640725, time: 0.08158588409423828
Test Loss Energy: 9.846419998697344, Test Loss Force: 8.644532795366223, time: 14.72139859199524


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5397869306024843, Training Loss Force: 2.749802348571001, time: 1.3164122104644775
Validation Loss Energy: 1.2855171873112126, Validation Loss Force: 2.640423647222172, time: 0.07619428634643555
Test Loss Energy: 9.686717070642029, Test Loss Force: 8.576193573334127, time: 14.811029195785522


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7574130867765971, Training Loss Force: 2.73138555803578, time: 1.2910549640655518
Validation Loss Energy: 1.6197481400663136, Validation Loss Force: 2.6599655368070865, time: 0.07718849182128906
Test Loss Energy: 10.155526173384956, Test Loss Force: 8.66346304894729, time: 14.694987058639526


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6857567022495017, Training Loss Force: 2.7391577764297095, time: 1.2891640663146973
Validation Loss Energy: 2.7700075153788695, Validation Loss Force: 2.6276562437329645, time: 0.07509517669677734
Test Loss Energy: 10.927023855562625, Test Loss Force: 8.613731655572964, time: 14.798107147216797


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5504223537500175, Training Loss Force: 2.720495875309501, time: 1.268233299255371
Validation Loss Energy: 1.1688919954400745, Validation Loss Force: 2.6189042329522727, time: 0.07737278938293457
Test Loss Energy: 9.651064168346199, Test Loss Force: 8.605037206515204, time: 14.960382223129272


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.712993107723544, Training Loss Force: 2.7051292970064735, time: 1.266157865524292
Validation Loss Energy: 1.6242944873532943, Validation Loss Force: 2.62210153921865, time: 0.07797455787658691
Test Loss Energy: 10.175181922680897, Test Loss Force: 8.575688993391383, time: 14.881528615951538


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.236831436053116, Training Loss Force: 2.745393896675243, time: 1.269923210144043
Validation Loss Energy: 2.760974496136017, Validation Loss Force: 2.656362304687683, time: 0.07779788970947266
Test Loss Energy: 10.95723078816739, Test Loss Force: 8.566204005912, time: 14.748081684112549

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÇ‚ñÖ‚ñà
wandb:   test_error_force ‚ñà‚ñà‚ñà‚ñá‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÇ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÖ‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÜ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÖ‚ñÅ‚ñÑ‚ñÜ‚ñÅ‚ñÇ‚ñà
wandb: train_error_energy ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÑ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb: valid_error_energy ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñá‚ñá‚ñÇ‚ñÇ‚ñÉ‚ñà‚ñÅ‚ñÉ‚ñà
wandb:  valid_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:  valid_error_total ‚ñÜ‚ñá‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñà‚ñá‚ñÑ‚ñÇ‚ñÉ‚ñá‚ñÇ‚ñÖ‚ñà
wandb: 
wandb: Run summary:
wandb:       dataset_size 1159
wandb:                 lr 0.0001
wandb:  test_error_energy 10.95723
wandb:   test_error_force 8.5662
wandb:   test_error_total 4.77527
wandb: train_error_energy 2.23683
wandb:  train_error_force 2.74539
wandb:  train_error_total 1.31496
wandb: valid_error_energy 2.76097
wandb:  valid_error_force 2.65636
wandb:  valid_error_total 1.3979
wandb: 
wandb: üöÄ View run al_40_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ilbq0uhg
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_051632-ilbq0uhg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0495526790618896, Uncertainty Bias: -0.005048409104347229
Found uncertainty sample after 3352 steps.
Found uncertainty sample after 2895 steps.
Found uncertainty sample after 1293 steps.
Found uncertainty sample after 3924 steps.
Found uncertainty sample after 1378 steps.
Found uncertainty sample after 3993 steps.
Found uncertainty sample after 1610 steps.
Found uncertainty sample after 402 steps.
Found uncertainty sample after 2087 steps.
Found uncertainty sample after 2071 steps.
Found uncertainty sample after 538 steps.
Found uncertainty sample after 1717 steps.
Found uncertainty sample after 2321 steps.
Found uncertainty sample after 792 steps.
Found uncertainty sample after 473 steps.
Found uncertainty sample after 93 steps.
Found uncertainty sample after 487 steps.
Found uncertainty sample after 1256 steps.
Found uncertainty sample after 3718 steps.
Found uncertainty sample after 3090 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 274 steps.
Found uncertainty sample after 1023 steps.
Found uncertainty sample after 1955 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_055000-q9pdcv0p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_19
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q9pdcv0p
Training model 19. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.9145140076281932, Training Loss Force: 2.9875634374916973, time: 1.231410026550293
Validation Loss Energy: 1.9152403394932007, Validation Loss Force: 2.6514239483692967, time: 0.08351325988769531
Test Loss Energy: 10.56173318176516, Test Loss Force: 8.509000241701186, time: 14.770192384719849


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5569504669674041, Training Loss Force: 2.7611660517823657, time: 1.2505168914794922
Validation Loss Energy: 1.3422580730802505, Validation Loss Force: 2.6391522063989243, time: 0.07731461524963379
Test Loss Energy: 9.625339017719648, Test Loss Force: 8.600325532050599, time: 14.847769975662231


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.514542693318814, Training Loss Force: 2.7253248529325576, time: 1.2614004611968994
Validation Loss Energy: 1.321504195334051, Validation Loss Force: 2.62933405574753, time: 0.07890772819519043
Test Loss Energy: 9.629544200317953, Test Loss Force: 8.632404820720854, time: 14.743114709854126


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6594779125189043, Training Loss Force: 2.7371469717345356, time: 1.3174052238464355
Validation Loss Energy: 2.299896390362244, Validation Loss Force: 2.655808526521761, time: 0.07703661918640137
Test Loss Energy: 9.372108212082141, Test Loss Force: 8.588725737945829, time: 15.131804704666138


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8126184882419127, Training Loss Force: 2.7380707658401398, time: 1.2680535316467285
Validation Loss Energy: 1.7416574934394642, Validation Loss Force: 2.654340246173513, time: 0.07611560821533203
Test Loss Energy: 10.252494785905535, Test Loss Force: 8.562004810898689, time: 14.704509973526001


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7413246241295994, Training Loss Force: 2.718555879402733, time: 1.295844554901123
Validation Loss Energy: 1.3587054182096334, Validation Loss Force: 2.647763044941098, time: 0.07880878448486328
Test Loss Energy: 9.97721939906875, Test Loss Force: 8.565826608523217, time: 14.941611766815186


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6229178684580634, Training Loss Force: 2.7143737616666828, time: 1.2673673629760742
Validation Loss Energy: 2.2894100096039205, Validation Loss Force: 2.634435628549882, time: 0.07935333251953125
Test Loss Energy: 10.645311880144558, Test Loss Force: 8.535099192035975, time: 14.749897480010986


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5666429404446982, Training Loss Force: 2.7402215873015066, time: 1.284419059753418
Validation Loss Energy: 2.2827931732635305, Validation Loss Force: 2.6443720165177638, time: 0.07757353782653809
Test Loss Energy: 9.410186072310074, Test Loss Force: 8.584946042276986, time: 14.891138553619385


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.91599553995587, Training Loss Force: 2.720682104950602, time: 1.2802705764770508
Validation Loss Energy: 1.8863102733776789, Validation Loss Force: 2.6487044900900805, time: 0.07738614082336426
Test Loss Energy: 9.391145682605686, Test Loss Force: 8.554027267889483, time: 14.777063369750977


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5756899457171492, Training Loss Force: 2.733038683865573, time: 1.2347228527069092
Validation Loss Energy: 2.3800771004502352, Validation Loss Force: 2.632930830461702, time: 0.07847070693969727
Test Loss Energy: 10.662192341827621, Test Loss Force: 8.54391335548775, time: 14.848065853118896


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7105632878404151, Training Loss Force: 2.738066583271048, time: 1.2604548931121826
Validation Loss Energy: 1.3245707948117684, Validation Loss Force: 2.6362626288922195, time: 0.0757603645324707
Test Loss Energy: 9.582070779337576, Test Loss Force: 8.57962264087559, time: 14.756296634674072


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6009366805061054, Training Loss Force: 2.724378045669817, time: 1.2880604267120361
Validation Loss Energy: 1.1981605186574065, Validation Loss Force: 2.6369869716239225, time: 0.07831692695617676
Test Loss Energy: 9.812788484576632, Test Loss Force: 8.563953340796614, time: 14.866122722625732


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3340304014980595, Training Loss Force: 2.7082856682585104, time: 1.2869822978973389
Validation Loss Energy: 1.2021194647374296, Validation Loss Force: 2.6397458423419677, time: 0.07926535606384277
Test Loss Energy: 9.801375830482232, Test Loss Force: 8.542845133485661, time: 14.856127738952637


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9566940570956382, Training Loss Force: 2.750286178534678, time: 1.389932632446289
Validation Loss Energy: 1.5197701388830287, Validation Loss Force: 2.6466592739847337, time: 0.07761168479919434
Test Loss Energy: 10.039905991126219, Test Loss Force: 8.509626741744876, time: 14.742849349975586


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0585795399768223, Training Loss Force: 2.7307046779141277, time: 1.2811949253082275
Validation Loss Energy: 2.2959867654980437, Validation Loss Force: 2.630367017915489, time: 0.07751703262329102
Test Loss Energy: 10.658060213362095, Test Loss Force: 8.528962719494352, time: 15.220852136611938


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.063141006197907, Training Loss Force: 2.730998799783558, time: 1.2357876300811768
Validation Loss Energy: 1.195547162226225, Validation Loss Force: 2.628925903203045, time: 0.07736468315124512
Test Loss Energy: 9.587367208627144, Test Loss Force: 8.524164164425398, time: 14.76630449295044


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6092008562875368, Training Loss Force: 2.735619389176451, time: 1.27836012840271
Validation Loss Energy: 1.206108248483007, Validation Loss Force: 2.643088106222344, time: 0.08316922187805176
Test Loss Energy: 9.658255649632842, Test Loss Force: 8.540222792762474, time: 14.953181505203247


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6028548262506686, Training Loss Force: 2.7279334520675262, time: 1.2495670318603516
Validation Loss Energy: 1.175544458843813, Validation Loss Force: 2.636461917777825, time: 0.07889652252197266
Test Loss Energy: 9.570914789322588, Test Loss Force: 8.54073857844255, time: 14.796249151229858


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4391933771150163, Training Loss Force: 2.7219179006562464, time: 1.268815040588379
Validation Loss Energy: 1.2202659981193877, Validation Loss Force: 2.6453836024477133, time: 0.07899355888366699
Test Loss Energy: 9.705423773727043, Test Loss Force: 8.534145785706693, time: 15.047297239303589


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.38128291864795, Training Loss Force: 2.7149419832366655, time: 1.2919001579284668
Validation Loss Energy: 1.469628053253561, Validation Loss Force: 2.6138271537559734, time: 0.0798943042755127
Test Loss Energy: 10.138992017016742, Test Loss Force: 8.507773024602448, time: 14.810046195983887

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñá‚ñÇ‚ñÇ‚ñÅ‚ñÜ‚ñÑ‚ñà‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÖ
wandb:   test_error_force ‚ñÅ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ
wandb:   test_error_total ‚ñá‚ñá‚ñÜ‚ñÉ‚ñÖ‚ñÖ‚ñÜ‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÖ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñÇ‚ñá‚ñá‚ñÖ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ
wandb:  valid_error_force ‚ñá‚ñÖ‚ñÑ‚ñà‚ñà‚ñá‚ñÑ‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÑ‚ñÜ‚ñÖ‚ñÜ‚ñÅ
wandb:  valid_error_total ‚ñÖ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÖ‚ñÜ‚ñÇ‚ñÑ‚ñÅ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1180
wandb:                 lr 0.0001
wandb:  test_error_energy 10.13899
wandb:   test_error_force 8.50777
wandb:   test_error_total 4.65827
wandb: train_error_energy 1.38128
wandb:  train_error_force 2.71494
wandb:  train_error_total 1.21959
wandb: valid_error_energy 1.46963
wandb:  valid_error_force 2.61383
wandb:  valid_error_total 1.29608
wandb: 
wandb: üöÄ View run al_40_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q9pdcv0p
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_055000-q9pdcv0p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6373385787010193, Uncertainty Bias: 0.03515267372131348
Found uncertainty sample after 2176 steps.
Found uncertainty sample after 3851 steps.
Found uncertainty sample after 425 steps.
Found uncertainty sample after 1631 steps.
Found uncertainty sample after 1616 steps.
Found uncertainty sample after 1570 steps.
Found uncertainty sample after 470 steps.
Found uncertainty sample after 1159 steps.
Found uncertainty sample after 1406 steps.
Found uncertainty sample after 757 steps.
Found uncertainty sample after 2120 steps.
Found uncertainty sample after 2708 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_063512-eqzlcq7t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_20
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eqzlcq7t
Training model 20. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.248444304378047, Training Loss Force: 3.1324000737283235, time: 1.3164846897125244
Validation Loss Energy: 1.5858911850934205, Validation Loss Force: 2.6643474429297993, time: 0.07992100715637207
Test Loss Energy: 9.401614424703391, Test Loss Force: 8.5161989976238, time: 14.690526962280273


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6111849732303694, Training Loss Force: 2.7906884514006345, time: 1.3174901008605957
Validation Loss Energy: 1.1709060378649911, Validation Loss Force: 2.6493148262190687, time: 0.07839703559875488
Test Loss Energy: 9.516577702670661, Test Loss Force: 8.50104699877406, time: 14.857752799987793


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6745791574124427, Training Loss Force: 2.7461153211108207, time: 1.3117225170135498
Validation Loss Energy: 1.16016993365951, Validation Loss Force: 2.659515077124875, time: 0.07815313339233398
Test Loss Energy: 9.63310306415277, Test Loss Force: 8.526899231695163, time: 15.014144897460938


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5618801499583046, Training Loss Force: 2.720173211246503, time: 1.2814359664916992
Validation Loss Energy: 1.245706838718221, Validation Loss Force: 2.634875845451381, time: 0.07994818687438965
Test Loss Energy: 9.84476115786085, Test Loss Force: 8.539676612161076, time: 14.84735655784607


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4891144630628532, Training Loss Force: 2.7247680418101528, time: 1.284289836883545
Validation Loss Energy: 1.6837323418178094, Validation Loss Force: 2.6784426225361746, time: 0.07787823677062988
Test Loss Energy: 10.14168898571222, Test Loss Force: 8.52776247450745, time: 14.656616687774658


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.472786358726043, Training Loss Force: 2.728942496465148, time: 1.2786386013031006
Validation Loss Energy: 1.1524106932659373, Validation Loss Force: 2.631207816610513, time: 0.08036494255065918
Test Loss Energy: 9.508436566621812, Test Loss Force: 8.52933655184519, time: 14.841627597808838


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6070492556821228, Training Loss Force: 2.74198796098019, time: 1.3050956726074219
Validation Loss Energy: 1.5807244815658852, Validation Loss Force: 2.6325226779172164, time: 0.07966160774230957
Test Loss Energy: 9.404051054695648, Test Loss Force: 8.51003690064329, time: 14.723309755325317


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5712022142615714, Training Loss Force: 2.7387906078360977, time: 1.3054604530334473
Validation Loss Energy: 2.697219420935681, Validation Loss Force: 2.6453956265815934, time: 0.07835650444030762
Test Loss Energy: 10.786866979023383, Test Loss Force: 8.51879893853039, time: 14.849680185317993


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1003636175852245, Training Loss Force: 2.7468854164922973, time: 1.2857601642608643
Validation Loss Energy: 1.7418519949384321, Validation Loss Force: 2.6597807214159666, time: 0.07809615135192871
Test Loss Energy: 9.222250720392148, Test Loss Force: 8.523206178806035, time: 14.692836046218872


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.570647630384924, Training Loss Force: 2.7505241760599053, time: 1.3022148609161377
Validation Loss Energy: 2.3759325596370813, Validation Loss Force: 2.644691769411316, time: 0.07824301719665527
Test Loss Energy: 10.587719715658048, Test Loss Force: 8.491518218918776, time: 14.843530654907227


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6876574626966516, Training Loss Force: 2.7533722726486096, time: 1.308983564376831
Validation Loss Energy: 1.9068918052049302, Validation Loss Force: 2.661410214225866, time: 0.08353304862976074
Test Loss Energy: 10.479872043591595, Test Loss Force: 8.487380825668625, time: 14.673244953155518


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.649744688845828, Training Loss Force: 2.7385051401313034, time: 1.2747166156768799
Validation Loss Energy: 1.1802707228007032, Validation Loss Force: 2.640396481586369, time: 0.07941746711730957
Test Loss Energy: 9.737142520246797, Test Loss Force: 8.500954662192731, time: 14.795113801956177


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5670265671547028, Training Loss Force: 2.7328732690384965, time: 1.278169870376587
Validation Loss Energy: 1.1850156909658514, Validation Loss Force: 2.632261041670751, time: 0.08474397659301758
Test Loss Energy: 9.56393608647489, Test Loss Force: 8.48820869789511, time: 14.679747343063354


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6805065778486112, Training Loss Force: 2.718511214601012, time: 1.5240757465362549
Validation Loss Energy: 1.234237151011481, Validation Loss Force: 2.6591570251382226, time: 0.07892346382141113
Test Loss Energy: 9.801614564449265, Test Loss Force: 8.503333244320514, time: 14.70614242553711


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.473901236770989, Training Loss Force: 2.7437277043158956, time: 1.3050510883331299
Validation Loss Energy: 1.3426467420744672, Validation Loss Force: 2.6475319143676246, time: 0.07747054100036621
Test Loss Energy: 10.002689932773063, Test Loss Force: 8.49077909258791, time: 14.834072828292847


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5405928155356055, Training Loss Force: 2.742917657401867, time: 1.2544782161712646
Validation Loss Energy: 1.2124299368704698, Validation Loss Force: 2.6537544036505767, time: 0.079071044921875
Test Loss Energy: 9.766014617772726, Test Loss Force: 8.553299650405783, time: 14.985912322998047


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4989611827516411, Training Loss Force: 2.738417332311522, time: 1.309577226638794
Validation Loss Energy: 1.2223933791395818, Validation Loss Force: 2.6390695961457853, time: 0.07764148712158203
Test Loss Energy: 9.496828520934764, Test Loss Force: 8.52375772211985, time: 14.815526962280273


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5078177967584183, Training Loss Force: 2.731992805936926, time: 1.2962417602539062
Validation Loss Energy: 1.9742841809039968, Validation Loss Force: 2.6497715206373664, time: 0.08607935905456543
Test Loss Energy: 10.419303979415604, Test Loss Force: 8.493923344141397, time: 14.712570190429688


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5541064712285324, Training Loss Force: 2.7438009155871903, time: 1.3131599426269531
Validation Loss Energy: 3.2953379165558356, Validation Loss Force: 2.6570185106607322, time: 0.08004641532897949
Test Loss Energy: 10.950985695051608, Test Loss Force: 8.487141602062632, time: 14.895201444625854


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9884340213909106, Training Loss Force: 2.740658526563857, time: 1.3151142597198486
Validation Loss Energy: 2.3626942109042366, Validation Loss Force: 2.6507828838981706, time: 0.08305954933166504
Test Loss Energy: 10.511318606808528, Test Loss Force: 8.432898253292102, time: 14.770455598831177

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÇ‚ñá‚ñÅ‚ñá‚ñÜ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÇ‚ñÜ‚ñà‚ñÜ
wandb:   test_error_force ‚ñÜ‚ñÖ‚ñÜ‚ñá‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÖ‚ñÑ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÅ
wandb:   test_error_total ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñà‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÖ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: valid_error_energy ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñÖ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñà‚ñÖ
wandb:  valid_error_force ‚ñÜ‚ñÑ‚ñÖ‚ñÇ‚ñà‚ñÅ‚ñÅ‚ñÉ‚ñÖ‚ñÉ‚ñÖ‚ñÇ‚ñÅ‚ñÖ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÖ‚ñÑ
wandb:  valid_error_total ‚ñÜ‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñà‚ñÑ‚ñá‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÖ‚ñá‚ñá
wandb: 
wandb: Run summary:
wandb:       dataset_size 1190
wandb:                 lr 0.0001
wandb:  test_error_energy 10.51132
wandb:   test_error_force 8.4329
wandb:   test_error_total 4.63036
wandb: train_error_energy 1.98843
wandb:  train_error_force 2.74066
wandb:  train_error_total 1.27489
wandb: valid_error_energy 2.36269
wandb:  valid_error_force 2.65078
wandb:  valid_error_total 1.40261
wandb: 
wandb: üöÄ View run al_40_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eqzlcq7t
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_063512-eqzlcq7t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0302133560180664, Uncertainty Bias: -0.00010116398334503174
Found uncertainty sample after 1935 steps.
Found uncertainty sample after 2025 steps.
Found uncertainty sample after 767 steps.
Found uncertainty sample after 1967 steps.
Found uncertainty sample after 2868 steps.
Found uncertainty sample after 3615 steps.
Found uncertainty sample after 1812 steps.
Found uncertainty sample after 754 steps.
Found uncertainty sample after 1065 steps.
Found uncertainty sample after 935 steps.
Found uncertainty sample after 1337 steps.
Found uncertainty sample after 1063 steps.
Found uncertainty sample after 1749 steps.
Found uncertainty sample after 47 steps.
Found uncertainty sample after 2537 steps.
Found uncertainty sample after 407 steps.
Found uncertainty sample after 532 steps.
Found uncertainty sample after 3725 steps.
Found uncertainty sample after 468 steps.
Found uncertainty sample after 92 steps.
Found uncertainty sample after 2018 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_070954-qfmk9cqf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_21
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qfmk9cqf
Training model 21. Added 21 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.3351034471234953, Training Loss Force: 2.965465583418555, time: 1.3042161464691162
Validation Loss Energy: 2.467190837065834, Validation Loss Force: 2.65492163531353, time: 0.0799112319946289
Test Loss Energy: 10.50088436327295, Test Loss Force: 8.489086415367693, time: 14.70008373260498


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7313179834918808, Training Loss Force: 2.7516701428194232, time: 1.3299198150634766
Validation Loss Energy: 1.5676162829488351, Validation Loss Force: 2.645298320164823, time: 0.07852649688720703
Test Loss Energy: 10.116208220885264, Test Loss Force: 8.483848826691391, time: 15.172396421432495


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4882432378009816, Training Loss Force: 2.7443074117178896, time: 1.2894468307495117
Validation Loss Energy: 1.4643391043649112, Validation Loss Force: 2.6265805290889874, time: 0.07863473892211914
Test Loss Energy: 9.376649175089277, Test Loss Force: 8.451926852024021, time: 14.65965747833252


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5272857279584557, Training Loss Force: 2.736682909596461, time: 1.3115484714508057
Validation Loss Energy: 1.1767537749753467, Validation Loss Force: 2.627404850267212, time: 0.07883358001708984
Test Loss Energy: 9.447123232311824, Test Loss Force: 8.446678803726895, time: 14.801028728485107


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.452758354561925, Training Loss Force: 2.738220926405384, time: 1.3353228569030762
Validation Loss Energy: 1.178602819563131, Validation Loss Force: 2.6287780508901486, time: 0.07763814926147461
Test Loss Energy: 9.60678248457194, Test Loss Force: 8.45817748039166, time: 14.669957876205444


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5373578928328526, Training Loss Force: 2.74503612579651, time: 1.283540964126587
Validation Loss Energy: 1.96213735632449, Validation Loss Force: 2.6659290618733245, time: 0.07982993125915527
Test Loss Energy: 10.344354734019502, Test Loss Force: 8.462218839120528, time: 14.87544322013855


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7933121500682188, Training Loss Force: 2.7574694962682536, time: 1.3249576091766357
Validation Loss Energy: 1.675250762714847, Validation Loss Force: 2.654423301764944, time: 0.08059144020080566
Test Loss Energy: 10.123715248833632, Test Loss Force: 8.487880705077355, time: 14.652616739273071


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7589514266616648, Training Loss Force: 2.7689138934477886, time: 1.2930526733398438
Validation Loss Energy: 1.2044263170892415, Validation Loss Force: 2.6220783816274733, time: 0.07889199256896973
Test Loss Energy: 9.711542861753985, Test Loss Force: 8.47314827552051, time: 14.828659534454346


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5317677370466207, Training Loss Force: 2.7430688907699525, time: 1.3180367946624756
Validation Loss Energy: 1.1809989622424601, Validation Loss Force: 2.6362989239630057, time: 0.07811212539672852
Test Loss Energy: 9.363040061243934, Test Loss Force: 8.48304274106699, time: 14.670468091964722


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8315634718464253, Training Loss Force: 2.758656076708046, time: 1.260740041732788
Validation Loss Energy: 1.1852087451153708, Validation Loss Force: 2.635777210154097, time: 0.07882380485534668
Test Loss Energy: 9.505408287221721, Test Loss Force: 8.48477636609392, time: 14.803081512451172


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4504499215521627, Training Loss Force: 2.7401663632944975, time: 1.2859642505645752
Validation Loss Energy: 1.2815124827217013, Validation Loss Force: 2.6223845517031243, time: 0.07872700691223145
Test Loss Energy: 9.347741133400483, Test Loss Force: 8.452920660562315, time: 14.761616468429565


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4844228871500842, Training Loss Force: 2.7511863648013235, time: 1.3206102848052979
Validation Loss Energy: 1.401694034857025, Validation Loss Force: 2.6375973077529107, time: 0.07959127426147461
Test Loss Energy: 9.335652371840938, Test Loss Force: 8.482761371204646, time: 14.85540223121643


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5437797647568399, Training Loss Force: 2.750229573060414, time: 1.3041226863861084
Validation Loss Energy: 1.6164498533422582, Validation Loss Force: 2.641617153844345, time: 0.07980608940124512
Test Loss Energy: 9.287881558146168, Test Loss Force: 8.438961175067146, time: 14.687195777893066


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.578075793986931, Training Loss Force: 2.739753224133086, time: 1.5314249992370605
Validation Loss Energy: 1.6340900370863765, Validation Loss Force: 2.626921435551403, time: 0.07852411270141602
Test Loss Energy: 9.26245840750346, Test Loss Force: 8.47321432082132, time: 14.691545724868774


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.812563742078773, Training Loss Force: 2.7320935871643157, time: 1.2870492935180664
Validation Loss Energy: 1.6447212641241258, Validation Loss Force: 2.6281570266421563, time: 0.07803702354431152
Test Loss Energy: 10.080641942716234, Test Loss Force: 8.403298503308264, time: 15.153142213821411


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0066979937032743, Training Loss Force: 2.7422280451972143, time: 1.3210041522979736
Validation Loss Energy: 2.3457335020589167, Validation Loss Force: 2.660047701721934, time: 0.07905983924865723
Test Loss Energy: 10.4319446713369, Test Loss Force: 8.421226204798188, time: 14.722365379333496


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.443375703741965, Training Loss Force: 2.742900113417054, time: 1.3160464763641357
Validation Loss Energy: 1.3738845512183848, Validation Loss Force: 2.631696575385824, time: 0.07918667793273926
Test Loss Energy: 9.306930752025373, Test Loss Force: 8.416023790852101, time: 14.860146522521973


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5596582927633786, Training Loss Force: 2.7360238089245144, time: 1.292973518371582
Validation Loss Energy: 2.293682362506837, Validation Loss Force: 2.6287845082953805, time: 0.07934093475341797
Test Loss Energy: 10.494384200901797, Test Loss Force: 8.406232401301466, time: 14.719018697738647


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5207377476566577, Training Loss Force: 2.7363764992725206, time: 1.3037850856781006
Validation Loss Energy: 2.2507000919301046, Validation Loss Force: 2.6203233034192706, time: 0.08018898963928223
Test Loss Energy: 10.481561036861546, Test Loss Force: 8.450384554586375, time: 14.935006618499756


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.59365258186188, Training Loss Force: 2.727217009814496, time: 1.3042683601379395
Validation Loss Energy: 1.2586293312675674, Validation Loss Force: 2.6206561937924326, time: 0.08258819580078125
Test Loss Energy: 9.335423062258073, Test Loss Force: 8.431830516265746, time: 14.756074905395508

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñà‚ñÜ‚ñÇ‚ñÇ‚ñÉ‚ñá‚ñÜ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÜ‚ñà‚ñÅ‚ñà‚ñà‚ñÅ
wandb:   test_error_force ‚ñà‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñà‚ñá‚ñà‚ñà‚ñÖ‚ñá‚ñÑ‚ñá‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÖ‚ñÉ
wandb:   test_error_total ‚ñá‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñá‚ñÜ‚ñÑ‚ñÖ‚ñá‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñÜ‚ñÅ‚ñÜ‚ñÜ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñà‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÖ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñá‚ñÇ‚ñá‚ñá‚ñÅ
wandb:  valid_error_force ‚ñÜ‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñà‚ñÜ‚ñÅ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñá‚ñÉ‚ñÇ‚ñÅ‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÜ‚ñÑ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÜ‚ñÖ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1208
wandb:                 lr 0.0001
wandb:  test_error_energy 9.33542
wandb:   test_error_force 8.43183
wandb:   test_error_total 4.56957
wandb: train_error_energy 1.59365
wandb:  train_error_force 2.72722
wandb:  train_error_total 1.23097
wandb: valid_error_energy 1.25863
wandb:  valid_error_force 2.62066
wandb:  valid_error_total 1.27828
wandb: 
wandb: üöÄ View run al_40_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qfmk9cqf
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_070954-qfmk9cqf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6346033811569214, Uncertainty Bias: 0.03516368567943573
Found uncertainty sample after 2898 steps.
Found uncertainty sample after 1306 steps.
Found uncertainty sample after 750 steps.
Found uncertainty sample after 611 steps.
Found uncertainty sample after 1259 steps.
Found uncertainty sample after 740 steps.
Found uncertainty sample after 2555 steps.
Found uncertainty sample after 1267 steps.
Found uncertainty sample after 2971 steps.
Found uncertainty sample after 3952 steps.
Found uncertainty sample after 3209 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_075731-ge7f65tn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_22
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ge7f65tn
Training model 22. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.116328204154968, Training Loss Force: 3.2028400285727723, time: 1.3650496006011963
Validation Loss Energy: 1.5977669099877603, Validation Loss Force: 3.4588000045888627, time: 0.11305737495422363
Test Loss Energy: 9.219540461496342, Test Loss Force: 8.460719732502351, time: 14.87460732460022


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6661138968627456, Training Loss Force: 2.798424237761584, time: 1.3287546634674072
Validation Loss Energy: 0.6295165708818536, Validation Loss Force: 2.4282220665098766, time: 0.11183619499206543
Test Loss Energy: 9.51386322355334, Test Loss Force: 8.4721579550769, time: 15.325705766677856


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.709558931019369, Training Loss Force: 2.805562982032702, time: 1.3152046203613281
Validation Loss Energy: 1.8832587040673117, Validation Loss Force: 3.3457308389781915, time: 0.10718750953674316
Test Loss Energy: 9.148674623157664, Test Loss Force: 8.416133549253937, time: 14.935117721557617


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.050301554619132, Training Loss Force: 2.780067090769637, time: 1.3291268348693848
Validation Loss Energy: 1.4135886309614822, Validation Loss Force: 3.4827420591664557, time: 0.10349678993225098
Test Loss Energy: 9.097566630832855, Test Loss Force: 8.418343392469778, time: 15.02063775062561


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.880648242335027, Training Loss Force: 2.7474769776457086, time: 1.3181722164154053
Validation Loss Energy: 1.8652300739981222, Validation Loss Force: 2.224628596642717, time: 0.10961318016052246
Test Loss Energy: 9.09497756690601, Test Loss Force: 8.374526641872212, time: 14.940008640289307


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9116502933838622, Training Loss Force: 2.751700400431173, time: 1.331890344619751
Validation Loss Energy: 2.294465712562211, Validation Loss Force: 3.4757562600512637, time: 0.11489319801330566
Test Loss Energy: 9.097699169104384, Test Loss Force: 8.416081458663475, time: 15.067241668701172


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.785454810168074, Training Loss Force: 2.753126824689452, time: 1.351813793182373
Validation Loss Energy: 0.8309954632047101, Validation Loss Force: 2.8260792803643944, time: 0.11736178398132324
Test Loss Energy: 9.214940266164774, Test Loss Force: 8.443504175905, time: 14.920714855194092


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7193289094848274, Training Loss Force: 2.7817671582798646, time: 1.3418593406677246
Validation Loss Energy: 1.9951393731115934, Validation Loss Force: 2.0434061391940572, time: 0.10359883308410645
Test Loss Energy: 10.422463796824777, Test Loss Force: 8.401463989339511, time: 15.049210786819458


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8949208664128456, Training Loss Force: 2.876620828732191, time: 1.321336030960083
Validation Loss Energy: 3.2834918066579046, Validation Loss Force: 2.2509317235091557, time: 0.11730599403381348
Test Loss Energy: 9.021806445391807, Test Loss Force: 8.413760856783354, time: 14.908815145492554


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1509464841512616, Training Loss Force: 2.7704158220789177, time: 1.4901561737060547
Validation Loss Energy: 3.157351071504688, Validation Loss Force: 3.546938687283167, time: 0.1448507308959961
Test Loss Energy: 10.672082806324319, Test Loss Force: 8.409438272752215, time: 15.21570086479187


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.140993267534467, Training Loss Force: 2.779522139437038, time: 1.3032739162445068
Validation Loss Energy: 2.70910338458842, Validation Loss Force: 2.3723675152762045, time: 0.1204538345336914
Test Loss Energy: 9.01718436553036, Test Loss Force: 8.391199072282628, time: 15.053417205810547


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7651311235023412, Training Loss Force: 2.8022353115455823, time: 1.32419753074646
Validation Loss Energy: 3.0934848844005343, Validation Loss Force: 2.600257807337707, time: 0.10579848289489746
Test Loss Energy: 9.133571285094057, Test Loss Force: 8.372284151395839, time: 14.873297691345215


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7015812436294426, Training Loss Force: 2.7651950870267026, time: 1.3204193115234375
Validation Loss Energy: 1.8866035286428657, Validation Loss Force: 3.7788030669266157, time: 0.10984921455383301
Test Loss Energy: 9.21584447310507, Test Loss Force: 8.363785753777517, time: 15.05578064918518


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5472405031218863, Training Loss Force: 2.755578537594353, time: 1.3362934589385986
Validation Loss Energy: 1.9845287429698426, Validation Loss Force: 3.7608003778129273, time: 0.10809946060180664
Test Loss Energy: 9.78165349495101, Test Loss Force: 8.313156395193817, time: 14.855381727218628


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.526879313833461, Training Loss Force: 2.7319294042782274, time: 1.326183557510376
Validation Loss Energy: 0.8431347170332554, Validation Loss Force: 2.1783035055127433, time: 0.10370254516601562
Test Loss Energy: 9.790123740660768, Test Loss Force: 8.304263255309468, time: 15.001878023147583


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.500599952616251, Training Loss Force: 2.7514414847449142, time: 1.3069992065429688
Validation Loss Energy: 2.120276649758686, Validation Loss Force: 2.762384325833459, time: 0.11841583251953125
Test Loss Energy: 9.422598074857856, Test Loss Force: 8.382702866381555, time: 14.888076543807983


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4234873635784748, Training Loss Force: 2.762795981134894, time: 1.343738079071045
Validation Loss Energy: 1.7067097936552438, Validation Loss Force: 2.283278146663361, time: 0.10358119010925293
Test Loss Energy: 9.267102749616273, Test Loss Force: 8.322022826438726, time: 15.015783071517944


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5734437728679407, Training Loss Force: 2.7730947374451786, time: 1.3385088443756104
Validation Loss Energy: 2.7744107977395913, Validation Loss Force: 2.6767587984546686, time: 0.11391663551330566
Test Loss Energy: 10.745934439722687, Test Loss Force: 8.281217108291806, time: 15.26564335823059


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7452658583681544, Training Loss Force: 2.7495550973994654, time: 1.3351647853851318
Validation Loss Energy: 2.4411332029327806, Validation Loss Force: 3.3477402053510437, time: 0.11568713188171387
Test Loss Energy: 9.408810951602932, Test Loss Force: 8.340028902804788, time: 15.107634544372559


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.545806636575615, Training Loss Force: 2.7791904708894455, time: 1.3443365097045898
Validation Loss Energy: 1.6806738697639183, Validation Loss Force: 2.4852147910829583, time: 0.10965824127197266
Test Loss Energy: 10.088447393952428, Test Loss Force: 8.3130744669378, time: 14.872684717178345

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñá‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÑ‚ñÉ‚ñÇ‚ñà‚ñÉ‚ñÖ
wandb:   test_error_force ‚ñà‚ñà‚ñÜ‚ñÜ‚ñÑ‚ñÜ‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÖ‚ñÇ‚ñÅ‚ñÉ‚ñÇ
wandb:   test_error_total ‚ñÉ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÇ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÉ‚ñÉ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: valid_error_energy ‚ñÑ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñà‚ñà‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÇ‚ñÖ‚ñÑ‚ñá‚ñÜ‚ñÑ
wandb:  valid_error_force ‚ñá‚ñÉ‚ñÜ‚ñá‚ñÇ‚ñá‚ñÑ‚ñÅ‚ñÇ‚ñá‚ñÇ‚ñÉ‚ñà‚ñà‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÜ‚ñÉ
wandb:  valid_error_total ‚ñÜ‚ñÇ‚ñÜ‚ñÜ‚ñÅ‚ñÜ‚ñÑ‚ñÅ‚ñÉ‚ñà‚ñÇ‚ñÑ‚ñà‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÜ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1217
wandb:                 lr 0.0001
wandb:  test_error_energy 10.08845
wandb:   test_error_force 8.31307
wandb:   test_error_total 4.55951
wandb: train_error_energy 1.54581
wandb:  train_error_force 2.77919
wandb:  train_error_total 1.26386
wandb: valid_error_energy 1.68067
wandb:  valid_error_force 2.48521
wandb:  valid_error_total 1.24135
wandb: 
wandb: üöÄ View run al_40_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ge7f65tn
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_075731-ge7f65tn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.9871383905410767, Uncertainty Bias: 0.004903003573417664
Found uncertainty sample after 3117 steps.
Found uncertainty sample after 749 steps.
Found uncertainty sample after 1975 steps.
Found uncertainty sample after 438 steps.
Found uncertainty sample after 1712 steps.
Found uncertainty sample after 1373 steps.
Found uncertainty sample after 1792 steps.
Found uncertainty sample after 1413 steps.
Found uncertainty sample after 64 steps.
Found uncertainty sample after 124 steps.
Found uncertainty sample after 1125 steps.
Found uncertainty sample after 446 steps.
Found uncertainty sample after 2653 steps.
Found uncertainty sample after 285 steps.
Found uncertainty sample after 1479 steps.
Found uncertainty sample after 2246 steps.
Found uncertainty sample after 2120 steps.
Found uncertainty sample after 2469 steps.
Found uncertainty sample after 1685 steps.
Found uncertainty sample after 263 steps.
Found uncertainty sample after 675 steps.
Found uncertainty sample after 577 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_082921-aazycjpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_23
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/aazycjpu
Training model 23. Added 22 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.490995837083859, Training Loss Force: 3.1163230681061216, time: 1.316798448562622
Validation Loss Energy: 1.8160388412890525, Validation Loss Force: 2.617185895153148, time: 0.10904860496520996
Test Loss Energy: 10.108379509466873, Test Loss Force: 8.273068856156742, time: 14.751550912857056


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0057068054390346, Training Loss Force: 2.798088486946316, time: 1.3394732475280762
Validation Loss Energy: 1.2303381029317122, Validation Loss Force: 2.4916629555453085, time: 0.11336517333984375
Test Loss Energy: 9.677926852866996, Test Loss Force: 8.273967504529042, time: 14.915275812149048


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.735345545399769, Training Loss Force: 2.782033516254118, time: 1.3328800201416016
Validation Loss Energy: 1.5251923552555162, Validation Loss Force: 2.707664273898289, time: 0.10233521461486816
Test Loss Energy: 9.594514883548198, Test Loss Force: 8.309318250622882, time: 14.690294742584229


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4370000621095973, Training Loss Force: 2.7677718200928445, time: 1.3662705421447754
Validation Loss Energy: 1.8609640114985782, Validation Loss Force: 2.508464233282144, time: 0.10567235946655273
Test Loss Energy: 9.055296575097119, Test Loss Force: 8.371232507169955, time: 14.976206064224243


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5649375759780564, Training Loss Force: 2.7604695795739627, time: 1.3107333183288574
Validation Loss Energy: 1.1896465968609982, Validation Loss Force: 2.547405281529433, time: 0.11080169677734375
Test Loss Energy: 9.65854236355469, Test Loss Force: 8.310826184732019, time: 14.766030073165894


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8262077600767672, Training Loss Force: 2.765494628413164, time: 1.3353958129882812
Validation Loss Energy: 1.031772725048748, Validation Loss Force: 2.6870176113458535, time: 0.10758328437805176
Test Loss Energy: 9.338196022920084, Test Loss Force: 8.314882158018023, time: 14.85274887084961


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5235693084319182, Training Loss Force: 2.7766506951920635, time: 1.326941967010498
Validation Loss Energy: 1.1506101348846787, Validation Loss Force: 2.9247259427241774, time: 0.11309385299682617
Test Loss Energy: 9.350549912318197, Test Loss Force: 8.284063927493458, time: 15.031510591506958


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7295738155459566, Training Loss Force: 2.7828170718502414, time: 1.3270905017852783
Validation Loss Energy: 1.0122060356877058, Validation Loss Force: 2.50947303584777, time: 0.11230349540710449
Test Loss Energy: 9.363223009012167, Test Loss Force: 8.294354338418838, time: 14.930105686187744


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.803050794086725, Training Loss Force: 2.754805847110657, time: 1.3314075469970703
Validation Loss Energy: 1.4153319633722372, Validation Loss Force: 2.8280186172908524, time: 0.11069869995117188
Test Loss Energy: 9.12337917035563, Test Loss Force: 8.292761871640742, time: 14.714094877243042


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8778900439065187, Training Loss Force: 2.759505741902151, time: 1.3584003448486328
Validation Loss Energy: 0.859272106711507, Validation Loss Force: 2.6300211013972907, time: 0.10848355293273926
Test Loss Energy: 9.360723896425434, Test Loss Force: 8.306508268592292, time: 14.925206899642944


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5711088285195842, Training Loss Force: 2.7813730224726427, time: 1.3255507946014404
Validation Loss Energy: 1.3880762578995194, Validation Loss Force: 2.918940664309254, time: 0.10982227325439453
Test Loss Energy: 9.398912932676573, Test Loss Force: 8.265172873008527, time: 14.761616468429565


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.828555383720145, Training Loss Force: 2.7652953223991625, time: 1.5588860511779785
Validation Loss Energy: 1.834689274948245, Validation Loss Force: 2.9816821495573267, time: 0.10549759864807129
Test Loss Energy: 9.32152140079242, Test Loss Force: 8.270948957286176, time: 14.76754379272461


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9072560976371336, Training Loss Force: 2.7727198254075547, time: 1.3004968166351318
Validation Loss Energy: 1.0867440034478113, Validation Loss Force: 2.673396049012867, time: 0.1131443977355957
Test Loss Energy: 9.292804206380405, Test Loss Force: 8.304545606781348, time: 14.81867527961731


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4150675123593888, Training Loss Force: 2.7677665959321143, time: 1.3327958583831787
Validation Loss Energy: 1.5298526534779255, Validation Loss Force: 2.650586601046035, time: 0.10576820373535156
Test Loss Energy: 9.001707577500627, Test Loss Force: 8.251834375621332, time: 14.679547786712646


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.979987200197895, Training Loss Force: 2.77115339935114, time: 1.3602571487426758
Validation Loss Energy: 1.1482915367354192, Validation Loss Force: 2.635574247227584, time: 0.11025667190551758
Test Loss Energy: 9.463440651160365, Test Loss Force: 8.269418401857106, time: 14.909179925918579


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8245657977946952, Training Loss Force: 2.7824145488385215, time: 1.3170852661132812
Validation Loss Energy: 0.8910297648102361, Validation Loss Force: 2.426787409202664, time: 0.10426974296569824
Test Loss Energy: 9.239648884342074, Test Loss Force: 8.282824875121582, time: 14.789249181747437


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.584036765044075, Training Loss Force: 2.770701655039241, time: 1.3502063751220703
Validation Loss Energy: 1.6681598080954902, Validation Loss Force: 2.468480091420756, time: 0.10515379905700684
Test Loss Energy: 9.490935534189697, Test Loss Force: 8.25276260984486, time: 14.846437454223633


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3858487228667462, Training Loss Force: 2.7719023498782014, time: 1.3058242797851562
Validation Loss Energy: 1.4183415595485973, Validation Loss Force: 3.04983505172431, time: 0.10877156257629395
Test Loss Energy: 9.156772349215318, Test Loss Force: 8.269617792167923, time: 14.786386251449585


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7268989253527174, Training Loss Force: 2.758410717846596, time: 1.315016269683838
Validation Loss Energy: 1.282709774719355, Validation Loss Force: 2.581741420504363, time: 0.10504579544067383
Test Loss Energy: 9.687138043566609, Test Loss Force: 8.237860996037778, time: 15.153991460800171


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.540451923211135, Training Loss Force: 2.749184113473953, time: 1.319753646850586
Validation Loss Energy: 0.9655667862264713, Validation Loss Force: 2.772926151209118, time: 0.10607409477233887
Test Loss Energy: 9.239837166843353, Test Loss Force: 8.260385017716647, time: 14.730722427368164

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñà‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÑ‚ñÇ‚ñÖ‚ñÉ
wandb:   test_error_force ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ
wandb:   test_error_total ‚ñà‚ñÑ‚ñÑ‚ñÉ‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñà‚ñÑ‚ñÜ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñÖ‚ñà‚ñÉ‚ñÜ‚ñÉ‚ñÅ‚ñá‚ñÖ‚ñÑ‚ñÇ
wandb:  valid_error_force ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÑ‚ñá‚ñÇ‚ñÜ‚ñÉ‚ñá‚ñá‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÅ‚ñà‚ñÉ‚ñÖ
wandb:  valid_error_total ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÖ‚ñÅ‚ñÜ‚ñÉ‚ñÜ‚ñà‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñà‚ñÉ‚ñÉ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1236
wandb:                 lr 0.0001
wandb:  test_error_energy 9.23984
wandb:   test_error_force 8.26039
wandb:   test_error_total 4.48207
wandb: train_error_energy 1.54045
wandb:  train_error_force 2.74918
wandb:  train_error_total 1.24598
wandb: valid_error_energy 0.96557
wandb:  valid_error_force 2.77293
wandb:  valid_error_total 1.30451
wandb: 
wandb: üöÄ View run al_40_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/aazycjpu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_082921-aazycjpu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6322667002677917, Uncertainty Bias: 0.038228362798690796
Found uncertainty sample after 1289 steps.
Found uncertainty sample after 1943 steps.
Found uncertainty sample after 3832 steps.
Found uncertainty sample after 1428 steps.
Found uncertainty sample after 2135 steps.
Found uncertainty sample after 3089 steps.
Found uncertainty sample after 989 steps.
Found uncertainty sample after 1368 steps.
Found uncertainty sample after 1336 steps.
Found uncertainty sample after 518 steps.
Found uncertainty sample after 818 steps.
Found uncertainty sample after 1369 steps.
Found uncertainty sample after 1422 steps.
Found uncertainty sample after 2399 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_091253-9edbi3ef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_24
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9edbi3ef
Training model 24. Added 14 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8663102256662762, Training Loss Force: 3.1354398366157366, time: 1.310741662979126
Validation Loss Energy: 1.8126799328900183, Validation Loss Force: 2.9763494461815023, time: 0.1197047233581543
Test Loss Energy: 9.50182281034364, Test Loss Force: 8.265144511254695, time: 14.865275144577026


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7279051586589669, Training Loss Force: 2.790812081757826, time: 1.3465616703033447
Validation Loss Energy: 1.0998905011579607, Validation Loss Force: 2.4764992980421994, time: 0.11858725547790527
Test Loss Energy: 9.265840497684168, Test Loss Force: 8.273332293575097, time: 15.076136112213135


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.484045741997852, Training Loss Force: 2.768150488958624, time: 1.3560171127319336
Validation Loss Energy: 1.594916577918025, Validation Loss Force: 2.5829644307883712, time: 0.11699223518371582
Test Loss Energy: 9.016690343136233, Test Loss Force: 8.225195885122082, time: 14.994868993759155


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7666478772108183, Training Loss Force: 2.7668323389999188, time: 1.3651323318481445
Validation Loss Energy: 1.0425464046726045, Validation Loss Force: 2.574580603440471, time: 0.11114645004272461
Test Loss Energy: 9.22871456554218, Test Loss Force: 8.238430271276775, time: 14.983895540237427


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6804365158732897, Training Loss Force: 2.7732577598073247, time: 1.3467929363250732
Validation Loss Energy: 1.8350327977731253, Validation Loss Force: 2.932351804299339, time: 0.10568666458129883
Test Loss Energy: 8.968297331225772, Test Loss Force: 8.226251609672628, time: 15.06729769706726


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4923951641079738, Training Loss Force: 2.772880935098831, time: 1.3485088348388672
Validation Loss Energy: 1.642810261846487, Validation Loss Force: 2.5017043320154952, time: 0.11456847190856934
Test Loss Energy: 9.758278522729357, Test Loss Force: 8.20830577055667, time: 15.09297251701355


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6245218425428511, Training Loss Force: 2.7688855426471926, time: 1.32218599319458
Validation Loss Energy: 1.2720361292093065, Validation Loss Force: 2.6419943553775465, time: 0.11188864707946777
Test Loss Energy: 9.15338690384193, Test Loss Force: 8.250215521966542, time: 15.318218231201172


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4980357247064393, Training Loss Force: 2.782250396002251, time: 1.3235456943511963
Validation Loss Energy: 1.5932763413218347, Validation Loss Force: 2.685492884369113, time: 0.10935568809509277
Test Loss Energy: 9.330373658155253, Test Loss Force: 8.207116195035859, time: 15.082159042358398


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6350081076845022, Training Loss Force: 2.778644543238283, time: 1.3382370471954346
Validation Loss Energy: 1.0846281316390973, Validation Loss Force: 2.7730525159494324, time: 0.11679792404174805
Test Loss Energy: 8.950692036006238, Test Loss Force: 8.246589999616404, time: 14.961826801300049


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6506909696865295, Training Loss Force: 2.7874656785151224, time: 1.5695295333862305
Validation Loss Energy: 1.3561164440499311, Validation Loss Force: 2.4234012795005397, time: 0.10735058784484863
Test Loss Energy: 9.26303017990115, Test Loss Force: 8.209321519583584, time: 14.933687210083008


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9053972441879974, Training Loss Force: 2.7944467444835968, time: 1.33577299118042
Validation Loss Energy: 1.543779829213698, Validation Loss Force: 2.5139941101866876, time: 0.11404252052307129
Test Loss Energy: 9.654861878065526, Test Loss Force: 8.177279595029175, time: 15.01634669303894


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6700360968242252, Training Loss Force: 2.7879245653680877, time: 1.3759210109710693
Validation Loss Energy: 1.0190767148544535, Validation Loss Force: 2.6016930213177845, time: 0.11775088310241699
Test Loss Energy: 9.248908917693717, Test Loss Force: 8.1983404985534, time: 14.902777433395386


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5614852478807415, Training Loss Force: 2.791296455663803, time: 1.3518333435058594
Validation Loss Energy: 1.62604065879566, Validation Loss Force: 2.827563370222003, time: 0.11842632293701172
Test Loss Energy: 9.637444077261707, Test Loss Force: 8.206288679546327, time: 15.154623031616211


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.897889599946195, Training Loss Force: 2.787276843660446, time: 1.361637830734253
Validation Loss Energy: 2.8939776716975816, Validation Loss Force: 2.7635634702957192, time: 0.11043548583984375
Test Loss Energy: 8.961377065622099, Test Loss Force: 8.282118405377712, time: 14.959826231002808


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9184194297106019, Training Loss Force: 2.8195132325724037, time: 1.3863306045532227
Validation Loss Energy: 1.773468007626708, Validation Loss Force: 2.883070446253455, time: 0.114532470703125
Test Loss Energy: 9.57822489847108, Test Loss Force: 8.228341055331523, time: 15.223517656326294


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8318505930424136, Training Loss Force: 2.7777679975811402, time: 1.3103289604187012
Validation Loss Energy: 1.8045235620746836, Validation Loss Force: 2.5369727867044243, time: 0.11522746086120605
Test Loss Energy: 9.625928002092575, Test Loss Force: 8.151001984764473, time: 14.925795793533325


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7032113816089196, Training Loss Force: 2.7705031369314477, time: 1.3944346904754639
Validation Loss Energy: 1.1137806024809362, Validation Loss Force: 2.458701130539045, time: 0.1109766960144043
Test Loss Energy: 9.168389199077184, Test Loss Force: 8.170954189465945, time: 15.084092140197754


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5800247052359162, Training Loss Force: 2.7640329995919677, time: 1.35378098487854
Validation Loss Energy: 1.7428546184352585, Validation Loss Force: 2.550967987864278, time: 0.10649943351745605
Test Loss Energy: 8.959086098557105, Test Loss Force: 8.197730231207027, time: 15.264489650726318


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6506652085791853, Training Loss Force: 2.764874506260685, time: 1.3594956398010254
Validation Loss Energy: 1.0086864993335278, Validation Loss Force: 2.4561289678998603, time: 0.11046886444091797
Test Loss Energy: 9.179287634336177, Test Loss Force: 8.23737826798232, time: 15.107113361358643


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7485452938652208, Training Loss Force: 2.756453096357579, time: 1.3351118564605713
Validation Loss Energy: 1.7816926822025563, Validation Loss Force: 2.591397579352094, time: 0.11464476585388184
Test Loss Energy: 9.600455155427081, Test Loss Force: 8.163850057438088, time: 14.963431119918823

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.040 MB of 0.058 MB uploadedwandb: - 0.040 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÜ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÑ‚ñá‚ñÅ‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÉ‚ñá
wandb:   test_error_force ‚ñá‚ñà‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÇ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÇ
wandb:   test_error_total ‚ñá‚ñÜ‚ñÇ‚ñÉ‚ñÖ‚ñá‚ñÜ‚ñá‚ñÑ‚ñÖ‚ñÖ‚ñÉ‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñá
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ
wandb: valid_error_energy ‚ñÑ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñà‚ñÑ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÑ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÉ‚ñÉ‚ñá‚ñÇ‚ñÑ‚ñÑ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÉ
wandb:  valid_error_total ‚ñà‚ñÅ‚ñÇ‚ñÇ‚ñá‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÅ‚ñÇ‚ñÉ‚ñÜ‚ñà‚ñá‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1248
wandb:                 lr 0.0001
wandb:  test_error_energy 9.60046
wandb:   test_error_force 8.16385
wandb:   test_error_total 4.50036
wandb: train_error_energy 1.74855
wandb:  train_error_force 2.75645
wandb:  train_error_total 1.26918
wandb: valid_error_energy 1.78169
wandb:  valid_error_force 2.5914
wandb:  valid_error_total 1.39381
wandb: 
wandb: üöÄ View run al_40_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/9edbi3ef
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_091253-9edbi3ef/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0372384786605835, Uncertainty Bias: -0.005856424570083618
Found uncertainty sample after 377 steps.
Found uncertainty sample after 3402 steps.
Found uncertainty sample after 1298 steps.
Found uncertainty sample after 3052 steps.
Found uncertainty sample after 2617 steps.
Found uncertainty sample after 1323 steps.
Found uncertainty sample after 653 steps.
Found uncertainty sample after 1102 steps.
Found uncertainty sample after 1342 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 33 steps.
Found uncertainty sample after 3676 steps.
Found uncertainty sample after 808 steps.
Found uncertainty sample after 3085 steps.
Found uncertainty sample after 754 steps.
Found uncertainty sample after 309 steps.
Found uncertainty sample after 647 steps.
Found uncertainty sample after 227 steps.
Found uncertainty sample after 484 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_094818-gpf1n6k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_25
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gpf1n6k9
Training model 25. Added 19 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.19615245947922, Training Loss Force: 3.090047824698008, time: 1.414231777191162
Validation Loss Energy: 2.5004009381698067, Validation Loss Force: 2.51448253495828, time: 0.11656403541564941
Test Loss Energy: 8.885133963264849, Test Loss Force: 8.157914269253103, time: 14.733250617980957


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.620183213310542, Training Loss Force: 2.7949342852872285, time: 1.370490312576294
Validation Loss Energy: 2.8353144831917496, Validation Loss Force: 2.708894075591248, time: 0.11077380180358887
Test Loss Energy: 10.02553844984855, Test Loss Force: 8.156233138185877, time: 15.00007176399231


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6060220971950117, Training Loss Force: 2.7834939342404637, time: 1.3896996974945068
Validation Loss Energy: 1.4387482960962954, Validation Loss Force: 2.800952625930465, time: 0.11546659469604492
Test Loss Energy: 8.98213954819011, Test Loss Force: 8.184668792527718, time: 14.824735403060913


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5774619248896582, Training Loss Force: 2.7783955066397987, time: 1.3356680870056152
Validation Loss Energy: 1.140760699218282, Validation Loss Force: 2.6658661578396, time: 0.11724042892456055
Test Loss Energy: 9.301078078887981, Test Loss Force: 8.206999278578754, time: 14.990624189376831


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.513206431400857, Training Loss Force: 2.7831768255430194, time: 1.3730762004852295
Validation Loss Energy: 1.1627796160497836, Validation Loss Force: 2.686979423587327, time: 0.1137840747833252
Test Loss Energy: 9.36285854042353, Test Loss Force: 8.148708378312326, time: 15.118289709091187


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4758633961129617, Training Loss Force: 2.7742793394425647, time: 1.3572766780853271
Validation Loss Energy: 1.2923153320036744, Validation Loss Force: 2.627959630444291, time: 0.11579608917236328
Test Loss Energy: 9.248057365594496, Test Loss Force: 8.173246322337983, time: 14.958856344223022


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1160105065415764, Training Loss Force: 2.7716965666185764, time: 1.3781795501708984
Validation Loss Energy: 2.131137003347595, Validation Loss Force: 2.7435143403963815, time: 0.10768866539001465
Test Loss Energy: 8.863430688399802, Test Loss Force: 8.165529414146992, time: 14.81847071647644


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9380641718868596, Training Loss Force: 2.7923638761675678, time: 1.4066417217254639
Validation Loss Energy: 1.7444963580481838, Validation Loss Force: 2.416896557075124, time: 0.11564373970031738
Test Loss Energy: 10.158004921654197, Test Loss Force: 8.152753178503596, time: 14.963106155395508


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6946698892328829, Training Loss Force: 2.7763015426916793, time: 1.397867202758789
Validation Loss Energy: 1.1046918324506718, Validation Loss Force: 2.5752551796180594, time: 0.10515165328979492
Test Loss Energy: 9.154558539923908, Test Loss Force: 8.176804178915512, time: 14.793803930282593


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5152955912621526, Training Loss Force: 2.7773330853438334, time: 1.3895161151885986
Validation Loss Energy: 2.3362589298996896, Validation Loss Force: 2.6993246463758553, time: 0.14894676208496094
Test Loss Energy: 8.865892376248722, Test Loss Force: 8.206860123186427, time: 14.924357652664185


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.808629803794738, Training Loss Force: 2.7820664802801223, time: 1.4002103805541992
Validation Loss Energy: 1.8782391848452344, Validation Loss Force: 2.749916301010951, time: 0.11187338829040527
Test Loss Energy: 9.103064730751822, Test Loss Force: 8.149639188969427, time: 14.967262983322144


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4639237039397255, Training Loss Force: 2.7688968361122535, time: 1.3883585929870605
Validation Loss Energy: 1.0906860823400304, Validation Loss Force: 2.7032842604633163, time: 0.10621809959411621
Test Loss Energy: 9.035556444687133, Test Loss Force: 8.16878513783867, time: 14.806729555130005


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.493711067142302, Training Loss Force: 2.774769445366209, time: 1.373530387878418
Validation Loss Energy: 1.037900023271816, Validation Loss Force: 2.511234682795777, time: 0.11628246307373047
Test Loss Energy: 9.463975882501982, Test Loss Force: 8.124660793715053, time: 14.94385838508606


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5317141744962925, Training Loss Force: 2.7736080643350647, time: 1.4141428470611572
Validation Loss Energy: 0.9331286790514302, Validation Loss Force: 2.2422322069796166, time: 0.11872076988220215
Test Loss Energy: 9.223324424018971, Test Loss Force: 8.132130429568205, time: 14.810513019561768


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0018799369546003, Training Loss Force: 2.7795240606721046, time: 1.359555959701538
Validation Loss Energy: 2.182808158002149, Validation Loss Force: 2.6105235229724157, time: 0.12289285659790039
Test Loss Energy: 8.927213768617015, Test Loss Force: 8.158203585256281, time: 14.930348634719849


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6961509549651534, Training Loss Force: 2.757201668061618, time: 1.4001107215881348
Validation Loss Energy: 1.3019390924906733, Validation Loss Force: 2.7098147011750866, time: 0.11729192733764648
Test Loss Energy: 9.033357077413417, Test Loss Force: 8.168362814909534, time: 14.801624536514282


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6444589932705949, Training Loss Force: 2.7713542239401696, time: 1.3750896453857422
Validation Loss Energy: 2.0543018971771687, Validation Loss Force: 2.9168577057836726, time: 0.11122274398803711
Test Loss Energy: 8.966871351020409, Test Loss Force: 8.183801942708428, time: 15.201140880584717


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6159360248044794, Training Loss Force: 2.7660390446261296, time: 1.3946707248687744
Validation Loss Energy: 2.7124491555078443, Validation Loss Force: 3.081804440347173, time: 0.11389422416687012
Test Loss Energy: 9.201685347816376, Test Loss Force: 8.110940548147173, time: 14.775673389434814


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5300051094754135, Training Loss Force: 2.7746068968896815, time: 1.3788256645202637
Validation Loss Energy: 2.009432616923271, Validation Loss Force: 2.837113761225419, time: 0.10716462135314941
Test Loss Energy: 8.833591409368527, Test Loss Force: 8.17872243513605, time: 14.910478830337524


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6186897699571219, Training Loss Force: 2.7751368160566177, time: 1.377915382385254
Validation Loss Energy: 3.0756846015404937, Validation Loss Force: 2.7494407910498224, time: 0.10614013671875
Test Loss Energy: 10.14600048058673, Test Loss Force: 8.134954911906842, time: 14.798844575881958

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÅ‚ñá‚ñÇ‚ñÉ‚ñÑ‚ñÉ‚ñÅ‚ñà‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñà
wandb:   test_error_force ‚ñÑ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÜ‚ñà‚ñÑ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÅ‚ñÜ‚ñÉ
wandb:   test_error_total ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÉ‚ñÜ‚ñÇ‚ñà‚ñÜ‚ñÉ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñá‚ñÅ‚ñÇ‚ñá
wandb: train_error_energy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: valid_error_energy ‚ñÜ‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÖ‚ñÑ‚ñÇ‚ñÜ‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÖ‚ñÇ‚ñÖ‚ñá‚ñÖ‚ñà
wandb:  valid_error_force ‚ñÉ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÉ‚ñÅ‚ñÑ‚ñÖ‚ñá‚ñà‚ñÜ‚ñÖ
wandb:  valid_error_total ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÜ‚ñÉ‚ñÑ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÅ‚ñá‚ñÑ‚ñà‚ñà‚ñÖ‚ñá
wandb: 
wandb: Run summary:
wandb:       dataset_size 1265
wandb:                 lr 0.0001
wandb:  test_error_energy 10.146
wandb:   test_error_force 8.13495
wandb:   test_error_total 4.47211
wandb: train_error_energy 1.61869
wandb:  train_error_force 2.77514
wandb:  train_error_total 1.28851
wandb: valid_error_energy 3.07568
wandb:  valid_error_force 2.74944
wandb:  valid_error_total 1.48028
wandb: 
wandb: üöÄ View run al_40_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/gpf1n6k9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_094818-gpf1n6k9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6238970756530762, Uncertainty Bias: 0.041108936071395874
Found uncertainty sample after 2523 steps.
Found uncertainty sample after 3190 steps.
Found uncertainty sample after 1002 steps.
Found uncertainty sample after 2323 steps.
Found uncertainty sample after 706 steps.
Found uncertainty sample after 1131 steps.
Found uncertainty sample after 72 steps.
Found uncertainty sample after 2128 steps.
Found uncertainty sample after 315 steps.
Found uncertainty sample after 3677 steps.
Found uncertainty sample after 2408 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_103523-m91iy8vj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_26
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/m91iy8vj
Training model 26. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.335649686047381, Training Loss Force: 3.0761355677950126, time: 1.4098734855651855
Validation Loss Energy: 1.6922066285062427, Validation Loss Force: 2.6694287528398712, time: 0.12125205993652344
Test Loss Energy: 9.25184523123912, Test Loss Force: 8.063383259007857, time: 16.689934730529785


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9668299276562369, Training Loss Force: 2.815813820799203, time: 1.4624102115631104
Validation Loss Energy: 2.3405566670852416, Validation Loss Force: 2.715834895538963, time: 0.11360573768615723
Test Loss Energy: 8.830028071166263, Test Loss Force: 8.109096164455963, time: 16.90118384361267


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.562609344533503, Training Loss Force: 2.767001899413493, time: 1.4113366603851318
Validation Loss Energy: 1.6406897279025303, Validation Loss Force: 2.6886398674085106, time: 0.11698746681213379
Test Loss Energy: 9.244108124275234, Test Loss Force: 8.070989450503623, time: 16.76686954498291


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5075841593258927, Training Loss Force: 2.7844848230733, time: 1.3813469409942627
Validation Loss Energy: 1.9216880586172589, Validation Loss Force: 2.705325023185744, time: 0.11830544471740723
Test Loss Energy: 8.980101451668396, Test Loss Force: 8.111683363091535, time: 17.20334267616272


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.567341677616302, Training Loss Force: 2.7842862912627906, time: 1.3960785865783691
Validation Loss Energy: 1.416173485741985, Validation Loss Force: 2.6908427332691742, time: 0.11583566665649414
Test Loss Energy: 8.9355112673702, Test Loss Force: 8.114171043774366, time: 16.901947021484375


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5710695696653707, Training Loss Force: 2.8098786971825285, time: 1.4646430015563965
Validation Loss Energy: 1.2344037631999214, Validation Loss Force: 2.6838322178787832, time: 0.11807441711425781
Test Loss Energy: 8.903290960347958, Test Loss Force: 8.127207221746586, time: 16.734161376953125


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.620074527108733, Training Loss Force: 2.7946139757208113, time: 1.4201862812042236
Validation Loss Energy: 0.924637553008836, Validation Loss Force: 2.329057921054958, time: 0.13101816177368164
Test Loss Energy: 9.083793975243381, Test Loss Force: 8.05894061783543, time: 16.916008710861206


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5238267031166266, Training Loss Force: 2.7796062923876956, time: 1.4565227031707764
Validation Loss Energy: 1.5803799567298484, Validation Loss Force: 2.7396386725769357, time: 0.11837649345397949
Test Loss Energy: 9.43985200049673, Test Loss Force: 8.080790868326474, time: 16.833103895187378


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3901332685111896, Training Loss Force: 2.7783327195073757, time: 1.4412727355957031
Validation Loss Energy: 1.6251244309274537, Validation Loss Force: 2.705304982962611, time: 0.1220235824584961
Test Loss Energy: 8.902395939967189, Test Loss Force: 8.067150074840447, time: 16.860228300094604


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.687982625425, Training Loss Force: 2.80220410446478, time: 1.4171638488769531
Validation Loss Energy: 1.316743807330547, Validation Loss Force: 2.655346376709388, time: 0.12184000015258789
Test Loss Energy: 9.250168320393401, Test Loss Force: 8.051013927329603, time: 16.82335877418518


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.747913533395979, Training Loss Force: 2.7922635971176986, time: 1.4140625
Validation Loss Energy: 1.477749353678412, Validation Loss Force: 2.8030078621473784, time: 0.1207277774810791
Test Loss Energy: 8.964714050728167, Test Loss Force: 8.054843575498781, time: 16.778084993362427


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0019236510829925, Training Loss Force: 2.8030635739676897, time: 1.3807973861694336
Validation Loss Energy: 1.945124375897164, Validation Loss Force: 2.8023465347839727, time: 0.1246175765991211
Test Loss Energy: 8.88525876757243, Test Loss Force: 8.07181512868125, time: 16.93889021873474


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3953148644295408, Training Loss Force: 2.779807635396172, time: 1.4035968780517578
Validation Loss Energy: 1.3887488857220807, Validation Loss Force: 2.5435475385762345, time: 0.1253666877746582
Test Loss Energy: 8.822579874504699, Test Loss Force: 8.100062276686861, time: 16.809489250183105


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6719194430229933, Training Loss Force: 2.802781875231177, time: 1.416257381439209
Validation Loss Energy: 1.1423653644184104, Validation Loss Force: 2.614750451369563, time: 0.1179354190826416
Test Loss Energy: 8.814818164348898, Test Loss Force: 8.073463994872654, time: 17.000685453414917


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8763987241530256, Training Loss Force: 2.7970565393503373, time: 1.4593896865844727
Validation Loss Energy: 1.7485132537734347, Validation Loss Force: 2.547173705617668, time: 0.12131118774414062
Test Loss Energy: 8.808269187305084, Test Loss Force: 8.056684543375347, time: 16.99644947052002


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.064715760161392, Training Loss Force: 2.7836324010488593, time: 1.445955753326416
Validation Loss Energy: 2.6286634876145687, Validation Loss Force: 2.532853741508479, time: 0.12466883659362793
Test Loss Energy: 8.74222492406131, Test Loss Force: 8.100512222248165, time: 17.14843988418579


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6520628829677821, Training Loss Force: 2.7902139944301774, time: 1.4215569496154785
Validation Loss Energy: 1.8118057894903923, Validation Loss Force: 2.8059075711002235, time: 0.1227865219116211
Test Loss Energy: 9.547311081095135, Test Loss Force: 8.04710623071026, time: 16.906948566436768


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4300357269797583, Training Loss Force: 2.776551672510029, time: 1.4389712810516357
Validation Loss Energy: 1.1674512147313485, Validation Loss Force: 2.713531605893486, time: 0.12024736404418945
Test Loss Energy: 8.892355172631184, Test Loss Force: 8.094031514865009, time: 16.800976991653442


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.642979120209937, Training Loss Force: 2.7762098976379446, time: 1.6486527919769287
Validation Loss Energy: 1.8018681768422082, Validation Loss Force: 2.698875968046811, time: 0.12110114097595215
Test Loss Energy: 9.357771499406015, Test Loss Force: 8.023416194470993, time: 16.820728302001953


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7136362180426743, Training Loss Force: 2.7781163741651924, time: 1.384099006652832
Validation Loss Energy: 1.2229614081308435, Validation Loss Force: 2.5564810532483038, time: 0.12028264999389648
Test Loss Energy: 8.788886511988544, Test Loss Force: 8.063462522228965, time: 16.978066205978394

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÖ‚ñÇ‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñá‚ñÇ‚ñÖ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñà‚ñÇ‚ñÜ‚ñÅ
wandb:   test_error_force ‚ñÑ‚ñá‚ñÑ‚ñá‚ñá‚ñà‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÑ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñÉ‚ñÜ‚ñÅ‚ñÑ
wandb:   test_error_total ‚ñà‚ñÉ‚ñá‚ñÜ‚ñÜ‚ñà‚ñà‚ñá‚ñÇ‚ñÜ‚ñá‚ñá‚ñá‚ñÑ‚ñÅ‚ñÑ‚ñá‚ñÉ‚ñá‚ñÉ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb: valid_error_energy ‚ñÑ‚ñá‚ñÑ‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÖ‚ñÉ‚ñÇ‚ñÑ‚ñà‚ñÖ‚ñÇ‚ñÖ‚ñÇ
wandb:  valid_error_force ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÅ‚ñá‚ñá‚ñÜ‚ñà‚ñà‚ñÑ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñá‚ñÜ‚ñÑ
wandb:  valid_error_total ‚ñÜ‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÅ‚ñá‚ñÖ‚ñÉ‚ñÜ‚ñá‚ñÉ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñÖ‚ñà‚ñÑ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1274
wandb:                 lr 0.0001
wandb:  test_error_energy 8.78889
wandb:   test_error_force 8.06346
wandb:   test_error_total 4.37377
wandb: train_error_energy 1.71364
wandb:  train_error_force 2.77812
wandb:  train_error_total 1.2661
wandb: valid_error_energy 1.22296
wandb:  valid_error_force 2.55648
wandb:  valid_error_total 1.30878
wandb: 
wandb: üöÄ View run al_40_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/m91iy8vj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_103523-m91iy8vj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0346013307571411, Uncertainty Bias: -0.004825174808502197
Found uncertainty sample after 320 steps.
Found uncertainty sample after 313 steps.
Found uncertainty sample after 3426 steps.
Found uncertainty sample after 1745 steps.
Found uncertainty sample after 61 steps.
Found uncertainty sample after 101 steps.
Found uncertainty sample after 1312 steps.
Found uncertainty sample after 3041 steps.
Found uncertainty sample after 3271 steps.
Found uncertainty sample after 733 steps.
Found uncertainty sample after 1348 steps.
Found uncertainty sample after 2146 steps.
Found uncertainty sample after 1975 steps.
Found uncertainty sample after 973 steps.
Found uncertainty sample after 1420 steps.
Found uncertainty sample after 3870 steps.
Found uncertainty sample after 1757 steps.
Found uncertainty sample after 2096 steps.
Found uncertainty sample after 3373 steps.
Found uncertainty sample after 2650 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 991 steps.
Found uncertainty sample after 88 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_111013-h3cm0vzo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_40_27
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/h3cm0vzo
Training model 27. Added 23 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5727896103283165, Training Loss Force: 2.996994292079564, time: 1.4488754272460938
Validation Loss Energy: 1.3394961406614487, Validation Loss Force: 2.8247581843216047, time: 0.12830376625061035
Test Loss Energy: 8.904423080234277, Test Loss Force: 8.000309250615842, time: 16.81758737564087


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.56720284608535, Training Loss Force: 2.8113520706801682, time: 1.452279806137085
Validation Loss Energy: 1.2987607687689868, Validation Loss Force: 2.8185358063732258, time: 0.12112879753112793
Test Loss Energy: 8.871869156541079, Test Loss Force: 8.066669641093254, time: 17.159822702407837


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4587758460968199, Training Loss Force: 2.7963063327826916, time: 1.4431030750274658
Validation Loss Energy: 2.024403442946007, Validation Loss Force: 2.49398105268899, time: 0.11634063720703125
Test Loss Energy: 8.658475423291497, Test Loss Force: 8.084975959406137, time: 16.820333003997803


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.727146160134476, Training Loss Force: 2.7872025699228913, time: 1.4727301597595215
Validation Loss Energy: 1.4764200188772234, Validation Loss Force: 2.6060124687450648, time: 0.11688351631164551
Test Loss Energy: 8.802104823995677, Test Loss Force: 8.064625179265066, time: 16.828929662704468


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7583979689220743, Training Loss Force: 2.8111914501925868, time: 1.505131483078003
Validation Loss Energy: 1.3283562259598272, Validation Loss Force: 2.6249363401154566, time: 0.1246805191040039
Test Loss Energy: 9.121811808066477, Test Loss Force: 8.03796502340766, time: 16.886176347732544


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7004386837496348, Training Loss Force: 2.7782584879954952, time: 1.4660942554473877
Validation Loss Energy: 1.6796967418843005, Validation Loss Force: 2.596914207442455, time: 0.12058711051940918
Test Loss Energy: 8.65558976639389, Test Loss Force: 8.040086102074959, time: 16.865859508514404


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6937158025862358, Training Loss Force: 2.793020730053522, time: 1.4645967483520508
Validation Loss Energy: 1.3473675506372822, Validation Loss Force: 2.594010824448703, time: 0.11645722389221191
Test Loss Energy: 9.031418375268895, Test Loss Force: 8.026086258671448, time: 16.889920473098755


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6883819044003598, Training Loss Force: 2.807653204878066, time: 1.4331774711608887
Validation Loss Energy: 1.538495612044399, Validation Loss Force: 2.6259931278820297, time: 0.1191709041595459
Test Loss Energy: 8.659093011906121, Test Loss Force: 8.050938254794199, time: 16.782352447509766


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.356467012983491, Training Loss Force: 2.8170757430595583, time: 1.5643212795257568
Validation Loss Energy: 2.151443761448771, Validation Loss Force: 2.8490943632874908, time: 0.15852808952331543
Test Loss Energy: 9.582884671205964, Test Loss Force: 7.990793973137771, time: 16.908960103988647


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6025966078361498, Training Loss Force: 2.800506399677503, time: 1.4329748153686523
Validation Loss Energy: 1.7751985365615721, Validation Loss Force: 2.611860539859139, time: 0.11794757843017578
Test Loss Energy: 8.65394171626742, Test Loss Force: 8.04470869022828, time: 16.919631242752075


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6957287343809002, Training Loss Force: 2.7737685601822335, time: 1.4330236911773682
Validation Loss Energy: 1.3896274268373388, Validation Loss Force: 2.6186595195608984, time: 0.12174367904663086
Test Loss Energy: 8.660339112747401, Test Loss Force: 7.99268797824012, time: 16.812324285507202


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7429674275124447, Training Loss Force: 2.798067374179241, time: 1.472264289855957
Validation Loss Energy: 1.304967949548156, Validation Loss Force: 2.6282113579137625, time: 0.1177978515625
Test Loss Energy: 9.082845327738465, Test Loss Force: 7.995971711611907, time: 16.829054832458496

