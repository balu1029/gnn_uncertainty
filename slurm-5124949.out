wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_162427-ob19kzyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ob19kzyi
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
79
Uncertainty Slope: 0.6297209858894348, Uncertainty Bias: 0.03318388760089874
1.1444092e-05 0.0025911331
0.5307793 3.2033625
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 13.237398152431767, Test Loss Force: 20.395767161422185, time: 14.14229941368103

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.050 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.039 MB of 0.050 MB uploadedwandb: - 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.2374
wandb:   test_error_force 20.39577
wandb:          test_loss 9.85373
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_80 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/ob19kzyi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_162427-ob19kzyi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2 steps.
Found uncertainty sample 5 after 1330 steps.
Found uncertainty sample 6 after 545 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 235 steps.
Found uncertainty sample 12 after 2761 steps.
Found uncertainty sample 13 after 1863 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2625 steps.
Found uncertainty sample 16 after 2372 steps.
Found uncertainty sample 17 after 831 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 231 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 876 steps.
Found uncertainty sample 23 after 37 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2520 steps.
Found uncertainty sample 28 after 3821 steps.
Found uncertainty sample 29 after 1265 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2419 steps.
Found uncertainty sample 33 after 3224 steps.
Found uncertainty sample 34 after 1662 steps.
Found uncertainty sample 35 after 2465 steps.
Found uncertainty sample 36 after 3413 steps.
Found uncertainty sample 37 after 2744 steps.
Found uncertainty sample 38 after 3913 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3579 steps.
Found uncertainty sample 41 after 729 steps.
Found uncertainty sample 42 after 765 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3596 steps.
Found uncertainty sample 45 after 2726 steps.
Found uncertainty sample 46 after 3684 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 446 steps.
Found uncertainty sample 49 after 2495 steps.
Found 2 uncertainty samples at step 1. Dropping index -2
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1057 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1450 steps.
Found uncertainty sample 55 after 1534 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3662 steps.
Found uncertainty sample 59 after 396 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 310 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2114 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3 steps.
Found uncertainty sample 69 after 3850 steps.
Found uncertainty sample 70 after 802 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 166 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3850 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3567 steps.
Found uncertainty sample 80 after 1091 steps.
Found uncertainty sample 81 after 452 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 427 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3920 steps.
Found uncertainty sample 86 after 857 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2927 steps.
Found uncertainty sample 89 after 1783 steps.
Found uncertainty sample 90 after 2300 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 739 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1176 steps.
Found uncertainty sample 95 after 385 steps.
Found uncertainty sample 96 after 1030 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3136 steps.
Found uncertainty sample 99 after 2694 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_182641-krup45ui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/krup45ui
Training model 0. Added 58 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.470610557522991, Training Loss Force: 3.193539207495337, time: 1.0435175895690918
Validation Loss Energy: 1.5112851084083045, Validation Loss Force: 2.607130601861341, time: 0.06280827522277832
Test Loss Energy: 12.238902165143429, Test Loss Force: 19.901720061511714, time: 14.420772075653076


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.374583996240771, Training Loss Force: 2.5534338053687686, time: 0.9056541919708252
Validation Loss Energy: 1.209716379323621, Validation Loss Force: 2.5527298574814314, time: 0.06186532974243164
Test Loss Energy: 12.335983375971812, Test Loss Force: 19.3933021327477, time: 14.625931978225708


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3304012977425794, Training Loss Force: 2.497193079860014, time: 0.9063279628753662
Validation Loss Energy: 1.0452537274833675, Validation Loss Force: 2.5359866963916833, time: 0.06777644157409668
Test Loss Energy: 12.046568041372248, Test Loss Force: 19.374729213016145, time: 14.513398885726929


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5231377932312948, Training Loss Force: 2.4700674667740534, time: 0.9043233394622803
Validation Loss Energy: 2.973390395901268, Validation Loss Force: 2.5420167995325538, time: 0.06062150001525879
Test Loss Energy: 12.600486337301673, Test Loss Force: 18.506133042749664, time: 14.579692125320435


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.520060555116605, Training Loss Force: 2.465965769153977, time: 0.8823509216308594
Validation Loss Energy: 1.059624571492401, Validation Loss Force: 2.5301273804857396, time: 0.06471109390258789
Test Loss Energy: 11.887040501992272, Test Loss Force: 19.012111058608777, time: 14.504834175109863


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.360148134902878, Training Loss Force: 2.480539761647145, time: 0.917741060256958
Validation Loss Energy: 1.1238759762190103, Validation Loss Force: 2.5260886075169013, time: 0.06380724906921387
Test Loss Energy: 11.593731329887536, Test Loss Force: 18.86278962365179, time: 14.623266220092773


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.2901257541304691, Training Loss Force: 2.4520934731156707, time: 0.9286954402923584
Validation Loss Energy: 1.2412713806659126, Validation Loss Force: 2.517344612825463, time: 0.06348443031311035
Test Loss Energy: 11.558718049959516, Test Loss Force: 18.738335841606194, time: 14.486963272094727


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.1730612545901775, Training Loss Force: 2.434247555451223, time: 0.9258027076721191
Validation Loss Energy: 1.1941461279600474, Validation Loss Force: 2.520773049665313, time: 0.06234121322631836
Test Loss Energy: 11.678821814202548, Test Loss Force: 18.72308762636927, time: 14.60634994506836


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.2911794451465128, Training Loss Force: 2.455288008388232, time: 0.9089498519897461
Validation Loss Energy: 1.1077572907490165, Validation Loss Force: 2.5208454171377395, time: 0.06110668182373047
Test Loss Energy: 11.43922157326004, Test Loss Force: 18.625519835658945, time: 14.469905376434326


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.2022760093940223, Training Loss Force: 2.435902523260818, time: 0.9328389167785645
Validation Loss Energy: 1.7614094713635615, Validation Loss Force: 2.5243459987808703, time: 0.06400680541992188
Test Loss Energy: 11.743082227120208, Test Loss Force: 18.81541191542995, time: 14.609451293945312


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6745066972697187, Training Loss Force: 2.4718458427725247, time: 0.9171748161315918
Validation Loss Energy: 2.2024545907510764, Validation Loss Force: 2.5230607524705753, time: 0.06487417221069336
Test Loss Energy: 11.9859859548691, Test Loss Force: 18.500077057526546, time: 14.491551160812378


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.619778400390895, Training Loss Force: 2.452371191022675, time: 0.8858335018157959
Validation Loss Energy: 1.0473510481688615, Validation Loss Force: 2.5097533763024926, time: 0.06707954406738281
Test Loss Energy: 11.380441903726037, Test Loss Force: 18.877261038337323, time: 14.62411117553711


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.720242447084713, Training Loss Force: 2.48831724029317, time: 0.911447286605835
Validation Loss Energy: 1.119090482269303, Validation Loss Force: 2.5167532035738787, time: 0.06324195861816406
Test Loss Energy: 11.651623806269283, Test Loss Force: 19.249008832909773, time: 14.935259103775024


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.2914972084500116, Training Loss Force: 2.460489559637105, time: 0.9120337963104248
Validation Loss Energy: 1.0310944191629654, Validation Loss Force: 2.5107772090354685, time: 0.0623934268951416
Test Loss Energy: 11.323928036146116, Test Loss Force: 18.3289013663655, time: 14.658272981643677


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.2107428923333534, Training Loss Force: 2.4464500473172115, time: 0.8968584537506104
Validation Loss Energy: 1.0454632591496857, Validation Loss Force: 2.510917490597403, time: 0.06120944023132324
Test Loss Energy: 11.076564434265029, Test Loss Force: 18.21301830394418, time: 14.57485556602478


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.544275430941744, Training Loss Force: 2.416458715311182, time: 0.9157512187957764
Validation Loss Energy: 1.1480482706934931, Validation Loss Force: 2.5077041521525194, time: 0.06170916557312012
Test Loss Energy: 11.376462869041887, Test Loss Force: 18.68812873833482, time: 14.656200647354126


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5900170567480894, Training Loss Force: 2.434656186322022, time: 0.8997063636779785
Validation Loss Energy: 1.143694309548594, Validation Loss Force: 2.511244814241917, time: 0.06289482116699219
Test Loss Energy: 11.261199540320158, Test Loss Force: 18.515918873732296, time: 14.508347272872925


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5114271094708658, Training Loss Force: 2.4303032601763017, time: 0.9088783264160156
Validation Loss Energy: 1.3118352330104286, Validation Loss Force: 2.5380824583931556, time: 0.06386208534240723
Test Loss Energy: 10.979693931402274, Test Loss Force: 17.853162492028243, time: 14.673826932907104


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.671602040113631, Training Loss Force: 2.439424250225806, time: 0.9187171459197998
Validation Loss Energy: 2.8739971238951894, Validation Loss Force: 2.591771997520972, time: 0.06346487998962402
Test Loss Energy: 11.528749897954066, Test Loss Force: 18.699904536661055, time: 14.541959285736084


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.568568682182747, Training Loss Force: 2.471092693250943, time: 0.9012455940246582
Validation Loss Energy: 1.234946352241261, Validation Loss Force: 2.500946143573611, time: 0.06333732604980469
Test Loss Energy: 11.139442559093824, Test Loss Force: 18.258318847118552, time: 14.714104890823364

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: - 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: \ 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‡â–†â–ˆâ–…â–„â–„â–„â–ƒâ–„â–…â–ƒâ–„â–‚â–â–ƒâ–‚â–â–ƒâ–‚
wandb:   test_error_force â–ˆâ–†â–†â–ƒâ–…â–„â–„â–„â–„â–„â–ƒâ–„â–†â–ƒâ–‚â–„â–ƒâ–â–„â–‚
wandb:          test_loss â–ˆâ–†â–†â–„â–…â–„â–„â–„â–ƒâ–„â–ƒâ–„â–†â–ƒâ–‚â–„â–ƒâ–â–„â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–â–â–â–â–ƒâ–‚â–ƒâ–â–â–‚â–‚â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–ƒâ–‚â–â–ˆâ–â–â–‚â–‚â–â–„â–…â–â–â–â–â–â–â–‚â–ˆâ–‚
wandb:  valid_error_force â–ˆâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‡â–
wandb:         valid_loss â–ˆâ–ƒâ–ƒâ–†â–‚â–‚â–‚â–‚â–‚â–†â–…â–ƒâ–†â–‚â–â–‚â–‚â–ƒâ–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 852
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.13944
wandb:   test_error_force 18.25832
wandb:          test_loss 8.86937
wandb: train_error_energy 1.56857
wandb:  train_error_force 2.47109
wandb:         train_loss 1.15587
wandb: valid_error_energy 1.23495
wandb:  valid_error_force 2.50095
wandb:         valid_loss 1.30264
wandb: 
wandb: ğŸš€ View run al_80_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/krup45ui
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_182641-krup45ui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6193889379501343, Uncertainty Bias: 0.03406974673271179
0.00010681152 0.0039024353
0.5894863 4.1109667
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1829 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1008 steps.
Found uncertainty sample 6 after 3467 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 347 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1464 steps.
Found uncertainty sample 11 after 1183 steps.
Found uncertainty sample 12 after 1309 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1490 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3863 steps.
Found uncertainty sample 17 after 1166 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 263 steps.
Found uncertainty sample 22 after 1055 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2165 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 4 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1771 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3725 steps.
Found uncertainty sample 42 after 536 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1141 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1334 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 507 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1241 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2691 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 310 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 54 steps.
Found uncertainty sample 60 after 390 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1003 steps.
Found uncertainty sample 64 after 182 steps.
Found uncertainty sample 65 after 2509 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 114 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 377 steps.
Found uncertainty sample 75 after 349 steps.
Found uncertainty sample 76 after 673 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 971 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1066 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3639 steps.
Found uncertainty sample 88 after 1525 steps.
Found uncertainty sample 89 after 1749 steps.
Found uncertainty sample 90 after 439 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3949 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1359 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_204356-zt3k6kef
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/zt3k6kef
Training model 1. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.311095042008567, Training Loss Force: 2.8993832515038807, time: 1.001389741897583
Validation Loss Energy: 1.4473749441478296, Validation Loss Force: 2.636876973065834, time: 0.0684347152709961
Test Loss Energy: 10.703398412104082, Test Loss Force: 17.835762742580734, time: 16.131742238998413


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3317488190315352, Training Loss Force: 2.668695670344191, time: 1.0465261936187744
Validation Loss Energy: 1.7488469234886075, Validation Loss Force: 2.679914242921611, time: 0.07426691055297852
Test Loss Energy: 10.854892300513301, Test Loss Force: 18.118306642570584, time: 17.22329068183899


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4385054594877222, Training Loss Force: 2.609852453833876, time: 0.9658279418945312
Validation Loss Energy: 1.1814891683672202, Validation Loss Force: 2.6342470277832812, time: 0.06737422943115234
Test Loss Energy: 10.959042578225189, Test Loss Force: 18.11278135136806, time: 15.83333134651184


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.3409099644866955, Training Loss Force: 2.5982625486457422, time: 0.951042652130127
Validation Loss Energy: 1.2530381090133207, Validation Loss Force: 2.661209366656239, time: 0.0708017349243164
Test Loss Energy: 10.935154692872022, Test Loss Force: 18.419538667344348, time: 16.192830324172974


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.491010102529714, Training Loss Force: 2.5934205444477874, time: 0.9418842792510986
Validation Loss Energy: 1.6556706853714058, Validation Loss Force: 2.6009653385488924, time: 0.0715627670288086
Test Loss Energy: 10.467495943237626, Test Loss Force: 17.163908094910838, time: 16.252460479736328


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4744130879481543, Training Loss Force: 2.5877894803213586, time: 0.9799928665161133
Validation Loss Energy: 1.1195252437767271, Validation Loss Force: 2.6524045832879626, time: 0.07546496391296387
Test Loss Energy: 10.283165691061992, Test Loss Force: 17.331204026852603, time: 17.369943380355835


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6508955077627545, Training Loss Force: 2.56977190418477, time: 1.0216829776763916
Validation Loss Energy: 2.195767836298865, Validation Loss Force: 2.661969336451291, time: 0.07206201553344727
Test Loss Energy: 10.729961334990561, Test Loss Force: 17.74883724066832, time: 16.160101890563965


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.490683023423637, Training Loss Force: 2.559550030514401, time: 0.9929366111755371
Validation Loss Energy: 1.233857166113955, Validation Loss Force: 2.5981686140760396, time: 0.06974339485168457
Test Loss Energy: 10.554608836974728, Test Loss Force: 17.32379652618343, time: 16.181565046310425


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.197623160352879, Training Loss Force: 2.5617567771801792, time: 1.0616929531097412
Validation Loss Energy: 1.2534559476656542, Validation Loss Force: 2.591384998545349, time: 0.07285594940185547
Test Loss Energy: 10.615372001291602, Test Loss Force: 17.427348744880337, time: 16.0407874584198


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7101079435150128, Training Loss Force: 2.5865667722311914, time: 0.9844202995300293
Validation Loss Energy: 1.2686343013323946, Validation Loss Force: 2.645084112446441, time: 0.06768679618835449
Test Loss Energy: 10.515983728266143, Test Loss Force: 17.85571505919968, time: 15.93256139755249


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2791136381908605, Training Loss Force: 2.5802879317493805, time: 0.9680807590484619
Validation Loss Energy: 1.1569718480511222, Validation Loss Force: 2.5906125592781257, time: 0.06795740127563477
Test Loss Energy: 10.287866644764991, Test Loss Force: 17.13844624413741, time: 15.641133069992065


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.478843641314901, Training Loss Force: 2.555521889997281, time: 0.9559330940246582
Validation Loss Energy: 1.1011432377729504, Validation Loss Force: 2.6177004835493873, time: 0.07343626022338867
Test Loss Energy: 10.258455216919872, Test Loss Force: 17.213916250878068, time: 15.661594152450562


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.335176357242332, Training Loss Force: 2.5733821742396796, time: 0.9516079425811768
Validation Loss Energy: 1.0873291779633094, Validation Loss Force: 2.62392074614088, time: 0.06674909591674805
Test Loss Energy: 10.550182062436209, Test Loss Force: 17.57779559400151, time: 15.599011659622192


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3065034560973003, Training Loss Force: 2.5718135814411904, time: 0.952155590057373
Validation Loss Energy: 1.1132588886720274, Validation Loss Force: 2.575286909971354, time: 0.06746912002563477
Test Loss Energy: 10.44176259931915, Test Loss Force: 17.120331733726314, time: 15.951847076416016


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.581276414758884, Training Loss Force: 2.5366778614206433, time: 1.1147968769073486
Validation Loss Energy: 1.319209812454411, Validation Loss Force: 2.665760946668149, time: 0.06675577163696289
Test Loss Energy: 10.389491784413638, Test Loss Force: 17.552713880263425, time: 15.956843614578247


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3197417710321495, Training Loss Force: 2.5740053138445584, time: 0.9550316333770752
Validation Loss Energy: 1.12387408353127, Validation Loss Force: 2.598009628305847, time: 0.07077550888061523
Test Loss Energy: 10.548508597716122, Test Loss Force: 17.366383438948017, time: 15.961943864822388


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5356995913650966, Training Loss Force: 2.5406869875831943, time: 0.9563579559326172
Validation Loss Energy: 2.1493039109564056, Validation Loss Force: 2.636572139005059, time: 0.07460808753967285
Test Loss Energy: 10.685170986285666, Test Loss Force: 17.742341671576934, time: 15.86876893043518


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5430951096612657, Training Loss Force: 2.5661678688659477, time: 0.9897115230560303
Validation Loss Energy: 1.6255734989275035, Validation Loss Force: 2.5794982515282863, time: 0.06832242012023926
Test Loss Energy: 10.456113101161025, Test Loss Force: 16.946930759400903, time: 15.920587301254272


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4378758843469026, Training Loss Force: 2.557688691408774, time: 0.9790709018707275
Validation Loss Energy: 1.4854037169042529, Validation Loss Force: 2.6619708951353123, time: 0.06788802146911621
Test Loss Energy: 10.414531207335294, Test Loss Force: 17.479272270529854, time: 16.66029381752014


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7387667568603302, Training Loss Force: 2.5491892590117904, time: 0.9805011749267578
Validation Loss Energy: 2.280885566690367, Validation Loss Force: 2.571762502729609, time: 0.06961369514465332
Test Loss Energy: 11.01021482050796, Test Loss Force: 17.18483054019535, time: 15.940151453018188

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‡â–ˆâ–‡â–ƒâ–â–…â–„â–„â–ƒâ–â–â–„â–ƒâ–‚â–„â–…â–ƒâ–‚â–ˆ
wandb:   test_error_force â–…â–‡â–‡â–ˆâ–‚â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–‚â–„â–‚â–„â–ƒâ–…â–â–„â–‚
wandb:          test_loss â–†â–‡â–‡â–ˆâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–…â–‚â–‚â–„â–‚â–ƒâ–ƒâ–„â–â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–…â–‚â–‚â–„â–â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚â–â–‡â–„â–ƒâ–ˆ
wandb:  valid_error_force â–…â–ˆâ–…â–‡â–ƒâ–†â–‡â–ƒâ–‚â–†â–‚â–„â–„â–â–‡â–ƒâ–…â–‚â–‡â–
wandb:         valid_loss â–ˆâ–…â–†â–„â–…â–…â–†â–ƒâ–‚â–ƒâ–„â–‚â–â–ƒâ–‡â–â–…â–†â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 888
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 11.01021
wandb:   test_error_force 17.18483
wandb:          test_loss 8.41898
wandb: train_error_energy 1.73877
wandb:  train_error_force 2.54919
wandb:         train_loss 1.19352
wandb: valid_error_energy 2.28089
wandb:  valid_error_force 2.57176
wandb:         valid_loss 1.33636
wandb: 
wandb: ğŸš€ View run al_80_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/zt3k6kef
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_204356-zt3k6kef/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7253371477127075, Uncertainty Bias: 0.01552651822566986
8.392334e-05 0.072384834
0.6140555 4.64626
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2850 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1288 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1135 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 594 steps.
Found uncertainty sample 18 after 222 steps.
Found uncertainty sample 19 after 3541 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1044 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 718 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2413 steps.
Found uncertainty sample 30 after 385 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2439 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1336 steps.
Found uncertainty sample 36 after 2797 steps.
Found uncertainty sample 37 after 552 steps.
Found uncertainty sample 38 after 1137 steps.
Found uncertainty sample 39 after 777 steps.
Found uncertainty sample 40 after 3628 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3174 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1314 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3008 steps.
Found uncertainty sample 47 after 342 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1469 steps.
Found uncertainty sample 51 after 1878 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3486 steps.
Found uncertainty sample 54 after 1066 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 905 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 684 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3185 steps.
Found uncertainty sample 63 after 1915 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3010 steps.
Found uncertainty sample 69 after 3169 steps.
Found uncertainty sample 70 after 1668 steps.
Found uncertainty sample 71 after 1578 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 438 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 757 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 807 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2403 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1238 steps.
Found uncertainty sample 88 after 3935 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1950 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241208_230935-rzcrg791
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rzcrg791
Training model 2. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 7.049531673935223, Training Loss Force: 3.341891477746901, time: 1.0634801387786865
Validation Loss Energy: 1.2702095742052608, Validation Loss Force: 2.9292885448588106, time: 0.07721495628356934
Test Loss Energy: 9.980464917285545, Test Loss Force: 16.55980742480912, time: 16.64816951751709


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5289650002037387, Training Loss Force: 2.83015439831262, time: 1.0312602519989014
Validation Loss Energy: 1.1788479782927976, Validation Loss Force: 2.6595277692661927, time: 0.07384490966796875
Test Loss Energy: 10.089172698474947, Test Loss Force: 16.33935839052564, time: 16.80828285217285


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.382689718498982, Training Loss Force: 2.6911701068222897, time: 1.0275287628173828
Validation Loss Energy: 1.222710125999664, Validation Loss Force: 2.6316658470436862, time: 0.07041788101196289
Test Loss Energy: 10.027668547199161, Test Loss Force: 16.4151081723046, time: 16.675381660461426


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5628395191652973, Training Loss Force: 2.6854780384796766, time: 1.0175831317901611
Validation Loss Energy: 1.639694396820233, Validation Loss Force: 2.625369876942578, time: 0.07700657844543457
Test Loss Energy: 10.234338940639793, Test Loss Force: 17.056031841918823, time: 17.174296855926514


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7897500976977039, Training Loss Force: 2.690775437278502, time: 1.0251898765563965
Validation Loss Energy: 1.3248039294075549, Validation Loss Force: 2.6185693385567976, time: 0.07536005973815918
Test Loss Energy: 10.124935480416545, Test Loss Force: 16.67679023032346, time: 16.906877040863037


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3863590180896312, Training Loss Force: 2.6694315861127973, time: 1.0137033462524414
Validation Loss Energy: 1.1278557418641775, Validation Loss Force: 2.619042065153602, time: 0.07354378700256348
Test Loss Energy: 10.176760504697068, Test Loss Force: 16.65847102284787, time: 16.722113132476807


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.1616638075226082, Training Loss Force: 2.653041094558967, time: 1.0323612689971924
Validation Loss Energy: 1.1264891099810457, Validation Loss Force: 2.6163735981088037, time: 0.07563066482543945
Test Loss Energy: 10.091031377292165, Test Loss Force: 16.648582349030796, time: 16.822680473327637


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6535519980457112, Training Loss Force: 2.6767977194857275, time: 1.0624258518218994
Validation Loss Energy: 1.7314397630057028, Validation Loss Force: 2.6372466038480744, time: 0.07232403755187988
Test Loss Energy: 10.121851543056428, Test Loss Force: 16.448316139398774, time: 16.671282291412354


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6070191508439018, Training Loss Force: 2.652035712652117, time: 1.0171856880187988
Validation Loss Energy: 1.4400860923250296, Validation Loss Force: 2.6096647994111453, time: 0.07512617111206055
Test Loss Energy: 10.148674235732294, Test Loss Force: 16.54665462649478, time: 16.80254077911377


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5022166636560719, Training Loss Force: 2.6526105829609317, time: 1.0068116188049316
Validation Loss Energy: 1.1132996371257322, Validation Loss Force: 2.615016206995228, time: 0.07123327255249023
Test Loss Energy: 10.071461356783212, Test Loss Force: 16.573298008720403, time: 16.76901912689209


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.2316904206439718, Training Loss Force: 2.657307619672857, time: 1.1472797393798828
Validation Loss Energy: 1.1383444606485331, Validation Loss Force: 2.612976780287675, time: 0.09752869606018066
Test Loss Energy: 10.161701789063981, Test Loss Force: 16.721686452961112, time: 16.745142221450806


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.342541717100492, Training Loss Force: 2.6550295607450876, time: 0.9774899482727051
Validation Loss Energy: 1.1408448124881563, Validation Loss Force: 2.6096480992252005, time: 0.08224868774414062
Test Loss Energy: 9.937515438529424, Test Loss Force: 16.530091446194334, time: 17.23809814453125


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5082353166119815, Training Loss Force: 2.6530351592744905, time: 1.0191760063171387
Validation Loss Energy: 1.8076990467647598, Validation Loss Force: 2.589286119175834, time: 0.07800054550170898
Test Loss Energy: 10.111152064428031, Test Loss Force: 16.29603881932768, time: 16.789910554885864


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4101000696131085, Training Loss Force: 2.654894899659526, time: 1.0482079982757568
Validation Loss Energy: 1.531668576030253, Validation Loss Force: 2.622313297576427, time: 0.07622671127319336
Test Loss Energy: 10.166245424100868, Test Loss Force: 16.824751019233595, time: 16.866708517074585


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3954827481355874, Training Loss Force: 2.648406351460176, time: 1.0269660949707031
Validation Loss Energy: 2.1869704010124043, Validation Loss Force: 2.5858730465070527, time: 0.07515120506286621
Test Loss Energy: 10.233204838881495, Test Loss Force: 16.42714950417025, time: 16.759663343429565


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5376196316243191, Training Loss Force: 2.675954740168723, time: 1.0485436916351318
Validation Loss Energy: 1.4611706337529318, Validation Loss Force: 2.623550447351202, time: 0.07320570945739746
Test Loss Energy: 9.953908229135148, Test Loss Force: 16.68138434014224, time: 16.905032634735107


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3493257568542965, Training Loss Force: 2.6504063734071455, time: 1.0297834873199463
Validation Loss Energy: 1.5350937841674872, Validation Loss Force: 2.618187683640677, time: 0.07403016090393066
Test Loss Energy: 10.081029097910001, Test Loss Force: 16.57483076052995, time: 16.832300901412964


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6633763968701223, Training Loss Force: 2.644792131770158, time: 0.9933404922485352
Validation Loss Energy: 1.1442669032573474, Validation Loss Force: 2.604522478155089, time: 0.07403969764709473
Test Loss Energy: 10.013115707886255, Test Loss Force: 16.643640217829194, time: 16.774686098098755


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4773511924520693, Training Loss Force: 2.6428861376287407, time: 1.032393217086792
Validation Loss Energy: 1.6535443063623685, Validation Loss Force: 2.6031835685806253, time: 0.07504916191101074
Test Loss Energy: 9.910838467071173, Test Loss Force: 16.10115264600339, time: 16.833515644073486


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5952517084195774, Training Loss Force: 2.641823982767926, time: 1.056065320968628
Validation Loss Energy: 1.4168335327578014, Validation Loss Force: 2.581327701231229, time: 0.07679343223571777
Test Loss Energy: 10.069818319627043, Test Loss Force: 16.173863252749605, time: 17.17676877975464

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–…â–„â–ˆâ–†â–‡â–…â–†â–†â–„â–†â–‚â–…â–‡â–ˆâ–‚â–…â–ƒâ–â–„
wandb:   test_error_force â–„â–ƒâ–ƒâ–ˆâ–…â–…â–…â–„â–„â–„â–†â–„â–‚â–†â–ƒâ–…â–„â–…â–â–‚
wandb:          test_loss â–…â–„â–„â–ˆâ–…â–…â–…â–„â–„â–…â–…â–„â–‚â–†â–„â–…â–„â–…â–â–‚
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–â–‚â–„â–‚â–â–â–…â–ƒâ–â–â–â–†â–„â–ˆâ–ƒâ–„â–â–…â–ƒ
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–
wandb:         valid_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–…â–‚â–‚â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 924
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.06982
wandb:   test_error_force 16.17386
wandb:          test_loss 7.92763
wandb: train_error_energy 1.59525
wandb:  train_error_force 2.64182
wandb:         train_loss 1.21618
wandb: valid_error_energy 1.41683
wandb:  valid_error_force 2.58133
wandb:         valid_loss 1.3033
wandb: 
wandb: ğŸš€ View run al_80_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/rzcrg791
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241208_230935-rzcrg791/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6591656804084778, Uncertainty Bias: 0.028874218463897705
0.00010681152 0.0039310455
0.54839355 4.3907504
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2075 steps.
Found uncertainty sample 5 after 657 steps.
Found uncertainty sample 6 after 1774 steps.
Found uncertainty sample 7 after 1937 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2913 steps.
Found uncertainty sample 10 after 2061 steps.
Found uncertainty sample 11 after 1228 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1836 steps.
Found uncertainty sample 15 after 2363 steps.
Found uncertainty sample 16 after 3732 steps.
Found uncertainty sample 17 after 3355 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3418 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 739 steps.
Found uncertainty sample 22 after 891 steps.
Found uncertainty sample 23 after 2356 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 57 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 531 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2452 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3007 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3268 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1698 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 699 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2154 steps.
Found uncertainty sample 52 after 1961 steps.
Found uncertainty sample 53 after 3138 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 768 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 845 steps.
Found uncertainty sample 69 after 503 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2213 steps.
Found uncertainty sample 74 after 867 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3256 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3804 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1179 steps.
Found uncertainty sample 85 after 2323 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 61 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_014610-bt4lm5dv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/bt4lm5dv
Training model 3. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7563263500822472, Training Loss Force: 3.0388983523075668, time: 1.0618703365325928
Validation Loss Energy: 2.570343654931757, Validation Loss Force: 2.7278315297795412, time: 0.08261728286743164
Test Loss Energy: 10.090715187104948, Test Loss Force: 16.002237196336715, time: 17.204938173294067


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.505632906352869, Training Loss Force: 2.8482895479264494, time: 1.0792136192321777
Validation Loss Energy: 1.135116092036299, Validation Loss Force: 2.6687255636770315, time: 0.07865262031555176
Test Loss Energy: 9.768936148884775, Test Loss Force: 16.182318473538142, time: 17.30098867416382


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3369297321641098, Training Loss Force: 2.7822493231937244, time: 1.0967762470245361
Validation Loss Energy: 1.1895306419032563, Validation Loss Force: 2.6724597252542406, time: 0.07766294479370117
Test Loss Energy: 9.703403742551327, Test Loss Force: 15.993495555409707, time: 17.57569718360901


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2893905171046265, Training Loss Force: 2.7360902467566506, time: 1.0832972526550293
Validation Loss Energy: 1.590647398050438, Validation Loss Force: 2.651860157226169, time: 0.0767827033996582
Test Loss Energy: 9.726794308608039, Test Loss Force: 15.710002679157348, time: 17.328062057495117


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4673732386811524, Training Loss Force: 2.7685514447221236, time: 1.0667400360107422
Validation Loss Energy: 1.6886277229910318, Validation Loss Force: 2.655925205154227, time: 0.07745575904846191
Test Loss Energy: 9.787774961224326, Test Loss Force: 15.791693656134381, time: 17.3491268157959


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.496903125375246, Training Loss Force: 2.76588356403941, time: 1.0573644638061523
Validation Loss Energy: 1.2955545557367725, Validation Loss Force: 2.674123286443467, time: 0.07628059387207031
Test Loss Energy: 9.663742469202825, Test Loss Force: 15.869206357339738, time: 17.22356915473938


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3410399095613181, Training Loss Force: 2.7582778688665637, time: 1.0698175430297852
Validation Loss Energy: 1.4935243493216663, Validation Loss Force: 2.7033971537203016, time: 0.07829737663269043
Test Loss Energy: 9.688168346528693, Test Loss Force: 15.907574773989545, time: 17.3235285282135


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9886422808155786, Training Loss Force: 2.7632524979888218, time: 1.0475573539733887
Validation Loss Energy: 2.418371740166896, Validation Loss Force: 2.6627197314730675, time: 0.07585883140563965
Test Loss Energy: 9.713441490447082, Test Loss Force: 15.275320828997234, time: 17.242536306381226


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1811321273407507, Training Loss Force: 2.7896180390168634, time: 1.1312694549560547
Validation Loss Energy: 1.949883205216646, Validation Loss Force: 2.6746761739328058, time: 0.09798836708068848
Test Loss Energy: 9.658964007984126, Test Loss Force: 15.685016752789453, time: 17.2830491065979


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5310673767585528, Training Loss Force: 2.7424840576804788, time: 1.0668890476226807
Validation Loss Energy: 1.3715951783945282, Validation Loss Force: 2.645415444135581, time: 0.08168506622314453
Test Loss Energy: 9.619505267962241, Test Loss Force: 15.684326315224093, time: 17.37979769706726


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3777926990439169, Training Loss Force: 2.7486533884159927, time: 1.0490868091583252
Validation Loss Energy: 1.3498837119862663, Validation Loss Force: 2.645052048089427, time: 0.0764315128326416
Test Loss Energy: 9.649418291284066, Test Loss Force: 15.570760382909507, time: 17.308830976486206


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6011006901736766, Training Loss Force: 2.7403385439695014, time: 1.065908670425415
Validation Loss Energy: 1.1213310905502016, Validation Loss Force: 2.6402181236004805, time: 0.08212113380432129
Test Loss Energy: 9.551968941906463, Test Loss Force: 15.745920774576946, time: 17.681657552719116


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4144553353560576, Training Loss Force: 2.762745792080349, time: 1.069563388824463
Validation Loss Energy: 1.3231640824823696, Validation Loss Force: 2.654626821364322, time: 0.08098244667053223
Test Loss Energy: 9.593685379191845, Test Loss Force: 15.805249208140767, time: 17.210310459136963


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.461900558057893, Training Loss Force: 2.754430747231625, time: 1.3069093227386475
Validation Loss Energy: 1.4118681221381846, Validation Loss Force: 2.6218185267341756, time: 0.07743263244628906
Test Loss Energy: 9.594328181881275, Test Loss Force: 15.66525506893879, time: 17.222704648971558


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7061266639847357, Training Loss Force: 2.728963253136024, time: 1.0872931480407715
Validation Loss Energy: 2.488272483794839, Validation Loss Force: 2.664709502961078, time: 0.08148479461669922
Test Loss Energy: 9.919020446004097, Test Loss Force: 15.742072091110305, time: 17.335134267807007


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.858741231593964, Training Loss Force: 2.722597810261386, time: 1.0933778285980225
Validation Loss Energy: 1.1870079118144674, Validation Loss Force: 2.6503301975244993, time: 0.07535195350646973
Test Loss Energy: 9.568109685028684, Test Loss Force: 15.610693918835707, time: 17.278775930404663


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5471079610256129, Training Loss Force: 2.7303092064778043, time: 1.058431625366211
Validation Loss Energy: 2.178307680559229, Validation Loss Force: 2.632612413583025, time: 0.08209013938903809
Test Loss Energy: 9.792524337888821, Test Loss Force: 15.469168865136089, time: 17.39567279815674


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9142314812602885, Training Loss Force: 2.73919441794159, time: 1.065613031387329
Validation Loss Energy: 1.2065231924364435, Validation Loss Force: 2.625351618072612, time: 0.07654786109924316
Test Loss Energy: 9.475674718910215, Test Loss Force: 15.372586260655144, time: 17.389261722564697


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8360450739774274, Training Loss Force: 2.7376872372935486, time: 1.0503740310668945
Validation Loss Energy: 1.1691784592963106, Validation Loss Force: 2.633585255081584, time: 0.07643675804138184
Test Loss Energy: 9.620685367803377, Test Loss Force: 15.836219254722186, time: 17.226290225982666


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6516838462697028, Training Loss Force: 2.754041350851532, time: 1.065006971359253
Validation Loss Energy: 1.597767132656906, Validation Loss Force: 2.6588958342300493, time: 0.07752537727355957
Test Loss Energy: 9.580300025687826, Test Loss Force: 15.680047952585848, time: 17.319379568099976

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–„â–„â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–†â–‚â–…â–â–ƒâ–‚
wandb:   test_error_force â–‡â–ˆâ–‡â–„â–…â–†â–†â–â–„â–„â–ƒâ–…â–…â–„â–…â–„â–‚â–‚â–…â–„
wandb:          test_loss â–‡â–ˆâ–‡â–…â–…â–…â–†â–‚â–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–ƒâ–â–…â–„
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–â–„â–…â–‚â–â–‚â–‚â–‚â–ƒâ–„â–‚â–„â–„â–ƒ
wandb:  train_error_force â–ˆâ–„â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–‚â–‚â–ƒâ–â–â–â–â–â–â–‚â–â–â–‚â–
wandb: valid_error_energy â–ˆâ–â–â–ƒâ–„â–‚â–ƒâ–‡â–…â–‚â–‚â–â–‚â–‚â–ˆâ–â–†â–â–â–ƒ
wandb:  valid_error_force â–ˆâ–„â–„â–ƒâ–ƒâ–„â–†â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–â–„â–ƒâ–‚â–â–‚â–ƒ
wandb:         valid_loss â–ˆâ–…â–‚â–„â–„â–ƒâ–„â–†â–…â–‚â–ƒâ–‚â–ƒâ–ƒâ–†â–â–…â–„â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 955
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.5803
wandb:   test_error_force 15.68005
wandb:          test_loss 7.63192
wandb: train_error_energy 1.65168
wandb:  train_error_force 2.75404
wandb:         train_loss 1.25885
wandb: valid_error_energy 1.59777
wandb:  valid_error_force 2.6589
wandb:         valid_loss 1.38054
wandb: 
wandb: ğŸš€ View run al_80_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/bt4lm5dv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_014610-bt4lm5dv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6626573204994202, Uncertainty Bias: 0.02782408893108368
0.00053596497 0.0010690689
0.74526787 7.584553
(48745, 22, 3)
Found uncertainty sample 0 after 2700 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2560 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1220 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2199 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3814 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3178 steps.
Found uncertainty sample 21 after 3463 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2238 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2909 steps.
Found uncertainty sample 28 after 2584 steps.
Found uncertainty sample 29 after 1250 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3310 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 943 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2271 steps.
Found uncertainty sample 41 after 2354 steps.
Found uncertainty sample 42 after 382 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 843 steps.
Found uncertainty sample 48 after 2129 steps.
Found uncertainty sample 49 after 764 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1157 steps.
Found uncertainty sample 52 after 862 steps.
Found uncertainty sample 53 after 73 steps.
Found uncertainty sample 54 after 2905 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3287 steps.
Found uncertainty sample 58 after 1833 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2033 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 898 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 934 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 180 steps.
Found uncertainty sample 73 after 2867 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 744 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 985 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1049 steps.
Found uncertainty sample 85 after 3318 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2126 steps.
Found uncertainty sample 88 after 1196 steps.
Found uncertainty sample 89 after 2911 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2613 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3541 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_042029-u7rxlxfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/u7rxlxfn
Training model 4. Added 39 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.52673847277688, Training Loss Force: 3.241522016279143, time: 1.124171495437622
Validation Loss Energy: 1.882566091688903, Validation Loss Force: 2.735676386459723, time: 0.07821869850158691
Test Loss Energy: 9.331383149129943, Test Loss Force: 14.731041006039735, time: 17.157610654830933


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6197513759518054, Training Loss Force: 2.894270208675201, time: 1.1093616485595703
Validation Loss Energy: 1.2949783993216843, Validation Loss Force: 2.66559795285333, time: 0.07966995239257812
Test Loss Energy: 9.243818999464413, Test Loss Force: 14.64827825134913, time: 17.31891417503357


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.503529617475834, Training Loss Force: 2.8660670495779987, time: 1.0952117443084717
Validation Loss Energy: 1.2084536225970646, Validation Loss Force: 2.6726545607569276, time: 0.08062911033630371
Test Loss Energy: 9.159658927100493, Test Loss Force: 14.466609634589, time: 17.227059841156006


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5489088244396576, Training Loss Force: 2.861121172788781, time: 1.1456377506256104
Validation Loss Energy: 1.1878096320743803, Validation Loss Force: 2.68413560459011, time: 0.0782318115234375
Test Loss Energy: 9.210650390016136, Test Loss Force: 14.603867993047299, time: 17.3715763092041


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4969241139175407, Training Loss Force: 2.8577831539879273, time: 1.083775520324707
Validation Loss Energy: 1.205232824735792, Validation Loss Force: 2.695212281254288, time: 0.07949399948120117
Test Loss Energy: 9.1550763634347, Test Loss Force: 14.420468306709287, time: 17.813319444656372


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.515217580204308, Training Loss Force: 2.841860801650199, time: 1.1321163177490234
Validation Loss Energy: 1.2115146553461338, Validation Loss Force: 2.660892063123292, time: 0.07848405838012695
Test Loss Energy: 9.26895600509911, Test Loss Force: 14.702855396324896, time: 17.270529747009277


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4012343092651927, Training Loss Force: 2.847317409631419, time: 1.0764412879943848
Validation Loss Energy: 1.807688581314901, Validation Loss Force: 2.6808665988587443, time: 0.07987523078918457
Test Loss Energy: 9.267307581914386, Test Loss Force: 14.23310710543543, time: 17.34827971458435


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7457007736627888, Training Loss Force: 2.837271245774595, time: 1.1529474258422852
Validation Loss Energy: 1.1850362878618497, Validation Loss Force: 2.647778631781313, time: 0.07833266258239746
Test Loss Energy: 9.170717301759845, Test Loss Force: 14.164193471618486, time: 17.318032264709473


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8973325684901206, Training Loss Force: 2.844613071305499, time: 1.320406198501587
Validation Loss Energy: 2.3096194612883267, Validation Loss Force: 2.6613008836752154, time: 0.09695267677307129
Test Loss Energy: 9.678338284826705, Test Loss Force: 14.490312534343216, time: 17.293402433395386


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4539200720446368, Training Loss Force: 2.8211200039206044, time: 1.1397409439086914
Validation Loss Energy: 1.3358674685921228, Validation Loss Force: 2.650897558508323, time: 0.07688117027282715
Test Loss Energy: 9.184800138967013, Test Loss Force: 14.658073320186803, time: 17.453092336654663


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7773200940653127, Training Loss Force: 2.8432000057225655, time: 1.1288280487060547
Validation Loss Energy: 1.1934888086412685, Validation Loss Force: 2.656399267765907, time: 0.08156943321228027
Test Loss Energy: 9.075489794084204, Test Loss Force: 14.30203683205284, time: 17.24549436569214


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.667602899991492, Training Loss Force: 2.813032222385091, time: 1.0811645984649658
Validation Loss Energy: 1.999833684046043, Validation Loss Force: 2.6593941677786357, time: 0.07977819442749023
Test Loss Energy: 9.31756543976134, Test Loss Force: 14.356174463108756, time: 17.39132833480835


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5333256097812098, Training Loss Force: 2.821439333024492, time: 1.0962674617767334
Validation Loss Energy: 1.1925116250943646, Validation Loss Force: 2.6531759092094562, time: 0.08104443550109863
Test Loss Energy: 9.084023021353854, Test Loss Force: 14.332687144393624, time: 17.35391402244568


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.626337026041733, Training Loss Force: 2.835254926378089, time: 1.1624016761779785
Validation Loss Energy: 1.376150098443627, Validation Loss Force: 2.643998600360043, time: 0.07695603370666504
Test Loss Energy: 9.101414325695117, Test Loss Force: 14.225097558691171, time: 17.229320287704468


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4713164133210557, Training Loss Force: 2.8415468740688197, time: 1.1136486530303955
Validation Loss Energy: 1.1831326893333132, Validation Loss Force: 2.646553728809564, time: 0.07892489433288574
Test Loss Energy: 9.016610373436052, Test Loss Force: 14.417378419070007, time: 17.847347497940063


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6080183281084375, Training Loss Force: 2.8400877806185596, time: 1.0905146598815918
Validation Loss Energy: 1.2804497942227608, Validation Loss Force: 2.6508532473482838, time: 0.08087944984436035
Test Loss Energy: 9.10086494611918, Test Loss Force: 14.22837111223583, time: 17.2871835231781


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6140058834852469, Training Loss Force: 2.8242108312379735, time: 1.091590166091919
Validation Loss Energy: 1.1641482519552289, Validation Loss Force: 2.64638717228841, time: 0.0771481990814209
Test Loss Energy: 9.021801814806217, Test Loss Force: 14.381856338977734, time: 17.391443967819214


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5894701462759178, Training Loss Force: 2.8256740404759944, time: 1.1338624954223633
Validation Loss Energy: 1.433331535117883, Validation Loss Force: 2.716490767508293, time: 0.07874727249145508
Test Loss Energy: 9.078443272972564, Test Loss Force: 14.24515777308391, time: 17.369015216827393


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8074094080774756, Training Loss Force: 2.8379258930636238, time: 1.0995867252349854
Validation Loss Energy: 1.1877318092078786, Validation Loss Force: 2.6728280200216052, time: 0.08086943626403809
Test Loss Energy: 9.070916300397236, Test Loss Force: 14.158518043121253, time: 17.766088485717773


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.630146869988493, Training Loss Force: 2.8382504584838775, time: 1.1661529541015625
Validation Loss Energy: 1.1888891320938384, Validation Loss Force: 2.647738105996754, time: 0.07941198348999023
Test Loss Energy: 9.143242018278583, Test Loss Force: 14.071691364340584, time: 18.120466947555542

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–ƒâ–ˆâ–ƒâ–‚â–„â–‚â–‚â–â–‚â–â–‚â–‚â–‚
wandb:   test_error_force â–ˆâ–‡â–…â–‡â–…â–ˆâ–ƒâ–‚â–…â–‡â–ƒâ–„â–„â–ƒâ–…â–ƒâ–„â–ƒâ–‚â–
wandb:          test_loss â–ˆâ–‡â–…â–†â–…â–‡â–ƒâ–ƒâ–†â–‡â–ƒâ–„â–„â–ƒâ–…â–‚â–„â–ƒâ–‚â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–‚â–ƒâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–
wandb: valid_error_energy â–…â–‚â–â–â–â–â–…â–â–ˆâ–‚â–â–†â–â–‚â–â–‚â–â–ƒâ–â–
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–„â–…â–‚â–„â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‡â–ƒâ–
wandb:         valid_loss â–ˆâ–„â–â–ƒâ–ƒâ–‚â–„â–â–†â–„â–â–„â–ƒâ–‚â–†â–‚â–â–…â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 990
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 9.14324
wandb:   test_error_force 14.07169
wandb:          test_loss 6.91537
wandb: train_error_energy 1.63015
wandb:  train_error_force 2.83825
wandb:         train_loss 1.30463
wandb: valid_error_energy 1.18889
wandb:  valid_error_force 2.64774
wandb:         valid_loss 1.3411
wandb: 
wandb: ğŸš€ View run al_80_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/u7rxlxfn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_042029-u7rxlxfn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6230777502059937, Uncertainty Bias: 0.03676876425743103
3.8146973e-05 0.018501282
0.6444391 6.5378685
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3599 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 196 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3978 steps.
Found uncertainty sample 11 after 723 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 99 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1148 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 593 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2107 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3704 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2065 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3235 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2091 steps.
Found uncertainty sample 44 after 1612 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3344 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2747 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 855 steps.
Found uncertainty sample 57 after 906 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3573 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1257 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1938 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1045 steps.
Found uncertainty sample 74 after 1743 steps.
Found uncertainty sample 75 after 2336 steps.
Found uncertainty sample 76 after 27 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1058 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 430 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1364 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3625 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1012 steps.
Found uncertainty sample 91 after 1895 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2529 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 585 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3283 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_065858-2hdwzofv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2hdwzofv
Training model 5. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.146898516083337, Training Loss Force: 3.3263047443075697, time: 1.1567323207855225
Validation Loss Energy: 2.230153296489618, Validation Loss Force: 2.8258195368056698, time: 0.08272194862365723
Test Loss Energy: 9.179202101404774, Test Loss Force: 13.669480210908597, time: 17.639894485473633


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7827802731141835, Training Loss Force: 2.9756996489048095, time: 1.1430175304412842
Validation Loss Energy: 1.7453820802433981, Validation Loss Force: 2.755047934148003, time: 0.08389663696289062
Test Loss Energy: 9.253228181506389, Test Loss Force: 13.62214545568159, time: 17.3908748626709


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6799312872978789, Training Loss Force: 2.9205474379078584, time: 1.1444034576416016
Validation Loss Energy: 1.707757117983115, Validation Loss Force: 2.7227072447243055, time: 0.08247876167297363
Test Loss Energy: 9.092230209698357, Test Loss Force: 13.617727177544825, time: 17.381682634353638


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6021707872926063, Training Loss Force: 2.9203981939128, time: 1.144592523574829
Validation Loss Energy: 1.5707014753002375, Validation Loss Force: 2.707214370888942, time: 0.08194851875305176
Test Loss Energy: 9.237101003714963, Test Loss Force: 13.82634566253993, time: 17.485692977905273


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.444804378463926, Training Loss Force: 2.900502002924661, time: 1.1204290390014648
Validation Loss Energy: 1.2757209695706926, Validation Loss Force: 2.7229684356324784, time: 0.08206987380981445
Test Loss Energy: 8.880454313519822, Test Loss Force: 13.409004059035658, time: 17.40400242805481


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4188893012931418, Training Loss Force: 2.903571524934918, time: 1.0949769020080566
Validation Loss Energy: 1.8524474176724186, Validation Loss Force: 2.717791600658803, time: 0.07950520515441895
Test Loss Energy: 9.047660473655762, Test Loss Force: 13.443984696366373, time: 17.27752375602722


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8940507260620638, Training Loss Force: 2.9134952555535367, time: 1.06787109375
Validation Loss Energy: 1.2202821416324674, Validation Loss Force: 2.7266447032317465, time: 0.08402442932128906
Test Loss Energy: 8.899999318141164, Test Loss Force: 13.469778345151761, time: 17.408517837524414


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9123122576202773, Training Loss Force: 2.9290729593750875, time: 1.1383159160614014
Validation Loss Energy: 1.189796842867213, Validation Loss Force: 2.718949034879336, time: 0.0846104621887207
Test Loss Energy: 8.870879619519803, Test Loss Force: 13.20309315624338, time: 17.345926761627197


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8345637139043798, Training Loss Force: 2.915644639068712, time: 1.373927116394043
Validation Loss Energy: 1.3226189884131383, Validation Loss Force: 2.7044212091224233, time: 0.07864618301391602
Test Loss Energy: 9.067888727476216, Test Loss Force: 13.677041957176511, time: 17.292768478393555


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5453192523540698, Training Loss Force: 2.9001824657418434, time: 1.1036057472229004
Validation Loss Energy: 1.297301061182857, Validation Loss Force: 2.746028943061344, time: 0.07995343208312988
Test Loss Energy: 8.975976672450493, Test Loss Force: 13.591796886847101, time: 17.410364866256714


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3404356426742126, Training Loss Force: 2.9008858010313103, time: 1.1541569232940674
Validation Loss Energy: 1.3370921488947256, Validation Loss Force: 2.70236597290551, time: 0.08003830909729004
Test Loss Energy: 9.001613065523348, Test Loss Force: 13.589965147499118, time: 17.251320123672485


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4081990217020515, Training Loss Force: 2.8880866741472193, time: 1.1214690208435059
Validation Loss Energy: 1.4227036481173228, Validation Loss Force: 2.7338300139016902, time: 0.08003973960876465
Test Loss Energy: 8.84059723821459, Test Loss Force: 13.026689384728309, time: 17.45738983154297


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.500950160065239, Training Loss Force: 2.8780926983714714, time: 1.141570806503296
Validation Loss Energy: 1.6264223137117801, Validation Loss Force: 2.7143135085994112, time: 0.08295011520385742
Test Loss Energy: 8.93888388653446, Test Loss Force: 13.32951472265609, time: 17.52927279472351


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6049998092292352, Training Loss Force: 2.888010611758652, time: 1.1962165832519531
Validation Loss Energy: 1.755158035091639, Validation Loss Force: 2.7258702599422096, time: 0.08423733711242676
Test Loss Energy: 9.177890936872215, Test Loss Force: 13.547653770898417, time: 17.49890899658203


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6804326773284135, Training Loss Force: 2.8980211555105386, time: 1.22882080078125
Validation Loss Energy: 1.7769164846896917, Validation Loss Force: 2.7030177254956405, time: 0.08008813858032227
Test Loss Energy: 8.904769210678067, Test Loss Force: 13.431867652327874, time: 17.99961757659912


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7839109470263428, Training Loss Force: 2.885778673657623, time: 1.1834416389465332
Validation Loss Energy: 1.1779388201699745, Validation Loss Force: 2.7241098376745043, time: 0.08077502250671387
Test Loss Energy: 8.831442318689508, Test Loss Force: 13.27677933364245, time: 17.569621562957764


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.680641687113921, Training Loss Force: 2.879986471623944, time: 1.1791133880615234
Validation Loss Energy: 1.2410282259585594, Validation Loss Force: 2.703879677759527, time: 0.08205366134643555
Test Loss Energy: 8.956469297749004, Test Loss Force: 13.188750619195252, time: 17.66930842399597


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6203852017116211, Training Loss Force: 2.865999265678112, time: 1.1967649459838867
Validation Loss Energy: 1.593176474209886, Validation Loss Force: 2.722464090016952, time: 0.08270955085754395
Test Loss Energy: 8.81071816086235, Test Loss Force: 13.08020606031885, time: 17.67314600944519


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9399471373356616, Training Loss Force: 2.918494866762285, time: 1.165999412536621
Validation Loss Energy: 1.9382977295540231, Validation Loss Force: 2.7306335983118966, time: 0.0772409439086914
Test Loss Energy: 8.985824239911098, Test Loss Force: 13.284292913426425, time: 17.52323293685913


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.509275040975563, Training Loss Force: 2.8876499155758926, time: 1.132011890411377
Validation Loss Energy: 1.2362391693025176, Validation Loss Force: 2.704305866504833, time: 0.08404827117919922
Test Loss Energy: 8.942637316570536, Test Loss Force: 13.318272313696339, time: 17.533795595169067

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–ˆâ–…â–ˆâ–‚â–…â–‚â–‚â–…â–„â–„â–â–ƒâ–‡â–‚â–â–ƒâ–â–„â–ƒ
wandb:   test_error_force â–‡â–†â–†â–ˆâ–„â–…â–…â–ƒâ–‡â–†â–†â–â–„â–†â–…â–ƒâ–‚â–â–ƒâ–„
wandb:          test_loss â–‡â–‡â–†â–ˆâ–„â–…â–†â–ƒâ–†â–…â–…â–â–ƒâ–…â–„â–ƒâ–‚â–â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–…â–„â–‚â–…â–â–â–‚â–‚â–‚â–ƒâ–„â–…â–…â–â–â–„â–†â–
wandb:  valid_error_force â–ˆâ–„â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–â–ƒâ–‚â–‚â–â–‚â–â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–â–â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1019
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.94264
wandb:   test_error_force 13.31827
wandb:          test_loss 6.56122
wandb: train_error_energy 1.50928
wandb:  train_error_force 2.88765
wandb:         train_loss 1.30593
wandb: valid_error_energy 1.23624
wandb:  valid_error_force 2.70431
wandb:         valid_loss 1.34715
wandb: 
wandb: ğŸš€ View run al_80_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2hdwzofv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_065858-2hdwzofv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.655900776386261, Uncertainty Bias: 0.03155064582824707
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:995: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  # Calculate the average uncertainty for each bin
0.00032043457 0.010718346
0.53154343 7.009195
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1437 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1598 steps.
Found uncertainty sample 5 after 1566 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2508 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3917 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 147 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3208 steps.
Found uncertainty sample 24 after 370 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 270 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3929 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1430 steps.
Found uncertainty sample 33 after 1736 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 605 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 298 steps.
Found uncertainty sample 39 after 630 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1929 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1196 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1645 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2235 steps.
Found uncertainty sample 50 after 3525 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2371 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 245 steps.
Found uncertainty sample 55 after 2789 steps.
Found uncertainty sample 56 after 2393 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1117 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1858 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2531 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1519 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1991 steps.
Found uncertainty sample 76 after 2371 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1443 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3741 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 462 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1320 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3941 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1340 steps.
Found uncertainty sample 94 after 492 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2829 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_093158-679rnw61
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/679rnw61
Training model 6. Added 38 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.977702495246732, Training Loss Force: 3.3520978742745995, time: 1.1638679504394531
Validation Loss Energy: 1.8842365556216534, Validation Loss Force: 2.8020887952475615, time: 0.08039522171020508
Test Loss Energy: 9.174188860636544, Test Loss Force: 13.613370342102652, time: 16.917643785476685


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9481447057384902, Training Loss Force: 3.017787027155185, time: 1.1510403156280518
Validation Loss Energy: 1.6558325658404953, Validation Loss Force: 2.7436443791776033, time: 0.0816655158996582
Test Loss Energy: 8.977979696833012, Test Loss Force: 13.271770965947677, time: 17.190728902816772


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7846989788270264, Training Loss Force: 3.0069641528320648, time: 1.1669082641601562
Validation Loss Energy: 2.6107347246573283, Validation Loss Force: 2.752906079633324, time: 0.07935643196105957
Test Loss Energy: 8.920849383129369, Test Loss Force: 12.857400459007856, time: 17.00692319869995


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7006678148265908, Training Loss Force: 2.99879741778012, time: 1.1513700485229492
Validation Loss Energy: 2.413440954599471, Validation Loss Force: 2.779586742036683, time: 0.0791468620300293
Test Loss Energy: 9.353530675754678, Test Loss Force: 13.246982051644226, time: 17.04228639602661


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9442986697843267, Training Loss Force: 2.986721172572323, time: 1.1401424407958984
Validation Loss Energy: 1.255410648763181, Validation Loss Force: 2.7575438326047075, time: 0.08063650131225586
Test Loss Energy: 8.736120417948907, Test Loss Force: 13.094930907466662, time: 17.242460250854492


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6221759557447633, Training Loss Force: 2.98614169973647, time: 1.2641842365264893
Validation Loss Energy: 1.4019401955978483, Validation Loss Force: 2.742695140608513, time: 0.08306264877319336
Test Loss Energy: 8.667346729941473, Test Loss Force: 12.829784709767148, time: 17.693249464035034


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8192420196107095, Training Loss Force: 3.0095915407932154, time: 1.1193218231201172
Validation Loss Energy: 1.4343286475533477, Validation Loss Force: 2.7321824848909704, time: 0.08057785034179688
Test Loss Energy: 8.755847871373067, Test Loss Force: 13.22315038617008, time: 17.16349697113037


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8731856411029042, Training Loss Force: 2.9967021078644893, time: 1.173750877380371
Validation Loss Energy: 1.5525273309441845, Validation Loss Force: 2.757700814352587, time: 0.08414721488952637
Test Loss Energy: 8.881547273947442, Test Loss Force: 12.98774635577485, time: 17.02776575088501


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5698714203915052, Training Loss Force: 2.9698455368358467, time: 1.1454544067382812
Validation Loss Energy: 2.0356406640643985, Validation Loss Force: 2.7529461600795906, time: 0.08339285850524902
Test Loss Energy: 8.720951351684004, Test Loss Force: 12.96949198116074, time: 17.14569330215454


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6727642602213457, Training Loss Force: 2.972341010196909, time: 1.1866068840026855
Validation Loss Energy: 1.2465233664763384, Validation Loss Force: 2.7347970660024545, time: 0.08358001708984375
Test Loss Energy: 8.773009754213986, Test Loss Force: 12.995883404504186, time: 17.127639770507812


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.413631978908777, Training Loss Force: 2.9686627318277785, time: 1.125833511352539
Validation Loss Energy: 1.319585455303591, Validation Loss Force: 2.7546524737448355, time: 0.08376288414001465
Test Loss Energy: 8.653800215271314, Test Loss Force: 12.908237321919415, time: 17.968679428100586


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6195448650656188, Training Loss Force: 2.9789488385582144, time: 1.270556926727295
Validation Loss Energy: 1.5611029877613014, Validation Loss Force: 2.760712859889552, time: 0.08301901817321777
Test Loss Energy: 8.616900988299252, Test Loss Force: 12.458205803329944, time: 18.232996940612793


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5998565722041442, Training Loss Force: 2.9719867773234876, time: 1.1743433475494385
Validation Loss Energy: 1.3765550222854968, Validation Loss Force: 2.7417746263592475, time: 0.08223724365234375
Test Loss Energy: 8.682251883138749, Test Loss Force: 12.903242333026315, time: 17.43562889099121


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5698463717994757, Training Loss Force: 2.960620414848008, time: 1.1684315204620361
Validation Loss Energy: 1.6911329735518654, Validation Loss Force: 2.737564843486337, time: 0.08479571342468262
Test Loss Energy: 8.760418828263902, Test Loss Force: 12.80494214968663, time: 17.29241180419922


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.870761393191452, Training Loss Force: 2.968137003226693, time: 1.2242777347564697
Validation Loss Energy: 1.2403591051750464, Validation Loss Force: 2.745483180984675, time: 0.08382415771484375
Test Loss Energy: 8.48771754338632, Test Loss Force: 12.628538014439759, time: 17.419353008270264


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6517543905541527, Training Loss Force: 2.9636023460698735, time: 1.23337984085083
Validation Loss Energy: 1.3320151810329992, Validation Loss Force: 2.799451724552339, time: 0.08127784729003906
Test Loss Energy: 8.774362964743492, Test Loss Force: 12.898109303252419, time: 17.3892183303833


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7169352669024884, Training Loss Force: 2.9806011380866964, time: 1.1633236408233643
Validation Loss Energy: 1.5359263441041113, Validation Loss Force: 2.732777679518035, time: 0.0837240219116211
Test Loss Energy: 8.458716852679906, Test Loss Force: 12.280195829498153, time: 17.436026334762573


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8222655579120024, Training Loss Force: 2.9668873367468973, time: 1.1645336151123047
Validation Loss Energy: 1.2929379706029749, Validation Loss Force: 2.7411084002746318, time: 0.08309698104858398
Test Loss Energy: 8.471980507586315, Test Loss Force: 12.656968667469368, time: 17.50217342376709


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5190996770239777, Training Loss Force: 2.966271865732453, time: 1.197300910949707
Validation Loss Energy: 1.5322868169139217, Validation Loss Force: 2.746759075190841, time: 0.08085370063781738
Test Loss Energy: 8.57919469642487, Test Loss Force: 12.71473368849831, time: 17.355619430541992


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1326545779214663, Training Loss Force: 2.973679872538524, time: 1.1537091732025146
Validation Loss Energy: 1.3635381180182773, Validation Loss Force: 2.7510254160268177, time: 0.08402514457702637
Test Loss Energy: 8.466377326483382, Test Loss Force: 12.646120310617878, time: 17.506775379180908

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–…â–…â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–â–â–‚â–
wandb:   test_error_force â–ˆâ–†â–„â–†â–…â–„â–†â–…â–…â–…â–„â–‚â–„â–„â–ƒâ–„â–â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–ˆâ–‡â–„â–†â–…â–„â–†â–…â–…â–…â–„â–‚â–„â–„â–ƒâ–„â–â–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚
wandb: valid_error_energy â–„â–ƒâ–ˆâ–‡â–â–‚â–‚â–ƒâ–…â–â–â–ƒâ–‚â–ƒâ–â–â–ƒâ–â–‚â–‚
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–†â–„â–‚â–â–„â–ƒâ–â–ƒâ–„â–‚â–‚â–‚â–ˆâ–â–‚â–‚â–ƒ
wandb:         valid_loss â–ˆâ–‡â–‡â–‡â–‚â–‡â–„â–‡â–…â–â–‚â–ƒâ–‚â–„â–â–†â–†â–†â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1053
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.46638
wandb:   test_error_force 12.64612
wandb:          test_loss 6.29015
wandb: train_error_energy 2.13265
wandb:  train_error_force 2.97368
wandb:         train_loss 1.39972
wandb: valid_error_energy 1.36354
wandb:  valid_error_force 2.75103
wandb:         valid_loss 1.40913
wandb: 
wandb: ğŸš€ View run al_80_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/679rnw61
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_093158-679rnw61/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6882468461990356, Uncertainty Bias: 0.024046212434768677
8.869171e-05 0.006336212
0.5020176 7.4658732
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2618 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1088 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1370 steps.
Found uncertainty sample 6 after 2000 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 544 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 918 steps.
Found uncertainty sample 14 after 3135 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3565 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 981 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3505 steps.
Found uncertainty sample 26 after 1652 steps.
Found uncertainty sample 27 after 1651 steps.
Found uncertainty sample 28 after 2065 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1730 steps.
Found uncertainty sample 33 after 1154 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 63 steps.
Found uncertainty sample 37 after 1025 steps.
Found uncertainty sample 38 after 3275 steps.
Found uncertainty sample 39 after 1619 steps.
Found uncertainty sample 40 after 1961 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1337 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 740 steps.
Found uncertainty sample 52 after 1926 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2284 steps.
Found uncertainty sample 57 after 2985 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1463 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2778 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1882 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 838 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 530 steps.
Found uncertainty sample 74 after 3447 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1961 steps.
Found uncertainty sample 78 after 2111 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3771 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 129 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3786 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1943 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2775 steps.
Found uncertainty sample 93 after 2521 steps.
Found uncertainty sample 94 after 2016 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_120527-qyfa2ih2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qyfa2ih2
Training model 7. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.487959915564849, Training Loss Force: 3.3763300902693683, time: 1.222409725189209
Validation Loss Energy: 1.2462283298579842, Validation Loss Force: 3.0568507998396295, time: 0.08611130714416504
Test Loss Energy: 8.61973060951535, Test Loss Force: 12.913646265578679, time: 17.107927799224854


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6700114101974648, Training Loss Force: 3.1229580119340836, time: 1.2271904945373535
Validation Loss Energy: 1.3818075647687873, Validation Loss Force: 2.898381399396596, time: 0.08509111404418945
Test Loss Energy: 8.388036072220215, Test Loss Force: 12.443910868515145, time: 17.283349752426147


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0390085380775442, Training Loss Force: 3.0713277107058325, time: 1.252357006072998
Validation Loss Energy: 2.890669476196533, Validation Loss Force: 2.840683815642079, time: 0.08108377456665039
Test Loss Energy: 8.6858363457647, Test Loss Force: 12.076983653438381, time: 17.166136264801025


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.834864618948194, Training Loss Force: 3.146502595724221, time: 1.2358453273773193
Validation Loss Energy: 3.499612587007675, Validation Loss Force: 2.81035048856892, time: 0.08115577697753906
Test Loss Energy: 8.93035855877336, Test Loss Force: 12.10384427214909, time: 17.34524416923523


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.160535762567392, Training Loss Force: 3.1234026313226972, time: 1.2396605014801025
Validation Loss Energy: 1.7260266760681982, Validation Loss Force: 2.851537377822037, time: 0.08142232894897461
Test Loss Energy: 8.436888461070989, Test Loss Force: 12.040389441227184, time: 17.983983278274536


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4600325049473508, Training Loss Force: 3.1076814961648553, time: 1.382157564163208
Validation Loss Energy: 1.338194695170787, Validation Loss Force: 2.8535963994144318, time: 0.0866398811340332
Test Loss Energy: 8.39519616998116, Test Loss Force: 12.491740891218207, time: 18.20460319519043


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7522877041516114, Training Loss Force: 3.0985329561690946, time: 1.2432618141174316
Validation Loss Energy: 1.3058067998881526, Validation Loss Force: 2.8218704995026402, time: 0.08397579193115234
Test Loss Energy: 8.394853170895097, Test Loss Force: 11.953578360944796, time: 17.535950899124146


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6902552753983742, Training Loss Force: 3.062925735822539, time: 1.2541186809539795
Validation Loss Energy: 1.3770519084846347, Validation Loss Force: 2.8060999572423047, time: 0.0853123664855957
Test Loss Energy: 8.251145518890324, Test Loss Force: 11.882114099859344, time: 17.56045389175415


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8540621920517724, Training Loss Force: 3.170882894990878, time: 1.2905795574188232
Validation Loss Energy: 2.6157318656302397, Validation Loss Force: 2.7826526735069628, time: 0.08712482452392578
Test Loss Energy: 8.50249027489277, Test Loss Force: 11.5996297259773, time: 17.384264707565308


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9434888058100743, Training Loss Force: 3.196860743587958, time: 1.2112267017364502
Validation Loss Energy: 1.3198713624869625, Validation Loss Force: 2.7956681304247337, time: 0.08243799209594727
Test Loss Energy: 8.413354817847043, Test Loss Force: 11.988098732990226, time: 17.642178297042847


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7303508257906923, Training Loss Force: 3.046878759360497, time: 1.2403428554534912
Validation Loss Energy: 1.3759906673351427, Validation Loss Force: 2.79882446556826, time: 0.08394098281860352
Test Loss Energy: 8.369113659857344, Test Loss Force: 11.59857141566672, time: 17.516135931015015


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9390520690006703, Training Loss Force: 3.0791673378420725, time: 1.2349786758422852
Validation Loss Energy: 1.3775735109589704, Validation Loss Force: 2.7970909862672126, time: 0.08293771743774414
Test Loss Energy: 8.398790101291945, Test Loss Force: 12.059653367437946, time: 17.67996573448181


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9227250049724358, Training Loss Force: 3.0501884880976657, time: 1.1818981170654297
Validation Loss Energy: 2.4402075672931587, Validation Loss Force: 2.816450509821612, time: 0.08816695213317871
Test Loss Energy: 8.950414067968856, Test Loss Force: 12.11549851410617, time: 17.59983229637146


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8570811657801638, Training Loss Force: 3.1464738395945178, time: 1.2122349739074707
Validation Loss Energy: 1.499750623980099, Validation Loss Force: 2.805945647524177, time: 0.08594512939453125
Test Loss Energy: 8.278356707438057, Test Loss Force: 11.928344500060657, time: 17.487426280975342


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6483904444825774, Training Loss Force: 3.0622256640277414, time: 1.285531997680664
Validation Loss Energy: 2.768800871277087, Validation Loss Force: 2.896546382965005, time: 0.08681726455688477
Test Loss Energy: 9.411100270216759, Test Loss Force: 12.413181775597373, time: 18.008323907852173


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.91385270672862, Training Loss Force: 3.056071139730103, time: 1.252943992614746
Validation Loss Energy: 1.3133465998384135, Validation Loss Force: 2.8062426881648443, time: 0.08609485626220703
Test Loss Energy: 8.28393370917795, Test Loss Force: 11.77856714128383, time: 17.606720447540283


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6660386983927415, Training Loss Force: 3.0718789758913934, time: 1.243129014968872
Validation Loss Energy: 1.8138505045901607, Validation Loss Force: 2.8379383050727895, time: 0.0832676887512207
Test Loss Energy: 8.660245484451863, Test Loss Force: 12.006789870219555, time: 17.547271490097046


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.907881995810945, Training Loss Force: 3.050958948790478, time: 1.2315571308135986
Validation Loss Energy: 2.3165215368046503, Validation Loss Force: 2.7626451827379133, time: 0.08264994621276855
Test Loss Energy: 8.297731121845867, Test Loss Force: 11.41882085927155, time: 17.597819328308105


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9013290209816063, Training Loss Force: 3.0504016969858796, time: 1.2626025676727295
Validation Loss Energy: 1.4552652253337808, Validation Loss Force: 2.796549454904316, time: 0.0849299430847168
Test Loss Energy: 8.45148536089542, Test Loss Force: 11.599867266157917, time: 17.516247987747192


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.084002319012906, Training Loss Force: 3.0431558139462673, time: 1.247476577758789
Validation Loss Energy: 2.3531120895475257, Validation Loss Force: 2.804085469479096, time: 0.08447861671447754
Test Loss Energy: 8.845658454274403, Test Loss Force: 11.776480220763, time: 17.581780672073364

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–„â–…â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–…â–â–ˆâ–â–ƒâ–â–‚â–…
wandb:   test_error_force â–ˆâ–†â–„â–„â–„â–†â–„â–ƒâ–‚â–„â–‚â–„â–„â–ƒâ–†â–ƒâ–„â–â–‚â–ƒ
wandb:          test_loss â–ˆâ–†â–„â–†â–…â–†â–ƒâ–ƒâ–‚â–„â–â–ƒâ–„â–„â–†â–‚â–ƒâ–â–‚â–‚
wandb: train_error_energy â–ˆâ–â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–„â–„â–â–‚â–â–ƒâ–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–â–‚â–â–‚â–â–‚â–â–â–â–‚
wandb: valid_error_energy â–â–â–†â–ˆâ–‚â–â–â–â–…â–â–â–â–…â–‚â–†â–â–ƒâ–„â–‚â–„
wandb:  valid_error_force â–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–„â–‚â–ƒâ–â–‚â–‚
wandb:         valid_loss â–…â–…â–…â–ˆâ–…â–…â–â–‚â–…â–„â–…â–‚â–„â–„â–†â–‚â–ƒâ–…â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1089
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.84566
wandb:   test_error_force 11.77648
wandb:          test_loss 5.90213
wandb: train_error_energy 2.084
wandb:  train_error_force 3.04316
wandb:         train_loss 1.44181
wandb: valid_error_energy 2.35311
wandb:  valid_error_force 2.80409
wandb:         valid_loss 1.51624
wandb: 
wandb: ğŸš€ View run al_80_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qyfa2ih2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_120527-qyfa2ih2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6483683586120605, Uncertainty Bias: 0.031881123781204224
2.193451e-05 0.027881622
1.0349456 8.775323
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2806 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2706 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 681 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1235 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1364 steps.
Found uncertainty sample 19 after 2056 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1593 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3043 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 780 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1271 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3328 steps.
Found uncertainty sample 45 after 1626 steps.
Found uncertainty sample 46 after 693 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3725 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1340 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1901 steps.
Found uncertainty sample 58 after 973 steps.
Found uncertainty sample 59 after 13 steps.
Found uncertainty sample 60 after 3303 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 348 steps.
Found uncertainty sample 63 after 1755 steps.
Found uncertainty sample 64 after 1732 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3236 steps.
Found uncertainty sample 67 after 1229 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2298 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 380 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2635 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1485 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2078 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1346 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3383 steps.
Found uncertainty sample 98 after 1727 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_144428-31r20iio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/31r20iio
Training model 8. Added 32 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8769533271913432, Training Loss Force: 3.386248359330747, time: 1.24920654296875
Validation Loss Energy: 2.057527037086787, Validation Loss Force: 2.9275120904125984, time: 0.08314704895019531
Test Loss Energy: 8.98083901115459, Test Loss Force: 11.809724840830723, time: 17.137218713760376


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6291604873327115, Training Loss Force: 3.168239634093398, time: 1.293945074081421
Validation Loss Energy: 1.3301421995120275, Validation Loss Force: 2.870370066177172, time: 0.08593153953552246
Test Loss Energy: 8.248372178175215, Test Loss Force: 11.85433063295366, time: 17.26654362678528


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8302857715088712, Training Loss Force: 3.1111014715771597, time: 1.2030003070831299
Validation Loss Energy: 1.3428464762983645, Validation Loss Force: 2.841022495413035, time: 0.08263826370239258
Test Loss Energy: 8.410060517600185, Test Loss Force: 11.775243980317718, time: 17.159533739089966


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8899269515325086, Training Loss Force: 3.1280108265554527, time: 1.2386629581451416
Validation Loss Energy: 1.6552868037638264, Validation Loss Force: 2.8712119782179246, time: 0.09126400947570801
Test Loss Energy: 8.409865671605235, Test Loss Force: 11.830259827811632, time: 17.252124071121216


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.616395000388653, Training Loss Force: 3.111351554475939, time: 1.226288080215454
Validation Loss Energy: 1.3553814131992235, Validation Loss Force: 2.8213363162215597, time: 0.0827178955078125
Test Loss Energy: 8.341236019058424, Test Loss Force: 11.611680696735618, time: 17.625518083572388


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7970979245955399, Training Loss Force: 3.115906048272673, time: 1.2193872928619385
Validation Loss Energy: 1.2794159413782182, Validation Loss Force: 2.8424486912927027, time: 0.08489108085632324
Test Loss Energy: 8.469079898047527, Test Loss Force: 11.870720257227452, time: 17.188485383987427


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6817811016350073, Training Loss Force: 3.1128771689482755, time: 1.1803045272827148
Validation Loss Energy: 2.1512894517306433, Validation Loss Force: 2.827254639451174, time: 0.08429312705993652
Test Loss Energy: 8.851296117618164, Test Loss Force: 11.498589760844153, time: 17.245718002319336


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8457633511548972, Training Loss Force: 3.104358324573248, time: 1.188265323638916
Validation Loss Energy: 2.5128996913344523, Validation Loss Force: 2.859124160962089, time: 0.08610820770263672
Test Loss Energy: 8.414811307222822, Test Loss Force: 11.66048467661458, time: 17.09178113937378


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8954907632148916, Training Loss Force: 3.108707288386315, time: 1.4227752685546875
Validation Loss Energy: 1.3856654190565592, Validation Loss Force: 2.8336559320583063, time: 0.08310174942016602
Test Loss Energy: 8.386360646612676, Test Loss Force: 11.49765408410844, time: 17.18416452407837


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.92536585309067, Training Loss Force: 3.0955123346890234, time: 1.247086763381958
Validation Loss Energy: 1.3629634089526377, Validation Loss Force: 2.8425206134268373, time: 0.08404350280761719
Test Loss Energy: 8.285403087716436, Test Loss Force: 11.555483555614153, time: 17.330037593841553


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7656146481661392, Training Loss Force: 3.082302150422151, time: 1.2156858444213867
Validation Loss Energy: 1.6086037719817738, Validation Loss Force: 2.805916700535206, time: 0.08599638938903809
Test Loss Energy: 8.303844989388855, Test Loss Force: 11.429983466407334, time: 17.152397632598877


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6664681730984439, Training Loss Force: 3.0748096899323145, time: 1.2527694702148438
Validation Loss Energy: 2.002512171202408, Validation Loss Force: 2.8240531024710247, time: 0.08419251441955566
Test Loss Energy: 8.347325145844264, Test Loss Force: 11.494511986966373, time: 17.30746603012085


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7948274945540261, Training Loss Force: 3.0942493807412235, time: 1.2318360805511475
Validation Loss Energy: 1.3737865767941766, Validation Loss Force: 2.8208061409851055, time: 0.08984565734863281
Test Loss Energy: 8.162942730798134, Test Loss Force: 11.444376925907266, time: 17.294615507125854


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6503715223309332, Training Loss Force: 3.0877171205044327, time: 1.2087628841400146
Validation Loss Energy: 1.3516041651422774, Validation Loss Force: 2.8183449789151656, time: 0.08588647842407227
Test Loss Energy: 8.250436104317856, Test Loss Force: 11.4618756943421, time: 17.15432596206665


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6528514267809848, Training Loss Force: 3.07926136784141, time: 1.2300891876220703
Validation Loss Energy: 1.9728655557752908, Validation Loss Force: 2.840927193018578, time: 0.08644413948059082
Test Loss Energy: 8.249728275242969, Test Loss Force: 11.383206340006925, time: 17.295966625213623


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7977888160595488, Training Loss Force: 3.102011519014681, time: 1.2789347171783447
Validation Loss Energy: 1.3679616632712785, Validation Loss Force: 2.8470906749778595, time: 0.08530092239379883
Test Loss Energy: 8.213777269090443, Test Loss Force: 11.409603904821893, time: 17.20878529548645


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6859484564926561, Training Loss Force: 3.0797773304243785, time: 1.2432963848114014
Validation Loss Energy: 1.5325532405470241, Validation Loss Force: 2.8675370466335326, time: 0.08540868759155273
Test Loss Energy: 8.390027783611151, Test Loss Force: 11.433017432614198, time: 17.623923301696777


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6729532576956825, Training Loss Force: 3.0585035902041686, time: 1.2401001453399658
Validation Loss Energy: 1.3552756453549077, Validation Loss Force: 2.852435402487564, time: 0.08525252342224121
Test Loss Energy: 8.359333452727899, Test Loss Force: 11.545293851764699, time: 17.32949447631836


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8496080775060229, Training Loss Force: 3.0746244610127804, time: 1.2099599838256836
Validation Loss Energy: 1.2973880134843419, Validation Loss Force: 2.823752276454876, time: 0.08451104164123535
Test Loss Energy: 8.267083698374947, Test Loss Force: 11.488910060271825, time: 17.171293020248413


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5020888885864256, Training Loss Force: 3.065947496096242, time: 1.1763558387756348
Validation Loss Energy: 1.5224749009986136, Validation Loss Force: 2.8125925441992674, time: 0.08342647552490234
Test Loss Energy: 8.339242778128645, Test Loss Force: 11.38936942559181, time: 17.369987726211548

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–â–ƒâ–ƒâ–‚â–ƒ
wandb:   test_error_force â–‡â–ˆâ–‡â–‡â–„â–ˆâ–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–‚â–ƒâ–ƒâ–
wandb:          test_loss â–ˆâ–ˆâ–†â–‡â–„â–‡â–ƒâ–…â–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–„â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–‚â–
wandb: valid_error_energy â–…â–â–â–ƒâ–â–â–†â–ˆâ–‚â–â–ƒâ–…â–‚â–â–…â–‚â–‚â–â–â–‚
wandb:  valid_error_force â–ˆâ–…â–ƒâ–…â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–â–‚â–‚â–‚â–ƒâ–ƒâ–…â–„â–‚â–
wandb:         valid_loss â–ˆâ–†â–‚â–…â–ƒâ–‚â–…â–‡â–‡â–…â–ƒâ–„â–â–‚â–…â–â–„â–ƒâ–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1117
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.33924
wandb:   test_error_force 11.38937
wandb:          test_loss 5.72248
wandb: train_error_energy 1.50209
wandb:  train_error_force 3.06595
wandb:         train_loss 1.37498
wandb: valid_error_energy 1.52247
wandb:  valid_error_force 2.81259
wandb:         valid_loss 1.40362
wandb: 
wandb: ğŸš€ View run al_80_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/31r20iio
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_144428-31r20iio/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6495988965034485, Uncertainty Bias: 0.03562800586223602
5.340576e-05 0.0039863586
0.53492516 6.7948194
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2747 steps.
Found uncertainty sample 6 after 284 steps.
Found uncertainty sample 7 after 3486 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 747 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1818 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 435 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2888 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2218 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1488 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2742 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1537 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2926 steps.
Found uncertainty sample 33 after 626 steps.
Found uncertainty sample 34 after 1624 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1936 steps.
Found uncertainty sample 38 after 1312 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2481 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3170 steps.
Found uncertainty sample 47 after 3583 steps.
Found uncertainty sample 48 after 2023 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2392 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1097 steps.
Found uncertainty sample 65 after 917 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2428 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3533 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2427 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1361 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2462 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2150 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2665 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 645 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2590 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3577 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3274 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_172346-xd7bqxho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xd7bqxho
Training model 9. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.948737290374077, Training Loss Force: 3.553427049711611, time: 1.301339864730835
Validation Loss Energy: 1.7928328752406097, Validation Loss Force: 2.882969354461204, time: 0.08612179756164551
Test Loss Energy: 8.737620487523706, Test Loss Force: 11.52796187767566, time: 17.858393669128418


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7952689684758707, Training Loss Force: 3.215930041591327, time: 1.2909941673278809
Validation Loss Energy: 1.5587966920823544, Validation Loss Force: 2.881096484274805, time: 0.0886080265045166
Test Loss Energy: 8.51717682761071, Test Loss Force: 11.456487669924481, time: 17.334898710250854


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.070323839088511, Training Loss Force: 3.163654519577947, time: 1.2785727977752686
Validation Loss Energy: 2.958899978560871, Validation Loss Force: 2.8799112164110316, time: 0.08725237846374512
Test Loss Energy: 8.399556992483433, Test Loss Force: 11.015338551804849, time: 17.243823051452637


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7373599665525497, Training Loss Force: 3.1703251861843658, time: 1.4667458534240723
Validation Loss Energy: 1.4258265828889598, Validation Loss Force: 2.845334260754781, time: 0.08376932144165039
Test Loss Energy: 8.412276709801201, Test Loss Force: 11.016155516740605, time: 17.2333767414093


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6889550002461402, Training Loss Force: 3.140794507159227, time: 1.2668654918670654
Validation Loss Energy: 1.9120011714273892, Validation Loss Force: 2.8728091840016647, time: 0.08525323867797852
Test Loss Energy: 8.599048835769183, Test Loss Force: 11.156734905069731, time: 17.752442121505737


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8719509896084712, Training Loss Force: 3.1607594248246262, time: 1.279726266860962
Validation Loss Energy: 1.5556006104962798, Validation Loss Force: 2.8982179602434845, time: 0.0851905345916748
Test Loss Energy: 8.353955831972373, Test Loss Force: 11.243303334273408, time: 17.97854781150818


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8981773791204948, Training Loss Force: 3.1612304071797883, time: 1.376988410949707
Validation Loss Energy: 1.7068700041057387, Validation Loss Force: 2.8555953003374253, time: 0.09024238586425781
Test Loss Energy: 8.073947387438128, Test Loss Force: 10.97304341722792, time: 17.94327998161316


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.136133102105198, Training Loss Force: 3.169954040014882, time: 1.293184518814087
Validation Loss Energy: 1.5456519757253722, Validation Loss Force: 2.866366920271682, time: 0.09078001976013184
Test Loss Energy: 8.094111880939584, Test Loss Force: 11.047344016909674, time: 17.669800281524658


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.685196004873906, Training Loss Force: 3.1491570757889455, time: 1.2742750644683838
Validation Loss Energy: 1.4193402306680833, Validation Loss Force: 2.876246972945644, time: 0.08741474151611328
Test Loss Energy: 8.089447890314807, Test Loss Force: 11.236526497910695, time: 17.496923446655273


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5842900980627619, Training Loss Force: 3.1355647202256, time: 1.3102517127990723
Validation Loss Energy: 1.4137190594137095, Validation Loss Force: 2.8690039909669047, time: 0.08621048927307129
Test Loss Energy: 8.163076723996857, Test Loss Force: 11.103836596852922, time: 17.637555599212646


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3295844902882985, Training Loss Force: 3.156148757080743, time: 1.291086196899414
Validation Loss Energy: 1.9552528716706947, Validation Loss Force: 2.836253367645554, time: 0.08939623832702637
Test Loss Energy: 8.134683467725692, Test Loss Force: 10.853834796941198, time: 17.56371235847473


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8090316009906837, Training Loss Force: 3.1533345778209507, time: 1.349090337753296
Validation Loss Energy: 1.7195730562117733, Validation Loss Force: 2.86583607702779, time: 0.10693836212158203
Test Loss Energy: 8.483485402665867, Test Loss Force: 11.169370975731894, time: 17.585386276245117


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9542079719624124, Training Loss Force: 3.141568987560289, time: 1.326909065246582
Validation Loss Energy: 1.516470516144098, Validation Loss Force: 2.86139605425799, time: 0.09165000915527344
Test Loss Energy: 8.074917117397678, Test Loss Force: 10.942021235755368, time: 17.730093002319336


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7056742398658362, Training Loss Force: 3.1299714630227697, time: 1.2887907028198242
Validation Loss Energy: 1.6799015418312677, Validation Loss Force: 2.8377281053990338, time: 0.08570003509521484
Test Loss Energy: 8.035674511007416, Test Loss Force: 11.061793080742511, time: 17.552414655685425


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.791025162066725, Training Loss Force: 3.1442335950065576, time: 1.291318655014038
Validation Loss Energy: 1.5203236943798053, Validation Loss Force: 2.8165518242830094, time: 0.0873873233795166
Test Loss Energy: 8.03585456757417, Test Loss Force: 10.695270703820794, time: 17.70010542869568


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.771784828357937, Training Loss Force: 3.1115630274284225, time: 1.336540937423706
Validation Loss Energy: 1.8750015754634444, Validation Loss Force: 2.9011660997355686, time: 0.08752298355102539
Test Loss Energy: 8.448947291700414, Test Loss Force: 10.94316323235899, time: 17.665704488754272


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8081188306794926, Training Loss Force: 3.1146127040510496, time: 1.3006799221038818
Validation Loss Energy: 1.4130889057307336, Validation Loss Force: 2.848688326099891, time: 0.08644938468933105
Test Loss Energy: 8.072114008965437, Test Loss Force: 10.874327036109321, time: 17.729151964187622


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8785417210841286, Training Loss Force: 3.108364409888185, time: 1.2758715152740479
Validation Loss Energy: 1.6309829118241002, Validation Loss Force: 2.874948143817447, time: 0.0876312255859375
Test Loss Energy: 8.38878574910485, Test Loss Force: 10.938529820853043, time: 17.728702068328857


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8096311005545698, Training Loss Force: 3.1214050098636843, time: 1.278224229812622
Validation Loss Energy: 1.5807804828560859, Validation Loss Force: 2.829762784710905, time: 0.08768844604492188
Test Loss Energy: 7.966969101987094, Test Loss Force: 10.984678143575039, time: 18.02808117866516


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7141854989103749, Training Loss Force: 3.105060556435482, time: 1.547767162322998
Validation Loss Energy: 2.120955233980901, Validation Loss Force: 2.845309989817875, time: 0.08710694313049316
Test Loss Energy: 8.152572870122517, Test Loss Force: 10.843919822517153, time: 17.621196746826172

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–…â–…â–‡â–…â–‚â–‚â–‚â–ƒâ–ƒâ–†â–‚â–‚â–‚â–…â–‚â–…â–â–ƒ
wandb:   test_error_force â–ˆâ–‡â–„â–„â–…â–†â–ƒâ–„â–†â–„â–‚â–…â–ƒâ–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:          test_loss â–ˆâ–ˆâ–ƒâ–ƒâ–…â–…â–ƒâ–ƒâ–…â–„â–‚â–…â–ƒâ–ƒâ–â–‚â–â–‚â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–‚â–‚â–ƒâ–â–â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–‚â–ˆâ–â–ƒâ–‚â–‚â–‚â–â–â–ƒâ–‚â–â–‚â–â–ƒâ–â–‚â–‚â–„
wandb:  valid_error_force â–†â–†â–†â–ƒâ–†â–ˆâ–„â–…â–†â–…â–ƒâ–…â–…â–ƒâ–â–ˆâ–„â–†â–‚â–ƒ
wandb:         valid_loss â–‡â–ƒâ–ˆâ–‚â–„â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–…â–â–ƒâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1147
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.15257
wandb:   test_error_force 10.84392
wandb:          test_loss 5.48398
wandb: train_error_energy 1.71419
wandb:  train_error_force 3.10506
wandb:         train_loss 1.42374
wandb: valid_error_energy 2.12096
wandb:  valid_error_force 2.84531
wandb:         valid_loss 1.44324
wandb: 
wandb: ğŸš€ View run al_80_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/xd7bqxho
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_172346-xd7bqxho/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.683367133140564, Uncertainty Bias: 0.028734907507896423
0.0006093979 0.013755798
0.45442066 6.386517
(48745, 22, 3)
Found uncertainty sample 0 after 808 steps.
Found uncertainty sample 1 after 1663 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1044 steps.
Found uncertainty sample 7 after 1700 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1546 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1756 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3884 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1808 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2017 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2533 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 332 steps.
Found uncertainty sample 33 after 2532 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3560 steps.
Found uncertainty sample 41 after 3142 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2670 steps.
Found uncertainty sample 45 after 3155 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 250 steps.
Found uncertainty sample 55 after 944 steps.
Found uncertainty sample 56 after 1995 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3943 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1369 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1839 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3200 steps.
Found uncertainty sample 71 after 773 steps.
Found uncertainty sample 72 after 1295 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 683 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2419 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1489 steps.
Found uncertainty sample 91 after 3069 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1203 steps.
Found uncertainty sample 95 after 2217 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2464 steps.
Found uncertainty sample 98 after 630 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_200341-hmdfnag5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/hmdfnag5
Training model 10. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.737025848433872, Training Loss Force: 3.820869851364121, time: 1.3400003910064697
Validation Loss Energy: 2.4112997680922295, Validation Loss Force: 3.0188202457300393, time: 0.0899345874786377
Test Loss Energy: 8.374528343950502, Test Loss Force: 10.734206924461105, time: 17.686654567718506


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8371028264430305, Training Loss Force: 3.3060939195594523, time: 1.3121991157531738
Validation Loss Energy: 1.3944116404394569, Validation Loss Force: 2.9000255883701267, time: 0.08683562278747559
Test Loss Energy: 8.413274185968463, Test Loss Force: 10.710313587794188, time: 17.729828357696533


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6627239186338256, Training Loss Force: 3.201795643462196, time: 1.3375234603881836
Validation Loss Energy: 1.5032827133073787, Validation Loss Force: 2.8787301792610305, time: 0.08817791938781738
Test Loss Energy: 8.188563453092666, Test Loss Force: 10.746944835363637, time: 17.653428316116333


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7774576910759963, Training Loss Force: 3.2096494731071505, time: 1.5442733764648438
Validation Loss Energy: 1.395628861325671, Validation Loss Force: 2.871846807952965, time: 0.0945429801940918
Test Loss Energy: 8.355097453186122, Test Loss Force: 10.760652408608923, time: 17.71826434135437


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8972008889071361, Training Loss Force: 3.1955941272055566, time: 1.3423614501953125
Validation Loss Energy: 1.4393704336900175, Validation Loss Force: 2.892713356287004, time: 0.09269309043884277
Test Loss Energy: 8.25345702747548, Test Loss Force: 10.697921590495328, time: 17.83654808998108


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.706091281957749, Training Loss Force: 3.18905375063541, time: 1.3017191886901855
Validation Loss Energy: 1.5400197823482749, Validation Loss Force: 2.868716302430366, time: 0.08815431594848633
Test Loss Energy: 8.236429907265936, Test Loss Force: 10.732222585633933, time: 17.68104648590088


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7505086762432842, Training Loss Force: 3.1748123857256916, time: 1.2806353569030762
Validation Loss Energy: 1.4823288786681361, Validation Loss Force: 2.89114643350711, time: 0.0881659984588623
Test Loss Energy: 8.136192273858498, Test Loss Force: 10.486324496475165, time: 17.830190420150757


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7465575777461333, Training Loss Force: 3.189914896475903, time: 1.3431918621063232
Validation Loss Energy: 1.5223152472209833, Validation Loss Force: 2.88219914188544, time: 0.08860349655151367
Test Loss Energy: 8.019559893621112, Test Loss Force: 10.558292889833456, time: 17.798948526382446


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6927528103443423, Training Loss Force: 3.1860503711408805, time: 1.3205170631408691
Validation Loss Energy: 1.4606010460776484, Validation Loss Force: 2.886514024595228, time: 0.08768939971923828
Test Loss Energy: 8.0429152173308, Test Loss Force: 10.443960989646559, time: 17.673678636550903


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.650310906552951, Training Loss Force: 3.2325327659862824, time: 1.3182003498077393
Validation Loss Energy: 1.5794469173411245, Validation Loss Force: 2.8809105555379557, time: 0.08965301513671875
Test Loss Energy: 8.079435717894041, Test Loss Force: 10.59599182546537, time: 17.78081774711609


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.099206407300803, Training Loss Force: 3.212789083992392, time: 1.2837960720062256
Validation Loss Energy: 1.3953995121053655, Validation Loss Force: 2.8880446523043357, time: 0.09259653091430664
Test Loss Energy: 8.17463909569543, Test Loss Force: 10.567130224866089, time: 17.82105040550232


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.829345402006614, Training Loss Force: 3.186447751313172, time: 1.3087270259857178
Validation Loss Energy: 1.95146215213042, Validation Loss Force: 2.8838433308589706, time: 0.0910484790802002
Test Loss Energy: 8.060952789140035, Test Loss Force: 10.36084415137649, time: 18.179672241210938


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8926991386392338, Training Loss Force: 3.190643903223501, time: 1.3210573196411133
Validation Loss Energy: 1.5988817030668476, Validation Loss Force: 2.8825347042883527, time: 0.09459900856018066
Test Loss Energy: 8.046910473054197, Test Loss Force: 10.366018609269595, time: 17.80514430999756


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.042385839076991, Training Loss Force: 3.183806606374387, time: 1.3336164951324463
Validation Loss Energy: 2.3918436061284973, Validation Loss Force: 2.9094242303505924, time: 0.08870315551757812
Test Loss Energy: 8.886577262699701, Test Loss Force: 10.540385380121581, time: 17.81420397758484


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.985891688775896, Training Loss Force: 3.187578368946833, time: 1.3329095840454102
Validation Loss Energy: 1.8904830931723655, Validation Loss Force: 2.859943806088249, time: 0.09100079536437988
Test Loss Energy: 8.37669608287904, Test Loss Force: 10.438785482527111, time: 17.830671072006226


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8062917867896235, Training Loss Force: 3.1763706364450637, time: 1.3832933902740479
Validation Loss Energy: 1.9443333994235419, Validation Loss Force: 2.8689452063123797, time: 0.09016275405883789
Test Loss Energy: 8.003775705589293, Test Loss Force: 10.32449038453707, time: 17.792283535003662


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.843962110365783, Training Loss Force: 3.180391006109895, time: 1.3119540214538574
Validation Loss Energy: 2.2814921174438743, Validation Loss Force: 2.8512777455978857, time: 0.09032344818115234
Test Loss Energy: 8.251095452140895, Test Loss Force: 10.330924333731195, time: 17.66994881629944


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9166399324280152, Training Loss Force: 3.175352352386481, time: 1.327380895614624
Validation Loss Energy: 1.5351822951529936, Validation Loss Force: 2.874607014685886, time: 0.0950775146484375
Test Loss Energy: 8.191205419011677, Test Loss Force: 10.389124186798886, time: 17.83354353904724


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7229729492743495, Training Loss Force: 3.159557605388174, time: 1.3233246803283691
Validation Loss Energy: 1.4527318071259874, Validation Loss Force: 2.8768978348591907, time: 0.08790254592895508
Test Loss Energy: 8.127460059647271, Test Loss Force: 10.439399839524604, time: 17.789798974990845


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.925714220688927, Training Loss Force: 3.1596412026072573, time: 1.3535103797912598
Validation Loss Energy: 3.200891016957397, Validation Loss Force: 2.8579437918195256, time: 0.08818364143371582
Test Loss Energy: 8.200096586350503, Test Loss Force: 10.354579379437757, time: 18.128244638442993

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–‚â–„â–ƒâ–ƒâ–‚â–â–â–‚â–‚â–â–â–ˆâ–„â–â–ƒâ–‚â–‚â–ƒ
wandb:   test_error_force â–ˆâ–‡â–ˆâ–ˆâ–‡â–ˆâ–„â–…â–ƒâ–…â–…â–‚â–‚â–„â–ƒâ–â–â–‚â–ƒâ–
wandb:          test_loss â–‡â–†â–‡â–ˆâ–‡â–ˆâ–ƒâ–„â–‚â–…â–…â–‚â–â–‡â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–â–â–â–â–‚â–â–â–â–‚â–â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–‚â–â–ˆ
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–
wandb:         valid_loss â–ˆâ–‚â–â–â–â–…â–â–â–…â–‚â–‚â–ƒâ–ƒâ–ˆâ–‚â–…â–ƒâ–‚â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1176
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.2001
wandb:   test_error_force 10.35458
wandb:          test_loss 5.30302
wandb: train_error_energy 1.92571
wandb:  train_error_force 3.15964
wandb:         train_loss 1.46225
wandb: valid_error_energy 3.20089
wandb:  valid_error_force 2.85794
wandb:         valid_loss 1.52441
wandb: 
wandb: ğŸš€ View run al_80_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/hmdfnag5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_200341-hmdfnag5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6734201312065125, Uncertainty Bias: 0.03051692247390747
0.00018119812 0.21975672
0.6844452 6.964719
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2779 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 326 steps.
Found uncertainty sample 16 after 17 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2333 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 275 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3540 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 543 steps.
Found uncertainty sample 33 after 3928 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3089 steps.
Found uncertainty sample 38 after 1392 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3392 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2197 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2171 steps.
Found uncertainty sample 53 after 3967 steps.
Found uncertainty sample 54 after 219 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1566 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 583 steps.
Found uncertainty sample 67 after 2196 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1836 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 916 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1393 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3730 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1336 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3212 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241209_225122-scmlxcf4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/scmlxcf4
Training model 11. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.465240428527989, Training Loss Force: 3.601963350609966, time: 1.3727548122406006
Validation Loss Energy: 1.9304838238851252, Validation Loss Force: 2.9248396153231733, time: 0.09750843048095703
Test Loss Energy: 8.00574134720305, Test Loss Force: 10.12465313593951, time: 17.680890321731567


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9126226292942448, Training Loss Force: 3.232394763378125, time: 1.3914151191711426
Validation Loss Energy: 1.475897191722585, Validation Loss Force: 2.9025546645295743, time: 0.09041929244995117
Test Loss Energy: 8.056495351544573, Test Loss Force: 10.241911622177808, time: 17.803142547607422


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6129747482722645, Training Loss Force: 3.2219170667164923, time: 1.3632705211639404
Validation Loss Energy: 1.440784494101232, Validation Loss Force: 2.9028476971256154, time: 0.0917510986328125
Test Loss Energy: 8.096288041658228, Test Loss Force: 10.227997160150784, time: 17.67562770843506


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8266692948445054, Training Loss Force: 3.210996152979605, time: 1.5696566104888916
Validation Loss Energy: 2.131408214367335, Validation Loss Force: 2.9028476971256154, time: 0.09497642517089844
Test Loss Energy: 8.042119570342695, Test Loss Force: 10.097819092966237, time: 17.69775938987732


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8407440093984555, Training Loss Force: 3.222195848487194, time: 1.3470146656036377
Validation Loss Energy: 2.5409880680783674, Validation Loss Force: 2.894257121475721, time: 0.09493446350097656
Test Loss Energy: 8.13834641248203, Test Loss Force: 10.053393254819035, time: 17.803290605545044


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2847341684891544, Training Loss Force: 3.2203373814787084, time: 1.3270313739776611
Validation Loss Energy: 2.5925248419033537, Validation Loss Force: 2.9397328411485533, time: 0.08944344520568848
Test Loss Energy: 8.709296459206593, Test Loss Force: 10.28856008078608, time: 17.66227412223816


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.275054002391663, Training Loss Force: 3.2201087471435557, time: 1.31123685836792
Validation Loss Energy: 1.614218151827197, Validation Loss Force: 2.9005408447738033, time: 0.09083747863769531
Test Loss Energy: 8.146297440375767, Test Loss Force: 10.210292379621109, time: 17.78951358795166


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8695296980117009, Training Loss Force: 3.1986860943369906, time: 1.3367929458618164
Validation Loss Energy: 1.6288888198412224, Validation Loss Force: 2.8888754308877926, time: 0.09117317199707031
Test Loss Energy: 8.137295418776478, Test Loss Force: 9.98676727484346, time: 17.805644035339355


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7084080150549485, Training Loss Force: 3.1874123847772386, time: 1.375756025314331
Validation Loss Energy: 1.4516844827981161, Validation Loss Force: 2.8928367149938476, time: 0.0891575813293457
Test Loss Energy: 7.962431158420211, Test Loss Force: 10.056719903879825, time: 17.668505907058716


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8518654015429643, Training Loss Force: 3.192542101787693, time: 1.351592779159546
Validation Loss Energy: 1.4989748446756868, Validation Loss Force: 2.926141116481121, time: 0.08944535255432129
Test Loss Energy: 7.975513047686733, Test Loss Force: 10.084403918117964, time: 17.838988304138184


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7741933758084247, Training Loss Force: 3.2284298228103046, time: 1.4147865772247314
Validation Loss Energy: 1.9281066080832001, Validation Loss Force: 2.9376328484333083, time: 0.08887791633605957
Test Loss Energy: 8.379412674438727, Test Loss Force: 10.263816259899196, time: 17.863004446029663


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.102642762277655, Training Loss Force: 3.2121342735815865, time: 1.3615095615386963
Validation Loss Energy: 1.417174105216498, Validation Loss Force: 2.8927305018112404, time: 0.0948324203491211
Test Loss Energy: 7.95019096085691, Test Loss Force: 10.080205557822499, time: 17.751614093780518


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.878574316559141, Training Loss Force: 3.196053605938403, time: 1.3555264472961426
Validation Loss Energy: 1.5309324318338158, Validation Loss Force: 2.884816617695821, time: 0.09022116661071777
Test Loss Energy: 7.986775373294071, Test Loss Force: 9.960882147510727, time: 18.35583734512329


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7509650285809593, Training Loss Force: 3.1914999691667503, time: 1.3664076328277588
Validation Loss Energy: 1.5982666908857952, Validation Loss Force: 2.8932943000887295, time: 0.08954477310180664
Test Loss Energy: 8.37834637135504, Test Loss Force: 9.94957803005238, time: 17.681192636489868


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9715696184161342, Training Loss Force: 3.1918372426062582, time: 1.3845524787902832
Validation Loss Energy: 1.7557862960868742, Validation Loss Force: 2.895976127282284, time: 0.092498779296875
Test Loss Energy: 7.777827295993936, Test Loss Force: 9.88179350833958, time: 17.85714316368103


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0955060403592376, Training Loss Force: 3.191896349545073, time: 1.4211912155151367
Validation Loss Energy: 1.429372366368714, Validation Loss Force: 2.886323419806314, time: 0.0894155502319336
Test Loss Energy: 7.925537256854737, Test Loss Force: 9.877434560455038, time: 17.868438959121704


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7836644145598894, Training Loss Force: 3.214397664431942, time: 1.4086260795593262
Validation Loss Energy: 1.439757321331067, Validation Loss Force: 2.9010650079433176, time: 0.08993339538574219
Test Loss Energy: 7.897510255188606, Test Loss Force: 9.82268314131547, time: 17.739525079727173


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8633909206081885, Training Loss Force: 3.197763142446549, time: 1.3779664039611816
Validation Loss Energy: 1.5748210771690476, Validation Loss Force: 2.897927822346341, time: 0.09560799598693848
Test Loss Energy: 7.814344819085982, Test Loss Force: 9.968786333277325, time: 17.899192571640015


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8335753549665985, Training Loss Force: 3.1842817972186395, time: 1.3544859886169434
Validation Loss Energy: 1.7077428671577757, Validation Loss Force: 2.860939582508838, time: 0.09030342102050781
Test Loss Energy: 8.411698168727797, Test Loss Force: 9.902054885069846, time: 17.912315130233765


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9172474205774506, Training Loss Force: 3.1815603583559673, time: 1.344801902770996
Validation Loss Energy: 1.7565673081162159, Validation Loss Force: 2.907649334588402, time: 0.09104537963867188
Test Loss Energy: 8.436632328599591, Test Loss Force: 10.0235422197895, time: 17.728787660598755

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–„â–„â–‚â–‚â–†â–‚â–ƒâ–†â–â–‚â–‚â–â–†â–†
wandb:   test_error_force â–†â–‡â–‡â–…â–„â–ˆâ–‡â–ƒâ–…â–…â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–‚â–„
wandb:          test_loss â–…â–†â–‡â–…â–…â–ˆâ–‡â–ƒâ–…â–†â–‡â–…â–„â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒ
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–â–â–‚â–
wandb: valid_error_energy â–„â–â–â–…â–ˆâ–ˆâ–‚â–‚â–â–â–„â–â–‚â–‚â–ƒâ–â–â–‚â–ƒâ–ƒ
wandb:  valid_error_force â–‡â–…â–…â–…â–„â–ˆâ–…â–ƒâ–„â–‡â–ˆâ–„â–ƒâ–„â–„â–ƒâ–…â–„â–â–…
wandb:         valid_loss â–„â–â–…â–„â–…â–ˆâ–…â–‚â–ƒâ–†â–…â–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1197
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.43663
wandb:   test_error_force 10.02354
wandb:          test_loss 5.12943
wandb: train_error_energy 1.91725
wandb:  train_error_force 3.18156
wandb:         train_loss 1.45056
wandb: valid_error_energy 1.75657
wandb:  valid_error_force 2.90765
wandb:         valid_loss 1.47518
wandb: 
wandb: ğŸš€ View run al_80_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/scmlxcf4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241209_225122-scmlxcf4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7008280158042908, Uncertainty Bias: 0.023762419819831848
0.00017547607 0.045288086
0.6689331 6.918012
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3679 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1877 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2961 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1702 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1242 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1109 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2799 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 476 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 925 steps.
Found uncertainty sample 40 after 3044 steps.
Found uncertainty sample 41 after 1031 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2415 steps.
Found uncertainty sample 49 after 424 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3328 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2934 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3982 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1535 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 499 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1405 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2846 steps.
Found uncertainty sample 86 after 1378 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1074 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2232 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1151 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_014001-av1mtyma
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/av1mtyma
Training model 12. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.1352747563761865, Training Loss Force: 3.5395456177358753, time: 1.4218003749847412
Validation Loss Energy: 2.934266758954318, Validation Loss Force: 2.986131079092964, time: 0.0953371524810791
Test Loss Energy: 8.111266974120262, Test Loss Force: 9.915296182128714, time: 18.21271514892578


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9331993740353568, Training Loss Force: 3.259716773922886, time: 1.390202283859253
Validation Loss Energy: 2.32257301618353, Validation Loss Force: 2.941870019611168, time: 0.09378695487976074
Test Loss Energy: 7.934643809377064, Test Loss Force: 9.762756947183275, time: 17.911529302597046


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.995700804815724, Training Loss Force: 3.237503100093844, time: 1.416407585144043
Validation Loss Energy: 1.4557223650903706, Validation Loss Force: 2.9551925372811736, time: 0.0907278060913086
Test Loss Energy: 8.002550547305802, Test Loss Force: 9.994154229329244, time: 17.968265056610107


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.030438750264481, Training Loss Force: 3.290288179988763, time: 1.3874549865722656
Validation Loss Energy: 2.446339652902864, Validation Loss Force: 2.954362426705155, time: 0.09319233894348145
Test Loss Energy: 7.905950660901194, Test Loss Force: 9.722615594492924, time: 17.88190770149231


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7529180320140598, Training Loss Force: 3.2150755611143373, time: 1.3842051029205322
Validation Loss Energy: 2.093523953886619, Validation Loss Force: 2.9331048713508667, time: 0.09096121788024902
Test Loss Energy: 8.702281152349238, Test Loss Force: 9.817210982934906, time: 17.922171592712402


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9282751914645284, Training Loss Force: 3.2620911863773583, time: 1.4387927055358887
Validation Loss Energy: 1.654081829680638, Validation Loss Force: 2.9391066955102043, time: 0.08997941017150879
Test Loss Energy: 7.765814071736178, Test Loss Force: 9.706834181081875, time: 17.83327555656433


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9801399569414666, Training Loss Force: 3.2529721540400587, time: 1.3856244087219238
Validation Loss Energy: 2.1015614193780285, Validation Loss Force: 2.9601836661871452, time: 0.09410285949707031
Test Loss Energy: 7.78103352884487, Test Loss Force: 9.580383133740572, time: 17.91121530532837


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.86715331023249, Training Loss Force: 3.23109116504343, time: 1.37772536277771
Validation Loss Energy: 1.4396296205758776, Validation Loss Force: 2.9422552372336233, time: 0.09125041961669922
Test Loss Energy: 7.899516245384251, Test Loss Force: 9.711596815304109, time: 17.90474033355713


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.888658790552373, Training Loss Force: 3.2402134460664738, time: 1.3688654899597168
Validation Loss Energy: 2.362405631691114, Validation Loss Force: 2.9748960846660317, time: 0.09289312362670898
Test Loss Energy: 7.921445910651321, Test Loss Force: 9.750571390996253, time: 17.885579109191895


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.067626147669887, Training Loss Force: 3.2724842973108634, time: 1.3944787979125977
Validation Loss Energy: 1.900148715458799, Validation Loss Force: 2.9377646685676977, time: 0.09466028213500977
Test Loss Energy: 7.714348363177147, Test Loss Force: 9.705690598980674, time: 18.46369504928589


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0783101130384294, Training Loss Force: 3.2713475028073185, time: 1.4023010730743408
Validation Loss Energy: 2.4700292006689755, Validation Loss Force: 2.9139078962729945, time: 0.09177541732788086
Test Loss Energy: 8.491559402218508, Test Loss Force: 9.607381700067508, time: 17.99855375289917


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8307235588697661, Training Loss Force: 3.233911857851529, time: 1.4279260635375977
Validation Loss Energy: 1.5309911051537677, Validation Loss Force: 2.920014597600064, time: 0.09115314483642578
Test Loss Energy: 7.9111067783178415, Test Loss Force: 9.644687786704042, time: 17.907816886901855


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2326426833011697, Training Loss Force: 3.2138930794696208, time: 1.4200773239135742
Validation Loss Energy: 2.29567146598741, Validation Loss Force: 2.931333760964157, time: 0.09033966064453125
Test Loss Energy: 7.803884925463762, Test Loss Force: 9.395406357619414, time: 17.997959852218628


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8686885483348117, Training Loss Force: 3.2044571603903407, time: 1.4005565643310547
Validation Loss Energy: 1.532436116576266, Validation Loss Force: 2.914436958163719, time: 0.09640908241271973
Test Loss Energy: 7.900064093089725, Test Loss Force: 9.572216720663338, time: 17.935635328292847


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.33309555213074, Training Loss Force: 3.289841317269677, time: 1.409125804901123
Validation Loss Energy: 1.5128048253292616, Validation Loss Force: 2.911251008023784, time: 0.09175682067871094
Test Loss Energy: 7.869382026496605, Test Loss Force: 9.386635627474975, time: 17.85834574699402


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0524731668668514, Training Loss Force: 3.2617063684174723, time: 1.3881168365478516
Validation Loss Energy: 2.7973924802907986, Validation Loss Force: 2.9475607749736445, time: 0.09125208854675293
Test Loss Energy: 8.629196678277978, Test Loss Force: 9.601731896009163, time: 17.96921730041504


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.4389454014962584, Training Loss Force: 3.2400114794416512, time: 1.4294569492340088
Validation Loss Energy: 1.9134476301993362, Validation Loss Force: 2.904244723347166, time: 0.09410905838012695
Test Loss Energy: 7.712584762919434, Test Loss Force: 9.663227812023969, time: 17.876993417739868


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.904620822568741, Training Loss Force: 3.228856765806024, time: 1.4551074504852295
Validation Loss Energy: 3.1361459547342663, Validation Loss Force: 2.9686341829442506, time: 0.09617185592651367
Test Loss Energy: 7.873010360773339, Test Loss Force: 9.624837478201684, time: 18.08416986465454


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1283633964996618, Training Loss Force: 3.238102668171314, time: 1.4152953624725342
Validation Loss Energy: 1.8635708548572414, Validation Loss Force: 2.9046996364122966, time: 0.09766530990600586
Test Loss Energy: 7.6579108209845765, Test Loss Force: 9.473134028980969, time: 17.991852521896362


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.791607267149899, Training Loss Force: 3.194628595674275, time: 1.4229607582092285
Validation Loss Energy: 2.3929117500215127, Validation Loss Force: 2.9381151498033877, time: 0.09448599815368652
Test Loss Energy: 8.598582802070634, Test Loss Force: 9.60533343770835, time: 17.875837326049805

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–‚â–ƒâ–ƒâ–â–‡â–ƒâ–‚â–ƒâ–‚â–ˆâ–â–‚â–â–‡
wandb:   test_error_force â–‡â–…â–ˆâ–…â–†â–…â–ƒâ–…â–…â–…â–„â–„â–â–ƒâ–â–ƒâ–„â–„â–‚â–„
wandb:          test_loss â–‡â–„â–ˆâ–„â–†â–„â–‚â–„â–…â–†â–„â–ƒâ–‚â–‚â–â–…â–ƒâ–„â–â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–ƒâ–‚â–ƒâ–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–â–ƒâ–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–â–‚â–
wandb: valid_error_energy â–‡â–…â–â–…â–„â–‚â–„â–â–…â–ƒâ–…â–â–…â–â–â–‡â–ƒâ–ˆâ–ƒâ–…
wandb:  valid_error_force â–ˆâ–„â–…â–…â–ƒâ–„â–†â–„â–‡â–„â–‚â–‚â–ƒâ–‚â–‚â–…â–â–‡â–â–„
wandb:         valid_loss â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–†â–„â–ƒâ–„â–…â–â–…â–…â–ƒâ–ˆâ–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1218
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.59858
wandb:   test_error_force 9.60533
wandb:          test_loss 4.97932
wandb: train_error_energy 1.79161
wandb:  train_error_force 3.19463
wandb:         train_loss 1.46069
wandb: valid_error_energy 2.39291
wandb:  valid_error_force 2.93812
wandb:         valid_loss 1.5233
wandb: 
wandb: ğŸš€ View run al_80_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/av1mtyma
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_014001-av1mtyma/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6844285726547241, Uncertainty Bias: 0.029670044779777527
1.5258789e-05 0.0007362366
0.7646957 6.7584653
(48745, 22, 3)
Found uncertainty sample 0 after 2191 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 621 steps.
Found uncertainty sample 5 after 1925 steps.
Found uncertainty sample 6 after 3229 steps.
Found uncertainty sample 7 after 193 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3795 steps.
Found uncertainty sample 10 after 1314 steps.
Found uncertainty sample 11 after 1226 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2281 steps.
Found uncertainty sample 14 after 3099 steps.
Found uncertainty sample 15 after 2331 steps.
Found uncertainty sample 16 after 1378 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1672 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1138 steps.
Found uncertainty sample 25 after 3670 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2360 steps.
Found uncertainty sample 28 after 1385 steps.
Found uncertainty sample 29 after 3260 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2883 steps.
Found uncertainty sample 32 after 2299 steps.
Found uncertainty sample 33 after 1095 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3762 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1809 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1545 steps.
Found uncertainty sample 47 after 607 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2023 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3362 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2208 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2411 steps.
Found uncertainty sample 63 after 2733 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2894 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2419 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1668 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1713 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3130 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_042216-dtmgjhj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/dtmgjhj3
Training model 13. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.870196193389075, Training Loss Force: 3.7646830485770133, time: 1.4366333484649658
Validation Loss Energy: 1.58458244718823, Validation Loss Force: 2.9625813675504955, time: 0.09314918518066406
Test Loss Energy: 7.85879232725457, Test Loss Force: 9.411700273797894, time: 18.197433471679688


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.125246307792261, Training Loss Force: 3.403350098860628, time: 1.4601290225982666
Validation Loss Energy: 1.6491307812209337, Validation Loss Force: 3.0415540975218285, time: 0.09716343879699707
Test Loss Energy: 8.216048816141653, Test Loss Force: 9.367667513144253, time: 17.85238814353943


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.018853553651973, Training Loss Force: 3.2576800270955983, time: 1.4966742992401123
Validation Loss Energy: 2.2243912870004445, Validation Loss Force: 2.953844052933435, time: 0.0957798957824707
Test Loss Energy: 8.154127793250481, Test Loss Force: 9.26889077586323, time: 17.906596183776855


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9701402162472577, Training Loss Force: 3.282162755759876, time: 1.463719129562378
Validation Loss Energy: 1.607801829052715, Validation Loss Force: 2.950227683334422, time: 0.0971062183380127
Test Loss Energy: 7.896653121205244, Test Loss Force: 9.361781684454451, time: 17.783812761306763


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2835018874045536, Training Loss Force: 3.362895768830698, time: 1.3814802169799805
Validation Loss Energy: 4.446830210929394, Validation Loss Force: 3.013091413943609, time: 0.09719514846801758
Test Loss Energy: 9.55965553678263, Test Loss Force: 9.5178227379643, time: 17.91737127304077


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4611231445897666, Training Loss Force: 3.2788368051778036, time: 1.4013638496398926
Validation Loss Energy: 1.4493617096023703, Validation Loss Force: 2.9596860006459966, time: 0.09520387649536133
Test Loss Energy: 7.9079101703698855, Test Loss Force: 9.094648261389516, time: 17.791109561920166


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.08843591936834, Training Loss Force: 3.324996828886537, time: 1.394273042678833
Validation Loss Energy: 1.8366733127057482, Validation Loss Force: 2.947825083249861, time: 0.09234452247619629
Test Loss Energy: 8.08915531704674, Test Loss Force: 9.128932119164531, time: 17.845715284347534


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8961350734864433, Training Loss Force: 3.3609767448970778, time: 1.4090526103973389
Validation Loss Energy: 2.184414604555445, Validation Loss Force: 2.9831635673851844, time: 0.09260153770446777
Test Loss Energy: 8.667489093634794, Test Loss Force: 9.326819047184543, time: 17.85902500152588


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0165889221535935, Training Loss Force: 3.2678989989098484, time: 1.4086894989013672
Validation Loss Energy: 1.5818197910947038, Validation Loss Force: 2.9498026079348456, time: 0.09753966331481934
Test Loss Energy: 8.021817530262638, Test Loss Force: 9.21494943407139, time: 17.801524877548218


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9184558517456218, Training Loss Force: 3.284222712562684, time: 1.3828155994415283
Validation Loss Energy: 2.108101880201365, Validation Loss Force: 2.9827836938222316, time: 0.09484457969665527
Test Loss Energy: 8.07110519649045, Test Loss Force: 9.15661191784439, time: 17.917818784713745


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9446098264680252, Training Loss Force: 3.25080412077065, time: 1.447221040725708
Validation Loss Energy: 2.8603552986699237, Validation Loss Force: 2.996653309583782, time: 0.0931544303894043
Test Loss Energy: 7.773910659966157, Test Loss Force: 8.973058853268082, time: 17.908342123031616


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8611868587798228, Training Loss Force: 3.256242230153428, time: 1.380188226699829
Validation Loss Energy: 1.468064359176283, Validation Loss Force: 2.9366704723846087, time: 0.09415912628173828
Test Loss Energy: 7.805777132891643, Test Loss Force: 9.229936904904235, time: 17.83698344230652


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0513580830332443, Training Loss Force: 3.270498538720525, time: 1.4435479640960693
Validation Loss Energy: 1.4073676446952652, Validation Loss Force: 2.9721216271077715, time: 0.09274554252624512
Test Loss Energy: 7.763697185311018, Test Loss Force: 9.039296237112378, time: 17.941713571548462


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.832962431187746, Training Loss Force: 3.33329260172068, time: 1.434802532196045
Validation Loss Energy: 1.6173288397958083, Validation Loss Force: 2.928818044953465, time: 0.09506011009216309
Test Loss Energy: 7.555814459796024, Test Loss Force: 9.169717659523087, time: 17.835830211639404


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7755836484161833, Training Loss Force: 3.261595135187517, time: 1.4164948463439941
Validation Loss Energy: 3.0463646417504524, Validation Loss Force: 2.9465002018315904, time: 0.09460210800170898
Test Loss Energy: 7.939016732956481, Test Loss Force: 8.91135386608074, time: 18.275742530822754


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.182561913760396, Training Loss Force: 3.2835487320250607, time: 1.3970661163330078
Validation Loss Energy: 1.5270329384157555, Validation Loss Force: 2.911663391282042, time: 0.093170166015625
Test Loss Energy: 8.133788920662587, Test Loss Force: 9.048655256808747, time: 17.868420124053955


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.225046975267729, Training Loss Force: 3.237444731873443, time: 1.423842191696167
Validation Loss Energy: 2.1726340707209895, Validation Loss Force: 2.9503425806137207, time: 0.09280276298522949
Test Loss Energy: 7.608925224689029, Test Loss Force: 9.06099876119769, time: 17.854296445846558


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0340480146480573, Training Loss Force: 3.266005220090647, time: 1.4659509658813477
Validation Loss Energy: 1.4906094988668985, Validation Loss Force: 3.0075874779945657, time: 0.09467458724975586
Test Loss Energy: 7.768316670085981, Test Loss Force: 9.114139837073909, time: 17.987808227539062


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8508954693925888, Training Loss Force: 3.304357998721309, time: 1.4778025150299072
Validation Loss Energy: 2.160864447674684, Validation Loss Force: 2.9679185243092387, time: 0.09623193740844727
Test Loss Energy: 7.4180790181199905, Test Loss Force: 8.826209498164028, time: 17.982967138290405


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9616002866946052, Training Loss Force: 3.2960969734073893, time: 1.443789005279541
Validation Loss Energy: 3.910511978077475, Validation Loss Force: 2.9427141583433807, time: 0.09227299690246582
Test Loss Energy: 8.016408829091242, Test Loss Force: 8.920912611840356, time: 17.835674285888672

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–â–ƒ
wandb:   test_error_force â–‡â–†â–…â–†â–ˆâ–„â–„â–†â–…â–„â–‚â–…â–ƒâ–„â–‚â–ƒâ–ƒâ–„â–â–‚
wandb:          test_loss â–…â–„â–„â–…â–ˆâ–ƒâ–ƒâ–…â–„â–ƒâ–‚â–„â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–â–â–‚â–â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–ƒâ–â–ˆâ–â–‚â–ƒâ–â–ƒâ–„â–â–â–â–…â–â–ƒâ–â–ƒâ–‡
wandb:  valid_error_force â–„â–ˆâ–ƒâ–ƒâ–†â–„â–ƒâ–…â–ƒâ–…â–†â–‚â–„â–‚â–ƒâ–â–ƒâ–†â–„â–ƒ
wandb:         valid_loss â–â–‚â–‚â–â–ˆâ–â–â–ƒâ–‚â–‚â–ƒâ–„â–‚â–â–ƒâ–â–‚â–â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1249
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.01641
wandb:   test_error_force 8.92091
wandb:          test_loss 4.70495
wandb: train_error_energy 1.9616
wandb:  train_error_force 3.2961
wandb:         train_loss 1.49272
wandb: valid_error_energy 3.91051
wandb:  valid_error_force 2.94271
wandb:         valid_loss 1.62668
wandb: 
wandb: ğŸš€ View run al_80_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/dtmgjhj3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_042216-dtmgjhj3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7087339758872986, Uncertainty Bias: 0.019412457942962646
3.71933e-05 0.10539341
0.4744512 7.981565
(48745, 22, 3)
Found uncertainty sample 0 after 3990 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2330 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 992 steps.
Found uncertainty sample 9 after 2224 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1026 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3208 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1812 steps.
Found uncertainty sample 17 after 2547 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3003 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3977 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1720 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3020 steps.
Found uncertainty sample 48 after 1995 steps.
Found uncertainty sample 49 after 1807 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2632 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3610 steps.
Found uncertainty sample 55 after 2279 steps.
Found uncertainty sample 56 after 3742 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 692 steps.
Found uncertainty sample 60 after 269 steps.
Found uncertainty sample 61 after 1132 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2366 steps.
Found uncertainty sample 76 after 2833 steps.
Found uncertainty sample 77 after 1563 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1713 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2786 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 419 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_071142-q6uevbp8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q6uevbp8
Training model 14. Added 27 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.536951222395506, Training Loss Force: 3.579563819840601, time: 1.4421472549438477
Validation Loss Energy: 1.2897269145168369, Validation Loss Force: 2.7871255399757873, time: 0.127716064453125
Test Loss Energy: 7.958118043073906, Test Loss Force: 9.015964642239318, time: 17.811686038970947


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0494063295185363, Training Loss Force: 3.3391627838809455, time: 1.4672701358795166
Validation Loss Energy: 1.4539407614201592, Validation Loss Force: 3.191634549226606, time: 0.12171268463134766
Test Loss Energy: 7.589944412387956, Test Loss Force: 8.83285122215325, time: 17.963033199310303


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.145223830077633, Training Loss Force: 3.2992419746913884, time: 1.4217846393585205
Validation Loss Energy: 1.386605249854234, Validation Loss Force: 2.6462963232768715, time: 0.13030242919921875
Test Loss Energy: 7.6185769109180255, Test Loss Force: 8.896072089590557, time: 17.962692737579346


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8632714372234411, Training Loss Force: 3.2727772790926637, time: 1.4491832256317139
Validation Loss Energy: 1.439780868593249, Validation Loss Force: 2.76152415492274, time: 0.1247406005859375
Test Loss Energy: 7.662062029048229, Test Loss Force: 8.86959298356751, time: 18.294496297836304


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9674158564634674, Training Loss Force: 3.2852179879776946, time: 1.4725446701049805
Validation Loss Energy: 2.5279905360268433, Validation Loss Force: 3.826167800298926, time: 0.1223607063293457
Test Loss Energy: 8.631403236249557, Test Loss Force: 8.863948117867814, time: 17.980383157730103


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1551220330703527, Training Loss Force: 3.3148843764249705, time: 1.4245579242706299
Validation Loss Energy: 2.206529436121555, Validation Loss Force: 2.5067141651297247, time: 0.12410569190979004
Test Loss Energy: 8.158254589314575, Test Loss Force: 8.75383573504267, time: 17.84714365005493


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.5463469656958457, Training Loss Force: 3.3060708811263595, time: 1.5685317516326904
Validation Loss Energy: 1.6494839344863752, Validation Loss Force: 3.061224912542235, time: 0.14067387580871582
Test Loss Energy: 7.749304110527412, Test Loss Force: 8.888639020441232, time: 17.867947578430176


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8640286125207113, Training Loss Force: 3.2851250291759984, time: 1.4095263481140137
Validation Loss Energy: 1.4684783567858495, Validation Loss Force: 2.5871546187764407, time: 0.13090729713439941
Test Loss Energy: 7.690616765916667, Test Loss Force: 8.882503228730927, time: 18.00203013420105


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9270068451714628, Training Loss Force: 3.2807910303200316, time: 1.460808515548706
Validation Loss Energy: 0.8809027303029754, Validation Loss Force: 2.7769275157614404, time: 0.1318826675415039
Test Loss Energy: 8.004480095533392, Test Loss Force: 8.744562173666056, time: 17.979458332061768


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1565002604492585, Training Loss Force: 3.3040143756953135, time: 1.4471335411071777
Validation Loss Energy: 1.7539447109154784, Validation Loss Force: 3.6840641367432925, time: 0.13115525245666504
Test Loss Energy: 7.996964608489092, Test Loss Force: 8.769332556300695, time: 18.012620449066162


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8824350731634394, Training Loss Force: 3.282098042539341, time: 1.4456300735473633
Validation Loss Energy: 1.471246857944456, Validation Loss Force: 2.546770785798112, time: 0.12363171577453613
Test Loss Energy: 8.02041547008626, Test Loss Force: 8.807065934536002, time: 18.080148935317993


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1380871614826176, Training Loss Force: 3.2606019027619197, time: 1.4610846042633057
Validation Loss Energy: 1.2474460239161334, Validation Loss Force: 2.4413154576287224, time: 0.13179826736450195
Test Loss Energy: 7.933051410215778, Test Loss Force: 8.76195972673309, time: 17.894383430480957


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9401222527021122, Training Loss Force: 3.2659184403577504, time: 1.4149417877197266
Validation Loss Energy: 0.9289508770346032, Validation Loss Force: 2.6854118327999954, time: 0.12158346176147461
Test Loss Energy: 7.840710641306684, Test Loss Force: 8.772051269629209, time: 17.974299430847168


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.334263313346598, Training Loss Force: 3.2869665308464646, time: 1.4598751068115234
Validation Loss Energy: 1.9043242072832367, Validation Loss Force: 3.072291457760273, time: 0.1318821907043457
Test Loss Energy: 7.330865850987182, Test Loss Force: 8.656451400392452, time: 18.039687395095825


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9386385191151372, Training Loss Force: 3.260941445375816, time: 1.4762425422668457
Validation Loss Energy: 1.1416972734796975, Validation Loss Force: 2.6336765494314145, time: 0.13464689254760742
Test Loss Energy: 7.814978171743495, Test Loss Force: 8.822096437638557, time: 18.353776216506958


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8467068790556413, Training Loss Force: 3.2617452141918717, time: 1.4520277976989746
Validation Loss Energy: 1.6741228321561499, Validation Loss Force: 2.871738590748044, time: 0.12078523635864258
Test Loss Energy: 7.490788032373776, Test Loss Force: 8.727857184596441, time: 17.977931022644043


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.085664128273102, Training Loss Force: 3.267203519666187, time: 1.4526703357696533
Validation Loss Energy: 2.6973875361408566, Validation Loss Force: 3.2023889123020535, time: 0.12529683113098145
Test Loss Energy: 7.583177310514084, Test Loss Force: 8.69395528717899, time: 18.01189637184143


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.969182418832871, Training Loss Force: 3.2409824630802078, time: 1.4773733615875244
Validation Loss Energy: 2.150971034851967, Validation Loss Force: 2.578938238626278, time: 0.12010025978088379
Test Loss Energy: 7.685664366286596, Test Loss Force: 8.76628856415323, time: 17.886014461517334


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1870868068751665, Training Loss Force: 3.272009109506313, time: 1.4591281414031982
Validation Loss Energy: 1.5685461493022297, Validation Loss Force: 2.5673756978856854, time: 0.12670183181762695
Test Loss Energy: 7.811217688574786, Test Loss Force: 8.780885456982817, time: 18.006099700927734


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2047853605525254, Training Loss Force: 3.2564316325289537, time: 1.468294382095337
Validation Loss Energy: 2.6995924060238337, Validation Loss Force: 2.800221380455238, time: 0.12185883522033691
Test Loss Energy: 8.521344154122591, Test Loss Force: 8.716928424364546, time: 17.928884506225586

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ƒâ–ƒâ–ˆâ–…â–ƒâ–ƒâ–…â–…â–…â–„â–„â–â–„â–‚â–‚â–ƒâ–„â–‡
wandb:   test_error_force â–ˆâ–„â–†â–…â–…â–ƒâ–†â–…â–ƒâ–ƒâ–„â–ƒâ–ƒâ–â–„â–‚â–‚â–ƒâ–ƒâ–‚
wandb:          test_loss â–ˆâ–„â–„â–„â–†â–„â–ˆâ–†â–ƒâ–ƒâ–…â–‚â–ƒâ–‚â–ƒâ–â–â–„â–‚â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–‚â–ƒâ–â–â–‚â–â–‚â–â–‚â–â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–ƒâ–â–â–‚â–â–â–â–‚â–â–â–â–â–‚â–‚
wandb: valid_error_energy â–ƒâ–ƒâ–ƒâ–ƒâ–‡â–†â–„â–ƒâ–â–„â–ƒâ–‚â–â–…â–‚â–„â–ˆâ–†â–„â–ˆ
wandb:  valid_error_force â–ƒâ–…â–‚â–ƒâ–ˆâ–â–„â–‚â–ƒâ–‡â–‚â–â–‚â–„â–‚â–ƒâ–…â–‚â–‚â–ƒ
wandb:         valid_loss â–‚â–…â–‚â–‚â–ˆâ–‚â–…â–‚â–‚â–ˆâ–â–â–ƒâ–…â–‚â–„â–†â–‚â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1273
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 8.52134
wandb:   test_error_force 8.71693
wandb:          test_loss 4.68771
wandb: train_error_energy 2.20479
wandb:  train_error_force 3.25643
wandb:         train_loss 1.51233
wandb: valid_error_energy 2.69959
wandb:  valid_error_force 2.80022
wandb:         valid_loss 1.54475
wandb: 
wandb: ğŸš€ View run al_80_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/q6uevbp8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_071142-q6uevbp8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.704059898853302, Uncertainty Bias: 0.017555877566337585
4.9591064e-05 0.0024280548
1.2284105 7.2601595
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3852 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2194 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3496 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1016 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1577 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3440 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1099 steps.
Found uncertainty sample 32 after 3159 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 252 steps.
Found uncertainty sample 35 after 3232 steps.
Found uncertainty sample 36 after 3134 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1010 steps.
Found uncertainty sample 40 after 2395 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1572 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2355 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2278 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3165 steps.
Found uncertainty sample 72 after 3713 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1697 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 334 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1340 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_100433-kt4vj109
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/kt4vj109
Training model 15. Added 21 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.077103659232698, Training Loss Force: 3.5964107152894225, time: 1.4972283840179443
Validation Loss Energy: 1.2431140235157516, Validation Loss Force: 3.2682695871694163, time: 0.12964320182800293
Test Loss Energy: 7.5415044767438655, Test Loss Force: 8.755460832760006, time: 17.97516131401062


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9722274728983382, Training Loss Force: 3.333991558676234, time: 1.4618301391601562
Validation Loss Energy: 2.7122441328917315, Validation Loss Force: 2.734691298158139, time: 0.12425422668457031
Test Loss Energy: 8.540652789033595, Test Loss Force: 8.68288971249532, time: 18.137062072753906


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0800174191758463, Training Loss Force: 3.323259074202114, time: 1.4835834503173828
Validation Loss Energy: 2.0686641127567977, Validation Loss Force: 3.881179882818981, time: 0.12449884414672852
Test Loss Energy: 7.6556188443306805, Test Loss Force: 8.634567754192748, time: 18.169942617416382


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8694554491422026, Training Loss Force: 3.3144042228617323, time: 1.4441022872924805
Validation Loss Energy: 2.554231760870714, Validation Loss Force: 2.818683770020695, time: 0.1359999179840088
Test Loss Energy: 7.401205168894494, Test Loss Force: 8.528093195313698, time: 17.977571725845337


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1663417991000857, Training Loss Force: 3.3066115305021997, time: 1.4919452667236328
Validation Loss Energy: 1.1880814554342718, Validation Loss Force: 3.2236681778980696, time: 0.1237788200378418
Test Loss Energy: 7.31195247362892, Test Loss Force: 8.627912891558106, time: 18.747292041778564


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1483055385394323, Training Loss Force: 3.2984060964413935, time: 1.4312193393707275
Validation Loss Energy: 2.1859526916809413, Validation Loss Force: 3.022536259771855, time: 0.11864161491394043
Test Loss Energy: 8.120657715426372, Test Loss Force: 8.653855880226182, time: 18.039327144622803


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.148396686253484, Training Loss Force: 3.3075814066994482, time: 1.6523644924163818
Validation Loss Energy: 1.92177712627563, Validation Loss Force: 2.951590529842073, time: 0.12309813499450684
Test Loss Energy: 7.267711499836731, Test Loss Force: 8.603980052685216, time: 17.99578046798706


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1802852839930584, Training Loss Force: 3.295426082675714, time: 1.4307794570922852
Validation Loss Energy: 1.6374310206191636, Validation Loss Force: 3.050150128565798, time: 0.1192622184753418
Test Loss Energy: 7.783639986612853, Test Loss Force: 8.579051647237005, time: 18.13529944419861


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9311432585607908, Training Loss Force: 3.2989339961077957, time: 1.5194613933563232
Validation Loss Energy: 1.4003993807753146, Validation Loss Force: 2.85611122474854, time: 0.12538814544677734
Test Loss Energy: 7.390960611491878, Test Loss Force: 8.528069133056253, time: 18.032896995544434


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8277829225550333, Training Loss Force: 3.276002669369298, time: 1.4865586757659912
Validation Loss Energy: 1.8137341042941268, Validation Loss Force: 2.8135103864187814, time: 0.13437509536743164
Test Loss Energy: 7.979883243277663, Test Loss Force: 8.516797135913658, time: 18.111679077148438


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8880278236883605, Training Loss Force: 3.2588298165684106, time: 1.5023877620697021
Validation Loss Energy: 1.5505774172332947, Validation Loss Force: 3.0383688153893313, time: 0.1239771842956543
Test Loss Energy: 7.51964909903343, Test Loss Force: 8.559550015301031, time: 18.137815713882446


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.221179080909632, Training Loss Force: 3.2767417354194057, time: 1.496211290359497
Validation Loss Energy: 1.407465229448468, Validation Loss Force: 2.7673067613079114, time: 0.1305992603302002
Test Loss Energy: 7.343349511030896, Test Loss Force: 8.451270071308096, time: 18.025503873825073


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.5948095495370556, Training Loss Force: 3.292166276981743, time: 1.4646234512329102
Validation Loss Energy: 1.8138068057702723, Validation Loss Force: 3.1774790262816843, time: 0.13261818885803223
Test Loss Energy: 7.423120005095927, Test Loss Force: 8.474400128453759, time: 18.181909561157227


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2680372962845046, Training Loss Force: 3.273266157892076, time: 1.4749658107757568
Validation Loss Energy: 1.5443383947662577, Validation Loss Force: 2.6284179948811834, time: 0.12281513214111328
Test Loss Energy: 7.312121170571813, Test Loss Force: 8.51823074282872, time: 18.03561758995056


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7643137911970135, Training Loss Force: 3.2642410243955617, time: 1.4753727912902832
Validation Loss Energy: 1.3092116894658208, Validation Loss Force: 2.6586634789762735, time: 0.12967562675476074
Test Loss Energy: 7.194297745896732, Test Loss Force: 8.450028929809996, time: 17.963977336883545


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.084408337968014, Training Loss Force: 3.2961482584564594, time: 1.4894700050354004
Validation Loss Energy: 1.582093896813341, Validation Loss Force: 2.822965697696886, time: 0.13320422172546387
Test Loss Energy: 8.01596962061284, Test Loss Force: 8.602143752700067, time: 18.18038296699524


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.943526427430358, Training Loss Force: 3.267797707801557, time: 1.453150987625122
Validation Loss Energy: 1.3860929438167406, Validation Loss Force: 3.00344360518885, time: 0.12688684463500977
Test Loss Energy: 7.427588326665981, Test Loss Force: 8.56900702807452, time: 18.101491928100586


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.11577026072149, Training Loss Force: 3.267282418812151, time: 1.4700732231140137
Validation Loss Energy: 1.7700803192405625, Validation Loss Force: 2.757460331674985, time: 0.12679600715637207
Test Loss Energy: 7.213901113150452, Test Loss Force: 8.447016999687929, time: 18.012630701065063


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9063714056870777, Training Loss Force: 3.2510661092145323, time: 1.4673244953155518
Validation Loss Energy: 2.0631417509359293, Validation Loss Force: 2.9112468886445844, time: 0.12856388092041016
Test Loss Energy: 7.738329126046113, Test Loss Force: 8.494160091573221, time: 18.05235505104065


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.096800842648846, Training Loss Force: 3.253246355148543, time: 1.4865880012512207
Validation Loss Energy: 1.0683735762396227, Validation Loss Force: 2.534947833491357, time: 0.12502312660217285
Test Loss Energy: 7.362713470481109, Test Loss Force: 8.43998195338566, time: 18.6690936088562

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–‚â–‚â–†â–â–„â–‚â–…â–ƒâ–‚â–‚â–‚â–â–…â–‚â–â–„â–‚
wandb:   test_error_force â–ˆâ–†â–…â–ƒâ–…â–†â–…â–„â–ƒâ–ƒâ–„â–â–‚â–ƒâ–â–…â–„â–â–‚â–
wandb:          test_loss â–ˆâ–ˆâ–…â–„â–ƒâ–…â–„â–…â–„â–„â–ƒâ–‚â–†â–ƒâ–â–…â–ƒâ–‚â–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–„â–ƒâ–â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–…â–‡â–‚â–†â–…â–ƒâ–‚â–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–„â–…â–
wandb:  valid_error_force â–…â–‚â–ˆâ–‚â–…â–„â–ƒâ–„â–ƒâ–‚â–„â–‚â–„â–â–‚â–‚â–ƒâ–‚â–ƒâ–
wandb:         valid_loss â–†â–„â–ˆâ–„â–„â–„â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–†â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1291
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.36271
wandb:   test_error_force 8.43998
wandb:          test_loss 4.447
wandb: train_error_energy 2.0968
wandb:  train_error_force 3.25325
wandb:         train_loss 1.50109
wandb: valid_error_energy 1.06837
wandb:  valid_error_force 2.53495
wandb:         valid_loss 1.26279
wandb: 
wandb: ğŸš€ View run al_80_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/kt4vj109
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_100433-kt4vj109/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6891927719116211, Uncertainty Bias: 0.029485642910003662
0.00010681152 0.0018672943
0.5700386 6.760106
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1964 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1932 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2962 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2440 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1567 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3254 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 923 steps.
Found uncertainty sample 33 after 3041 steps.
Found uncertainty sample 34 after 1752 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3602 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2272 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1595 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2632 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3751 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1447 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 789 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2546 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3761 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1405 steps.
Found uncertainty sample 85 after 2176 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3924 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1494 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2498 steps.
Found uncertainty sample 98 after 2250 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_125621-eqnr73hk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eqnr73hk
Training model 16. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.4081219271703724, Training Loss Force: 3.5997716725161473, time: 1.5217077732086182
Validation Loss Energy: 1.669369235561597, Validation Loss Force: 2.9572700404126797, time: 0.13018250465393066
Test Loss Energy: 7.297550499074316, Test Loss Force: 8.508105652669025, time: 17.78011918067932


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.374720128852982, Training Loss Force: 3.333118842259977, time: 1.4459576606750488
Validation Loss Energy: 1.5024082359040336, Validation Loss Force: 3.3565226104701544, time: 0.12839961051940918
Test Loss Energy: 7.3255224839743, Test Loss Force: 8.388015929406063, time: 18.370980978012085


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9562541713722936, Training Loss Force: 3.3074941584109285, time: 1.4601702690124512
Validation Loss Energy: 1.7656220932680828, Validation Loss Force: 2.9574487324022867, time: 0.1269843578338623
Test Loss Energy: 7.299883230010954, Test Loss Force: 8.459806527863268, time: 17.978854179382324


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1538407269177493, Training Loss Force: 3.325701613528118, time: 1.4871070384979248
Validation Loss Energy: 1.291214066075202, Validation Loss Force: 2.709229415325015, time: 0.12523102760314941
Test Loss Energy: 7.470853244829582, Test Loss Force: 8.469324932035839, time: 17.90016269683838


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1987918326518208, Training Loss Force: 3.319527791030937, time: 1.4399447441101074
Validation Loss Energy: 1.4231045639145656, Validation Loss Force: 2.9189719493242574, time: 0.13414311408996582
Test Loss Energy: 7.412259600794413, Test Loss Force: 8.388262332051847, time: 18.09194779396057


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.04125300730178, Training Loss Force: 3.3143560014142515, time: 1.4721195697784424
Validation Loss Energy: 1.9591141773302285, Validation Loss Force: 3.1853244396347313, time: 0.12860321998596191
Test Loss Energy: 7.2236453947699415, Test Loss Force: 8.361392825228215, time: 17.85256290435791


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1870704609232474, Training Loss Force: 3.3046741622968487, time: 1.7022347450256348
Validation Loss Energy: 2.313725591673808, Validation Loss Force: 2.6174881685187454, time: 0.1308279037475586
Test Loss Energy: 7.198264285460955, Test Loss Force: 8.354401186585527, time: 17.906222343444824


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.048063144900132, Training Loss Force: 3.2946978459494343, time: 1.4801013469696045
Validation Loss Energy: 1.1984701401048192, Validation Loss Force: 3.0872530430134533, time: 0.12538814544677734
Test Loss Energy: 7.147670190208807, Test Loss Force: 8.321389205645593, time: 17.966241359710693


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3030179239475483, Training Loss Force: 3.2925969679885605, time: 1.482919692993164
Validation Loss Energy: 1.580504651451568, Validation Loss Force: 3.328447259871276, time: 0.12607812881469727
Test Loss Energy: 7.180155585432182, Test Loss Force: 8.364433303633245, time: 17.865540266036987


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0681659407791155, Training Loss Force: 3.2875070826008925, time: 1.4881560802459717
Validation Loss Energy: 1.3095577729858792, Validation Loss Force: 3.126707566311252, time: 0.1282517910003662
Test Loss Energy: 7.515130344650534, Test Loss Force: 8.432149791178409, time: 18.057223558425903


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0903682378719375, Training Loss Force: 3.304702077404412, time: 1.5018441677093506
Validation Loss Energy: 2.094646095047522, Validation Loss Force: 2.893988471151159, time: 0.12836480140686035
Test Loss Energy: 7.124506774660312, Test Loss Force: 8.284875746556912, time: 18.003101110458374


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9743645861894954, Training Loss Force: 3.297124108703966, time: 1.5238101482391357
Validation Loss Energy: 3.1062176628375497, Validation Loss Force: 3.0495514825669705, time: 0.12354922294616699
Test Loss Energy: 7.2833695265615646, Test Loss Force: 8.299918388042437, time: 17.947730541229248


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0667814953643098, Training Loss Force: 3.3026814961099413, time: 1.4968817234039307
Validation Loss Energy: 1.0929819960700484, Validation Loss Force: 2.925485133177218, time: 0.1218254566192627
Test Loss Energy: 7.427984558833413, Test Loss Force: 8.391089514399605, time: 18.007689237594604


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0669149447851325, Training Loss Force: 3.293057860534902, time: 1.4714107513427734
Validation Loss Energy: 1.6512778684605425, Validation Loss Force: 2.8170084073667345, time: 0.13064336776733398
Test Loss Energy: 7.536550125552798, Test Loss Force: 8.313041227447284, time: 18.001545429229736


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1178332659192147, Training Loss Force: 3.292405836397032, time: 1.4760773181915283
Validation Loss Energy: 2.0863073582016725, Validation Loss Force: 2.9344198439921434, time: 0.12687420845031738
Test Loss Energy: 8.166135633811296, Test Loss Force: 8.427429748550823, time: 17.473854780197144


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.156130925246732, Training Loss Force: 3.3011463552774125, time: 1.5565786361694336
Validation Loss Energy: 1.438745958070263, Validation Loss Force: 2.8393020422570245, time: 0.1269676685333252
Test Loss Energy: 7.199136698511473, Test Loss Force: 8.248837148657737, time: 18.066996335983276


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9569184287358024, Training Loss Force: 3.283926834282112, time: 1.418431282043457
Validation Loss Energy: 1.618642086751204, Validation Loss Force: 3.1924279193935465, time: 0.12261605262756348
Test Loss Energy: 7.317567438709481, Test Loss Force: 8.28137660235387, time: 16.651396989822388


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.200369199157754, Training Loss Force: 3.274741693995908, time: 1.6404716968536377
Validation Loss Energy: 1.4848214927549384, Validation Loss Force: 2.983715007525075, time: 0.12226033210754395
Test Loss Energy: 7.110604926665533, Test Loss Force: 8.263326628689267, time: 16.17562770843506


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.90675479579325, Training Loss Force: 3.2719809930461023, time: 1.4488084316253662
Validation Loss Energy: 1.3921261086583676, Validation Loss Force: 3.0909018109731985, time: 0.11939811706542969
Test Loss Energy: 7.213951884047336, Test Loss Force: 8.270735185579628, time: 16.32222867012024


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9239564353699405, Training Loss Force: 3.2684313590194103, time: 1.49534010887146
Validation Loss Energy: 1.7578763800251251, Validation Loss Force: 3.1963722806445114, time: 0.12492847442626953
Test Loss Energy: 7.125449285356935, Test Loss Force: 8.257490920376021, time: 16.174624919891357

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–â–„â–â–‚â–ƒâ–„â–ˆâ–‚â–‚â–â–‚â–
wandb:   test_error_force â–ˆâ–…â–‡â–‡â–…â–„â–„â–ƒâ–„â–†â–‚â–‚â–…â–ƒâ–†â–â–‚â–â–‚â–
wandb:          test_loss â–ˆâ–‡â–ˆâ–†â–†â–…â–†â–ƒâ–„â–…â–‚â–„â–„â–ƒâ–‡â–ƒâ–…â–â–‚â–
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–ƒâ–‚â–ƒâ–‚â–‚â–„â–…â–â–ƒâ–‚â–„â–ˆâ–â–ƒâ–„â–‚â–ƒâ–‚â–‚â–ƒ
wandb:  valid_error_force â–„â–ˆâ–„â–‚â–„â–†â–â–…â–ˆâ–†â–„â–…â–„â–ƒâ–„â–ƒâ–†â–„â–…â–†
wandb:         valid_loss â–„â–ˆâ–…â–â–ƒâ–†â–‚â–†â–†â–„â–„â–‡â–„â–ƒâ–„â–ƒâ–†â–„â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1312
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.12545
wandb:   test_error_force 8.25749
wandb:          test_loss 4.36509
wandb: train_error_energy 1.92396
wandb:  train_error_force 3.26843
wandb:         train_loss 1.48667
wandb: valid_error_energy 1.75788
wandb:  valid_error_force 3.19637
wandb:         valid_loss 1.60467
wandb: 
wandb: ğŸš€ View run al_80_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eqnr73hk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_125621-eqnr73hk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7014780640602112, Uncertainty Bias: 0.023642271757125854
0.00035524368 0.007582277
0.5384252 6.135458
(48745, 22, 3)
Found uncertainty sample 0 after 1491 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1831 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1663 steps.
Found uncertainty sample 7 after 244 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1666 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2820 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2714 steps.
Found uncertainty sample 15 after 2420 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3235 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2114 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1899 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1963 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2992 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 705 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3440 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1145 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1778 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2565 steps.
Found uncertainty sample 59 after 3469 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3974 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1586 steps.
Found uncertainty sample 64 after 2081 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 537 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1332 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 721 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1912 steps.
Found uncertainty sample 80 after 2945 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2571 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2982 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3317 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1366 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3932 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3851 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_153618-8b9arfug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/8b9arfug
Training model 17. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.637420225809521, Training Loss Force: 3.539803100754167, time: 1.4916355609893799
Validation Loss Energy: 1.500927374749041, Validation Loss Force: 2.6870531270746287, time: 0.1325066089630127
Test Loss Energy: 7.486510765594158, Test Loss Force: 8.248685362911866, time: 17.615412712097168


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.25928289006483, Training Loss Force: 3.3512033096562552, time: 1.4758610725402832
Validation Loss Energy: 1.4909889270915597, Validation Loss Force: 3.0169842272872915, time: 0.1281108856201172
Test Loss Energy: 7.2273778962379165, Test Loss Force: 8.210628794983833, time: 17.64862060546875


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9575485799619172, Training Loss Force: 3.3572220407657456, time: 1.491985559463501
Validation Loss Energy: 1.890331010145697, Validation Loss Force: 2.9146712061052344, time: 0.12729239463806152
Test Loss Energy: 7.0632764924443325, Test Loss Force: 8.173074144295251, time: 17.687729120254517


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0338761224174937, Training Loss Force: 3.3367659777005776, time: 1.4706037044525146
Validation Loss Energy: 1.9166183275027748, Validation Loss Force: 2.9241848566995725, time: 0.12247133255004883
Test Loss Energy: 7.112854330377695, Test Loss Force: 8.156644950198682, time: 17.604607820510864


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.093225895329856, Training Loss Force: 3.3324759066956213, time: 1.498215913772583
Validation Loss Energy: 2.6389788584688194, Validation Loss Force: 3.1088493894732707, time: 0.12868404388427734
Test Loss Energy: 8.004309225526166, Test Loss Force: 8.282602390173167, time: 17.706427812576294


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.6024954917606538, Training Loss Force: 3.382953003356784, time: 1.478132963180542
Validation Loss Energy: 1.904251784143524, Validation Loss Force: 2.7920495341342613, time: 0.1308901309967041
Test Loss Energy: 6.864224706344516, Test Loss Force: 8.226981738304705, time: 17.584983825683594


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3198410221615626, Training Loss Force: 3.329483063721669, time: 1.446319580078125
Validation Loss Energy: 1.2826166433490707, Validation Loss Force: 2.995611440649986, time: 0.12716460227966309
Test Loss Energy: 7.125759000651815, Test Loss Force: 8.208970849487152, time: 18.260591745376587


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0408481823162177, Training Loss Force: 3.328210626188911, time: 1.5229673385620117
Validation Loss Energy: 1.7824941241260368, Validation Loss Force: 3.0839000910140726, time: 0.12818384170532227
Test Loss Energy: 6.954358236450713, Test Loss Force: 8.120904222994794, time: 17.770740270614624


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.099212572685624, Training Loss Force: 3.328218880852249, time: 1.452934980392456
Validation Loss Energy: 1.3256201788292397, Validation Loss Force: 2.8891073408032764, time: 0.12839436531066895
Test Loss Energy: 6.949767782602829, Test Loss Force: 8.160768447028834, time: 17.629381895065308


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.225136724982901, Training Loss Force: 3.3114165958026107, time: 1.5184288024902344
Validation Loss Energy: 2.4471745508655203, Validation Loss Force: 2.8488912890264046, time: 0.1255941390991211
Test Loss Energy: 7.015308160724861, Test Loss Force: 8.076617129875837, time: 17.855488061904907


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.5765903939450303, Training Loss Force: 3.3301057102734397, time: 1.4944286346435547
Validation Loss Energy: 1.741025558403321, Validation Loss Force: 3.035573760935073, time: 0.12732648849487305
Test Loss Energy: 7.14887885931743, Test Loss Force: 8.108254001766696, time: 17.77640128135681


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.189257560398917, Training Loss Force: 3.350380080617176, time: 1.5010299682617188
Validation Loss Energy: 2.4540224064448104, Validation Loss Force: 3.2685432475497613, time: 0.12899374961853027
Test Loss Energy: 7.88023692818886, Test Loss Force: 8.218270697481056, time: 17.659133434295654


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.333831523411943, Training Loss Force: 3.3315356067022455, time: 1.5190024375915527
Validation Loss Energy: 1.5880987270061486, Validation Loss Force: 2.8825938229465966, time: 0.1292884349822998
Test Loss Energy: 7.166284120700657, Test Loss Force: 8.12564539237768, time: 17.81589937210083


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.861474309208668, Training Loss Force: 3.343668366014035, time: 1.5016815662384033
Validation Loss Energy: 2.9506447426447444, Validation Loss Force: 3.1626824388656374, time: 0.12694621086120605
Test Loss Energy: 7.905031897694113, Test Loss Force: 8.180311898795193, time: 17.661661386489868


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1898592097803906, Training Loss Force: 3.3364236610002385, time: 1.714813470840454
Validation Loss Energy: 1.7338945790049838, Validation Loss Force: 2.786519323225999, time: 0.12318134307861328
Test Loss Energy: 6.936492784393855, Test Loss Force: 8.086942962682524, time: 17.629892826080322


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8739708558918835, Training Loss Force: 3.3040696909524794, time: 1.502037763595581
Validation Loss Energy: 1.5083252787860593, Validation Loss Force: 2.9577643659166397, time: 0.12743282318115234
Test Loss Energy: 7.044657071001295, Test Loss Force: 8.08323658228724, time: 17.726221323013306


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0101983390045923, Training Loss Force: 3.282684684020379, time: 1.4719252586364746
Validation Loss Energy: 1.7132247588613718, Validation Loss Force: 3.047858306381336, time: 0.12900829315185547
Test Loss Energy: 6.978196227593894, Test Loss Force: 7.9897743466366205, time: 18.103909969329834


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8701710811396743, Training Loss Force: 3.3193538548767068, time: 1.4373459815979004
Validation Loss Energy: 1.5711808819714201, Validation Loss Force: 2.9448909719139706, time: 0.12639689445495605
Test Loss Energy: 6.90244217896114, Test Loss Force: 8.073237977528887, time: 17.748075008392334


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1431639630051897, Training Loss Force: 3.298823616477713, time: 1.4843268394470215
Validation Loss Energy: 1.432509830302123, Validation Loss Force: 2.7691013632895167, time: 0.12432861328125
Test Loss Energy: 6.846697753358523, Test Loss Force: 8.056960767365387, time: 17.70956587791443


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0701783901886186, Training Loss Force: 3.290655258640023, time: 1.4410386085510254
Validation Loss Energy: 1.3684950115430623, Validation Loss Force: 3.0777599893151137, time: 0.1311485767364502
Test Loss Energy: 6.876608062681544, Test Loss Force: 8.07512907044523, time: 17.6091091632843

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–‚â–ƒâ–ˆâ–â–ƒâ–‚â–‚â–‚â–ƒâ–‡â–ƒâ–‡â–‚â–‚â–‚â–â–â–
wandb:   test_error_force â–‡â–†â–…â–…â–ˆâ–‡â–†â–„â–…â–ƒâ–„â–†â–„â–†â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–…â–†â–…â–…â–ˆâ–„â–„â–…â–„â–ƒâ–„â–…â–†â–‡â–‚â–‚â–â–â–â–
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–…â–‚â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–„â–„â–‡â–„â–â–ƒâ–â–†â–ƒâ–†â–‚â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–
wandb:  valid_error_force â–â–…â–„â–„â–†â–‚â–…â–†â–ƒâ–ƒâ–…â–ˆâ–ƒâ–‡â–‚â–„â–…â–„â–‚â–†
wandb:         valid_loss â–â–„â–ƒâ–ƒâ–…â–ƒâ–„â–…â–„â–„â–…â–ˆâ–„â–‡â–â–„â–„â–ƒâ–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1341
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.87661
wandb:   test_error_force 8.07513
wandb:          test_loss 4.25632
wandb: train_error_energy 2.07018
wandb:  train_error_force 3.29066
wandb:         train_loss 1.50852
wandb: valid_error_energy 1.3685
wandb:  valid_error_force 3.07776
wandb:         valid_loss 1.50091
wandb: 
wandb: ğŸš€ View run al_80_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/8b9arfug
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_153618-8b9arfug/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6857962608337402, Uncertainty Bias: 0.029271572828292847
5.340576e-05 0.00077056885
0.5161412 6.2307334
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2988 steps.
Found uncertainty sample 2 after 3391 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1779 steps.
Found uncertainty sample 6 after 2302 steps.
Found uncertainty sample 7 after 1735 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2736 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2291 steps.
Found uncertainty sample 15 after 3172 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2569 steps.
Found uncertainty sample 24 after 3178 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1629 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3894 steps.
Found uncertainty sample 29 after 2441 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3661 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 227 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2429 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3948 steps.
Found uncertainty sample 44 after 2053 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1385 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3633 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 873 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1972 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3120 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3787 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3121 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3312 steps.
Found uncertainty sample 78 after 2158 steps.
Found uncertainty sample 79 after 2822 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3222 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3706 steps.
Found uncertainty sample 92 after 3854 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1380 steps.
Found uncertainty sample 97 after 2434 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_182925-fcyrww66
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fcyrww66
Training model 18. Added 33 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7784599584830048, Training Loss Force: 3.6025490222472785, time: 1.5479061603546143
Validation Loss Energy: 1.5194935838037864, Validation Loss Force: 3.0874609046611767, time: 0.12508440017700195
Test Loss Energy: 7.040494104607768, Test Loss Force: 8.023507962138485, time: 17.563024520874023


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0578150881079815, Training Loss Force: 3.378084748735134, time: 1.5252320766448975
Validation Loss Energy: 1.2512227431338578, Validation Loss Force: 2.924695103047466, time: 0.1258237361907959
Test Loss Energy: 7.216960773744627, Test Loss Force: 8.034080510027247, time: 18.82017755508423


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8440834143514464, Training Loss Force: 3.361960110749251, time: 1.7363815307617188
Validation Loss Energy: 1.4544248163097628, Validation Loss Force: 3.0888548135146845, time: 0.13491177558898926
Test Loss Energy: 7.056718555007558, Test Loss Force: 8.05362474521594, time: 18.356382608413696


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9516651202352855, Training Loss Force: 3.3610918616090526, time: 1.6032538414001465
Validation Loss Energy: 1.6217773239931537, Validation Loss Force: 2.7834902434993705, time: 0.13009262084960938
Test Loss Energy: 6.812234608449405, Test Loss Force: 8.049709512819845, time: 17.99017643928528


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9396411909000977, Training Loss Force: 3.360179063104611, time: 1.538334846496582
Validation Loss Energy: 1.527835660686825, Validation Loss Force: 2.95109308697007, time: 0.1263113021850586
Test Loss Energy: 6.877561552948933, Test Loss Force: 7.986778087292875, time: 18.210638523101807


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0733480941731344, Training Loss Force: 3.3745482396842252, time: 1.5759084224700928
Validation Loss Energy: 1.2320128532455217, Validation Loss Force: 3.254854884472996, time: 0.13065576553344727
Test Loss Energy: 6.986216655981122, Test Loss Force: 7.936082839626508, time: 18.180583953857422


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0250707047010685, Training Loss Force: 3.3489520951236376, time: 1.5053911209106445
Validation Loss Energy: 1.3644250092265076, Validation Loss Force: 3.0698701534674546, time: 0.12941408157348633
Test Loss Energy: 6.969338281092671, Test Loss Force: 7.986012709318933, time: 18.0616672039032


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0687617467043466, Training Loss Force: 3.370710516240752, time: 1.6002976894378662
Validation Loss Energy: 1.6580168944947604, Validation Loss Force: 3.1461723010371028, time: 0.13515257835388184
Test Loss Energy: 6.920755436157564, Test Loss Force: 7.994916709861729, time: 18.21007251739502


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2032518783414803, Training Loss Force: 3.3630500037216366, time: 1.6731774806976318
Validation Loss Energy: 2.167795024841687, Validation Loss Force: 2.8686472749951286, time: 0.13717889785766602
Test Loss Energy: 7.6298622938571325, Test Loss Force: 7.96277117537185, time: 18.714474201202393


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.5071187472003467, Training Loss Force: 3.3873014182398546, time: 1.8824436664581299
Validation Loss Energy: 1.478372326281432, Validation Loss Force: 2.9992204621671834, time: 0.13085317611694336
Test Loss Energy: 7.0160554686895775, Test Loss Force: 7.929684673713875, time: 18.676023244857788


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9741130544869991, Training Loss Force: 3.362138649977467, time: 1.6753671169281006
Validation Loss Energy: 1.4694887737027833, Validation Loss Force: 3.2040663903129003, time: 0.13103151321411133
Test Loss Energy: 6.845866938635048, Test Loss Force: 7.94350113800055, time: 18.853277921676636


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0313387505377722, Training Loss Force: 3.350164896286221, time: 1.6630384922027588
Validation Loss Energy: 1.405433262157304, Validation Loss Force: 2.9956943849068436, time: 0.13609576225280762
Test Loss Energy: 6.785157224239651, Test Loss Force: 7.886109056314248, time: 19.36509084701538


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2916705079357373, Training Loss Force: 3.3443739242730217, time: 1.6011860370635986
Validation Loss Energy: 1.9691763176982726, Validation Loss Force: 3.1325141096296107, time: 0.12569379806518555
Test Loss Energy: 6.655842339245428, Test Loss Force: 7.931196986594279, time: 18.684348821640015


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.069151686984036, Training Loss Force: 3.350462667074553, time: 1.6846613883972168
Validation Loss Energy: 1.6215794267897103, Validation Loss Force: 3.2004412252826233, time: 0.13236069679260254
Test Loss Energy: 7.038064788888924, Test Loss Force: 7.976310226545295, time: 18.86899995803833


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1313242137266215, Training Loss Force: 3.3511390116594284, time: 1.6683814525604248
Validation Loss Energy: 1.8026188502004172, Validation Loss Force: 3.0814994949518253, time: 0.1300065517425537
Test Loss Energy: 6.890174832083333, Test Loss Force: 7.962452665228609, time: 18.83473825454712


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9088390313510115, Training Loss Force: 3.3342504631524474, time: 1.6468303203582764
Validation Loss Energy: 1.7725847904593852, Validation Loss Force: 3.16805076930481, time: 0.13367247581481934
Test Loss Energy: 6.790301210268171, Test Loss Force: 7.878277649549963, time: 18.78963613510132


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.063165159677189, Training Loss Force: 3.3431573895184776, time: 1.6894252300262451
Validation Loss Energy: 1.6959731327768977, Validation Loss Force: 2.7814267685240575, time: 0.13532161712646484
Test Loss Energy: 7.441017526173027, Test Loss Force: 8.036009953332204, time: 18.84992790222168


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0784801027407234, Training Loss Force: 3.3309439765076334, time: 1.7021982669830322
Validation Loss Energy: 1.8059430778799732, Validation Loss Force: 2.8252654246360285, time: 0.13426446914672852
Test Loss Energy: 6.675312114338045, Test Loss Force: 7.885688731578386, time: 18.862179279327393


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.126107800606846, Training Loss Force: 3.338505385721754, time: 1.654155969619751
Validation Loss Energy: 1.5295839474860773, Validation Loss Force: 3.304718522335482, time: 0.14456510543823242
Test Loss Energy: 6.927043288744205, Test Loss Force: 7.836826074299147, time: 18.817401885986328


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.067261546992948, Training Loss Force: 3.3371542189875596, time: 1.6561813354492188
Validation Loss Energy: 2.0118600446176025, Validation Loss Force: 2.971025538236942, time: 0.13330388069152832
Test Loss Energy: 6.732395522960969, Test Loss Force: 7.9585818174383975, time: 18.6392023563385

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–â–„â–ƒâ–‚â–‡â–â–ƒâ–‚
wandb:   test_error_force â–‡â–‡â–ˆâ–ˆâ–†â–„â–†â–†â–…â–„â–„â–ƒâ–„â–†â–…â–‚â–‡â–ƒâ–â–…
wandb:          test_loss â–ˆâ–…â–…â–†â–‡â–ƒâ–ƒâ–„â–‡â–„â–ƒâ–„â–…â–‡â–‚â–â–ˆâ–„â–â–„
wandb: train_error_energy â–ˆâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–„â–†â–‚â–‚â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–
wandb: valid_error_energy â–ƒâ–â–ƒâ–„â–ƒâ–â–‚â–„â–ˆâ–ƒâ–ƒâ–‚â–‡â–„â–…â–…â–„â–…â–ƒâ–‡
wandb:  valid_error_force â–…â–ƒâ–…â–â–ƒâ–‡â–…â–†â–‚â–„â–‡â–„â–†â–‡â–…â–†â–â–‚â–ˆâ–„
wandb:         valid_loss â–†â–‚â–„â–â–„â–†â–„â–†â–„â–ƒâ–†â–„â–ˆâ–‡â–…â–…â–‚â–ƒâ–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1370
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.7324
wandb:   test_error_force 7.95858
wandb:          test_loss 4.2283
wandb: train_error_energy 2.06726
wandb:  train_error_force 3.33715
wandb:         train_loss 1.52029
wandb: valid_error_energy 2.01186
wandb:  valid_error_force 2.97103
wandb:         valid_loss 1.50209
wandb: 
wandb: ğŸš€ View run al_80_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/fcyrww66
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_182925-fcyrww66/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6789688467979431, Uncertainty Bias: 0.032481566071510315
0.000333786 0.011294842
0.5107789 5.5654907
(48745, 22, 3)
Found uncertainty sample 0 after 2178 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 862 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3722 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1989 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 801 steps.
Found uncertainty sample 14 after 2928 steps.
Found uncertainty sample 15 after 3552 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2375 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1170 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2236 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3307 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3227 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1157 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2569 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 568 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 949 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2457 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1263 steps.
Found uncertainty sample 59 after 2615 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3758 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 641 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1330 steps.
Found uncertainty sample 69 after 1331 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2255 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2437 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1021 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3230 steps.
Found uncertainty sample 80 after 2345 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3523 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_211810-yhzr1n0v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/yhzr1n0v
Training model 19. Added 29 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7810145966413207, Training Loss Force: 3.692667606961, time: 1.6065337657928467
Validation Loss Energy: 1.5141802526436576, Validation Loss Force: 3.2439585698170204, time: 0.12489628791809082
Test Loss Energy: 6.687515318512139, Test Loss Force: 7.924377628585343, time: 17.547868251800537


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9968059125006463, Training Loss Force: 3.4044137286427754, time: 1.5549256801605225
Validation Loss Energy: 1.4953034201303428, Validation Loss Force: 2.942077101916881, time: 0.12894725799560547
Test Loss Energy: 6.954867076252403, Test Loss Force: 7.981142251934563, time: 17.71946382522583


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3428423937018334, Training Loss Force: 3.3848635446321755, time: 1.5997397899627686
Validation Loss Energy: 1.7806115121645036, Validation Loss Force: 3.2746159918320767, time: 0.12448906898498535
Test Loss Energy: 7.251629350176681, Test Loss Force: 7.9004570563342, time: 18.21864891052246


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0696740463804715, Training Loss Force: 3.40400177048016, time: 1.5726730823516846
Validation Loss Energy: 1.6894032796262983, Validation Loss Force: 3.0950263115632195, time: 0.12840747833251953
Test Loss Energy: 6.846600056396391, Test Loss Force: 7.836695324375627, time: 17.68071484565735


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0626231747377126, Training Loss Force: 3.3885186080559566, time: 1.5181574821472168
Validation Loss Energy: 1.7579567635868054, Validation Loss Force: 3.0450424323619334, time: 0.12751340866088867
Test Loss Energy: 6.7093197737707735, Test Loss Force: 7.802293393662918, time: 17.77289319038391


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1900316463092944, Training Loss Force: 3.394671584080079, time: 1.5248892307281494
Validation Loss Energy: 1.4939094556095485, Validation Loss Force: 3.0819271310465792, time: 0.12113022804260254
Test Loss Energy: 6.649454614300707, Test Loss Force: 7.848764931725393, time: 17.67042303085327


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.048459195425909, Training Loss Force: 3.3764601831273824, time: 1.5064711570739746
Validation Loss Energy: 1.5933853378687661, Validation Loss Force: 3.022594042415223, time: 0.13051533699035645
Test Loss Energy: 6.70507162651957, Test Loss Force: 7.817670994829114, time: 17.823731660842896


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3845792947228763, Training Loss Force: 3.40341223873433, time: 1.5656509399414062
Validation Loss Energy: 2.4542507536539597, Validation Loss Force: 3.048697101054046, time: 0.12717270851135254
Test Loss Energy: 6.665679183612816, Test Loss Force: 7.785476703956926, time: 17.73352289199829


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.174479524768796, Training Loss Force: 3.3986914099288636, time: 1.5851006507873535
Validation Loss Energy: 1.429296825860958, Validation Loss Force: 3.147644366760831, time: 0.12846899032592773
Test Loss Energy: 6.747387631374246, Test Loss Force: 7.906723320505951, time: 17.6523756980896


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1097525038071474, Training Loss Force: 3.3807045961131474, time: 1.5516083240509033
Validation Loss Energy: 1.403419553736106, Validation Loss Force: 3.0828507626638877, time: 0.1276543140411377
Test Loss Energy: 6.78541402821591, Test Loss Force: 7.848189237552798, time: 17.816304922103882


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1232564386334656, Training Loss Force: 3.361613733004634, time: 1.5479762554168701
Validation Loss Energy: 1.6867553538102116, Validation Loss Force: 2.898611750628058, time: 0.12992286682128906
Test Loss Energy: 6.595076108856019, Test Loss Force: 7.792491239050013, time: 17.683847904205322


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.986062799277731, Training Loss Force: 3.3701496332578786, time: 1.507979154586792
Validation Loss Energy: 1.519653627252422, Validation Loss Force: 3.147083685851385, time: 0.1252915859222412
Test Loss Energy: 6.602011028654271, Test Loss Force: 7.816456757826036, time: 17.68387746810913


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0172262065629343, Training Loss Force: 3.3731599480483, time: 1.5325841903686523
Validation Loss Energy: 2.3059811587784393, Validation Loss Force: 2.9449575499886027, time: 0.1309962272644043
Test Loss Energy: 6.683654582932251, Test Loss Force: 7.731781179575731, time: 17.735634326934814


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.973781902569064, Training Loss Force: 3.381687275539426, time: 1.5466792583465576
Validation Loss Energy: 2.0107656257653677, Validation Loss Force: 3.0023154519610067, time: 0.12525105476379395
Test Loss Energy: 6.5180910495884, Test Loss Force: 7.802597520078816, time: 18.173293352127075


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.055180681204223, Training Loss Force: 3.3712236880045854, time: 1.5249171257019043
Validation Loss Energy: 2.325104096365291, Validation Loss Force: 2.9598065759885164, time: 0.12890934944152832
Test Loss Energy: 6.662929445827174, Test Loss Force: 7.693529215391823, time: 17.6662917137146


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0177915002661644, Training Loss Force: 3.3786992074209476, time: 1.5502429008483887
Validation Loss Energy: 1.4739205577141838, Validation Loss Force: 3.0588463607254344, time: 0.12372493743896484
Test Loss Energy: 6.451090990110896, Test Loss Force: 7.747364053715102, time: 17.847718238830566


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.339791155864854, Training Loss Force: 3.378233105231234, time: 1.507131814956665
Validation Loss Energy: 1.347658245207291, Validation Loss Force: 3.0087725231891937, time: 0.12383675575256348
Test Loss Energy: 6.614904117801189, Test Loss Force: 7.740165192869855, time: 17.61650562286377


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.003116277655973, Training Loss Force: 3.3631109907058274, time: 1.5764968395233154
Validation Loss Energy: 1.5541743032820394, Validation Loss Force: 2.8769380266400306, time: 0.12613964080810547
Test Loss Energy: 6.801139564495206, Test Loss Force: 7.778791278524747, time: 17.77742028236389


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9895736616565427, Training Loss Force: 3.3533608857211643, time: 1.5409598350524902
Validation Loss Energy: 1.458963704180355, Validation Loss Force: 2.806222759276284, time: 0.12738394737243652
Test Loss Energy: 6.613405878543453, Test Loss Force: 7.758194930455736, time: 17.74781632423401


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9846907448948299, Training Loss Force: 3.359102095887843, time: 1.5677473545074463
Validation Loss Energy: 2.9095261014848544, Validation Loss Force: 3.021821046475135, time: 0.12946748733520508
Test Loss Energy: 7.620848826364262, Test Loss Force: 7.800719722026029, time: 17.681110858917236

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–†â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–â–‚â–ƒâ–‚â–ˆ
wandb:   test_error_force â–‡â–ˆâ–†â–„â–„â–…â–„â–ƒâ–†â–…â–ƒâ–„â–‚â–„â–â–‚â–‚â–ƒâ–ƒâ–„
wandb:          test_loss â–‡â–ˆâ–ˆâ–„â–„â–„â–„â–„â–…â–…â–‚â–†â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–â–…
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–‚â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–†â–â–â–ƒâ–‚â–…â–„â–…â–‚â–â–‚â–â–ˆ
wandb:  valid_error_force â–ˆâ–ƒâ–ˆâ–…â–…â–…â–„â–…â–†â–…â–‚â–†â–ƒâ–„â–ƒâ–…â–„â–‚â–â–„
wandb:         valid_loss â–†â–ƒâ–ˆâ–†â–…â–…â–„â–‡â–†â–…â–ƒâ–ˆâ–…â–…â–„â–…â–…â–‚â–â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1396
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 7.62085
wandb:   test_error_force 7.80072
wandb:          test_loss 4.15926
wandb: train_error_energy 1.98469
wandb:  train_error_force 3.3591
wandb:         train_loss 1.53312
wandb: valid_error_energy 2.90953
wandb:  valid_error_force 3.02182
wandb:         valid_loss 1.57435
wandb: 
wandb: ğŸš€ View run al_80_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/yhzr1n0v
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_211810-yhzr1n0v/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.6988793015480042, Uncertainty Bias: 0.02832302451133728
4.9591064e-05 0.010393143
0.5222878 6.2066684
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3235 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 686 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 497 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1480 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1023 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1593 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3461 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3194 steps.
Found uncertainty sample 28 after 378 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1028 steps.
Found uncertainty sample 39 after 1421 steps.
Found uncertainty sample 40 after 3419 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1663 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 305 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 215 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3359 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2171 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3228 steps.
Found uncertainty sample 63 after 3026 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3378 steps.
Found uncertainty sample 66 after 192 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3431 steps.
Found uncertainty sample 76 after 230 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1820 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2146 steps.
Found uncertainty sample 86 after 1267 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3396 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 394 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 545 steps.
Found uncertainty sample 97 after 474 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2844 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241210_235238-ojotar8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ojotar8j
Training model 20. Added 31 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.220437913755954, Training Loss Force: 3.9511211299645685, time: 1.637535810470581
Validation Loss Energy: 1.6049198222969716, Validation Loss Force: 3.161791316943634, time: 0.12712907791137695
Test Loss Energy: 6.672744403333068, Test Loss Force: 7.9159246811205435, time: 17.64650058746338


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.127410720546999, Training Loss Force: 3.4408444842225867, time: 1.6286649703979492
Validation Loss Energy: 2.661440385895139, Validation Loss Force: 3.069282418256778, time: 0.12485384941101074
Test Loss Energy: 6.650479832012453, Test Loss Force: 7.692071728085214, time: 17.751972675323486


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.254690948972841, Training Loss Force: 3.4025939478414284, time: 1.5875952243804932
Validation Loss Energy: 1.39145136547892, Validation Loss Force: 3.070155503977961, time: 0.1256427764892578
Test Loss Energy: 6.593724924499161, Test Loss Force: 7.704340648802532, time: 17.80820059776306


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9939023767311193, Training Loss Force: 3.4077513858583925, time: 1.5807163715362549
Validation Loss Energy: 1.8797466549631654, Validation Loss Force: 2.921192628716595, time: 0.12534284591674805
Test Loss Energy: 7.26477447981226, Test Loss Force: 7.743966805711174, time: 18.203571319580078


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.096756258794533, Training Loss Force: 3.382554847950064, time: 1.5769755840301514
Validation Loss Energy: 1.7277671694473429, Validation Loss Force: 3.0634714215555006, time: 0.12337350845336914
Test Loss Energy: 6.5936525278815585, Test Loss Force: 7.734720291058045, time: 17.871671199798584


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9860075085607618, Training Loss Force: 3.3939979737017967, time: 1.5588324069976807
Validation Loss Energy: 1.8504932175804698, Validation Loss Force: 3.045690065572864, time: 0.13212895393371582
Test Loss Energy: 6.9453140499421595, Test Loss Force: 7.6749205426897555, time: 17.734379768371582


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.063217097226708, Training Loss Force: 3.3937604945835638, time: 1.737454891204834
Validation Loss Energy: 2.023228306528373, Validation Loss Force: 2.9772454668247157, time: 0.16598868370056152
Test Loss Energy: 6.385656033588486, Test Loss Force: 7.718535030427936, time: 17.72392988204956


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.14235854360991, Training Loss Force: 3.412490621530083, time: 1.589810848236084
Validation Loss Energy: 1.7415307946954313, Validation Loss Force: 3.238714154757556, time: 0.13080596923828125
Test Loss Energy: 6.315511095353305, Test Loss Force: 7.59167249283657, time: 17.82715630531311


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.4180256281946693, Training Loss Force: 3.411596006176592, time: 1.573533058166504
Validation Loss Energy: 1.7699014045818096, Validation Loss Force: 2.8991471585894413, time: 0.13213634490966797
Test Loss Energy: 7.1244413658901475, Test Loss Force: 7.697339187069666, time: 17.765756845474243


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2332140645098137, Training Loss Force: 3.3853595835639676, time: 1.5901775360107422
Validation Loss Energy: 1.7731341709096757, Validation Loss Force: 3.15651684154947, time: 0.1298694610595703
Test Loss Energy: 6.452681108953598, Test Loss Force: 7.6463747149187675, time: 17.85238218307495


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9903507865348595, Training Loss Force: 3.391989483160918, time: 1.5651302337646484
Validation Loss Energy: 2.2096851032576437, Validation Loss Force: 3.0147584265045975, time: 0.13833260536193848
Test Loss Energy: 7.036260653520193, Test Loss Force: 7.756728429129043, time: 17.89774203300476


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2436278130668366, Training Loss Force: 3.4060048185597673, time: 1.5711500644683838
Validation Loss Energy: 3.0042473294710765, Validation Loss Force: 3.3454951436872267, time: 0.12777996063232422
Test Loss Energy: 6.584895621877076, Test Loss Force: 7.658807683340476, time: 17.778239727020264


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1822828320048724, Training Loss Force: 3.393148283085546, time: 1.6107487678527832
Validation Loss Energy: 2.3060288099756683, Validation Loss Force: 3.005649699752129, time: 0.1307070255279541
Test Loss Energy: 6.478422923626074, Test Loss Force: 7.565293487669784, time: 17.819424390792847


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3590334658185417, Training Loss Force: 3.4013078207509566, time: 1.5778882503509521
Validation Loss Energy: 1.4107390225664713, Validation Loss Force: 2.9290322526718473, time: 0.12232518196105957
Test Loss Energy: 6.6480645945795045, Test Loss Force: 7.650987643194899, time: 17.8969304561615


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2539339926335638, Training Loss Force: 3.368779975436004, time: 1.5367763042449951
Validation Loss Energy: 1.3388881425584929, Validation Loss Force: 3.01801718945525, time: 0.1247706413269043
Test Loss Energy: 6.354693741955539, Test Loss Force: 7.611664719693957, time: 17.783525943756104


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.920655801568262, Training Loss Force: 3.38012949107879, time: 1.5832982063293457
Validation Loss Energy: 1.5439946492722316, Validation Loss Force: 3.0605813987105037, time: 0.12849020957946777
Test Loss Energy: 6.788210822637184, Test Loss Force: 7.677563863276555, time: 17.808589458465576


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9574645923410612, Training Loss Force: 3.395819446901111, time: 1.6061797142028809
Validation Loss Energy: 1.4635457341979703, Validation Loss Force: 3.0241448216820377, time: 0.12688660621643066
Test Loss Energy: 6.574444511445146, Test Loss Force: 7.68269460340541, time: 17.74138355255127


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.092030885514226, Training Loss Force: 3.382541131530674, time: 1.791430950164795
Validation Loss Energy: 1.5848139674327084, Validation Loss Force: 2.9063167710845974, time: 0.12782526016235352
Test Loss Energy: 6.567373094294634, Test Loss Force: 7.62671216663613, time: 17.75089979171753


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1048415734113, Training Loss Force: 3.3593061801446855, time: 1.6118371486663818
Validation Loss Energy: 1.7647226212531075, Validation Loss Force: 2.925451844139902, time: 0.12853598594665527
Test Loss Energy: 7.032099326251374, Test Loss Force: 7.587085806877063, time: 17.87215781211853


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2175649833203783, Training Loss Force: 3.367495184360408, time: 1.5847485065460205
Validation Loss Energy: 1.9146315063809478, Validation Loss Force: 2.9621456040319147, time: 0.12828922271728516
Test Loss Energy: 6.9437617568748955, Test Loss Force: 7.692394955083763, time: 18.183536052703857

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–ƒâ–ˆâ–ƒâ–†â–‚â–â–‡â–‚â–†â–ƒâ–‚â–ƒâ–â–„â–ƒâ–ƒâ–†â–†
wandb:   test_error_force â–ˆâ–„â–„â–…â–„â–ƒâ–„â–‚â–„â–ƒâ–…â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–„
wandb:          test_loss â–ˆâ–†â–†â–‡â–„â–„â–ƒâ–ƒâ–„â–‚â–„â–„â–â–ƒâ–‚â–ƒâ–„â–„â–‚â–„
wandb: train_error_energy â–ˆâ–â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‡â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–…â–ˆâ–…â–â–â–‚â–‚â–‚â–ƒâ–ƒ
wandb:  valid_error_force â–…â–„â–„â–â–„â–ƒâ–‚â–†â–â–…â–ƒâ–ˆâ–ƒâ–â–ƒâ–„â–ƒâ–â–â–‚
wandb:         valid_loss â–„â–…â–ƒâ–â–‚â–ƒâ–ƒâ–†â–â–„â–ƒâ–ˆâ–‚â–â–‚â–‚â–ƒâ–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1423
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.94376
wandb:   test_error_force 7.69239
wandb:          test_loss 4.07505
wandb: train_error_energy 2.21756
wandb:  train_error_force 3.3675
wandb:         train_loss 1.54392
wandb: valid_error_energy 1.91463
wandb:  valid_error_force 2.96215
wandb:         valid_loss 1.46965
wandb: 
wandb: ğŸš€ View run al_80_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ojotar8j
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241210_235238-ojotar8j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7204034328460693, Uncertainty Bias: 0.022043853998184204
0.0001296997 0.0026097298
0.3789434 5.5064983
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1238 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1668 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1834 steps.
Found uncertainty sample 12 after 3855 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 703 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2211 steps.
Found uncertainty sample 17 after 3201 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3717 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1108 steps.
Found uncertainty sample 22 after 2196 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3995 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 186 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1150 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3901 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 575 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2838 steps.
Found uncertainty sample 47 after 2549 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2190 steps.
Found uncertainty sample 50 after 2516 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 304 steps.
Found uncertainty sample 54 after 3221 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3962 steps.
Found uncertainty sample 60 after 2006 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1630 steps.
Found uncertainty sample 65 after 2719 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2746 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3456 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3476 steps.
Found uncertainty sample 98 after 3770 steps.
Found uncertainty sample 99 after 3234 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_023613-iqv16q5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/iqv16q5f
Training model 21. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.170418967962158, Training Loss Force: 3.898486154816245, time: 1.6381065845489502
Validation Loss Energy: 1.4027240466588005, Validation Loss Force: 2.882058414985213, time: 0.1334240436553955
Test Loss Energy: 6.314678604199296, Test Loss Force: 7.571773033909123, time: 17.724979162216187


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.125570652268822, Training Loss Force: 3.457187463677856, time: 1.6249573230743408
Validation Loss Energy: 2.281875999051454, Validation Loss Force: 2.934013584135398, time: 0.13447856903076172
Test Loss Energy: 6.511398216618247, Test Loss Force: 7.601317869717831, time: 17.89383101463318


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.989006208040594, Training Loss Force: 3.4362463889488, time: 1.6733074188232422
Validation Loss Energy: 1.6641155797325766, Validation Loss Force: 3.113823261520432, time: 0.12432360649108887
Test Loss Energy: 6.349540287242186, Test Loss Force: 7.5775572461935, time: 18.2057044506073


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3158075760218764, Training Loss Force: 3.408470029765934, time: 1.6385557651519775
Validation Loss Energy: 1.4527860827303072, Validation Loss Force: 2.993270965257139, time: 0.13419628143310547
Test Loss Energy: 6.405650214338482, Test Loss Force: 7.570863436277043, time: 18.14292621612549


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1919617162827696, Training Loss Force: 3.408783722186211, time: 1.6926722526550293
Validation Loss Energy: 1.571460498751419, Validation Loss Force: 3.025151397556204, time: 0.1384882926940918
Test Loss Energy: 6.50859622736077, Test Loss Force: 7.516617989053829, time: 18.34683084487915


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2795249468741754, Training Loss Force: 3.41990404200299, time: 1.6301937103271484
Validation Loss Energy: 1.6210220859174531, Validation Loss Force: 3.128680637613318, time: 0.12938189506530762
Test Loss Energy: 6.521690021848854, Test Loss Force: 7.547705094320813, time: 18.21951913833618


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.500609709856648, Training Loss Force: 3.448363796997877, time: 1.611452341079712
Validation Loss Energy: 1.6187542563334651, Validation Loss Force: 3.168189603517296, time: 0.13070011138916016
Test Loss Energy: 6.964480892405295, Test Loss Force: 7.569273548264136, time: 18.118577480316162


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1163274720772822, Training Loss Force: 3.420372426551449, time: 1.6799941062927246
Validation Loss Energy: 3.6420152952262894, Validation Loss Force: 3.1395611427599337, time: 0.13120722770690918
Test Loss Energy: 6.5937206436556846, Test Loss Force: 7.522780032407214, time: 18.22092580795288


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.181313665622918, Training Loss Force: 3.4059788460863634, time: 1.6559405326843262
Validation Loss Energy: 3.132279527684376, Validation Loss Force: 2.9984652797587694, time: 0.12636494636535645
Test Loss Energy: 7.634413035653776, Test Loss Force: 7.5901175836982935, time: 18.106295585632324


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.132441428248242, Training Loss Force: 3.3841303607032183, time: 1.9050121307373047
Validation Loss Energy: 1.4744419931866601, Validation Loss Force: 3.120564458578823, time: 0.131819486618042
Test Loss Energy: 6.176640491034558, Test Loss Force: 7.513882858830482, time: 18.09896159172058


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.001697395753657, Training Loss Force: 3.3908923918486535, time: 1.6743838787078857
Validation Loss Energy: 1.4355899012631692, Validation Loss Force: 2.942684877350691, time: 0.12994837760925293
Test Loss Energy: 6.326489637877708, Test Loss Force: 7.4831387992818446, time: 18.823959827423096


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.092559934442809, Training Loss Force: 3.3771747526198324, time: 1.6582119464874268
Validation Loss Energy: 1.7349665082734802, Validation Loss Force: 3.0622951717921367, time: 0.12912964820861816
Test Loss Energy: 6.318200996926464, Test Loss Force: 7.459445881167561, time: 18.121502161026


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1662855337592246, Training Loss Force: 3.3844106721141394, time: 1.8742656707763672
Validation Loss Energy: 1.8250143562249694, Validation Loss Force: 3.00611663695114, time: 0.1349623203277588
Test Loss Energy: 6.63994696120072, Test Loss Force: 7.468913334908961, time: 18.159097909927368


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.119825507547135, Training Loss Force: 3.392353692003239, time: 1.6633784770965576
Validation Loss Energy: 1.5288698475350868, Validation Loss Force: 3.0475603750640845, time: 0.13038158416748047
Test Loss Energy: 6.307390768960239, Test Loss Force: 7.462507358089114, time: 18.239344596862793


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.220059154692797, Training Loss Force: 3.3885185015620163, time: 1.6719374656677246
Validation Loss Energy: 1.8828694784002298, Validation Loss Force: 3.096044132229255, time: 0.130964994430542
Test Loss Energy: 6.658496958834125, Test Loss Force: 7.446554582700268, time: 18.108809232711792


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1486055382240044, Training Loss Force: 3.3791041226816927, time: 1.6819937229156494
Validation Loss Energy: 2.031471796647052, Validation Loss Force: 3.0692868716396964, time: 0.13102960586547852
Test Loss Energy: 6.255884543943107, Test Loss Force: 7.485622709744686, time: 18.25589156150818


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0867316010122683, Training Loss Force: 3.411276512956139, time: 1.6564252376556396
Validation Loss Energy: 1.5982565037723688, Validation Loss Force: 3.036619749248069, time: 0.13645625114440918
Test Loss Energy: 6.230152382152975, Test Loss Force: 7.513349017130867, time: 18.273822784423828


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.307220077804798, Training Loss Force: 3.364417132051145, time: 1.6786625385284424
Validation Loss Energy: 1.598271645274292, Validation Loss Force: 3.065371346043129, time: 0.12552118301391602
Test Loss Energy: 6.408753410831011, Test Loss Force: 7.426055278741443, time: 18.236425399780273


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0924888352163884, Training Loss Force: 3.3778326818584468, time: 1.6304285526275635
Validation Loss Energy: 2.3072792085646254, Validation Loss Force: 3.174573527931046, time: 0.13065171241760254
Test Loss Energy: 6.297924655896944, Test Loss Force: 7.436120877767545, time: 18.254809141159058


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.15442339652342, Training Loss Force: 3.3810555224671, time: 1.647775411605835
Validation Loss Energy: 1.5645345419691945, Validation Loss Force: 2.9790587730145788, time: 0.13678288459777832
Test Loss Energy: 6.33337553315803, Test Loss Force: 7.492880287627651, time: 18.119273900985718

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–…â–ƒâ–ˆâ–â–‚â–‚â–ƒâ–‚â–ƒâ–â–â–‚â–‚â–‚
wandb:   test_error_force â–‡â–ˆâ–‡â–‡â–…â–†â–‡â–…â–ˆâ–…â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„â–â–â–„
wandb:          test_loss â–„â–‡â–„â–†â–ˆâ–‡â–…â–…â–ˆâ–…â–‚â–‡â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–„â–‚â–â–‚â–‚â–‚â–ˆâ–†â–â–â–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–„â–‚
wandb:  valid_error_force â–â–‚â–‡â–„â–„â–‡â–ˆâ–‡â–„â–‡â–‚â–…â–„â–…â–†â–…â–…â–…â–ˆâ–ƒ
wandb:         valid_loss â–â–‚â–„â–„â–†â–…â–…â–ˆâ–„â–„â–ƒâ–†â–ƒâ–‚â–…â–…â–ƒâ–„â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1450
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.33338
wandb:   test_error_force 7.49288
wandb:          test_loss 3.9385
wandb: train_error_energy 2.15442
wandb:  train_error_force 3.38106
wandb:         train_loss 1.54875
wandb: valid_error_energy 1.56453
wandb:  valid_error_force 2.97906
wandb:         valid_loss 1.48234
wandb: 
wandb: ğŸš€ View run al_80_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/iqv16q5f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_023613-iqv16q5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7134295701980591, Uncertainty Bias: 0.024444207549095154
2.670288e-05 0.0051403046
0.5141471 6.0854273
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 678 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 726 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1702 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1837 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 686 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1867 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1546 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1118 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2903 steps.
Found uncertainty sample 39 after 970 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2270 steps.
Found uncertainty sample 45 after 1803 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2492 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2528 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1190 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 776 steps.
Found uncertainty sample 60 after 2455 steps.
Found uncertainty sample 61 after 3420 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1566 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1426 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3092 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3943 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3567 steps.
Found uncertainty sample 81 after 2531 steps.
Found uncertainty sample 82 after 1329 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1832 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3502 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 446 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3056 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1943 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_051553-7w9lny2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7w9lny2t
Training model 22. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.244997830679224, Training Loss Force: 3.6825303111262393, time: 1.6346523761749268
Validation Loss Energy: 1.248453295631381, Validation Loss Force: 2.9685654895127316, time: 0.1330585479736328
Test Loss Energy: 6.300599294724249, Test Loss Force: 7.411898338175154, time: 17.43897247314453


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9184737679064532, Training Loss Force: 3.4409460418829085, time: 1.6635463237762451
Validation Loss Energy: 1.370496918499526, Validation Loss Force: 2.9292172907321135, time: 0.12420892715454102
Test Loss Energy: 6.229247515365894, Test Loss Force: 7.341260331176009, time: 17.672741889953613


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.047173225010195, Training Loss Force: 3.439740961202788, time: 1.632331132888794
Validation Loss Energy: 1.7974421822286015, Validation Loss Force: 2.81901376569496, time: 0.1277296543121338
Test Loss Energy: 6.494502841931441, Test Loss Force: 7.39005798771755, time: 18.175477504730225


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0877818922365714, Training Loss Force: 3.4314587965329286, time: 1.665356159210205
Validation Loss Energy: 1.6144441610103137, Validation Loss Force: 3.0220215600410425, time: 0.1391153335571289
Test Loss Energy: 6.328467205697555, Test Loss Force: 7.421089539947144, time: 17.51699423789978


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.184216016840767, Training Loss Force: 3.436604031438448, time: 1.6497905254364014
Validation Loss Energy: 2.1340812461296252, Validation Loss Force: 3.1030211359131834, time: 0.13672614097595215
Test Loss Energy: 6.717647259412817, Test Loss Force: 7.352835657322485, time: 17.673015832901


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2932448531673995, Training Loss Force: 3.442845386009465, time: 1.647061824798584
Validation Loss Energy: 1.7819165760287865, Validation Loss Force: 3.1000546262165605, time: 0.12617206573486328
Test Loss Energy: 6.218324031576692, Test Loss Force: 7.3100283627253955, time: 17.524066925048828


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9724237209692526, Training Loss Force: 3.4140997846996, time: 1.7366321086883545
Validation Loss Energy: 1.542325966692649, Validation Loss Force: 3.0646438859433838, time: 0.16604351997375488
Test Loss Energy: 6.507519534604681, Test Loss Force: 7.407393841612441, time: 17.561153650283813


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.160133296952286, Training Loss Force: 3.4432431346934305, time: 1.6448702812194824
Validation Loss Energy: 3.0430396347288857, Validation Loss Force: 2.9957978147251274, time: 0.1232142448425293
Test Loss Energy: 7.362452077888315, Test Loss Force: 7.425380421021455, time: 17.688111305236816


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.30494697903664, Training Loss Force: 3.4356539779950364, time: 1.646296739578247
Validation Loss Energy: 1.7695002661154207, Validation Loss Force: 2.983747962558672, time: 0.13117003440856934
Test Loss Energy: 6.114860094784204, Test Loss Force: 7.2826292787243245, time: 17.521777868270874


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.3075464778667194, Training Loss Force: 3.429180355816609, time: 1.6611740589141846
Validation Loss Energy: 3.2022152303682296, Validation Loss Force: 3.086937743502819, time: 0.13113164901733398
Test Loss Energy: 6.307279065992249, Test Loss Force: 7.382227336396234, time: 17.624464750289917


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.32664215861817, Training Loss Force: 3.4236246753481647, time: 1.6666123867034912
Validation Loss Energy: 1.859092588661628, Validation Loss Force: 2.9646144481873895, time: 0.1266031265258789
Test Loss Energy: 6.1001732622725715, Test Loss Force: 7.320026554788054, time: 17.707102298736572


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1248634944043774, Training Loss Force: 3.413340871398582, time: 1.6447138786315918
Validation Loss Energy: 1.918057438192906, Validation Loss Force: 3.0652100222469048, time: 0.12462115287780762
Test Loss Energy: 6.46249848667492, Test Loss Force: 7.348874753269525, time: 17.568742752075195


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0933168017006953, Training Loss Force: 3.400502649645686, time: 1.6248207092285156
Validation Loss Energy: 1.5890916643951272, Validation Loss Force: 3.0975464809568303, time: 0.1391596794128418
Test Loss Energy: 6.0958927732022765, Test Loss Force: 7.324258243175374, time: 17.662995100021362


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.225936798010019, Training Loss Force: 3.4504650010044378, time: 1.6298787593841553
Validation Loss Energy: 1.5067124304948178, Validation Loss Force: 3.01060776228993, time: 0.12188601493835449
Test Loss Energy: 6.06978734797515, Test Loss Force: 7.326736152063538, time: 17.6120924949646


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0685640360042163, Training Loss Force: 3.414965754483397, time: 1.6313495635986328
Validation Loss Energy: 2.666999989130664, Validation Loss Force: 2.9057460700635844, time: 0.12653064727783203
Test Loss Energy: 6.365121123550842, Test Loss Force: 7.323488801198068, time: 17.565809726715088


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.260783107530579, Training Loss Force: 3.4418520873753295, time: 1.7023570537567139
Validation Loss Energy: 1.6954187979381103, Validation Loss Force: 3.117037156638181, time: 0.12841391563415527
Test Loss Energy: 6.060754483784634, Test Loss Force: 7.386494588893321, time: 17.666157960891724


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.012624704677643, Training Loss Force: 3.4190654772088798, time: 1.721318006515503
Validation Loss Energy: 1.3721568056478446, Validation Loss Force: 3.000409515406438, time: 0.12897634506225586
Test Loss Energy: 6.322235701228709, Test Loss Force: 7.296778245170414, time: 17.52865695953369


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.017864592920747, Training Loss Force: 3.4323102075446945, time: 1.6327488422393799
Validation Loss Energy: 1.4908602243252134, Validation Loss Force: 3.1060126958887233, time: 0.13066577911376953
Test Loss Energy: 6.020390890965348, Test Loss Force: 7.385649488370294, time: 17.631362915039062


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.146643603314512, Training Loss Force: 3.4012009495625986, time: 1.6827969551086426
Validation Loss Energy: 2.8833006861503447, Validation Loss Force: 3.1387846954480834, time: 0.12833333015441895
Test Loss Energy: 6.173380414219362, Test Loss Force: 7.270558955569031, time: 18.214213848114014


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.343749138588567, Training Loss Force: 3.4112920973245413, time: 1.650968074798584
Validation Loss Energy: 1.778326258719847, Validation Loss Force: 2.976739228521449, time: 0.13077020645141602
Test Loss Energy: 6.775382587336278, Test Loss Force: 7.292255398804787, time: 17.475056648254395

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–ƒâ–…â–‚â–„â–ˆâ–â–‚â–â–ƒâ–â–â–ƒâ–â–ƒâ–â–‚â–…
wandb:   test_error_force â–‡â–„â–†â–ˆâ–…â–ƒâ–‡â–ˆâ–‚â–†â–ƒâ–…â–ƒâ–„â–ƒâ–†â–‚â–†â–â–‚
wandb:          test_loss â–ˆâ–†â–…â–…â–„â–ƒâ–…â–‡â–â–†â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–‚â–…
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–â–
wandb: valid_error_energy â–â–â–ƒâ–‚â–„â–ƒâ–‚â–‡â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–‚â–†â–ƒâ–â–‚â–‡â–ƒ
wandb:  valid_error_force â–„â–ƒâ–â–…â–‡â–‡â–†â–…â–…â–‡â–„â–†â–‡â–…â–ƒâ–ˆâ–…â–‡â–ˆâ–„
wandb:         valid_loss â–…â–„â–â–„â–†â–†â–†â–†â–„â–ˆâ–ƒâ–…â–…â–‡â–„â–†â–ƒâ–…â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1477
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.77538
wandb:   test_error_force 7.29226
wandb:          test_loss 3.91682
wandb: train_error_energy 2.34375
wandb:  train_error_force 3.41129
wandb:         train_loss 1.57073
wandb: valid_error_energy 1.77833
wandb:  valid_error_force 2.97674
wandb:         valid_loss 1.498
wandb: 
wandb: ğŸš€ View run al_80_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/7w9lny2t
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_051553-7w9lny2t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7289799451828003, Uncertainty Bias: 0.020298853516578674
0.00011444092 0.01270771
0.40364873 5.3387046
(48745, 22, 3)
Found uncertainty sample 0 after 660 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2286 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3966 steps.
Found uncertainty sample 8 after 3060 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3647 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2522 steps.
Found uncertainty sample 13 after 1657 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3766 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2749 steps.
Found uncertainty sample 25 after 2545 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1705 steps.
Found uncertainty sample 30 after 785 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3348 steps.
Found uncertainty sample 36 after 2171 steps.
Found uncertainty sample 37 after 2699 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1575 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2771 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3054 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 456 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3208 steps.
Found uncertainty sample 55 after 1603 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2545 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2466 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 114 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3697 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3148 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2475 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1185 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3869 steps.
Found uncertainty sample 98 after 1259 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_075933-ck3anhs9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ck3anhs9
Training model 23. Added 30 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.689656403121211, Training Loss Force: 3.7828817379425272, time: 1.7145709991455078
Validation Loss Energy: 2.908090887504777, Validation Loss Force: 3.0777102227609987, time: 0.1293497085571289
Test Loss Energy: 7.331019131297688, Test Loss Force: 7.25395770933689, time: 17.8012912273407


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0008177229600568, Training Loss Force: 3.457662435298731, time: 1.7211828231811523
Validation Loss Energy: 1.4922588092307856, Validation Loss Force: 3.0274330882945257, time: 0.12743401527404785
Test Loss Energy: 6.1798655703222085, Test Loss Force: 7.23695737937328, time: 17.891369819641113


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.066054348642209, Training Loss Force: 3.4526202583066463, time: 1.657719373703003
Validation Loss Energy: 1.3097516064774093, Validation Loss Force: 2.8847600597327547, time: 0.13449907302856445
Test Loss Energy: 6.10957387330114, Test Loss Force: 7.24617776595888, time: 17.922264575958252


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.086991059076602, Training Loss Force: 3.463354266105807, time: 1.6390886306762695
Validation Loss Energy: 1.562646307611727, Validation Loss Force: 2.9998875789283828, time: 0.12629318237304688
Test Loss Energy: 6.242719534965765, Test Loss Force: 7.223229280929134, time: 17.85413432121277


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9941561585471834, Training Loss Force: 3.465805772862567, time: 1.6621289253234863
Validation Loss Energy: 1.6256818274669973, Validation Loss Force: 3.174388712539926, time: 0.132216215133667
Test Loss Energy: 6.3388038082297395, Test Loss Force: 7.252944865501138, time: 18.54523229598999


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1202037374574987, Training Loss Force: 3.4662958108010584, time: 1.6659858226776123
Validation Loss Energy: 2.273985383861784, Validation Loss Force: 2.9576538106856862, time: 0.12795138359069824
Test Loss Energy: 6.977284202751542, Test Loss Force: 7.258373930990024, time: 17.8769371509552


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4324652355417515, Training Loss Force: 3.456731896200259, time: 1.8166823387145996
Validation Loss Energy: 1.7540116786611162, Validation Loss Force: 3.0681931207948994, time: 0.12886500358581543
Test Loss Energy: 6.168751551692517, Test Loss Force: 7.243388819750641, time: 17.864311933517456


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2814240020046066, Training Loss Force: 3.452289239301838, time: 1.6526668071746826
Validation Loss Energy: 1.6694978269933702, Validation Loss Force: 2.8816225401320597, time: 0.12549829483032227
Test Loss Energy: 6.871271347763673, Test Loss Force: 7.280214675490411, time: 17.96542978286743


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.023710572366142, Training Loss Force: 3.4405286746258943, time: 1.6404199600219727
Validation Loss Energy: 1.7115366483988068, Validation Loss Force: 3.1895951225190533, time: 0.1252305507659912
Test Loss Energy: 6.054103165203416, Test Loss Force: 7.170432024867139, time: 17.86792016029358


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1026906504192904, Training Loss Force: 3.435646151411439, time: 1.698075532913208
Validation Loss Energy: 1.5122599539291763, Validation Loss Force: 2.9265930235127815, time: 0.12693071365356445
Test Loss Energy: 6.092028605486443, Test Loss Force: 7.214909011632712, time: 17.91359305381775


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.341684396294179, Training Loss Force: 3.4718913206207755, time: 1.6588332653045654
Validation Loss Energy: 1.6154213445572179, Validation Loss Force: 3.187888140846371, time: 0.12714171409606934
Test Loss Energy: 6.016743132011601, Test Loss Force: 7.229393760819247, time: 17.999857664108276


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0968348759002953, Training Loss Force: 3.421216342717507, time: 1.691286325454712
Validation Loss Energy: 1.8696122027899813, Validation Loss Force: 3.049220596216122, time: 0.1272425651550293
Test Loss Energy: 5.916996175132066, Test Loss Force: 7.160766174082524, time: 17.934577465057373


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0417403678951165, Training Loss Force: 3.4285911069295048, time: 1.6564791202545166
Validation Loss Energy: 2.0325973335124305, Validation Loss Force: 3.0359450617359074, time: 0.12314701080322266
Test Loss Energy: 5.990921972511523, Test Loss Force: 7.235750533586879, time: 18.068938493728638


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.190314005645298, Training Loss Force: 3.4391882016297677, time: 1.6902825832366943
Validation Loss Energy: 2.097947387805047, Validation Loss Force: 3.114457645917181, time: 0.12378072738647461
Test Loss Energy: 6.098236015055245, Test Loss Force: 7.163640800113856, time: 17.9836208820343


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.129321103299064, Training Loss Force: 3.4364771574016832, time: 1.6563498973846436
Validation Loss Energy: 2.048673099504547, Validation Loss Force: 3.045064699276526, time: 0.1268482208251953
Test Loss Energy: 6.096553226210398, Test Loss Force: 7.1934028840657245, time: 17.86398696899414


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.113338253114548, Training Loss Force: 3.4289033080226607, time: 1.6844768524169922
Validation Loss Energy: 1.3681750916476505, Validation Loss Force: 2.9719488358505317, time: 0.12993383407592773
Test Loss Energy: 6.0649213089994864, Test Loss Force: 7.182754486438887, time: 18.06172227859497


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.25028275546776, Training Loss Force: 3.4114666888855143, time: 1.6427528858184814
Validation Loss Energy: 1.5799541019882613, Validation Loss Force: 3.0448193178777134, time: 0.12958717346191406
Test Loss Energy: 6.141380960015669, Test Loss Force: 7.203776582578138, time: 18.004467248916626


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1949707328704995, Training Loss Force: 3.436293526420913, time: 1.6971681118011475
Validation Loss Energy: 1.5101520564592508, Validation Loss Force: 3.05277628847287, time: 0.12865066528320312
Test Loss Energy: 6.533714468165243, Test Loss Force: 7.124464840580839, time: 17.93445634841919


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.949004083740316, Training Loss Force: 3.413808637684838, time: 1.6623475551605225
Validation Loss Energy: 2.0057004593683754, Validation Loss Force: 3.0851678577964123, time: 0.1320021152496338
Test Loss Energy: 5.916070776151275, Test Loss Force: 7.128434635078337, time: 18.034283876419067


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0047869970983374, Training Loss Force: 3.4385129503382794, time: 1.6626594066619873
Validation Loss Energy: 1.7573074603572798, Validation Loss Force: 3.121782236137902, time: 0.1297314167022705
Test Loss Energy: 6.294258367605996, Test Loss Force: 7.181184363518651, time: 18.533946752548218

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–‚â–ƒâ–ƒâ–†â–‚â–†â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–„â–â–ƒ
wandb:   test_error_force â–‡â–†â–†â–…â–‡â–‡â–†â–ˆâ–ƒâ–…â–†â–ƒâ–†â–ƒâ–„â–„â–…â–â–â–„
wandb:          test_loss â–‡â–„â–…â–ƒâ–„â–ˆâ–„â–†â–â–„â–‚â–„â–ƒâ–„â–‚â–ƒâ–…â–‚â–â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–
wandb: valid_error_energy â–ˆâ–‚â–â–‚â–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–„â–„â–â–‚â–‚â–„â–ƒ
wandb:  valid_error_force â–…â–„â–â–„â–ˆâ–ƒâ–…â–â–ˆâ–‚â–ˆâ–…â–…â–†â–…â–ƒâ–…â–…â–†â–†
wandb:         valid_loss â–‡â–ƒâ–â–„â–†â–†â–„â–â–‡â–„â–†â–…â–„â–ˆâ–…â–ƒâ–†â–„â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1504
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.29426
wandb:   test_error_force 7.18118
wandb:          test_loss 3.80717
wandb: train_error_energy 2.00479
wandb:  train_error_force 3.43851
wandb:         train_loss 1.55078
wandb: valid_error_energy 1.75731
wandb:  valid_error_force 3.12178
wandb:         valid_loss 1.55443
wandb: 
wandb: ğŸš€ View run al_80_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ck3anhs9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_075933-ck3anhs9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7333071827888489, Uncertainty Bias: 0.022766754031181335
5.722046e-05 0.008314133
0.75982517 5.8414907
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3363 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1637 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1860 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3761 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3017 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2754 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2452 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1725 steps.
Found uncertainty sample 43 after 2018 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2664 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1769 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1839 steps.
Found uncertainty sample 62 after 739 steps.
Found uncertainty sample 63 after 811 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1506 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2689 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 122 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1766 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1908 steps.
Found uncertainty sample 85 after 3149 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1008 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2988 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2383 steps.
Found uncertainty sample 97 after 1740 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2950 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_104618-hr6zl6ul
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/hr6zl6ul
Training model 24. Added 25 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.642935876740193, Training Loss Force: 3.6999887382189676, time: 1.6995043754577637
Validation Loss Energy: 1.4821539163867232, Validation Loss Force: 3.062896712489861, time: 0.1258411407470703
Test Loss Energy: 6.110483146838862, Test Loss Force: 7.183747390310912, time: 16.891783952713013


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.031318602594124, Training Loss Force: 3.4565680061816066, time: 1.7115352153778076
Validation Loss Energy: 1.6218999590252734, Validation Loss Force: 3.102633802933842, time: 0.1275465488433838
Test Loss Energy: 5.895427154606523, Test Loss Force: 7.088917031127045, time: 17.71906352043152


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1137790875379943, Training Loss Force: 3.459155328878477, time: 1.7109475135803223
Validation Loss Energy: 2.487406523486326, Validation Loss Force: 2.9679137369226014, time: 0.12408900260925293
Test Loss Energy: 6.046491918768295, Test Loss Force: 7.0634097395265485, time: 16.912882328033447


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.103980705731712, Training Loss Force: 3.4508101299884544, time: 1.8710553646087646
Validation Loss Energy: 1.86501080055667, Validation Loss Force: 3.1287709299519917, time: 0.1228630542755127
Test Loss Energy: 6.599360107005526, Test Loss Force: 7.121598515095684, time: 16.984293460845947


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.047700142032475, Training Loss Force: 3.442965983066175, time: 1.6880624294281006
Validation Loss Energy: 1.442421223658374, Validation Loss Force: 3.21769897476861, time: 0.12361812591552734
Test Loss Energy: 6.3691506563330265, Test Loss Force: 7.114704037143883, time: 17.143603563308716


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.168794428913778, Training Loss Force: 3.454032959705684, time: 1.6927788257598877
Validation Loss Energy: 1.5193781855189092, Validation Loss Force: 2.9893543263148423, time: 0.12385749816894531
Test Loss Energy: 6.266574040931569, Test Loss Force: 7.0766283359906, time: 17.00806760787964


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4765176543299168, Training Loss Force: 3.452956957447393, time: 1.6695771217346191
Validation Loss Energy: 2.552178974014406, Validation Loss Force: 2.9861463319294606, time: 0.12326335906982422
Test Loss Energy: 6.102352174295847, Test Loss Force: 7.096889031889552, time: 17.118356704711914


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.36910126971446, Training Loss Force: 3.460801906906385, time: 1.6896188259124756
Validation Loss Energy: 1.3246023024959173, Validation Loss Force: 2.919132716447617, time: 0.12706637382507324
Test Loss Energy: 6.142412232929215, Test Loss Force: 7.082060824288976, time: 17.060132265090942


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.277351638023163, Training Loss Force: 3.446622057357272, time: 1.7104465961456299
Validation Loss Energy: 1.7110786179656334, Validation Loss Force: 3.0594117176869453, time: 0.125715970993042
Test Loss Energy: 6.0833108659355055, Test Loss Force: 7.113328167988616, time: 16.952626943588257


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.309480253641127, Training Loss Force: 3.460861842018165, time: 1.654332160949707
Validation Loss Energy: 1.542595340691935, Validation Loss Force: 2.9511626710781727, time: 0.12965011596679688
Test Loss Energy: 5.96716571143716, Test Loss Force: 7.052920145804005, time: 17.10283374786377


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1410810502063082, Training Loss Force: 3.4144438839375173, time: 1.7035861015319824
Validation Loss Energy: 1.3517432776911957, Validation Loss Force: 3.033958518950513, time: 0.1273949146270752
Test Loss Energy: 6.165744527286503, Test Loss Force: 7.117506970705066, time: 16.977214336395264


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.171768908310249, Training Loss Force: 3.4285246642724556, time: 1.6959435939788818
Validation Loss Energy: 1.4537917679278902, Validation Loss Force: 2.9882764963139783, time: 0.12384963035583496
Test Loss Energy: 6.019501457131947, Test Loss Force: 7.054676091372649, time: 17.152637481689453


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9963828272065622, Training Loss Force: 3.4310010838178324, time: 1.6664671897888184
Validation Loss Energy: 2.1057011728045447, Validation Loss Force: 3.05992463606459, time: 0.12252664566040039
Test Loss Energy: 5.921604067121756, Test Loss Force: 7.024326384710484, time: 17.06254005432129


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1516041876100016, Training Loss Force: 3.4466815239360558, time: 1.7102622985839844
Validation Loss Energy: 1.4956182186353983, Validation Loss Force: 2.9445725550352937, time: 0.12874412536621094
Test Loss Energy: 6.1327301214679135, Test Loss Force: 7.093222076756974, time: 17.017364263534546


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9176420048312428, Training Loss Force: 3.430646241978034, time: 1.7296085357666016
Validation Loss Energy: 1.5757060756895376, Validation Loss Force: 2.988061509253585, time: 0.1261906623840332
Test Loss Energy: 5.991780556758852, Test Loss Force: 7.060036362587709, time: 17.135439157485962


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1711724194187734, Training Loss Force: 3.4277326950655578, time: 1.7234206199645996
Validation Loss Energy: 1.6821237242403406, Validation Loss Force: 2.9686220474757974, time: 0.13552355766296387
Test Loss Energy: 6.372030041188722, Test Loss Force: 7.037685425949457, time: 17.114317178726196


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3644240834290144, Training Loss Force: 3.4456822358374786, time: 1.664743423461914
Validation Loss Energy: 1.8628157837834003, Validation Loss Force: 3.118992303074, time: 0.1213371753692627
Test Loss Energy: 6.154726002243622, Test Loss Force: 7.073970265613043, time: 17.467562913894653


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.05121098501208, Training Loss Force: 3.4254141896951094, time: 1.6936745643615723
Validation Loss Energy: 1.5316084553608524, Validation Loss Force: 2.8931160534374145, time: 0.12257599830627441
Test Loss Energy: 6.226026940756669, Test Loss Force: 6.9858918621378985, time: 17.087417364120483


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.964617095031823, Training Loss Force: 3.407893217444992, time: 1.7136437892913818
Validation Loss Energy: 1.422016546800276, Validation Loss Force: 2.876492577013602, time: 0.12199926376342773
Test Loss Energy: 5.82330279491829, Test Loss Force: 7.014191802549815, time: 16.998257160186768


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.158913332478195, Training Loss Force: 3.423297431848752, time: 1.6674718856811523
Validation Loss Energy: 1.8645828304581966, Validation Loss Force: 3.1825700222996045, time: 0.1320490837097168
Test Loss Energy: 5.750698278944946, Test Loss Force: 7.0232985346064245, time: 17.112030267715454

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–ƒâ–ˆâ–†â–…â–„â–„â–„â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–†â–„â–…â–‚â–
wandb:   test_error_force â–ˆâ–…â–„â–†â–†â–„â–…â–„â–†â–ƒâ–†â–ƒâ–‚â–…â–„â–ƒâ–„â–â–‚â–‚
wandb:          test_loss â–†â–ƒâ–ƒâ–…â–„â–„â–ˆâ–†â–„â–„â–„â–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–ƒâ–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–ˆâ–„â–‚â–‚â–ˆâ–â–ƒâ–‚â–â–‚â–…â–‚â–‚â–ƒâ–„â–‚â–‚â–„
wandb:  valid_error_force â–…â–†â–ƒâ–†â–ˆâ–ƒâ–ƒâ–‚â–…â–ƒâ–„â–ƒâ–…â–‚â–ƒâ–ƒâ–†â–â–â–‡
wandb:         valid_loss â–…â–†â–„â–†â–†â–„â–ˆâ–„â–…â–‚â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–…â–â–‚â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1526
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.7507
wandb:   test_error_force 7.0233
wandb:          test_loss 3.71475
wandb: train_error_energy 2.15891
wandb:  train_error_force 3.4233
wandb:         train_loss 1.5559
wandb: valid_error_energy 1.86458
wandb:  valid_error_force 3.18257
wandb:         valid_loss 1.59007
wandb: 
wandb: ğŸš€ View run al_80_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/hr6zl6ul
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_104618-hr6zl6ul/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7455867528915405, Uncertainty Bias: 0.01674853265285492
0.0002861023 0.033637285
0.3262109 6.207613
(48745, 22, 3)
Found uncertainty sample 0 after 2770 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2317 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2764 steps.
Found uncertainty sample 9 after 1586 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2876 steps.
Found uncertainty sample 16 after 97 steps.
Found uncertainty sample 17 after 191 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2691 steps.
Found uncertainty sample 26 after 3641 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2117 steps.
Found uncertainty sample 33 after 3819 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2599 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1407 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1352 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1118 steps.
Found uncertainty sample 51 after 1629 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 742 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1144 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 770 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3072 steps.
Found uncertainty sample 67 after 280 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2130 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2707 steps.
Found uncertainty sample 81 after 3029 steps.
Found uncertainty sample 82 after 373 steps.
Found uncertainty sample 83 after 307 steps.
Found uncertainty sample 84 after 2393 steps.
Found uncertainty sample 85 after 2426 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2261 steps.
Found uncertainty sample 88 after 2658 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2035 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3316 steps.
Found uncertainty sample 93 after 1914 steps.
Found uncertainty sample 94 after 2066 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_132044-um6w8nbd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/um6w8nbd
Training model 25. Added 34 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8789954439662093, Training Loss Force: 3.701381797862339, time: 1.6445062160491943
Validation Loss Energy: 1.7447674577333512, Validation Loss Force: 2.977486283506037, time: 0.12411761283874512
Test Loss Energy: 5.926283493031832, Test Loss Force: 7.020624362101939, time: 17.063920497894287


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0399382467448293, Training Loss Force: 3.4702687698091412, time: 1.7089934349060059
Validation Loss Energy: 2.577918302603356, Validation Loss Force: 3.031969304135367, time: 0.13375544548034668
Test Loss Energy: 5.93393427198391, Test Loss Force: 6.96250596863583, time: 17.795472383499146


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.161135415576071, Training Loss Force: 3.4787585172343443, time: 1.7217915058135986
Validation Loss Energy: 1.5466260419042333, Validation Loss Force: 3.1088262318820936, time: 0.13094735145568848
Test Loss Energy: 5.977225500080941, Test Loss Force: 7.014464790259494, time: 17.113616466522217


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9743185014902136, Training Loss Force: 3.4600608481784714, time: 1.9855751991271973
Validation Loss Energy: 1.852365920765009, Validation Loss Force: 3.0937945058479466, time: 0.1265575885772705
Test Loss Energy: 6.147796191011851, Test Loss Force: 7.05155993110576, time: 17.124415636062622


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.156556206412993, Training Loss Force: 3.4585558183326093, time: 1.7143399715423584
Validation Loss Energy: 1.47286694298294, Validation Loss Force: 3.000979659754586, time: 0.12662053108215332
Test Loss Energy: 6.057579471246411, Test Loss Force: 6.996636753613994, time: 17.29918336868286


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9971721083840974, Training Loss Force: 3.467512989193529, time: 1.681126594543457
Validation Loss Energy: 1.8849244919479973, Validation Loss Force: 3.0158246777098725, time: 0.1210334300994873
Test Loss Energy: 6.362824115273732, Test Loss Force: 7.06741960747547, time: 17.087650775909424


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.138050241858959, Training Loss Force: 3.470782767450504, time: 1.7450857162475586
Validation Loss Energy: 1.830338152834957, Validation Loss Force: 3.1749413773601187, time: 0.12717247009277344
Test Loss Energy: 5.915420349083758, Test Loss Force: 6.973934242213042, time: 17.27738642692566


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.271617761010207, Training Loss Force: 3.465457216752958, time: 1.6663777828216553
Validation Loss Energy: 1.4825272768771578, Validation Loss Force: 3.0038692372612905, time: 0.12837481498718262
Test Loss Energy: 5.831985786424394, Test Loss Force: 6.977120439504072, time: 17.241112232208252


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3938117650765482, Training Loss Force: 3.4690877053935303, time: 1.7450473308563232
Validation Loss Energy: 1.9250567644587138, Validation Loss Force: 3.0479738716680727, time: 0.12700343132019043
Test Loss Energy: 5.734989984951871, Test Loss Force: 6.955719871101939, time: 17.139420986175537


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1501104299636262, Training Loss Force: 3.4412235383024914, time: 1.68674898147583
Validation Loss Energy: 1.8006212852922991, Validation Loss Force: 3.19526672833498, time: 0.1259784698486328
Test Loss Energy: 5.910991385159602, Test Loss Force: 7.0145320806422315, time: 17.268941164016724


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0643381999718162, Training Loss Force: 3.445823637466873, time: 1.714069128036499
Validation Loss Energy: 1.492235762974182, Validation Loss Force: 3.124718240161533, time: 0.1298685073852539
Test Loss Energy: 5.981118957533018, Test Loss Force: 6.978985938292514, time: 17.192250728607178


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2829586028061497, Training Loss Force: 3.4517480227503783, time: 1.973442554473877
Validation Loss Energy: 2.430166079488399, Validation Loss Force: 3.083401980134632, time: 0.12951040267944336
Test Loss Energy: 6.516079939168205, Test Loss Force: 6.968448798295375, time: 17.842150688171387


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1096703730259514, Training Loss Force: 3.4453870196258545, time: 1.7296876907348633
Validation Loss Energy: 1.6008832203523062, Validation Loss Force: 3.094993245195049, time: 0.13077807426452637
Test Loss Energy: 5.915655683557442, Test Loss Force: 6.969233710532192, time: 17.34215998649597


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.129994835596363, Training Loss Force: 3.473238835395697, time: 1.6640479564666748
Validation Loss Energy: 1.8564071430944526, Validation Loss Force: 3.0096242326723672, time: 0.13364458084106445
Test Loss Energy: 5.808340920544963, Test Loss Force: 6.90488796053871, time: 17.24729061126709


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.113527981923236, Training Loss Force: 3.459048766923279, time: 1.711977481842041
Validation Loss Energy: 2.171355615819645, Validation Loss Force: 3.0813558733527016, time: 0.12975716590881348
Test Loss Energy: 5.81828925570346, Test Loss Force: 6.9562911678503525, time: 17.324575901031494


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.212255289140125, Training Loss Force: 3.456354656572552, time: 1.6964170932769775
Validation Loss Energy: 2.3637904111096386, Validation Loss Force: 3.022709273698241, time: 0.1274559497833252
Test Loss Energy: 5.9232835823804155, Test Loss Force: 6.899985196309461, time: 17.2888503074646


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.064958578933712, Training Loss Force: 3.4386712454763804, time: 1.6987535953521729
Validation Loss Energy: 2.5684861489164277, Validation Loss Force: 3.1875633778970354, time: 0.12594270706176758
Test Loss Energy: 6.654561828443358, Test Loss Force: 6.935656994005905, time: 17.14864754676819


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.553262475262088, Training Loss Force: 3.467690856398442, time: 1.6874606609344482
Validation Loss Energy: 1.774890585132754, Validation Loss Force: 3.095393938323146, time: 0.13238739967346191
Test Loss Energy: 6.078881139573541, Test Loss Force: 6.922791767647406, time: 17.293757915496826


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.208131297508152, Training Loss Force: 3.4476718913519755, time: 1.776721477508545
Validation Loss Energy: 2.137156084365742, Validation Loss Force: 3.0832397656618236, time: 0.1221621036529541
Test Loss Energy: 5.7743135426518455, Test Loss Force: 6.879209334939783, time: 17.344067573547363


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.7100469950812403, Training Loss Force: 3.4558528148488503, time: 1.782681941986084
Validation Loss Energy: 1.5765060702635696, Validation Loss Force: 3.0339397034076816, time: 0.12326765060424805
Test Loss Energy: 6.017389569687405, Test Loss Force: 6.932791883291691, time: 17.323020219802856

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–ƒâ–„â–ƒâ–†â–‚â–‚â–â–‚â–ƒâ–‡â–‚â–‚â–‚â–‚â–ˆâ–„â–â–ƒ
wandb:   test_error_force â–†â–„â–†â–‡â–…â–ˆâ–…â–…â–„â–†â–…â–„â–„â–‚â–„â–‚â–ƒâ–ƒâ–â–ƒ
wandb:          test_loss â–ˆâ–„â–„â–„â–„â–…â–„â–ƒâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–â–
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–‚â–‚â–â–ƒâ–‚â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–‚â–â–‚
wandb: valid_error_energy â–ƒâ–ˆâ–â–ƒâ–â–„â–ƒâ–â–„â–ƒâ–â–‡â–‚â–ƒâ–…â–‡â–ˆâ–ƒâ–…â–‚
wandb:  valid_error_force â–â–ƒâ–…â–…â–‚â–‚â–‡â–‚â–ƒâ–ˆâ–†â–„â–…â–‚â–„â–‚â–ˆâ–…â–„â–ƒ
wandb:         valid_loss â–„â–„â–‚â–ƒâ–â–â–‡â–‚â–‚â–ˆâ–ƒâ–„â–†â–â–„â–ƒâ–‡â–ƒâ–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1556
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 6.01739
wandb:   test_error_force 6.93279
wandb:          test_loss 3.63811
wandb: train_error_energy 2.71005
wandb:  train_error_force 3.45585
wandb:         train_loss 1.6048
wandb: valid_error_energy 1.57651
wandb:  valid_error_force 3.03394
wandb:         valid_loss 1.51193
wandb: 
wandb: ğŸš€ View run al_80_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/um6w8nbd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_132044-um6w8nbd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7324613928794861, Uncertainty Bias: 0.021138474345207214
0.0 6.7949295e-05
0.3974194 5.9018316
(48745, 22, 3)
Found uncertainty sample 0 after 1339 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3196 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2400 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1878 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2547 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3222 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3357 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2395 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2815 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3256 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1494 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2170 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2307 steps.
Found uncertainty sample 44 after 3038 steps.
Found uncertainty sample 45 after 2055 steps.
Found uncertainty sample 46 after 3009 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2325 steps.
Found uncertainty sample 50 after 1317 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2539 steps.
Found uncertainty sample 56 after 2544 steps.
Found uncertainty sample 57 after 1854 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1953 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2817 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1736 steps.
Found uncertainty sample 70 after 1793 steps.
Found uncertainty sample 71 after 3185 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1667 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2260 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3368 steps.
Found uncertainty sample 81 after 3481 steps.
Found uncertainty sample 82 after 1316 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3856 steps.
Found uncertainty sample 92 after 2487 steps.
Found uncertainty sample 93 after 2931 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 994 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_160118-koq8ma10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/koq8ma10
Training model 26. Added 35 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.990705707630429, Training Loss Force: 3.7214075828557625, time: 1.8108932971954346
Validation Loss Energy: 1.5086808257448197, Validation Loss Force: 3.0836381207638883, time: 0.1361391544342041
Test Loss Energy: 5.9488789017394, Test Loss Force: 6.841299194708434, time: 18.437325716018677


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.147762011735131, Training Loss Force: 3.493777550945403, time: 1.9126942157745361
Validation Loss Energy: 2.0547876499190103, Validation Loss Force: 3.1046459526710186, time: 0.13532376289367676
Test Loss Energy: 6.25436000641001, Test Loss Force: 6.850433083074393, time: 18.612024068832397


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1371781018908913, Training Loss Force: 3.488342575630854, time: 1.9025328159332275
Validation Loss Energy: 1.502791393836889, Validation Loss Force: 3.1365225995946027, time: 0.14670062065124512
Test Loss Energy: 5.895953959494804, Test Loss Force: 6.899561586329342, time: 18.61656880378723


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2249399860831485, Training Loss Force: 3.4851135122908845, time: 1.9175631999969482
Validation Loss Energy: 1.5936130170704774, Validation Loss Force: 3.0932707880167247, time: 0.1287522315979004
Test Loss Energy: 5.8273660451718845, Test Loss Force: 6.928390714539144, time: 17.9700927734375


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2400654580544224, Training Loss Force: 3.5022079027846535, time: 1.91127347946167
Validation Loss Energy: 1.5261817856054465, Validation Loss Force: 3.1178871961027603, time: 0.12308382987976074
Test Loss Energy: 5.898692344651425, Test Loss Force: 6.877530565797632, time: 16.68865156173706


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2462651326566827, Training Loss Force: 3.476847031582888, time: 1.782395601272583
Validation Loss Energy: 2.112462966758934, Validation Loss Force: 3.020955197501195, time: 0.12810564041137695
Test Loss Energy: 5.789185442368919, Test Loss Force: 6.890833172649085, time: 16.724234580993652


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3323481449292394, Training Loss Force: 3.4767012055592206, time: 1.7827394008636475
Validation Loss Energy: 2.5722814331741937, Validation Loss Force: 3.144585783372367, time: 0.12483930587768555
Test Loss Energy: 5.710449697654048, Test Loss Force: 6.829863844682449, time: 16.57962727546692


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2322565468544675, Training Loss Force: 3.462757311823972, time: 1.7843070030212402
Validation Loss Energy: 1.510887476980964, Validation Loss Force: 3.045206428187909, time: 0.12882161140441895
Test Loss Energy: 5.95393382010955, Test Loss Force: 6.839536053778697, time: 17.332717418670654


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1498341886206664, Training Loss Force: 3.477132279665588, time: 1.7299470901489258
Validation Loss Energy: 2.4934539948205785, Validation Loss Force: 3.1570074930125216, time: 0.12232851982116699
Test Loss Energy: 6.406203664912625, Test Loss Force: 6.839000260518085, time: 16.528181076049805


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4476899698176733, Training Loss Force: 3.468486482067503, time: 1.7651731967926025
Validation Loss Energy: 1.9119739501242996, Validation Loss Force: 3.069649265674694, time: 0.13074493408203125
Test Loss Energy: 5.771124848202123, Test Loss Force: 6.845064951988223, time: 17.25865912437439


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1354718817466876, Training Loss Force: 3.475854906936292, time: 1.8399858474731445
Validation Loss Energy: 1.9637976888111006, Validation Loss Force: 3.1209888659709613, time: 0.13913321495056152
Test Loss Energy: 6.105844116142953, Test Loss Force: 6.829758381113773, time: 18.53706407546997


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2054593394201296, Training Loss Force: 3.4625709021217665, time: 1.787130355834961
Validation Loss Energy: 1.7303265286106368, Validation Loss Force: 2.996379983207156, time: 0.1223459243774414
Test Loss Energy: 5.725214431724158, Test Loss Force: 6.8872071256857765, time: 17.303672313690186


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3458079626213153, Training Loss Force: 3.4731998534808444, time: 1.7783424854278564
Validation Loss Energy: 3.1020166753959035, Validation Loss Force: 3.1096880728114074, time: 0.12850189208984375
Test Loss Energy: 6.004601654989017, Test Loss Force: 6.902325304473089, time: 17.34976077079773


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.5018167354003595, Training Loss Force: 3.488812661371587, time: 1.7561426162719727
Validation Loss Energy: 1.7344139547878603, Validation Loss Force: 3.1242941667731134, time: 0.12422704696655273
Test Loss Energy: 5.7465009888603475, Test Loss Force: 6.876639621078298, time: 17.37476921081543


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4110911449160266, Training Loss Force: 3.4623747127906728, time: 1.7696313858032227
Validation Loss Energy: 2.7403692500447248, Validation Loss Force: 3.028701745753449, time: 0.12960124015808105
Test Loss Energy: 5.911750649641393, Test Loss Force: 6.834262346068473, time: 17.24195098876953


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.7879889418158137, Training Loss Force: 3.4561085001942264, time: 1.7523410320281982
Validation Loss Energy: 2.071821950917059, Validation Loss Force: 3.0966558043731185, time: 0.12280726432800293
Test Loss Energy: 6.272254370481628, Test Loss Force: 6.833260402528606, time: 17.372062921524048


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.138638381736726, Training Loss Force: 3.4688143534781166, time: 1.7435846328735352
Validation Loss Energy: 2.4547033286930575, Validation Loss Force: 3.111516075164902, time: 0.12552237510681152
Test Loss Energy: 5.745652015526312, Test Loss Force: 6.7620960383110855, time: 17.313790798187256


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1535226050485363, Training Loss Force: 3.457784290372947, time: 1.7458772659301758
Validation Loss Energy: 1.8264603696586241, Validation Loss Force: 3.128829046599079, time: 0.12979459762573242
Test Loss Energy: 5.622022074346437, Test Loss Force: 6.805768030647655, time: 17.480915069580078


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2268920530046783, Training Loss Force: 3.4456807215017284, time: 1.713369607925415
Validation Loss Energy: 1.6955758910205625, Validation Loss Force: 3.0074467510943395, time: 0.12684011459350586
Test Loss Energy: 5.696237423222093, Test Loss Force: 6.723238073634597, time: 17.431670427322388


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1858942811105817, Training Loss Force: 3.4532814526370803, time: 1.7536561489105225
Validation Loss Energy: 1.6628808236511206, Validation Loss Force: 3.040306370962622, time: 0.12932753562927246
Test Loss Energy: 5.9595883713341875, Test Loss Force: 6.81163564709977, time: 17.920522928237915

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‡â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–ˆâ–‚â–…â–‚â–„â–‚â–„â–‡â–‚â–â–‚â–„
wandb:   test_error_force â–…â–…â–‡â–ˆâ–†â–‡â–…â–…â–…â–…â–…â–‡â–‡â–†â–…â–…â–‚â–„â–â–„
wandb:          test_loss â–‡â–ˆâ–†â–†â–‡â–†â–ƒâ–ƒâ–„â–„â–…â–…â–‡â–„â–…â–‡â–†â–ƒâ–â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–ƒâ–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–â–â–â–„â–†â–â–…â–ƒâ–ƒâ–‚â–ˆâ–‚â–†â–ƒâ–…â–‚â–‚â–‚
wandb:  valid_error_force â–…â–†â–‡â–…â–†â–‚â–‡â–ƒâ–ˆâ–„â–†â–â–†â–‡â–‚â–…â–†â–‡â–â–ƒ
wandb:         valid_loss â–„â–…â–ƒâ–‚â–…â–ƒâ–…â–‚â–ˆâ–‚â–„â–â–†â–‡â–„â–ˆâ–‡â–…â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1587
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.95959
wandb:   test_error_force 6.81164
wandb:          test_loss 3.5942
wandb: train_error_energy 2.18589
wandb:  train_error_force 3.45328
wandb:         train_loss 1.57643
wandb: valid_error_energy 1.66288
wandb:  valid_error_force 3.04031
wandb:         valid_loss 1.55202
wandb: 
wandb: ğŸš€ View run al_80_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/koq8ma10
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_160118-koq8ma10/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.75237637758255, Uncertainty Bias: 0.015602856874465942
0.00017642975 0.014951706
0.53114796 7.052177
(48745, 22, 3)
Found uncertainty sample 0 after 787 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2375 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3469 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3465 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2560 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1668 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 552 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1185 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3331 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3639 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3977 steps.
Found uncertainty sample 40 after 1963 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2458 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3736 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 447 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 791 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3019 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2858 steps.
Found uncertainty sample 70 after 2653 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1387 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2690 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 430 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1744 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2275 steps.
Found uncertainty sample 91 after 3309 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1697 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1331 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3402 steps.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_184450-4axan538
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4axan538
Training model 27. Added 28 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.395197912040805, Training Loss Force: 3.7612977551940046, time: 1.9246251583099365
Validation Loss Energy: 1.4538488268965342, Validation Loss Force: 3.1564893419099476, time: 0.13919734954833984
Test Loss Energy: 5.893850307311239, Test Loss Force: 6.767715379831299, time: 18.312167167663574


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.013198050417298, Training Loss Force: 3.516829417763552, time: 1.9005565643310547
Validation Loss Energy: 1.614401686870728, Validation Loss Force: 3.138582066525289, time: 0.12888050079345703
Test Loss Energy: 5.987666673173605, Test Loss Force: 6.787437430905604, time: 18.473652839660645


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9948195132495299, Training Loss Force: 3.4887657485627113, time: 1.884941816329956
Validation Loss Energy: 1.709660772178938, Validation Loss Force: 3.034677183618995, time: 0.14395570755004883
Test Loss Energy: 5.705200593135738, Test Loss Force: 6.763992419328195, time: 19.023448944091797


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0128440610510436, Training Loss Force: 3.4941312323296647, time: 1.971435308456421
Validation Loss Energy: 2.775642380785718, Validation Loss Force: 3.1451354421590896, time: 0.13223767280578613
Test Loss Energy: 6.69866193310686, Test Loss Force: 6.8108084860155795, time: 18.390824556350708


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.6419077458119045, Training Loss Force: 3.506459720003756, time: 1.9225518703460693
Validation Loss Energy: 1.4537738987289295, Validation Loss Force: 3.074080047674938, time: 0.1418468952178955
Test Loss Energy: 5.777497389675868, Test Loss Force: 6.801681007256765, time: 18.5074462890625


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0017958860375447, Training Loss Force: 3.4736469763567537, time: 1.886061668395996
Validation Loss Energy: 1.5288529803472826, Validation Loss Force: 3.0927746811595975, time: 0.1492302417755127
Test Loss Energy: 5.684094983242888, Test Loss Force: 6.7764489067412645, time: 18.638526916503906


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0973750626090877, Training Loss Force: 3.477541568870572, time: 1.8618793487548828
Validation Loss Energy: 1.4244236002677553, Validation Loss Force: 3.0653030979499025, time: 0.14685463905334473
Test Loss Energy: 5.775256141949805, Test Loss Force: 6.774700289435715, time: 18.365022897720337


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.024027295816702, Training Loss Force: 3.462661698827886, time: 1.8647058010101318
Validation Loss Energy: 1.651581477841015, Validation Loss Force: 3.0517730526358924, time: 0.12560200691223145
Test Loss Energy: 6.048481587665285, Test Loss Force: 6.790983062830442, time: 18.48543691635132


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2020983266666843, Training Loss Force: 3.4713256374122716, time: 1.8565826416015625
Validation Loss Energy: 1.4682031377214826, Validation Loss Force: 2.999855069233077, time: 0.1349620819091797
Test Loss Energy: 5.691969653106676, Test Loss Force: 6.766852824845169, time: 18.508583545684814


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1609073900743856, Training Loss Force: 3.4776323261948163, time: 1.9194581508636475
Validation Loss Energy: 1.4616960772700347, Validation Loss Force: 3.0306770437469748, time: 0.13438129425048828
Test Loss Energy: 5.88473690683832, Test Loss Force: 6.750030294445874, time: 18.390302181243896


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.061114046012485, Training Loss Force: 3.467208401948894, time: 1.9190874099731445
Validation Loss Energy: 2.758931395387557, Validation Loss Force: 3.18791964853052, time: 0.13356471061706543
Test Loss Energy: 5.785992809822991, Test Loss Force: 6.735091628959232, time: 17.973004817962646


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2217492215306542, Training Loss Force: 3.4788475627059943, time: 1.970170497894287
Validation Loss Energy: 2.204660351310637, Validation Loss Force: 2.8949596426311235, time: 0.1344587802886963
Test Loss Energy: 5.6994435255026366, Test Loss Force: 6.733431708585411, time: 16.987947463989258


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.4876243943304615, Training Loss Force: 3.5103469731678825, time: 1.8079826831817627
Validation Loss Energy: 1.5952775802708605, Validation Loss Force: 3.1301675108352507, time: 0.1215667724609375
Test Loss Energy: 5.71481484296885, Test Loss Force: 6.796530914730935, time: 17.02837371826172


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0161793152193845, Training Loss Force: 3.499471200832134, time: 1.7762484550476074
Validation Loss Energy: 1.486633852600931, Validation Loss Force: 2.9605830233003667, time: 0.12447214126586914
Test Loss Energy: 5.621492802610444, Test Loss Force: 6.728254037728086, time: 17.61081576347351


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.23332387372636, Training Loss Force: 3.45124431654013, time: 1.767744541168213
Validation Loss Energy: 1.8009673131450707, Validation Loss Force: 3.016869441342566, time: 0.12851977348327637
Test Loss Energy: 5.653997123545417, Test Loss Force: 6.756877909286008, time: 17.343974590301514


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.261263321923174, Training Loss Force: 3.4968452548620843, time: 1.8113932609558105
Validation Loss Energy: 1.3772497500207916, Validation Loss Force: 3.0966659358192583, time: 0.12958550453186035
Test Loss Energy: 5.5840183827628165, Test Loss Force: 6.740712166597476, time: 17.47710943222046


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.37321560092818, Training Loss Force: 3.4772943144312976, time: 1.7752916812896729
Validation Loss Energy: 2.4996173654452867, Validation Loss Force: 3.001183179353964, time: 0.12618494033813477
Test Loss Energy: 5.73155421401989, Test Loss Force: 6.746440555377228, time: 17.64089822769165


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0441867757420944, Training Loss Force: 3.44923332162627, time: 2.1686627864837646
Validation Loss Energy: 1.7648532167071942, Validation Loss Force: 2.90786487832166, time: 0.14150381088256836
Test Loss Energy: 5.915946034797274, Test Loss Force: 6.735802519443422, time: 18.731633186340332


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.3647702994317563, Training Loss Force: 3.4618608146687855, time: 1.7773141860961914
Validation Loss Energy: 1.5776031054782695, Validation Loss Force: 3.094909632930753, time: 0.129927396774292
Test Loss Energy: 5.618601971861164, Test Loss Force: 6.719721281444478, time: 18.557165145874023


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2386239757195834, Training Loss Force: 3.4510745902581936, time: 1.853442907333374
Validation Loss Energy: 1.3855652179408917, Validation Loss Force: 2.991627110287327, time: 0.12972092628479004
Test Loss Energy: 5.738634423687148, Test Loss Force: 6.732333725861036, time: 17.818244218826294

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–‚â–ˆâ–‚â–‚â–‚â–„â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–ƒâ–â–‚
wandb:   test_error_force â–…â–†â–„â–ˆâ–‡â–…â–…â–†â–…â–ƒâ–‚â–‚â–‡â–‚â–„â–ƒâ–ƒâ–‚â–â–‚
wandb:          test_loss â–†â–„â–†â–ˆâ–ƒâ–ƒâ–…â–†â–‚â–ƒâ–â–â–„â–‚â–„â–â–†â–„â–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–ƒâ–â–â–â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–‚â–â–â–â–â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb: valid_error_energy â–â–‚â–ƒâ–ˆâ–â–‚â–â–‚â–â–â–ˆâ–…â–‚â–‚â–ƒâ–â–‡â–ƒâ–‚â–
wandb:  valid_error_force â–‡â–‡â–„â–‡â–…â–†â–…â–…â–„â–„â–ˆâ–â–‡â–ƒâ–„â–†â–„â–â–†â–ƒ
wandb:         valid_loss â–…â–†â–„â–ˆâ–…â–…â–…â–ƒâ–„â–…â–ˆâ–â–†â–‚â–„â–„â–†â–‚â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1612
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.73863
wandb:   test_error_force 6.73233
wandb:          test_loss 3.55897
wandb: train_error_energy 2.23862
wandb:  train_error_force 3.45107
wandb:         train_loss 1.582
wandb: valid_error_energy 1.38557
wandb:  valid_error_force 2.99163
wandb:         valid_loss 1.52352
wandb: 
wandb: ğŸš€ View run al_80_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/4axan538
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_184450-4axan538/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.738621175289154, Uncertainty Bias: 0.021593958139419556
0.00017547607 0.022769928
0.5664461 7.10201
(48745, 22, 3)
Found uncertainty sample 0 after 3778 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3225 steps.
Found uncertainty sample 5 after 633 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1936 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 581 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 888 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3392 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 437 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3209 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3082 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 635 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1821 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3891 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1755 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3418 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2215 steps.
Found uncertainty sample 74 after 1542 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3710 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1054 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3610 steps.
Found uncertainty sample 82 after 2115 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2433 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2140 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241211_213156-e5sumqlw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/e5sumqlw
Training model 28. Added 23 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.1755103234412365, Training Loss Force: 3.7058963182080484, time: 1.7729172706604004
Validation Loss Energy: 2.136947220706862, Validation Loss Force: 3.1829428817844607, time: 0.13582444190979004
Test Loss Energy: 5.597174377720074, Test Loss Force: 6.7053292442291434, time: 17.22653818130493


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9907354926004206, Training Loss Force: 3.498291172242383, time: 1.76896333694458
Validation Loss Energy: 1.7711694497005819, Validation Loss Force: 2.9142215257650337, time: 0.13460421562194824
Test Loss Energy: 6.073889025560615, Test Loss Force: 6.704179714180389, time: 17.359626054763794


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.140861787952889, Training Loss Force: 3.4660393889327734, time: 1.7735686302185059
Validation Loss Energy: 1.8707039496124651, Validation Loss Force: 3.2017826955522652, time: 0.13198590278625488
Test Loss Energy: 5.810778982148273, Test Loss Force: 6.669878280698336, time: 17.94925594329834


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1869277686030824, Training Loss Force: 3.4712133816002915, time: 1.7975070476531982
Validation Loss Energy: 2.324409034626277, Validation Loss Force: 3.065140883477094, time: 0.12281489372253418
Test Loss Energy: 6.087626100719022, Test Loss Force: 6.698441131583818, time: 17.26419973373413


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.106487675156455, Training Loss Force: 3.4742667169826107, time: 1.750929832458496
Validation Loss Energy: 2.307863937741832, Validation Loss Force: 3.1006223212041037, time: 0.1297469139099121
Test Loss Energy: 6.184042568369351, Test Loss Force: 6.6556126239617095, time: 17.444631814956665


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1322120630823194, Training Loss Force: 3.4970087158455034, time: 1.7704038619995117
Validation Loss Energy: 1.6575099325167695, Validation Loss Force: 2.992113085698314, time: 0.13045144081115723
Test Loss Energy: 6.009286070553254, Test Loss Force: 6.66517122982448, time: 17.269763231277466


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.986545389750554, Training Loss Force: 3.468350458900172, time: 1.7083759307861328
Validation Loss Energy: 1.8096410557209688, Validation Loss Force: 3.0386618479853724, time: 0.1269364356994629
Test Loss Energy: 5.773821103423687, Test Loss Force: 6.611857763728644, time: 17.47506046295166


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2090952745203896, Training Loss Force: 3.4749395270882473, time: 1.7636611461639404
Validation Loss Energy: 1.8206167519274685, Validation Loss Force: 3.065188757343469, time: 0.1269848346710205
Test Loss Energy: 5.756352965403203, Test Loss Force: 6.662176360122735, time: 17.423434734344482


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0917265095988573, Training Loss Force: 3.478869615683565, time: 1.7619974613189697
Validation Loss Energy: 2.1703244350048534, Validation Loss Force: 2.9481501802029157, time: 0.12887787818908691
Test Loss Energy: 5.984739037895858, Test Loss Force: 6.619509459005059, time: 17.312520265579224


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.3262291453232757, Training Loss Force: 3.4632399313053055, time: 1.7496933937072754
Validation Loss Energy: 2.8727521807003074, Validation Loss Force: 3.0005673878309005, time: 0.13515734672546387
Test Loss Energy: 6.6622117750092, Test Loss Force: 6.6388445693940925, time: 17.370561838150024


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1563447704755054, Training Loss Force: 3.4627161261528507, time: 1.7719223499298096
Validation Loss Energy: 2.0669118735802052, Validation Loss Force: 3.0376638448733244, time: 0.1338794231414795
Test Loss Energy: 5.527289104351642, Test Loss Force: 6.626151649317101, time: 17.421371698379517


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1682639344090635, Training Loss Force: 3.4534436895514453, time: 1.795745611190796
Validation Loss Energy: 1.5356196730228822, Validation Loss Force: 3.0108837606963075, time: 0.13228607177734375
Test Loss Energy: 5.5532804506960165, Test Loss Force: 6.640394008565707, time: 17.868223667144775


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2336493898213363, Training Loss Force: 3.4494845841101713, time: 1.9529168605804443
Validation Loss Energy: 1.5950105999648931, Validation Loss Force: 3.043146627253504, time: 0.14095377922058105
Test Loss Energy: 5.780613594243424, Test Loss Force: 6.622652017806713, time: 18.652719974517822


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0269335953396603, Training Loss Force: 3.4405157241437787, time: 1.8951044082641602
Validation Loss Energy: 1.5856927868843989, Validation Loss Force: 3.1785614210000395, time: 0.13123369216918945
Test Loss Energy: 5.598801837362483, Test Loss Force: 6.621032704823947, time: 19.22562003135681


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1171001827047307, Training Loss Force: 3.451256689958945, time: 1.910698652267456
Validation Loss Energy: 2.7197083366669497, Validation Loss Force: 3.0673284965012617, time: 0.13179445266723633
Test Loss Energy: 5.762428820641623, Test Loss Force: 6.707060407071591, time: 18.562973499298096


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.5788355357572645, Training Loss Force: 3.4448885444921244, time: 1.902827262878418
Validation Loss Energy: 1.4842388232673316, Validation Loss Force: 3.079067168536283, time: 0.1337583065032959
Test Loss Energy: 5.778432502160974, Test Loss Force: 6.598559255854767, time: 18.60604763031006


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.192924423345385, Training Loss Force: 3.45288311342748, time: 1.883115291595459
Validation Loss Energy: 1.6857468852483044, Validation Loss Force: 2.9366449767673997, time: 0.13964223861694336
Test Loss Energy: 5.989662751677739, Test Loss Force: 6.634522451685773, time: 18.654208421707153


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2973115770593275, Training Loss Force: 3.4466106152739897, time: 1.9113702774047852
Validation Loss Energy: 1.98970079055688, Validation Loss Force: 3.1535662526967805, time: 0.13505101203918457
Test Loss Energy: 5.9940992257308885, Test Loss Force: 6.601585721259093, time: 18.542059659957886


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.086535982655738, Training Loss Force: 3.4387684830162994, time: 1.9144747257232666
Validation Loss Energy: 1.7184823670677325, Validation Loss Force: 3.056616106559822, time: 0.1324756145477295
Test Loss Energy: 5.886761675853876, Test Loss Force: 6.599053896126628, time: 18.594455003738403


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0103270199406302, Training Loss Force: 3.452699782497334, time: 1.910275936126709
Validation Loss Energy: 2.497953692921487, Validation Loss Force: 3.014209769729031, time: 0.13301324844360352
Test Loss Energy: 5.629261764086077, Test Loss Force: 6.603555527135621, time: 18.74375009536743

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–ƒâ–„â–…â–„â–ƒâ–‚â–„â–ˆâ–â–â–ƒâ–â–‚â–ƒâ–„â–„â–ƒâ–‚
wandb:   test_error_force â–ˆâ–ˆâ–†â–‡â–…â–…â–‚â–…â–‚â–„â–ƒâ–„â–ƒâ–‚â–ˆâ–â–ƒâ–â–â–
wandb:          test_loss â–…â–ˆâ–„â–ˆâ–…â–…â–ƒâ–ƒâ–â–ˆâ–‚â–ƒâ–ƒâ–â–„â–ƒâ–…â–ƒâ–…â–‚
wandb: train_error_energy â–ˆâ–â–â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–„â–‚â–ƒâ–…â–…â–‚â–ƒâ–ƒâ–„â–ˆâ–„â–â–‚â–‚â–‡â–â–‚â–„â–‚â–†
wandb:  valid_error_force â–ˆâ–â–ˆâ–…â–†â–ƒâ–„â–…â–‚â–ƒâ–„â–ƒâ–„â–‡â–…â–…â–‚â–‡â–„â–ƒ
wandb:         valid_loss â–…â–â–…â–…â–ˆâ–â–ƒâ–ƒâ–â–„â–ƒâ–…â–‚â–„â–„â–ƒâ–â–…â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1632
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.62926
wandb:   test_error_force 6.60356
wandb:          test_loss 3.50359
wandb: train_error_energy 2.01033
wandb:  train_error_force 3.4527
wandb:         train_loss 1.56874
wandb: valid_error_energy 2.49795
wandb:  valid_error_force 3.01421
wandb:         valid_loss 1.53914
wandb: 
wandb: ğŸš€ View run al_80_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/e5sumqlw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241211_213156-e5sumqlw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7421988844871521, Uncertainty Bias: 0.020729586482048035
0.0004348755 0.015842438
0.37036464 4.794203
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 302 steps.
Found uncertainty sample 9 after 2968 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3828 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 574 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1811 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3121 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2224 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3238 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2058 steps.
Found uncertainty sample 90 after 3293 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1323 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241212_003200-2k7xqfth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_80_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2k7xqfth
Training model 29. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.425743841430064, Training Loss Force: 3.765919498656818, time: 1.7696442604064941
Validation Loss Energy: 1.7624168822470252, Validation Loss Force: 3.1563881387831234, time: 0.13263893127441406
Test Loss Energy: 5.84548059055719, Test Loss Force: 6.6385042586590775, time: 17.76349115371704


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0655138560527453, Training Loss Force: 3.4606190873302225, time: 1.8247308731079102
Validation Loss Energy: 1.588327241217157, Validation Loss Force: 3.03500005388059, time: 0.13052654266357422
Test Loss Energy: 5.796717085167274, Test Loss Force: 6.619990193530466, time: 17.94528317451477


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9808725477094502, Training Loss Force: 3.4382079131055763, time: 1.8510675430297852
Validation Loss Energy: 1.4159203665903515, Validation Loss Force: 2.9758464365808517, time: 0.13334250450134277
Test Loss Energy: 5.651579696726834, Test Loss Force: 6.587071516791716, time: 18.033872604370117


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0859297263175254, Training Loss Force: 3.4453419285120757, time: 1.7864103317260742
Validation Loss Energy: 1.6060516495657224, Validation Loss Force: 3.0063305106658036, time: 0.1297919750213623
Test Loss Energy: 5.846094441594422, Test Loss Force: 6.5480701601800915, time: 17.914926767349243


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9616806105210047, Training Loss Force: 3.4700260708394626, time: 1.9304139614105225
Validation Loss Energy: 2.24042402218011, Validation Loss Force: 3.1278615491600226, time: 0.13533735275268555
Test Loss Energy: 6.185447599022085, Test Loss Force: 6.566469698756043, time: 18.038813591003418


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.7624106586010146, Training Loss Force: 3.4602020965334837, time: 1.802786111831665
Validation Loss Energy: 2.040600953293659, Validation Loss Force: 3.1297560182535764, time: 0.13441157341003418
Test Loss Energy: 5.416611547596694, Test Loss Force: 6.594376638617658, time: 17.94196605682373


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.172333349616266, Training Loss Force: 3.433370708528825, time: 1.8058884143829346
Validation Loss Energy: 1.5007230201403656, Validation Loss Force: 2.996536519616743, time: 0.13771867752075195
Test Loss Energy: 5.483360249748462, Test Loss Force: 6.575640515226013, time: 17.873233318328857


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9718397896746338, Training Loss Force: 3.4514919561164237, time: 1.7929558753967285
Validation Loss Energy: 1.723778218699906, Validation Loss Force: 3.0933085304369596, time: 0.13029026985168457
Test Loss Energy: 5.403810421972851, Test Loss Force: 6.600760066397607, time: 18.005695819854736


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2205592066663136, Training Loss Force: 3.450366894564031, time: 1.778228521347046
Validation Loss Energy: 1.5567773055979353, Validation Loss Force: 3.0727843359147844, time: 0.13118863105773926
Test Loss Energy: 5.542670153975082, Test Loss Force: 6.643980042699556, time: 17.840977430343628


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.285212793620933, Training Loss Force: 3.4536792394189715, time: 2.045896530151367
Validation Loss Energy: 1.5715818534359496, Validation Loss Force: 2.9565461430192688, time: 0.13144159317016602
Test Loss Energy: 5.563240091851252, Test Loss Force: 6.5617286296325625, time: 17.772765636444092


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.324773580416002, Training Loss Force: 3.4480347521357597, time: 1.8437414169311523
Validation Loss Energy: 1.542271134415464, Validation Loss Force: 3.0997015842856923, time: 0.1342918872833252
Test Loss Energy: 5.600295488003682, Test Loss Force: 6.551442777012735, time: 17.992419242858887


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9799833784245733, Training Loss Force: 3.419994270668714, time: 1.8085017204284668
Validation Loss Energy: 2.0632150090849395, Validation Loss Force: 2.982555012609364, time: 0.12960290908813477
Test Loss Energy: 5.8483544494874815, Test Loss Force: 6.544219382923996, time: 17.803274154663086


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9125966979171238, Training Loss Force: 3.4511874303667747, time: 1.841247320175171
Validation Loss Energy: 1.619076848258628, Validation Loss Force: 3.028163777096888, time: 0.1325068473815918
Test Loss Energy: 5.73071916974845, Test Loss Force: 6.582462710809302, time: 17.957679748535156


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8714196981715552, Training Loss Force: 3.408275857243874, time: 1.8440485000610352
Validation Loss Energy: 1.4786280061282433, Validation Loss Force: 2.9924604495659617, time: 0.13002991676330566
Test Loss Energy: 5.392240561129813, Test Loss Force: 6.553867881836528, time: 18.657989263534546


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0670207223947226, Training Loss Force: 3.429742764416324, time: 1.8138580322265625
Validation Loss Energy: 1.8415069031909757, Validation Loss Force: 3.0186890936030877, time: 0.13176918029785156
Test Loss Energy: 5.678153083897367, Test Loss Force: 6.558828983050392, time: 17.896639585494995


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1591309191294985, Training Loss Force: 3.4144262274161385, time: 1.8258836269378662
Validation Loss Energy: 1.362972928058626, Validation Loss Force: 2.941484467984994, time: 0.12996625900268555
Test Loss Energy: 5.582848803164472, Test Loss Force: 6.579891131656543, time: 17.946987867355347


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.297237825671291, Training Loss Force: 3.4458203588646947, time: 1.786062240600586
Validation Loss Energy: 2.6755703018882793, Validation Loss Force: 3.127788068341866, time: 0.13611149787902832
Test Loss Energy: 6.351157508767113, Test Loss Force: 6.496818528769052, time: 17.957347631454468


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.281477384882402, Training Loss Force: 3.4266275588333097, time: 1.8588998317718506
Validation Loss Energy: 1.5292575701854334, Validation Loss Force: 2.9926859020762135, time: 0.1345505714416504
Test Loss Energy: 5.466952620750645, Test Loss Force: 6.518985190950654, time: 17.82260799407959


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9864416443583697, Training Loss Force: 3.424825985594597, time: 1.836937427520752
Validation Loss Energy: 1.8408128991304054, Validation Loss Force: 2.890159341183212, time: 0.1367948055267334
Test Loss Energy: 6.072139487267499, Test Loss Force: 6.491064513218799, time: 18.00508165359497


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.3329514345218203, Training Loss Force: 3.428646016102254, time: 1.835376262664795
Validation Loss Energy: 2.5785923221080793, Validation Loss Force: 3.011282227132946, time: 0.14010119438171387
Test Loss Energy: 5.535637593173436, Test Loss Force: 6.4967386430069824, time: 17.988463163375854

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–ƒâ–„â–‡â–â–‚â–â–‚â–‚â–ƒâ–„â–ƒâ–â–ƒâ–‚â–ˆâ–‚â–†â–‚
wandb:   test_error_force â–ˆâ–‡â–…â–„â–„â–†â–…â–†â–ˆâ–„â–„â–ƒâ–…â–„â–„â–…â–â–‚â–â–
wandb:          test_loss â–ƒâ–ƒâ–‚â–‚â–ˆâ–‚â–ƒâ–ƒâ–…â–„â–…â–ƒâ–ƒâ–ƒâ–‚â–â–„â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–ƒâ–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–
wandb: valid_error_energy â–ƒâ–‚â–â–‚â–†â–…â–‚â–ƒâ–‚â–‚â–‚â–…â–‚â–‚â–„â–â–ˆâ–‚â–„â–‡
wandb:  valid_error_force â–ˆâ–…â–ƒâ–„â–‡â–‡â–„â–†â–†â–ƒâ–‡â–ƒâ–…â–„â–„â–‚â–‡â–„â–â–„
wandb:         valid_loss â–†â–‚â–‚â–ƒâ–ˆâ–…â–‚â–…â–„â–â–‡â–ƒâ–‚â–„â–ƒâ–‚â–‡â–â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1641
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 5.53564
wandb:   test_error_force 6.49674
wandb:          test_loss 3.44972
wandb: train_error_energy 2.33295
wandb:  train_error_force 3.42865
wandb:         train_loss 1.56582
wandb: valid_error_energy 2.57859
wandb:  valid_error_force 3.01128
wandb:         valid_loss 1.53662
wandb: 
wandb: ğŸš€ View run al_80_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/2k7xqfth
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241212_003200-2k7xqfth/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.7442633509635925, Uncertainty Bias: 0.02096216380596161
1.335144e-05 0.0061483383
0.34153992 5.730222
(48745, 22, 3)
