Training on device: cuda
Loaded dataset in: 95.03940916061401 seconds
Number of trainable parameters: 9314
Epoch 0, Batch 100/3125, Loss: 13380.9345703125, Uncertainty: 20.911338806152344
Epoch 0, Batch 200/3125, Loss: 12943.001953125, Uncertainty: 369.7572021484375
Epoch 0, Batch 300/3125, Loss: 812.4801025390625, Uncertainty: 3372.30078125
Epoch 0, Batch 400/3125, Loss: 341.47503662109375, Uncertainty: 128.690185546875
Epoch 0, Batch 500/3125, Loss: 350.16534423828125, Uncertainty: 144.44418334960938
Epoch 0, Batch 600/3125, Loss: 361.43560791015625, Uncertainty: 162.09432983398438
Epoch 0, Batch 700/3125, Loss: 334.090087890625, Uncertainty: 163.78250122070312
Epoch 0, Batch 800/3125, Loss: 306.35064697265625, Uncertainty: 159.94015502929688
Epoch 0, Batch 900/3125, Loss: 291.70147705078125, Uncertainty: 176.21762084960938
Epoch 0, Batch 1000/3125, Loss: 307.87506103515625, Uncertainty: 194.7254638671875
Epoch 0, Batch 1100/3125, Loss: 275.23455810546875, Uncertainty: 185.37255859375
Epoch 0, Batch 1200/3125, Loss: 266.51190185546875, Uncertainty: 200.4855194091797
Epoch 0, Batch 1300/3125, Loss: 280.67889404296875, Uncertainty: 242.90774536132812
Epoch 0, Batch 1400/3125, Loss: 256.34893798828125, Uncertainty: 239.06411743164062
Epoch 0, Batch 1500/3125, Loss: 268.6658630371094, Uncertainty: 317.6462097167969
Epoch 0, Batch 1600/3125, Loss: 252.30734252929688, Uncertainty: 302.5430908203125
Epoch 0, Batch 1700/3125, Loss: 251.46827697753906, Uncertainty: 342.66943359375
Epoch 0, Batch 1800/3125, Loss: 206.13308715820312, Uncertainty: 314.8919677734375
Epoch 0, Batch 1900/3125, Loss: 197.04995727539062, Uncertainty: 338.7344970703125
Epoch 0, Batch 2000/3125, Loss: 212.69229125976562, Uncertainty: 416.6446838378906
Epoch 0, Batch 2100/3125, Loss: 185.6517791748047, Uncertainty: 433.06707763671875
Epoch 0, Batch 2200/3125, Loss: 169.3114013671875, Uncertainty: 446.56256103515625
Epoch 0, Batch 2300/3125, Loss: 154.61355590820312, Uncertainty: 465.36334228515625
Epoch 0, Batch 2400/3125, Loss: 152.34017944335938, Uncertainty: 515.5686645507812
Epoch 0, Batch 2500/3125, Loss: 145.20831298828125, Uncertainty: 478.46453857421875
Epoch 0, Batch 2600/3125, Loss: 127.98444366455078, Uncertainty: 495.8627624511719
Epoch 0, Batch 2700/3125, Loss: 119.18058013916016, Uncertainty: 465.494140625
Epoch 0, Batch 2800/3125, Loss: 117.74130249023438, Uncertainty: 462.3224182128906
Epoch 0, Batch 2900/3125, Loss: 109.1993408203125, Uncertainty: 407.09588623046875
Epoch 0, Batch 3000/3125, Loss: 115.60603332519531, Uncertainty: 433.66424560546875
Epoch 0, Batch 3100/3125, Loss: 101.37443542480469, Uncertainty: 397.59429931640625

Training and Validation Results of Epoch 0:
================================
Training Loss: 1332.1603895385742, Training Uncertainty: 403.4103400691986, time: 142.1221616268158
Validation Loss: 102.01574835813868, Validation Uncertainty: 423.37980484047813, time: 29.34958243370056
Number of predictions within uncertainty interval: 189873/200000 (94.94%)

Epoch 1, Batch 100/3125, Loss: 99.75582122802734, Uncertainty: 401.007568359375
Epoch 1, Batch 200/3125, Loss: 94.67515563964844, Uncertainty: 372.6458435058594
Epoch 1, Batch 300/3125, Loss: 107.75422668457031, Uncertainty: 429.5091247558594
Epoch 1, Batch 400/3125, Loss: 102.76112365722656, Uncertainty: 405.4490661621094
Epoch 1, Batch 500/3125, Loss: 92.57142639160156, Uncertainty: 367.12164306640625
Epoch 1, Batch 600/3125, Loss: 82.47386169433594, Uncertainty: 323.71075439453125
Epoch 1, Batch 700/3125, Loss: 87.83585357666016, Uncertainty: 351.6834716796875
Epoch 1, Batch 800/3125, Loss: 78.9735107421875, Uncertainty: 311.96746826171875
Epoch 1, Batch 900/3125, Loss: 72.52879333496094, Uncertainty: 283.848876953125
Epoch 1, Batch 1000/3125, Loss: 67.3648681640625, Uncertainty: 261.96856689453125
Epoch 1, Batch 1100/3125, Loss: 70.47389221191406, Uncertainty: 282.297607421875
Epoch 1, Batch 1200/3125, Loss: 58.639373779296875, Uncertainty: 231.26551818847656
Epoch 1, Batch 1300/3125, Loss: 53.769996643066406, Uncertainty: 197.44537353515625
Epoch 1, Batch 1400/3125, Loss: 58.57529067993164, Uncertainty: 213.67886352539062
Epoch 1, Batch 1500/3125, Loss: 53.782779693603516, Uncertainty: 183.97964477539062
Epoch 1, Batch 1600/3125, Loss: 49.75353240966797, Uncertainty: 171.11306762695312
Epoch 1, Batch 1700/3125, Loss: 46.470211029052734, Uncertainty: 173.4202880859375
Epoch 1, Batch 1800/3125, Loss: 31.59404754638672, Uncertainty: 115.17648315429688
Epoch 1, Batch 1900/3125, Loss: 37.42496871948242, Uncertainty: 117.17579650878906
Epoch 1, Batch 2000/3125, Loss: 31.284799575805664, Uncertainty: 93.6933822631836
Epoch 1, Batch 2100/3125, Loss: 28.64510726928711, Uncertainty: 77.63701629638672
Epoch 1, Batch 2200/3125, Loss: 23.83670425415039, Uncertainty: 61.59880828857422
Epoch 1, Batch 2300/3125, Loss: 19.56686019897461, Uncertainty: 45.0213623046875
Epoch 1, Batch 2400/3125, Loss: 19.205982208251953, Uncertainty: 45.131011962890625
Epoch 1, Batch 2500/3125, Loss: 27.945932388305664, Uncertainty: 64.70088958740234
Epoch 1, Batch 2600/3125, Loss: 13.857990264892578, Uncertainty: 46.72776412963867
Epoch 1, Batch 2700/3125, Loss: 21.838886260986328, Uncertainty: 85.01937866210938
Epoch 1, Batch 2800/3125, Loss: 15.627107620239258, Uncertainty: 49.3578987121582
Epoch 1, Batch 2900/3125, Loss: 21.98887825012207, Uncertainty: 35.592132568359375
Epoch 1, Batch 3000/3125, Loss: 12.164628982543945, Uncertainty: 38.82464599609375
Epoch 1, Batch 3100/3125, Loss: 10.084636688232422, Uncertainty: 17.875141143798828

Training and Validation Results of Epoch 1:
================================
Training Loss: 49.33693125976563, Training Uncertainty: 196.35019323303223, time: 135.83716106414795
Validation Loss: 9.023524081920419, Validation Uncertainty: 29.26602936522735, time: 31.191457986831665
Number of predictions within uncertainty interval: 155134/200000 (77.57%)

Epoch 2, Batch 100/3125, Loss: 11.986543655395508, Uncertainty: 34.364891052246094
Epoch 2, Batch 200/3125, Loss: 14.112003326416016, Uncertainty: 14.227437973022461
Epoch 2, Batch 300/3125, Loss: 19.484352111816406, Uncertainty: 16.69614028930664
Epoch 2, Batch 400/3125, Loss: 17.1325740814209, Uncertainty: 22.364845275878906
Epoch 2, Batch 500/3125, Loss: 19.869510650634766, Uncertainty: 17.407072067260742
Epoch 2, Batch 600/3125, Loss: 11.4228515625, Uncertainty: 33.18235397338867
Epoch 2, Batch 700/3125, Loss: 8.822439193725586, Uncertainty: 20.681392669677734
Epoch 2, Batch 800/3125, Loss: 9.235210418701172, Uncertainty: 13.386788368225098
Epoch 2, Batch 900/3125, Loss: 12.786453247070312, Uncertainty: 12.927459716796875
Epoch 2, Batch 1000/3125, Loss: 16.274917602539062, Uncertainty: 9.301606178283691
Epoch 2, Batch 1100/3125, Loss: 18.20707893371582, Uncertainty: 10.124961853027344
Epoch 2, Batch 1200/3125, Loss: 7.592704772949219, Uncertainty: 11.6990966796875
Epoch 2, Batch 1300/3125, Loss: 23.20207405090332, Uncertainty: 86.50192260742188
Epoch 2, Batch 1400/3125, Loss: 33.86277389526367, Uncertainty: 130.9157257080078
Epoch 2, Batch 1500/3125, Loss: 16.44515037536621, Uncertainty: 68.73823547363281
Epoch 2, Batch 1600/3125, Loss: 25.951099395751953, Uncertainty: 110.10118865966797
Epoch 2, Batch 1700/3125, Loss: 30.087032318115234, Uncertainty: 117.94801330566406
Epoch 2, Batch 1800/3125, Loss: 10.975374221801758, Uncertainty: 31.777606964111328
Epoch 2, Batch 1900/3125, Loss: 8.255455017089844, Uncertainty: 14.967632293701172
Epoch 2, Batch 2000/3125, Loss: 10.216262817382812, Uncertainty: 34.10337448120117
Epoch 2, Batch 2100/3125, Loss: 12.328758239746094, Uncertainty: 40.86375427246094
Epoch 2, Batch 2200/3125, Loss: 19.91615104675293, Uncertainty: 82.27180480957031
Epoch 2, Batch 2300/3125, Loss: 18.452404022216797, Uncertainty: 76.63506317138672
Epoch 2, Batch 2400/3125, Loss: 18.403478622436523, Uncertainty: 75.849609375
Epoch 2, Batch 2500/3125, Loss: 17.614145278930664, Uncertainty: 72.00471496582031
Epoch 2, Batch 2600/3125, Loss: 11.113763809204102, Uncertainty: 39.23564910888672
Epoch 2, Batch 2700/3125, Loss: 12.908660888671875, Uncertainty: 19.967391967773438
Epoch 2, Batch 2800/3125, Loss: 9.195352554321289, Uncertainty: 27.249988555908203
Epoch 2, Batch 2900/3125, Loss: 9.655364990234375, Uncertainty: 14.433820724487305
Epoch 2, Batch 3000/3125, Loss: 11.31094741821289, Uncertainty: 22.777149200439453
Epoch 2, Batch 3100/3125, Loss: 17.003355026245117, Uncertainty: 17.582454681396484

Training and Validation Results of Epoch 2:
================================
Training Loss: 11.712969478759765, Training Uncertainty: 46.81776237991333, time: 138.17823767662048
Validation Loss: 17.55096959457983, Validation Uncertainty: 10.287280455879543, time: 31.294424533843994
Number of predictions within uncertainty interval: 15315/200000 (7.66%)

Epoch 3, Batch 100/3125, Loss: 15.530912399291992, Uncertainty: 65.05094146728516
Epoch 3, Batch 200/3125, Loss: 16.21776580810547, Uncertainty: 68.57749938964844
Epoch 3, Batch 300/3125, Loss: 15.477121353149414, Uncertainty: 64.9591293334961
Epoch 3, Batch 400/3125, Loss: 16.21186065673828, Uncertainty: 67.63809204101562
Epoch 3, Batch 500/3125, Loss: 14.737699508666992, Uncertainty: 61.35682678222656
Epoch 3, Batch 600/3125, Loss: 15.10068130493164, Uncertainty: 63.356658935546875
Epoch 3, Batch 700/3125, Loss: 8.618986129760742, Uncertainty: 27.664405822753906
Epoch 3, Batch 800/3125, Loss: 7.345447540283203, Uncertainty: 8.860031127929688
Epoch 3, Batch 900/3125, Loss: 9.029365539550781, Uncertainty: 30.801837921142578
Epoch 3, Batch 1000/3125, Loss: 6.827545166015625, Uncertainty: 11.32018756866455
Epoch 3, Batch 1100/3125, Loss: 8.392873764038086, Uncertainty: 20.671892166137695
Epoch 3, Batch 1200/3125, Loss: 13.710054397583008, Uncertainty: 19.16408920288086
Epoch 3, Batch 1300/3125, Loss: 11.276031494140625, Uncertainty: 44.15064239501953
Epoch 3, Batch 1400/3125, Loss: 7.479135513305664, Uncertainty: 22.164596557617188
Epoch 3, Batch 1500/3125, Loss: 9.283185958862305, Uncertainty: 18.797077178955078
Epoch 3, Batch 1600/3125, Loss: 9.514766693115234, Uncertainty: 35.56378936767578
Epoch 3, Batch 1700/3125, Loss: 15.034435272216797, Uncertainty: 55.957298278808594
Epoch 3, Batch 1800/3125, Loss: 23.305150985717773, Uncertainty: 98.83635711669922
Epoch 3, Batch 1900/3125, Loss: 27.09560203552246, Uncertainty: 72.99411010742188
Epoch 3, Batch 2000/3125, Loss: 13.215682983398438, Uncertainty: 54.02643966674805
Epoch 3, Batch 2100/3125, Loss: 13.91987419128418, Uncertainty: 58.19507598876953
Epoch 3, Batch 2200/3125, Loss: 12.888872146606445, Uncertainty: 20.582294464111328
Epoch 3, Batch 2300/3125, Loss: 9.800666809082031, Uncertainty: 37.64666748046875
Epoch 3, Batch 2400/3125, Loss: 6.70823860168457, Uncertainty: 9.075275421142578
Epoch 3, Batch 2500/3125, Loss: 16.506961822509766, Uncertainty: 46.78525161743164
Epoch 3, Batch 2600/3125, Loss: 10.304397583007812, Uncertainty: 41.17569351196289
Epoch 3, Batch 2700/3125, Loss: 12.096492767333984, Uncertainty: 39.20957946777344
Epoch 3, Batch 2800/3125, Loss: 16.620464324951172, Uncertainty: 9.315653800964355
Epoch 3, Batch 2900/3125, Loss: 9.662982940673828, Uncertainty: 27.110536575317383
Epoch 3, Batch 3000/3125, Loss: 11.269403457641602, Uncertainty: 38.3719482421875
Epoch 3, Batch 3100/3125, Loss: 6.990232467651367, Uncertainty: 15.924509048461914

Training and Validation Results of Epoch 3:
================================
Training Loss: 10.214035988769531, Training Uncertainty: 36.857603340301516, time: 139.07836508750916
Validation Loss: 7.3009483942290405, Validation Uncertainty: 7.767197963831674, time: 31.280699491500854
Number of predictions within uncertainty interval: 56552/200000 (28.28%)

Epoch 4, Batch 100/3125, Loss: 6.284749984741211, Uncertainty: 7.393280029296875
Epoch 4, Batch 200/3125, Loss: 7.5287933349609375, Uncertainty: 9.82829475402832
Epoch 4, Batch 300/3125, Loss: 16.443016052246094, Uncertainty: 21.91628646850586
Epoch 4, Batch 400/3125, Loss: 32.84681701660156, Uncertainty: 95.35470581054688
Epoch 4, Batch 500/3125, Loss: 25.00084114074707, Uncertainty: 105.28912353515625
Epoch 4, Batch 600/3125, Loss: 25.016870498657227, Uncertainty: 38.73150634765625
Epoch 4, Batch 700/3125, Loss: 20.148527145385742, Uncertainty: 83.58333587646484
Epoch 4, Batch 800/3125, Loss: 12.12611198425293, Uncertainty: 47.920108795166016
Epoch 4, Batch 900/3125, Loss: 11.754417419433594, Uncertainty: 20.968379974365234
Epoch 4, Batch 1000/3125, Loss: 10.345426559448242, Uncertainty: 25.99516487121582
Epoch 4, Batch 1100/3125, Loss: 5.5381317138671875, Uncertainty: 10.542155265808105
Epoch 4, Batch 1200/3125, Loss: 7.67597770690918, Uncertainty: 21.603660583496094
Epoch 4, Batch 1300/3125, Loss: 16.693470001220703, Uncertainty: 67.9111557006836
Epoch 4, Batch 1400/3125, Loss: 13.172447204589844, Uncertainty: 36.940757751464844
Epoch 4, Batch 1500/3125, Loss: 10.906034469604492, Uncertainty: 40.94274139404297
Epoch 4, Batch 1600/3125, Loss: 10.894588470458984, Uncertainty: 35.99097442626953
Epoch 4, Batch 1700/3125, Loss: 11.866575241088867, Uncertainty: 47.94265365600586
Epoch 4, Batch 1800/3125, Loss: 15.554105758666992, Uncertainty: 27.41375732421875
Epoch 4, Batch 1900/3125, Loss: 16.594711303710938, Uncertainty: 14.431328773498535
Epoch 4, Batch 2000/3125, Loss: 11.315670013427734, Uncertainty: 6.916382789611816
Epoch 4, Batch 2100/3125, Loss: 10.345149993896484, Uncertainty: 13.153846740722656
Epoch 4, Batch 2200/3125, Loss: 12.245182037353516, Uncertainty: 50.54838180541992
Epoch 4, Batch 2300/3125, Loss: 31.70762062072754, Uncertainty: 96.81179809570312
Epoch 4, Batch 2400/3125, Loss: 15.089605331420898, Uncertainty: 63.57140350341797
Epoch 4, Batch 2500/3125, Loss: 17.02509117126465, Uncertainty: 60.78498077392578
Epoch 4, Batch 2600/3125, Loss: 5.874538421630859, Uncertainty: 11.029888153076172
Epoch 4, Batch 2700/3125, Loss: 5.793695449829102, Uncertainty: 8.817878723144531
Epoch 4, Batch 2800/3125, Loss: 22.536375045776367, Uncertainty: 95.61373901367188
Epoch 4, Batch 2900/3125, Loss: 15.01011848449707, Uncertainty: 61.998390197753906
Epoch 4, Batch 3000/3125, Loss: 13.997491836547852, Uncertainty: 57.596527099609375
Epoch 4, Batch 3100/3125, Loss: 17.70047950744629, Uncertainty: 74.57272338867188

Training and Validation Results of Epoch 4:
================================
Training Loss: 9.988435399169921, Training Uncertainty: 39.46940659439087, time: 143.50526547431946
Validation Loss: 5.416577648933586, Validation Uncertainty: 52.492584321200084, time: 30.817264318466187
Number of predictions within uncertainty interval: 199926/200000 (99.96%)

Epoch 5, Batch 100/3125, Loss: 16.22920799255371, Uncertainty: 68.7260971069336
Epoch 5, Batch 200/3125, Loss: 11.46122932434082, Uncertainty: 47.08205032348633
Epoch 5, Batch 300/3125, Loss: 10.693016052246094, Uncertainty: 29.96892547607422
Epoch 5, Batch 400/3125, Loss: 8.767269134521484, Uncertainty: 26.934741973876953
Epoch 5, Batch 500/3125, Loss: 9.332906723022461, Uncertainty: 19.118562698364258
Epoch 5, Batch 600/3125, Loss: 6.82868766784668, Uncertainty: 12.78048038482666
Epoch 5, Batch 700/3125, Loss: 8.50039291381836, Uncertainty: 23.75514030456543
Epoch 5, Batch 800/3125, Loss: 9.118667602539062, Uncertainty: 23.59915542602539
Epoch 5, Batch 900/3125, Loss: 14.613666534423828, Uncertainty: 61.278358459472656
Epoch 5, Batch 1000/3125, Loss: 15.141485214233398, Uncertainty: 62.49622344970703
Epoch 5, Batch 1100/3125, Loss: 9.566627502441406, Uncertainty: 35.80318832397461
Epoch 5, Batch 1200/3125, Loss: 12.482994079589844, Uncertainty: 50.95033645629883
Epoch 5, Batch 1300/3125, Loss: 7.249656677246094, Uncertainty: 23.627235412597656
Epoch 5, Batch 1400/3125, Loss: 6.736915588378906, Uncertainty: 6.486639022827148
Epoch 5, Batch 1500/3125, Loss: 13.927864074707031, Uncertainty: 41.713890075683594
Epoch 5, Batch 1600/3125, Loss: 7.1792449951171875, Uncertainty: 11.214778900146484
Epoch 5, Batch 1700/3125, Loss: 5.507898330688477, Uncertainty: 7.541593551635742
Epoch 5, Batch 1800/3125, Loss: 10.186359405517578, Uncertainty: 8.731689453125
Epoch 5, Batch 1900/3125, Loss: 11.730573654174805, Uncertainty: 44.67094421386719
Epoch 5, Batch 2000/3125, Loss: 25.581560134887695, Uncertainty: 12.459026336669922
Epoch 5, Batch 2100/3125, Loss: 32.142311096191406, Uncertainty: 136.3682861328125
Epoch 5, Batch 2200/3125, Loss: 17.681026458740234, Uncertainty: 9.254314422607422
Epoch 5, Batch 2300/3125, Loss: 21.769065856933594, Uncertainty: 6.860821723937988
Epoch 5, Batch 2400/3125, Loss: 26.116731643676758, Uncertainty: 110.77345275878906
Epoch 5, Batch 2500/3125, Loss: 9.096294403076172, Uncertainty: 10.540116310119629
Epoch 5, Batch 2600/3125, Loss: 7.749828338623047, Uncertainty: 10.51143741607666
Epoch 5, Batch 2700/3125, Loss: 6.440797805786133, Uncertainty: 17.07382583618164
Epoch 5, Batch 2800/3125, Loss: 9.281293869018555, Uncertainty: 11.454137802124023
Epoch 5, Batch 2900/3125, Loss: 7.268289566040039, Uncertainty: 11.893625259399414
Epoch 5, Batch 3000/3125, Loss: 8.25344467163086, Uncertainty: 16.921960830688477
Epoch 5, Batch 3100/3125, Loss: 9.695606231689453, Uncertainty: 40.14278793334961

Training and Validation Results of Epoch 5:
================================
Training Loss: 8.528928555908204, Training Uncertainty: 36.296259002532956, time: 135.15337896347046
Validation Loss: 6.907503240248737, Validation Uncertainty: 40.069205184116996, time: 30.723119020462036
Number of predictions within uncertainty interval: 194088/200000 (97.04%)

Epoch 6, Batch 100/3125, Loss: 13.977609634399414, Uncertainty: 21.4005126953125
Epoch 6, Batch 200/3125, Loss: 15.393136978149414, Uncertainty: 15.605287551879883
Epoch 6, Batch 300/3125, Loss: 10.021444320678711, Uncertainty: 38.768402099609375
Epoch 6, Batch 400/3125, Loss: 13.92220687866211, Uncertainty: 56.10852813720703
Epoch 6, Batch 500/3125, Loss: 8.799310684204102, Uncertainty: 26.184650421142578
Epoch 6, Batch 600/3125, Loss: 8.236865997314453, Uncertainty: 31.013755798339844
Epoch 6, Batch 700/3125, Loss: 6.861186981201172, Uncertainty: 20.803009033203125
Epoch 6, Batch 800/3125, Loss: 5.665685653686523, Uncertainty: 8.895450592041016
Epoch 6, Batch 900/3125, Loss: 6.603294372558594, Uncertainty: 8.407013893127441
Epoch 6, Batch 1000/3125, Loss: 24.988420486450195, Uncertainty: 105.66001892089844
Epoch 6, Batch 1100/3125, Loss: 21.07052993774414, Uncertainty: 85.67634582519531
Epoch 6, Batch 1200/3125, Loss: 36.68487548828125, Uncertainty: 155.5941162109375
Epoch 6, Batch 1300/3125, Loss: 16.37782859802246, Uncertainty: 8.70225715637207
Epoch 6, Batch 1400/3125, Loss: 14.891407012939453, Uncertainty: 13.643909454345703
Epoch 6, Batch 1500/3125, Loss: 16.557199478149414, Uncertainty: 8.07550048828125
Epoch 6, Batch 1600/3125, Loss: 13.390233993530273, Uncertainty: 7.771023750305176
Epoch 6, Batch 1700/3125, Loss: 18.446077346801758, Uncertainty: 18.257083892822266
Epoch 6, Batch 1800/3125, Loss: 8.343698501586914, Uncertainty: 30.702526092529297
Epoch 6, Batch 1900/3125, Loss: 10.3857421875, Uncertainty: 18.35484504699707
Epoch 6, Batch 2000/3125, Loss: 10.045854568481445, Uncertainty: 25.567005157470703
Epoch 6, Batch 2100/3125, Loss: 7.716917037963867, Uncertainty: 16.986722946166992
Epoch 6, Batch 2200/3125, Loss: 9.204984664916992, Uncertainty: 15.241592407226562
Epoch 6, Batch 2300/3125, Loss: 12.42567253112793, Uncertainty: 51.848304748535156
Epoch 6, Batch 2400/3125, Loss: 14.4019775390625, Uncertainty: 61.050899505615234
Epoch 6, Batch 2500/3125, Loss: 13.012319564819336, Uncertainty: 54.49047088623047
Epoch 6, Batch 2600/3125, Loss: 12.170591354370117, Uncertainty: 49.880523681640625
Epoch 6, Batch 2700/3125, Loss: 13.268289566040039, Uncertainty: 56.01078414916992
Epoch 6, Batch 2800/3125, Loss: 10.886062622070312, Uncertainty: 45.333412170410156
Epoch 6, Batch 2900/3125, Loss: 12.19795036315918, Uncertainty: 50.516780853271484
Epoch 6, Batch 3000/3125, Loss: 12.925979614257812, Uncertainty: 54.22974395751953
Epoch 6, Batch 3100/3125, Loss: 11.756114959716797, Uncertainty: 48.741458892822266

Training and Validation Results of Epoch 6:
================================
Training Loss: 9.174461033935547, Training Uncertainty: 33.05359813735962, time: 137.0176796913147
Validation Loss: 5.320080657139458, Validation Uncertainty: 15.50844796661221, time: 30.60403037071228
Number of predictions within uncertainty interval: 136121/200000 (68.06%)

Epoch 7, Batch 100/3125, Loss: 8.333351135253906, Uncertainty: 8.824684143066406
Epoch 7, Batch 200/3125, Loss: 10.028003692626953, Uncertainty: 38.53215026855469
Epoch 7, Batch 300/3125, Loss: 8.445053100585938, Uncertainty: 26.9681453704834
Epoch 7, Batch 400/3125, Loss: 11.300714492797852, Uncertainty: 47.29560089111328
Epoch 7, Batch 500/3125, Loss: 15.547161102294922, Uncertainty: 10.488569259643555
Epoch 7, Batch 600/3125, Loss: 14.294271469116211, Uncertainty: 16.22909927368164
Epoch 7, Batch 700/3125, Loss: 11.460485458374023, Uncertainty: 8.806241989135742
Epoch 7, Batch 800/3125, Loss: 11.91287612915039, Uncertainty: 40.427734375
Epoch 7, Batch 900/3125, Loss: 11.03416633605957, Uncertainty: 24.72867202758789
Epoch 7, Batch 1000/3125, Loss: 9.602163314819336, Uncertainty: 38.85021209716797
Epoch 7, Batch 1100/3125, Loss: 15.01862907409668, Uncertainty: 62.876312255859375
Epoch 7, Batch 1200/3125, Loss: 15.308298110961914, Uncertainty: 64.23434448242188
Epoch 7, Batch 1300/3125, Loss: 23.01078224182129, Uncertainty: 97.05012512207031
Epoch 7, Batch 1400/3125, Loss: 14.528833389282227, Uncertainty: 10.270120620727539
Epoch 7, Batch 1500/3125, Loss: 10.209096908569336, Uncertainty: 27.20621109008789
Epoch 7, Batch 1600/3125, Loss: 10.196329116821289, Uncertainty: 38.39643859863281
Epoch 7, Batch 1700/3125, Loss: 9.468366622924805, Uncertainty: 29.052574157714844
Epoch 7, Batch 1800/3125, Loss: 10.48208999633789, Uncertainty: 38.83042907714844
Epoch 7, Batch 1900/3125, Loss: 10.308794021606445, Uncertainty: 37.789310455322266
Epoch 7, Batch 2000/3125, Loss: 11.681093215942383, Uncertainty: 28.244537353515625
Epoch 7, Batch 2100/3125, Loss: 12.014694213867188, Uncertainty: 11.240900039672852
Epoch 7, Batch 2200/3125, Loss: 7.633317947387695, Uncertainty: 30.53240966796875
Epoch 7, Batch 2300/3125, Loss: 7.420663833618164, Uncertainty: 23.15991973876953
Epoch 7, Batch 2400/3125, Loss: 15.631635665893555, Uncertainty: 23.924339294433594
Epoch 7, Batch 2500/3125, Loss: 15.221977233886719, Uncertainty: 13.589498519897461
Epoch 7, Batch 2600/3125, Loss: 7.053655624389648, Uncertainty: 24.24964714050293
Epoch 7, Batch 2700/3125, Loss: 7.392974853515625, Uncertainty: 10.469422340393066
Epoch 7, Batch 2800/3125, Loss: 19.117082595825195, Uncertainty: 40.228492736816406
Epoch 7, Batch 2900/3125, Loss: 24.714942932128906, Uncertainty: 104.56849670410156
Epoch 7, Batch 3000/3125, Loss: 8.882867813110352, Uncertainty: 34.22578430175781
Epoch 7, Batch 3100/3125, Loss: 8.841297149658203, Uncertainty: 8.079296112060547

Training and Validation Results of Epoch 7:
================================
Training Loss: 9.205959454345702, Training Uncertainty: 30.788424565582275, time: 142.56262350082397
Validation Loss: 7.598501059100451, Validation Uncertainty: 17.171448490503803, time: 30.641862392425537
Number of predictions within uncertainty interval: 117010/200000 (58.50%)

Epoch 8, Batch 100/3125, Loss: 11.557456970214844, Uncertainty: 48.13290786743164
Epoch 8, Batch 200/3125, Loss: 15.880874633789062, Uncertainty: 67.07424926757812
Epoch 8, Batch 300/3125, Loss: 21.23638153076172, Uncertainty: 89.38340759277344
Epoch 8, Batch 400/3125, Loss: 11.07682991027832, Uncertainty: 33.277462005615234
Epoch 8, Batch 500/3125, Loss: 15.258796691894531, Uncertainty: 64.16390991210938
Epoch 8, Batch 600/3125, Loss: 14.699531555175781, Uncertainty: 61.23407745361328
Epoch 8, Batch 700/3125, Loss: 16.073373794555664, Uncertainty: 67.6746826171875
Epoch 8, Batch 800/3125, Loss: 11.921436309814453, Uncertainty: 48.1483154296875
Epoch 8, Batch 900/3125, Loss: 15.031494140625, Uncertainty: 63.44407272338867
Epoch 8, Batch 1000/3125, Loss: 9.48238754272461, Uncertainty: 37.66271209716797
Epoch 8, Batch 1100/3125, Loss: 10.805170059204102, Uncertainty: 7.455007076263428
Epoch 8, Batch 1200/3125, Loss: 7.933811187744141, Uncertainty: 27.797775268554688
Epoch 8, Batch 1300/3125, Loss: 6.597208023071289, Uncertainty: 19.264238357543945
Epoch 8, Batch 1400/3125, Loss: 9.048629760742188, Uncertainty: 36.694297790527344
Epoch 8, Batch 1500/3125, Loss: 10.398664474487305, Uncertainty: 19.623191833496094
Epoch 8, Batch 1600/3125, Loss: 7.38311767578125, Uncertainty: 23.896007537841797
Epoch 8, Batch 1700/3125, Loss: 12.545974731445312, Uncertainty: 11.092214584350586
Epoch 8, Batch 1800/3125, Loss: 12.900911331176758, Uncertainty: 8.00606918334961
Epoch 8, Batch 1900/3125, Loss: 8.145326614379883, Uncertainty: 25.810970306396484
Epoch 8, Batch 2000/3125, Loss: 10.042715072631836, Uncertainty: 34.33674621582031
Epoch 8, Batch 2100/3125, Loss: 8.185474395751953, Uncertainty: 29.82587242126465
Epoch 8, Batch 2200/3125, Loss: 7.396945953369141, Uncertainty: 24.9346923828125
Epoch 8, Batch 2300/3125, Loss: 14.038278579711914, Uncertainty: 9.607046127319336
Epoch 8, Batch 2400/3125, Loss: 13.520978927612305, Uncertainty: 11.89979076385498
Epoch 8, Batch 2500/3125, Loss: 13.028879165649414, Uncertainty: 10.747333526611328
Epoch 8, Batch 2600/3125, Loss: 12.466594696044922, Uncertainty: 13.276119232177734
Epoch 8, Batch 2700/3125, Loss: 12.993059158325195, Uncertainty: 11.018049240112305
Epoch 8, Batch 2800/3125, Loss: 10.530879974365234, Uncertainty: 7.144631385803223
Epoch 8, Batch 2900/3125, Loss: 15.448713302612305, Uncertainty: 7.594257831573486
Epoch 8, Batch 3000/3125, Loss: 9.6787109375, Uncertainty: 14.317827224731445
Epoch 8, Batch 3100/3125, Loss: 7.261312484741211, Uncertainty: 6.672573089599609

Training and Validation Results of Epoch 8:
================================
Training Loss: 8.576132044677735, Training Uncertainty: 32.3359853453064, time: 135.6974139213562
Validation Loss: 14.17697050382414, Validation Uncertainty: 11.203750220101202, time: 30.013832092285156
Number of predictions within uncertainty interval: 19984/200000 (9.99%)

Epoch 9, Batch 100/3125, Loss: 9.636194229125977, Uncertainty: 8.895952224731445
Epoch 9, Batch 200/3125, Loss: 10.953636169433594, Uncertainty: 10.233389854431152
Epoch 9, Batch 300/3125, Loss: 10.827438354492188, Uncertainty: 43.844112396240234
Epoch 9, Batch 400/3125, Loss: 11.343364715576172, Uncertainty: 31.51699447631836
Epoch 9, Batch 500/3125, Loss: 8.316761016845703, Uncertainty: 18.95026969909668
Epoch 9, Batch 600/3125, Loss: 15.60560417175293, Uncertainty: 27.979516983032227
Epoch 9, Batch 700/3125, Loss: 10.196184158325195, Uncertainty: 36.51239776611328
Epoch 9, Batch 800/3125, Loss: 11.225204467773438, Uncertainty: 19.30339813232422
Epoch 9, Batch 900/3125, Loss: 8.217096328735352, Uncertainty: 28.6136531829834
Epoch 9, Batch 1000/3125, Loss: 10.052286148071289, Uncertainty: 33.142967224121094
Epoch 9, Batch 1100/3125, Loss: 14.631231307983398, Uncertainty: 61.055389404296875
Epoch 9, Batch 1200/3125, Loss: 11.572500228881836, Uncertainty: 11.888786315917969
Epoch 9, Batch 1300/3125, Loss: 10.642158508300781, Uncertainty: 8.963545799255371
Epoch 9, Batch 1400/3125, Loss: 6.065238952636719, Uncertainty: 12.463096618652344
Epoch 9, Batch 1500/3125, Loss: 9.286870956420898, Uncertainty: 28.42635154724121
Epoch 9, Batch 1600/3125, Loss: 8.584888458251953, Uncertainty: 34.682498931884766
Epoch 9, Batch 1700/3125, Loss: 32.702606201171875, Uncertainty: 138.41033935546875
Epoch 9, Batch 1800/3125, Loss: 12.252786636352539, Uncertainty: 51.751956939697266
Epoch 9, Batch 1900/3125, Loss: 8.442991256713867, Uncertainty: 25.109424591064453
Epoch 9, Batch 2000/3125, Loss: 7.324239730834961, Uncertainty: 27.77267837524414
Epoch 9, Batch 2100/3125, Loss: 13.898794174194336, Uncertainty: 24.127567291259766
Epoch 9, Batch 2200/3125, Loss: 7.484962463378906, Uncertainty: 24.037979125976562
Epoch 9, Batch 2300/3125, Loss: 8.63892936706543, Uncertainty: 12.369171142578125
Epoch 9, Batch 2400/3125, Loss: 7.981605529785156, Uncertainty: 31.990306854248047
Epoch 9, Batch 2500/3125, Loss: 23.850128173828125, Uncertainty: 101.11144256591797
Epoch 9, Batch 2600/3125, Loss: 12.368066787719727, Uncertainty: 20.818893432617188
Epoch 9, Batch 2700/3125, Loss: 15.709383010864258, Uncertainty: 9.45895767211914
Epoch 9, Batch 2800/3125, Loss: 10.704849243164062, Uncertainty: 32.51300048828125
Epoch 9, Batch 2900/3125, Loss: 9.611196517944336, Uncertainty: 27.634578704833984
Epoch 9, Batch 3000/3125, Loss: 15.555194854736328, Uncertainty: 54.72319412231445
Epoch 9, Batch 3100/3125, Loss: 24.224885940551758, Uncertainty: 102.59183502197266

Training and Validation Results of Epoch 9:
================================
Training Loss: 8.858564422607422, Training Uncertainty: 28.421843942260743, time: 145.53559017181396
Validation Loss: 7.387757664751214, Validation Uncertainty: 84.23949157246544, time: 30.708505630493164
Number of predictions within uncertainty interval: 200000/200000 (100.00%)

Epoch 10, Batch 100/3125, Loss: 10.35664176940918, Uncertainty: 30.221927642822266
Epoch 10, Batch 200/3125, Loss: 9.375085830688477, Uncertainty: 13.492140769958496
Epoch 10, Batch 300/3125, Loss: 14.685342788696289, Uncertainty: 15.908843994140625
Epoch 10, Batch 400/3125, Loss: 13.387542724609375, Uncertainty: 14.092881202697754
Epoch 10, Batch 500/3125, Loss: 13.406913757324219, Uncertainty: 20.15241241455078
Epoch 10, Batch 600/3125, Loss: 12.881830215454102, Uncertainty: 53.91661834716797
Epoch 10, Batch 700/3125, Loss: 5.364725112915039, Uncertainty: 12.874527931213379
Epoch 10, Batch 800/3125, Loss: 4.294164657592773, Uncertainty: 9.40729808807373
Epoch 10, Batch 900/3125, Loss: 18.382829666137695, Uncertainty: 59.53373718261719
Epoch 10, Batch 1000/3125, Loss: 29.709794998168945, Uncertainty: 126.04798126220703
Epoch 10, Batch 1100/3125, Loss: 11.93374252319336, Uncertainty: 23.6279296875
Epoch 10, Batch 1200/3125, Loss: 14.732141494750977, Uncertainty: 61.38153839111328
Epoch 10, Batch 1300/3125, Loss: 17.872804641723633, Uncertainty: 74.99442291259766
Epoch 10, Batch 1400/3125, Loss: 22.092798233032227, Uncertainty: 35.83525848388672
Epoch 10, Batch 1500/3125, Loss: 25.99565315246582, Uncertainty: 110.05669403076172
Epoch 10, Batch 1600/3125, Loss: 24.481651306152344, Uncertainty: 32.37247085571289
Epoch 10, Batch 1700/3125, Loss: 14.647478103637695, Uncertainty: 61.530452728271484
Epoch 10, Batch 1800/3125, Loss: 16.152469635009766, Uncertainty: 67.67941284179688
Epoch 10, Batch 1900/3125, Loss: 20.70163345336914, Uncertainty: 29.341442108154297
Epoch 10, Batch 2000/3125, Loss: 24.388418197631836, Uncertainty: 103.34738159179688
Epoch 10, Batch 2100/3125, Loss: 22.855144500732422, Uncertainty: 7.5804443359375
Epoch 10, Batch 2200/3125, Loss: 16.538084030151367, Uncertainty: 65.43827056884766
Epoch 10, Batch 2300/3125, Loss: 17.53948402404785, Uncertainty: 74.18753814697266
Epoch 10, Batch 2400/3125, Loss: 20.315725326538086, Uncertainty: 85.92993927001953
Epoch 10, Batch 2500/3125, Loss: 10.30866813659668, Uncertainty: 31.026308059692383
Epoch 10, Batch 2600/3125, Loss: 9.609073638916016, Uncertainty: 23.5908203125
Epoch 10, Batch 2700/3125, Loss: 9.874814987182617, Uncertainty: 37.681053161621094
Epoch 10, Batch 2800/3125, Loss: 6.4557037353515625, Uncertainty: 23.325687408447266
Epoch 10, Batch 2900/3125, Loss: 12.100120544433594, Uncertainty: 22.908550262451172
Epoch 10, Batch 3000/3125, Loss: 6.089878082275391, Uncertainty: 6.24977970123291
Epoch 10, Batch 3100/3125, Loss: 6.0668487548828125, Uncertainty: 13.511861801147461

Training and Validation Results of Epoch 10:
================================
Training Loss: 10.369963038330079, Training Uncertainty: 38.97542292114258, time: 137.0475950241089
Validation Loss: 4.047512981287964, Validation Uncertainty: 18.875113396998255, time: 30.621398210525513
Number of predictions within uncertainty interval: 169846/200000 (84.92%)

Epoch 11, Batch 100/3125, Loss: 11.237159729003906, Uncertainty: 11.595791816711426
Epoch 11, Batch 200/3125, Loss: 6.491601943969727, Uncertainty: 9.762901306152344
Epoch 11, Batch 300/3125, Loss: 11.610712051391602, Uncertainty: 45.10614776611328
Epoch 11, Batch 400/3125, Loss: 11.687284469604492, Uncertainty: 39.16050338745117
Epoch 11, Batch 500/3125, Loss: 22.61578941345215, Uncertainty: 95.95066833496094
Epoch 11, Batch 600/3125, Loss: 33.950111389160156, Uncertainty: 17.2257022857666
Epoch 11, Batch 700/3125, Loss: 13.018844604492188, Uncertainty: 37.134063720703125
Epoch 11, Batch 800/3125, Loss: 14.305553436279297, Uncertainty: 55.319068908691406
Epoch 11, Batch 900/3125, Loss: 21.469167709350586, Uncertainty: 33.589752197265625
Epoch 11, Batch 1000/3125, Loss: 15.952505111694336, Uncertainty: 66.96296691894531
Epoch 11, Batch 1100/3125, Loss: 15.517972946166992, Uncertainty: 32.13825988769531
Epoch 11, Batch 1200/3125, Loss: 23.3704776763916, Uncertainty: 99.15254211425781
Epoch 11, Batch 1300/3125, Loss: 8.596891403198242, Uncertainty: 33.222206115722656
Epoch 11, Batch 1400/3125, Loss: 11.881189346313477, Uncertainty: 46.49748229980469
Epoch 11, Batch 1500/3125, Loss: 27.836488723754883, Uncertainty: 118.1002197265625
Epoch 11, Batch 1600/3125, Loss: 15.719158172607422, Uncertainty: 66.28224182128906
Epoch 11, Batch 1700/3125, Loss: 16.17051887512207, Uncertainty: 68.57987976074219
Epoch 11, Batch 1800/3125, Loss: 24.274105072021484, Uncertainty: 14.516263961791992
Epoch 11, Batch 1900/3125, Loss: 6.739030838012695, Uncertainty: 17.984119415283203
Epoch 11, Batch 2000/3125, Loss: 12.325990676879883, Uncertainty: 43.90106964111328
Epoch 11, Batch 2100/3125, Loss: 8.949209213256836, Uncertainty: 34.905723571777344
Epoch 11, Batch 2200/3125, Loss: 8.848686218261719, Uncertainty: 31.498077392578125
Epoch 11, Batch 2300/3125, Loss: 6.508352279663086, Uncertainty: 8.241860389709473
Epoch 11, Batch 2400/3125, Loss: 10.229883193969727, Uncertainty: 40.70466995239258
Epoch 11, Batch 2500/3125, Loss: 8.902647018432617, Uncertainty: 24.403057098388672
Epoch 11, Batch 2600/3125, Loss: 12.88599967956543, Uncertainty: 6.15915584564209
Epoch 11, Batch 2700/3125, Loss: 13.87554931640625, Uncertainty: 6.946000099182129
Epoch 11, Batch 2800/3125, Loss: 13.888103485107422, Uncertainty: 58.911224365234375
Epoch 11, Batch 2900/3125, Loss: 8.399866104125977, Uncertainty: 16.97955322265625
Epoch 11, Batch 3000/3125, Loss: 10.77398681640625, Uncertainty: 44.872257232666016
Epoch 11, Batch 3100/3125, Loss: 5.985340118408203, Uncertainty: 12.110681533813477

Training and Validation Results of Epoch 11:
================================
Training Loss: 10.146050313720703, Training Uncertainty: 36.8077425378418, time: 134.99439430236816
Validation Loss: 5.78672575401833, Validation Uncertainty: 8.273101368828502, time: 30.528762102127075
Number of predictions within uncertainty interval: 73296/200000 (36.65%)

Epoch 12, Batch 100/3125, Loss: 10.421272277832031, Uncertainty: 43.150238037109375
Epoch 12, Batch 200/3125, Loss: 9.554975509643555, Uncertainty: 39.493072509765625
Epoch 12, Batch 300/3125, Loss: 11.956560134887695, Uncertainty: 22.206302642822266
Epoch 12, Batch 400/3125, Loss: 11.461906433105469, Uncertainty: 16.28939437866211
Epoch 12, Batch 500/3125, Loss: 10.948053359985352, Uncertainty: 7.529714584350586
Epoch 12, Batch 600/3125, Loss: 10.509088516235352, Uncertainty: 7.7852983474731445
Epoch 12, Batch 700/3125, Loss: 11.600566864013672, Uncertainty: 7.308546543121338
Epoch 12, Batch 800/3125, Loss: 10.059307098388672, Uncertainty: 41.541107177734375
Epoch 12, Batch 900/3125, Loss: 13.908958435058594, Uncertainty: 23.03391456604004
Epoch 12, Batch 1000/3125, Loss: 12.122201919555664, Uncertainty: 7.5652875900268555
Epoch 12, Batch 1100/3125, Loss: 13.818235397338867, Uncertainty: 58.45323181152344
Epoch 12, Batch 1200/3125, Loss: 14.383127212524414, Uncertainty: 7.016669273376465
Epoch 12, Batch 1300/3125, Loss: 13.918210983276367, Uncertainty: 7.883634567260742
Epoch 12, Batch 1400/3125, Loss: 14.476448059082031, Uncertainty: 7.071558952331543
Epoch 12, Batch 1500/3125, Loss: 11.640464782714844, Uncertainty: 10.989362716674805
Epoch 12, Batch 1600/3125, Loss: 11.272085189819336, Uncertainty: 34.14263153076172
Epoch 12, Batch 1700/3125, Loss: 4.273990631103516, Uncertainty: 6.774979591369629
Epoch 12, Batch 1800/3125, Loss: 6.534700393676758, Uncertainty: 11.084308624267578
Epoch 12, Batch 1900/3125, Loss: 10.1268310546875, Uncertainty: 41.0156135559082
Epoch 12, Batch 2000/3125, Loss: 12.114953994750977, Uncertainty: 50.51512908935547
Epoch 12, Batch 2100/3125, Loss: 17.64543914794922, Uncertainty: 74.42138671875
Epoch 12, Batch 2200/3125, Loss: 10.561616897583008, Uncertainty: 43.37885284423828
Epoch 12, Batch 2300/3125, Loss: 11.081714630126953, Uncertainty: 7.111145496368408
Epoch 12, Batch 2400/3125, Loss: 12.122358322143555, Uncertainty: 10.374833106994629
Epoch 12, Batch 2500/3125, Loss: 20.243236541748047, Uncertainty: 34.384124755859375
Epoch 12, Batch 2600/3125, Loss: 9.375228881835938, Uncertainty: 37.272491455078125
Epoch 12, Batch 2700/3125, Loss: 8.643173217773438, Uncertainty: 20.722023010253906
Epoch 12, Batch 2800/3125, Loss: 8.942644119262695, Uncertainty: 10.956840515136719
Epoch 12, Batch 2900/3125, Loss: 9.220390319824219, Uncertainty: 6.934444427490234
Epoch 12, Batch 3000/3125, Loss: 9.911186218261719, Uncertainty: 19.39273452758789
Epoch 12, Batch 3100/3125, Loss: 10.436744689941406, Uncertainty: 10.940485954284668

Training and Validation Results of Epoch 12:
================================
Training Loss: 8.530653967285156, Training Uncertainty: 23.90721741546631, time: 135.44859862327576
Validation Loss: 14.995698255651137, Validation Uncertainty: 13.286870439339172, time: 30.65481400489807
Number of predictions within uncertainty interval: 22575/200000 (11.29%)

Epoch 13, Batch 100/3125, Loss: 11.618925094604492, Uncertainty: 47.297706604003906
Epoch 13, Batch 200/3125, Loss: 13.935308456420898, Uncertainty: 58.845237731933594
Epoch 13, Batch 300/3125, Loss: 11.117971420288086, Uncertainty: 46.06720733642578
Epoch 13, Batch 400/3125, Loss: 8.427816390991211, Uncertainty: 8.622873306274414
Epoch 13, Batch 500/3125, Loss: 16.9796199798584, Uncertainty: 28.832773208618164
Epoch 13, Batch 600/3125, Loss: 17.164993286132812, Uncertainty: 70.10075378417969
Epoch 13, Batch 700/3125, Loss: 8.579877853393555, Uncertainty: 12.113279342651367
Epoch 13, Batch 800/3125, Loss: 5.022098541259766, Uncertainty: 10.552530288696289
Epoch 13, Batch 900/3125, Loss: 7.255472183227539, Uncertainty: 26.848405838012695
Epoch 13, Batch 1000/3125, Loss: 12.183475494384766, Uncertainty: 14.479267120361328
Epoch 13, Batch 1100/3125, Loss: 11.293584823608398, Uncertainty: 43.598297119140625
Epoch 13, Batch 1200/3125, Loss: 8.09528923034668, Uncertainty: 32.24174118041992
Epoch 13, Batch 1300/3125, Loss: 4.466920852661133, Uncertainty: 10.042503356933594
Epoch 13, Batch 1400/3125, Loss: 5.5106353759765625, Uncertainty: 9.041685104370117
Epoch 13, Batch 1500/3125, Loss: 8.676826477050781, Uncertainty: 7.567529201507568
Epoch 13, Batch 1600/3125, Loss: 11.195158004760742, Uncertainty: 8.235742568969727
Epoch 13, Batch 1700/3125, Loss: 12.273529052734375, Uncertainty: 6.8996968269348145
Epoch 13, Batch 1800/3125, Loss: 13.905599594116211, Uncertainty: 13.619285583496094
Epoch 13, Batch 1900/3125, Loss: 9.695226669311523, Uncertainty: 23.96552848815918
Epoch 13, Batch 2000/3125, Loss: 7.703939437866211, Uncertainty: 15.477091789245605
Epoch 13, Batch 2100/3125, Loss: 5.827564239501953, Uncertainty: 14.035846710205078
Epoch 13, Batch 2200/3125, Loss: 4.062557220458984, Uncertainty: 6.633625030517578
Epoch 13, Batch 2300/3125, Loss: 6.072906494140625, Uncertainty: 22.45632553100586
Epoch 13, Batch 2400/3125, Loss: 11.748638153076172, Uncertainty: 49.46854019165039
Epoch 13, Batch 2500/3125, Loss: 8.740623474121094, Uncertainty: 16.638103485107422
Epoch 13, Batch 2600/3125, Loss: 10.859186172485352, Uncertainty: 45.6580810546875
Epoch 13, Batch 2700/3125, Loss: 11.559429168701172, Uncertainty: 48.92137908935547
Epoch 13, Batch 2800/3125, Loss: 8.706624984741211, Uncertainty: 35.563846588134766
Epoch 13, Batch 2900/3125, Loss: 9.638015747070312, Uncertainty: 40.398597717285156
Epoch 13, Batch 3000/3125, Loss: 8.237251281738281, Uncertainty: 9.150006294250488
Epoch 13, Batch 3100/3125, Loss: 10.119741439819336, Uncertainty: 42.44569396972656

Training and Validation Results of Epoch 13:
================================
Training Loss: 7.422073995361328, Training Uncertainty: 31.174868089294435, time: 136.58415508270264
Validation Loss: 4.337189018269024, Validation Uncertainty: 47.69894865284795, time: 31.18671989440918
Number of predictions within uncertainty interval: 198100/200000 (99.05%)

Epoch 14, Batch 100/3125, Loss: 6.15690803527832, Uncertainty: 11.581282615661621
Epoch 14, Batch 200/3125, Loss: 6.5310516357421875, Uncertainty: 9.812433242797852
Epoch 14, Batch 300/3125, Loss: 4.73060417175293, Uncertainty: 13.159098625183105
Epoch 14, Batch 400/3125, Loss: 5.849994659423828, Uncertainty: 20.1644229888916
Epoch 14, Batch 500/3125, Loss: 8.423040390014648, Uncertainty: 34.096275329589844
Epoch 14, Batch 600/3125, Loss: 6.914157867431641, Uncertainty: 25.093265533447266
Epoch 14, Batch 700/3125, Loss: 14.652505874633789, Uncertainty: 7.276898384094238
Epoch 14, Batch 800/3125, Loss: 9.020822525024414, Uncertainty: 34.13084411621094
Epoch 14, Batch 900/3125, Loss: 14.63226318359375, Uncertainty: 8.74122142791748
Epoch 14, Batch 1000/3125, Loss: 13.973052978515625, Uncertainty: 7.592421531677246
Epoch 14, Batch 1100/3125, Loss: 15.545629501342773, Uncertainty: 6.684290885925293
Epoch 14, Batch 1200/3125, Loss: 12.958108901977539, Uncertainty: 15.647480010986328
Epoch 14, Batch 1300/3125, Loss: 15.410673141479492, Uncertainty: 10.88792610168457
Epoch 14, Batch 1400/3125, Loss: 4.333833694458008, Uncertainty: 9.284830093383789
Epoch 14, Batch 1500/3125, Loss: 10.296808242797852, Uncertainty: 42.3931884765625
Epoch 14, Batch 1600/3125, Loss: 7.397615432739258, Uncertainty: 25.56652069091797
Epoch 14, Batch 1700/3125, Loss: 13.866125106811523, Uncertainty: 21.674888610839844
Epoch 14, Batch 1800/3125, Loss: 13.971942901611328, Uncertainty: 42.95655822753906
Epoch 14, Batch 1900/3125, Loss: 6.332160949707031, Uncertainty: 24.68724822998047
Epoch 14, Batch 2000/3125, Loss: 8.180795669555664, Uncertainty: 18.314132690429688
Epoch 14, Batch 2100/3125, Loss: 13.98942756652832, Uncertainty: 31.256675720214844
Epoch 14, Batch 2200/3125, Loss: 6.019378662109375, Uncertainty: 21.334976196289062
Epoch 14, Batch 2300/3125, Loss: 18.550193786621094, Uncertainty: 29.83045196533203
Epoch 14, Batch 2400/3125, Loss: 20.818483352661133, Uncertainty: 88.19795989990234
Epoch 14, Batch 2500/3125, Loss: 19.662858963012695, Uncertainty: 22.850181579589844
Epoch 14, Batch 2600/3125, Loss: 16.89732551574707, Uncertainty: 17.688396453857422
Epoch 14, Batch 2700/3125, Loss: 19.91886329650879, Uncertainty: 84.50858306884766
Epoch 14, Batch 2800/3125, Loss: 15.662555694580078, Uncertainty: 14.582167625427246
Epoch 14, Batch 2900/3125, Loss: 18.49013328552246, Uncertainty: 22.370847702026367
Epoch 14, Batch 3000/3125, Loss: 17.66932487487793, Uncertainty: 74.96459197998047
Epoch 14, Batch 3100/3125, Loss: 15.366676330566406, Uncertainty: 65.14271545410156

Training and Validation Results of Epoch 14:
================================
Training Loss: 9.414577020263671, Training Uncertainty: 30.633060758361815, time: 137.77533435821533
Validation Loss: 4.217321156845678, Validation Uncertainty: 41.37110506726043, time: 31.20172882080078
Number of predictions within uncertainty interval: 198081/200000 (99.04%)

Epoch 15, Batch 100/3125, Loss: 12.699792861938477, Uncertainty: 13.053834915161133
Epoch 15, Batch 200/3125, Loss: 10.220685958862305, Uncertainty: 8.302227020263672
Epoch 15, Batch 300/3125, Loss: 9.825929641723633, Uncertainty: 8.516250610351562
Epoch 15, Batch 400/3125, Loss: 18.594772338867188, Uncertainty: 78.32804870605469
Epoch 15, Batch 500/3125, Loss: 9.863842010498047, Uncertainty: 6.852616310119629
Epoch 15, Batch 600/3125, Loss: 10.541629791259766, Uncertainty: 44.047630310058594
Epoch 15, Batch 700/3125, Loss: 12.114072799682617, Uncertainty: 51.088951110839844
Epoch 15, Batch 800/3125, Loss: 7.347368240356445, Uncertainty: 22.614471435546875
Epoch 15, Batch 900/3125, Loss: 10.999917984008789, Uncertainty: 45.74494171142578
Epoch 15, Batch 1000/3125, Loss: 8.521080017089844, Uncertainty: 17.748432159423828
Epoch 15, Batch 1100/3125, Loss: 7.562007904052734, Uncertainty: 25.188640594482422
Epoch 15, Batch 1200/3125, Loss: 9.685007095336914, Uncertainty: 38.05876541137695
Epoch 15, Batch 1300/3125, Loss: 9.006235122680664, Uncertainty: 28.49892234802246
Epoch 15, Batch 1400/3125, Loss: 11.997486114501953, Uncertainty: 6.3613715171813965
Epoch 15, Batch 1500/3125, Loss: 13.318075180053711, Uncertainty: 6.840615272521973
Epoch 15, Batch 1600/3125, Loss: 12.651937484741211, Uncertainty: 8.560789108276367
Epoch 15, Batch 1700/3125, Loss: 12.48309326171875, Uncertainty: 6.96088981628418
Epoch 15, Batch 1800/3125, Loss: 11.70235824584961, Uncertainty: 6.88289737701416
Epoch 15, Batch 1900/3125, Loss: 11.583641052246094, Uncertainty: 8.166513442993164
Epoch 15, Batch 2000/3125, Loss: 12.779958724975586, Uncertainty: 7.4333038330078125
Epoch 15, Batch 2100/3125, Loss: 10.868309020996094, Uncertainty: 6.546375274658203
Epoch 15, Batch 2200/3125, Loss: 8.249853134155273, Uncertainty: 8.496440887451172
Epoch 15, Batch 2300/3125, Loss: 11.078508377075195, Uncertainty: 7.369894027709961
Epoch 15, Batch 2400/3125, Loss: 10.42459487915039, Uncertainty: 6.534399032592773
Epoch 15, Batch 2500/3125, Loss: 10.031814575195312, Uncertainty: 6.778815269470215
Epoch 15, Batch 2600/3125, Loss: 12.037307739257812, Uncertainty: 7.540016174316406
Epoch 15, Batch 2700/3125, Loss: 10.035734176635742, Uncertainty: 8.24652099609375
Epoch 15, Batch 2800/3125, Loss: 9.731887817382812, Uncertainty: 6.594248294830322
Epoch 15, Batch 2900/3125, Loss: 11.938629150390625, Uncertainty: 7.372992992401123
Epoch 15, Batch 3000/3125, Loss: 17.199790954589844, Uncertainty: 70.88842010498047
Epoch 15, Batch 3100/3125, Loss: 12.586719512939453, Uncertainty: 52.94621276855469

Training and Validation Results of Epoch 15:
================================
Training Loss: 7.775735107421875, Training Uncertainty: 29.647671439208985, time: 145.11292457580566
Validation Loss: 9.035044638397139, Validation Uncertainty: 7.942128270483383, time: 31.203415155410767
Number of predictions within uncertainty interval: 38169/200000 (19.08%)

Epoch 16, Batch 100/3125, Loss: 8.547843933105469, Uncertainty: 34.781856536865234
Epoch 16, Batch 200/3125, Loss: 8.032596588134766, Uncertainty: 23.113475799560547
Epoch 16, Batch 300/3125, Loss: 6.061792373657227, Uncertainty: 16.199237823486328
Epoch 16, Batch 400/3125, Loss: 5.323976516723633, Uncertainty: 17.272411346435547
Epoch 16, Batch 500/3125, Loss: 7.450981140136719, Uncertainty: 7.758472919464111
Epoch 16, Batch 600/3125, Loss: 7.535242080688477, Uncertainty: 18.46626853942871
Epoch 16, Batch 700/3125, Loss: 7.0152130126953125, Uncertainty: 15.116640090942383
Epoch 16, Batch 800/3125, Loss: 9.877664566040039, Uncertainty: 7.684469699859619
Epoch 16, Batch 900/3125, Loss: 9.270259857177734, Uncertainty: 13.117172241210938
Epoch 16, Batch 1000/3125, Loss: 7.375392913818359, Uncertainty: 24.160850524902344
Epoch 16, Batch 1100/3125, Loss: 8.591781616210938, Uncertainty: 35.53785705566406
Epoch 16, Batch 1200/3125, Loss: 8.934650421142578, Uncertainty: 34.649757385253906
Epoch 16, Batch 1300/3125, Loss: 8.853158950805664, Uncertainty: 23.20104217529297
Epoch 16, Batch 1400/3125, Loss: 19.917661666870117, Uncertainty: 68.70082092285156
Epoch 16, Batch 1500/3125, Loss: 8.922773361206055, Uncertainty: 23.331989288330078
Epoch 16, Batch 1600/3125, Loss: 14.935216903686523, Uncertainty: 63.193397521972656
Epoch 16, Batch 1700/3125, Loss: 20.55654525756836, Uncertainty: 47.3953857421875
Epoch 16, Batch 1800/3125, Loss: 13.586790084838867, Uncertainty: 57.52866744995117
Epoch 16, Batch 1900/3125, Loss: 16.751134872436523, Uncertainty: 70.87373352050781
Epoch 16, Batch 2000/3125, Loss: 19.885250091552734, Uncertainty: 32.317474365234375
Epoch 16, Batch 2100/3125, Loss: 12.249664306640625, Uncertainty: 51.68326187133789
Epoch 16, Batch 2200/3125, Loss: 20.79750633239746, Uncertainty: 88.23634338378906
Epoch 16, Batch 2300/3125, Loss: 22.208080291748047, Uncertainty: 93.94805908203125
Epoch 16, Batch 2400/3125, Loss: 14.60708236694336, Uncertainty: 7.571235656738281
Epoch 16, Batch 2500/3125, Loss: 21.692243576049805, Uncertainty: 91.91059112548828
Epoch 16, Batch 2600/3125, Loss: 22.387083053588867, Uncertainty: 94.48237609863281
Epoch 16, Batch 2700/3125, Loss: 8.02790641784668, Uncertainty: 21.811031341552734
Epoch 16, Batch 2800/3125, Loss: 13.123821258544922, Uncertainty: 23.83717918395996
Epoch 16, Batch 2900/3125, Loss: 13.48663330078125, Uncertainty: 49.77873229980469
Epoch 16, Batch 3000/3125, Loss: 15.831493377685547, Uncertainty: 9.995802879333496
Epoch 16, Batch 3100/3125, Loss: 16.51858901977539, Uncertainty: 20.69473648071289
Learning rate changed to: 1e-05

Training and Validation Results of Epoch 16:
================================
Training Loss: 9.287709188232421, Training Uncertainty: 39.32914164291382, time: 138.78563451766968
Validation Loss: 4.282587148954192, Validation Uncertainty: 51.45287319583356, time: 30.83808922767639
Number of predictions within uncertainty interval: 199357/200000 (99.68%)

Epoch 17, Batch 100/3125, Loss: 4.242374420166016, Uncertainty: 8.694998741149902
Epoch 17, Batch 200/3125, Loss: 4.100011825561523, Uncertainty: 8.677705764770508
Epoch 17, Batch 300/3125, Loss: 4.369754791259766, Uncertainty: 9.089994430541992
Epoch 17, Batch 400/3125, Loss: 4.471553802490234, Uncertainty: 8.93012523651123
Epoch 17, Batch 500/3125, Loss: 4.237253189086914, Uncertainty: 9.273080825805664
Epoch 17, Batch 600/3125, Loss: 4.152538299560547, Uncertainty: 8.623527526855469
Epoch 17, Batch 700/3125, Loss: 4.15899658203125, Uncertainty: 7.608896255493164
Epoch 17, Batch 800/3125, Loss: 4.032978057861328, Uncertainty: 9.044208526611328
Epoch 17, Batch 900/3125, Loss: 4.784181594848633, Uncertainty: 8.732830047607422
Epoch 17, Batch 1000/3125, Loss: 4.303091049194336, Uncertainty: 8.676459312438965
Epoch 17, Batch 1100/3125, Loss: 4.2939453125, Uncertainty: 9.39008617401123
Epoch 17, Batch 1200/3125, Loss: 4.413454055786133, Uncertainty: 9.76952075958252
Epoch 17, Batch 1300/3125, Loss: 4.087549209594727, Uncertainty: 8.154900550842285
Epoch 17, Batch 1400/3125, Loss: 4.012744903564453, Uncertainty: 7.857230186462402
Epoch 17, Batch 1500/3125, Loss: 3.7274169921875, Uncertainty: 8.159085273742676
Epoch 17, Batch 1600/3125, Loss: 4.143369674682617, Uncertainty: 8.724413871765137
Epoch 17, Batch 1700/3125, Loss: 3.7741470336914062, Uncertainty: 7.433296203613281
Epoch 17, Batch 1800/3125, Loss: 4.147552490234375, Uncertainty: 7.315101623535156
Epoch 17, Batch 1900/3125, Loss: 4.258028030395508, Uncertainty: 8.389671325683594
Epoch 17, Batch 2000/3125, Loss: 4.1900787353515625, Uncertainty: 8.817951202392578
Epoch 17, Batch 2100/3125, Loss: 4.092653274536133, Uncertainty: 9.32296085357666
Epoch 17, Batch 2200/3125, Loss: 4.065958023071289, Uncertainty: 7.714815139770508
Epoch 17, Batch 2300/3125, Loss: 4.309459686279297, Uncertainty: 8.654181480407715
Epoch 17, Batch 2400/3125, Loss: 4.001216888427734, Uncertainty: 7.892496109008789
Epoch 17, Batch 2500/3125, Loss: 3.969453811645508, Uncertainty: 8.200913429260254
Epoch 17, Batch 2600/3125, Loss: 4.137479782104492, Uncertainty: 8.096183776855469
Epoch 17, Batch 2700/3125, Loss: 3.9698753356933594, Uncertainty: 7.253843307495117
Epoch 17, Batch 2800/3125, Loss: 3.935636520385742, Uncertainty: 8.686088562011719
Epoch 17, Batch 2900/3125, Loss: 3.956930160522461, Uncertainty: 8.513806343078613
Epoch 17, Batch 3000/3125, Loss: 4.007528305053711, Uncertainty: 7.135074615478516
Epoch 17, Batch 3100/3125, Loss: 3.7975215911865234, Uncertainty: 7.6502885818481445

Training and Validation Results of Epoch 17:
================================
Training Loss: 3.755949149169922, Training Uncertainty: 8.325571311950684, time: 137.54141759872437
Validation Loss: 3.583153312468468, Validation Uncertainty: 7.23172945927476, time: 31.093202114105225
Number of predictions within uncertainty interval: 98157/200000 (49.08%)

Epoch 18, Batch 100/3125, Loss: 3.9521045684814453, Uncertainty: 7.293713569641113
Epoch 18, Batch 200/3125, Loss: 4.00096321105957, Uncertainty: 7.260114669799805
Epoch 18, Batch 300/3125, Loss: 4.100770950317383, Uncertainty: 7.591020584106445
Epoch 18, Batch 400/3125, Loss: 4.199838638305664, Uncertainty: 10.52686882019043
Epoch 18, Batch 500/3125, Loss: 3.8760528564453125, Uncertainty: 7.291568756103516
Epoch 18, Batch 600/3125, Loss: 4.199949264526367, Uncertainty: 10.788894653320312
Epoch 18, Batch 700/3125, Loss: 3.717388153076172, Uncertainty: 6.810925483703613
Epoch 18, Batch 800/3125, Loss: 3.8489990234375, Uncertainty: 7.076656818389893
Epoch 18, Batch 900/3125, Loss: 4.313503265380859, Uncertainty: 6.925446033477783
Epoch 18, Batch 1000/3125, Loss: 3.9794769287109375, Uncertainty: 6.886231422424316
Epoch 18, Batch 1100/3125, Loss: 4.092557907104492, Uncertainty: 8.465269088745117
Epoch 18, Batch 1200/3125, Loss: 4.006965637207031, Uncertainty: 6.957086563110352
Epoch 18, Batch 1300/3125, Loss: 3.786865234375, Uncertainty: 6.045096397399902
Epoch 18, Batch 1400/3125, Loss: 3.8228759765625, Uncertainty: 7.486251354217529
Epoch 18, Batch 1500/3125, Loss: 3.920907974243164, Uncertainty: 8.437643051147461
Epoch 18, Batch 1600/3125, Loss: 3.696147918701172, Uncertainty: 6.406590461730957
Epoch 18, Batch 1700/3125, Loss: 4.2078094482421875, Uncertainty: 8.635149002075195
Epoch 18, Batch 1800/3125, Loss: 3.5346145629882812, Uncertainty: 6.756562232971191
Epoch 18, Batch 1900/3125, Loss: 3.6397457122802734, Uncertainty: 6.37965202331543
Epoch 18, Batch 2000/3125, Loss: 3.6564598083496094, Uncertainty: 6.563692569732666
Epoch 18, Batch 2100/3125, Loss: 3.436147689819336, Uncertainty: 6.953274726867676
Epoch 18, Batch 2200/3125, Loss: 3.8409156799316406, Uncertainty: 9.614952087402344
Epoch 18, Batch 2300/3125, Loss: 3.8743667602539062, Uncertainty: 7.858735084533691
Epoch 18, Batch 2400/3125, Loss: 3.6657772064208984, Uncertainty: 6.327587127685547
Epoch 18, Batch 2500/3125, Loss: 3.907350540161133, Uncertainty: 7.246633529663086
Epoch 18, Batch 2600/3125, Loss: 3.6918201446533203, Uncertainty: 5.367738723754883
Epoch 18, Batch 2700/3125, Loss: 3.5808563232421875, Uncertainty: 7.946357250213623
Epoch 18, Batch 2800/3125, Loss: 3.8188552856445312, Uncertainty: 6.305324554443359
Epoch 18, Batch 2900/3125, Loss: 4.500812530517578, Uncertainty: 6.234453201293945
Epoch 18, Batch 3000/3125, Loss: 3.267271041870117, Uncertainty: 5.726207256317139
Epoch 18, Batch 3100/3125, Loss: 3.413055419921875, Uncertainty: 6.284090995788574

Training and Validation Results of Epoch 18:
================================
Training Loss: 3.478667482910156, Training Uncertainty: 7.119565231170654, time: 145.42828154563904
Validation Loss: 3.4121573757942376, Validation Uncertainty: 6.103634378184443, time: 31.305236339569092
Number of predictions within uncertainty interval: 90639/200000 (45.32%)

Epoch 19, Batch 100/3125, Loss: 3.6066055297851562, Uncertainty: 6.665670394897461
Epoch 19, Batch 200/3125, Loss: 3.520587921142578, Uncertainty: 7.131716251373291
Epoch 19, Batch 300/3125, Loss: 3.7711524963378906, Uncertainty: 5.716375350952148
Epoch 19, Batch 400/3125, Loss: 3.3050975799560547, Uncertainty: 5.722953796386719
Epoch 19, Batch 500/3125, Loss: 3.8074684143066406, Uncertainty: 6.251673698425293
Epoch 19, Batch 600/3125, Loss: 3.5523929595947266, Uncertainty: 6.382969856262207
Epoch 19, Batch 700/3125, Loss: 3.765748977661133, Uncertainty: 6.372902870178223
Epoch 19, Batch 800/3125, Loss: 3.9818344116210938, Uncertainty: 6.78886604309082
Epoch 19, Batch 900/3125, Loss: 3.5212974548339844, Uncertainty: 6.240053176879883
Epoch 19, Batch 1000/3125, Loss: 3.642606735229492, Uncertainty: 5.829495429992676
Epoch 19, Batch 1100/3125, Loss: 3.5901641845703125, Uncertainty: 5.325344085693359
Epoch 19, Batch 1200/3125, Loss: 3.705097198486328, Uncertainty: 6.577157974243164
Epoch 19, Batch 1300/3125, Loss: 3.3150501251220703, Uncertainty: 5.62973165512085
Epoch 19, Batch 1400/3125, Loss: 3.5867786407470703, Uncertainty: 5.680874824523926
Epoch 19, Batch 1500/3125, Loss: 3.3755359649658203, Uncertainty: 5.714780807495117
Epoch 19, Batch 1600/3125, Loss: 3.5413150787353516, Uncertainty: 5.805380821228027
Epoch 19, Batch 1700/3125, Loss: 3.984048843383789, Uncertainty: 7.724542617797852
Epoch 19, Batch 1800/3125, Loss: 3.6905574798583984, Uncertainty: 6.844871997833252
Epoch 19, Batch 1900/3125, Loss: 4.072475433349609, Uncertainty: 6.314970970153809
Epoch 19, Batch 2000/3125, Loss: 3.553438186645508, Uncertainty: 5.3284759521484375
Epoch 19, Batch 2100/3125, Loss: 3.3471336364746094, Uncertainty: 5.774444580078125
Epoch 19, Batch 2200/3125, Loss: 3.4835357666015625, Uncertainty: 5.588372707366943
Epoch 19, Batch 2300/3125, Loss: 3.5472068786621094, Uncertainty: 5.373217582702637
Epoch 19, Batch 2400/3125, Loss: 3.334688186645508, Uncertainty: 5.941653728485107
Epoch 19, Batch 2500/3125, Loss: 5.0868377685546875, Uncertainty: 6.541536331176758
Epoch 19, Batch 2600/3125, Loss: 4.082056045532227, Uncertainty: 11.172012329101562
Epoch 19, Batch 2700/3125, Loss: 3.4717884063720703, Uncertainty: 6.148134231567383
Epoch 19, Batch 2800/3125, Loss: 3.9044723510742188, Uncertainty: 7.545891284942627
Epoch 19, Batch 2900/3125, Loss: 3.5822925567626953, Uncertainty: 5.931069374084473
Epoch 19, Batch 3000/3125, Loss: 3.1854991912841797, Uncertainty: 5.312291622161865
Epoch 19, Batch 3100/3125, Loss: 4.132986068725586, Uncertainty: 6.597833156585693

Training and Validation Results of Epoch 19:
================================
Training Loss: 3.2978570349121092, Training Uncertainty: 6.355029152526855, time: 143.75879406929016
Validation Loss: 3.1177417823420766, Validation Uncertainty: 5.75820859923692, time: 31.293574571609497
Number of predictions within uncertainty interval: 89755/200000 (44.88%)

Epoch 20, Batch 100/3125, Loss: 3.3381595611572266, Uncertainty: 6.503592014312744
Epoch 20, Batch 200/3125, Loss: 3.765594482421875, Uncertainty: 5.553544044494629
Epoch 20, Batch 300/3125, Loss: 3.3879642486572266, Uncertainty: 5.737681865692139
Epoch 20, Batch 400/3125, Loss: 3.2420597076416016, Uncertainty: 5.561433792114258
Epoch 20, Batch 500/3125, Loss: 3.2131786346435547, Uncertainty: 5.406807899475098
Epoch 20, Batch 600/3125, Loss: 3.5926361083984375, Uncertainty: 6.203848838806152
Epoch 20, Batch 700/3125, Loss: 3.4784698486328125, Uncertainty: 5.3914570808410645
Epoch 20, Batch 800/3125, Loss: 3.7995948791503906, Uncertainty: 5.570812702178955
Epoch 20, Batch 900/3125, Loss: 3.243375778198242, Uncertainty: 5.830515384674072
Epoch 20, Batch 1000/3125, Loss: 3.284646987915039, Uncertainty: 5.583266258239746
Epoch 20, Batch 1100/3125, Loss: 3.4433250427246094, Uncertainty: 5.488774299621582
Epoch 20, Batch 1200/3125, Loss: 3.374622344970703, Uncertainty: 5.802362442016602
Epoch 20, Batch 1300/3125, Loss: 3.2226085662841797, Uncertainty: 5.278045177459717
Epoch 20, Batch 1400/3125, Loss: 3.5316505432128906, Uncertainty: 5.7553791999816895
Epoch 20, Batch 1500/3125, Loss: 3.3517990112304688, Uncertainty: 5.554757595062256
Epoch 20, Batch 1600/3125, Loss: 3.2763633728027344, Uncertainty: 5.23490571975708
Epoch 20, Batch 1700/3125, Loss: 3.2634220123291016, Uncertainty: 6.122239112854004
Epoch 20, Batch 1800/3125, Loss: 3.1515026092529297, Uncertainty: 5.6302337646484375
Epoch 20, Batch 1900/3125, Loss: 3.728515625, Uncertainty: 5.456631660461426
Epoch 20, Batch 2000/3125, Loss: 3.409210205078125, Uncertainty: 6.162902355194092
Epoch 20, Batch 2100/3125, Loss: 3.2665233612060547, Uncertainty: 5.215508460998535
Epoch 20, Batch 2200/3125, Loss: 3.3863487243652344, Uncertainty: 5.661283493041992
Epoch 20, Batch 2300/3125, Loss: 3.3159542083740234, Uncertainty: 5.833040237426758
Epoch 20, Batch 2400/3125, Loss: 3.234333038330078, Uncertainty: 5.732834815979004
Epoch 20, Batch 2500/3125, Loss: 3.4257659912109375, Uncertainty: 6.549709320068359
Epoch 20, Batch 2600/3125, Loss: 3.4987754821777344, Uncertainty: 7.288704872131348
Epoch 20, Batch 2700/3125, Loss: 3.504262924194336, Uncertainty: 6.770569324493408
Epoch 20, Batch 2800/3125, Loss: 3.727682113647461, Uncertainty: 5.712952136993408
Epoch 20, Batch 2900/3125, Loss: 3.050870895385742, Uncertainty: 5.498379707336426
Epoch 20, Batch 3000/3125, Loss: 3.310823440551758, Uncertainty: 5.701088905334473
Epoch 20, Batch 3100/3125, Loss: 3.2160205841064453, Uncertainty: 5.131527900695801

Training and Validation Results of Epoch 20:
================================
Training Loss: 3.142742928466797, Training Uncertainty: 5.917349157867432, time: 144.79186415672302
Validation Loss: 2.9978515254262157, Validation Uncertainty: 5.419459106367262, time: 31.221438884735107
Number of predictions within uncertainty interval: 88360/200000 (44.18%)

Epoch 21, Batch 100/3125, Loss: 3.331249237060547, Uncertainty: 5.149743556976318
Epoch 21, Batch 200/3125, Loss: 3.276212692260742, Uncertainty: 5.751114845275879
Epoch 21, Batch 300/3125, Loss: 3.3941993713378906, Uncertainty: 6.360012054443359
Epoch 21, Batch 400/3125, Loss: 3.558879852294922, Uncertainty: 6.076639175415039
Epoch 21, Batch 500/3125, Loss: 3.1110172271728516, Uncertainty: 5.733020782470703
Epoch 21, Batch 600/3125, Loss: 3.7258567810058594, Uncertainty: 9.330090522766113
Epoch 21, Batch 700/3125, Loss: 3.3531627655029297, Uncertainty: 7.62766170501709
Epoch 21, Batch 800/3125, Loss: 3.2047500610351562, Uncertainty: 4.524184226989746
Epoch 21, Batch 900/3125, Loss: 3.1907100677490234, Uncertainty: 5.204293251037598
Epoch 21, Batch 1000/3125, Loss: 3.3351268768310547, Uncertainty: 7.472130298614502
Epoch 21, Batch 1100/3125, Loss: 3.5834922790527344, Uncertainty: 5.549919128417969
Epoch 21, Batch 1200/3125, Loss: 3.135793685913086, Uncertainty: 5.310138702392578
Epoch 21, Batch 1300/3125, Loss: 3.2998828887939453, Uncertainty: 5.236645698547363
Epoch 21, Batch 1400/3125, Loss: 3.427845001220703, Uncertainty: 5.229807376861572
Epoch 21, Batch 1500/3125, Loss: 3.262928009033203, Uncertainty: 5.40021276473999
Epoch 21, Batch 1600/3125, Loss: 3.442819595336914, Uncertainty: 7.903428077697754
Epoch 21, Batch 1700/3125, Loss: 3.4666481018066406, Uncertainty: 5.859979152679443
Epoch 21, Batch 1800/3125, Loss: 3.2303428649902344, Uncertainty: 5.419844627380371
Epoch 21, Batch 1900/3125, Loss: 3.377887725830078, Uncertainty: 5.861629962921143
Epoch 21, Batch 2000/3125, Loss: 3.707162857055664, Uncertainty: 5.364032745361328
Epoch 21, Batch 2100/3125, Loss: 3.1153926849365234, Uncertainty: 5.825352668762207
Epoch 21, Batch 2200/3125, Loss: 3.171998977661133, Uncertainty: 5.519144058227539
Epoch 21, Batch 2300/3125, Loss: 3.472820281982422, Uncertainty: 5.260217666625977
Epoch 21, Batch 2400/3125, Loss: 2.783275604248047, Uncertainty: 4.587837219238281
Epoch 21, Batch 2500/3125, Loss: 3.0281333923339844, Uncertainty: 5.891101837158203
Epoch 21, Batch 2600/3125, Loss: 3.425800323486328, Uncertainty: 5.5229878425598145
Epoch 21, Batch 2700/3125, Loss: 3.163562774658203, Uncertainty: 5.260817050933838
Epoch 21, Batch 2800/3125, Loss: 3.071615219116211, Uncertainty: 5.707287311553955
Epoch 21, Batch 2900/3125, Loss: 3.313037872314453, Uncertainty: 5.607891082763672
Epoch 21, Batch 3000/3125, Loss: 2.96990966796875, Uncertainty: 5.3556413650512695
Epoch 21, Batch 3100/3125, Loss: 3.2141056060791016, Uncertainty: 5.619163513183594

Training and Validation Results of Epoch 21:
================================
Training Loss: 3.05984400390625, Training Uncertainty: 5.711299279479981, time: 145.9915256500244
Validation Loss: 2.8950473902475498, Validation Uncertainty: 5.1318289337255765, time: 31.52577042579651
Number of predictions within uncertainty interval: 88703/200000 (44.35%)

Epoch 22, Batch 100/3125, Loss: 3.1068668365478516, Uncertainty: 5.105438709259033
Epoch 22, Batch 200/3125, Loss: 2.900310516357422, Uncertainty: 4.511690139770508
Epoch 22, Batch 300/3125, Loss: 3.187274932861328, Uncertainty: 6.249699115753174
Epoch 22, Batch 400/3125, Loss: 3.068002700805664, Uncertainty: 5.398667335510254
Epoch 22, Batch 500/3125, Loss: 3.358530044555664, Uncertainty: 4.831598281860352
Epoch 22, Batch 600/3125, Loss: 3.840452194213867, Uncertainty: 6.603336334228516
Epoch 22, Batch 700/3125, Loss: 3.121540069580078, Uncertainty: 5.3354105949401855
Epoch 22, Batch 800/3125, Loss: 3.2366943359375, Uncertainty: 5.329859256744385
Epoch 22, Batch 900/3125, Loss: 4.250165939331055, Uncertainty: 7.4188995361328125
Epoch 22, Batch 1000/3125, Loss: 3.310457229614258, Uncertainty: 5.458241939544678
Epoch 22, Batch 1100/3125, Loss: 3.268035888671875, Uncertainty: 5.857260227203369
Epoch 22, Batch 1200/3125, Loss: 2.9613590240478516, Uncertainty: 5.325141906738281
Epoch 22, Batch 1300/3125, Loss: 3.347818374633789, Uncertainty: 5.693401336669922
Epoch 22, Batch 1400/3125, Loss: 3.1662960052490234, Uncertainty: 6.027868270874023
Epoch 22, Batch 1500/3125, Loss: 3.2918167114257812, Uncertainty: 5.465354919433594
Epoch 22, Batch 1600/3125, Loss: 3.4734230041503906, Uncertainty: 5.8057451248168945
Epoch 22, Batch 1700/3125, Loss: 3.0443992614746094, Uncertainty: 5.390923500061035
Epoch 22, Batch 1800/3125, Loss: 3.282968521118164, Uncertainty: 5.42216682434082
Epoch 22, Batch 1900/3125, Loss: 3.044412612915039, Uncertainty: 5.491549491882324
Epoch 22, Batch 2000/3125, Loss: 3.269296646118164, Uncertainty: 5.348398685455322
Epoch 22, Batch 2100/3125, Loss: 3.4233436584472656, Uncertainty: 6.161170482635498
Epoch 22, Batch 2200/3125, Loss: 3.569154739379883, Uncertainty: 6.057971000671387
Epoch 22, Batch 2300/3125, Loss: 3.3481407165527344, Uncertainty: 5.6483845710754395
Epoch 22, Batch 2400/3125, Loss: 3.285247802734375, Uncertainty: 5.456615447998047
Epoch 22, Batch 2500/3125, Loss: 3.4485702514648438, Uncertainty: 5.065422534942627
Epoch 22, Batch 2600/3125, Loss: 3.1472206115722656, Uncertainty: 5.669633865356445
Epoch 22, Batch 2700/3125, Loss: 3.102497100830078, Uncertainty: 5.386973857879639
Epoch 22, Batch 2800/3125, Loss: 3.1124324798583984, Uncertainty: 5.958744525909424
Epoch 22, Batch 2900/3125, Loss: 2.967031478881836, Uncertainty: 4.946880340576172
Epoch 22, Batch 3000/3125, Loss: 3.476987838745117, Uncertainty: 5.028158187866211
Epoch 22, Batch 3100/3125, Loss: 2.915731430053711, Uncertainty: 4.991111755371094

Training and Validation Results of Epoch 22:
================================
Training Loss: 2.9625798547363282, Training Uncertainty: 5.468882595062256, time: 147.88956809043884
Validation Loss: 2.8048919180165166, Validation Uncertainty: 5.940005740241322, time: 31.277064561843872
Number of predictions within uncertainty interval: 107545/200000 (53.77%)

Epoch 23, Batch 100/3125, Loss: 2.8715248107910156, Uncertainty: 4.9441046714782715
Epoch 23, Batch 200/3125, Loss: 3.276754379272461, Uncertainty: 5.295783042907715
Epoch 23, Batch 300/3125, Loss: 3.1141204833984375, Uncertainty: 5.804450511932373
Epoch 23, Batch 400/3125, Loss: 2.983255386352539, Uncertainty: 4.802272796630859
Epoch 23, Batch 500/3125, Loss: 2.9713497161865234, Uncertainty: 5.78859806060791
Epoch 23, Batch 600/3125, Loss: 3.2552452087402344, Uncertainty: 4.93856954574585
Epoch 23, Batch 700/3125, Loss: 3.016559600830078, Uncertainty: 5.396862983703613
Epoch 23, Batch 800/3125, Loss: 3.147083282470703, Uncertainty: 4.881551742553711
Epoch 23, Batch 900/3125, Loss: 3.1576805114746094, Uncertainty: 4.827771186828613
Epoch 23, Batch 1000/3125, Loss: 3.11956787109375, Uncertainty: 4.932273864746094
Epoch 23, Batch 1100/3125, Loss: 3.028573989868164, Uncertainty: 4.965281963348389
Epoch 23, Batch 1200/3125, Loss: 3.1472702026367188, Uncertainty: 5.643853187561035
Epoch 23, Batch 1300/3125, Loss: 3.1408233642578125, Uncertainty: 4.280139923095703
Epoch 23, Batch 1400/3125, Loss: 3.2593040466308594, Uncertainty: 5.542926788330078
Epoch 23, Batch 1500/3125, Loss: 3.4511775970458984, Uncertainty: 8.29662799835205
Epoch 23, Batch 1600/3125, Loss: 3.2539730072021484, Uncertainty: 5.3155927658081055
Epoch 23, Batch 1700/3125, Loss: 3.155630111694336, Uncertainty: 5.071208953857422
Epoch 23, Batch 1800/3125, Loss: 3.127115249633789, Uncertainty: 4.621217727661133
Epoch 23, Batch 1900/3125, Loss: 3.429363250732422, Uncertainty: 5.054919242858887
Epoch 23, Batch 2000/3125, Loss: 2.9275665283203125, Uncertainty: 4.8328857421875
Epoch 23, Batch 2100/3125, Loss: 3.3480186462402344, Uncertainty: 4.620513916015625
Epoch 23, Batch 2200/3125, Loss: 3.1163578033447266, Uncertainty: 6.875865459442139
Epoch 23, Batch 2300/3125, Loss: 2.9069347381591797, Uncertainty: 5.464376449584961
Epoch 23, Batch 2400/3125, Loss: 2.941873550415039, Uncertainty: 5.044682502746582
Epoch 23, Batch 2500/3125, Loss: 3.410470962524414, Uncertainty: 8.29484748840332
Epoch 23, Batch 2600/3125, Loss: 2.950674057006836, Uncertainty: 4.867592811584473
Epoch 23, Batch 2700/3125, Loss: 3.061494827270508, Uncertainty: 4.865537643432617
Epoch 23, Batch 2800/3125, Loss: 3.3181915283203125, Uncertainty: 5.065260887145996
Epoch 23, Batch 2900/3125, Loss: 3.0735816955566406, Uncertainty: 4.72017765045166
Epoch 23, Batch 3000/3125, Loss: 2.8285179138183594, Uncertainty: 5.48997163772583
Epoch 23, Batch 3100/3125, Loss: 3.5486831665039062, Uncertainty: 5.597775936126709

Training and Validation Results of Epoch 23:
================================
Training Loss: 2.886254794921875, Training Uncertainty: 5.342770611877442, time: 155.18550419807434
Validation Loss: 2.732307419447643, Validation Uncertainty: 4.948120881224532, time: 31.646836757659912
Number of predictions within uncertainty interval: 88803/200000 (44.40%)

Epoch 24, Batch 100/3125, Loss: 2.9112396240234375, Uncertainty: 4.527680397033691
Epoch 24, Batch 200/3125, Loss: 2.932790756225586, Uncertainty: 5.090921401977539
Epoch 24, Batch 300/3125, Loss: 3.521015167236328, Uncertainty: 6.406299591064453
Epoch 24, Batch 400/3125, Loss: 3.700937271118164, Uncertainty: 5.023950576782227
Epoch 24, Batch 500/3125, Loss: 2.950857162475586, Uncertainty: 5.154121398925781
Epoch 24, Batch 600/3125, Loss: 3.0470142364501953, Uncertainty: 5.320723533630371
Epoch 24, Batch 700/3125, Loss: 2.6963329315185547, Uncertainty: 4.934142589569092
Epoch 24, Batch 800/3125, Loss: 3.112764358520508, Uncertainty: 5.829512119293213
Epoch 24, Batch 900/3125, Loss: 3.0862674713134766, Uncertainty: 5.048938751220703
Epoch 24, Batch 1000/3125, Loss: 2.8769607543945312, Uncertainty: 4.721940994262695
Epoch 24, Batch 1100/3125, Loss: 3.557645797729492, Uncertainty: 5.080482482910156
Epoch 24, Batch 1200/3125, Loss: 2.8908843994140625, Uncertainty: 4.789122581481934
Epoch 24, Batch 1300/3125, Loss: 3.1978206634521484, Uncertainty: 5.67378568649292
Epoch 24, Batch 1400/3125, Loss: 2.7595996856689453, Uncertainty: 5.59220027923584
Epoch 24, Batch 1500/3125, Loss: 3.1383628845214844, Uncertainty: 4.997918128967285
Epoch 24, Batch 1600/3125, Loss: 3.098064422607422, Uncertainty: 6.18277645111084
Epoch 24, Batch 1700/3125, Loss: 2.8206310272216797, Uncertainty: 4.672150135040283
Epoch 24, Batch 1800/3125, Loss: 3.1145191192626953, Uncertainty: 6.567487716674805
Epoch 24, Batch 1900/3125, Loss: 2.925180435180664, Uncertainty: 4.79573392868042
Epoch 24, Batch 2000/3125, Loss: 3.1598987579345703, Uncertainty: 6.97824764251709
Epoch 24, Batch 2100/3125, Loss: 3.285806655883789, Uncertainty: 6.972291946411133
Epoch 24, Batch 2200/3125, Loss: 3.039487838745117, Uncertainty: 4.731044769287109
Epoch 24, Batch 2300/3125, Loss: 3.085519790649414, Uncertainty: 5.421341419219971
Epoch 24, Batch 2400/3125, Loss: 2.8443374633789062, Uncertainty: 4.479628562927246
Epoch 24, Batch 2500/3125, Loss: 3.168294906616211, Uncertainty: 5.840727806091309
Epoch 24, Batch 2600/3125, Loss: 3.2651119232177734, Uncertainty: 4.724603652954102
Epoch 24, Batch 2700/3125, Loss: 2.947633743286133, Uncertainty: 4.61142635345459
Epoch 24, Batch 2800/3125, Loss: 2.564638137817383, Uncertainty: 4.153779983520508
Epoch 24, Batch 2900/3125, Loss: 3.015462875366211, Uncertainty: 4.858513355255127
Epoch 24, Batch 3000/3125, Loss: 2.9212417602539062, Uncertainty: 4.968947410583496
Epoch 24, Batch 3100/3125, Loss: 2.9846229553222656, Uncertainty: 4.710239887237549

Training and Validation Results of Epoch 24:
================================
Training Loss: 2.782175166015625, Training Uncertainty: 5.206841359786988, time: 136.846577167511
Validation Loss: 2.656780252676181, Validation Uncertainty: 4.584571852098645, time: 32.395874977111816
Number of predictions within uncertainty interval: 87920/200000 (43.96%)

Epoch 25, Batch 100/3125, Loss: 2.822620391845703, Uncertainty: 4.399742603302002
Epoch 25, Batch 200/3125, Loss: 3.078754425048828, Uncertainty: 6.477640151977539
Epoch 25, Batch 300/3125, Loss: 2.7915477752685547, Uncertainty: 4.647031784057617
Epoch 25, Batch 400/3125, Loss: 2.7084789276123047, Uncertainty: 4.902939319610596
Epoch 25, Batch 500/3125, Loss: 3.0274906158447266, Uncertainty: 7.863679885864258
Epoch 25, Batch 600/3125, Loss: 3.2789955139160156, Uncertainty: 7.657741546630859
Epoch 25, Batch 700/3125, Loss: 2.923572540283203, Uncertainty: 4.568205833435059
Epoch 25, Batch 800/3125, Loss: 3.1348743438720703, Uncertainty: 4.287689685821533
Epoch 25, Batch 900/3125, Loss: 3.0443248748779297, Uncertainty: 4.5595550537109375
Epoch 25, Batch 1000/3125, Loss: 3.2170886993408203, Uncertainty: 4.907309532165527
Epoch 25, Batch 1100/3125, Loss: 3.3243789672851562, Uncertainty: 4.689135551452637
Epoch 25, Batch 1200/3125, Loss: 2.5963001251220703, Uncertainty: 4.157907485961914
Epoch 25, Batch 1300/3125, Loss: 2.8419551849365234, Uncertainty: 6.77396821975708
Epoch 25, Batch 1400/3125, Loss: 2.9515247344970703, Uncertainty: 4.885250091552734
Epoch 25, Batch 1500/3125, Loss: 2.8388824462890625, Uncertainty: 6.0923871994018555
Epoch 25, Batch 1600/3125, Loss: 2.9987754821777344, Uncertainty: 5.614720821380615
Epoch 25, Batch 1700/3125, Loss: 2.8120155334472656, Uncertainty: 5.12990140914917
Epoch 25, Batch 1800/3125, Loss: 2.76934814453125, Uncertainty: 4.888300895690918
Epoch 25, Batch 1900/3125, Loss: 3.151348114013672, Uncertainty: 6.487382888793945
Epoch 25, Batch 2000/3125, Loss: 3.0509281158447266, Uncertainty: 4.578426361083984
Epoch 25, Batch 2100/3125, Loss: 3.0267868041992188, Uncertainty: 4.411006927490234
Epoch 25, Batch 2200/3125, Loss: 3.0903759002685547, Uncertainty: 4.906241416931152
Epoch 25, Batch 2300/3125, Loss: 2.759981155395508, Uncertainty: 4.461461544036865
Epoch 25, Batch 2400/3125, Loss: 2.758005142211914, Uncertainty: 4.85173225402832
Epoch 25, Batch 2500/3125, Loss: 2.7812271118164062, Uncertainty: 4.392023086547852
Epoch 25, Batch 2600/3125, Loss: 2.6686344146728516, Uncertainty: 4.303631782531738
Epoch 25, Batch 2700/3125, Loss: 2.817667007446289, Uncertainty: 7.29326057434082
Epoch 25, Batch 2800/3125, Loss: 3.264310836791992, Uncertainty: 5.681553840637207
Epoch 25, Batch 2900/3125, Loss: 3.1109619140625, Uncertainty: 4.409080982208252
Epoch 25, Batch 3000/3125, Loss: 2.877910614013672, Uncertainty: 5.318012237548828
Epoch 25, Batch 3100/3125, Loss: 2.846261978149414, Uncertainty: 4.416517734527588

Training and Validation Results of Epoch 25:
================================
Training Loss: 2.714583895263672, Training Uncertainty: 5.165617437820434, time: 145.4191026687622
Validation Loss: 2.577191394308339, Validation Uncertainty: 4.687370695421458, time: 30.711262464523315
Number of predictions within uncertainty interval: 89515/200000 (44.76%)

Epoch 26, Batch 100/3125, Loss: 3.2710437774658203, Uncertainty: 6.008737564086914
Epoch 26, Batch 200/3125, Loss: 3.140888214111328, Uncertainty: 5.928762435913086
Epoch 26, Batch 300/3125, Loss: 2.5823974609375, Uncertainty: 4.36274528503418
Epoch 26, Batch 400/3125, Loss: 2.6255340576171875, Uncertainty: 4.687080383300781
Epoch 26, Batch 500/3125, Loss: 2.756744384765625, Uncertainty: 5.737916946411133
Epoch 26, Batch 600/3125, Loss: 3.047962188720703, Uncertainty: 6.690206050872803
Epoch 26, Batch 700/3125, Loss: 2.961963653564453, Uncertainty: 4.190915107727051
Epoch 26, Batch 800/3125, Loss: 2.829072952270508, Uncertainty: 4.483245849609375
Epoch 26, Batch 900/3125, Loss: 3.196500778198242, Uncertainty: 5.501486778259277
Epoch 26, Batch 1000/3125, Loss: 3.0806713104248047, Uncertainty: 4.689305305480957
Epoch 26, Batch 1100/3125, Loss: 3.120260238647461, Uncertainty: 4.747925758361816
Epoch 26, Batch 1200/3125, Loss: 2.9145355224609375, Uncertainty: 5.8633294105529785
Epoch 26, Batch 1300/3125, Loss: 2.9190902709960938, Uncertainty: 4.733756065368652
Epoch 26, Batch 1400/3125, Loss: 2.7306041717529297, Uncertainty: 4.385653972625732
Epoch 26, Batch 1500/3125, Loss: 3.0684261322021484, Uncertainty: 6.750597953796387
Epoch 26, Batch 1600/3125, Loss: 2.690664291381836, Uncertainty: 4.304408550262451
Epoch 26, Batch 1700/3125, Loss: 2.8865108489990234, Uncertainty: 4.939548492431641
Epoch 26, Batch 1800/3125, Loss: 2.8671131134033203, Uncertainty: 4.771975517272949
Epoch 26, Batch 1900/3125, Loss: 3.271554946899414, Uncertainty: 4.46071720123291
Epoch 26, Batch 2000/3125, Loss: 2.8579139709472656, Uncertainty: 4.520785331726074
Epoch 26, Batch 2100/3125, Loss: 2.8196258544921875, Uncertainty: 4.824178218841553
Epoch 26, Batch 2200/3125, Loss: 2.741046905517578, Uncertainty: 4.654727458953857
Epoch 26, Batch 2300/3125, Loss: 3.170825958251953, Uncertainty: 5.9320478439331055
Epoch 26, Batch 2400/3125, Loss: 3.3733062744140625, Uncertainty: 4.5330047607421875
Epoch 26, Batch 2500/3125, Loss: 3.0467376708984375, Uncertainty: 4.382829666137695
Epoch 26, Batch 2600/3125, Loss: 2.7828521728515625, Uncertainty: 5.883041858673096
Epoch 26, Batch 2700/3125, Loss: 3.332416534423828, Uncertainty: 4.336655616760254
Epoch 26, Batch 2800/3125, Loss: 3.0034141540527344, Uncertainty: 4.547813415527344
Epoch 26, Batch 2900/3125, Loss: 2.6707077026367188, Uncertainty: 4.364347457885742
Epoch 26, Batch 3000/3125, Loss: 2.690969467163086, Uncertainty: 3.870861053466797
Epoch 26, Batch 3100/3125, Loss: 2.546113967895508, Uncertainty: 4.4058685302734375

Training and Validation Results of Epoch 26:
================================
Training Loss: 2.6602490637207032, Training Uncertainty: 4.893326005096435, time: 144.23526549339294
Validation Loss: 2.524270264998726, Validation Uncertainty: 4.897678028287181, time: 30.66594696044922
Number of predictions within uncertainty interval: 94848/200000 (47.42%)

Epoch 27, Batch 100/3125, Loss: 2.5509471893310547, Uncertainty: 4.478811264038086
Epoch 27, Batch 200/3125, Loss: 2.802745819091797, Uncertainty: 3.840280771255493
Epoch 27, Batch 300/3125, Loss: 2.628164291381836, Uncertainty: 6.0275115966796875
Epoch 27, Batch 400/3125, Loss: 2.6894187927246094, Uncertainty: 4.318545341491699
Epoch 27, Batch 500/3125, Loss: 2.923877716064453, Uncertainty: 4.850607395172119
Epoch 27, Batch 600/3125, Loss: 2.667236328125, Uncertainty: 4.085862159729004
Epoch 27, Batch 700/3125, Loss: 2.9344329833984375, Uncertainty: 4.125724792480469
Epoch 27, Batch 800/3125, Loss: 2.963106155395508, Uncertainty: 5.010403633117676
Epoch 27, Batch 900/3125, Loss: 2.7376537322998047, Uncertainty: 4.245059967041016
Epoch 27, Batch 1000/3125, Loss: 2.896547317504883, Uncertainty: 4.426503658294678
Epoch 27, Batch 1100/3125, Loss: 2.6938915252685547, Uncertainty: 4.355081558227539
Epoch 27, Batch 1200/3125, Loss: 2.9233150482177734, Uncertainty: 4.525470733642578
Epoch 27, Batch 1300/3125, Loss: 2.9220447540283203, Uncertainty: 4.889118194580078
Epoch 27, Batch 1400/3125, Loss: 2.8667964935302734, Uncertainty: 4.566013336181641
Epoch 27, Batch 1500/3125, Loss: 2.631420135498047, Uncertainty: 4.260896682739258
Epoch 27, Batch 1600/3125, Loss: 2.9997787475585938, Uncertainty: 4.261609077453613
Epoch 27, Batch 1700/3125, Loss: 2.6842002868652344, Uncertainty: 3.8162951469421387
Epoch 27, Batch 1800/3125, Loss: 2.5464820861816406, Uncertainty: 4.425249099731445
Epoch 27, Batch 1900/3125, Loss: 3.1299057006835938, Uncertainty: 6.334214210510254
Epoch 27, Batch 2000/3125, Loss: 2.6120243072509766, Uncertainty: 4.796413421630859
Epoch 27, Batch 2100/3125, Loss: 2.6902236938476562, Uncertainty: 5.224693298339844
Epoch 27, Batch 2200/3125, Loss: 2.5659332275390625, Uncertainty: 4.21648645401001
Epoch 27, Batch 2300/3125, Loss: 2.714794158935547, Uncertainty: 4.879852294921875
Epoch 27, Batch 2400/3125, Loss: 2.9096317291259766, Uncertainty: 6.08430290222168
Epoch 27, Batch 2500/3125, Loss: 2.6414222717285156, Uncertainty: 4.441093921661377
Epoch 27, Batch 2600/3125, Loss: 3.6680431365966797, Uncertainty: 5.381641387939453
Epoch 27, Batch 2700/3125, Loss: 2.7554759979248047, Uncertainty: 3.9771924018859863
Epoch 27, Batch 2800/3125, Loss: 2.716400146484375, Uncertainty: 3.939474582672119
Epoch 27, Batch 2900/3125, Loss: 2.680400848388672, Uncertainty: 4.293750762939453
Epoch 27, Batch 3000/3125, Loss: 2.6043453216552734, Uncertainty: 4.268511772155762
Epoch 27, Batch 3100/3125, Loss: 3.0032577514648438, Uncertainty: 4.036564826965332

Training and Validation Results of Epoch 27:
================================
Training Loss: 2.592094093017578, Training Uncertainty: 4.749993721313476, time: 136.18985772132874
Validation Loss: 2.4510171553667854, Validation Uncertainty: 4.1911544397359, time: 30.919942617416382
Number of predictions within uncertainty interval: 89165/200000 (44.58%)

Epoch 28, Batch 100/3125, Loss: 3.131664276123047, Uncertainty: 4.261446952819824
Epoch 28, Batch 200/3125, Loss: 2.9559097290039062, Uncertainty: 4.384901523590088
Epoch 28, Batch 300/3125, Loss: 2.685922622680664, Uncertainty: 4.071855068206787
Epoch 28, Batch 400/3125, Loss: 2.4913101196289062, Uncertainty: 3.9983534812927246
Epoch 28, Batch 500/3125, Loss: 2.759397506713867, Uncertainty: 5.8243327140808105
Epoch 28, Batch 600/3125, Loss: 2.646146774291992, Uncertainty: 3.89717698097229
Epoch 28, Batch 700/3125, Loss: 2.552776336669922, Uncertainty: 3.8703675270080566
Epoch 28, Batch 800/3125, Loss: 2.7061843872070312, Uncertainty: 4.026142120361328
Epoch 28, Batch 900/3125, Loss: 2.5733108520507812, Uncertainty: 4.122795104980469
Epoch 28, Batch 1000/3125, Loss: 2.986398696899414, Uncertainty: 4.186861038208008
Epoch 28, Batch 1100/3125, Loss: 3.007772445678711, Uncertainty: 4.331663131713867
Epoch 28, Batch 1200/3125, Loss: 2.484769821166992, Uncertainty: 3.756340265274048
Epoch 28, Batch 1300/3125, Loss: 2.7039127349853516, Uncertainty: 4.025777816772461
Epoch 28, Batch 1400/3125, Loss: 2.8372669219970703, Uncertainty: 3.792593240737915
Epoch 28, Batch 1500/3125, Loss: 2.7954559326171875, Uncertainty: 4.6017560958862305
Epoch 28, Batch 1600/3125, Loss: 2.677642822265625, Uncertainty: 3.957212448120117
Epoch 28, Batch 1700/3125, Loss: 2.653196334838867, Uncertainty: 4.721529006958008
Epoch 28, Batch 1800/3125, Loss: 2.778911590576172, Uncertainty: 5.035999298095703
Epoch 28, Batch 1900/3125, Loss: 2.577028274536133, Uncertainty: 4.122463703155518
Epoch 28, Batch 2000/3125, Loss: 2.6046810150146484, Uncertainty: 3.947720527648926
Epoch 28, Batch 2100/3125, Loss: 2.711559295654297, Uncertainty: 4.818173885345459
Epoch 28, Batch 2200/3125, Loss: 2.463869094848633, Uncertainty: 3.5538411140441895
Epoch 28, Batch 2300/3125, Loss: 3.3567352294921875, Uncertainty: 4.860058784484863
Epoch 28, Batch 2400/3125, Loss: 2.829275131225586, Uncertainty: 3.9214696884155273
Epoch 28, Batch 2500/3125, Loss: 2.747028350830078, Uncertainty: 4.247625350952148
Epoch 28, Batch 2600/3125, Loss: 2.6422672271728516, Uncertainty: 5.295799255371094
Epoch 28, Batch 2700/3125, Loss: 2.572725296020508, Uncertainty: 4.594869613647461
Epoch 28, Batch 2800/3125, Loss: 2.825794219970703, Uncertainty: 4.291711807250977
Epoch 28, Batch 2900/3125, Loss: 2.603334426879883, Uncertainty: 4.311966419219971
Epoch 28, Batch 3000/3125, Loss: 2.769519805908203, Uncertainty: 4.259552955627441
Epoch 28, Batch 3100/3125, Loss: 2.7829055786132812, Uncertainty: 5.765721321105957

Training and Validation Results of Epoch 28:
================================
Training Loss: 2.536407713623047, Training Uncertainty: 4.641010707244873, time: 145.7754852771759
Validation Loss: 2.8943466859705307, Validation Uncertainty: 4.906968622256423, time: 30.730822563171387
Number of predictions within uncertainty interval: 92546/200000 (46.27%)

Epoch 29, Batch 100/3125, Loss: 3.3317394256591797, Uncertainty: 3.931487798690796
Epoch 29, Batch 200/3125, Loss: 2.6884593963623047, Uncertainty: 4.138243198394775
Epoch 29, Batch 300/3125, Loss: 2.7729644775390625, Uncertainty: 5.134432792663574
Epoch 29, Batch 400/3125, Loss: 2.523578643798828, Uncertainty: 4.796551704406738
Epoch 29, Batch 500/3125, Loss: 2.6255054473876953, Uncertainty: 4.092749118804932
Epoch 29, Batch 600/3125, Loss: 2.7150115966796875, Uncertainty: 4.914033889770508
Epoch 29, Batch 700/3125, Loss: 2.7143115997314453, Uncertainty: 6.299409866333008
Epoch 29, Batch 800/3125, Loss: 2.9557228088378906, Uncertainty: 5.574227333068848
Epoch 29, Batch 900/3125, Loss: 2.805234909057617, Uncertainty: 3.974311351776123
Epoch 29, Batch 1000/3125, Loss: 2.5126380920410156, Uncertainty: 4.241621017456055
Epoch 29, Batch 1100/3125, Loss: 2.9650135040283203, Uncertainty: 5.6800007820129395
Epoch 29, Batch 1200/3125, Loss: 2.735048294067383, Uncertainty: 5.1569695472717285
Epoch 29, Batch 1300/3125, Loss: 2.375009536743164, Uncertainty: 3.8359673023223877
Epoch 29, Batch 1400/3125, Loss: 2.6779918670654297, Uncertainty: 4.085919380187988
Epoch 29, Batch 1500/3125, Loss: 2.8575382232666016, Uncertainty: 5.443141937255859
Epoch 29, Batch 1600/3125, Loss: 2.7525386810302734, Uncertainty: 5.22670841217041
Epoch 29, Batch 1700/3125, Loss: 3.010915756225586, Uncertainty: 3.797675132751465
Epoch 29, Batch 1800/3125, Loss: 2.5069808959960938, Uncertainty: 4.1049275398254395
Epoch 29, Batch 1900/3125, Loss: 2.635883331298828, Uncertainty: 6.846514701843262
Epoch 29, Batch 2000/3125, Loss: 2.8750648498535156, Uncertainty: 4.736248016357422
Epoch 29, Batch 2100/3125, Loss: 3.445047378540039, Uncertainty: 4.157745838165283
Epoch 29, Batch 2200/3125, Loss: 2.949758529663086, Uncertainty: 3.848963737487793
Epoch 29, Batch 2300/3125, Loss: 2.841228485107422, Uncertainty: 4.225404262542725
Epoch 29, Batch 2400/3125, Loss: 2.8422374725341797, Uncertainty: 5.648764610290527
Epoch 29, Batch 2500/3125, Loss: 2.4279556274414062, Uncertainty: 3.964576482772827
Epoch 29, Batch 2600/3125, Loss: 2.6411476135253906, Uncertainty: 4.200771808624268
Epoch 29, Batch 2700/3125, Loss: 2.6970272064208984, Uncertainty: 4.432249069213867
Epoch 29, Batch 2800/3125, Loss: 2.787403106689453, Uncertainty: 4.490650177001953
Epoch 29, Batch 2900/3125, Loss: 2.4111785888671875, Uncertainty: 3.9983694553375244
Epoch 29, Batch 3000/3125, Loss: 2.428302764892578, Uncertainty: 3.8671789169311523
Epoch 29, Batch 3100/3125, Loss: 2.4148292541503906, Uncertainty: 3.850849151611328

Training and Validation Results of Epoch 29:
================================
Training Loss: 2.4745739794921877, Training Uncertainty: 4.51451670211792, time: 146.13364791870117
Validation Loss: 2.3590925806928476, Validation Uncertainty: 6.807716464752431, time: 30.767566680908203
Number of predictions within uncertainty interval: 135606/200000 (67.80%)

Epoch 30, Batch 100/3125, Loss: 2.5304431915283203, Uncertainty: 4.406952857971191
Epoch 30, Batch 200/3125, Loss: 2.5608901977539062, Uncertainty: 3.745941638946533
Epoch 30, Batch 300/3125, Loss: 2.919313430786133, Uncertainty: 4.144150733947754
Epoch 30, Batch 400/3125, Loss: 2.6032257080078125, Uncertainty: 3.873507022857666
Epoch 30, Batch 500/3125, Loss: 2.519702911376953, Uncertainty: 3.8300843238830566
Epoch 30, Batch 600/3125, Loss: 2.4916954040527344, Uncertainty: 3.6578500270843506
Epoch 30, Batch 700/3125, Loss: 2.3654308319091797, Uncertainty: 4.002294540405273
Epoch 30, Batch 800/3125, Loss: 2.7319774627685547, Uncertainty: 3.8424572944641113
Epoch 30, Batch 900/3125, Loss: 2.9659690856933594, Uncertainty: 6.557186126708984
Epoch 30, Batch 1000/3125, Loss: 2.495759963989258, Uncertainty: 4.234135627746582
Epoch 30, Batch 1100/3125, Loss: 2.51171875, Uncertainty: 3.62902569770813
Epoch 30, Batch 1200/3125, Loss: 2.5322437286376953, Uncertainty: 4.008962631225586
Epoch 30, Batch 1300/3125, Loss: 2.503692626953125, Uncertainty: 3.569289207458496
Epoch 30, Batch 1400/3125, Loss: 2.7027034759521484, Uncertainty: 3.98138427734375
Epoch 30, Batch 1500/3125, Loss: 2.292600631713867, Uncertainty: 3.6714046001434326
Epoch 30, Batch 1600/3125, Loss: 2.5123844146728516, Uncertainty: 3.7580718994140625
Epoch 30, Batch 1700/3125, Loss: 2.752613067626953, Uncertainty: 7.312058925628662
Epoch 30, Batch 1800/3125, Loss: 2.5173721313476562, Uncertainty: 4.184683799743652
Epoch 30, Batch 1900/3125, Loss: 2.4747257232666016, Uncertainty: 3.805880546569824
Epoch 30, Batch 2000/3125, Loss: 2.5541629791259766, Uncertainty: 3.7440237998962402
Epoch 30, Batch 2100/3125, Loss: 2.7818355560302734, Uncertainty: 6.878260135650635
Epoch 30, Batch 2200/3125, Loss: 3.0431957244873047, Uncertainty: 6.010971546173096
Epoch 30, Batch 2300/3125, Loss: 2.7129898071289062, Uncertainty: 4.222312927246094
Epoch 30, Batch 2400/3125, Loss: 2.5305233001708984, Uncertainty: 3.8041486740112305
Epoch 30, Batch 2500/3125, Loss: 2.7052764892578125, Uncertainty: 3.5150065422058105
Epoch 30, Batch 2600/3125, Loss: 2.4609413146972656, Uncertainty: 3.7809486389160156
Epoch 30, Batch 2700/3125, Loss: 2.5210037231445312, Uncertainty: 4.121662139892578
Epoch 30, Batch 2800/3125, Loss: 2.5264244079589844, Uncertainty: 3.923387289047241
Epoch 30, Batch 2900/3125, Loss: 2.578714370727539, Uncertainty: 5.370134353637695
Epoch 30, Batch 3000/3125, Loss: 2.9092235565185547, Uncertainty: 3.7723302841186523
Epoch 30, Batch 3100/3125, Loss: 2.576038360595703, Uncertainty: 4.530431747436523

Training and Validation Results of Epoch 30:
================================
Training Loss: 2.4345096813964844, Training Uncertainty: 4.476183520889283, time: 145.57949542999268
Validation Loss: 2.382880559662724, Validation Uncertainty: 4.663225286147174, time: 31.029289722442627
Number of predictions within uncertainty interval: 97063/200000 (48.53%)

Epoch 31, Batch 100/3125, Loss: 2.5977306365966797, Uncertainty: 4.236563682556152
Epoch 31, Batch 200/3125, Loss: 2.549346923828125, Uncertainty: 5.312752723693848
Epoch 31, Batch 300/3125, Loss: 2.7616500854492188, Uncertainty: 5.924182891845703
Epoch 31, Batch 400/3125, Loss: 2.5439453125, Uncertainty: 6.434233665466309
Epoch 31, Batch 500/3125, Loss: 2.569700241088867, Uncertainty: 5.17857551574707
Epoch 31, Batch 600/3125, Loss: 2.3194847106933594, Uncertainty: 3.822202444076538
Epoch 31, Batch 700/3125, Loss: 2.49444580078125, Uncertainty: 4.076491832733154
Epoch 31, Batch 800/3125, Loss: 2.478260040283203, Uncertainty: 5.208930015563965
Epoch 31, Batch 900/3125, Loss: 2.422842025756836, Uncertainty: 3.601212978363037
Epoch 31, Batch 1000/3125, Loss: 2.5045738220214844, Uncertainty: 4.591802597045898
Epoch 31, Batch 1100/3125, Loss: 2.604921340942383, Uncertainty: 5.07190465927124
Epoch 31, Batch 1200/3125, Loss: 2.283231735229492, Uncertainty: 3.614063262939453
Epoch 31, Batch 1300/3125, Loss: 2.654254913330078, Uncertainty: 4.133913993835449
Epoch 31, Batch 1400/3125, Loss: 2.685361862182617, Uncertainty: 4.134342670440674
Epoch 31, Batch 1500/3125, Loss: 2.281393051147461, Uncertainty: 3.9523978233337402
Epoch 31, Batch 1600/3125, Loss: 2.303865432739258, Uncertainty: 3.8283932209014893
Epoch 31, Batch 1700/3125, Loss: 2.2757129669189453, Uncertainty: 3.5334324836730957
Epoch 31, Batch 1800/3125, Loss: 2.8248844146728516, Uncertainty: 8.29955768585205
Epoch 31, Batch 1900/3125, Loss: 2.4911975860595703, Uncertainty: 3.888582706451416
Epoch 31, Batch 2000/3125, Loss: 2.8169517517089844, Uncertainty: 6.857924461364746
Epoch 31, Batch 2100/3125, Loss: 2.5896644592285156, Uncertainty: 4.8058576583862305
Epoch 31, Batch 2200/3125, Loss: 2.7935314178466797, Uncertainty: 3.931795120239258
Epoch 31, Batch 2300/3125, Loss: 2.458038330078125, Uncertainty: 3.7468156814575195
Epoch 31, Batch 2400/3125, Loss: 2.5348777770996094, Uncertainty: 3.9901480674743652
Epoch 31, Batch 2500/3125, Loss: 2.4701614379882812, Uncertainty: 4.130110740661621
Epoch 31, Batch 2600/3125, Loss: 2.715890884399414, Uncertainty: 5.909252166748047
Epoch 31, Batch 2700/3125, Loss: 2.861703872680664, Uncertainty: 6.2467451095581055
Epoch 31, Batch 2800/3125, Loss: 2.278097152709961, Uncertainty: 3.7064762115478516
Epoch 31, Batch 2900/3125, Loss: 2.671527862548828, Uncertainty: 3.9005351066589355
Epoch 31, Batch 3000/3125, Loss: 2.5175399780273438, Uncertainty: 4.2921977043151855
Epoch 31, Batch 3100/3125, Loss: 2.4712581634521484, Uncertainty: 3.8398191928863525

Training and Validation Results of Epoch 31:
================================
Training Loss: 2.3783953039550783, Training Uncertainty: 4.384863125305176, time: 136.21499490737915
Validation Loss: 2.3438041716280495, Validation Uncertainty: 4.092001507044448, time: 30.787359952926636
Number of predictions within uncertainty interval: 90771/200000 (45.39%)

Epoch 32, Batch 100/3125, Loss: 2.4576587677001953, Uncertainty: 4.093542098999023
Epoch 32, Batch 200/3125, Loss: 2.431621551513672, Uncertainty: 3.7933459281921387
Epoch 32, Batch 300/3125, Loss: 2.5205764770507812, Uncertainty: 3.6551151275634766
Epoch 32, Batch 400/3125, Loss: 2.484498977661133, Uncertainty: 4.307483673095703
Epoch 32, Batch 500/3125, Loss: 2.1717662811279297, Uncertainty: 3.4391422271728516
Epoch 32, Batch 600/3125, Loss: 2.5109901428222656, Uncertainty: 4.330667495727539
Epoch 32, Batch 700/3125, Loss: 2.6658668518066406, Uncertainty: 6.977850914001465
Epoch 32, Batch 800/3125, Loss: 2.396575927734375, Uncertainty: 3.7561864852905273
Epoch 32, Batch 900/3125, Loss: 2.4584732055664062, Uncertainty: 3.9965569972991943
Epoch 32, Batch 1000/3125, Loss: 2.644571304321289, Uncertainty: 4.257813930511475
Epoch 32, Batch 1100/3125, Loss: 2.259357452392578, Uncertainty: 3.434100866317749
Epoch 32, Batch 1200/3125, Loss: 2.433025360107422, Uncertainty: 4.80291223526001
Epoch 32, Batch 1300/3125, Loss: 2.4238052368164062, Uncertainty: 3.4892735481262207
Epoch 32, Batch 1400/3125, Loss: 2.2991504669189453, Uncertainty: 3.8675918579101562
Epoch 32, Batch 1500/3125, Loss: 2.367166519165039, Uncertainty: 3.82871675491333
Epoch 32, Batch 1600/3125, Loss: 3.133136749267578, Uncertainty: 9.202961921691895
Epoch 32, Batch 1700/3125, Loss: 2.6429290771484375, Uncertainty: 4.664422035217285
Epoch 32, Batch 1800/3125, Loss: 2.362791061401367, Uncertainty: 3.5567708015441895
Epoch 32, Batch 1900/3125, Loss: 2.3633766174316406, Uncertainty: 3.8691372871398926
Epoch 32, Batch 2000/3125, Loss: 2.481821060180664, Uncertainty: 3.3137459754943848
Epoch 32, Batch 2100/3125, Loss: 2.19989013671875, Uncertainty: 3.622276782989502
Epoch 32, Batch 2200/3125, Loss: 2.6119346618652344, Uncertainty: 5.731215953826904
Epoch 32, Batch 2300/3125, Loss: 2.408273696899414, Uncertainty: 3.579817056655884
Epoch 32, Batch 2400/3125, Loss: 2.4823741912841797, Uncertainty: 4.273026943206787
Epoch 32, Batch 2500/3125, Loss: 2.7995662689208984, Uncertainty: 3.6034140586853027
Epoch 32, Batch 2600/3125, Loss: 2.4480457305908203, Uncertainty: 4.265549659729004
Epoch 32, Batch 2700/3125, Loss: 2.9809207916259766, Uncertainty: 3.4745864868164062
Epoch 32, Batch 2800/3125, Loss: 2.3757076263427734, Uncertainty: 3.3284249305725098
Epoch 32, Batch 2900/3125, Loss: 2.378448486328125, Uncertainty: 3.5038719177246094
Epoch 32, Batch 3000/3125, Loss: 2.4501190185546875, Uncertainty: 3.64359188079834
Epoch 32, Batch 3100/3125, Loss: 2.644268035888672, Uncertainty: 5.056715488433838

Training and Validation Results of Epoch 32:
================================
Training Loss: 2.344549744873047, Training Uncertainty: 4.312880828781128, time: 146.84283900260925
Validation Loss: 2.2229548890877258, Validation Uncertainty: 4.080552728279777, time: 30.919634103775024
Number of predictions within uncertainty interval: 96185/200000 (48.09%)

Epoch 33, Batch 100/3125, Loss: 2.3554553985595703, Uncertainty: 3.5731492042541504
Epoch 33, Batch 200/3125, Loss: 2.2694644927978516, Uncertainty: 3.660658121109009
Epoch 33, Batch 300/3125, Loss: 2.3034534454345703, Uncertainty: 4.659170150756836
Epoch 33, Batch 400/3125, Loss: 2.3818283081054688, Uncertainty: 3.327558994293213
Epoch 33, Batch 500/3125, Loss: 2.3907814025878906, Uncertainty: 3.7186062335968018
Epoch 33, Batch 600/3125, Loss: 2.845224380493164, Uncertainty: 4.9146409034729
Epoch 33, Batch 700/3125, Loss: 2.377269744873047, Uncertainty: 3.7330751419067383
Epoch 33, Batch 800/3125, Loss: 2.3965225219726562, Uncertainty: 5.015833854675293
Epoch 33, Batch 900/3125, Loss: 2.485136032104492, Uncertainty: 3.6438584327697754
Epoch 33, Batch 1000/3125, Loss: 2.791360855102539, Uncertainty: 3.953207015991211
Epoch 33, Batch 1100/3125, Loss: 2.4153289794921875, Uncertainty: 4.860528469085693
Epoch 33, Batch 1200/3125, Loss: 2.4305553436279297, Uncertainty: 4.263850212097168
Epoch 33, Batch 1300/3125, Loss: 2.5794124603271484, Uncertainty: 4.861572265625
Epoch 33, Batch 1400/3125, Loss: 2.5020408630371094, Uncertainty: 5.404534339904785
Epoch 33, Batch 1500/3125, Loss: 2.3359508514404297, Uncertainty: 3.302659273147583
Epoch 33, Batch 1600/3125, Loss: 2.5993690490722656, Uncertainty: 3.8120388984680176
Epoch 33, Batch 1700/3125, Loss: 2.4676876068115234, Uncertainty: 3.7231297492980957
Epoch 33, Batch 1800/3125, Loss: 2.9126949310302734, Uncertainty: 3.4396278858184814
Epoch 33, Batch 1900/3125, Loss: 2.3490066528320312, Uncertainty: 3.8065037727355957
Epoch 33, Batch 2000/3125, Loss: 2.4708595275878906, Uncertainty: 4.145275115966797
Epoch 33, Batch 2100/3125, Loss: 2.550731658935547, Uncertainty: 4.135969161987305
Epoch 33, Batch 2200/3125, Loss: 2.77264404296875, Uncertainty: 6.493161201477051
Epoch 33, Batch 2300/3125, Loss: 2.4244613647460938, Uncertainty: 4.1650848388671875
Epoch 33, Batch 2400/3125, Loss: 2.639719009399414, Uncertainty: 3.4404048919677734
Epoch 33, Batch 2500/3125, Loss: 2.752603530883789, Uncertainty: 6.693062782287598
Epoch 33, Batch 2600/3125, Loss: 2.318828582763672, Uncertainty: 3.518130302429199
Epoch 33, Batch 2700/3125, Loss: 2.6020240783691406, Uncertainty: 3.857241630554199
Epoch 33, Batch 2800/3125, Loss: 2.805147171020508, Uncertainty: 3.8511159420013428
Epoch 33, Batch 2900/3125, Loss: 2.2023963928222656, Uncertainty: 3.58003568649292
Epoch 33, Batch 3000/3125, Loss: 2.779714584350586, Uncertainty: 4.1065545082092285
Epoch 33, Batch 3100/3125, Loss: 2.3239784240722656, Uncertainty: 3.5232770442962646

Training and Validation Results of Epoch 33:
================================
Training Loss: 2.3099390856933595, Training Uncertainty: 4.176220623092651, time: 143.49918150901794
Validation Loss: 2.192075163507096, Validation Uncertainty: 3.46010092243819, time: 30.909632205963135
Number of predictions within uncertainty interval: 81333/200000 (40.67%)

Epoch 34, Batch 100/3125, Loss: 2.335317611694336, Uncertainty: 3.672456741333008
Epoch 34, Batch 200/3125, Loss: 2.3913135528564453, Uncertainty: 3.2963638305664062
Epoch 34, Batch 300/3125, Loss: 2.43121337890625, Uncertainty: 3.722539186477661
Epoch 34, Batch 400/3125, Loss: 2.3291473388671875, Uncertainty: 3.864816188812256
Epoch 34, Batch 500/3125, Loss: 2.5077476501464844, Uncertainty: 3.525477886199951
Epoch 34, Batch 600/3125, Loss: 2.3587646484375, Uncertainty: 4.040885925292969
Epoch 34, Batch 700/3125, Loss: 2.5948219299316406, Uncertainty: 4.363133430480957
Epoch 34, Batch 800/3125, Loss: 2.6258068084716797, Uncertainty: 4.856183052062988
Epoch 34, Batch 900/3125, Loss: 2.3894119262695312, Uncertainty: 3.927708864212036
Epoch 34, Batch 1000/3125, Loss: 2.3439865112304688, Uncertainty: 3.7788283824920654
Epoch 34, Batch 1100/3125, Loss: 2.2263126373291016, Uncertainty: 3.2313671112060547
Epoch 34, Batch 1200/3125, Loss: 2.4180164337158203, Uncertainty: 3.791217565536499
Epoch 34, Batch 1300/3125, Loss: 2.3940792083740234, Uncertainty: 3.7664554119110107
Epoch 34, Batch 1400/3125, Loss: 2.4911670684814453, Uncertainty: 3.496014356613159
Epoch 34, Batch 1500/3125, Loss: 2.282266616821289, Uncertainty: 3.409686803817749
Epoch 34, Batch 1600/3125, Loss: 2.373537063598633, Uncertainty: 3.348170042037964
Epoch 34, Batch 1700/3125, Loss: 2.3576908111572266, Uncertainty: 5.917344570159912
Epoch 34, Batch 1800/3125, Loss: 2.6256275177001953, Uncertainty: 4.607460975646973
Epoch 34, Batch 1900/3125, Loss: 2.4305763244628906, Uncertainty: 3.6889564990997314
Epoch 34, Batch 2000/3125, Loss: 2.385599136352539, Uncertainty: 3.4535627365112305
Epoch 34, Batch 2100/3125, Loss: 2.4280338287353516, Uncertainty: 4.693545341491699
Epoch 34, Batch 2200/3125, Loss: 2.3804664611816406, Uncertainty: 3.315582752227783
Epoch 34, Batch 2300/3125, Loss: 2.6331005096435547, Uncertainty: 3.5643608570098877
Epoch 34, Batch 2400/3125, Loss: 2.675596237182617, Uncertainty: 6.816161155700684
Epoch 34, Batch 2500/3125, Loss: 2.2394027709960938, Uncertainty: 4.084648609161377
Epoch 34, Batch 2600/3125, Loss: 2.278841018676758, Uncertainty: 3.236675500869751
Epoch 34, Batch 2700/3125, Loss: 3.218231201171875, Uncertainty: 8.59743881225586
Epoch 34, Batch 2800/3125, Loss: 2.6579017639160156, Uncertainty: 4.097951889038086
Epoch 34, Batch 2900/3125, Loss: 2.3287277221679688, Uncertainty: 3.3181560039520264
Epoch 34, Batch 3000/3125, Loss: 2.4114456176757812, Uncertainty: 4.576443672180176
Epoch 34, Batch 3100/3125, Loss: 3.146770477294922, Uncertainty: 7.702134609222412

Training and Validation Results of Epoch 34:
================================
Training Loss: 2.2781251086425782, Training Uncertainty: 4.261718750305175, time: 144.84904670715332
Validation Loss: 2.1648074537896744, Validation Uncertainty: 5.04364863624963, time: 30.938489198684692
Number of predictions within uncertainty interval: 117670/200000 (58.83%)

Epoch 35, Batch 100/3125, Loss: 2.227985382080078, Uncertainty: 3.377326011657715
Epoch 35, Batch 200/3125, Loss: 2.3406505584716797, Uncertainty: 3.4736313819885254
Epoch 35, Batch 300/3125, Loss: 2.443044662475586, Uncertainty: 3.6340670585632324
Epoch 35, Batch 400/3125, Loss: 2.267047882080078, Uncertainty: 3.7056264877319336
Epoch 35, Batch 500/3125, Loss: 2.5284385681152344, Uncertainty: 4.880985260009766
Epoch 35, Batch 600/3125, Loss: 2.3710880279541016, Uncertainty: 4.757798194885254
Epoch 35, Batch 700/3125, Loss: 2.455738067626953, Uncertainty: 3.5609540939331055
Epoch 35, Batch 800/3125, Loss: 2.370229721069336, Uncertainty: 4.455635070800781
Epoch 35, Batch 900/3125, Loss: 2.2795162200927734, Uncertainty: 3.6467232704162598
Epoch 35, Batch 1000/3125, Loss: 2.540792465209961, Uncertainty: 5.246339797973633
Epoch 35, Batch 1100/3125, Loss: 2.1136646270751953, Uncertainty: 3.3968849182128906
Epoch 35, Batch 1200/3125, Loss: 2.3701820373535156, Uncertainty: 3.249016046524048
Epoch 35, Batch 1300/3125, Loss: 2.1958274841308594, Uncertainty: 3.5450611114501953
Epoch 35, Batch 1400/3125, Loss: 2.5328197479248047, Uncertainty: 5.632451057434082
Epoch 35, Batch 1500/3125, Loss: 2.332448959350586, Uncertainty: 3.720184326171875
Epoch 35, Batch 1600/3125, Loss: 2.1442718505859375, Uncertainty: 3.5929994583129883
Epoch 35, Batch 1700/3125, Loss: 2.408407211303711, Uncertainty: 4.1987080574035645
Epoch 35, Batch 1800/3125, Loss: 2.375062942504883, Uncertainty: 3.1972179412841797
Epoch 35, Batch 1900/3125, Loss: 2.3038253784179688, Uncertainty: 4.47661828994751
Epoch 35, Batch 2000/3125, Loss: 2.9070281982421875, Uncertainty: 6.952053546905518
Epoch 35, Batch 2100/3125, Loss: 3.115457534790039, Uncertainty: 3.1144349575042725
Epoch 35, Batch 2200/3125, Loss: 2.2661266326904297, Uncertainty: 3.440340042114258
Epoch 35, Batch 2300/3125, Loss: 2.3745079040527344, Uncertainty: 3.3221373558044434
Epoch 35, Batch 2400/3125, Loss: 2.4119510650634766, Uncertainty: 4.407519340515137
Epoch 35, Batch 2500/3125, Loss: 2.192708969116211, Uncertainty: 3.519174098968506
Epoch 35, Batch 2600/3125, Loss: 2.2015209197998047, Uncertainty: 3.191990375518799
Epoch 35, Batch 2700/3125, Loss: 2.040975570678711, Uncertainty: 3.355630874633789
Epoch 35, Batch 2800/3125, Loss: 2.440349578857422, Uncertainty: 3.5193605422973633
Epoch 35, Batch 2900/3125, Loss: 2.529603958129883, Uncertainty: 5.266003608703613
Epoch 35, Batch 3000/3125, Loss: 2.4831275939941406, Uncertainty: 4.4579901695251465
Epoch 35, Batch 3100/3125, Loss: 3.0691566467285156, Uncertainty: 5.332756519317627

Training and Validation Results of Epoch 35:
================================
Training Loss: 2.232093016357422, Training Uncertainty: 4.164036676864624, time: 146.9687843322754
Validation Loss: 2.424078787684136, Validation Uncertainty: 4.1272971136185825, time: 31.079617023468018
Number of predictions within uncertainty interval: 93954/200000 (46.98%)

Epoch 36, Batch 100/3125, Loss: 2.5532283782958984, Uncertainty: 3.1952435970306396
Epoch 36, Batch 200/3125, Loss: 2.3759822845458984, Uncertainty: 3.752310276031494
Epoch 36, Batch 300/3125, Loss: 2.3655776977539062, Uncertainty: 3.5115270614624023
Epoch 36, Batch 400/3125, Loss: 2.3824291229248047, Uncertainty: 3.2739806175231934
Epoch 36, Batch 500/3125, Loss: 2.1453495025634766, Uncertainty: 3.8995721340179443
Epoch 36, Batch 600/3125, Loss: 2.3440704345703125, Uncertainty: 3.827122688293457
Epoch 36, Batch 700/3125, Loss: 2.381643295288086, Uncertainty: 4.1778950691223145
Epoch 36, Batch 800/3125, Loss: 2.2165355682373047, Uncertainty: 3.395331382751465
Epoch 36, Batch 900/3125, Loss: 2.1162586212158203, Uncertainty: 3.3091979026794434
Epoch 36, Batch 1000/3125, Loss: 2.3276500701904297, Uncertainty: 3.5138657093048096
Epoch 36, Batch 1100/3125, Loss: 2.315692901611328, Uncertainty: 4.128378868103027
Epoch 36, Batch 1200/3125, Loss: 2.4526920318603516, Uncertainty: 3.627091407775879
Epoch 36, Batch 1300/3125, Loss: 2.1019153594970703, Uncertainty: 3.6077675819396973
Epoch 36, Batch 1400/3125, Loss: 2.314382553100586, Uncertainty: 3.880620241165161
Epoch 36, Batch 1500/3125, Loss: 2.4022445678710938, Uncertainty: 3.600541353225708
Epoch 36, Batch 1600/3125, Loss: 2.2692623138427734, Uncertainty: 3.5396151542663574
Epoch 36, Batch 1700/3125, Loss: 2.287261962890625, Uncertainty: 3.220677375793457
Epoch 36, Batch 1800/3125, Loss: 2.674884796142578, Uncertainty: 6.248048782348633
Epoch 36, Batch 1900/3125, Loss: 2.3282032012939453, Uncertainty: 3.9179413318634033
Epoch 36, Batch 2000/3125, Loss: 2.239198684692383, Uncertainty: 3.166419267654419
Epoch 36, Batch 2100/3125, Loss: 2.431699752807617, Uncertainty: 3.6048378944396973
Epoch 36, Batch 2200/3125, Loss: 2.2972335815429688, Uncertainty: 3.4005022048950195
Epoch 36, Batch 2300/3125, Loss: 2.4358444213867188, Uncertainty: 5.537100791931152
Epoch 36, Batch 2400/3125, Loss: 2.673307418823242, Uncertainty: 3.759204864501953
Epoch 36, Batch 2500/3125, Loss: 2.499357223510742, Uncertainty: 3.3279881477355957
Epoch 36, Batch 2600/3125, Loss: 2.154569625854492, Uncertainty: 3.301623582839966
Epoch 36, Batch 2700/3125, Loss: 2.36761474609375, Uncertainty: 4.807120323181152
Epoch 36, Batch 2800/3125, Loss: 2.2180957794189453, Uncertainty: 3.560201644897461
Epoch 36, Batch 2900/3125, Loss: 2.4088077545166016, Uncertainty: 4.512701511383057
Epoch 36, Batch 3000/3125, Loss: 2.4492759704589844, Uncertainty: 5.480390548706055
Epoch 36, Batch 3100/3125, Loss: 2.2592525482177734, Uncertainty: 3.6784448623657227

Training and Validation Results of Epoch 36:
================================
Training Loss: 2.2170810314941405, Training Uncertainty: 4.178681520309448, time: 136.9414141178131
Validation Loss: 2.105488662524601, Validation Uncertainty: 3.9218818415766177, time: 30.8861026763916
Number of predictions within uncertainty interval: 96769/200000 (48.38%)

Epoch 37, Batch 100/3125, Loss: 2.1453895568847656, Uncertainty: 3.634657859802246
Epoch 37, Batch 200/3125, Loss: 2.4942283630371094, Uncertainty: 3.5588502883911133
Epoch 37, Batch 300/3125, Loss: 2.1107425689697266, Uncertainty: 3.42375111579895
Epoch 37, Batch 400/3125, Loss: 2.5952835083007812, Uncertainty: 6.374755859375
Epoch 37, Batch 500/3125, Loss: 2.1101646423339844, Uncertainty: 3.2502946853637695
Epoch 37, Batch 600/3125, Loss: 2.3207321166992188, Uncertainty: 4.264699935913086
Epoch 37, Batch 700/3125, Loss: 2.252889633178711, Uncertainty: 4.130507469177246
Epoch 37, Batch 800/3125, Loss: 2.700550079345703, Uncertainty: 3.944993257522583
Epoch 37, Batch 900/3125, Loss: 2.2319583892822266, Uncertainty: 4.42582368850708
Epoch 37, Batch 1000/3125, Loss: 2.308469772338867, Uncertainty: 3.700455665588379
Epoch 37, Batch 1100/3125, Loss: 2.450288772583008, Uncertainty: 4.1038031578063965
Epoch 37, Batch 1200/3125, Loss: 2.5916976928710938, Uncertainty: 3.5278408527374268
Epoch 37, Batch 1300/3125, Loss: 2.5824928283691406, Uncertainty: 6.8992109298706055
Epoch 37, Batch 1400/3125, Loss: 2.2735328674316406, Uncertainty: 3.4917173385620117
Epoch 37, Batch 1500/3125, Loss: 2.1919994354248047, Uncertainty: 3.2835781574249268
Epoch 37, Batch 1600/3125, Loss: 2.3781585693359375, Uncertainty: 5.6075029373168945
Epoch 37, Batch 1700/3125, Loss: 2.2566757202148438, Uncertainty: 5.084310054779053
Epoch 37, Batch 1800/3125, Loss: 2.3602981567382812, Uncertainty: 3.4923646450042725
Epoch 37, Batch 1900/3125, Loss: 2.3025646209716797, Uncertainty: 3.617122173309326
Epoch 37, Batch 2000/3125, Loss: 2.436704635620117, Uncertainty: 5.403554916381836
Epoch 37, Batch 2100/3125, Loss: 2.224151611328125, Uncertainty: 3.7690367698669434
Epoch 37, Batch 2200/3125, Loss: 2.963376998901367, Uncertainty: 3.3254146575927734
Epoch 37, Batch 2300/3125, Loss: 2.398435592651367, Uncertainty: 3.522799491882324
Epoch 37, Batch 2400/3125, Loss: 2.177854537963867, Uncertainty: 3.720977306365967
Epoch 37, Batch 2500/3125, Loss: 2.0854530334472656, Uncertainty: 3.8859853744506836
Epoch 37, Batch 2600/3125, Loss: 2.5017547607421875, Uncertainty: 5.098827362060547
Epoch 37, Batch 2700/3125, Loss: 2.151285171508789, Uncertainty: 3.289517641067505
Epoch 37, Batch 2800/3125, Loss: 2.087902069091797, Uncertainty: 3.9616312980651855
Epoch 37, Batch 2900/3125, Loss: 2.226318359375, Uncertainty: 4.45743989944458
Epoch 37, Batch 3000/3125, Loss: 2.234832763671875, Uncertainty: 3.305629253387451
Epoch 37, Batch 3100/3125, Loss: 2.1243858337402344, Uncertainty: 3.220677375793457

Training and Validation Results of Epoch 37:
================================
Training Loss: 2.1967558935546876, Training Uncertainty: 4.065117937698364, time: 145.08562231063843
Validation Loss: 2.3863053236471115, Validation Uncertainty: 3.231380565087204, time: 30.917490005493164
Number of predictions within uncertainty interval: 70926/200000 (35.46%)

Epoch 38, Batch 100/3125, Loss: 2.410146713256836, Uncertainty: 4.674820899963379
Epoch 38, Batch 200/3125, Loss: 2.2836227416992188, Uncertainty: 3.326313018798828
Epoch 38, Batch 300/3125, Loss: 2.3647232055664062, Uncertainty: 3.427999496459961
Epoch 38, Batch 400/3125, Loss: 2.2643260955810547, Uncertainty: 3.308825731277466
Epoch 38, Batch 500/3125, Loss: 2.2281055450439453, Uncertainty: 3.2177562713623047
Epoch 38, Batch 600/3125, Loss: 2.330657958984375, Uncertainty: 3.155179023742676
Epoch 38, Batch 700/3125, Loss: 2.6767501831054688, Uncertainty: 5.766870498657227
Epoch 38, Batch 800/3125, Loss: 2.285612106323242, Uncertainty: 3.221834659576416
Epoch 38, Batch 900/3125, Loss: 2.109445571899414, Uncertainty: 3.4503421783447266
Epoch 38, Batch 1000/3125, Loss: 2.3016223907470703, Uncertainty: 4.535812854766846
Epoch 38, Batch 1100/3125, Loss: 2.2904796600341797, Uncertainty: 6.313053131103516
Epoch 38, Batch 1200/3125, Loss: 2.48291015625, Uncertainty: 3.726391077041626
Epoch 38, Batch 1300/3125, Loss: 2.123880386352539, Uncertainty: 3.1511573791503906
Epoch 38, Batch 1400/3125, Loss: 2.308490753173828, Uncertainty: 3.5332140922546387
Epoch 38, Batch 1500/3125, Loss: 2.1999454498291016, Uncertainty: 3.4218735694885254
Epoch 38, Batch 1600/3125, Loss: 2.21728515625, Uncertainty: 3.6203346252441406
Epoch 38, Batch 1700/3125, Loss: 2.595874786376953, Uncertainty: 7.039885520935059
Epoch 38, Batch 1800/3125, Loss: 2.3761749267578125, Uncertainty: 3.7320070266723633
Epoch 38, Batch 1900/3125, Loss: 2.184467315673828, Uncertainty: 3.2927465438842773
Epoch 38, Batch 2000/3125, Loss: 2.0964431762695312, Uncertainty: 3.262773036956787
Epoch 38, Batch 2100/3125, Loss: 2.5327911376953125, Uncertainty: 4.918549537658691
Epoch 38, Batch 2200/3125, Loss: 2.2312850952148438, Uncertainty: 3.4819579124450684
Epoch 38, Batch 2300/3125, Loss: 2.3709869384765625, Uncertainty: 3.8783137798309326
Epoch 38, Batch 2400/3125, Loss: 2.797412872314453, Uncertainty: 7.06574821472168
Epoch 38, Batch 2500/3125, Loss: 2.395254135131836, Uncertainty: 5.023092269897461
Epoch 38, Batch 2600/3125, Loss: 2.729127883911133, Uncertainty: 5.942479133605957
Epoch 38, Batch 2700/3125, Loss: 2.2527618408203125, Uncertainty: 3.2931511402130127
Epoch 38, Batch 2800/3125, Loss: 2.4658126831054688, Uncertainty: 4.905666351318359
Epoch 38, Batch 2900/3125, Loss: 2.1723289489746094, Uncertainty: 4.828758239746094
Epoch 38, Batch 3000/3125, Loss: 2.0594348907470703, Uncertainty: 3.333150863647461
Epoch 38, Batch 3100/3125, Loss: 2.363363265991211, Uncertainty: 3.5022616386413574

Training and Validation Results of Epoch 38:
================================
Training Loss: 2.164364645996094, Training Uncertainty: 4.029867876434326, time: 136.80832743644714
Validation Loss: 2.0518726436683283, Validation Uncertainty: 3.51149247278033, time: 31.263306617736816
Number of predictions within uncertainty interval: 88551/200000 (44.28%)

Epoch 39, Batch 100/3125, Loss: 2.7003040313720703, Uncertainty: 3.583296775817871
Epoch 39, Batch 200/3125, Loss: 2.2313804626464844, Uncertainty: 3.4078660011291504
Epoch 39, Batch 300/3125, Loss: 2.383432388305664, Uncertainty: 3.409233570098877
Epoch 39, Batch 400/3125, Loss: 2.0705833435058594, Uncertainty: 3.5144400596618652
Epoch 39, Batch 500/3125, Loss: 2.150350570678711, Uncertainty: 3.4835360050201416
Epoch 39, Batch 600/3125, Loss: 2.5258407592773438, Uncertainty: 3.750570297241211
Epoch 39, Batch 700/3125, Loss: 2.0572853088378906, Uncertainty: 3.7275238037109375
Epoch 39, Batch 800/3125, Loss: 2.1437320709228516, Uncertainty: 3.824557304382324
Epoch 39, Batch 900/3125, Loss: 2.4501895904541016, Uncertainty: 5.2144083976745605
Epoch 39, Batch 1000/3125, Loss: 2.1020278930664062, Uncertainty: 3.6097826957702637
Epoch 39, Batch 1100/3125, Loss: 2.1772708892822266, Uncertainty: 3.3117549419403076
Epoch 39, Batch 1200/3125, Loss: 2.415313720703125, Uncertainty: 5.1325554847717285
Epoch 39, Batch 1300/3125, Loss: 3.1991920471191406, Uncertainty: 5.712247848510742
Epoch 39, Batch 1400/3125, Loss: 2.3853588104248047, Uncertainty: 3.6310083866119385
Epoch 39, Batch 1500/3125, Loss: 2.4109764099121094, Uncertainty: 5.802249908447266
Epoch 39, Batch 1600/3125, Loss: 2.3861026763916016, Uncertainty: 3.5658984184265137
Epoch 39, Batch 1700/3125, Loss: 2.1594467163085938, Uncertainty: 4.028278350830078
Epoch 39, Batch 1800/3125, Loss: 2.4409942626953125, Uncertainty: 3.754228115081787
Epoch 39, Batch 1900/3125, Loss: 2.2204742431640625, Uncertainty: 3.652266502380371
Epoch 39, Batch 2000/3125, Loss: 2.356657028198242, Uncertainty: 3.2689473628997803
Epoch 39, Batch 2100/3125, Loss: 2.505949020385742, Uncertainty: 3.535665988922119
Epoch 39, Batch 2200/3125, Loss: 2.0634498596191406, Uncertainty: 3.4620676040649414
Epoch 39, Batch 2300/3125, Loss: 2.1318893432617188, Uncertainty: 3.7598764896392822
Epoch 39, Batch 2400/3125, Loss: 2.4537315368652344, Uncertainty: 3.2246265411376953
Epoch 39, Batch 2500/3125, Loss: 2.283933639526367, Uncertainty: 3.0871481895446777
Epoch 39, Batch 2600/3125, Loss: 2.2294082641601562, Uncertainty: 4.295207500457764
Epoch 39, Batch 2700/3125, Loss: 2.4834156036376953, Uncertainty: 3.3615384101867676
Epoch 39, Batch 2800/3125, Loss: 1.9802303314208984, Uncertainty: 3.471203565597534
Epoch 39, Batch 2900/3125, Loss: 2.614847183227539, Uncertainty: 5.449081897735596
Epoch 39, Batch 3000/3125, Loss: 2.2854061126708984, Uncertainty: 4.128872871398926
Epoch 39, Batch 3100/3125, Loss: 2.1194114685058594, Uncertainty: 3.3360073566436768

Training and Validation Results of Epoch 39:
================================
Training Loss: 2.1206455041503904, Training Uncertainty: 3.9644822494506835, time: 144.25233507156372
Validation Loss: 2.047359715337339, Validation Uncertainty: 3.153070187324758, time: 31.492031574249268
Number of predictions within uncertainty interval: 78284/200000 (39.14%)

Epoch 40, Batch 100/3125, Loss: 2.166013717651367, Uncertainty: 3.0668530464172363
Epoch 40, Batch 200/3125, Loss: 2.070962905883789, Uncertainty: 3.080366611480713
Epoch 40, Batch 300/3125, Loss: 2.6092453002929688, Uncertainty: 3.5593035221099854
Epoch 40, Batch 400/3125, Loss: 2.4195098876953125, Uncertainty: 4.188908576965332
Epoch 40, Batch 500/3125, Loss: 2.286357879638672, Uncertainty: 3.6874027252197266
Epoch 40, Batch 600/3125, Loss: 2.131908416748047, Uncertainty: 3.911038875579834
Epoch 40, Batch 700/3125, Loss: 2.2111568450927734, Uncertainty: 2.882997989654541
Epoch 40, Batch 800/3125, Loss: 3.071258544921875, Uncertainty: 5.886942386627197
Epoch 40, Batch 900/3125, Loss: 2.165895462036133, Uncertainty: 3.2453503608703613
Epoch 40, Batch 1000/3125, Loss: 2.2562122344970703, Uncertainty: 3.3465352058410645
Epoch 40, Batch 1100/3125, Loss: 2.0823001861572266, Uncertainty: 3.2524070739746094
Epoch 40, Batch 1200/3125, Loss: 2.7334861755371094, Uncertainty: 3.406101942062378
Epoch 40, Batch 1300/3125, Loss: 2.079303741455078, Uncertainty: 2.98014497756958
Epoch 40, Batch 1400/3125, Loss: 2.4064788818359375, Uncertainty: 3.2383670806884766
Epoch 40, Batch 1500/3125, Loss: 2.306201934814453, Uncertainty: 4.874641418457031
Epoch 40, Batch 1600/3125, Loss: 2.207132339477539, Uncertainty: 3.6268651485443115
Epoch 40, Batch 1700/3125, Loss: 2.228219985961914, Uncertainty: 4.547481536865234
Epoch 40, Batch 1800/3125, Loss: 2.227998733520508, Uncertainty: 3.943204879760742
Epoch 40, Batch 1900/3125, Loss: 2.622364044189453, Uncertainty: 3.541160821914673
Epoch 40, Batch 2000/3125, Loss: 2.242563247680664, Uncertainty: 3.39639949798584
Epoch 40, Batch 2100/3125, Loss: 2.2139625549316406, Uncertainty: 4.012805938720703
Epoch 40, Batch 2200/3125, Loss: 1.989166259765625, Uncertainty: 3.333531141281128
Epoch 40, Batch 2300/3125, Loss: 2.1717967987060547, Uncertainty: 3.133451461791992
Epoch 40, Batch 2400/3125, Loss: 2.0722007751464844, Uncertainty: 3.07236385345459
Epoch 40, Batch 2500/3125, Loss: 2.4239978790283203, Uncertainty: 6.028595924377441
Epoch 40, Batch 2600/3125, Loss: 2.368389129638672, Uncertainty: 3.5391860008239746
Epoch 40, Batch 2700/3125, Loss: 2.347156524658203, Uncertainty: 6.034899711608887
Epoch 40, Batch 2800/3125, Loss: 2.1347179412841797, Uncertainty: 3.1574530601501465
Epoch 40, Batch 2900/3125, Loss: 2.089933395385742, Uncertainty: 3.484523296356201
Epoch 40, Batch 3000/3125, Loss: 2.1255722045898438, Uncertainty: 3.547861099243164
Epoch 40, Batch 3100/3125, Loss: 2.1540775299072266, Uncertainty: 3.3090360164642334

Training and Validation Results of Epoch 40:
================================
Training Loss: 2.1094710046386718, Training Uncertainty: 3.8656745949554443, time: 147.60124039649963
Validation Loss: 2.024560767366453, Validation Uncertainty: 3.6721145652444163, time: 30.97455096244812
Number of predictions within uncertainty interval: 91916/200000 (45.96%)

Epoch 41, Batch 100/3125, Loss: 2.1837520599365234, Uncertainty: 3.5829567909240723
Epoch 41, Batch 200/3125, Loss: 2.281709671020508, Uncertainty: 2.8964152336120605
Epoch 41, Batch 300/3125, Loss: 2.3075809478759766, Uncertainty: 3.7632832527160645
Epoch 41, Batch 400/3125, Loss: 2.1419200897216797, Uncertainty: 3.1439552307128906
Epoch 41, Batch 500/3125, Loss: 2.1881675720214844, Uncertainty: 3.119605779647827
Epoch 41, Batch 600/3125, Loss: 2.1287174224853516, Uncertainty: 3.3168530464172363
Epoch 41, Batch 700/3125, Loss: 2.2602691650390625, Uncertainty: 2.9410109519958496
Epoch 41, Batch 800/3125, Loss: 2.239999771118164, Uncertainty: 3.5586318969726562
Epoch 41, Batch 900/3125, Loss: 2.0828189849853516, Uncertainty: 3.274644136428833
Epoch 41, Batch 1000/3125, Loss: 2.1272106170654297, Uncertainty: 3.416743278503418
Epoch 41, Batch 1100/3125, Loss: 2.074756622314453, Uncertainty: 3.2059333324432373
Epoch 41, Batch 1200/3125, Loss: 2.2198848724365234, Uncertainty: 5.9914045333862305
Epoch 41, Batch 1300/3125, Loss: 2.2661819458007812, Uncertainty: 3.2698941230773926
Epoch 41, Batch 1400/3125, Loss: 2.256786346435547, Uncertainty: 4.775819301605225
Epoch 41, Batch 1500/3125, Loss: 2.155193328857422, Uncertainty: 3.5139870643615723
Epoch 41, Batch 1600/3125, Loss: 2.3022518157958984, Uncertainty: 4.0480637550354
Epoch 41, Batch 1700/3125, Loss: 2.1530723571777344, Uncertainty: 3.347773551940918
Epoch 41, Batch 1800/3125, Loss: 2.337831497192383, Uncertainty: 4.929951190948486
Epoch 41, Batch 1900/3125, Loss: 2.078500747680664, Uncertainty: 3.7003583908081055
Epoch 41, Batch 2000/3125, Loss: 2.1713695526123047, Uncertainty: 4.19645881652832
Epoch 41, Batch 2100/3125, Loss: 2.315164566040039, Uncertainty: 4.162762641906738
Epoch 41, Batch 2200/3125, Loss: 2.1983776092529297, Uncertainty: 3.9078421592712402
Epoch 41, Batch 2300/3125, Loss: 2.0509681701660156, Uncertainty: 3.5349135398864746
Epoch 41, Batch 2400/3125, Loss: 2.3001480102539062, Uncertainty: 4.964998245239258
Epoch 41, Batch 2500/3125, Loss: 2.0543460845947266, Uncertainty: 3.190291404724121
Epoch 41, Batch 2600/3125, Loss: 2.2872257232666016, Uncertainty: 4.284938812255859
Epoch 41, Batch 2700/3125, Loss: 1.9998092651367188, Uncertainty: 2.7523012161254883
Epoch 41, Batch 2800/3125, Loss: 2.2153053283691406, Uncertainty: 3.4187097549438477
Epoch 41, Batch 2900/3125, Loss: 2.1972999572753906, Uncertainty: 4.867196083068848
Epoch 41, Batch 3000/3125, Loss: 2.080768585205078, Uncertainty: 3.1638541221618652
Epoch 41, Batch 3100/3125, Loss: 2.1979408264160156, Uncertainty: 3.56349515914917

Training and Validation Results of Epoch 41:
================================
Training Loss: 2.0663554333496092, Training Uncertainty: 3.9066853479766848, time: 144.12954187393188
Validation Loss: 1.9736382906394236, Validation Uncertainty: 3.0568573221831064, time: 31.193458080291748
Number of predictions within uncertainty interval: 78644/200000 (39.32%)

Epoch 42, Batch 100/3125, Loss: 1.9710216522216797, Uncertainty: 3.2228379249572754
Epoch 42, Batch 200/3125, Loss: 1.9648628234863281, Uncertainty: 3.1345114707946777
Epoch 42, Batch 300/3125, Loss: 2.2486419677734375, Uncertainty: 3.137861967086792
Epoch 42, Batch 400/3125, Loss: 2.6613235473632812, Uncertainty: 3.6405975818634033
Epoch 42, Batch 500/3125, Loss: 2.7234039306640625, Uncertainty: 4.19140100479126
Epoch 42, Batch 600/3125, Loss: 2.440000534057617, Uncertainty: 3.3658270835876465
Epoch 42, Batch 700/3125, Loss: 2.238147735595703, Uncertainty: 3.1764779090881348
Epoch 42, Batch 800/3125, Loss: 2.1399612426757812, Uncertainty: 3.4958930015563965
Epoch 42, Batch 900/3125, Loss: 2.2503490447998047, Uncertainty: 3.3854265213012695
Epoch 42, Batch 1000/3125, Loss: 2.0077362060546875, Uncertainty: 3.097109794616699
Epoch 42, Batch 1100/3125, Loss: 2.1516189575195312, Uncertainty: 4.365237236022949
Epoch 42, Batch 1200/3125, Loss: 2.109098434448242, Uncertainty: 3.1698989868164062
Epoch 42, Batch 1300/3125, Loss: 2.748655319213867, Uncertainty: 3.6974289417266846
Epoch 42, Batch 1400/3125, Loss: 2.388601303100586, Uncertainty: 6.409754753112793
Epoch 42, Batch 1500/3125, Loss: 2.049924850463867, Uncertainty: 3.4758810997009277
Epoch 42, Batch 1600/3125, Loss: 2.0887184143066406, Uncertainty: 3.2648122310638428
Epoch 42, Batch 1700/3125, Loss: 2.1314125061035156, Uncertainty: 4.1409220695495605
Epoch 42, Batch 1800/3125, Loss: 2.102609634399414, Uncertainty: 3.600743532180786
Epoch 42, Batch 1900/3125, Loss: 2.0191307067871094, Uncertainty: 3.434084892272949
Epoch 42, Batch 2000/3125, Loss: 2.407806396484375, Uncertainty: 7.596467018127441
Epoch 42, Batch 2100/3125, Loss: 2.1026954650878906, Uncertainty: 4.2063069343566895
Epoch 42, Batch 2200/3125, Loss: 2.146726608276367, Uncertainty: 5.098106861114502
Epoch 42, Batch 2300/3125, Loss: 2.313425064086914, Uncertainty: 5.789261341094971
Epoch 42, Batch 2400/3125, Loss: 2.212024688720703, Uncertainty: 3.4485373497009277
Epoch 42, Batch 2500/3125, Loss: 1.9833526611328125, Uncertainty: 3.025752544403076
Epoch 42, Batch 2600/3125, Loss: 2.3844776153564453, Uncertainty: 3.6595897674560547
Epoch 42, Batch 2700/3125, Loss: 2.0831260681152344, Uncertainty: 3.9915072917938232
Epoch 42, Batch 2800/3125, Loss: 2.298971176147461, Uncertainty: 5.289778709411621
Epoch 42, Batch 2900/3125, Loss: 2.122781753540039, Uncertainty: 2.9962241649627686
Epoch 42, Batch 3000/3125, Loss: 2.3933162689208984, Uncertainty: 3.700601100921631
Epoch 42, Batch 3100/3125, Loss: 2.233560562133789, Uncertainty: 3.179755210876465
