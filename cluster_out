Training on device: cuda
Loaded dataset in: 287.8823745250702 seconds
Created data loaders in: 0.0002789497375488281 seconds
Number of trainable parameters: 647050
Epoch 0, Batch 100/2971, Loss: 22.223026275634766, Uncertainty: 15.369104385375977
Epoch 0, Batch 200/2971, Loss: 7.814568519592285, Uncertainty: 2.7279114723205566
Epoch 0, Batch 300/2971, Loss: 6.65247917175293, Uncertainty: 3.3993921279907227
Epoch 0, Batch 400/2971, Loss: 4.793938636779785, Uncertainty: 5.886807918548584
Epoch 0, Batch 500/2971, Loss: 2.5702481269836426, Uncertainty: 2.988570213317871
Epoch 0, Batch 600/2971, Loss: 1.854457139968872, Uncertainty: 2.8856558799743652
Epoch 0, Batch 700/2971, Loss: 1.6654314994812012, Uncertainty: 2.467722177505493
Epoch 0, Batch 800/2971, Loss: 1.4244513511657715, Uncertainty: 2.776280403137207
Epoch 0, Batch 900/2971, Loss: 1.0484368801116943, Uncertainty: 1.9883980751037598
Epoch 0, Batch 1000/2971, Loss: 0.9163742661476135, Uncertainty: 2.41306734085083
Epoch 0, Batch 1100/2971, Loss: 0.9057265520095825, Uncertainty: 2.4280428886413574
Epoch 0, Batch 1200/2971, Loss: 0.49620339274406433, Uncertainty: 1.6045422554016113
Epoch 0, Batch 1300/2971, Loss: 0.716147780418396, Uncertainty: 2.4474380016326904
Epoch 0, Batch 1400/2971, Loss: 0.48350629210472107, Uncertainty: 1.3928894996643066
Epoch 0, Batch 1500/2971, Loss: 0.4386454224586487, Uncertainty: 1.2078932523727417
Epoch 0, Batch 1600/2971, Loss: 0.4272455871105194, Uncertainty: 1.1595489978790283
Epoch 0, Batch 1700/2971, Loss: 0.45787766575813293, Uncertainty: 1.1358122825622559
Epoch 0, Batch 1800/2971, Loss: 0.5169845819473267, Uncertainty: 1.6488186120986938
Epoch 0, Batch 1900/2971, Loss: 0.4275311231613159, Uncertainty: 1.246911883354187
Epoch 0, Batch 2000/2971, Loss: 0.36266282200813293, Uncertainty: 0.9202513694763184
Epoch 0, Batch 2100/2971, Loss: 0.42714157700538635, Uncertainty: 1.2626852989196777
Epoch 0, Batch 2200/2971, Loss: 0.3608412742614746, Uncertainty: 0.9175649881362915
Epoch 0, Batch 2300/2971, Loss: 0.33450087904930115, Uncertainty: 0.8609716296195984
Epoch 0, Batch 2400/2971, Loss: 0.43732064962387085, Uncertainty: 1.333082675933838
Epoch 0, Batch 2500/2971, Loss: 0.3822174668312073, Uncertainty: 1.0415493249893188
Epoch 0, Batch 2600/2971, Loss: 0.2856394648551941, Uncertainty: 0.651923656463623
Epoch 0, Batch 2700/2971, Loss: 0.33124271035194397, Uncertainty: 0.8193232417106628
Epoch 0, Batch 2800/2971, Loss: 0.46061068773269653, Uncertainty: 1.3632484674453735
Epoch 0, Batch 2900/2971, Loss: 0.33969271183013916, Uncertainty: 0.9860208034515381

Training and Validation Results of Epoch 0:
================================
Training Loss: 2.8589658407912597, Training Uncertainty: 2.3002788790626103, time: 1689.9030137062073
Validation Loss: 0.2744629125174732, Validation Uncertainty: 0.9602386839136301, time: 330.5556552410126
Number of predictions within uncertainty interval: 587147/763521 (76.90%)

Epoch 1, Batch 100/2971, Loss: 0.325603723526001, Uncertainty: 0.8534449934959412
Epoch 1, Batch 200/2971, Loss: 0.34002235531806946, Uncertainty: 1.0085389614105225
Epoch 1, Batch 300/2971, Loss: 0.3070363700389862, Uncertainty: 0.9048820734024048
Epoch 1, Batch 400/2971, Loss: 0.36907586455345154, Uncertainty: 1.137344241142273
Epoch 1, Batch 500/2971, Loss: 0.28635790944099426, Uncertainty: 0.7970044612884521
Epoch 1, Batch 600/2971, Loss: 0.277129203081131, Uncertainty: 0.7217363119125366
Epoch 1, Batch 700/2971, Loss: 0.33103519678115845, Uncertainty: 0.998340904712677
Epoch 1, Batch 800/2971, Loss: 0.3964291214942932, Uncertainty: 1.2574217319488525
Epoch 1, Batch 900/2971, Loss: 0.4001733064651489, Uncertainty: 0.9793912768363953
Epoch 1, Batch 1000/2971, Loss: 0.29659637808799744, Uncertainty: 0.6413124203681946
Epoch 1, Batch 1100/2971, Loss: 0.27506569027900696, Uncertainty: 0.6527839303016663
Epoch 1, Batch 1200/2971, Loss: 0.27657830715179443, Uncertainty: 0.6553848385810852
Epoch 1, Batch 1300/2971, Loss: 0.3365323543548584, Uncertainty: 1.095375418663025
Epoch 1, Batch 1400/2971, Loss: 0.33001184463500977, Uncertainty: 1.0336028337478638
Epoch 1, Batch 1500/2971, Loss: 0.4084634482860565, Uncertainty: 1.2979674339294434
Epoch 1, Batch 1600/2971, Loss: 0.34468138217926025, Uncertainty: 0.99952632188797
Epoch 1, Batch 1700/2971, Loss: 0.31954851746559143, Uncertainty: 0.8130660653114319
Epoch 1, Batch 1800/2971, Loss: 0.31478574872016907, Uncertainty: 0.9943215847015381
Epoch 1, Batch 1900/2971, Loss: 0.2567155361175537, Uncertainty: 0.5830832123756409
Epoch 1, Batch 2000/2971, Loss: 0.286781907081604, Uncertainty: 0.8432756662368774
Epoch 1, Batch 2100/2971, Loss: 0.34688103199005127, Uncertainty: 1.0490564107894897
Epoch 1, Batch 2200/2971, Loss: 0.2731339931488037, Uncertainty: 0.7151767015457153
Epoch 1, Batch 2300/2971, Loss: 0.29694128036499023, Uncertainty: 0.8743744492530823
Epoch 1, Batch 2400/2971, Loss: 0.29519808292388916, Uncertainty: 0.8457711935043335
Epoch 1, Batch 2500/2971, Loss: 0.3431726396083832, Uncertainty: 1.1927729845046997
Epoch 1, Batch 2600/2971, Loss: 0.25704067945480347, Uncertainty: 0.6289904117584229
Epoch 1, Batch 2700/2971, Loss: 0.2500942349433899, Uncertainty: 0.6333398222923279
Epoch 1, Batch 2800/2971, Loss: 0.2789977490901947, Uncertainty: 0.7841811180114746
Epoch 1, Batch 2900/2971, Loss: 0.21550029516220093, Uncertainty: 0.45524653792381287

Training and Validation Results of Epoch 1:
================================
Training Loss: 0.20437543324371332, Training Uncertainty: 0.8732937099214597, time: 1695.0654768943787
Validation Loss: 0.17569766298919154, Validation Uncertainty: 0.7443146523524422, time: 337.61290287971497
Number of predictions within uncertainty interval: 625750/763521 (81.96%)

Epoch 2, Batch 100/2971, Loss: 0.3744840919971466, Uncertainty: 1.1096328496932983
Epoch 2, Batch 200/2971, Loss: 0.414070725440979, Uncertainty: 1.2349834442138672
Epoch 2, Batch 300/2971, Loss: 0.22923268377780914, Uncertainty: 0.5241557955741882
Epoch 2, Batch 400/2971, Loss: 0.2511708736419678, Uncertainty: 0.7024984955787659
Epoch 2, Batch 500/2971, Loss: 0.2574644386768341, Uncertainty: 0.8567493557929993
Epoch 2, Batch 600/2971, Loss: 0.2529125213623047, Uncertainty: 0.7167057394981384
Epoch 2, Batch 700/2971, Loss: 0.3141457438468933, Uncertainty: 0.9355294108390808
Epoch 2, Batch 800/2971, Loss: 0.26837158203125, Uncertainty: 0.7775705456733704
Epoch 2, Batch 900/2971, Loss: 0.25821131467819214, Uncertainty: 0.6974465847015381
Epoch 2, Batch 1000/2971, Loss: 0.3010040521621704, Uncertainty: 0.9528125524520874
Epoch 2, Batch 1100/2971, Loss: 0.2873198091983795, Uncertainty: 0.8542478084564209
Epoch 2, Batch 1200/2971, Loss: 0.22646385431289673, Uncertainty: 0.4819585978984833
Epoch 2, Batch 1300/2971, Loss: 0.3356545567512512, Uncertainty: 0.9046735167503357
Epoch 2, Batch 1400/2971, Loss: 0.24755781888961792, Uncertainty: 0.664834201335907
Epoch 2, Batch 1500/2971, Loss: 0.2607002854347229, Uncertainty: 0.6591218113899231
Epoch 2, Batch 1600/2971, Loss: 0.2688940465450287, Uncertainty: 0.7672945857048035
Epoch 2, Batch 1700/2971, Loss: 0.2766588628292084, Uncertainty: 0.8068135976791382
Epoch 2, Batch 1800/2971, Loss: 0.3300653100013733, Uncertainty: 1.056719422340393
Epoch 2, Batch 1900/2971, Loss: 0.2993123233318329, Uncertainty: 0.9088768362998962
Epoch 2, Batch 2000/2971, Loss: 0.2511337101459503, Uncertainty: 0.7106972932815552
Epoch 2, Batch 2100/2971, Loss: 0.3349093794822693, Uncertainty: 0.985707700252533
Epoch 2, Batch 2200/2971, Loss: 0.30298593640327454, Uncertainty: 0.8983701467514038
Epoch 2, Batch 2300/2971, Loss: 0.3253253996372223, Uncertainty: 0.9952875971794128
Epoch 2, Batch 2400/2971, Loss: 0.3111407160758972, Uncertainty: 1.010655403137207
Epoch 2, Batch 2500/2971, Loss: 0.21649707853794098, Uncertainty: 0.4654283821582794
Epoch 2, Batch 2600/2971, Loss: 0.33399367332458496, Uncertainty: 0.9466548562049866
Epoch 2, Batch 2700/2971, Loss: 0.26731768250465393, Uncertainty: 0.7843319773674011
Epoch 2, Batch 2800/2971, Loss: 0.3027823269367218, Uncertainty: 0.9394494295120239
Epoch 2, Batch 2900/2971, Loss: 0.216261625289917, Uncertainty: 0.531167209148407

Training and Validation Results of Epoch 2:
================================
Training Loss: 0.18629685544839253, Training Uncertainty: 0.7932634073971337, time: 1709.243943452835
Validation Loss: 0.17083850767699096, Validation Uncertainty: 0.39486962584916546, time: 340.67996764183044
Number of predictions within uncertainty interval: 463397/763521 (60.69%)

Epoch 3, Batch 100/2971, Loss: 0.33563029766082764, Uncertainty: 1.0623043775558472
Epoch 3, Batch 200/2971, Loss: 0.32614004611968994, Uncertainty: 0.9965238571166992
Epoch 3, Batch 300/2971, Loss: 0.24394968152046204, Uncertainty: 0.6530900001525879
Epoch 3, Batch 400/2971, Loss: 0.2565305531024933, Uncertainty: 0.7446656227111816
Epoch 3, Batch 500/2971, Loss: 0.24554722011089325, Uncertainty: 0.6881794333457947
Epoch 3, Batch 600/2971, Loss: 0.2664887011051178, Uncertainty: 0.7009828090667725
Epoch 3, Batch 700/2971, Loss: 0.2445044070482254, Uncertainty: 0.6550216674804688
Epoch 3, Batch 800/2971, Loss: 0.21416477859020233, Uncertainty: 0.5024336576461792
Epoch 3, Batch 900/2971, Loss: 0.22079215943813324, Uncertainty: 0.5760834217071533
Epoch 3, Batch 1000/2971, Loss: 0.26388776302337646, Uncertainty: 0.7756651043891907
Epoch 3, Batch 1100/2971, Loss: 0.36559945344924927, Uncertainty: 1.0357677936553955
Epoch 3, Batch 1200/2971, Loss: 0.3273649215698242, Uncertainty: 1.0265954732894897
Epoch 3, Batch 1300/2971, Loss: 0.32622843980789185, Uncertainty: 1.0390337705612183
Epoch 3, Batch 1400/2971, Loss: 0.2768329679965973, Uncertainty: 0.8065672516822815
Epoch 3, Batch 1500/2971, Loss: 0.26261892914772034, Uncertainty: 0.7688521146774292
Epoch 3, Batch 1600/2971, Loss: 0.23659120500087738, Uncertainty: 0.6382843852043152
Epoch 3, Batch 1700/2971, Loss: 0.25193729996681213, Uncertainty: 0.6612334847450256
Epoch 3, Batch 1800/2971, Loss: 0.25398191809654236, Uncertainty: 0.7312802672386169
Epoch 3, Batch 1900/2971, Loss: 0.2900618016719818, Uncertainty: 0.8862899541854858
Epoch 3, Batch 2000/2971, Loss: 0.18978247046470642, Uncertainty: 0.34360411763191223
Epoch 3, Batch 2100/2971, Loss: 0.27742254734039307, Uncertainty: 0.8151058554649353
Epoch 3, Batch 2200/2971, Loss: 0.25534117221832275, Uncertainty: 0.6705930233001709
Epoch 3, Batch 2300/2971, Loss: 0.26060089468955994, Uncertainty: 0.828239381313324
Epoch 3, Batch 2400/2971, Loss: 0.2943856120109558, Uncertainty: 0.9553787708282471
Epoch 3, Batch 2500/2971, Loss: 0.2924253046512604, Uncertainty: 0.9749526977539062
Epoch 3, Batch 2600/2971, Loss: 0.22370104491710663, Uncertainty: 0.5227642059326172
Epoch 3, Batch 2700/2971, Loss: 0.24993476271629333, Uncertainty: 0.65967857837677
Epoch 3, Batch 2800/2971, Loss: 0.2916148900985718, Uncertainty: 0.6203113198280334
Epoch 3, Batch 2900/2971, Loss: 0.27763432264328003, Uncertainty: 0.7950136065483093

Training and Validation Results of Epoch 3:
================================
Training Loss: 0.1802863058458872, Training Uncertainty: 0.6841307178525883, time: 1717.5156021118164
Validation Loss: 0.18285634445871352, Validation Uncertainty: 0.6835946023544425, time: 342.08123660087585
Number of predictions within uncertainty interval: 590276/763521 (77.31%)

Epoch 4, Batch 100/2971, Loss: 0.25832778215408325, Uncertainty: 0.6706599593162537
Epoch 4, Batch 200/2971, Loss: 0.30224335193634033, Uncertainty: 0.9361535310745239
Epoch 4, Batch 300/2971, Loss: 0.28250300884246826, Uncertainty: 0.8459111452102661
Epoch 4, Batch 400/2971, Loss: 0.25791457295417786, Uncertainty: 0.739193320274353
Epoch 4, Batch 500/2971, Loss: 0.21498379111289978, Uncertainty: 0.4736175537109375
Epoch 4, Batch 600/2971, Loss: 0.20015260577201843, Uncertainty: 0.41760504245758057
Epoch 4, Batch 700/2971, Loss: 0.28975602984428406, Uncertainty: 0.7331312298774719
Epoch 4, Batch 800/2971, Loss: 0.30792540311813354, Uncertainty: 1.0001235008239746
Epoch 4, Batch 900/2971, Loss: 0.23713260889053345, Uncertainty: 0.6341621279716492
Epoch 4, Batch 1000/2971, Loss: 0.2899300456047058, Uncertainty: 0.9392682313919067
Epoch 4, Batch 1100/2971, Loss: 0.2215789407491684, Uncertainty: 0.5094224214553833
Epoch 4, Batch 1200/2971, Loss: 0.269374817609787, Uncertainty: 0.8045739531517029
Epoch 4, Batch 1300/2971, Loss: 0.26362287998199463, Uncertainty: 0.8010126948356628
Epoch 4, Batch 1400/2971, Loss: 0.24883650243282318, Uncertainty: 0.6967000365257263
Epoch 4, Batch 1500/2971, Loss: 0.25391191244125366, Uncertainty: 0.6473415493965149
Epoch 4, Batch 1600/2971, Loss: 0.217307910323143, Uncertainty: 0.49315735697746277
Epoch 4, Batch 1700/2971, Loss: 0.24697473645210266, Uncertainty: 0.6965585947036743
Epoch 4, Batch 1800/2971, Loss: 0.19566205143928528, Uncertainty: 0.38526785373687744
Epoch 4, Batch 1900/2971, Loss: 0.25089001655578613, Uncertainty: 0.7332977652549744
Epoch 4, Batch 2000/2971, Loss: 0.24486929178237915, Uncertainty: 0.6954711079597473
Epoch 4, Batch 2100/2971, Loss: 0.2810196578502655, Uncertainty: 0.8670266270637512
Epoch 4, Batch 2200/2971, Loss: 0.23429857194423676, Uncertainty: 0.609098494052887
Epoch 4, Batch 2300/2971, Loss: 0.3016175329685211, Uncertainty: 0.9205843210220337
Epoch 4, Batch 2400/2971, Loss: 0.2139303833246231, Uncertainty: 0.5237394571304321
Epoch 4, Batch 2500/2971, Loss: 0.2697070240974426, Uncertainty: 0.7575641870498657
Epoch 4, Batch 2600/2971, Loss: 0.2280399054288864, Uncertainty: 0.6071798801422119
Epoch 4, Batch 2700/2971, Loss: 0.2594233453273773, Uncertainty: 0.6601546406745911
Epoch 4, Batch 2800/2971, Loss: 0.3022530674934387, Uncertainty: 0.9136981964111328
Epoch 4, Batch 2900/2971, Loss: 0.21386951208114624, Uncertainty: 0.4698280692100525

Training and Validation Results of Epoch 4:
================================
Training Loss: 0.17585267772059857, Training Uncertainty: 0.6508618180888625, time: 1719.5214836597443
Validation Loss: 0.19578836782062037, Validation Uncertainty: 1.1176381489790945, time: 341.52959394454956
Number of predictions within uncertainty interval: 723130/763521 (94.71%)

Epoch 5, Batch 100/2971, Loss: 0.25235921144485474, Uncertainty: 0.7246657609939575
Epoch 5, Batch 200/2971, Loss: 0.22792743146419525, Uncertainty: 0.6176761388778687
Epoch 5, Batch 300/2971, Loss: 0.2859251797199249, Uncertainty: 0.6052866578102112
Epoch 5, Batch 400/2971, Loss: 0.20953521132469177, Uncertainty: 0.5105609893798828
Epoch 5, Batch 500/2971, Loss: 0.26377591490745544, Uncertainty: 0.7491586208343506
Epoch 5, Batch 600/2971, Loss: 0.2030748426914215, Uncertainty: 0.4415343701839447
Epoch 5, Batch 700/2971, Loss: 0.28009331226348877, Uncertainty: 0.848317563533783
Epoch 5, Batch 800/2971, Loss: 0.22592011094093323, Uncertainty: 0.6060953736305237
Epoch 5, Batch 900/2971, Loss: 0.17552420496940613, Uncertainty: 0.273543119430542
Epoch 5, Batch 1000/2971, Loss: 0.19860312342643738, Uncertainty: 0.40989169478416443
Epoch 5, Batch 1100/2971, Loss: 0.24377045035362244, Uncertainty: 0.5770137310028076
Epoch 5, Batch 1200/2971, Loss: 0.2575221359729767, Uncertainty: 0.7420568466186523
Epoch 5, Batch 1300/2971, Loss: 0.23753449320793152, Uncertainty: 0.6085840463638306
Epoch 5, Batch 1400/2971, Loss: 0.2623453438282013, Uncertainty: 0.7626720666885376
Epoch 5, Batch 1500/2971, Loss: 0.22707177698612213, Uncertainty: 0.5712679028511047
Epoch 5, Batch 1600/2971, Loss: 0.24804188311100006, Uncertainty: 0.6511197090148926
Epoch 5, Batch 1700/2971, Loss: 0.2797737419605255, Uncertainty: 0.7537437081336975
Epoch 5, Batch 1800/2971, Loss: 0.24403971433639526, Uncertainty: 0.7099002003669739
Epoch 5, Batch 1900/2971, Loss: 0.2410574108362198, Uncertainty: 0.6339535117149353
Epoch 5, Batch 2000/2971, Loss: 0.19429540634155273, Uncertainty: 0.4398144781589508
Epoch 5, Batch 2100/2971, Loss: 0.22814972698688507, Uncertainty: 0.5820731520652771
Epoch 5, Batch 2200/2971, Loss: 0.22582824528217316, Uncertainty: 0.5630068182945251
Epoch 5, Batch 2300/2971, Loss: 0.20453965663909912, Uncertainty: 0.4324931502342224
Epoch 5, Batch 2400/2971, Loss: 0.2070484459400177, Uncertainty: 0.46239861845970154
Epoch 5, Batch 2500/2971, Loss: 0.23187389969825745, Uncertainty: 0.5768131017684937
Epoch 5, Batch 2600/2971, Loss: 0.22456912696361542, Uncertainty: 0.6048359870910645
Epoch 5, Batch 2700/2971, Loss: 0.2138403207063675, Uncertainty: 0.48591476678848267
Epoch 5, Batch 2800/2971, Loss: 0.23458008468151093, Uncertainty: 0.6603588461875916
Epoch 5, Batch 2900/2971, Loss: 0.26731693744659424, Uncertainty: 0.7424805760383606

Training and Validation Results of Epoch 5:
================================
Training Loss: 0.1709252193755712, Training Uncertainty: 0.6082643481947605, time: 1722.1903502941132
Validation Loss: 0.16108580296646058, Validation Uncertainty: 0.3235524763249132, time: 344.97582817077637
Number of predictions within uncertainty interval: 419387/763521 (54.93%)

Epoch 6, Batch 100/2971, Loss: 0.25721463561058044, Uncertainty: 0.5688230991363525
Epoch 6, Batch 200/2971, Loss: 0.23276694118976593, Uncertainty: 0.7162588238716125
Epoch 6, Batch 300/2971, Loss: 0.23918284475803375, Uncertainty: 0.5598101615905762
Epoch 6, Batch 400/2971, Loss: 0.2063441276550293, Uncertainty: 0.423634797334671
Epoch 6, Batch 500/2971, Loss: 0.22014100849628448, Uncertainty: 0.5803431868553162
Epoch 6, Batch 600/2971, Loss: 0.2041747272014618, Uncertainty: 0.496999591588974
Epoch 6, Batch 700/2971, Loss: 0.20560292899608612, Uncertainty: 0.4710618555545807
Epoch 6, Batch 800/2971, Loss: 0.22511005401611328, Uncertainty: 0.6212098598480225
Epoch 6, Batch 900/2971, Loss: 0.2220693826675415, Uncertainty: 0.5191369652748108
Epoch 6, Batch 1000/2971, Loss: 0.20015636086463928, Uncertainty: 0.45734602212905884
Epoch 6, Batch 1100/2971, Loss: 0.17987895011901855, Uncertainty: 0.2801419198513031
Epoch 6, Batch 1200/2971, Loss: 0.19777944684028625, Uncertainty: 0.370530366897583
Epoch 6, Batch 1300/2971, Loss: 0.25736236572265625, Uncertainty: 0.7448195219039917
Epoch 6, Batch 1400/2971, Loss: 0.23110859096050262, Uncertainty: 0.3939131200313568
Epoch 6, Batch 1500/2971, Loss: 0.18298929929733276, Uncertainty: 0.3210080564022064
Epoch 6, Batch 1600/2971, Loss: 0.2449127584695816, Uncertainty: 0.6269745826721191
Epoch 6, Batch 1700/2971, Loss: 0.21566073596477509, Uncertainty: 0.5424970984458923
Epoch 6, Batch 1800/2971, Loss: 0.2050035446882248, Uncertainty: 0.5064545273780823
Epoch 6, Batch 1900/2971, Loss: 0.18510282039642334, Uncertainty: 0.30470725893974304
Epoch 6, Batch 2000/2971, Loss: 0.23324401676654816, Uncertainty: 0.6363717913627625
Epoch 6, Batch 2100/2971, Loss: 0.21621829271316528, Uncertainty: 0.5637781023979187
Epoch 6, Batch 2200/2971, Loss: 0.20895487070083618, Uncertainty: 0.48760339617729187
Epoch 6, Batch 2300/2971, Loss: 0.1984878033399582, Uncertainty: 0.46145784854888916
Epoch 6, Batch 2400/2971, Loss: 0.2510817348957062, Uncertainty: 0.736328125
Epoch 6, Batch 2500/2971, Loss: 0.256525456905365, Uncertainty: 0.7216565608978271
Epoch 6, Batch 2600/2971, Loss: 0.22698000073432922, Uncertainty: 0.5110389590263367
Epoch 6, Batch 2700/2971, Loss: 0.20252342522144318, Uncertainty: 0.49384573101997375
Epoch 6, Batch 2800/2971, Loss: 0.22936686873435974, Uncertainty: 0.6500841379165649
Epoch 6, Batch 2900/2971, Loss: 0.20968495309352875, Uncertainty: 0.4791928827762604

Training and Validation Results of Epoch 6:
================================
Training Loss: 0.16946195374932285, Training Uncertainty: 0.5613481235279454, time: 1716.5633521080017
Validation Loss: 0.15814436653260427, Validation Uncertainty: 0.6485671967388322, time: 341.4994795322418
Number of predictions within uncertainty interval: 565464/763521 (74.06%)

Epoch 7, Batch 100/2971, Loss: 0.19361147284507751, Uncertainty: 0.33635392785072327
Epoch 7, Batch 200/2971, Loss: 0.22744865715503693, Uncertainty: 0.5610436201095581
Epoch 7, Batch 300/2971, Loss: 0.18762096762657166, Uncertainty: 0.36337074637413025
Epoch 7, Batch 400/2971, Loss: 0.21323846280574799, Uncertainty: 0.513237714767456
Epoch 7, Batch 500/2971, Loss: 0.1820746213197708, Uncertainty: 0.3025814890861511
Epoch 7, Batch 600/2971, Loss: 0.22281219065189362, Uncertainty: 0.6145918965339661
Epoch 7, Batch 700/2971, Loss: 0.24549734592437744, Uncertainty: 0.7083181738853455
Epoch 7, Batch 800/2971, Loss: 0.24281080067157745, Uncertainty: 0.665395200252533
Epoch 7, Batch 900/2971, Loss: 0.19671858847141266, Uncertainty: 0.39874783158302307
Epoch 7, Batch 1000/2971, Loss: 0.19989287853240967, Uncertainty: 0.35709062218666077
Epoch 7, Batch 1100/2971, Loss: 0.2151733785867691, Uncertainty: 0.5268775224685669
Epoch 7, Batch 1200/2971, Loss: 0.21239317953586578, Uncertainty: 0.4666259288787842
Epoch 7, Batch 1300/2971, Loss: 0.23345811665058136, Uncertainty: 0.4966161847114563
Epoch 7, Batch 1400/2971, Loss: 0.23905134201049805, Uncertainty: 0.6280010342597961
Epoch 7, Batch 1500/2971, Loss: 0.2219737023115158, Uncertainty: 0.6148958206176758
Epoch 7, Batch 1600/2971, Loss: 0.18919771909713745, Uncertainty: 0.3324284553527832
Epoch 7, Batch 1700/2971, Loss: 0.23041106760501862, Uncertainty: 0.5802562236785889
Epoch 7, Batch 1800/2971, Loss: 0.24228085577487946, Uncertainty: 0.6514697074890137
Epoch 7, Batch 1900/2971, Loss: 0.1990525871515274, Uncertainty: 0.42189812660217285
Epoch 7, Batch 2000/2971, Loss: 0.23121251165866852, Uncertainty: 0.509795606136322
Epoch 7, Batch 2100/2971, Loss: 0.20958289504051208, Uncertainty: 0.4698341190814972
Epoch 7, Batch 2200/2971, Loss: 0.18767060339450836, Uncertainty: 0.35353541374206543
Epoch 7, Batch 2300/2971, Loss: 0.2057666778564453, Uncertainty: 0.5211197733879089
Epoch 7, Batch 2400/2971, Loss: 0.23911623656749725, Uncertainty: 0.6710240840911865
Epoch 7, Batch 2500/2971, Loss: 0.27033084630966187, Uncertainty: 0.8096141815185547
Epoch 7, Batch 2600/2971, Loss: 0.208912193775177, Uncertainty: 0.5214958786964417
Epoch 7, Batch 2700/2971, Loss: 0.1817021369934082, Uncertainty: 0.3434761166572571
Epoch 7, Batch 2800/2971, Loss: 0.18418407440185547, Uncertainty: 0.39742907881736755
Epoch 7, Batch 2900/2971, Loss: 0.20239882171154022, Uncertainty: 0.4881201386451721

Training and Validation Results of Epoch 7:
================================
Training Loss: 0.16709575225551776, Training Uncertainty: 0.5257187787028363, time: 1726.2187507152557
Validation Loss: 0.1600673158188046, Validation Uncertainty: 0.6251921173220207, time: 343.1564631462097
Number of predictions within uncertainty interval: 574364/763521 (75.23%)

Epoch 8, Batch 100/2971, Loss: 0.28413695096969604, Uncertainty: 0.8155637979507446
Epoch 8, Batch 200/2971, Loss: 0.1925898939371109, Uncertainty: 0.37300553917884827
Epoch 8, Batch 300/2971, Loss: 0.2120923101902008, Uncertainty: 0.46559831500053406
Epoch 8, Batch 400/2971, Loss: 0.20624248683452606, Uncertainty: 0.4416691064834595
Epoch 8, Batch 500/2971, Loss: 0.20424558222293854, Uncertainty: 0.5051289796829224
Epoch 8, Batch 600/2971, Loss: 0.1822410225868225, Uncertainty: 0.3599942624568939
Epoch 8, Batch 700/2971, Loss: 0.2214653044939041, Uncertainty: 0.5597171783447266
Epoch 8, Batch 800/2971, Loss: 0.18442469835281372, Uncertainty: 0.3699619770050049
Epoch 8, Batch 900/2971, Loss: 0.2045373022556305, Uncertainty: 0.5308700203895569
Epoch 8, Batch 1000/2971, Loss: 0.20424339175224304, Uncertainty: 0.507992148399353
Epoch 8, Batch 1100/2971, Loss: 0.2278972715139389, Uncertainty: 0.5986525416374207
Epoch 8, Batch 1200/2971, Loss: 0.23136579990386963, Uncertainty: 0.6563124060630798
Epoch 8, Batch 1300/2971, Loss: 0.19457502663135529, Uncertainty: 0.36321133375167847
Epoch 8, Batch 1400/2971, Loss: 0.2077411264181137, Uncertainty: 0.5060178637504578
Epoch 8, Batch 1500/2971, Loss: 0.20546557009220123, Uncertainty: 0.4823041260242462
Epoch 8, Batch 1600/2971, Loss: 0.2274198830127716, Uncertainty: 0.5989912152290344
Epoch 8, Batch 1700/2971, Loss: 0.22071027755737305, Uncertainty: 0.56526118516922
Epoch 8, Batch 1800/2971, Loss: 0.2003025859594345, Uncertainty: 0.49089115858078003
Epoch 8, Batch 1900/2971, Loss: 0.20540931820869446, Uncertainty: 0.4976953864097595
Epoch 8, Batch 2000/2971, Loss: 0.20655511319637299, Uncertainty: 0.5110344290733337
Epoch 8, Batch 2100/2971, Loss: 0.21249519288539886, Uncertainty: 0.5202617645263672
Epoch 8, Batch 2200/2971, Loss: 0.216950923204422, Uncertainty: 0.5459467172622681
Epoch 8, Batch 2300/2971, Loss: 0.20667965710163116, Uncertainty: 0.5361816883087158
Epoch 8, Batch 2400/2971, Loss: 0.21370553970336914, Uncertainty: 0.5290605425834656
Epoch 8, Batch 2500/2971, Loss: 0.21113502979278564, Uncertainty: 0.5123645067214966
Epoch 8, Batch 2600/2971, Loss: 0.23349300026893616, Uncertainty: 0.6522789001464844
Epoch 8, Batch 2700/2971, Loss: 0.25463882088661194, Uncertainty: 0.7002573013305664
Epoch 8, Batch 2800/2971, Loss: 0.2579706311225891, Uncertainty: 0.8280029892921448
Epoch 8, Batch 2900/2971, Loss: 0.20355592668056488, Uncertainty: 0.5277280807495117

Training and Validation Results of Epoch 8:
================================
Training Loss: 0.16509583079325393, Training Uncertainty: 0.5317888331860655, time: 1716.64905834198
Validation Loss: 0.1701612734858794, Validation Uncertainty: 0.49007455100121117, time: 341.91112875938416
Number of predictions within uncertainty interval: 540136/763521 (70.74%)

Epoch 9, Batch 100/2971, Loss: 0.27036556601524353, Uncertainty: 0.7961441278457642
Epoch 9, Batch 200/2971, Loss: 0.21571941673755646, Uncertainty: 0.5317150950431824
Epoch 9, Batch 300/2971, Loss: 0.1870003640651703, Uncertainty: 0.37829336524009705
Epoch 9, Batch 400/2971, Loss: 0.23642370104789734, Uncertainty: 0.6169418692588806
Epoch 9, Batch 500/2971, Loss: 0.20977403223514557, Uncertainty: 0.5132359862327576
Epoch 9, Batch 600/2971, Loss: 0.17410530149936676, Uncertainty: 0.2855967879295349
Epoch 9, Batch 700/2971, Loss: 0.1896788626909256, Uncertainty: 0.3640453815460205
Epoch 9, Batch 800/2971, Loss: 0.22905145585536957, Uncertainty: 0.6538035273551941
Epoch 9, Batch 900/2971, Loss: 0.20450294017791748, Uncertainty: 0.5282992124557495
Epoch 9, Batch 1000/2971, Loss: 0.21559661626815796, Uncertainty: 0.5690434575080872
Epoch 9, Batch 1100/2971, Loss: 0.21324507892131805, Uncertainty: 0.5533319115638733
Epoch 9, Batch 1200/2971, Loss: 0.1969139724969864, Uncertainty: 0.4098353385925293
Epoch 9, Batch 1300/2971, Loss: 0.2305482029914856, Uncertainty: 0.5864847302436829
Epoch 9, Batch 1400/2971, Loss: 0.22373925149440765, Uncertainty: 0.5909625291824341
Epoch 9, Batch 1500/2971, Loss: 0.20130306482315063, Uncertainty: 0.49386417865753174
Epoch 9, Batch 1600/2971, Loss: 0.20602983236312866, Uncertainty: 0.4789524972438812
Epoch 9, Batch 1700/2971, Loss: 0.21742133796215057, Uncertainty: 0.5403798222541809
Epoch 9, Batch 1800/2971, Loss: 0.1634683609008789, Uncertainty: 0.22006019949913025
Epoch 9, Batch 1900/2971, Loss: 0.17120352387428284, Uncertainty: 0.2467648684978485
Epoch 9, Batch 2000/2971, Loss: 0.22117651998996735, Uncertainty: 0.4836452007293701
Epoch 9, Batch 2100/2971, Loss: 0.22965653240680695, Uncertainty: 0.6220608949661255
Epoch 9, Batch 2200/2971, Loss: 0.21762892603874207, Uncertainty: 0.5053532719612122
Epoch 9, Batch 2300/2971, Loss: 0.1916215717792511, Uncertainty: 0.4364052712917328
Epoch 9, Batch 2400/2971, Loss: 0.20076192915439606, Uncertainty: 0.44745123386383057
Epoch 9, Batch 2500/2971, Loss: 0.20218110084533691, Uncertainty: 0.3991686701774597
Epoch 9, Batch 2600/2971, Loss: 0.20918500423431396, Uncertainty: 0.5135432481765747
Epoch 9, Batch 2700/2971, Loss: 0.2138371467590332, Uncertainty: 0.5563345551490784
Epoch 9, Batch 2800/2971, Loss: 0.1644333153963089, Uncertainty: 0.24195803701877594
Epoch 9, Batch 2900/2971, Loss: 0.22996599972248077, Uncertainty: 0.6179769039154053

Training and Validation Results of Epoch 9:
================================
Training Loss: 0.16309107058640482, Training Uncertainty: 0.4624394615494575, time: 1720.8005957603455
Validation Loss: 0.1628179038557679, Validation Uncertainty: 0.5820010239471497, time: 341.9921431541443
Number of predictions within uncertainty interval: 569624/763521 (74.60%)

Epoch 10, Batch 100/2971, Loss: 0.23167864978313446, Uncertainty: 0.6266164183616638
Epoch 10, Batch 200/2971, Loss: 0.1821972131729126, Uncertainty: 0.26672136783599854
Epoch 10, Batch 300/2971, Loss: 0.2090364396572113, Uncertainty: 0.5161030888557434
Epoch 10, Batch 400/2971, Loss: 0.19142553210258484, Uncertainty: 0.3984677493572235
Epoch 10, Batch 500/2971, Loss: 0.18483911454677582, Uncertainty: 0.3427850008010864
Epoch 10, Batch 600/2971, Loss: 0.20340384542942047, Uncertainty: 0.476382851600647
Epoch 10, Batch 700/2971, Loss: 0.22519338130950928, Uncertainty: 0.6013886332511902
Epoch 10, Batch 800/2971, Loss: 0.19501043856143951, Uncertainty: 0.47015440464019775
Epoch 10, Batch 900/2971, Loss: 0.19637584686279297, Uncertainty: 0.4757389426231384
Epoch 10, Batch 1000/2971, Loss: 0.20355160534381866, Uncertainty: 0.5136709213256836
Epoch 10, Batch 1100/2971, Loss: 0.19693730771541595, Uncertainty: 0.4231593608856201
Epoch 10, Batch 1200/2971, Loss: 0.24467840790748596, Uncertainty: 0.5120038986206055
Epoch 10, Batch 1300/2971, Loss: 0.22510960698127747, Uncertainty: 0.6139082312583923
Epoch 10, Batch 1400/2971, Loss: 0.2017221301794052, Uncertainty: 0.5039362907409668
Epoch 10, Batch 1500/2971, Loss: 0.20172345638275146, Uncertainty: 0.5093071460723877
Epoch 10, Batch 1600/2971, Loss: 0.250967800617218, Uncertainty: 0.729861855506897
Epoch 10, Batch 1700/2971, Loss: 0.1822735071182251, Uncertainty: 0.3527984619140625
Epoch 10, Batch 1800/2971, Loss: 0.17167986929416656, Uncertainty: 0.293047159910202
Epoch 10, Batch 1900/2971, Loss: 0.18577513098716736, Uncertainty: 0.3578639030456543
Epoch 10, Batch 2000/2971, Loss: 0.18345476686954498, Uncertainty: 0.40994465351104736
Epoch 10, Batch 2100/2971, Loss: 0.20084230601787567, Uncertainty: 0.45752280950546265
Epoch 10, Batch 2200/2971, Loss: 0.21767716109752655, Uncertainty: 0.5483403205871582
Epoch 10, Batch 2300/2971, Loss: 0.19212111830711365, Uncertainty: 0.44561880826950073
Epoch 10, Batch 2400/2971, Loss: 0.1925225555896759, Uncertainty: 0.37777677178382874
Epoch 10, Batch 2500/2971, Loss: 0.23056067526340485, Uncertainty: 0.6319754719734192
Epoch 10, Batch 2600/2971, Loss: 0.23478271067142487, Uncertainty: 0.6274324059486389
Epoch 10, Batch 2700/2971, Loss: 0.20420551300048828, Uncertainty: 0.4768484830856323
Epoch 10, Batch 2800/2971, Loss: 0.1855655014514923, Uncertainty: 0.3788853585720062
Epoch 10, Batch 2900/2971, Loss: 0.17872563004493713, Uncertainty: 0.26883986592292786

Training and Validation Results of Epoch 10:
================================
Training Loss: 0.16303248970807901, Training Uncertainty: 0.4736732122814643, time: 1719.5862905979156
Validation Loss: 0.15632693345180912, Validation Uncertainty: 0.5754204793541139, time: 342.6806015968323
Number of predictions within uncertainty interval: 606465/763521 (79.43%)

Epoch 11, Batch 100/2971, Loss: 0.2020292580127716, Uncertainty: 0.35636231303215027
Epoch 11, Batch 200/2971, Loss: 0.1871498078107834, Uncertainty: 0.331390917301178
Epoch 11, Batch 300/2971, Loss: 0.1910591870546341, Uncertainty: 0.4193722605705261
Epoch 11, Batch 400/2971, Loss: 0.16911081969738007, Uncertainty: 0.2688589096069336
Epoch 11, Batch 500/2971, Loss: 0.1753205806016922, Uncertainty: 0.30623674392700195
Epoch 11, Batch 600/2971, Loss: 0.20462700724601746, Uncertainty: 0.4953966438770294
Epoch 11, Batch 700/2971, Loss: 0.18959355354309082, Uncertainty: 0.33949580788612366
Epoch 11, Batch 800/2971, Loss: 0.2022343873977661, Uncertainty: 0.4398960471153259
Epoch 11, Batch 900/2971, Loss: 0.2032279521226883, Uncertainty: 0.4916159212589264
Epoch 11, Batch 1000/2971, Loss: 0.18255765736103058, Uncertainty: 0.35654357075691223
Epoch 11, Batch 1100/2971, Loss: 0.2330876886844635, Uncertainty: 0.6256113648414612
Epoch 11, Batch 1200/2971, Loss: 0.18953993916511536, Uncertainty: 0.37129443883895874
Epoch 11, Batch 1300/2971, Loss: 0.1847246140241623, Uncertainty: 0.263955682516098
Epoch 11, Batch 1400/2971, Loss: 0.16999782621860504, Uncertainty: 0.2969207465648651
Epoch 11, Batch 1500/2971, Loss: 0.18715395033359528, Uncertainty: 0.39975816011428833
Epoch 11, Batch 1600/2971, Loss: 0.1705000400543213, Uncertainty: 0.19469183683395386
Epoch 11, Batch 1700/2971, Loss: 0.22712644934654236, Uncertainty: 0.6136024594306946
Epoch 11, Batch 1800/2971, Loss: 0.17658624053001404, Uncertainty: 0.36143824458122253
Epoch 11, Batch 1900/2971, Loss: 0.18559584021568298, Uncertainty: 0.3555542528629303
Epoch 11, Batch 2000/2971, Loss: 0.20419135689735413, Uncertainty: 0.5410010814666748
Epoch 11, Batch 2100/2971, Loss: 0.24540798366069794, Uncertainty: 0.6819425225257874
Epoch 11, Batch 2200/2971, Loss: 0.22453844547271729, Uncertainty: 0.605119526386261
Epoch 11, Batch 2300/2971, Loss: 0.19002437591552734, Uncertainty: 0.40014785528182983
Epoch 11, Batch 2400/2971, Loss: 0.21991048753261566, Uncertainty: 0.5664688348770142
Epoch 11, Batch 2500/2971, Loss: 0.24976171553134918, Uncertainty: 0.6588784456253052
Epoch 11, Batch 2600/2971, Loss: 0.18124109506607056, Uncertainty: 0.35669395327568054
Epoch 11, Batch 2700/2971, Loss: 0.19757206737995148, Uncertainty: 0.4526064991950989
Epoch 11, Batch 2800/2971, Loss: 0.2502891421318054, Uncertainty: 0.7285376191139221
Epoch 11, Batch 2900/2971, Loss: 0.19812265038490295, Uncertainty: 0.45295560359954834

Training and Validation Results of Epoch 11:
================================
Training Loss: 0.16096966396434184, Training Uncertainty: 0.4612152317042946, time: 1719.178524017334
Validation Loss: 0.15372807826360493, Validation Uncertainty: 0.570458773328029, time: 343.7496862411499
Number of predictions within uncertainty interval: 597124/763521 (78.21%)

Epoch 12, Batch 100/2971, Loss: 0.18372191488742828, Uncertainty: 0.32267504930496216
Epoch 12, Batch 200/2971, Loss: 0.18403831124305725, Uncertainty: 0.32965871691703796
Epoch 12, Batch 300/2971, Loss: 0.16997261345386505, Uncertainty: 0.24654775857925415
Epoch 12, Batch 400/2971, Loss: 0.1774098128080368, Uncertainty: 0.33339545130729675
Epoch 12, Batch 500/2971, Loss: 0.17866748571395874, Uncertainty: 0.3453379273414612
Epoch 12, Batch 600/2971, Loss: 0.23177579045295715, Uncertainty: 0.6292402744293213
Epoch 12, Batch 700/2971, Loss: 0.2139299362897873, Uncertainty: 0.5674344897270203
Epoch 12, Batch 800/2971, Loss: 0.18398992717266083, Uncertainty: 0.3741306662559509
Epoch 12, Batch 900/2971, Loss: 0.17995376884937286, Uncertainty: 0.381429523229599
Epoch 12, Batch 1000/2971, Loss: 0.20108523964881897, Uncertainty: 0.41609612107276917
Epoch 12, Batch 1100/2971, Loss: 0.23306947946548462, Uncertainty: 0.6007984280586243
Epoch 12, Batch 1200/2971, Loss: 0.20801104605197906, Uncertainty: 0.42144009470939636
Epoch 12, Batch 1300/2971, Loss: 0.18913805484771729, Uncertainty: 0.42188560962677
Epoch 12, Batch 1400/2971, Loss: 0.23666507005691528, Uncertainty: 0.6423421502113342
Epoch 12, Batch 1500/2971, Loss: 0.21065600216388702, Uncertainty: 0.46068522334098816
Epoch 12, Batch 1600/2971, Loss: 0.1704244166612625, Uncertainty: 0.18916042149066925
Epoch 12, Batch 1700/2971, Loss: 0.17162960767745972, Uncertainty: 0.23484383523464203
Epoch 12, Batch 1800/2971, Loss: 0.1667395532131195, Uncertainty: 0.2661854922771454
Epoch 12, Batch 1900/2971, Loss: 0.18976202607154846, Uncertainty: 0.30546078085899353
Epoch 12, Batch 2000/2971, Loss: 0.19221234321594238, Uncertainty: 0.44591063261032104
Epoch 12, Batch 2100/2971, Loss: 0.20169416069984436, Uncertainty: 0.4004475176334381
Epoch 12, Batch 2200/2971, Loss: 0.2024465799331665, Uncertainty: 0.4616859555244446
Epoch 12, Batch 2300/2971, Loss: 0.19263926148414612, Uncertainty: 0.40925246477127075
Epoch 12, Batch 2400/2971, Loss: 0.19347155094146729, Uncertainty: 0.41829994320869446
Epoch 12, Batch 2500/2971, Loss: 0.2137124240398407, Uncertainty: 0.4522860050201416
Epoch 12, Batch 2600/2971, Loss: 0.1804559975862503, Uncertainty: 0.35384929180145264
Epoch 12, Batch 2700/2971, Loss: 0.1704157143831253, Uncertainty: 0.2762361764907837
Epoch 12, Batch 2800/2971, Loss: 0.17565038800239563, Uncertainty: 0.32538506388664246
Epoch 12, Batch 2900/2971, Loss: 0.1621008962392807, Uncertainty: 0.19851155579090118

Training and Validation Results of Epoch 12:
================================
Training Loss: 0.16018189802810986, Training Uncertainty: 0.4132576876268849, time: 1721.561663866043
Validation Loss: 0.1567889802348405, Validation Uncertainty: 0.23744495676311478, time: 341.0094299316406
Number of predictions within uncertainty interval: 350498/763521 (45.91%)

Epoch 13, Batch 100/2971, Loss: 0.19054193794727325, Uncertainty: 0.39489877223968506
Epoch 13, Batch 200/2971, Loss: 0.20941025018692017, Uncertainty: 0.5030379891395569
Epoch 13, Batch 300/2971, Loss: 0.22132672369480133, Uncertainty: 0.5590097308158875
Epoch 13, Batch 400/2971, Loss: 0.1971193552017212, Uncertainty: 0.4722140431404114
Epoch 13, Batch 500/2971, Loss: 0.18901586532592773, Uncertainty: 0.43412134051322937
Epoch 13, Batch 600/2971, Loss: 0.1694353073835373, Uncertainty: 0.27289605140686035
Epoch 13, Batch 700/2971, Loss: 0.19815832376480103, Uncertainty: 0.4409845769405365
Epoch 13, Batch 800/2971, Loss: 0.2186603546142578, Uncertainty: 0.4998760223388672
Epoch 13, Batch 900/2971, Loss: 0.19847489893436432, Uncertainty: 0.4803020656108856
Epoch 13, Batch 1000/2971, Loss: 0.1837683618068695, Uncertainty: 0.3738928735256195
Epoch 13, Batch 1100/2971, Loss: 0.189713254570961, Uncertainty: 0.3691173493862152
Epoch 13, Batch 1200/2971, Loss: 0.1738116294145584, Uncertainty: 0.24922922253608704
Epoch 13, Batch 1300/2971, Loss: 0.18024681508541107, Uncertainty: 0.2950778901576996
Epoch 13, Batch 1400/2971, Loss: 0.17280182242393494, Uncertainty: 0.29959481954574585
Epoch 13, Batch 1500/2971, Loss: 0.19810935854911804, Uncertainty: 0.4662620425224304
Epoch 13, Batch 1600/2971, Loss: 0.20117615163326263, Uncertainty: 0.4631199538707733
Epoch 13, Batch 1700/2971, Loss: 0.23703478276729584, Uncertainty: 0.6677150726318359
Epoch 13, Batch 1800/2971, Loss: 0.214425727725029, Uncertainty: 0.5863470435142517
Epoch 13, Batch 1900/2971, Loss: 0.20107842981815338, Uncertainty: 0.4232434928417206
Epoch 13, Batch 2000/2971, Loss: 0.19413292407989502, Uncertainty: 0.47976595163345337
Epoch 13, Batch 2100/2971, Loss: 0.2129228711128235, Uncertainty: 0.5199673771858215
Epoch 13, Batch 2200/2971, Loss: 0.1723521202802658, Uncertainty: 0.16444993019104004
Epoch 13, Batch 2300/2971, Loss: 0.2002958208322525, Uncertainty: 0.5321512818336487
Epoch 13, Batch 2400/2971, Loss: 0.18141810595989227, Uncertainty: 0.29638421535491943
Epoch 13, Batch 2500/2971, Loss: 0.21047720313072205, Uncertainty: 0.4196241497993469
Epoch 13, Batch 2600/2971, Loss: 0.208555668592453, Uncertainty: 0.4708249270915985
Epoch 13, Batch 2700/2971, Loss: 0.1895362287759781, Uncertainty: 0.3033202588558197
Epoch 13, Batch 2800/2971, Loss: 0.19373860955238342, Uncertainty: 0.4788525700569153
Epoch 13, Batch 2900/2971, Loss: 0.1804991066455841, Uncertainty: 0.35156506299972534

Training and Validation Results of Epoch 13:
================================
Training Loss: 0.15994803728839838, Training Uncertainty: 0.4252186123368235, time: 1718.1875984668732
Validation Loss: 0.15497072971605197, Validation Uncertainty: 0.26454879626290795, time: 341.98246812820435
Number of predictions within uncertainty interval: 382929/763521 (50.15%)

Epoch 14, Batch 100/2971, Loss: 0.18500269949436188, Uncertainty: 0.37529465556144714
Epoch 14, Batch 200/2971, Loss: 0.2533363997936249, Uncertainty: 0.7047543525695801
Epoch 14, Batch 300/2971, Loss: 0.19268091022968292, Uncertainty: 0.42264845967292786
Epoch 14, Batch 400/2971, Loss: 0.1789795160293579, Uncertainty: 0.3838251531124115
Epoch 14, Batch 500/2971, Loss: 0.169950470328331, Uncertainty: 0.2644868791103363
Epoch 14, Batch 600/2971, Loss: 0.17972324788570404, Uncertainty: 0.3619775176048279
Epoch 14, Batch 700/2971, Loss: 0.20445795357227325, Uncertainty: 0.48375219106674194
Epoch 14, Batch 800/2971, Loss: 0.17710407078266144, Uncertainty: 0.35431087017059326
Epoch 14, Batch 900/2971, Loss: 0.18978792428970337, Uncertainty: 0.44959548115730286
Epoch 14, Batch 1000/2971, Loss: 0.19272643327713013, Uncertainty: 0.35870587825775146
Epoch 14, Batch 1100/2971, Loss: 0.1907118260860443, Uncertainty: 0.4051908552646637
Epoch 14, Batch 1200/2971, Loss: 0.19315354526042938, Uncertainty: 0.3936191201210022
Epoch 14, Batch 1300/2971, Loss: 0.1844777911901474, Uncertainty: 0.37681907415390015
Epoch 14, Batch 1400/2971, Loss: 0.18754270672798157, Uncertainty: 0.38245418667793274
Epoch 14, Batch 1500/2971, Loss: 0.19622662663459778, Uncertainty: 0.47443827986717224
Epoch 14, Batch 1600/2971, Loss: 0.17313428223133087, Uncertainty: 0.1687425822019577
Epoch 14, Batch 1700/2971, Loss: 0.18246690928936005, Uncertainty: 0.362862229347229
Epoch 14, Batch 1800/2971, Loss: 0.2041861116886139, Uncertainty: 0.49424976110458374
Epoch 14, Batch 1900/2971, Loss: 0.17475992441177368, Uncertainty: 0.2837112247943878
Epoch 14, Batch 2000/2971, Loss: 0.1819780468940735, Uncertainty: 0.42033788561820984
Epoch 14, Batch 2100/2971, Loss: 0.2084534764289856, Uncertainty: 0.5095446109771729
Epoch 14, Batch 2200/2971, Loss: 0.201887845993042, Uncertainty: 0.44522860646247864
Epoch 14, Batch 2300/2971, Loss: 0.1839369237422943, Uncertainty: 0.4517814815044403
Epoch 14, Batch 2400/2971, Loss: 0.19863680005073547, Uncertainty: 0.4408608675003052
Epoch 14, Batch 2500/2971, Loss: 0.2071976214647293, Uncertainty: 0.4945929944515228
Epoch 14, Batch 2600/2971, Loss: 0.21202583611011505, Uncertainty: 0.5119931697845459
Epoch 14, Batch 2700/2971, Loss: 0.17392361164093018, Uncertainty: 0.2376609891653061
Epoch 14, Batch 2800/2971, Loss: 0.19701677560806274, Uncertainty: 0.4900181293487549
Epoch 14, Batch 2900/2971, Loss: 0.17322181165218353, Uncertainty: 0.28913620114326477

Training and Validation Results of Epoch 14:
================================
Training Loss: 0.15927946836869752, Training Uncertainty: 0.39606732445527953, time: 1716.1308431625366
Validation Loss: 0.15501693398522495, Validation Uncertainty: 0.2646107988514778, time: 340.65590167045593
Number of predictions within uncertainty interval: 395402/763521 (51.79%)

Epoch 15, Batch 100/2971, Loss: 0.20733006298542023, Uncertainty: 0.516056478023529
Epoch 15, Batch 200/2971, Loss: 0.19479863345623016, Uncertainty: 0.4154030680656433
Epoch 15, Batch 300/2971, Loss: 0.20266379415988922, Uncertainty: 0.4457657039165497
Epoch 15, Batch 400/2971, Loss: 0.17486773431301117, Uncertainty: 0.3263525366783142
Epoch 15, Batch 500/2971, Loss: 0.17397642135620117, Uncertainty: 0.29162198305130005
Epoch 15, Batch 600/2971, Loss: 0.16393741965293884, Uncertainty: 0.23101839423179626
Epoch 15, Batch 700/2971, Loss: 0.18941232562065125, Uncertainty: 0.37959718704223633
Epoch 15, Batch 800/2971, Loss: 0.17695149779319763, Uncertainty: 0.3226518929004669
Epoch 15, Batch 900/2971, Loss: 0.18312792479991913, Uncertainty: 0.31052935123443604
Epoch 15, Batch 1000/2971, Loss: 0.17606619000434875, Uncertainty: 0.20607511699199677
Epoch 15, Batch 1100/2971, Loss: 0.18372955918312073, Uncertainty: 0.3426225483417511
Epoch 15, Batch 1200/2971, Loss: 0.23283694684505463, Uncertainty: 0.6122843623161316
Epoch 15, Batch 1300/2971, Loss: 0.18648450076580048, Uncertainty: 0.3574763536453247
Epoch 15, Batch 1400/2971, Loss: 0.22468654811382294, Uncertainty: 0.6105526089668274
Epoch 15, Batch 1500/2971, Loss: 0.18910245597362518, Uncertainty: 0.42450377345085144
Epoch 15, Batch 1600/2971, Loss: 0.19704602658748627, Uncertainty: 0.42128971219062805
Epoch 15, Batch 1700/2971, Loss: 0.17529797554016113, Uncertainty: 0.3102332651615143
Epoch 15, Batch 1800/2971, Loss: 0.16455958783626556, Uncertainty: 0.2524169087409973
Epoch 15, Batch 1900/2971, Loss: 0.18149462342262268, Uncertainty: 0.2929128110408783
Epoch 15, Batch 2000/2971, Loss: 0.2185073345899582, Uncertainty: 0.5010198354721069
Epoch 15, Batch 2100/2971, Loss: 0.1918076127767563, Uncertainty: 0.37406420707702637
Epoch 15, Batch 2200/2971, Loss: 0.1776530146598816, Uncertainty: 0.3291912376880646
Epoch 15, Batch 2300/2971, Loss: 0.18404175341129303, Uncertainty: 0.4622741639614105
Epoch 15, Batch 2400/2971, Loss: 0.20139789581298828, Uncertainty: 0.4743039011955261
Epoch 15, Batch 2500/2971, Loss: 0.20651046931743622, Uncertainty: 0.5094893574714661
Epoch 15, Batch 2600/2971, Loss: 0.19694775342941284, Uncertainty: 0.38582560420036316
Epoch 15, Batch 2700/2971, Loss: 0.1924857795238495, Uncertainty: 0.40926501154899597
Epoch 15, Batch 2800/2971, Loss: 0.18311122059822083, Uncertainty: 0.39602577686309814
Epoch 15, Batch 2900/2971, Loss: 0.183247372508049, Uncertainty: 0.35060185194015503

Training and Validation Results of Epoch 15:
================================
Training Loss: 0.15852005172361633, Training Uncertainty: 0.38827131945390325, time: 1716.9858748912811
Validation Loss: 0.1572629317019541, Validation Uncertainty: 0.36457683653401496, time: 341.6185653209686
Number of predictions within uncertainty interval: 438972/763521 (57.49%)

Epoch 16, Batch 100/2971, Loss: 0.1810494214296341, Uncertainty: 0.32944345474243164
Epoch 16, Batch 200/2971, Loss: 0.20208525657653809, Uncertainty: 0.4869901239871979
Epoch 16, Batch 300/2971, Loss: 0.1936095803976059, Uncertainty: 0.42597389221191406
Epoch 16, Batch 400/2971, Loss: 0.18433289229869843, Uncertainty: 0.34184810519218445
Epoch 16, Batch 500/2971, Loss: 0.16955983638763428, Uncertainty: 0.28042930364608765
Epoch 16, Batch 600/2971, Loss: 0.1867322027683258, Uncertainty: 0.4024355411529541
Epoch 16, Batch 700/2971, Loss: 0.20672377943992615, Uncertainty: 0.4241066873073578
Epoch 16, Batch 800/2971, Loss: 0.1736088991165161, Uncertainty: 0.29651719331741333
Epoch 16, Batch 900/2971, Loss: 0.18901127576828003, Uncertainty: 0.4125562906265259
Epoch 16, Batch 1000/2971, Loss: 0.172505721449852, Uncertainty: 0.24867460131645203
Epoch 16, Batch 1100/2971, Loss: 0.20405302941799164, Uncertainty: 0.4875734746456146
Epoch 16, Batch 1200/2971, Loss: 0.21066279709339142, Uncertainty: 0.5043714046478271
Epoch 16, Batch 1300/2971, Loss: 0.20351679623126984, Uncertainty: 0.4876277446746826
Epoch 16, Batch 1400/2971, Loss: 0.20146635174751282, Uncertainty: 0.4157654345035553
Epoch 16, Batch 1500/2971, Loss: 0.18488922715187073, Uncertainty: 0.3948867619037628
Epoch 16, Batch 1600/2971, Loss: 0.18340739607810974, Uncertainty: 0.35113459825515747
Epoch 16, Batch 1700/2971, Loss: 0.1668732762336731, Uncertainty: 0.22265151143074036
Epoch 16, Batch 1800/2971, Loss: 0.20037288963794708, Uncertainty: 0.5184755921363831
Epoch 16, Batch 1900/2971, Loss: 0.2126718908548355, Uncertainty: 0.5375779271125793
Epoch 16, Batch 2000/2971, Loss: 0.18501275777816772, Uncertainty: 0.4458966553211212
Epoch 16, Batch 2100/2971, Loss: 0.18537497520446777, Uncertainty: 0.23680615425109863
Epoch 16, Batch 2200/2971, Loss: 0.19524168968200684, Uncertainty: 0.42519450187683105
Epoch 16, Batch 2300/2971, Loss: 0.16932152211666107, Uncertainty: 0.28820255398750305
Epoch 16, Batch 2400/2971, Loss: 0.16847774386405945, Uncertainty: 0.2591027319431305
Epoch 16, Batch 2500/2971, Loss: 0.18866799771785736, Uncertainty: 0.3858184814453125
Epoch 16, Batch 2600/2971, Loss: 0.20869222283363342, Uncertainty: 0.5736698508262634
Epoch 16, Batch 2700/2971, Loss: 0.20384807884693146, Uncertainty: 0.5189921259880066
Epoch 16, Batch 2800/2971, Loss: 0.18721823394298553, Uncertainty: 0.4296901226043701
Epoch 16, Batch 2900/2971, Loss: 0.20125742256641388, Uncertainty: 0.4829072058200836

Training and Validation Results of Epoch 16:
================================
Training Loss: 0.15789857794142298, Training Uncertainty: 0.3929351668482636, time: 1717.7350590229034
Validation Loss: 0.1603480252972522, Validation Uncertainty: 0.4190169022108953, time: 340.48950266838074
Number of predictions within uncertainty interval: 495857/763521 (64.94%)

Epoch 17, Batch 100/2971, Loss: 0.1853725016117096, Uncertainty: 0.31339403986930847
Epoch 17, Batch 200/2971, Loss: 0.20269563794136047, Uncertainty: 0.5190482139587402
Epoch 17, Batch 300/2971, Loss: 0.2111603170633316, Uncertainty: 0.4438154697418213
Epoch 17, Batch 400/2971, Loss: 0.1748076230287552, Uncertainty: 0.323698490858078
Epoch 17, Batch 500/2971, Loss: 0.17332297563552856, Uncertainty: 0.31903573870658875
Epoch 17, Batch 600/2971, Loss: 0.17511405050754547, Uncertainty: 0.3394140303134918
Epoch 17, Batch 700/2971, Loss: 0.180634543299675, Uncertainty: 0.3359203338623047
Epoch 17, Batch 800/2971, Loss: 0.18114197254180908, Uncertainty: 0.3913600444793701
Epoch 17, Batch 900/2971, Loss: 0.1638721078634262, Uncertainty: 0.2608456015586853
Epoch 17, Batch 1000/2971, Loss: 0.19231931865215302, Uncertainty: 0.3916151225566864
Epoch 17, Batch 1100/2971, Loss: 0.1955479383468628, Uncertainty: 0.4501352310180664
Epoch 17, Batch 1200/2971, Loss: 0.2083648294210434, Uncertainty: 0.47089359164237976
Epoch 17, Batch 1300/2971, Loss: 0.20254570245742798, Uncertainty: 0.4825896620750427
Epoch 17, Batch 1400/2971, Loss: 0.19624674320220947, Uncertainty: 0.46688467264175415
Epoch 17, Batch 1500/2971, Loss: 0.2093474417924881, Uncertainty: 0.5228591561317444
Epoch 17, Batch 1600/2971, Loss: 0.20690065622329712, Uncertainty: 0.49205920100212097
Epoch 17, Batch 1700/2971, Loss: 0.18459969758987427, Uncertainty: 0.36323970556259155
Epoch 17, Batch 1800/2971, Loss: 0.18912622332572937, Uncertainty: 0.41205349564552307
Epoch 17, Batch 1900/2971, Loss: 0.18840092420578003, Uncertainty: 0.3033190071582794
Epoch 17, Batch 2000/2971, Loss: 0.17592352628707886, Uncertainty: 0.35617029666900635
Epoch 17, Batch 2100/2971, Loss: 0.19876541197299957, Uncertainty: 0.4494127929210663
Epoch 17, Batch 2200/2971, Loss: 0.1970447599887848, Uncertainty: 0.37925228476524353
Epoch 17, Batch 2300/2971, Loss: 0.18079373240470886, Uncertainty: 0.3790653944015503
Epoch 17, Batch 2400/2971, Loss: 0.17638620734214783, Uncertainty: 0.31202852725982666
Epoch 17, Batch 2500/2971, Loss: 0.18366973102092743, Uncertainty: 0.33656761050224304
Epoch 17, Batch 2600/2971, Loss: 0.18076682090759277, Uncertainty: 0.3530934154987335
Epoch 17, Batch 2700/2971, Loss: 0.19630004465579987, Uncertainty: 0.45480823516845703
Epoch 17, Batch 2800/2971, Loss: 0.17574158310890198, Uncertainty: 0.3443443775177002
Epoch 17, Batch 2900/2971, Loss: 0.16827648878097534, Uncertainty: 0.27736571431159973
Learning rate changed to: 1e-05

Training and Validation Results of Epoch 17:
================================
Training Loss: 0.15819499118285563, Training Uncertainty: 0.37109622151632576, time: 1722.8558542728424
Validation Loss: 0.15550878756299796, Validation Uncertainty: 0.22170793422539173, time: 340.83205556869507
Number of predictions within uncertainty interval: 336048/763521 (44.01%)

Epoch 18, Batch 100/2971, Loss: 0.15332160890102386, Uncertainty: 0.0441281795501709
Epoch 18, Batch 200/2971, Loss: 0.15114648640155792, Uncertainty: 0.03893968462944031
Epoch 18, Batch 300/2971, Loss: 0.1533915400505066, Uncertainty: 0.036674581468105316
Epoch 18, Batch 400/2971, Loss: 0.14858484268188477, Uncertainty: 0.03975502774119377
Epoch 18, Batch 500/2971, Loss: 0.15250279009342194, Uncertainty: 0.04331644997000694
Epoch 18, Batch 600/2971, Loss: 0.14938725531101227, Uncertainty: 0.04050833359360695
Epoch 18, Batch 700/2971, Loss: 0.1569565385580063, Uncertainty: 0.041860319674015045
Epoch 18, Batch 800/2971, Loss: 0.14755424857139587, Uncertainty: 0.04312238469719887
Epoch 18, Batch 900/2971, Loss: 0.14555057883262634, Uncertainty: 0.03966965526342392
Epoch 18, Batch 1000/2971, Loss: 0.15167966485023499, Uncertainty: 0.04194101318717003
Epoch 18, Batch 1100/2971, Loss: 0.15370185673236847, Uncertainty: 0.046051908284425735
Epoch 18, Batch 1200/2971, Loss: 0.154988631606102, Uncertainty: 0.041907306760549545
Epoch 18, Batch 1300/2971, Loss: 0.14473475515842438, Uncertainty: 0.042366284877061844
Epoch 18, Batch 1400/2971, Loss: 0.14981605112552643, Uncertainty: 0.046031832695007324
Epoch 18, Batch 1500/2971, Loss: 0.15119677782058716, Uncertainty: 0.043252699077129364
Epoch 18, Batch 1600/2971, Loss: 0.15616610646247864, Uncertainty: 0.050296928733587265
Epoch 18, Batch 1700/2971, Loss: 0.1543923318386078, Uncertainty: 0.045337170362472534
Epoch 18, Batch 1800/2971, Loss: 0.1471724957227707, Uncertainty: 0.0449194498360157
Epoch 18, Batch 1900/2971, Loss: 0.15436318516731262, Uncertainty: 0.04337603971362114
Epoch 18, Batch 2000/2971, Loss: 0.14395134150981903, Uncertainty: 0.05753207206726074
Epoch 18, Batch 2100/2971, Loss: 0.1529833972454071, Uncertainty: 0.057266466319561005
Epoch 18, Batch 2200/2971, Loss: 0.15057919919490814, Uncertainty: 0.05710756033658981
Epoch 18, Batch 2300/2971, Loss: 0.14538520574569702, Uncertainty: 0.051023080945014954
Epoch 18, Batch 2400/2971, Loss: 0.154191255569458, Uncertainty: 0.058334723114967346
Epoch 18, Batch 2500/2971, Loss: 0.15671561658382416, Uncertainty: 0.05584394186735153
Epoch 18, Batch 2600/2971, Loss: 0.1548277884721756, Uncertainty: 0.05941645801067352
Epoch 18, Batch 2700/2971, Loss: 0.15173526108264923, Uncertainty: 0.053072575479745865
Epoch 18, Batch 2800/2971, Loss: 0.14824195206165314, Uncertainty: 0.050512660294771194
Epoch 18, Batch 2900/2971, Loss: 0.15180470049381256, Uncertainty: 0.0580369308590889

Training and Validation Results of Epoch 18:
================================
Training Loss: 0.15203430455206862, Training Uncertainty: 0.04857177581125259, time: 1717.9150104522705
Validation Loss: 0.1516350021593343, Validation Uncertainty: 0.06021522844904685, time: 342.9202527999878
Number of predictions within uncertainty interval: 97832/763521 (12.81%)

Epoch 19, Batch 100/2971, Loss: 0.15645170211791992, Uncertainty: 0.061998553574085236
Epoch 19, Batch 200/2971, Loss: 0.15236841142177582, Uncertainty: 0.05335066840052605
Epoch 19, Batch 300/2971, Loss: 0.1519337296485901, Uncertainty: 0.047210775315761566
Epoch 19, Batch 400/2971, Loss: 0.1490766406059265, Uncertainty: 0.06450752168893814
Epoch 19, Batch 500/2971, Loss: 0.15206041932106018, Uncertainty: 0.04481510445475578
Epoch 19, Batch 600/2971, Loss: 0.14952336251735687, Uncertainty: 0.05052964389324188
Epoch 19, Batch 700/2971, Loss: 0.15650425851345062, Uncertainty: 0.05347825586795807
Epoch 19, Batch 800/2971, Loss: 0.14736169576644897, Uncertainty: 0.06393926590681076
Epoch 19, Batch 900/2971, Loss: 0.1460968554019928, Uncertainty: 0.051935795694589615
Epoch 19, Batch 1000/2971, Loss: 0.1520228385925293, Uncertainty: 0.06229286268353462
Epoch 19, Batch 1100/2971, Loss: 0.15337485074996948, Uncertainty: 0.05988657474517822
Epoch 19, Batch 1200/2971, Loss: 0.15525716543197632, Uncertainty: 0.056364186108112335
Epoch 19, Batch 1300/2971, Loss: 0.1463712453842163, Uncertainty: 0.05684329941868782
Epoch 19, Batch 1400/2971, Loss: 0.14972805976867676, Uncertainty: 0.06059001758694649
Epoch 19, Batch 1500/2971, Loss: 0.1506371647119522, Uncertainty: 0.05946626886725426
Epoch 19, Batch 1600/2971, Loss: 0.157577246427536, Uncertainty: 0.06667888909578323
Epoch 19, Batch 1700/2971, Loss: 0.1560806930065155, Uncertainty: 0.06061646714806557
Epoch 19, Batch 1800/2971, Loss: 0.1485094130039215, Uncertainty: 0.05683533102273941
Epoch 19, Batch 1900/2971, Loss: 0.15521271526813507, Uncertainty: 0.0716511607170105
Epoch 19, Batch 2000/2971, Loss: 0.1438189595937729, Uncertainty: 0.04644155874848366
Epoch 19, Batch 2100/2971, Loss: 0.15343979001045227, Uncertainty: 0.05936120077967644
Epoch 19, Batch 2200/2971, Loss: 0.1508764624595642, Uncertainty: 0.055106982588768005
Epoch 19, Batch 2300/2971, Loss: 0.14493758976459503, Uncertainty: 0.06195268779993057
Epoch 19, Batch 2400/2971, Loss: 0.15508946776390076, Uncertainty: 0.06767367571592331
Epoch 19, Batch 2500/2971, Loss: 0.15815478563308716, Uncertainty: 0.08008790016174316
Epoch 19, Batch 2600/2971, Loss: 0.15282756090164185, Uncertainty: 0.05026210844516754
Epoch 19, Batch 2700/2971, Loss: 0.1512666940689087, Uncertainty: 0.05455921217799187
Epoch 19, Batch 2800/2971, Loss: 0.14728108048439026, Uncertainty: 0.05519595742225647
Epoch 19, Batch 2900/2971, Loss: 0.15132646262645721, Uncertainty: 0.0749085545539856

Training and Validation Results of Epoch 19:
================================
Training Loss: 0.1522850591008489, Training Uncertainty: 0.060538629826643535, time: 1715.3230149745941
Validation Loss: 0.1527278970621155, Validation Uncertainty: 0.06729296829506334, time: 340.17734718322754
Number of predictions within uncertainty interval: 108077/763521 (14.16%)

Epoch 20, Batch 100/2971, Loss: 0.15544071793556213, Uncertainty: 0.06432878971099854
Epoch 20, Batch 200/2971, Loss: 0.1514071673154831, Uncertainty: 0.06839499622583389
Epoch 20, Batch 300/2971, Loss: 0.15176886320114136, Uncertainty: 0.05314338207244873
Epoch 20, Batch 400/2971, Loss: 0.15103895962238312, Uncertainty: 0.053920358419418335
Epoch 20, Batch 500/2971, Loss: 0.1521800011396408, Uncertainty: 0.059009891003370285
Epoch 20, Batch 600/2971, Loss: 0.14974290132522583, Uncertainty: 0.059979602694511414
Epoch 20, Batch 700/2971, Loss: 0.1568267047405243, Uncertainty: 0.06657513976097107
Epoch 20, Batch 800/2971, Loss: 0.14731962978839874, Uncertainty: 0.06242217868566513
Epoch 20, Batch 900/2971, Loss: 0.1458512544631958, Uncertainty: 0.053671810775995255
Epoch 20, Batch 1000/2971, Loss: 0.1510344296693802, Uncertainty: 0.055417172610759735
Epoch 20, Batch 1100/2971, Loss: 0.15301218628883362, Uncertainty: 0.05622267350554466
Epoch 20, Batch 1200/2971, Loss: 0.15525594353675842, Uncertainty: 0.05827608332037926
Epoch 20, Batch 1300/2971, Loss: 0.14714765548706055, Uncertainty: 0.053116586059331894
Epoch 20, Batch 1400/2971, Loss: 0.15072791278362274, Uncertainty: 0.07002491503953934
Epoch 20, Batch 1500/2971, Loss: 0.15058757364749908, Uncertainty: 0.06084579974412918
Epoch 20, Batch 1600/2971, Loss: 0.1575109213590622, Uncertainty: 0.06870126724243164
Epoch 20, Batch 1700/2971, Loss: 0.15621186792850494, Uncertainty: 0.06643403321504593
Epoch 20, Batch 1800/2971, Loss: 0.14913158118724823, Uncertainty: 0.06693711876869202
Epoch 20, Batch 1900/2971, Loss: 0.15503045916557312, Uncertainty: 0.06864123046398163
Epoch 20, Batch 2000/2971, Loss: 0.14364242553710938, Uncertainty: 0.0449962392449379
Epoch 20, Batch 2100/2971, Loss: 0.1533908247947693, Uncertainty: 0.061298489570617676
Epoch 20, Batch 2200/2971, Loss: 0.150803342461586, Uncertainty: 0.06063392385840416
Epoch 20, Batch 2300/2971, Loss: 0.14486224949359894, Uncertainty: 0.06564374268054962
Epoch 20, Batch 2400/2971, Loss: 0.15496963262557983, Uncertainty: 0.07102703303098679
Epoch 20, Batch 2500/2971, Loss: 0.15817895531654358, Uncertainty: 0.08679872751235962
Epoch 20, Batch 2600/2971, Loss: 0.15283842384815216, Uncertainty: 0.05248656123876572
Epoch 20, Batch 2700/2971, Loss: 0.15102677047252655, Uncertainty: 0.05287732183933258
Epoch 20, Batch 2800/2971, Loss: 0.14720283448696136, Uncertainty: 0.05623210221529007
Epoch 20, Batch 2900/2971, Loss: 0.1512339562177658, Uncertainty: 0.0740065947175026

Training and Validation Results of Epoch 20:
================================
Training Loss: 0.1522027414250719, Training Uncertainty: 0.06183732746501877, time: 1718.9748930931091
Validation Loss: 0.15224617777810925, Validation Uncertainty: 0.06816199155145827, time: 340.64769315719604
Number of predictions within uncertainty interval: 110406/763521 (14.46%)

Epoch 21, Batch 100/2971, Loss: 0.155329167842865, Uncertainty: 0.060463618487119675
Epoch 21, Batch 200/2971, Loss: 0.15127454698085785, Uncertainty: 0.06890928745269775
Epoch 21, Batch 300/2971, Loss: 0.15155747532844543, Uncertainty: 0.052291929721832275
Epoch 21, Batch 400/2971, Loss: 0.1509452611207962, Uncertainty: 0.052344050258398056
Epoch 21, Batch 500/2971, Loss: 0.15210901200771332, Uncertainty: 0.05691493675112724
Epoch 21, Batch 600/2971, Loss: 0.14937160909175873, Uncertainty: 0.05700958892703056
Epoch 21, Batch 700/2971, Loss: 0.1566958725452423, Uncertainty: 0.06382853537797928
Epoch 21, Batch 800/2971, Loss: 0.14720739424228668, Uncertainty: 0.061190165579319
Epoch 21, Batch 900/2971, Loss: 0.14600089192390442, Uncertainty: 0.05406287685036659
Epoch 21, Batch 1000/2971, Loss: 0.15086552500724792, Uncertainty: 0.05207211524248123
Epoch 21, Batch 1100/2971, Loss: 0.15282659232616425, Uncertainty: 0.05759182944893837
Epoch 21, Batch 1200/2971, Loss: 0.1550583392381668, Uncertainty: 0.05622072517871857
Epoch 21, Batch 1300/2971, Loss: 0.14722035825252533, Uncertainty: 0.057501018047332764
Epoch 21, Batch 1400/2971, Loss: 0.15055878460407257, Uncertainty: 0.07073745876550674
Epoch 21, Batch 1500/2971, Loss: 0.15037567913532257, Uncertainty: 0.05695970728993416
Epoch 21, Batch 1600/2971, Loss: 0.15727804601192474, Uncertainty: 0.07101152092218399
Epoch 21, Batch 1700/2971, Loss: 0.1560491919517517, Uncertainty: 0.061252884566783905
Epoch 21, Batch 1800/2971, Loss: 0.1486116349697113, Uncertainty: 0.06456029415130615
Epoch 21, Batch 1900/2971, Loss: 0.15508288145065308, Uncertainty: 0.07106595486402512
Epoch 21, Batch 2000/2971, Loss: 0.14352627098560333, Uncertainty: 0.04688539728522301
Epoch 21, Batch 2100/2971, Loss: 0.1529475301504135, Uncertainty: 0.06475748866796494
Epoch 21, Batch 2200/2971, Loss: 0.1505628079175949, Uncertainty: 0.056416478008031845
Epoch 21, Batch 2300/2971, Loss: 0.14509665966033936, Uncertainty: 0.07083915174007416
Epoch 21, Batch 2400/2971, Loss: 0.1545143574476242, Uncertainty: 0.06665284931659698
Epoch 21, Batch 2500/2971, Loss: 0.15803544223308563, Uncertainty: 0.0858168974518776
Epoch 21, Batch 2600/2971, Loss: 0.1525697261095047, Uncertainty: 0.04772823676466942
Epoch 21, Batch 2700/2971, Loss: 0.15086661279201508, Uncertainty: 0.05514168739318848
Epoch 21, Batch 2800/2971, Loss: 0.1471225619316101, Uncertainty: 0.05329808220267296
Epoch 21, Batch 2900/2971, Loss: 0.15112823247909546, Uncertainty: 0.07634135335683823

Training and Validation Results of Epoch 21:
================================
Training Loss: 0.1520836601571096, Training Uncertainty: 0.06163810661864457, time: 1718.4966492652893
Validation Loss: 0.15278011389969176, Validation Uncertainty: 0.07072213199867053, time: 341.9975244998932
Number of predictions within uncertainty interval: 114494/763521 (15.00%)

Epoch 22, Batch 100/2971, Loss: 0.15534567832946777, Uncertainty: 0.056262414902448654
Epoch 22, Batch 200/2971, Loss: 0.15121865272521973, Uncertainty: 0.07027620822191238
Epoch 22, Batch 300/2971, Loss: 0.15137428045272827, Uncertainty: 0.049839768558740616
Epoch 22, Batch 400/2971, Loss: 0.15117837488651276, Uncertainty: 0.06183662638068199
Epoch 22, Batch 500/2971, Loss: 0.15201786160469055, Uncertainty: 0.05861852318048477
Epoch 22, Batch 600/2971, Loss: 0.1493849754333496, Uncertainty: 0.055300358682870865
Epoch 22, Batch 700/2971, Loss: 0.1564827561378479, Uncertainty: 0.06253890693187714
Epoch 22, Batch 800/2971, Loss: 0.14710883796215057, Uncertainty: 0.06359999626874924
Epoch 22, Batch 900/2971, Loss: 0.14578643441200256, Uncertainty: 0.055867500603199005
Epoch 22, Batch 1000/2971, Loss: 0.15106353163719177, Uncertainty: 0.06139108166098595
Epoch 22, Batch 1100/2971, Loss: 0.1527525782585144, Uncertainty: 0.05815385654568672
Epoch 22, Batch 1200/2971, Loss: 0.15490853786468506, Uncertainty: 0.05532052367925644
Epoch 22, Batch 1300/2971, Loss: 0.14647197723388672, Uncertainty: 0.056091953068971634
Epoch 22, Batch 1400/2971, Loss: 0.15103165805339813, Uncertainty: 0.06781934946775436
Epoch 22, Batch 1500/2971, Loss: 0.15019775927066803, Uncertainty: 0.05749202519655228
Epoch 22, Batch 1600/2971, Loss: 0.1566612720489502, Uncertainty: 0.058272164314985275
Epoch 22, Batch 1700/2971, Loss: 0.15604794025421143, Uncertainty: 0.06272280961275101
Epoch 22, Batch 1800/2971, Loss: 0.14865197241306305, Uncertainty: 0.06688650697469711
Epoch 22, Batch 1900/2971, Loss: 0.1551956683397293, Uncertainty: 0.07015275955200195
Epoch 22, Batch 2000/2971, Loss: 0.14340126514434814, Uncertainty: 0.04824608191847801
Epoch 22, Batch 2100/2971, Loss: 0.15308113396167755, Uncertainty: 0.06446705758571625
Epoch 22, Batch 2200/2971, Loss: 0.1504330188035965, Uncertainty: 0.05733291059732437
Epoch 22, Batch 2300/2971, Loss: 0.1446443647146225, Uncertainty: 0.060511548072099686
Epoch 22, Batch 2400/2971, Loss: 0.15471504628658295, Uncertainty: 0.06941170245409012
Epoch 22, Batch 2500/2971, Loss: 0.158013716340065, Uncertainty: 0.08563017100095749
Epoch 22, Batch 2600/2971, Loss: 0.15259124338626862, Uncertainty: 0.05052933096885681
Epoch 22, Batch 2700/2971, Loss: 0.150626540184021, Uncertainty: 0.05232807248830795
Epoch 22, Batch 2800/2971, Loss: 0.1471378356218338, Uncertainty: 0.055019013583660126
Epoch 22, Batch 2900/2971, Loss: 0.1510758101940155, Uncertainty: 0.07640212774276733

Training and Validation Results of Epoch 22:
================================
Training Loss: 0.15198638219197003, Training Uncertainty: 0.060972776444511594, time: 1721.3591830730438
Validation Loss: 0.1523511488978346, Validation Uncertainty: 0.07224839909721673, time: 341.17086124420166
Number of predictions within uncertainty interval: 117633/763521 (15.41%)

Epoch 23, Batch 100/2971, Loss: 0.15527299046516418, Uncertainty: 0.06263517588376999
Epoch 23, Batch 200/2971, Loss: 0.15099328756332397, Uncertainty: 0.06817483901977539
Epoch 23, Batch 300/2971, Loss: 0.1511925756931305, Uncertainty: 0.04745207354426384
Epoch 23, Batch 400/2971, Loss: 0.1511620134115219, Uncertainty: 0.05471092835068703
Epoch 23, Batch 500/2971, Loss: 0.15168561041355133, Uncertainty: 0.05727096274495125
Epoch 23, Batch 600/2971, Loss: 0.14935988187789917, Uncertainty: 0.056466974318027496
Epoch 23, Batch 700/2971, Loss: 0.1563030630350113, Uncertainty: 0.06255798041820526
Epoch 23, Batch 800/2971, Loss: 0.1468048244714737, Uncertainty: 0.061075225472450256
Epoch 23, Batch 900/2971, Loss: 0.14565779268741608, Uncertainty: 0.05376651510596275
Epoch 23, Batch 1000/2971, Loss: 0.15094101428985596, Uncertainty: 0.058556269854307175
Epoch 23, Batch 1100/2971, Loss: 0.15273773670196533, Uncertainty: 0.05851827189326286
Epoch 23, Batch 1200/2971, Loss: 0.1548095941543579, Uncertainty: 0.05550713837146759
Epoch 23, Batch 1300/2971, Loss: 0.1463402360677719, Uncertainty: 0.05502014234662056
Epoch 23, Batch 1400/2971, Loss: 0.15056873857975006, Uncertainty: 0.06328889727592468
Epoch 23, Batch 1500/2971, Loss: 0.15003027021884918, Uncertainty: 0.05986675247550011
Epoch 23, Batch 1600/2971, Loss: 0.15703082084655762, Uncertainty: 0.07048047333955765
Epoch 23, Batch 1700/2971, Loss: 0.15581420063972473, Uncertainty: 0.06570033729076385
Epoch 23, Batch 1800/2971, Loss: 0.1485033631324768, Uncertainty: 0.06715479493141174
Epoch 23, Batch 1900/2971, Loss: 0.1550411432981491, Uncertainty: 0.07216240465641022
Epoch 23, Batch 2000/2971, Loss: 0.14335215091705322, Uncertainty: 0.04607642814517021
Epoch 23, Batch 2100/2971, Loss: 0.15315213799476624, Uncertainty: 0.06526022404432297
Epoch 23, Batch 2200/2971, Loss: 0.15044443309307098, Uncertainty: 0.056830260902643204
Epoch 23, Batch 2300/2971, Loss: 0.14437799155712128, Uncertainty: 0.05851222947239876
Epoch 23, Batch 2400/2971, Loss: 0.15436425805091858, Uncertainty: 0.07012363523244858
Epoch 23, Batch 2500/2971, Loss: 0.1575896292924881, Uncertainty: 0.07342126220464706
Epoch 23, Batch 2600/2971, Loss: 0.1525363326072693, Uncertainty: 0.04920916259288788
Epoch 23, Batch 2700/2971, Loss: 0.15054498612880707, Uncertainty: 0.055825598537921906
Epoch 23, Batch 2800/2971, Loss: 0.1469072699546814, Uncertainty: 0.054616689682006836
Epoch 23, Batch 2900/2971, Loss: 0.1511828452348709, Uncertainty: 0.08075250685214996

Training and Validation Results of Epoch 23:
================================
Training Loss: 0.15189023336470228, Training Uncertainty: 0.06092149054350094, time: 1716.1581146717072
Validation Loss: 0.15220945784734363, Validation Uncertainty: 0.06716687644394378, time: 341.0107681751251
Number of predictions within uncertainty interval: 111883/763521 (14.65%)

Epoch 24, Batch 100/2971, Loss: 0.15513531863689423, Uncertainty: 0.0601244792342186
Epoch 24, Batch 200/2971, Loss: 0.15097515285015106, Uncertainty: 0.06965319812297821
Epoch 24, Batch 300/2971, Loss: 0.1509837955236435, Uncertainty: 0.045164864510297775
Epoch 24, Batch 400/2971, Loss: 0.1505279242992401, Uncertainty: 0.05344569683074951
Epoch 24, Batch 500/2971, Loss: 0.15205395221710205, Uncertainty: 0.058069393038749695
Epoch 24, Batch 600/2971, Loss: 0.14909622073173523, Uncertainty: 0.052598048001527786
Epoch 24, Batch 700/2971, Loss: 0.156380295753479, Uncertainty: 0.06079899147152901
Epoch 24, Batch 800/2971, Loss: 0.14683857560157776, Uncertainty: 0.06110583245754242
Epoch 24, Batch 900/2971, Loss: 0.14592626690864563, Uncertainty: 0.054743099957704544
Epoch 24, Batch 1000/2971, Loss: 0.15086732804775238, Uncertainty: 0.05916782468557358
Epoch 24, Batch 1100/2971, Loss: 0.15280036628246307, Uncertainty: 0.06232529506087303
Epoch 24, Batch 1200/2971, Loss: 0.15488949418067932, Uncertainty: 0.05706426873803139
Epoch 24, Batch 1300/2971, Loss: 0.14634546637535095, Uncertainty: 0.05682184919714928
Epoch 24, Batch 1400/2971, Loss: 0.15107183158397675, Uncertainty: 0.06848344951868057
Epoch 24, Batch 1500/2971, Loss: 0.15017825365066528, Uncertainty: 0.061311930418014526
Epoch 24, Batch 1600/2971, Loss: 0.15679511427879333, Uncertainty: 0.0648040771484375
Epoch 24, Batch 1700/2971, Loss: 0.1559213548898697, Uncertainty: 0.06232556328177452
Epoch 24, Batch 1800/2971, Loss: 0.14833655953407288, Uncertainty: 0.06564530730247498
Epoch 24, Batch 1900/2971, Loss: 0.15497440099716187, Uncertainty: 0.07144100964069366
Epoch 24, Batch 2000/2971, Loss: 0.1432638019323349, Uncertainty: 0.047313399612903595
Epoch 24, Batch 2100/2971, Loss: 0.1530844271183014, Uncertainty: 0.06738720834255219
Epoch 24, Batch 2200/2971, Loss: 0.15023334324359894, Uncertainty: 0.05432650074362755
Epoch 24, Batch 2300/2971, Loss: 0.14461173117160797, Uncertainty: 0.06544388085603714
Epoch 24, Batch 2400/2971, Loss: 0.15411093831062317, Uncertainty: 0.06209750100970268
Epoch 24, Batch 2500/2971, Loss: 0.15769623219966888, Uncertainty: 0.07494430243968964
Epoch 24, Batch 2600/2971, Loss: 0.1524147093296051, Uncertainty: 0.05018940195441246
Epoch 24, Batch 2700/2971, Loss: 0.15044167637825012, Uncertainty: 0.05287659540772438
Epoch 24, Batch 2800/2971, Loss: 0.14729678630828857, Uncertainty: 0.06002069637179375
Epoch 24, Batch 2900/2971, Loss: 0.1512262523174286, Uncertainty: 0.08186111599206924
Learning rate changed to: 1.0000000000000002e-06

Training and Validation Results of Epoch 24:
================================
Training Loss: 0.1518029726362116, Training Uncertainty: 0.06075299036062474, time: 1718.006897687912
Validation Loss: 0.15257447657161574, Validation Uncertainty: 0.06779477141627072, time: 343.1324083805084
Number of predictions within uncertainty interval: 111065/763521 (14.55%)

Epoch 25, Batch 100/2971, Loss: 0.15314292907714844, Uncertainty: 0.03199557214975357
Epoch 25, Batch 200/2971, Loss: 0.15026476979255676, Uncertainty: 0.030929984524846077
Epoch 25, Batch 300/2971, Loss: 0.15134525299072266, Uncertainty: 0.029057536274194717
Epoch 25, Batch 400/2971, Loss: 0.14833255112171173, Uncertainty: 0.030172504484653473
Epoch 25, Batch 500/2971, Loss: 0.1509617418050766, Uncertainty: 0.029049940407276154
Epoch 25, Batch 600/2971, Loss: 0.14788778126239777, Uncertainty: 0.030527137219905853
Epoch 25, Batch 700/2971, Loss: 0.15554513037204742, Uncertainty: 0.02985760197043419
Epoch 25, Batch 800/2971, Loss: 0.14495564997196198, Uncertainty: 0.028983043506741524
Epoch 25, Batch 900/2971, Loss: 0.14429882168769836, Uncertainty: 0.03108799457550049
Epoch 25, Batch 1000/2971, Loss: 0.1504237949848175, Uncertainty: 0.030581645667552948
Epoch 25, Batch 1100/2971, Loss: 0.15225382149219513, Uncertainty: 0.031953271478414536
Epoch 25, Batch 1200/2971, Loss: 0.15357372164726257, Uncertainty: 0.03108985349535942
Epoch 25, Batch 1300/2971, Loss: 0.14339932799339294, Uncertainty: 0.030916716903448105
Epoch 25, Batch 1400/2971, Loss: 0.14727285504341125, Uncertainty: 0.02903330884873867
Epoch 25, Batch 1500/2971, Loss: 0.14916880428791046, Uncertainty: 0.03191516175866127
Epoch 25, Batch 1600/2971, Loss: 0.15542201697826385, Uncertainty: 0.031108904629945755
Epoch 25, Batch 1700/2971, Loss: 0.15383313596248627, Uncertainty: 0.030154895037412643
Epoch 25, Batch 1800/2971, Loss: 0.1459452211856842, Uncertainty: 0.02968723699450493
Epoch 25, Batch 1900/2971, Loss: 0.15324726700782776, Uncertainty: 0.03012148104608059
Epoch 25, Batch 2000/2971, Loss: 0.14326545596122742, Uncertainty: 0.029934369027614594
Epoch 25, Batch 2100/2971, Loss: 0.15135176479816437, Uncertainty: 0.03102766163647175
Epoch 25, Batch 2200/2971, Loss: 0.149240642786026, Uncertainty: 0.03274945914745331
Epoch 25, Batch 2300/2971, Loss: 0.14294256269931793, Uncertainty: 0.030843501910567284
Epoch 25, Batch 2400/2971, Loss: 0.15232707560062408, Uncertainty: 0.033685289323329926
Epoch 25, Batch 2500/2971, Loss: 0.15517303347587585, Uncertainty: 0.034038081765174866
Epoch 25, Batch 2600/2971, Loss: 0.15192626416683197, Uncertainty: 0.03253581374883652
Epoch 25, Batch 2700/2971, Loss: 0.14954885840415955, Uncertainty: 0.033468734472990036
Epoch 25, Batch 2800/2971, Loss: 0.14501214027404785, Uncertainty: 0.03266361355781555
Epoch 25, Batch 2900/2971, Loss: 0.14991144835948944, Uncertainty: 0.032486461102962494

Training and Validation Results of Epoch 25:
================================
Training Loss: 0.15080599867005576, Training Uncertainty: 0.03168446098422009, time: 1717.497617483139
Validation Loss: 0.15082133847162188, Validation Uncertainty: 0.03243453603132577, time: 341.48854517936707
Number of predictions within uncertainty interval: 50449/763521 (6.61%)

Epoch 26, Batch 100/2971, Loss: 0.15254144370555878, Uncertainty: 0.03400404378771782
Epoch 26, Batch 200/2971, Loss: 0.15003618597984314, Uncertainty: 0.03099161572754383
Epoch 26, Batch 300/2971, Loss: 0.1511814445257187, Uncertainty: 0.029689118266105652
Epoch 26, Batch 400/2971, Loss: 0.1480356603860855, Uncertainty: 0.03244398906826973
Epoch 26, Batch 500/2971, Loss: 0.15087302029132843, Uncertainty: 0.03150995448231697
Epoch 26, Batch 600/2971, Loss: 0.14773623645305634, Uncertainty: 0.030305279418826103
Epoch 26, Batch 700/2971, Loss: 0.15551944077014923, Uncertainty: 0.030679401010274887
Epoch 26, Batch 800/2971, Loss: 0.14496469497680664, Uncertainty: 0.03129677474498749
Epoch 26, Batch 900/2971, Loss: 0.14436623454093933, Uncertainty: 0.03271406516432762
Epoch 26, Batch 1000/2971, Loss: 0.15047696232795715, Uncertainty: 0.03182815760374069
Epoch 26, Batch 1100/2971, Loss: 0.15216481685638428, Uncertainty: 0.032450225204229355
Epoch 26, Batch 1200/2971, Loss: 0.15357263386249542, Uncertainty: 0.030339986085891724
Epoch 26, Batch 1300/2971, Loss: 0.14368870854377747, Uncertainty: 0.032630689442157745
Epoch 26, Batch 1400/2971, Loss: 0.14714282751083374, Uncertainty: 0.02997570112347603
Epoch 26, Batch 1500/2971, Loss: 0.14952442049980164, Uncertainty: 0.03441981226205826
Epoch 26, Batch 1600/2971, Loss: 0.1554592102766037, Uncertainty: 0.032469574362039566
Epoch 26, Batch 1700/2971, Loss: 0.1540374606847763, Uncertainty: 0.031008824706077576
Epoch 26, Batch 1800/2971, Loss: 0.14642377197742462, Uncertainty: 0.029732439666986465
Epoch 26, Batch 1900/2971, Loss: 0.1532081663608551, Uncertainty: 0.03200493007898331
Epoch 26, Batch 2000/2971, Loss: 0.14292201399803162, Uncertainty: 0.03135109692811966
Epoch 26, Batch 2100/2971, Loss: 0.15134625136852264, Uncertainty: 0.031731732189655304
Epoch 26, Batch 2200/2971, Loss: 0.1492454707622528, Uncertainty: 0.03448714315891266
Epoch 26, Batch 2300/2971, Loss: 0.14294934272766113, Uncertainty: 0.032322175800800323
Epoch 26, Batch 2400/2971, Loss: 0.15223336219787598, Uncertainty: 0.03496801108121872
Epoch 26, Batch 2500/2971, Loss: 0.15518170595169067, Uncertainty: 0.03331657871603966
Epoch 26, Batch 2600/2971, Loss: 0.15182538330554962, Uncertainty: 0.03400531783699989
Epoch 26, Batch 2700/2971, Loss: 0.14955542981624603, Uncertainty: 0.03415822982788086
Epoch 26, Batch 2800/2971, Loss: 0.14508888125419617, Uncertainty: 0.03224875405430794
Epoch 26, Batch 2900/2971, Loss: 0.1499149203300476, Uncertainty: 0.032925378531217575

Training and Validation Results of Epoch 26:
================================
Training Loss: 0.1508217067208526, Training Uncertainty: 0.03266558147971877, time: 1703.4569158554077
Validation Loss: 0.15082246424131407, Validation Uncertainty: 0.03233799431096978, time: 335.6745672225952
Number of predictions within uncertainty interval: 50421/763521 (6.60%)

Epoch 27, Batch 100/2971, Loss: 0.15251070261001587, Uncertainty: 0.03369499742984772
Epoch 27, Batch 200/2971, Loss: 0.15001390874385834, Uncertainty: 0.03202145919203758
Epoch 27, Batch 300/2971, Loss: 0.15114253759384155, Uncertainty: 0.02985825203359127
Epoch 27, Batch 400/2971, Loss: 0.1481068879365921, Uncertainty: 0.0321258008480072
Epoch 27, Batch 500/2971, Loss: 0.15083779394626617, Uncertainty: 0.03290093317627907
Epoch 27, Batch 600/2971, Loss: 0.1476965993642807, Uncertainty: 0.030288852751255035
Epoch 27, Batch 700/2971, Loss: 0.15549978613853455, Uncertainty: 0.030404027551412582
Epoch 27, Batch 800/2971, Loss: 0.14493241906166077, Uncertainty: 0.03157384321093559
Epoch 27, Batch 900/2971, Loss: 0.14432044327259064, Uncertainty: 0.03300389274954796
Epoch 27, Batch 1000/2971, Loss: 0.1504533886909485, Uncertainty: 0.03192540258169174
Epoch 27, Batch 1100/2971, Loss: 0.1521786004304886, Uncertainty: 0.03287791833281517
Epoch 27, Batch 1200/2971, Loss: 0.15357403457164764, Uncertainty: 0.030608413740992546
Epoch 27, Batch 1300/2971, Loss: 0.14367736876010895, Uncertainty: 0.03237185254693031
Epoch 27, Batch 1400/2971, Loss: 0.14713197946548462, Uncertainty: 0.03009461797773838
Epoch 27, Batch 1500/2971, Loss: 0.14954032003879547, Uncertainty: 0.0352255180478096
Epoch 27, Batch 1600/2971, Loss: 0.15542179346084595, Uncertainty: 0.03214079141616821
Epoch 27, Batch 1700/2971, Loss: 0.15405671298503876, Uncertainty: 0.030725201591849327
Epoch 27, Batch 1800/2971, Loss: 0.1464177817106247, Uncertainty: 0.029932675883173943
Epoch 27, Batch 1900/2971, Loss: 0.15318594872951508, Uncertainty: 0.031921111047267914
Epoch 27, Batch 2000/2971, Loss: 0.14290140569210052, Uncertainty: 0.031203310936689377
Epoch 27, Batch 2100/2971, Loss: 0.15132611989974976, Uncertainty: 0.03206108137965202
Epoch 27, Batch 2200/2971, Loss: 0.14923232793807983, Uncertainty: 0.034573256969451904
Epoch 27, Batch 2300/2971, Loss: 0.14292781054973602, Uncertainty: 0.03275718912482262
Epoch 27, Batch 2400/2971, Loss: 0.15221789479255676, Uncertainty: 0.034991879016160965
Epoch 27, Batch 2500/2971, Loss: 0.15519922971725464, Uncertainty: 0.03373095765709877
Epoch 27, Batch 2600/2971, Loss: 0.15182636678218842, Uncertainty: 0.03441283479332924
Epoch 27, Batch 2700/2971, Loss: 0.14954040944576263, Uncertainty: 0.03434301167726517
Epoch 27, Batch 2800/2971, Loss: 0.14508916437625885, Uncertainty: 0.032655805349349976
Epoch 27, Batch 2900/2971, Loss: 0.14989310503005981, Uncertainty: 0.03277329355478287

Training and Validation Results of Epoch 27:
================================
Training Loss: 0.15080881110749556, Training Uncertainty: 0.03271699443620008, time: 1698.420264005661
Validation Loss: 0.15080725623252095, Validation Uncertainty: 0.03235156476136653, time: 336.2371451854706
Number of predictions within uncertainty interval: 50818/763521 (6.66%)

Epoch 28, Batch 100/2971, Loss: 0.1525174379348755, Uncertainty: 0.03392626717686653
Epoch 28, Batch 200/2971, Loss: 0.14999812841415405, Uncertainty: 0.032050326466560364
Epoch 28, Batch 300/2971, Loss: 0.15113650262355804, Uncertainty: 0.03030107542872429
Epoch 28, Batch 400/2971, Loss: 0.14808639883995056, Uncertainty: 0.03213195130228996
Epoch 28, Batch 500/2971, Loss: 0.15079918503761292, Uncertainty: 0.03256788104772568
Epoch 28, Batch 600/2971, Loss: 0.14769765734672546, Uncertainty: 0.030626289546489716
Epoch 28, Batch 700/2971, Loss: 0.1554890275001526, Uncertainty: 0.030491704121232033
Epoch 28, Batch 800/2971, Loss: 0.14492402970790863, Uncertainty: 0.031417366117239
Epoch 28, Batch 900/2971, Loss: 0.1443132907152176, Uncertainty: 0.03305627033114433
Epoch 28, Batch 1000/2971, Loss: 0.1504521369934082, Uncertainty: 0.03173132240772247
Epoch 28, Batch 1100/2971, Loss: 0.15216343104839325, Uncertainty: 0.032989226281642914
Epoch 28, Batch 1200/2971, Loss: 0.15355798602104187, Uncertainty: 0.030351687222719193
Epoch 28, Batch 1300/2971, Loss: 0.14367781579494476, Uncertainty: 0.033127572387456894
Epoch 28, Batch 1400/2971, Loss: 0.14714168012142181, Uncertainty: 0.030581150203943253
Epoch 28, Batch 1500/2971, Loss: 0.14955763518810272, Uncertainty: 0.03495847433805466
Epoch 28, Batch 1600/2971, Loss: 0.15539933741092682, Uncertainty: 0.03229428827762604
Epoch 28, Batch 1700/2971, Loss: 0.1540408432483673, Uncertainty: 0.030835922807455063
Epoch 28, Batch 1800/2971, Loss: 0.14638668298721313, Uncertainty: 0.029996665194630623
Epoch 28, Batch 1900/2971, Loss: 0.15316128730773926, Uncertainty: 0.03152947500348091
Epoch 28, Batch 2000/2971, Loss: 0.14287546277046204, Uncertainty: 0.031000308692455292
Epoch 28, Batch 2100/2971, Loss: 0.15130677819252014, Uncertainty: 0.0319787971675396
Epoch 28, Batch 2200/2971, Loss: 0.14919601380825043, Uncertainty: 0.034437134861946106
Epoch 28, Batch 2300/2971, Loss: 0.1429291069507599, Uncertainty: 0.033084768801927567
Epoch 28, Batch 2400/2971, Loss: 0.152192622423172, Uncertainty: 0.034462545067071915
Epoch 28, Batch 2500/2971, Loss: 0.1551743894815445, Uncertainty: 0.03398911654949188
Epoch 28, Batch 2600/2971, Loss: 0.15180328488349915, Uncertainty: 0.034113213419914246
Epoch 28, Batch 2700/2971, Loss: 0.1495119035243988, Uncertainty: 0.034214362502098083
Epoch 28, Batch 2800/2971, Loss: 0.14505304396152496, Uncertainty: 0.03214346989989281
Epoch 28, Batch 2900/2971, Loss: 0.14987508952617645, Uncertainty: 0.03231032192707062

Training and Validation Results of Epoch 28:
================================
Training Loss: 0.15079356257520674, Training Uncertainty: 0.03270004903606115, time: 1697.6767625808716
Validation Loss: 0.15077794546795406, Validation Uncertainty: 0.03240647882443739, time: 336.89039063453674
Number of predictions within uncertainty interval: 50859/763521 (6.66%)

Epoch 29, Batch 100/2971, Loss: 0.15251736342906952, Uncertainty: 0.03397960215806961
Epoch 29, Batch 200/2971, Loss: 0.14998100697994232, Uncertainty: 0.03151199221611023
Epoch 29, Batch 300/2971, Loss: 0.15113553404808044, Uncertainty: 0.030099449679255486
Epoch 29, Batch 400/2971, Loss: 0.14806923270225525, Uncertainty: 0.032358329743146896
Epoch 29, Batch 500/2971, Loss: 0.150797501206398, Uncertainty: 0.031646229326725006
Epoch 29, Batch 600/2971, Loss: 0.1476614624261856, Uncertainty: 0.030693644657731056
Epoch 29, Batch 700/2971, Loss: 0.1554579883813858, Uncertainty: 0.03018821030855179
Epoch 29, Batch 800/2971, Loss: 0.14490564167499542, Uncertainty: 0.03151274099946022
Epoch 29, Batch 900/2971, Loss: 0.14428748190402985, Uncertainty: 0.03252286836504936
Epoch 29, Batch 1000/2971, Loss: 0.15044769644737244, Uncertainty: 0.031884077936410904
Epoch 29, Batch 1100/2971, Loss: 0.15215377509593964, Uncertainty: 0.03277698531746864
Epoch 29, Batch 1200/2971, Loss: 0.15355291962623596, Uncertainty: 0.03077632002532482
Epoch 29, Batch 1300/2971, Loss: 0.14366203546524048, Uncertainty: 0.03279322013258934
Epoch 29, Batch 1400/2971, Loss: 0.1471373587846756, Uncertainty: 0.0305503960698843
Epoch 29, Batch 1500/2971, Loss: 0.14954935014247894, Uncertainty: 0.0355142317712307
Epoch 29, Batch 1600/2971, Loss: 0.15541188418865204, Uncertainty: 0.0327533558011055
Epoch 29, Batch 1700/2971, Loss: 0.15400731563568115, Uncertainty: 0.03074430301785469
Epoch 29, Batch 1800/2971, Loss: 0.14638538658618927, Uncertainty: 0.029925275593996048
Epoch 29, Batch 1900/2971, Loss: 0.15314993262290955, Uncertainty: 0.03191357105970383
Epoch 29, Batch 2000/2971, Loss: 0.14286915957927704, Uncertainty: 0.031102659180760384
Epoch 29, Batch 2100/2971, Loss: 0.15129129588603973, Uncertainty: 0.031606096774339676
Epoch 29, Batch 2200/2971, Loss: 0.14920717477798462, Uncertainty: 0.03430487588047981
Epoch 29, Batch 2300/2971, Loss: 0.14289847016334534, Uncertainty: 0.033022742718458176
Epoch 29, Batch 2400/2971, Loss: 0.1521613597869873, Uncertainty: 0.03406995162367821
Epoch 29, Batch 2500/2971, Loss: 0.1551508754491806, Uncertainty: 0.0333101749420166
Epoch 29, Batch 2600/2971, Loss: 0.1518108993768692, Uncertainty: 0.03436161205172539
Epoch 29, Batch 2700/2971, Loss: 0.1495010405778885, Uncertainty: 0.03399462625384331
Epoch 29, Batch 2800/2971, Loss: 0.14506112039089203, Uncertainty: 0.03248552232980728
Epoch 29, Batch 2900/2971, Loss: 0.14986515045166016, Uncertainty: 0.032572127878665924

Training and Validation Results of Epoch 29:
================================
Training Loss: 0.1507791586744388, Training Uncertainty: 0.03266745278732779, time: 1689.339299440384
Validation Loss: 0.1507667262372868, Validation Uncertainty: 0.03229727933727315, time: 336.24806332588196
Number of predictions within uncertainty interval: 50741/763521 (6.65%)

Epoch 30, Batch 100/2971, Loss: 0.1525004357099533, Uncertainty: 0.03371633216738701
Epoch 30, Batch 200/2971, Loss: 0.14997170865535736, Uncertainty: 0.03185804933309555
Epoch 30, Batch 300/2971, Loss: 0.1510903388261795, Uncertainty: 0.029123511165380478
Epoch 30, Batch 400/2971, Loss: 0.1480814516544342, Uncertainty: 0.03215698525309563
Epoch 30, Batch 500/2971, Loss: 0.15078669786453247, Uncertainty: 0.0323946550488472
Epoch 30, Batch 600/2971, Loss: 0.1476696878671646, Uncertainty: 0.03135055676102638
Epoch 30, Batch 700/2971, Loss: 0.155445396900177, Uncertainty: 0.030189158394932747
Epoch 30, Batch 800/2971, Loss: 0.14488817751407623, Uncertainty: 0.031314052641391754
Epoch 30, Batch 900/2971, Loss: 0.14429184794425964, Uncertainty: 0.03293859586119652
Epoch 30, Batch 1000/2971, Loss: 0.150436133146286, Uncertainty: 0.031716238707304
Epoch 30, Batch 1100/2971, Loss: 0.15214921534061432, Uncertainty: 0.032813943922519684
Epoch 30, Batch 1200/2971, Loss: 0.15352344512939453, Uncertainty: 0.03068263828754425
Epoch 30, Batch 1300/2971, Loss: 0.14365200698375702, Uncertainty: 0.03252936154603958
Epoch 30, Batch 1400/2971, Loss: 0.14712446928024292, Uncertainty: 0.03027346543967724
Epoch 30, Batch 1500/2971, Loss: 0.1495359241962433, Uncertainty: 0.03548654168844223
Epoch 30, Batch 1600/2971, Loss: 0.1553785502910614, Uncertainty: 0.03274628892540932
Epoch 30, Batch 1700/2971, Loss: 0.15401796996593475, Uncertainty: 0.030767522752285004
Epoch 30, Batch 1800/2971, Loss: 0.14637592434883118, Uncertainty: 0.029978834092617035
Epoch 30, Batch 1900/2971, Loss: 0.15313400328159332, Uncertainty: 0.03163947910070419
Epoch 30, Batch 2000/2971, Loss: 0.1428297609090805, Uncertainty: 0.031078144907951355
Epoch 30, Batch 2100/2971, Loss: 0.15127767622470856, Uncertainty: 0.03150133416056633
Epoch 30, Batch 2200/2971, Loss: 0.1491805613040924, Uncertainty: 0.03428522124886513
Epoch 30, Batch 2300/2971, Loss: 0.14288093149662018, Uncertainty: 0.03278867527842522
Epoch 30, Batch 2400/2971, Loss: 0.15216650068759918, Uncertainty: 0.03448862582445145
Epoch 30, Batch 2500/2971, Loss: 0.15512993931770325, Uncertainty: 0.03313684090971947
Epoch 30, Batch 2600/2971, Loss: 0.15179197490215302, Uncertainty: 0.03436931595206261
Epoch 30, Batch 2700/2971, Loss: 0.14947441220283508, Uncertainty: 0.03373531997203827
Epoch 30, Batch 2800/2971, Loss: 0.1450599581003189, Uncertainty: 0.032377999275922775
Epoch 30, Batch 2900/2971, Loss: 0.1498466283082962, Uncertainty: 0.03253895044326782

Training and Validation Results of Epoch 30:
================================
Training Loss: 0.15076494230460896, Training Uncertainty: 0.03260194991336893, time: 1695.9207668304443
Validation Loss: 0.15075724211948877, Validation Uncertainty: 0.032414081487629164, time: 336.81042671203613
Number of predictions within uncertainty interval: 51167/763521 (6.70%)

Epoch 31, Batch 100/2971, Loss: 0.15244224667549133, Uncertainty: 0.03394709527492523
Epoch 31, Batch 200/2971, Loss: 0.149954691529274, Uncertainty: 0.031922485679388046
Epoch 31, Batch 300/2971, Loss: 0.15106403827667236, Uncertainty: 0.029546471312642097
Epoch 31, Batch 400/2971, Loss: 0.1480609029531479, Uncertainty: 0.032367363572120667
Epoch 31, Batch 500/2971, Loss: 0.15078401565551758, Uncertainty: 0.03281320631504059
Epoch 31, Batch 600/2971, Loss: 0.14765018224716187, Uncertainty: 0.030792541801929474
Epoch 31, Batch 700/2971, Loss: 0.15542300045490265, Uncertainty: 0.0303662046790123
Epoch 31, Batch 800/2971, Loss: 0.14489661157131195, Uncertainty: 0.03152088448405266
Epoch 31, Batch 900/2971, Loss: 0.14425340294837952, Uncertainty: 0.03208000212907791
Epoch 31, Batch 1000/2971, Loss: 0.15044860541820526, Uncertainty: 0.03174467757344246
Epoch 31, Batch 1100/2971, Loss: 0.15211889147758484, Uncertainty: 0.03342026472091675
Epoch 31, Batch 1200/2971, Loss: 0.15351080894470215, Uncertainty: 0.030787304043769836
Epoch 31, Batch 1300/2971, Loss: 0.14362816512584686, Uncertainty: 0.03255126252770424
Epoch 31, Batch 1400/2971, Loss: 0.14710640907287598, Uncertainty: 0.02967500127851963
Epoch 31, Batch 1500/2971, Loss: 0.1495111882686615, Uncertainty: 0.03537283465266228
Epoch 31, Batch 1600/2971, Loss: 0.15536019206047058, Uncertainty: 0.032440971583127975
Epoch 31, Batch 1700/2971, Loss: 0.1539813131093979, Uncertainty: 0.030808348208665848
Epoch 31, Batch 1800/2971, Loss: 0.1463610678911209, Uncertainty: 0.029998036101460457
Epoch 31, Batch 1900/2971, Loss: 0.15311968326568604, Uncertainty: 0.03140929713845253
Epoch 31, Batch 2000/2971, Loss: 0.14283506572246552, Uncertainty: 0.030903730541467667
Epoch 31, Batch 2100/2971, Loss: 0.15126219391822815, Uncertainty: 0.03175544738769531
Epoch 31, Batch 2200/2971, Loss: 0.14916430413722992, Uncertainty: 0.03420105576515198
Epoch 31, Batch 2300/2971, Loss: 0.14287136495113373, Uncertainty: 0.03223859518766403
Epoch 31, Batch 2400/2971, Loss: 0.1521378457546234, Uncertainty: 0.035294096916913986
Epoch 31, Batch 2500/2971, Loss: 0.1551222950220108, Uncertainty: 0.033558834344148636
Epoch 31, Batch 2600/2971, Loss: 0.1517684906721115, Uncertainty: 0.033672429621219635
Epoch 31, Batch 2700/2971, Loss: 0.14945897459983826, Uncertainty: 0.03388155251741409
Epoch 31, Batch 2800/2971, Loss: 0.1450435370206833, Uncertainty: 0.03249554708600044
Epoch 31, Batch 2900/2971, Loss: 0.1498469114303589, Uncertainty: 0.03245747461915016

Training and Validation Results of Epoch 31:
================================
Training Loss: 0.1507498462296062, Training Uncertainty: 0.032604971500593216, time: 1694.805385351181
Validation Loss: 0.15073730370398325, Validation Uncertainty: 0.03255812666588243, time: 335.4341096878052
Number of predictions within uncertainty interval: 51646/763521 (6.76%)

Epoch 32, Batch 100/2971, Loss: 0.15245775878429413, Uncertainty: 0.03366917744278908
Epoch 32, Batch 200/2971, Loss: 0.14994463324546814, Uncertainty: 0.03211105242371559
Epoch 32, Batch 300/2971, Loss: 0.15102826058864594, Uncertainty: 0.029227647930383682
Epoch 32, Batch 400/2971, Loss: 0.1480349749326706, Uncertainty: 0.032224517315626144
Epoch 32, Batch 500/2971, Loss: 0.1507745385169983, Uncertainty: 0.03229917585849762
Epoch 32, Batch 600/2971, Loss: 0.14764714241027832, Uncertainty: 0.030560407787561417
Epoch 32, Batch 700/2971, Loss: 0.15540266036987305, Uncertainty: 0.030090223997831345
Epoch 32, Batch 800/2971, Loss: 0.14487901329994202, Uncertainty: 0.031849563121795654
Epoch 32, Batch 900/2971, Loss: 0.14424976706504822, Uncertainty: 0.03237605467438698
Epoch 32, Batch 1000/2971, Loss: 0.15041157603263855, Uncertainty: 0.031681809574365616
Epoch 32, Batch 1100/2971, Loss: 0.1521177440881729, Uncertainty: 0.03320745378732681
Epoch 32, Batch 1200/2971, Loss: 0.15350839495658875, Uncertainty: 0.030799638479948044
Epoch 32, Batch 1300/2971, Loss: 0.14360922574996948, Uncertainty: 0.03260328993201256
Epoch 32, Batch 1400/2971, Loss: 0.14711777865886688, Uncertainty: 0.030380036681890488
Epoch 32, Batch 1500/2971, Loss: 0.14949238300323486, Uncertainty: 0.03484584018588066
Epoch 32, Batch 1600/2971, Loss: 0.15534621477127075, Uncertainty: 0.03241129592061043
Epoch 32, Batch 1700/2971, Loss: 0.153999924659729, Uncertainty: 0.03064223751425743
Epoch 32, Batch 1800/2971, Loss: 0.1463020294904709, Uncertainty: 0.029962817206978798
Epoch 32, Batch 1900/2971, Loss: 0.1531020551919937, Uncertainty: 0.0318816713988781
Epoch 32, Batch 2000/2971, Loss: 0.14280375838279724, Uncertainty: 0.03073047287762165
Epoch 32, Batch 2100/2971, Loss: 0.15124624967575073, Uncertainty: 0.0320030078291893
Epoch 32, Batch 2200/2971, Loss: 0.14916051924228668, Uncertainty: 0.034211162477731705
Epoch 32, Batch 2300/2971, Loss: 0.14285211265087128, Uncertainty: 0.032106902450323105
Epoch 32, Batch 2400/2971, Loss: 0.15211902558803558, Uncertainty: 0.03478413075208664
Epoch 32, Batch 2500/2971, Loss: 0.15512314438819885, Uncertainty: 0.03367112949490547
Epoch 32, Batch 2600/2971, Loss: 0.1517755538225174, Uncertainty: 0.033968735486269
Epoch 32, Batch 2700/2971, Loss: 0.1494326889514923, Uncertainty: 0.03365110605955124
Epoch 32, Batch 2800/2971, Loss: 0.14506271481513977, Uncertainty: 0.03212623670697212
Epoch 32, Batch 2900/2971, Loss: 0.14982111752033234, Uncertainty: 0.032898396253585815

Training and Validation Results of Epoch 32:
================================
Training Loss: 0.15073680159460612, Training Uncertainty: 0.03255384423977215, time: 1690.331111907959
Validation Loss: 0.15072768619772883, Validation Uncertainty: 0.03247908811670293, time: 341.89546751976013
Number of predictions within uncertainty interval: 51446/763521 (6.74%)

Epoch 33, Batch 100/2971, Loss: 0.15245383977890015, Uncertainty: 0.033995699137449265
Epoch 33, Batch 200/2971, Loss: 0.1499258577823639, Uncertainty: 0.031786397099494934
Epoch 33, Batch 300/2971, Loss: 0.1509917974472046, Uncertainty: 0.02910151518881321
Epoch 33, Batch 400/2971, Loss: 0.14800752699375153, Uncertainty: 0.0319460853934288
Epoch 33, Batch 500/2971, Loss: 0.15078547596931458, Uncertainty: 0.032794803380966187
Epoch 33, Batch 600/2971, Loss: 0.14761993288993835, Uncertainty: 0.03142603486776352
Epoch 33, Batch 700/2971, Loss: 0.1553884893655777, Uncertainty: 0.030517594888806343
Epoch 33, Batch 800/2971, Loss: 0.14486224949359894, Uncertainty: 0.03144211322069168
Epoch 33, Batch 900/2971, Loss: 0.14423537254333496, Uncertainty: 0.03209530934691429
Epoch 33, Batch 1000/2971, Loss: 0.15039180219173431, Uncertainty: 0.031617533415555954
Epoch 33, Batch 1100/2971, Loss: 0.15209941565990448, Uncertainty: 0.032879412174224854
Epoch 33, Batch 1200/2971, Loss: 0.15349550545215607, Uncertainty: 0.03054392896592617
Epoch 33, Batch 1300/2971, Loss: 0.14358338713645935, Uncertainty: 0.03186367079615593
Epoch 33, Batch 1400/2971, Loss: 0.14709725975990295, Uncertainty: 0.030054504051804543
Epoch 33, Batch 1500/2971, Loss: 0.1495116949081421, Uncertainty: 0.03498420491814613
Epoch 33, Batch 1600/2971, Loss: 0.15531156957149506, Uncertainty: 0.03189433738589287
Epoch 33, Batch 1700/2971, Loss: 0.15398184955120087, Uncertainty: 0.030358942225575447
Epoch 33, Batch 1800/2971, Loss: 0.146283820271492, Uncertainty: 0.03016858920454979
Epoch 33, Batch 1900/2971, Loss: 0.15308555960655212, Uncertainty: 0.03166675940155983
Epoch 33, Batch 2000/2971, Loss: 0.14280292391777039, Uncertainty: 0.03117121197283268
Epoch 33, Batch 2100/2971, Loss: 0.15122447907924652, Uncertainty: 0.03183430805802345
Epoch 33, Batch 2200/2971, Loss: 0.14914219081401825, Uncertainty: 0.03357698768377304
Epoch 33, Batch 2300/2971, Loss: 0.14282816648483276, Uncertainty: 0.031797610223293304
Epoch 33, Batch 2400/2971, Loss: 0.15209834277629852, Uncertainty: 0.034622665494680405
Epoch 33, Batch 2500/2971, Loss: 0.15509212017059326, Uncertainty: 0.03334321081638336
Epoch 33, Batch 2600/2971, Loss: 0.1517874002456665, Uncertainty: 0.03415485471487045
Epoch 33, Batch 2700/2971, Loss: 0.14942686259746552, Uncertainty: 0.03360491618514061
Epoch 33, Batch 2800/2971, Loss: 0.14506365358829498, Uncertainty: 0.032238151878118515
Epoch 33, Batch 2900/2971, Loss: 0.1498037576675415, Uncertainty: 0.03243072330951691

Training and Validation Results of Epoch 33:
================================
Training Loss: 0.15072345367508358, Training Uncertainty: 0.03251990436308916, time: 1700.5171439647675
Validation Loss: 0.1507233755705655, Validation Uncertainty: 0.03250317519698618, time: 337.31325578689575
Number of predictions within uncertainty interval: 51419/763521 (6.73%)

Epoch 34, Batch 100/2971, Loss: 0.1524260938167572, Uncertainty: 0.03351190686225891
Epoch 34, Batch 200/2971, Loss: 0.14991559088230133, Uncertainty: 0.03194883093237877
Epoch 34, Batch 300/2971, Loss: 0.1509876251220703, Uncertainty: 0.028918026015162468
Epoch 34, Batch 400/2971, Loss: 0.14804954826831818, Uncertainty: 0.032036297023296356
Epoch 34, Batch 500/2971, Loss: 0.15075615048408508, Uncertainty: 0.03276204690337181
Epoch 34, Batch 600/2971, Loss: 0.14760400354862213, Uncertainty: 0.03128333017230034
Epoch 34, Batch 700/2971, Loss: 0.15537843108177185, Uncertainty: 0.03077387623488903
Epoch 34, Batch 800/2971, Loss: 0.14483827352523804, Uncertainty: 0.031175365671515465
Epoch 34, Batch 900/2971, Loss: 0.1442187875509262, Uncertainty: 0.032211657613515854
Epoch 34, Batch 1000/2971, Loss: 0.15040229260921478, Uncertainty: 0.03197821229696274
Epoch 34, Batch 1100/2971, Loss: 0.1520988941192627, Uncertainty: 0.03344016149640083
Epoch 34, Batch 1200/2971, Loss: 0.15347935259342194, Uncertainty: 0.03067506104707718
Epoch 34, Batch 1300/2971, Loss: 0.14358331263065338, Uncertainty: 0.03227731212973595
Epoch 34, Batch 1400/2971, Loss: 0.14708063006401062, Uncertainty: 0.02971137873828411
Epoch 34, Batch 1500/2971, Loss: 0.14947813749313354, Uncertainty: 0.03486958518624306
Epoch 34, Batch 1600/2971, Loss: 0.155292809009552, Uncertainty: 0.03205377981066704
Epoch 34, Batch 1700/2971, Loss: 0.15395544469356537, Uncertainty: 0.03058241680264473
Epoch 34, Batch 1800/2971, Loss: 0.1462845355272293, Uncertainty: 0.02994631975889206
Epoch 34, Batch 1900/2971, Loss: 0.15307117998600006, Uncertainty: 0.031352151185274124
Epoch 34, Batch 2000/2971, Loss: 0.1427740603685379, Uncertainty: 0.03078322857618332
Epoch 34, Batch 2100/2971, Loss: 0.15122519433498383, Uncertainty: 0.03192036971449852
Epoch 34, Batch 2200/2971, Loss: 0.1491512656211853, Uncertainty: 0.03390762582421303
Epoch 34, Batch 2300/2971, Loss: 0.14281977713108063, Uncertainty: 0.03193410858511925
Epoch 34, Batch 2400/2971, Loss: 0.15206269919872284, Uncertainty: 0.03426649048924446
Epoch 34, Batch 2500/2971, Loss: 0.15507952868938446, Uncertainty: 0.03290187567472458
Epoch 34, Batch 2600/2971, Loss: 0.15178389847278595, Uncertainty: 0.03445925936102867
Epoch 34, Batch 2700/2971, Loss: 0.14939986169338226, Uncertainty: 0.03338911756873131
Epoch 34, Batch 2800/2971, Loss: 0.1450621336698532, Uncertainty: 0.03219166770577431
Epoch 34, Batch 2900/2971, Loss: 0.1498028039932251, Uncertainty: 0.03272553160786629

============================= JOB FEEDBACK =============================

NodeName=uc2n512
Job ID: 23867422
Cluster: uc2
User/Group: fq0795/iti
State: TIMEOUT (exit code 0)
Nodes: 1
Cores per node: 10
CPU Utilized: 00:00:00
CPU Efficiency: 0.00% of 8-08:01:10 core-walltime
Job Wall-clock time: 20:00:07
Memory Utilized: 37.18 GB
Memory Efficiency: 40.50% of 91.80 GB
