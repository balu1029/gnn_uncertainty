Epoch 286, Batch 300/1000, Loss: 13.20768928527832, Uncertainty: 4.446375370025635
Epoch 286, Batch 400/1000, Loss: 8.083127975463867, Uncertainty: 7.985527038574219
Epoch 286, Batch 500/1000, Loss: 8.653677940368652, Uncertainty: 5.9971232414245605
Epoch 99, Batch 2500/3125, Loss: 1.122145175933838, Uncertainty: 1.4243882894515991
Epoch 286, Batch 600/1000, Loss: 7.727470397949219, Uncertainty: 2.452512741088867
Training on device: cuda
Epoch 286, Batch 700/1000, Loss: 9.744083404541016, Uncertainty: 6.435784339904785
Epoch 286, Batch 800/1000, Loss: 8.462825775146484, Uncertainty: 6.44274377822876
Epoch 286, Batch 900/1000, Loss: 10.7123384475708, Uncertainty: 6.013002395629883
Epoch 286, Batch 1000/1000, Loss: 9.220345497131348, Uncertainty: 4.821114540100098

Training and Validation Results of Epoch 286:
================================
Training Loss: 8.854967340707779, Training Uncertainty: 5.735500151634216, time: 8.493070125579834
Validation Loss: 10.31358160018921, Validation Uncertainty: 9.28952732849121, time: 1.0929279327392578
Number of predictions within uncertainty interval: 537/2000 (26.85%)

Epoch 287, Batch 100/1000, Loss: 7.790164947509766, Uncertainty: 8.24435043334961
Epoch 287, Batch 200/1000, Loss: 9.554071426391602, Uncertainty: 7.1284403800964355
Epoch 99, Batch 2600/3125, Loss: 1.234227180480957, Uncertainty: 1.435513973236084
Epoch 287, Batch 300/1000, Loss: 13.22794246673584, Uncertainty: 4.505041122436523
Epoch 287, Batch 400/1000, Loss: 8.195588111877441, Uncertainty: 8.101122856140137
Epoch 287, Batch 500/1000, Loss: 8.619566917419434, Uncertainty: 6.0556535720825195
Epoch 287, Batch 600/1000, Loss: 7.729592800140381, Uncertainty: 2.2470955848693848
Epoch 287, Batch 700/1000, Loss: 9.8904447555542, Uncertainty: 6.764233112335205
Epoch 287, Batch 800/1000, Loss: 8.333451271057129, Uncertainty: 6.140800476074219
Epoch 287, Batch 900/1000, Loss: 10.603277206420898, Uncertainty: 5.851593017578125
Epoch 99, Batch 2700/3125, Loss: 1.4223754405975342, Uncertainty: 1.8675453662872314
Epoch 287, Batch 1000/1000, Loss: 9.165316581726074, Uncertainty: 4.854613304138184

Training and Validation Results of Epoch 287:
================================
Training Loss: 8.843081379890442, Training Uncertainty: 5.7462702896595, time: 8.653149843215942
Validation Loss: 10.3093779296875, Validation Uncertainty: 9.313936250686645, time: 1.107114553451538
Number of predictions within uncertainty interval: 538/2000 (26.90%)

Epoch 288, Batch 100/1000, Loss: 7.802504539489746, Uncertainty: 8.370588302612305
Epoch 288, Batch 200/1000, Loss: 9.427827835083008, Uncertainty: 6.955841064453125
Epoch 288, Batch 300/1000, Loss: 13.196258544921875, Uncertainty: 4.666048049926758
Epoch 288, Batch 400/1000, Loss: 8.077670097351074, Uncertainty: 8.157245635986328
Epoch 288, Batch 500/1000, Loss: 8.750357627868652, Uncertainty: 6.157209396362305
Epoch 99, Batch 2800/3125, Loss: 1.155440092086792, Uncertainty: 1.415671944618225
Epoch 288, Batch 600/1000, Loss: 7.762730598449707, Uncertainty: 2.2220940589904785
Epoch 288, Batch 700/1000, Loss: 9.822750091552734, Uncertainty: 6.716375350952148
Epoch 288, Batch 800/1000, Loss: 8.347354888916016, Uncertainty: 6.430015563964844
Epoch 288, Batch 900/1000, Loss: 10.53747272491455, Uncertainty: 5.907841682434082
Epoch 288, Batch 1000/1000, Loss: 9.168096542358398, Uncertainty: 5.058562755584717

Training and Validation Results of Epoch 288:
================================
Training Loss: 8.82888785648346, Training Uncertainty: 5.7559612381458285, time: 9.058249711990356
Validation Loss: 10.309747185707092, Validation Uncertainty: 9.347167068481445, time: 1.1414153575897217
Number of predictions within uncertainty interval: 548/2000 (27.40%)

Epoch 289, Batch 100/1000, Loss: 7.888058662414551, Uncertainty: 8.586782455444336
Epoch 289, Batch 200/1000, Loss: 9.319890022277832, Uncertainty: 7.133694171905518
Epoch 99, Batch 2900/3125, Loss: 1.2886898517608643, Uncertainty: 1.6218023300170898
Epoch 289, Batch 300/1000, Loss: 13.303728103637695, Uncertainty: 4.706300735473633
Epoch 289, Batch 400/1000, Loss: 8.006335258483887, Uncertainty: 8.183059692382812
Epoch 289, Batch 500/1000, Loss: 8.484302520751953, Uncertainty: 5.968255996704102
Epoch 289, Batch 600/1000, Loss: 7.598745822906494, Uncertainty: 2.173967123031616
Epoch 289, Batch 700/1000, Loss: 9.813440322875977, Uncertainty: 6.4945220947265625
Epoch 289, Batch 800/1000, Loss: 8.365478515625, Uncertainty: 6.349214553833008
Epoch 289, Batch 900/1000, Loss: 10.645389556884766, Uncertainty: 5.980373382568359
Epoch 99, Batch 3000/3125, Loss: 1.3400157690048218, Uncertainty: 1.5239431858062744
Epoch 289, Batch 1000/1000, Loss: 9.286160469055176, Uncertainty: 5.180515289306641

Training and Validation Results of Epoch 289:
================================
Training Loss: 8.82436963558197, Training Uncertainty: 5.767213013529777, time: 8.735313653945923
Validation Loss: 10.311877210617066, Validation Uncertainty: 9.39465916633606, time: 1.1007592678070068
Number of predictions within uncertainty interval: 547/2000 (27.35%)

Epoch 290, Batch 100/1000, Loss: 7.8326826095581055, Uncertainty: 8.447227478027344
Epoch 290, Batch 200/1000, Loss: 9.451435089111328, Uncertainty: 7.1277923583984375
Epoch 290, Batch 300/1000, Loss: 13.198812484741211, Uncertainty: 4.7562994956970215
Epoch 290, Batch 400/1000, Loss: 8.066043853759766, Uncertainty: 8.408369064331055
Epoch 290, Batch 500/1000, Loss: 8.58602523803711, Uncertainty: 6.2038774490356445
Epoch 99, Batch 3100/3125, Loss: 1.21405029296875, Uncertainty: 1.4199248552322388
Epoch 290, Batch 600/1000, Loss: 7.608942031860352, Uncertainty: 1.9589591026306152
Epoch 290, Batch 700/1000, Loss: 9.766735076904297, Uncertainty: 6.579339504241943
Epoch 290, Batch 800/1000, Loss: 8.438493728637695, Uncertainty: 6.230588912963867
Epoch 290, Batch 900/1000, Loss: 10.490886688232422, Uncertainty: 6.001278877258301
Epoch 290, Batch 1000/1000, Loss: 9.121170043945312, Uncertainty: 4.909533500671387

Training and Validation Results of Epoch 290:
================================
Training Loss: 8.81144372177124, Training Uncertainty: 5.771690246105194, time: 8.880380630493164
Validation Loss: 10.311554161071777, Validation Uncertainty: 9.393257877349853, time: 1.1058659553527832
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 291, Batch 100/1000, Loss: 7.899325370788574, Uncertainty: 8.57319450378418
Epoch 291, Batch 200/1000, Loss: 9.520992279052734, Uncertainty: 7.460391044616699
Epoch 291, Batch 300/1000, Loss: 13.24842643737793, Uncertainty: 4.679546356201172
Epoch 291, Batch 400/1000, Loss: 8.09994888305664, Uncertainty: 8.426033020019531
Epoch 291, Batch 500/1000, Loss: 8.812931060791016, Uncertainty: 6.137258529663086
Epoch 291, Batch 600/1000, Loss: 7.577499866485596, Uncertainty: 2.1431546211242676
Epoch 291, Batch 700/1000, Loss: 9.683388710021973, Uncertainty: 6.574507713317871
Epoch 291, Batch 800/1000, Loss: 8.364940643310547, Uncertainty: 6.295003890991211
Epoch 291, Batch 900/1000, Loss: 10.593021392822266, Uncertainty: 5.974149703979492
Epoch 291, Batch 1000/1000, Loss: 9.178226470947266, Uncertainty: 5.11361026763916

Training and Validation Results of Epoch 291:
================================
Training Loss: 8.803830238103867, Training Uncertainty: 5.786287463545799, time: 8.895875453948975
Validation Loss: 10.31711469554901, Validation Uncertainty: 9.481883716583251, time: 1.1022143363952637
Number of predictions within uncertainty interval: 545/2000 (27.25%)

Epoch 292, Batch 100/1000, Loss: 7.803450584411621, Uncertainty: 8.641948699951172
Epoch 292, Batch 200/1000, Loss: 9.462763786315918, Uncertainty: 7.24995231628418
Epoch 292, Batch 300/1000, Loss: 13.2659273147583, Uncertainty: 4.941722869873047
Epoch 292, Batch 400/1000, Loss: 8.026473045349121, Uncertainty: 8.542720794677734
Epoch 292, Batch 500/1000, Loss: 8.6552152633667, Uncertainty: 6.335496425628662
Epoch 292, Batch 600/1000, Loss: 7.566781044006348, Uncertainty: 2.012611150741577
Epoch 292, Batch 700/1000, Loss: 9.801661491394043, Uncertainty: 6.515608787536621
Epoch 292, Batch 800/1000, Loss: 8.384699821472168, Uncertainty: 6.242885112762451
Epoch 292, Batch 900/1000, Loss: 10.440755844116211, Uncertainty: 5.994927883148193
Epoch 292, Batch 1000/1000, Loss: 9.05399227142334, Uncertainty: 5.154579162597656
Learning rate changed to: 1e-05

Training and Validation Results of Epoch 292:
================================
Training Loss: 8.786254736423492, Training Uncertainty: 5.794969559550285, time: 8.6002938747406
Validation Loss: 10.309161943435669, Validation Uncertainty: 9.496338855743408, time: 1.138775110244751
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 293, Batch 100/1000, Loss: 7.979780197143555, Uncertainty: 6.878936290740967
Epoch 293, Batch 200/1000, Loss: 10.23483657836914, Uncertainty: 5.578242778778076
Epoch 293, Batch 300/1000, Loss: 13.103849411010742, Uncertainty: 4.826620578765869
Epoch 293, Batch 400/1000, Loss: 8.217119216918945, Uncertainty: 7.286713600158691
Epoch 293, Batch 500/1000, Loss: 8.736167907714844, Uncertainty: 4.9342241287231445
Epoch 293, Batch 600/1000, Loss: 8.19436264038086, Uncertainty: 4.57619571685791
Epoch 293, Batch 700/1000, Loss: 10.15084457397461, Uncertainty: 7.0127692222595215
Epoch 293, Batch 800/1000, Loss: 7.622334003448486, Uncertainty: 5.647340774536133
Epoch 293, Batch 900/1000, Loss: 10.452932357788086, Uncertainty: 6.872030735015869
Epoch 293, Batch 1000/1000, Loss: 9.214883804321289, Uncertainty: 5.358401298522949

Training and Validation Results of Epoch 293:
================================
Training Loss: 8.834780141830445, Training Uncertainty: 5.789420973062516, time: 8.841181516647339
Validation Loss: 10.303627914428711, Validation Uncertainty: 9.290701154708863, time: 1.1055293083190918
Number of predictions within uncertainty interval: 545/2000 (27.25%)

Epoch 294, Batch 100/1000, Loss: 8.053709030151367, Uncertainty: 7.798627853393555
Epoch 294, Batch 200/1000, Loss: 10.186029434204102, Uncertainty: 6.330251216888428
Epoch 294, Batch 300/1000, Loss: 13.095402717590332, Uncertainty: 4.979458332061768
Epoch 294, Batch 400/1000, Loss: 7.898366928100586, Uncertainty: 6.92288875579834
Loaded dataset in: 76.9071888923645 seconds
Epoch 294, Batch 500/1000, Loss: 8.527000427246094, Uncertainty: 5.211482048034668
Epoch 294, Batch 600/1000, Loss: 8.091073989868164, Uncertainty: 4.269400119781494
Epoch 294, Batch 700/1000, Loss: 10.054254531860352, Uncertainty: 7.163452625274658
Epoch 294, Batch 800/1000, Loss: 7.6473541259765625, Uncertainty: 5.646551132202148
Epoch 294, Batch 900/1000, Loss: 10.464096069335938, Uncertainty: 6.934560775756836
Epoch 294, Batch 1000/1000, Loss: 9.266007423400879, Uncertainty: 5.475863933563232

Training and Validation Results of Epoch 294:
================================
Training Loss: 8.799803530931472, Training Uncertainty: 5.721963606238365, time: 8.549934148788452
Validation Loss: 10.302718342781066, Validation Uncertainty: 9.249946573257446, time: 1.1216657161712646
Number of predictions within uncertainty interval: 546/2000 (27.30%)

Epoch 295, Batch 100/1000, Loss: 8.093877792358398, Uncertainty: 7.8921709060668945
Epoch 295, Batch 200/1000, Loss: 10.09560775756836, Uncertainty: 6.414072036743164
Epoch 295, Batch 300/1000, Loss: 13.104604721069336, Uncertainty: 5.075744152069092
Epoch 295, Batch 400/1000, Loss: 7.873812198638916, Uncertainty: 6.810635566711426
Epoch 295, Batch 500/1000, Loss: 8.49534797668457, Uncertainty: 5.233973026275635

Training and Validation Results of Epoch 99:
================================
Training Loss: 1.0365834403038026, Training Uncertainty: 1.5693010095977784, time: 204.7947473526001
Validation Loss: 0.9811519316547667, Validation Uncertainty: 2.235724625532584, time: 47.49964928627014
Number of predictions within uncertainty interval: 119541/200000 (59.77%)

Epoch 295, Batch 600/1000, Loss: 8.045297622680664, Uncertainty: 4.1135077476501465
Epoch 295, Batch 700/1000, Loss: 9.99297046661377, Uncertainty: 7.083919048309326
Epoch 295, Batch 800/1000, Loss: 7.580212116241455, Uncertainty: 5.637833118438721
Epoch 295, Batch 900/1000, Loss: 10.474556922912598, Uncertainty: 6.996769905090332
Epoch 295, Batch 1000/1000, Loss: 9.265835762023926, Uncertainty: 5.542433261871338

Training and Validation Results of Epoch 295:
================================
Training Loss: 8.787814620256423, Training Uncertainty: 5.713791008114815, time: 8.728785753250122
Validation Loss: 10.301287476539612, Validation Uncertainty: 9.240914049148559, time: 1.1124942302703857
Number of predictions within uncertainty interval: 545/2000 (27.25%)

Epoch 296, Batch 100/1000, Loss: 8.158679008483887, Uncertainty: 7.8545660972595215
Epoch 100, Batch 100/3125, Loss: 1.0751209259033203, Uncertainty: 1.2680530548095703
Epoch 296, Batch 200/1000, Loss: 10.038886070251465, Uncertainty: 6.444398403167725
Number of trainable parameters: 91107
Epoch 0, Batch 100/3125, Loss: 12.899057388305664, Uncertainty: 4.6029253005981445
Epoch 296, Batch 300/1000, Loss: 13.10389518737793, Uncertainty: 5.129723072052002
Epoch 296, Batch 400/1000, Loss: 7.891664505004883, Uncertainty: 6.8111371994018555
Epoch 296, Batch 500/1000, Loss: 8.478912353515625, Uncertainty: 5.264995574951172
Epoch 296, Batch 600/1000, Loss: 8.015754699707031, Uncertainty: 4.059154510498047
Epoch 296, Batch 700/1000, Loss: 9.989850044250488, Uncertainty: 7.062284469604492
Epoch 296, Batch 800/1000, Loss: 7.518882751464844, Uncertainty: 5.622585296630859
Epoch 296, Batch 900/1000, Loss: 10.47340202331543, Uncertainty: 7.006045341491699
Epoch 100, Batch 200/3125, Loss: 1.2927286624908447, Uncertainty: 1.6794434785842896
Epoch 0, Batch 200/3125, Loss: 11.930092811584473, Uncertainty: 1.0230958461761475
Epoch 296, Batch 1000/1000, Loss: 9.271783828735352, Uncertainty: 5.578333377838135

Training and Validation Results of Epoch 296:
================================
Training Loss: 8.781103680849075, Training Uncertainty: 5.711905668020249, time: 8.858283758163452
Validation Loss: 10.301860914230346, Validation Uncertainty: 9.237840560913085, time: 1.18174147605896
Number of predictions within uncertainty interval: 539/2000 (26.95%)

Epoch 297, Batch 100/1000, Loss: 8.202094078063965, Uncertainty: 7.827914237976074
Epoch 297, Batch 200/1000, Loss: 9.986207962036133, Uncertainty: 6.434609413146973
Epoch 297, Batch 300/1000, Loss: 13.121973037719727, Uncertainty: 5.125767707824707
Epoch 297, Batch 400/1000, Loss: 7.870181083679199, Uncertainty: 6.792122840881348
Epoch 0, Batch 300/3125, Loss: 12.039517402648926, Uncertainty: 2.675912857055664
Epoch 297, Batch 500/1000, Loss: 8.474442481994629, Uncertainty: 5.2711591720581055
Epoch 100, Batch 300/3125, Loss: 1.3607122898101807, Uncertainty: 1.5454535484313965
Epoch 297, Batch 600/1000, Loss: 7.9939799308776855, Uncertainty: 4.019397735595703
Epoch 297, Batch 700/1000, Loss: 9.995201110839844, Uncertainty: 7.0255632400512695
Epoch 297, Batch 800/1000, Loss: 7.449607849121094, Uncertainty: 5.57177734375
Epoch 297, Batch 900/1000, Loss: 10.488536834716797, Uncertainty: 7.074603080749512
Epoch 297, Batch 1000/1000, Loss: 9.275399208068848, Uncertainty: 5.613465785980225
Epoch 0, Batch 400/3125, Loss: 11.150941848754883, Uncertainty: 1.2451833486557007

Training and Validation Results of Epoch 297:
================================
Training Loss: 8.775841573476791, Training Uncertainty: 5.7099567326307294, time: 9.029617309570312
Validation Loss: 10.300667877197265, Validation Uncertainty: 9.240563423156738, time: 1.099015474319458
Number of predictions within uncertainty interval: 543/2000 (27.15%)

Epoch 298, Batch 100/1000, Loss: 8.224934577941895, Uncertainty: 7.798703193664551
Epoch 100, Batch 400/3125, Loss: 1.1255970001220703, Uncertainty: 1.4427447319030762
Epoch 298, Batch 200/1000, Loss: 9.979007720947266, Uncertainty: 6.435523509979248
Epoch 298, Batch 300/1000, Loss: 13.143777847290039, Uncertainty: 5.1830291748046875
Epoch 298, Batch 400/1000, Loss: 7.857111930847168, Uncertainty: 6.791961669921875
Epoch 298, Batch 500/1000, Loss: 8.51523208618164, Uncertainty: 5.292474746704102
Epoch 298, Batch 600/1000, Loss: 7.969784736633301, Uncertainty: 3.9346985816955566
Epoch 0, Batch 500/3125, Loss: 12.289934158325195, Uncertainty: 2.6732873916625977
Epoch 298, Batch 700/1000, Loss: 10.012821197509766, Uncertainty: 7.004512786865234
Epoch 298, Batch 800/1000, Loss: 7.401197910308838, Uncertainty: 5.496538162231445
Epoch 298, Batch 900/1000, Loss: 10.485893249511719, Uncertainty: 7.111364841461182
Epoch 100, Batch 500/3125, Loss: 1.267313003540039, Uncertainty: 1.6008572578430176
Epoch 298, Batch 1000/1000, Loss: 9.286663055419922, Uncertainty: 5.653439521789551

Training and Validation Results of Epoch 298:
================================
Training Loss: 8.770928262233735, Training Uncertainty: 5.710225593566895, time: 8.647921800613403
Validation Loss: 10.300733201980592, Validation Uncertainty: 9.245075721740722, time: 1.1787199974060059
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 299, Batch 100/1000, Loss: 8.246819496154785, Uncertainty: 7.785074234008789
Epoch 299, Batch 200/1000, Loss: 9.952062606811523, Uncertainty: 6.458182334899902
Epoch 0, Batch 600/3125, Loss: 12.913814544677734, Uncertainty: 2.4488930702209473
Epoch 299, Batch 300/1000, Loss: 13.149084091186523, Uncertainty: 5.229132652282715
Epoch 299, Batch 400/1000, Loss: 7.826714515686035, Uncertainty: 6.787210464477539
Epoch 299, Batch 500/1000, Loss: 8.500043869018555, Uncertainty: 5.284258842468262
Epoch 100, Batch 600/3125, Loss: 1.4558277130126953, Uncertainty: 1.5991712808609009
Epoch 299, Batch 600/1000, Loss: 7.936777591705322, Uncertainty: 3.884690046310425
Epoch 299, Batch 700/1000, Loss: 10.008308410644531, Uncertainty: 6.980542182922363
Epoch 299, Batch 800/1000, Loss: 7.367128849029541, Uncertainty: 5.471104621887207
Epoch 0, Batch 700/3125, Loss: 11.688140869140625, Uncertainty: 3.620522975921631
Epoch 299, Batch 900/1000, Loss: 10.501800537109375, Uncertainty: 7.122700214385986
Epoch 299, Batch 1000/1000, Loss: 9.27566909790039, Uncertainty: 5.631659030914307

Training and Validation Results of Epoch 299:
================================
Training Loss: 8.76712117767334, Training Uncertainty: 5.710801589250565, time: 9.027602672576904
Validation Loss: 10.300854285240174, Validation Uncertainty: 9.248784904479981, time: 1.1000823974609375
Number of predictions within uncertainty interval: 545/2000 (27.25%)

Epoch 300, Batch 100/1000, Loss: 8.275018692016602, Uncertainty: 7.79435920715332
Epoch 100, Batch 700/3125, Loss: 1.273876667022705, Uncertainty: 1.6252213716506958
Epoch 300, Batch 200/1000, Loss: 9.942547798156738, Uncertainty: 6.441636085510254
Epoch 300, Batch 300/1000, Loss: 13.13318920135498, Uncertainty: 5.213563919067383
Epoch 300, Batch 400/1000, Loss: 7.808194637298584, Uncertainty: 6.770578384399414
Epoch 0, Batch 800/3125, Loss: 11.427499771118164, Uncertainty: 1.6393166780471802
Epoch 300, Batch 500/1000, Loss: 8.48106575012207, Uncertainty: 5.284983158111572
Epoch 300, Batch 600/1000, Loss: 7.920111179351807, Uncertainty: 3.836742401123047
Epoch 300, Batch 700/1000, Loss: 10.013943672180176, Uncertainty: 6.9887375831604
Epoch 300, Batch 800/1000, Loss: 7.326329708099365, Uncertainty: 5.4448652267456055
Epoch 100, Batch 800/3125, Loss: 1.3474289178848267, Uncertainty: 1.5136573314666748
Epoch 300, Batch 900/1000, Loss: 10.505417823791504, Uncertainty: 7.157436847686768
Epoch 300, Batch 1000/1000, Loss: 9.270326614379883, Uncertainty: 5.671520233154297

Training and Validation Results of Epoch 300:
================================
Training Loss: 8.764204631328584, Training Uncertainty: 5.709960790395737, time: 8.266133308410645
Validation Loss: 10.301279215812682, Validation Uncertainty: 9.250354415893554, time: 1.1178853511810303
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 0, Batch 900/3125, Loss: 11.514488220214844, Uncertainty: 5.572484970092773
Epoch 301, Batch 100/1000, Loss: 8.290181159973145, Uncertainty: 7.789239406585693
Epoch 301, Batch 200/1000, Loss: 9.918811798095703, Uncertainty: 6.481348991394043
Epoch 301, Batch 300/1000, Loss: 13.139269828796387, Uncertainty: 5.221261024475098
Epoch 301, Batch 400/1000, Loss: 7.815639495849609, Uncertainty: 6.806598663330078
Epoch 100, Batch 900/3125, Loss: 1.414379596710205, Uncertainty: 1.7939561605453491
Epoch 301, Batch 500/1000, Loss: 8.482351303100586, Uncertainty: 5.274409294128418
Epoch 301, Batch 600/1000, Loss: 7.909124374389648, Uncertainty: 3.807027816772461
Epoch 301, Batch 700/1000, Loss: 10.044903755187988, Uncertainty: 6.994937419891357
Epoch 0, Batch 1000/3125, Loss: 11.261139869689941, Uncertainty: 3.826265335083008
Epoch 301, Batch 800/1000, Loss: 7.3022685050964355, Uncertainty: 5.415014266967773
Epoch 301, Batch 900/1000, Loss: 10.513093948364258, Uncertainty: 7.168993949890137
Epoch 301, Batch 1000/1000, Loss: 9.259976387023926, Uncertainty: 5.669413089752197

Training and Validation Results of Epoch 301:
================================
Training Loss: 8.760991695165634, Training Uncertainty: 5.711305177807808, time: 8.748687982559204
Validation Loss: 10.30110740852356, Validation Uncertainty: 9.252066841125488, time: 1.1115331649780273
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 302, Batch 100/1000, Loss: 8.276962280273438, Uncertainty: 7.738212585449219
Epoch 100, Batch 1000/3125, Loss: 1.1095094680786133, Uncertainty: 1.3098129034042358
Epoch 302, Batch 200/1000, Loss: 9.898019790649414, Uncertainty: 6.511443138122559
Epoch 0, Batch 1100/3125, Loss: 12.309013366699219, Uncertainty: 2.37115478515625
Epoch 302, Batch 300/1000, Loss: 13.141165733337402, Uncertainty: 5.246309280395508
Epoch 302, Batch 400/1000, Loss: 7.8199687004089355, Uncertainty: 6.815891265869141
Epoch 302, Batch 500/1000, Loss: 8.473865509033203, Uncertainty: 5.307781219482422
Epoch 302, Batch 600/1000, Loss: 7.894263744354248, Uncertainty: 3.785309314727783
Epoch 302, Batch 700/1000, Loss: 10.048912048339844, Uncertainty: 6.970874786376953
Epoch 302, Batch 800/1000, Loss: 7.277780532836914, Uncertainty: 5.401605606079102
Epoch 100, Batch 1100/3125, Loss: 1.301843523979187, Uncertainty: 1.5005626678466797
Epoch 0, Batch 1200/3125, Loss: 11.381171226501465, Uncertainty: 4.912369728088379
Epoch 302, Batch 900/1000, Loss: 10.5112943649292, Uncertainty: 7.192852973937988
Epoch 302, Batch 1000/1000, Loss: 9.26569938659668, Uncertainty: 5.667236328125

Training and Validation Results of Epoch 302:
================================
Training Loss: 8.757810770273208, Training Uncertainty: 5.712921829938889, time: 9.228289127349854
Validation Loss: 10.300015087127685, Validation Uncertainty: 9.258343292236328, time: 1.112389087677002
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 303, Batch 100/1000, Loss: 8.300935745239258, Uncertainty: 7.766844749450684
Epoch 303, Batch 200/1000, Loss: 9.888269424438477, Uncertainty: 6.505855083465576
Epoch 303, Batch 300/1000, Loss: 13.158724784851074, Uncertainty: 5.252089500427246
Epoch 303, Batch 400/1000, Loss: 7.811191558837891, Uncertainty: 6.8495073318481445
Epoch 0, Batch 1300/3125, Loss: 11.047588348388672, Uncertainty: 1.6165502071380615
Epoch 100, Batch 1200/3125, Loss: 1.3146157264709473, Uncertainty: 1.6457349061965942
Epoch 303, Batch 500/1000, Loss: 8.479944229125977, Uncertainty: 5.331602096557617
Epoch 303, Batch 600/1000, Loss: 7.8783392906188965, Uncertainty: 3.76391863822937
Epoch 303, Batch 700/1000, Loss: 10.059287071228027, Uncertainty: 6.979701995849609
Epoch 303, Batch 800/1000, Loss: 7.2596435546875, Uncertainty: 5.368477821350098
Epoch 303, Batch 900/1000, Loss: 10.521570205688477, Uncertainty: 7.239950180053711
Epoch 303, Batch 1000/1000, Loss: 9.268819808959961, Uncertainty: 5.693964004516602
Epoch 0, Batch 1400/3125, Loss: 11.893524169921875, Uncertainty: 2.5180811882019043

Training and Validation Results of Epoch 303:
================================
Training Loss: 8.754179201364517, Training Uncertainty: 5.717114783883095, time: 8.69343113899231
Validation Loss: 10.300543721199036, Validation Uncertainty: 9.263755760192872, time: 1.148005485534668
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 100, Batch 1300/3125, Loss: 1.2303450107574463, Uncertainty: 1.2766220569610596
Epoch 304, Batch 100/1000, Loss: 8.286299705505371, Uncertainty: 7.697699546813965
Epoch 304, Batch 200/1000, Loss: 9.873553276062012, Uncertainty: 6.5450873374938965
Epoch 304, Batch 300/1000, Loss: 13.144588470458984, Uncertainty: 5.270013809204102
Epoch 304, Batch 400/1000, Loss: 7.810945987701416, Uncertainty: 6.846463203430176
Epoch 304, Batch 500/1000, Loss: 8.47096061706543, Uncertainty: 5.316396713256836
Epoch 304, Batch 600/1000, Loss: 7.86463737487793, Uncertainty: 3.7382843494415283
Epoch 0, Batch 1500/3125, Loss: 12.126705169677734, Uncertainty: 4.2064313888549805
Epoch 304, Batch 700/1000, Loss: 10.071586608886719, Uncertainty: 6.97953987121582
Epoch 100, Batch 1400/3125, Loss: 1.194576621055603, Uncertainty: 1.5726120471954346
Epoch 304, Batch 800/1000, Loss: 7.249675750732422, Uncertainty: 5.364444732666016
Epoch 304, Batch 900/1000, Loss: 10.512747764587402, Uncertainty: 7.239714622497559
Epoch 304, Batch 1000/1000, Loss: 9.249152183532715, Uncertainty: 5.696262836456299

Training and Validation Results of Epoch 304:
================================
Training Loss: 8.751223549127578, Training Uncertainty: 5.717281994819641, time: 9.008430004119873
Validation Loss: 10.300035704612732, Validation Uncertainty: 9.265633953094483, time: 1.140852451324463
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 305, Batch 100/1000, Loss: 8.30032730102539, Uncertainty: 7.727038860321045
Epoch 0, Batch 1600/3125, Loss: 10.862862586975098, Uncertainty: 1.391313910484314
Epoch 305, Batch 200/1000, Loss: 9.871135711669922, Uncertainty: 6.5648884773254395
Epoch 305, Batch 300/1000, Loss: 13.143510818481445, Uncertainty: 5.293924331665039
Epoch 305, Batch 400/1000, Loss: 7.808337211608887, Uncertainty: 6.881870269775391
Epoch 100, Batch 1500/3125, Loss: 1.4028496742248535, Uncertainty: 1.534287452697754
Epoch 305, Batch 500/1000, Loss: 8.457137107849121, Uncertainty: 5.315675735473633
Epoch 305, Batch 600/1000, Loss: 7.864309310913086, Uncertainty: 3.7230710983276367
Epoch 305, Batch 700/1000, Loss: 10.088373184204102, Uncertainty: 6.956182479858398
Epoch 305, Batch 800/1000, Loss: 7.2424726486206055, Uncertainty: 5.363299369812012
Epoch 0, Batch 1700/3125, Loss: 10.72821044921875, Uncertainty: 1.9958096742630005
Epoch 305, Batch 900/1000, Loss: 10.527889251708984, Uncertainty: 7.2380828857421875
Epoch 305, Batch 1000/1000, Loss: 9.23613166809082, Uncertainty: 5.6598711013793945

Training and Validation Results of Epoch 305:
================================
Training Loss: 8.748529089689255, Training Uncertainty: 5.718388628959656, time: 8.69785213470459
Validation Loss: 10.299846592903137, Validation Uncertainty: 9.263077478408814, time: 1.1036710739135742
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 100, Batch 1600/3125, Loss: 1.193402886390686, Uncertainty: 1.5702910423278809
Epoch 306, Batch 100/1000, Loss: 8.30721664428711, Uncertainty: 7.709456920623779
Epoch 306, Batch 200/1000, Loss: 9.857744216918945, Uncertainty: 6.596980094909668
Epoch 306, Batch 300/1000, Loss: 13.137359619140625, Uncertainty: 5.2717742919921875
Epoch 0, Batch 1800/3125, Loss: 11.407751083374023, Uncertainty: 3.8374781608581543
Epoch 306, Batch 400/1000, Loss: 7.812348365783691, Uncertainty: 6.882939338684082
Epoch 306, Batch 500/1000, Loss: 8.456282615661621, Uncertainty: 5.327261924743652
Epoch 306, Batch 600/1000, Loss: 7.855743885040283, Uncertainty: 3.6959500312805176
Epoch 306, Batch 700/1000, Loss: 10.089922904968262, Uncertainty: 6.9382476806640625
Epoch 100, Batch 1700/3125, Loss: 1.19707190990448, Uncertainty: 1.582326889038086
Epoch 306, Batch 800/1000, Loss: 7.228579998016357, Uncertainty: 5.390581130981445
Epoch 306, Batch 900/1000, Loss: 10.525948524475098, Uncertainty: 7.270952224731445
Epoch 306, Batch 1000/1000, Loss: 9.230001449584961, Uncertainty: 5.678794860839844
Epoch 0, Batch 1900/3125, Loss: 11.615461349487305, Uncertainty: 1.6475591659545898

Training and Validation Results of Epoch 306:
================================
Training Loss: 8.744971029281617, Training Uncertainty: 5.719563907027244, time: 8.836654424667358
Validation Loss: 10.299655499458312, Validation Uncertainty: 9.267832080841064, time: 1.1430246829986572
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 307, Batch 100/1000, Loss: 8.321735382080078, Uncertainty: 7.7100629806518555
Epoch 307, Batch 200/1000, Loss: 9.86280345916748, Uncertainty: 6.59895133972168
Epoch 307, Batch 300/1000, Loss: 13.14639663696289, Uncertainty: 5.287460803985596
Epoch 100, Batch 1800/3125, Loss: 1.3489843606948853, Uncertainty: 1.5620038509368896
Epoch 307, Batch 400/1000, Loss: 7.804088115692139, Uncertainty: 6.899392604827881
Epoch 307, Batch 500/1000, Loss: 8.457925796508789, Uncertainty: 5.348264694213867
Epoch 0, Batch 2000/3125, Loss: 10.5681734085083, Uncertainty: 1.383845329284668
Epoch 307, Batch 600/1000, Loss: 7.850451469421387, Uncertainty: 3.6718904972076416
Epoch 307, Batch 700/1000, Loss: 10.09485149383545, Uncertainty: 6.935194969177246
Epoch 307, Batch 800/1000, Loss: 7.255135536193848, Uncertainty: 5.415088653564453
Epoch 307, Batch 900/1000, Loss: 10.53299331665039, Uncertainty: 7.287084579467773
Epoch 307, Batch 1000/1000, Loss: 9.226898193359375, Uncertainty: 5.647393703460693
Epoch 100, Batch 1900/3125, Loss: 1.075882911682129, Uncertainty: 1.4695384502410889

Training and Validation Results of Epoch 307:
================================
Training Loss: 8.7419888317585, Training Uncertainty: 5.725368075489998, time: 9.067266702651978
Validation Loss: 10.299324354171754, Validation Uncertainty: 9.27676996421814, time: 1.138505220413208
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 0, Batch 2100/3125, Loss: 10.930545806884766, Uncertainty: 1.890300989151001
Epoch 308, Batch 100/1000, Loss: 8.318758010864258, Uncertainty: 7.693037033081055
Epoch 308, Batch 200/1000, Loss: 9.833967208862305, Uncertainty: 6.5943827629089355
Epoch 308, Batch 300/1000, Loss: 13.132831573486328, Uncertainty: 5.291234493255615
Epoch 308, Batch 400/1000, Loss: 7.795779228210449, Uncertainty: 6.878842353820801
Epoch 308, Batch 500/1000, Loss: 8.435516357421875, Uncertainty: 5.339756488800049
Epoch 308, Batch 600/1000, Loss: 7.839601993560791, Uncertainty: 3.673621892929077
Epoch 308, Batch 700/1000, Loss: 10.10174560546875, Uncertainty: 6.94646692276001
Epoch 100, Batch 2000/3125, Loss: 1.252804160118103, Uncertainty: 1.518110752105713
Epoch 0, Batch 2200/3125, Loss: 11.01827621459961, Uncertainty: 3.631683349609375
Epoch 308, Batch 800/1000, Loss: 7.23744010925293, Uncertainty: 5.404423236846924
Epoch 308, Batch 900/1000, Loss: 10.532329559326172, Uncertainty: 7.278248310089111
Epoch 308, Batch 1000/1000, Loss: 9.224517822265625, Uncertainty: 5.654363632202148

Training and Validation Results of Epoch 308:
================================
Training Loss: 8.739882432460785, Training Uncertainty: 5.726864880800247, time: 8.828601598739624
Validation Loss: 10.298881049156188, Validation Uncertainty: 9.281465984344482, time: 1.1163203716278076
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 309, Batch 100/1000, Loss: 8.330024719238281, Uncertainty: 7.6796393394470215
Epoch 309, Batch 200/1000, Loss: 9.844305038452148, Uncertainty: 6.616185188293457
Epoch 0, Batch 2300/3125, Loss: 10.671165466308594, Uncertainty: 3.2469608783721924
Epoch 309, Batch 300/1000, Loss: 13.144718170166016, Uncertainty: 5.297132968902588
Epoch 100, Batch 2100/3125, Loss: 1.4420247077941895, Uncertainty: 1.6113734245300293
Epoch 309, Batch 400/1000, Loss: 7.790657997131348, Uncertainty: 6.898311138153076
Epoch 309, Batch 500/1000, Loss: 8.436684608459473, Uncertainty: 5.341704368591309
Epoch 309, Batch 600/1000, Loss: 7.836194038391113, Uncertainty: 3.6175990104675293
Epoch 309, Batch 700/1000, Loss: 10.083684921264648, Uncertainty: 6.89837646484375
Epoch 309, Batch 800/1000, Loss: 7.238998889923096, Uncertainty: 5.406804084777832
Epoch 309, Batch 900/1000, Loss: 10.531167984008789, Uncertainty: 7.300338268280029
Epoch 0, Batch 2400/3125, Loss: 11.618894577026367, Uncertainty: 1.8264551162719727
Epoch 309, Batch 1000/1000, Loss: 9.215494155883789, Uncertainty: 5.6171722412109375
Epoch 100, Batch 2200/3125, Loss: 1.0258095264434814, Uncertainty: 1.2864378690719604

Training and Validation Results of Epoch 309:
================================
Training Loss: 8.736719481229782, Training Uncertainty: 5.7299080095291135, time: 8.75692892074585
Validation Loss: 10.298815103530885, Validation Uncertainty: 9.285300828933716, time: 1.0962698459625244
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 310, Batch 100/1000, Loss: 8.325555801391602, Uncertainty: 7.656651020050049
Epoch 310, Batch 200/1000, Loss: 9.832878112792969, Uncertainty: 6.641772747039795
Epoch 310, Batch 300/1000, Loss: 13.142690658569336, Uncertainty: 5.315053462982178
Epoch 310, Batch 400/1000, Loss: 7.810273170471191, Uncertainty: 6.915660858154297
Epoch 0, Batch 2500/3125, Loss: 11.32955265045166, Uncertainty: 1.969902515411377
Epoch 310, Batch 500/1000, Loss: 8.448610305786133, Uncertainty: 5.391447067260742
Epoch 310, Batch 600/1000, Loss: 7.822627067565918, Uncertainty: 3.6183886528015137
Epoch 310, Batch 700/1000, Loss: 10.10482406616211, Uncertainty: 6.909876823425293
Epoch 100, Batch 2300/3125, Loss: 1.3575289249420166, Uncertainty: 1.8703904151916504
Epoch 310, Batch 800/1000, Loss: 7.230828285217285, Uncertainty: 5.40762996673584
Epoch 310, Batch 900/1000, Loss: 10.527589797973633, Uncertainty: 7.323546409606934
Epoch 310, Batch 1000/1000, Loss: 9.216557502746582, Uncertainty: 5.651178359985352

Training and Validation Results of Epoch 310:
================================
Training Loss: 8.734498621463775, Training Uncertainty: 5.730662618279457, time: 8.89854383468628
Validation Loss: 10.298579403877259, Validation Uncertainty: 9.289333003997802, time: 1.0760400295257568
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 0, Batch 2600/3125, Loss: 11.466377258300781, Uncertainty: 1.4972635507583618
Epoch 311, Batch 100/1000, Loss: 8.334036827087402, Uncertainty: 7.653212070465088
Epoch 311, Batch 200/1000, Loss: 9.856266975402832, Uncertainty: 6.643768787384033
Epoch 311, Batch 300/1000, Loss: 13.13378620147705, Uncertainty: 5.3489885330200195
Epoch 100, Batch 2400/3125, Loss: 1.318824291229248, Uncertainty: 1.6724556684494019
Epoch 311, Batch 400/1000, Loss: 7.799905776977539, Uncertainty: 6.904778957366943
Epoch 311, Batch 500/1000, Loss: 8.436222076416016, Uncertainty: 5.394720077514648
Epoch 311, Batch 600/1000, Loss: 7.827389240264893, Uncertainty: 3.6141319274902344
Epoch 311, Batch 700/1000, Loss: 10.109928131103516, Uncertainty: 6.92055606842041
Epoch 0, Batch 2700/3125, Loss: 10.804774284362793, Uncertainty: 1.7379480600357056
Epoch 311, Batch 800/1000, Loss: 7.253576755523682, Uncertainty: 5.403870105743408
Epoch 311, Batch 900/1000, Loss: 10.533306121826172, Uncertainty: 7.366812705993652
Epoch 311, Batch 1000/1000, Loss: 9.226448059082031, Uncertainty: 5.657101631164551
Epoch 100, Batch 2500/3125, Loss: 1.3199620246887207, Uncertainty: 1.678032636642456

Training and Validation Results of Epoch 311:
================================
Training Loss: 8.732525362968445, Training Uncertainty: 5.7322656373977665, time: 8.531707286834717
Validation Loss: 10.298132345199585, Validation Uncertainty: 9.290044855117797, time: 1.1052813529968262
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 312, Batch 100/1000, Loss: 8.3347806930542, Uncertainty: 7.640792369842529
Epoch 312, Batch 200/1000, Loss: 9.833446502685547, Uncertainty: 6.636559009552002
Epoch 0, Batch 2800/3125, Loss: 11.487293243408203, Uncertainty: 2.005436897277832
Epoch 312, Batch 300/1000, Loss: 13.135504722595215, Uncertainty: 5.3308329582214355
Epoch 312, Batch 400/1000, Loss: 7.800244331359863, Uncertainty: 6.91845703125
Epoch 312, Batch 500/1000, Loss: 8.438858032226562, Uncertainty: 5.379302024841309
Epoch 312, Batch 600/1000, Loss: 7.818242073059082, Uncertainty: 3.573075771331787
Epoch 312, Batch 700/1000, Loss: 10.099087715148926, Uncertainty: 6.855364799499512
Epoch 100, Batch 2600/3125, Loss: 1.2509101629257202, Uncertainty: 1.5323798656463623
Epoch 312, Batch 800/1000, Loss: 7.256546974182129, Uncertainty: 5.424431324005127
Epoch 312, Batch 900/1000, Loss: 10.540519714355469, Uncertainty: 7.394596099853516
Epoch 0, Batch 2900/3125, Loss: 11.270604133605957, Uncertainty: 2.7708168029785156
Epoch 312, Batch 1000/1000, Loss: 9.227703094482422, Uncertainty: 5.654001235961914

Training and Validation Results of Epoch 312:
================================
Training Loss: 8.729393418073654, Training Uncertainty: 5.734885495305061, time: 8.909448862075806
Validation Loss: 10.297539762496948, Validation Uncertainty: 9.295517818450929, time: 1.137930154800415
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 313, Batch 100/1000, Loss: 8.333208084106445, Uncertainty: 7.614432334899902
Epoch 313, Batch 200/1000, Loss: 9.839313507080078, Uncertainty: 6.690385341644287
Epoch 313, Batch 300/1000, Loss: 13.141854286193848, Uncertainty: 5.373859405517578
Epoch 100, Batch 2700/3125, Loss: 1.3918489217758179, Uncertainty: 1.809238076210022
Epoch 313, Batch 400/1000, Loss: 7.777927398681641, Uncertainty: 6.923128128051758
Epoch 0, Batch 3000/3125, Loss: 10.938837051391602, Uncertainty: 1.5153961181640625
Epoch 313, Batch 500/1000, Loss: 8.41781234741211, Uncertainty: 5.3891448974609375
Epoch 313, Batch 600/1000, Loss: 7.813271999359131, Uncertainty: 3.544196844100952
Epoch 313, Batch 700/1000, Loss: 10.08802604675293, Uncertainty: 6.833962440490723
Epoch 313, Batch 800/1000, Loss: 7.230040073394775, Uncertainty: 5.404427528381348
Epoch 313, Batch 900/1000, Loss: 10.539923667907715, Uncertainty: 7.387606620788574
Epoch 313, Batch 1000/1000, Loss: 9.213515281677246, Uncertainty: 5.655405044555664
Epoch 100, Batch 2800/3125, Loss: 1.2056177854537964, Uncertainty: 1.3745641708374023

Training and Validation Results of Epoch 313:
================================
Training Loss: 8.72661301279068, Training Uncertainty: 5.738243490219117, time: 8.72091293334961
Validation Loss: 10.296809869766236, Validation Uncertainty: 9.300590808868408, time: 1.0896048545837402
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 0, Batch 3100/3125, Loss: 11.275362014770508, Uncertainty: 2.9147427082061768
Epoch 314, Batch 100/1000, Loss: 8.337654113769531, Uncertainty: 7.667045593261719
Epoch 314, Batch 200/1000, Loss: 9.833734512329102, Uncertainty: 6.670566082000732
Epoch 314, Batch 300/1000, Loss: 13.14846420288086, Uncertainty: 5.404733657836914
Epoch 314, Batch 400/1000, Loss: 7.772427558898926, Uncertainty: 6.910871982574463
Epoch 314, Batch 500/1000, Loss: 8.42898178100586, Uncertainty: 5.411974906921387
Epoch 314, Batch 600/1000, Loss: 7.796755790710449, Uncertainty: 3.522578001022339
Epoch 100, Batch 2900/3125, Loss: 1.2606334686279297, Uncertainty: 1.6246308088302612
Epoch 314, Batch 700/1000, Loss: 10.106176376342773, Uncertainty: 6.867187976837158
Epoch 314, Batch 800/1000, Loss: 7.255291938781738, Uncertainty: 5.419580936431885
Epoch 314, Batch 900/1000, Loss: 10.539691925048828, Uncertainty: 7.375432968139648
Epoch 314, Batch 1000/1000, Loss: 9.223265647888184, Uncertainty: 5.644192695617676

Training and Validation Results of Epoch 314:
================================
Training Loss: 8.72382711648941, Training Uncertainty: 5.740706871151924, time: 8.825092792510986
Validation Loss: 10.297281207084655, Validation Uncertainty: 9.306288106918334, time: 1.1540682315826416
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 315, Batch 100/1000, Loss: 8.345064163208008, Uncertainty: 7.637058258056641
Epoch 315, Batch 200/1000, Loss: 9.823909759521484, Uncertainty: 6.711550712585449
Epoch 315, Batch 300/1000, Loss: 13.137537002563477, Uncertainty: 5.40582275390625
Epoch 100, Batch 3000/3125, Loss: 1.3384244441986084, Uncertainty: 1.5625883340835571
Epoch 315, Batch 400/1000, Loss: 7.765066623687744, Uncertainty: 6.929098129272461
Epoch 315, Batch 500/1000, Loss: 8.43527603149414, Uncertainty: 5.42510986328125
Epoch 315, Batch 600/1000, Loss: 7.797542095184326, Uncertainty: 3.4864532947540283
Epoch 315, Batch 700/1000, Loss: 10.107098579406738, Uncertainty: 6.857543468475342
Epoch 315, Batch 800/1000, Loss: 7.258605480194092, Uncertainty: 5.417638301849365
Epoch 315, Batch 900/1000, Loss: 10.534659385681152, Uncertainty: 7.400864124298096
Epoch 315, Batch 1000/1000, Loss: 9.21496868133545, Uncertainty: 5.66217565536499
Epoch 100, Batch 3100/3125, Loss: 1.181870460510254, Uncertainty: 1.443603754043579

Training and Validation Results of Epoch 315:
================================
Training Loss: 8.720478835821151, Training Uncertainty: 5.743042306780815, time: 8.903287172317505
Validation Loss: 10.296986369132995, Validation Uncertainty: 9.314319177627564, time: 1.1065680980682373
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 316, Batch 100/1000, Loss: 8.349170684814453, Uncertainty: 7.637849807739258
Epoch 316, Batch 200/1000, Loss: 9.843624114990234, Uncertainty: 6.730939865112305
Epoch 316, Batch 300/1000, Loss: 13.140222549438477, Uncertainty: 5.385393142700195
Epoch 316, Batch 400/1000, Loss: 7.759500980377197, Uncertainty: 6.940311431884766
Epoch 316, Batch 500/1000, Loss: 8.417104721069336, Uncertainty: 5.443524360656738
Epoch 316, Batch 600/1000, Loss: 7.802065849304199, Uncertainty: 3.467961072921753
Epoch 316, Batch 700/1000, Loss: 10.110130310058594, Uncertainty: 6.8466949462890625
Epoch 316, Batch 800/1000, Loss: 7.251965522766113, Uncertainty: 5.432150840759277
Epoch 316, Batch 900/1000, Loss: 10.553064346313477, Uncertainty: 7.442882537841797
Epoch 316, Batch 1000/1000, Loss: 9.209714889526367, Uncertainty: 5.662198066711426

Training and Validation Results of Epoch 316:
================================
Training Loss: 8.718836862564087, Training Uncertainty: 5.745730259537697, time: 8.821497917175293
Validation Loss: 10.29661859703064, Validation Uncertainty: 9.312452257156371, time: 1.1197168827056885
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 317, Batch 100/1000, Loss: 8.350431442260742, Uncertainty: 7.595094203948975
Epoch 317, Batch 200/1000, Loss: 9.835563659667969, Uncertainty: 6.729271411895752
Epoch 317, Batch 300/1000, Loss: 13.13153076171875, Uncertainty: 5.385433197021484
Epoch 317, Batch 400/1000, Loss: 7.781449794769287, Uncertainty: 6.947875022888184
Epoch 317, Batch 500/1000, Loss: 8.410321235656738, Uncertainty: 5.4587812423706055
Epoch 317, Batch 600/1000, Loss: 7.790130615234375, Uncertainty: 3.4874439239501953
Epoch 317, Batch 700/1000, Loss: 10.113232612609863, Uncertainty: 6.842870235443115
Epoch 317, Batch 800/1000, Loss: 7.257221698760986, Uncertainty: 5.421581268310547
Epoch 317, Batch 900/1000, Loss: 10.551048278808594, Uncertainty: 7.503622531890869
Epoch 317, Batch 1000/1000, Loss: 9.220117568969727, Uncertainty: 5.674449920654297

Training and Validation Results of Epoch 317:
================================
Training Loss: 8.715983021497726, Training Uncertainty: 5.744492823362351, time: 8.754976511001587
Validation Loss: 10.2964609375, Validation Uncertainty: 9.31582526397705, time: 1.1159117221832275
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 318, Batch 100/1000, Loss: 8.331991195678711, Uncertainty: 7.602550506591797
Epoch 318, Batch 200/1000, Loss: 9.819766998291016, Uncertainty: 6.725529670715332
Epoch 318, Batch 300/1000, Loss: 13.13143253326416, Uncertainty: 5.38798713684082
Epoch 318, Batch 400/1000, Loss: 7.785970687866211, Uncertainty: 6.949053764343262
Epoch 318, Batch 500/1000, Loss: 8.408942222595215, Uncertainty: 5.460175514221191

Training and Validation Results of Epoch 0:
================================
Training Loss: 11.764883784484864, Training Uncertainty: 2.3900145201206207, time: 185.43173122406006
Validation Loss: 11.271700716384537, Validation Uncertainty: 2.88964176025537, time: 42.59016132354736
Number of predictions within uncertainty interval: 16360/200000 (8.18%)

Epoch 318, Batch 600/1000, Loss: 7.7856011390686035, Uncertainty: 3.494778871536255
Epoch 318, Batch 700/1000, Loss: 10.117386817932129, Uncertainty: 6.854730606079102
Epoch 318, Batch 800/1000, Loss: 7.269199848175049, Uncertainty: 5.448707103729248
Epoch 318, Batch 900/1000, Loss: 10.5400390625, Uncertainty: 7.523229598999023
Epoch 318, Batch 1000/1000, Loss: 9.215059280395508, Uncertainty: 5.700429439544678

Training and Validation Results of Epoch 318:
================================
Training Loss: 8.714138726472855, Training Uncertainty: 5.747040489077568, time: 8.643309354782104
Validation Loss: 10.296552956581115, Validation Uncertainty: 9.320679485321046, time: 1.089498519897461
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 319, Batch 100/1000, Loss: 8.351459503173828, Uncertainty: 7.6027984619140625
Epoch 1, Batch 100/3125, Loss: 12.082723617553711, Uncertainty: 4.468894004821777
Epoch 319, Batch 200/1000, Loss: 9.82286548614502, Uncertainty: 6.749558925628662
Epoch 319, Batch 300/1000, Loss: 13.137853622436523, Uncertainty: 5.413433074951172
Epoch 319, Batch 400/1000, Loss: 7.773534774780273, Uncertainty: 6.97280740737915
Epoch 319, Batch 500/1000, Loss: 8.404561996459961, Uncertainty: 5.486069679260254
Epoch 319, Batch 600/1000, Loss: 7.788522720336914, Uncertainty: 3.4711992740631104
Epoch 319, Batch 700/1000, Loss: 10.117915153503418, Uncertainty: 6.845837593078613
Epoch 319, Batch 800/1000, Loss: 7.252338409423828, Uncertainty: 5.452126502990723
Epoch 1, Batch 200/3125, Loss: 9.569400787353516, Uncertainty: 2.240438222885132
Epoch 319, Batch 900/1000, Loss: 10.54443359375, Uncertainty: 7.528326988220215
Epoch 319, Batch 1000/1000, Loss: 9.215056419372559, Uncertainty: 5.721378326416016

Training and Validation Results of Epoch 319:
================================
Training Loss: 8.711872788667678, Training Uncertainty: 5.749362720608711, time: 8.691397190093994
Validation Loss: 10.296025257110596, Validation Uncertainty: 9.326711963653564, time: 1.1192309856414795
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 320, Batch 100/1000, Loss: 8.36862564086914, Uncertainty: 7.612999439239502
Epoch 320, Batch 200/1000, Loss: 9.812274932861328, Uncertainty: 6.773191928863525
Epoch 320, Batch 300/1000, Loss: 13.13774299621582, Uncertainty: 5.401098251342773
Epoch 320, Batch 400/1000, Loss: 7.7780585289001465, Uncertainty: 6.966920375823975
Epoch 1, Batch 300/3125, Loss: 11.048809051513672, Uncertainty: 1.6811673641204834
Epoch 320, Batch 500/1000, Loss: 8.40839958190918, Uncertainty: 5.476077079772949
Epoch 320, Batch 600/1000, Loss: 7.785937309265137, Uncertainty: 3.4675536155700684
Epoch 320, Batch 700/1000, Loss: 10.140426635742188, Uncertainty: 6.850285530090332
Epoch 320, Batch 800/1000, Loss: 7.273500919342041, Uncertainty: 5.472537994384766
Epoch 320, Batch 900/1000, Loss: 10.543107986450195, Uncertainty: 7.518195152282715
Epoch 320, Batch 1000/1000, Loss: 9.209161758422852, Uncertainty: 5.732179164886475
Epoch 1, Batch 400/3125, Loss: 10.182209968566895, Uncertainty: 2.3099076747894287

Training and Validation Results of Epoch 100:

Training and Validation Results of Epoch 320:
================================
Training Loss: 8.709556040287017, Training Uncertainty: 5.749465027093887, time: 8.832640647888184
Validation Loss: 10.296168054580688, Validation Uncertainty: 9.32206524848938, time: 1.1335768699645996
================================
Training Loss: 1.0251194128227235, Training Uncertainty: 1.554449730796814, time: 205.20227146148682
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Validation Loss: 0.908182065505201, Validation Uncertainty: 2.242610020863126, time: 47.942415714263916
Number of predictions within uncertainty interval: 125959/200000 (62.98%)

Epoch 321, Batch 100/1000, Loss: 8.367303848266602, Uncertainty: 7.574307918548584
Epoch 321, Batch 200/1000, Loss: 9.794388771057129, Uncertainty: 6.81069278717041
Epoch 321, Batch 300/1000, Loss: 13.135124206542969, Uncertainty: 5.400839805603027
Epoch 321, Batch 400/1000, Loss: 7.775221824645996, Uncertainty: 6.956126689910889
Epoch 321, Batch 500/1000, Loss: 8.387187004089355, Uncertainty: 5.477845191955566
Epoch 321, Batch 600/1000, Loss: 7.79057502746582, Uncertainty: 3.4823622703552246
Epoch 1, Batch 500/3125, Loss: 11.195502281188965, Uncertainty: 1.424990177154541
Epoch 321, Batch 700/1000, Loss: 10.122352600097656, Uncertainty: 6.820773124694824
Epoch 101, Batch 100/3125, Loss: 1.0578315258026123, Uncertainty: 1.2560207843780518
Epoch 321, Batch 800/1000, Loss: 7.272021770477295, Uncertainty: 5.489626884460449
Epoch 321, Batch 900/1000, Loss: 10.535309791564941, Uncertainty: 7.5959882736206055
Epoch 321, Batch 1000/1000, Loss: 9.216530799865723, Uncertainty: 5.738840579986572

Training and Validation Results of Epoch 321:
================================
Training Loss: 8.707700075387955, Training Uncertainty: 5.750767530322075, time: 8.904036283493042
Validation Loss: 10.296751385688781, Validation Uncertainty: 9.335087614059448, time: 1.114058017730713
Number of predictions within uncertainty interval: 557/2000 (27.85%)

Epoch 322, Batch 100/1000, Loss: 8.364259719848633, Uncertainty: 7.592209339141846
Epoch 322, Batch 200/1000, Loss: 9.803568840026855, Uncertainty: 6.799657344818115
Epoch 1, Batch 600/3125, Loss: 11.983861923217773, Uncertainty: 1.532031774520874
Epoch 322, Batch 300/1000, Loss: 13.133964538574219, Uncertainty: 5.410181522369385
Epoch 101, Batch 200/3125, Loss: 1.248530626296997, Uncertainty: 1.5338308811187744
Epoch 322, Batch 400/1000, Loss: 7.760134696960449, Uncertainty: 6.925782680511475
Epoch 322, Batch 500/1000, Loss: 8.391321182250977, Uncertainty: 5.47998046875
Epoch 322, Batch 600/1000, Loss: 7.7903571128845215, Uncertainty: 3.4512157440185547
Epoch 322, Batch 700/1000, Loss: 10.131579399108887, Uncertainty: 6.841554164886475
Epoch 322, Batch 800/1000, Loss: 7.29248571395874, Uncertainty: 5.498796463012695
Epoch 322, Batch 900/1000, Loss: 10.540492057800293, Uncertainty: 7.5600385665893555
Epoch 1, Batch 700/3125, Loss: 10.941244125366211, Uncertainty: 1.5924855470657349
Epoch 322, Batch 1000/1000, Loss: 9.200138092041016, Uncertainty: 5.719764709472656
Epoch 101, Batch 300/3125, Loss: 1.3732869625091553, Uncertainty: 1.6441783905029297

Training and Validation Results of Epoch 322:
================================
Training Loss: 8.705670222520828, Training Uncertainty: 5.75019895195961, time: 8.69287633895874
Validation Loss: 10.296195177078246, Validation Uncertainty: 9.326182529449463, time: 1.1054375171661377
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 323, Batch 100/1000, Loss: 8.366533279418945, Uncertainty: 7.608615398406982
Epoch 323, Batch 200/1000, Loss: 9.781867980957031, Uncertainty: 6.7962327003479
Epoch 323, Batch 300/1000, Loss: 13.139800071716309, Uncertainty: 5.409562587738037
Epoch 323, Batch 400/1000, Loss: 7.774388313293457, Uncertainty: 6.970876216888428
Epoch 323, Batch 500/1000, Loss: 8.384225845336914, Uncertainty: 5.5012054443359375
Epoch 1, Batch 800/3125, Loss: 9.890115737915039, Uncertainty: 1.6676945686340332
Epoch 323, Batch 600/1000, Loss: 7.807249546051025, Uncertainty: 3.501314163208008
Epoch 323, Batch 700/1000, Loss: 10.137825965881348, Uncertainty: 6.831334114074707
Epoch 101, Batch 400/3125, Loss: 1.20484459400177, Uncertainty: 1.5372427701950073
Epoch 323, Batch 800/1000, Loss: 7.2911577224731445, Uncertainty: 5.491294860839844
Epoch 323, Batch 900/1000, Loss: 10.535459518432617, Uncertainty: 7.612346649169922
Epoch 323, Batch 1000/1000, Loss: 9.195707321166992, Uncertainty: 5.742171287536621

Training and Validation Results of Epoch 323:
================================
Training Loss: 8.703942409276962, Training Uncertainty: 5.751534228920937, time: 8.831211566925049
Validation Loss: 10.295847365379334, Validation Uncertainty: 9.331094850540161, time: 1.1314961910247803
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 1, Batch 900/3125, Loss: 11.19747257232666, Uncertainty: 3.174938678741455
Epoch 324, Batch 100/1000, Loss: 8.366461753845215, Uncertainty: 7.581352233886719
Epoch 324, Batch 200/1000, Loss: 9.790413856506348, Uncertainty: 6.829307556152344
Epoch 324, Batch 300/1000, Loss: 13.128138542175293, Uncertainty: 5.412196159362793
Epoch 101, Batch 500/3125, Loss: 1.1833572387695312, Uncertainty: 1.499863624572754
Epoch 324, Batch 400/1000, Loss: 7.770419120788574, Uncertainty: 6.960094451904297
Epoch 324, Batch 500/1000, Loss: 8.37486457824707, Uncertainty: 5.497920513153076
Epoch 324, Batch 600/1000, Loss: 7.79248571395874, Uncertainty: 3.4759483337402344
Epoch 324, Batch 700/1000, Loss: 10.127758026123047, Uncertainty: 6.820871353149414
Epoch 1, Batch 1000/3125, Loss: 10.411341667175293, Uncertainty: 2.139476776123047
Epoch 324, Batch 800/1000, Loss: 7.27988862991333, Uncertainty: 5.499743938446045
Epoch 324, Batch 900/1000, Loss: 10.537725448608398, Uncertainty: 7.613656997680664
Epoch 324, Batch 1000/1000, Loss: 9.197762489318848, Uncertainty: 5.72589111328125
Epoch 101, Batch 600/3125, Loss: 1.4278616905212402, Uncertainty: 1.556715965270996

Training and Validation Results of Epoch 324:
================================
Training Loss: 8.701445736646653, Training Uncertainty: 5.75105665230751, time: 8.98457384109497
Validation Loss: 10.295847743988038, Validation Uncertainty: 9.330767534255981, time: 1.133829116821289
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 325, Batch 100/1000, Loss: 8.35753059387207, Uncertainty: 7.58204460144043
Epoch 325, Batch 200/1000, Loss: 9.78464412689209, Uncertainty: 6.812054634094238
Epoch 325, Batch 300/1000, Loss: 13.13214111328125, Uncertainty: 5.4130964279174805
Epoch 1, Batch 1100/3125, Loss: 12.100728988647461, Uncertainty: 1.8912872076034546
Epoch 325, Batch 400/1000, Loss: 7.77419376373291, Uncertainty: 6.989863395690918
Epoch 325, Batch 500/1000, Loss: 8.377348899841309, Uncertainty: 5.508723258972168
Epoch 325, Batch 600/1000, Loss: 7.808536052703857, Uncertainty: 3.473844528198242
Epoch 101, Batch 700/3125, Loss: 1.2690849304199219, Uncertainty: 1.6002204418182373
Epoch 325, Batch 700/1000, Loss: 10.125373840332031, Uncertainty: 6.824254989624023
Epoch 325, Batch 800/1000, Loss: 7.291504859924316, Uncertainty: 5.479521751403809
Epoch 325, Batch 900/1000, Loss: 10.542558670043945, Uncertainty: 7.638185501098633
Epoch 325, Batch 1000/1000, Loss: 9.193988800048828, Uncertainty: 5.754424095153809
Epoch 1, Batch 1200/3125, Loss: 10.638962745666504, Uncertainty: 1.5120878219604492

Training and Validation Results of Epoch 325:
================================
Training Loss: 8.700288030624389, Training Uncertainty: 5.753173181295395, time: 8.696701288223267
Validation Loss: 10.295454969406128, Validation Uncertainty: 9.336508434295654, time: 1.0834126472473145
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 326, Batch 100/1000, Loss: 8.368754386901855, Uncertainty: 7.580802917480469
Epoch 326, Batch 200/1000, Loss: 9.783099174499512, Uncertainty: 6.837998390197754
Epoch 101, Batch 800/3125, Loss: 1.3982491493225098, Uncertainty: 1.7659305334091187
Epoch 326, Batch 300/1000, Loss: 13.133867263793945, Uncertainty: 5.444512367248535
Epoch 326, Batch 400/1000, Loss: 7.773808002471924, Uncertainty: 6.960840225219727
Epoch 326, Batch 500/1000, Loss: 8.379924774169922, Uncertainty: 5.504863262176514
Epoch 1, Batch 1300/3125, Loss: 10.473722457885742, Uncertainty: 1.4308756589889526
Epoch 326, Batch 600/1000, Loss: 7.80305290222168, Uncertainty: 3.4781527519226074
Epoch 326, Batch 700/1000, Loss: 10.133907318115234, Uncertainty: 6.8356828689575195
Epoch 326, Batch 800/1000, Loss: 7.283309459686279, Uncertainty: 5.521101474761963
Epoch 326, Batch 900/1000, Loss: 10.54934310913086, Uncertainty: 7.666025161743164
Epoch 326, Batch 1000/1000, Loss: 9.185277938842773, Uncertainty: 5.714752674102783
Epoch 101, Batch 900/3125, Loss: 1.4170122146606445, Uncertainty: 1.6541229486465454

Training and Validation Results of Epoch 326:
================================
Training Loss: 8.697740664958953, Training Uncertainty: 5.753532579064369, time: 8.78246784210205
Validation Loss: 10.295105465888977, Validation Uncertainty: 9.333036087036133, time: 1.1250650882720947
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 327, Batch 100/1000, Loss: 8.372044563293457, Uncertainty: 7.549084186553955
Epoch 1, Batch 1400/3125, Loss: 11.693020820617676, Uncertainty: 4.245989799499512
Epoch 327, Batch 200/1000, Loss: 9.767870903015137, Uncertainty: 6.832629680633545
Epoch 327, Batch 300/1000, Loss: 13.142826080322266, Uncertainty: 5.451970100402832
Epoch 327, Batch 400/1000, Loss: 7.763409614562988, Uncertainty: 6.954841613769531
Epoch 327, Batch 500/1000, Loss: 8.35922622680664, Uncertainty: 5.533583641052246
Epoch 327, Batch 600/1000, Loss: 7.804023742675781, Uncertainty: 3.4754369258880615
Epoch 101, Batch 1000/3125, Loss: 1.1142475605010986, Uncertainty: 1.3198254108428955
Epoch 327, Batch 700/1000, Loss: 10.128019332885742, Uncertainty: 6.839754104614258
Epoch 327, Batch 800/1000, Loss: 7.2911553382873535, Uncertainty: 5.538265228271484
Epoch 1, Batch 1500/3125, Loss: 11.892158508300781, Uncertainty: 1.7218458652496338
Epoch 327, Batch 900/1000, Loss: 10.543495178222656, Uncertainty: 7.705256462097168
Epoch 327, Batch 1000/1000, Loss: 9.193926811218262, Uncertainty: 5.761011123657227

Training and Validation Results of Epoch 327:
================================
Training Loss: 8.695955748796463, Training Uncertainty: 5.754606834173202, time: 8.737276077270508
Validation Loss: 10.29520911693573, Validation Uncertainty: 9.342067167282105, time: 1.1105706691741943
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 328, Batch 100/1000, Loss: 8.378764152526855, Uncertainty: 7.545024394989014
Epoch 328, Batch 200/1000, Loss: 9.761587142944336, Uncertainty: 6.823756217956543
Epoch 101, Batch 1100/3125, Loss: 1.1738851070404053, Uncertainty: 1.4749608039855957
Epoch 328, Batch 300/1000, Loss: 13.12343978881836, Uncertainty: 5.400966644287109
Epoch 328, Batch 400/1000, Loss: 7.7848687171936035, Uncertainty: 6.974393844604492
Epoch 1, Batch 1600/3125, Loss: 11.009061813354492, Uncertainty: 1.6532617807388306
Epoch 328, Batch 500/1000, Loss: 8.361557960510254, Uncertainty: 5.517247200012207
Epoch 328, Batch 600/1000, Loss: 7.807916641235352, Uncertainty: 3.4931235313415527
Epoch 328, Batch 700/1000, Loss: 10.11561107635498, Uncertainty: 6.804775714874268
Epoch 328, Batch 800/1000, Loss: 7.288421630859375, Uncertainty: 5.525148391723633
Epoch 328, Batch 900/1000, Loss: 10.539861679077148, Uncertainty: 7.685389041900635
Epoch 101, Batch 1200/3125, Loss: 1.397574782371521, Uncertainty: 1.7395237684249878
Epoch 328, Batch 1000/1000, Loss: 9.179224967956543, Uncertainty: 5.738120079040527
Epoch 1, Batch 1700/3125, Loss: 10.471766471862793, Uncertainty: 2.5245282649993896

Training and Validation Results of Epoch 328:
================================
Training Loss: 8.694987679243088, Training Uncertainty: 5.755102946400642, time: 8.965988874435425
Validation Loss: 10.294884392738343, Validation Uncertainty: 9.342745920181274, time: 1.2074849605560303
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 329, Batch 100/1000, Loss: 8.382636070251465, Uncertainty: 7.5547075271606445
Epoch 329, Batch 200/1000, Loss: 9.771535873413086, Uncertainty: 6.850771427154541
Epoch 329, Batch 300/1000, Loss: 13.134140968322754, Uncertainty: 5.4270195960998535
Epoch 329, Batch 400/1000, Loss: 7.786351203918457, Uncertainty: 6.9773054122924805
Epoch 329, Batch 500/1000, Loss: 8.35760498046875, Uncertainty: 5.536691188812256
Epoch 329, Batch 600/1000, Loss: 7.817990303039551, Uncertainty: 3.489969253540039
Epoch 101, Batch 1300/3125, Loss: 1.2109922170639038, Uncertainty: 1.2764825820922852
Epoch 1, Batch 1800/3125, Loss: 10.992919921875, Uncertainty: 2.5616888999938965
Epoch 329, Batch 700/1000, Loss: 10.139571189880371, Uncertainty: 6.86568546295166
Epoch 329, Batch 800/1000, Loss: 7.299030303955078, Uncertainty: 5.534344673156738
Epoch 329, Batch 900/1000, Loss: 10.541158676147461, Uncertainty: 7.6948018074035645
Epoch 329, Batch 1000/1000, Loss: 9.160760879516602, Uncertainty: 5.756282806396484

Training and Validation Results of Epoch 329:
================================
Training Loss: 8.692103761911392, Training Uncertainty: 5.7566757303476335, time: 8.845218896865845
Validation Loss: 10.294865963935852, Validation Uncertainty: 9.344301942825318, time: 1.0806453227996826
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 330, Batch 100/1000, Loss: 8.381805419921875, Uncertainty: 7.553901672363281
Epoch 330, Batch 200/1000, Loss: 9.765387535095215, Uncertainty: 6.851963996887207
Epoch 101, Batch 1400/3125, Loss: 1.1738412380218506, Uncertainty: 1.5459051132202148
Epoch 1, Batch 1900/3125, Loss: 11.435417175292969, Uncertainty: 1.664203405380249
Epoch 330, Batch 300/1000, Loss: 13.135178565979004, Uncertainty: 5.417168140411377
Epoch 330, Batch 400/1000, Loss: 7.773152828216553, Uncertainty: 6.9870405197143555
Epoch 330, Batch 500/1000, Loss: 8.35766315460205, Uncertainty: 5.50638484954834
Epoch 330, Batch 600/1000, Loss: 7.804608345031738, Uncertainty: 3.480337619781494
Epoch 330, Batch 700/1000, Loss: 10.131631851196289, Uncertainty: 6.862666130065918
Epoch 330, Batch 800/1000, Loss: 7.324150085449219, Uncertainty: 5.549480438232422
Epoch 330, Batch 900/1000, Loss: 10.544672012329102, Uncertainty: 7.711286544799805
Epoch 101, Batch 1500/3125, Loss: 1.42103111743927, Uncertainty: 1.6267421245574951
Epoch 1, Batch 2000/3125, Loss: 10.573315620422363, Uncertainty: 1.967276692390442
Epoch 330, Batch 1000/1000, Loss: 9.164560317993164, Uncertainty: 5.773021221160889

Training and Validation Results of Epoch 330:
================================
Training Loss: 8.690297461271285, Training Uncertainty: 5.75716213953495, time: 8.439709901809692
Validation Loss: 10.29479390335083, Validation Uncertainty: 9.345987270355225, time: 1.1141629219055176
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 331, Batch 100/1000, Loss: 8.37527084350586, Uncertainty: 7.551705837249756
Epoch 331, Batch 200/1000, Loss: 9.774358749389648, Uncertainty: 6.869729042053223
Epoch 331, Batch 300/1000, Loss: 13.130880355834961, Uncertainty: 5.416370391845703
Epoch 331, Batch 400/1000, Loss: 7.780093669891357, Uncertainty: 7.002333641052246
Epoch 331, Batch 500/1000, Loss: 8.354021072387695, Uncertainty: 5.533596992492676
Epoch 1, Batch 2100/3125, Loss: 10.426124572753906, Uncertainty: 1.922480821609497
Epoch 101, Batch 1600/3125, Loss: 1.0685510635375977, Uncertainty: 1.3448452949523926
Epoch 331, Batch 600/1000, Loss: 7.814288139343262, Uncertainty: 3.476564407348633
Epoch 331, Batch 700/1000, Loss: 10.130741119384766, Uncertainty: 6.843701362609863
Epoch 331, Batch 800/1000, Loss: 7.3104329109191895, Uncertainty: 5.56681489944458
Epoch 331, Batch 900/1000, Loss: 10.548405647277832, Uncertainty: 7.803281307220459
Epoch 331, Batch 1000/1000, Loss: 9.163041114807129, Uncertainty: 5.7737531661987305

Training and Validation Results of Epoch 331:
================================
Training Loss: 8.688431106567382, Training Uncertainty: 5.758204463720322, time: 8.737617254257202
Validation Loss: 10.29503311252594, Validation Uncertainty: 9.345843999862671, time: 1.1132316589355469
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 332, Batch 100/1000, Loss: 8.390310287475586, Uncertainty: 7.5517048835754395
Epoch 1, Batch 2200/3125, Loss: 10.687076568603516, Uncertainty: 2.270040988922119
Epoch 101, Batch 1700/3125, Loss: 1.2147018909454346, Uncertainty: 1.599003791809082
Epoch 332, Batch 200/1000, Loss: 9.774194717407227, Uncertainty: 6.876219272613525
Epoch 332, Batch 300/1000, Loss: 13.132613182067871, Uncertainty: 5.412930011749268
Epoch 332, Batch 400/1000, Loss: 7.779613018035889, Uncertainty: 6.96414041519165
Epoch 332, Batch 500/1000, Loss: 8.342655181884766, Uncertainty: 5.528486251831055
Epoch 332, Batch 600/1000, Loss: 7.802454948425293, Uncertainty: 3.490238666534424
Epoch 332, Batch 700/1000, Loss: 10.127108573913574, Uncertainty: 6.830066204071045
Epoch 1, Batch 2300/3125, Loss: 10.579145431518555, Uncertainty: 2.0296568870544434
Epoch 332, Batch 800/1000, Loss: 7.311906337738037, Uncertainty: 5.530633926391602
Epoch 332, Batch 900/1000, Loss: 10.54088306427002, Uncertainty: 7.763236999511719
Epoch 101, Batch 1800/3125, Loss: 1.3512141704559326, Uncertainty: 1.5721957683563232
Epoch 332, Batch 1000/1000, Loss: 9.15594482421875, Uncertainty: 5.76371955871582

Training and Validation Results of Epoch 332:
================================
Training Loss: 8.686189729452133, Training Uncertainty: 5.758956685423851, time: 8.904730081558228
Validation Loss: 10.295316444396972, Validation Uncertainty: 9.351499588012695, time: 1.0850179195404053
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 333, Batch 100/1000, Loss: 8.36020278930664, Uncertainty: 7.532507419586182
Epoch 333, Batch 200/1000, Loss: 9.765495300292969, Uncertainty: 6.8812255859375
Epoch 333, Batch 300/1000, Loss: 13.136129379272461, Uncertainty: 5.4161763191223145
Epoch 1, Batch 2400/3125, Loss: 11.453373908996582, Uncertainty: 2.1332240104675293
Epoch 333, Batch 400/1000, Loss: 7.782224655151367, Uncertainty: 6.9999237060546875
Epoch 333, Batch 500/1000, Loss: 8.331104278564453, Uncertainty: 5.530365467071533
Epoch 101, Batch 1900/3125, Loss: 1.0986058712005615, Uncertainty: 1.5175223350524902
Epoch 333, Batch 600/1000, Loss: 7.806100845336914, Uncertainty: 3.5023696422576904
Epoch 333, Batch 700/1000, Loss: 10.133596420288086, Uncertainty: 6.854580402374268
Epoch 333, Batch 800/1000, Loss: 7.316227436065674, Uncertainty: 5.548922061920166
Epoch 333, Batch 900/1000, Loss: 10.539934158325195, Uncertainty: 7.819644927978516
Epoch 333, Batch 1000/1000, Loss: 9.143999099731445, Uncertainty: 5.777117729187012
Epoch 1, Batch 2500/3125, Loss: 11.173377990722656, Uncertainty: 1.8297361135482788

Training and Validation Results of Epoch 333:
================================
Training Loss: 8.684754979610442, Training Uncertainty: 5.758860843658447, time: 8.72162413597107
Validation Loss: 10.294697157859803, Validation Uncertainty: 9.351632926940917, time: 1.116283893585205
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 334, Batch 100/1000, Loss: 8.380252838134766, Uncertainty: 7.552037239074707
Epoch 101, Batch 2000/3125, Loss: 1.279127597808838, Uncertainty: 1.5181171894073486
Epoch 334, Batch 200/1000, Loss: 9.76758861541748, Uncertainty: 6.8798394203186035
Epoch 334, Batch 300/1000, Loss: 13.132743835449219, Uncertainty: 5.411139488220215
Epoch 334, Batch 400/1000, Loss: 7.779374122619629, Uncertainty: 6.979479789733887
Epoch 334, Batch 500/1000, Loss: 8.342803955078125, Uncertainty: 5.514995574951172
Epoch 334, Batch 600/1000, Loss: 7.799185752868652, Uncertainty: 3.485818862915039
Epoch 1, Batch 2600/3125, Loss: 11.213207244873047, Uncertainty: 2.6335835456848145
Epoch 334, Batch 700/1000, Loss: 10.122238159179688, Uncertainty: 6.834467887878418
Epoch 334, Batch 800/1000, Loss: 7.312240123748779, Uncertainty: 5.550534725189209
Epoch 334, Batch 900/1000, Loss: 10.534300804138184, Uncertainty: 7.754335880279541
Epoch 101, Batch 2100/3125, Loss: 1.4295227527618408, Uncertainty: 1.610182523727417
Epoch 334, Batch 1000/1000, Loss: 9.14034652709961, Uncertainty: 5.813076972961426

Training and Validation Results of Epoch 334:
================================
Training Loss: 8.682678160429, Training Uncertainty: 5.759425699710846, time: 9.017940521240234
Validation Loss: 10.294725184440614, Validation Uncertainty: 9.361712133407593, time: 1.1434121131896973
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 335, Batch 100/1000, Loss: 8.377262115478516, Uncertainty: 7.553225040435791
Epoch 1, Batch 2700/3125, Loss: 10.575889587402344, Uncertainty: 2.3096964359283447
Epoch 335, Batch 200/1000, Loss: 9.767483711242676, Uncertainty: 6.883130073547363
Epoch 335, Batch 300/1000, Loss: 13.13483715057373, Uncertainty: 5.4364118576049805
Epoch 335, Batch 400/1000, Loss: 7.770022869110107, Uncertainty: 6.974752902984619
Epoch 335, Batch 500/1000, Loss: 8.324935913085938, Uncertainty: 5.500420093536377
Epoch 101, Batch 2200/3125, Loss: 1.0296025276184082, Uncertainty: 1.2839465141296387
Epoch 335, Batch 600/1000, Loss: 7.809185981750488, Uncertainty: 3.488468647003174
Epoch 335, Batch 700/1000, Loss: 10.134744644165039, Uncertainty: 6.878814697265625
Epoch 335, Batch 800/1000, Loss: 7.313773155212402, Uncertainty: 5.547595024108887
Epoch 1, Batch 2800/3125, Loss: 11.227123260498047, Uncertainty: 2.2863664627075195
Epoch 335, Batch 900/1000, Loss: 10.525989532470703, Uncertainty: 7.8245391845703125
Epoch 335, Batch 1000/1000, Loss: 9.141950607299805, Uncertainty: 5.842493057250977

Training and Validation Results of Epoch 335:
================================
Training Loss: 8.681067115068435, Training Uncertainty: 5.761044016718865, time: 8.837878942489624
Validation Loss: 10.295287638664245, Validation Uncertainty: 9.357337661743165, time: 1.1183533668518066
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 336, Batch 100/1000, Loss: 8.37307357788086, Uncertainty: 7.543251991271973
Epoch 101, Batch 2300/3125, Loss: 1.3028162717819214, Uncertainty: 1.6531462669372559
Epoch 336, Batch 200/1000, Loss: 9.765911102294922, Uncertainty: 6.885927200317383
Epoch 336, Batch 300/1000, Loss: 13.137531280517578, Uncertainty: 5.40629768371582
Epoch 336, Batch 400/1000, Loss: 7.775173187255859, Uncertainty: 6.978674411773682
Epoch 1, Batch 2900/3125, Loss: 10.918935775756836, Uncertainty: 1.787339687347412
Epoch 336, Batch 500/1000, Loss: 8.326353073120117, Uncertainty: 5.520973205566406
Epoch 336, Batch 600/1000, Loss: 7.796322822570801, Uncertainty: 3.5255260467529297
Epoch 336, Batch 700/1000, Loss: 10.137371063232422, Uncertainty: 6.848356246948242
Epoch 336, Batch 800/1000, Loss: 7.315069675445557, Uncertainty: 5.5536017417907715
Epoch 101, Batch 2400/3125, Loss: 1.2853484153747559, Uncertainty: 1.5736401081085205
Epoch 336, Batch 900/1000, Loss: 10.540019989013672, Uncertainty: 7.79749870300293
Epoch 336, Batch 1000/1000, Loss: 9.130386352539062, Uncertainty: 5.851944923400879

Training and Validation Results of Epoch 336:
================================
Training Loss: 8.679620951652527, Training Uncertainty: 5.761214168548584, time: 8.985427618026733
Validation Loss: 10.294829448699952, Validation Uncertainty: 9.364162334442138, time: 1.139204978942871
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 1, Batch 3000/3125, Loss: 10.950082778930664, Uncertainty: 2.728029251098633
Epoch 337, Batch 100/1000, Loss: 8.38372802734375, Uncertainty: 7.534912109375
Epoch 337, Batch 200/1000, Loss: 9.751989364624023, Uncertainty: 6.883092403411865
Epoch 337, Batch 300/1000, Loss: 13.138158798217773, Uncertainty: 5.404505729675293
Epoch 337, Batch 400/1000, Loss: 7.774827480316162, Uncertainty: 6.984061241149902
Epoch 101, Batch 2500/3125, Loss: 1.222085952758789, Uncertainty: 1.6634325981140137
Epoch 337, Batch 500/1000, Loss: 8.318670272827148, Uncertainty: 5.537086486816406
Epoch 337, Batch 600/1000, Loss: 7.796897888183594, Uncertainty: 3.524661064147949
Epoch 337, Batch 700/1000, Loss: 10.133580207824707, Uncertainty: 6.857118129730225
Epoch 1, Batch 3100/3125, Loss: 11.12509536743164, Uncertainty: 2.3378686904907227
Epoch 337, Batch 800/1000, Loss: 7.303345203399658, Uncertainty: 5.553549766540527
Epoch 337, Batch 900/1000, Loss: 10.539146423339844, Uncertainty: 7.862448692321777
Epoch 337, Batch 1000/1000, Loss: 9.140579223632812, Uncertainty: 5.851898193359375

Training and Validation Results of Epoch 337:
================================
Training Loss: 8.676911427259444, Training Uncertainty: 5.761349848270417, time: 8.875734329223633
Validation Loss: 10.295101405143738, Validation Uncertainty: 9.36414582824707, time: 1.1195878982543945
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 101, Batch 2600/3125, Loss: 1.3843541145324707, Uncertainty: 1.7064127922058105
Epoch 338, Batch 100/1000, Loss: 8.378596305847168, Uncertainty: 7.514344215393066
Epoch 338, Batch 200/1000, Loss: 9.754018783569336, Uncertainty: 6.9114179611206055
Epoch 338, Batch 300/1000, Loss: 13.142538070678711, Uncertainty: 5.411191940307617
Epoch 338, Batch 400/1000, Loss: 7.775652885437012, Uncertainty: 6.969084739685059
Epoch 338, Batch 500/1000, Loss: 8.309102058410645, Uncertainty: 5.53299617767334
Epoch 338, Batch 600/1000, Loss: 7.8044962882995605, Uncertainty: 3.534975051879883
Epoch 338, Batch 700/1000, Loss: 10.138711929321289, Uncertainty: 6.838552474975586
Epoch 101, Batch 2700/3125, Loss: 1.4078938961029053, Uncertainty: 1.7894724607467651
Epoch 338, Batch 800/1000, Loss: 7.303948402404785, Uncertainty: 5.570234298706055
Epoch 338, Batch 900/1000, Loss: 10.524682998657227, Uncertainty: 7.873801231384277
Epoch 338, Batch 1000/1000, Loss: 9.146011352539062, Uncertainty: 5.875369071960449

Training and Validation Results of Epoch 338:
================================
Training Loss: 8.67556489443779, Training Uncertainty: 5.76323694229126, time: 8.803069829940796
Validation Loss: 10.294206186294556, Validation Uncertainty: 9.36890746498108, time: 1.1075196266174316
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 339, Batch 100/1000, Loss: 8.380729675292969, Uncertainty: 7.5155029296875
Epoch 339, Batch 200/1000, Loss: 9.741361618041992, Uncertainty: 6.903316497802734
Epoch 339, Batch 300/1000, Loss: 13.134239196777344, Uncertainty: 5.397134780883789
Epoch 101, Batch 2800/3125, Loss: 1.1303764581680298, Uncertainty: 1.3645448684692383
Epoch 339, Batch 400/1000, Loss: 7.776515960693359, Uncertainty: 7.010368347167969
Epoch 339, Batch 500/1000, Loss: 8.323528289794922, Uncertainty: 5.533768653869629
Epoch 339, Batch 600/1000, Loss: 7.797711372375488, Uncertainty: 3.5397212505340576
Epoch 339, Batch 700/1000, Loss: 10.147555351257324, Uncertainty: 6.863129615783691
Epoch 339, Batch 800/1000, Loss: 7.3158369064331055, Uncertainty: 5.57383918762207
Epoch 339, Batch 900/1000, Loss: 10.52083683013916, Uncertainty: 7.842625141143799
Epoch 339, Batch 1000/1000, Loss: 9.133552551269531, Uncertainty: 5.891144752502441

Training and Validation Results of Epoch 339:
================================
Training Loss: 8.6737761323452, Training Uncertainty: 5.764408442020416, time: 8.755592346191406
Validation Loss: 10.294539202690125, Validation Uncertainty: 9.367504343032836, time: 1.1049525737762451
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 101, Batch 2900/3125, Loss: 1.2858762741088867, Uncertainty: 1.5828378200531006
Epoch 340, Batch 100/1000, Loss: 8.368782043457031, Uncertainty: 7.511112213134766
Epoch 340, Batch 200/1000, Loss: 9.74216365814209, Uncertainty: 6.907531261444092
Epoch 340, Batch 300/1000, Loss: 13.141826629638672, Uncertainty: 5.407669544219971
Epoch 340, Batch 400/1000, Loss: 7.770205020904541, Uncertainty: 6.979050636291504
Epoch 340, Batch 500/1000, Loss: 8.301458358764648, Uncertainty: 5.540350914001465
Epoch 340, Batch 600/1000, Loss: 7.797616958618164, Uncertainty: 3.560703992843628
Epoch 340, Batch 700/1000, Loss: 10.149492263793945, Uncertainty: 6.853682518005371
Epoch 101, Batch 3000/3125, Loss: 1.3063290119171143, Uncertainty: 1.5076909065246582
Epoch 340, Batch 800/1000, Loss: 7.292692184448242, Uncertainty: 5.564336776733398
Epoch 340, Batch 900/1000, Loss: 10.515942573547363, Uncertainty: 7.878118515014648
Epoch 340, Batch 1000/1000, Loss: 9.120563507080078, Uncertainty: 5.885676383972168

Training and Validation Results of Epoch 340:
================================
Training Loss: 8.671971813201905, Training Uncertainty: 5.763967044830323, time: 9.06087327003479
Validation Loss: 10.294427959442139, Validation Uncertainty: 9.369478775024414, time: 1.1469225883483887
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 341, Batch 100/1000, Loss: 8.368850708007812, Uncertainty: 7.511685848236084
Epoch 341, Batch 200/1000, Loss: 9.757814407348633, Uncertainty: 6.932864189147949
Epoch 341, Batch 300/1000, Loss: 13.142577171325684, Uncertainty: 5.410606384277344
Epoch 341, Batch 400/1000, Loss: 7.777785778045654, Uncertainty: 7.010679244995117
Epoch 101, Batch 3100/3125, Loss: 1.1806769371032715, Uncertainty: 1.3932440280914307
Epoch 341, Batch 500/1000, Loss: 8.288387298583984, Uncertainty: 5.531465530395508
Epoch 341, Batch 600/1000, Loss: 7.809051036834717, Uncertainty: 3.5786733627319336
Epoch 341, Batch 700/1000, Loss: 10.150615692138672, Uncertainty: 6.859157085418701
Epoch 341, Batch 800/1000, Loss: 7.321784019470215, Uncertainty: 5.594742774963379
Epoch 341, Batch 900/1000, Loss: 10.530526161193848, Uncertainty: 7.928565979003906
Epoch 341, Batch 1000/1000, Loss: 9.145835876464844, Uncertainty: 5.9046430587768555

Training and Validation Results of Epoch 341:
================================
Training Loss: 8.67024678182602, Training Uncertainty: 5.765715183973312, time: 8.715885877609253
Validation Loss: 10.295078401565553, Validation Uncertainty: 9.378726318359375, time: 1.08282470703125
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 342, Batch 100/1000, Loss: 8.377351760864258, Uncertainty: 7.497756481170654
Epoch 342, Batch 200/1000, Loss: 9.74669361114502, Uncertainty: 6.9382548332214355
Epoch 342, Batch 300/1000, Loss: 13.148260116577148, Uncertainty: 5.40856409072876

Training and Validation Results of Epoch 1:
================================
Training Loss: 11.201415852966308, Training Uncertainty: 2.2180193508911135, time: 191.46287322044373
Validation Loss: 11.084942918909176, Validation Uncertainty: 4.60872057392774, time: 44.58773875236511
Number of predictions within uncertainty interval: 26100/200000 (13.05%)

Epoch 342, Batch 400/1000, Loss: 7.762920379638672, Uncertainty: 6.997872829437256
Epoch 342, Batch 500/1000, Loss: 8.301155090332031, Uncertainty: 5.532883167266846
Epoch 342, Batch 600/1000, Loss: 7.8122382164001465, Uncertainty: 3.551222801208496
Epoch 342, Batch 700/1000, Loss: 10.138372421264648, Uncertainty: 6.849928855895996
Epoch 342, Batch 800/1000, Loss: 7.2900261878967285, Uncertainty: 5.589500427246094
Epoch 342, Batch 900/1000, Loss: 10.50937271118164, Uncertainty: 7.862667560577393
Epoch 342, Batch 1000/1000, Loss: 9.119121551513672, Uncertainty: 5.896877765655518
Epoch 2, Batch 100/3125, Loss: 11.606257438659668, Uncertainty: 3.296416759490967

Training and Validation Results of Epoch 342:
================================
Training Loss: 8.668338134527206, Training Uncertainty: 5.766586840629578, time: 8.64773154258728
Validation Loss: 10.294486610412598, Validation Uncertainty: 9.374226713180542, time: 1.1300151348114014
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 343, Batch 100/1000, Loss: 8.383825302124023, Uncertainty: 7.509970664978027
Epoch 343, Batch 200/1000, Loss: 9.760046005249023, Uncertainty: 6.930562973022461
Epoch 343, Batch 300/1000, Loss: 13.146207809448242, Uncertainty: 5.399937629699707
Epoch 343, Batch 400/1000, Loss: 7.761547565460205, Uncertainty: 7.013221740722656
Epoch 343, Batch 500/1000, Loss: 8.285760879516602, Uncertainty: 5.529882907867432
Epoch 343, Batch 600/1000, Loss: 7.816544532775879, Uncertainty: 3.5716681480407715
Epoch 2, Batch 200/3125, Loss: 9.369222640991211, Uncertainty: 1.921309232711792
Epoch 343, Batch 700/1000, Loss: 10.149992942810059, Uncertainty: 6.895723819732666
Epoch 343, Batch 800/1000, Loss: 7.30923318862915, Uncertainty: 5.602153778076172
Epoch 343, Batch 900/1000, Loss: 10.524646759033203, Uncertainty: 7.917163848876953
Epoch 343, Batch 1000/1000, Loss: 9.109067916870117, Uncertainty: 5.931495666503906

Training and Validation Results of Epoch 343:
================================
Training Loss: 8.667748795747757, Training Uncertainty: 5.7654858911037445, time: 8.803998708724976
Validation Loss: 10.294244480133056, Validation Uncertainty: 9.381097059249878, time: 1.0985984802246094
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 344, Batch 100/1000, Loss: 8.381027221679688, Uncertainty: 7.47420597076416
Epoch 344, Batch 200/1000, Loss: 9.749268531799316, Uncertainty: 6.967872142791748
Epoch 2, Batch 300/3125, Loss: 11.037155151367188, Uncertainty: 3.404541492462158
Epoch 344, Batch 300/1000, Loss: 13.142053604125977, Uncertainty: 5.401433944702148
Epoch 344, Batch 400/1000, Loss: 7.776134014129639, Uncertainty: 7.012633323669434
Epoch 344, Batch 500/1000, Loss: 8.289887428283691, Uncertainty: 5.533926010131836
Epoch 344, Batch 600/1000, Loss: 7.813570022583008, Uncertainty: 3.582669734954834
Epoch 344, Batch 700/1000, Loss: 10.151445388793945, Uncertainty: 6.929954528808594
Epoch 344, Batch 800/1000, Loss: 7.313520431518555, Uncertainty: 5.592622756958008
Epoch 2, Batch 400/3125, Loss: 10.087333679199219, Uncertainty: 2.1853866577148438
Epoch 344, Batch 900/1000, Loss: 10.506937980651855, Uncertainty: 7.973466873168945
Epoch 344, Batch 1000/1000, Loss: 9.12076187133789, Uncertainty: 5.9564104080200195

Training and Validation Results of Epoch 344:
================================
Training Loss: 8.665389395713806, Training Uncertainty: 5.767264136314392, time: 8.963517904281616
Validation Loss: 10.29500239276886, Validation Uncertainty: 9.381554624557495, time: 1.0987977981567383
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 345, Batch 100/1000, Loss: 8.384166717529297, Uncertainty: 7.470418453216553
Epoch 345, Batch 200/1000, Loss: 9.734732627868652, Uncertainty: 6.972403526306152
Epoch 345, Batch 300/1000, Loss: 13.149213790893555, Uncertainty: 5.4004645347595215
Epoch 345, Batch 400/1000, Loss: 7.750108242034912, Uncertainty: 7.002044200897217
Epoch 2, Batch 500/3125, Loss: 10.940971374511719, Uncertainty: 2.3282482624053955
Epoch 345, Batch 500/1000, Loss: 8.292108535766602, Uncertainty: 5.51981258392334
Epoch 345, Batch 600/1000, Loss: 7.822269439697266, Uncertainty: 3.591754913330078
Epoch 345, Batch 700/1000, Loss: 10.172021865844727, Uncertainty: 6.9312872886657715
Epoch 345, Batch 800/1000, Loss: 7.303432941436768, Uncertainty: 5.604576110839844
Epoch 345, Batch 900/1000, Loss: 10.52175521850586, Uncertainty: 7.929288864135742
Epoch 345, Batch 1000/1000, Loss: 9.105220794677734, Uncertainty: 5.9416890144348145

Training and Validation Results of Epoch 345:
================================
Training Loss: 8.663628175735473, Training Uncertainty: 5.765781885266304, time: 8.7553870677948
Validation Loss: 10.295312831878663, Validation Uncertainty: 9.384931116104125, time: 1.127953290939331
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 2, Batch 600/3125, Loss: 11.705918312072754, Uncertainty: 2.02331805229187
Epoch 346, Batch 100/1000, Loss: 8.383293151855469, Uncertainty: 7.481287002563477
Epoch 346, Batch 200/1000, Loss: 9.721436500549316, Uncertainty: 6.938196182250977
Epoch 346, Batch 300/1000, Loss: 13.14801025390625, Uncertainty: 5.40421199798584
Epoch 346, Batch 400/1000, Loss: 7.763935089111328, Uncertainty: 7.019930362701416

Training and Validation Results of Epoch 101:
================================
Training Loss: 1.0188186629486085, Training Uncertainty: 1.551492082901001, time: 204.1693160533905
Validation Loss: 0.9068067600507566, Validation Uncertainty: 2.2447394946651995, time: 47.96356225013733
Number of predictions within uncertainty interval: 125852/200000 (62.93%)

Epoch 346, Batch 500/1000, Loss: 8.284212112426758, Uncertainty: 5.493519306182861
Epoch 346, Batch 600/1000, Loss: 7.819841384887695, Uncertainty: 3.5914878845214844
Epoch 346, Batch 700/1000, Loss: 10.158027648925781, Uncertainty: 6.934514999389648
Epoch 2, Batch 700/3125, Loss: 10.740259170532227, Uncertainty: 2.3369479179382324
Epoch 346, Batch 800/1000, Loss: 7.291031837463379, Uncertainty: 5.629703521728516
Epoch 346, Batch 900/1000, Loss: 10.512887954711914, Uncertainty: 8.004003524780273
Epoch 346, Batch 1000/1000, Loss: 9.114907264709473, Uncertainty: 5.9612321853637695

Training and Validation Results of Epoch 346:
================================
Training Loss: 8.66196409702301, Training Uncertainty: 5.768477659225464, time: 9.015267372131348
Validation Loss: 10.295767928123475, Validation Uncertainty: 9.388044733047485, time: 1.1211402416229248
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 102, Batch 100/3125, Loss: 1.057002305984497, Uncertainty: 1.255915880203247
Epoch 347, Batch 100/1000, Loss: 8.380622863769531, Uncertainty: 7.46727991104126
Epoch 347, Batch 200/1000, Loss: 9.737482070922852, Uncertainty: 6.942471504211426
Epoch 347, Batch 300/1000, Loss: 13.149625778198242, Uncertainty: 5.388617515563965
Epoch 2, Batch 800/3125, Loss: 9.832783699035645, Uncertainty: 3.613889694213867
Epoch 347, Batch 400/1000, Loss: 7.756696701049805, Uncertainty: 7.006267547607422
Epoch 347, Batch 500/1000, Loss: 8.280085563659668, Uncertainty: 5.471408843994141
Epoch 347, Batch 600/1000, Loss: 7.826611518859863, Uncertainty: 3.586740016937256
Epoch 347, Batch 700/1000, Loss: 10.170700073242188, Uncertainty: 6.9451775550842285
Epoch 102, Batch 200/3125, Loss: 1.2319447994232178, Uncertainty: 1.5216279029846191
Epoch 347, Batch 800/1000, Loss: 7.291959285736084, Uncertainty: 5.599651336669922
Epoch 347, Batch 900/1000, Loss: 10.506448745727539, Uncertainty: 7.986384391784668
Epoch 347, Batch 1000/1000, Loss: 9.11160659790039, Uncertainty: 5.984768867492676
Epoch 2, Batch 900/3125, Loss: 10.976372718811035, Uncertainty: 3.037036895751953

Training and Validation Results of Epoch 347:
================================
Training Loss: 8.660490899085998, Training Uncertainty: 5.769446264386177, time: 8.563101291656494
Validation Loss: 10.294633367538452, Validation Uncertainty: 9.390756753921508, time: 1.0885698795318604
Number of predictions within uncertainty interval: 557/2000 (27.85%)

Epoch 348, Batch 100/1000, Loss: 8.37040901184082, Uncertainty: 7.441699028015137
Epoch 348, Batch 200/1000, Loss: 9.727533340454102, Uncertainty: 7.001053810119629
Epoch 348, Batch 300/1000, Loss: 13.152050018310547, Uncertainty: 5.405976295471191
Epoch 102, Batch 300/3125, Loss: 1.3594610691070557, Uncertainty: 1.4562374353408813
Epoch 348, Batch 400/1000, Loss: 7.7646894454956055, Uncertainty: 7.008738994598389
Epoch 348, Batch 500/1000, Loss: 8.291803359985352, Uncertainty: 5.502957344055176
Epoch 348, Batch 600/1000, Loss: 7.8122992515563965, Uncertainty: 3.586153984069824
Epoch 2, Batch 1000/3125, Loss: 10.22935676574707, Uncertainty: 2.091832160949707
Epoch 348, Batch 700/1000, Loss: 10.153356552124023, Uncertainty: 6.9659552574157715
Epoch 348, Batch 800/1000, Loss: 7.29630184173584, Uncertainty: 5.586553573608398
Epoch 348, Batch 900/1000, Loss: 10.505463600158691, Uncertainty: 8.007708549499512
Epoch 348, Batch 1000/1000, Loss: 9.125009536743164, Uncertainty: 5.968348503112793

Training and Validation Results of Epoch 348:
================================
Training Loss: 8.658564099788666, Training Uncertainty: 5.767839325070381, time: 8.837372064590454
Validation Loss: 10.294726929664613, Validation Uncertainty: 9.390846883773804, time: 1.1152331829071045
Number of predictions within uncertainty interval: 558/2000 (27.90%)

Epoch 102, Batch 400/3125, Loss: 1.115239143371582, Uncertainty: 1.4199151992797852
Epoch 349, Batch 100/1000, Loss: 8.3932466506958, Uncertainty: 7.428109645843506
Epoch 2, Batch 1100/3125, Loss: 11.82138442993164, Uncertainty: 2.1552963256835938
Epoch 349, Batch 200/1000, Loss: 9.713424682617188, Uncertainty: 6.961930274963379
Epoch 349, Batch 300/1000, Loss: 13.160563468933105, Uncertainty: 5.4166178703308105
Epoch 349, Batch 400/1000, Loss: 7.779145240783691, Uncertainty: 7.02840518951416
Epoch 349, Batch 500/1000, Loss: 8.2896728515625, Uncertainty: 5.494710445404053
Epoch 349, Batch 600/1000, Loss: 7.832597255706787, Uncertainty: 3.6143221855163574
Epoch 349, Batch 700/1000, Loss: 10.163472175598145, Uncertainty: 6.995120048522949
Epoch 102, Batch 500/3125, Loss: 1.2533111572265625, Uncertainty: 1.5770577192306519
Epoch 349, Batch 800/1000, Loss: 7.29788064956665, Uncertainty: 5.639404296875
Epoch 349, Batch 900/1000, Loss: 10.515432357788086, Uncertainty: 8.074000358581543
Epoch 2, Batch 1200/3125, Loss: 10.53319263458252, Uncertainty: 1.879961609840393
Epoch 349, Batch 1000/1000, Loss: 9.12312126159668, Uncertainty: 5.984575271606445

Training and Validation Results of Epoch 349:
================================
Training Loss: 8.657708649396897, Training Uncertainty: 5.769454365611076, time: 8.842248678207397
Validation Loss: 10.294172992706299, Validation Uncertainty: 9.396363834381104, time: 1.1210620403289795
Number of predictions within uncertainty interval: 558/2000 (27.90%)

Epoch 350, Batch 100/1000, Loss: 8.387627601623535, Uncertainty: 7.458907604217529
Epoch 350, Batch 200/1000, Loss: 9.725693702697754, Uncertainty: 6.988028526306152
Epoch 350, Batch 300/1000, Loss: 13.157590866088867, Uncertainty: 5.408320903778076
Epoch 102, Batch 600/3125, Loss: 1.3945567607879639, Uncertainty: 1.4904862642288208
Epoch 350, Batch 400/1000, Loss: 7.7468414306640625, Uncertainty: 6.998887538909912
Epoch 2, Batch 1300/3125, Loss: 10.31065559387207, Uncertainty: 2.032149314880371
Epoch 350, Batch 500/1000, Loss: 8.281286239624023, Uncertainty: 5.49608039855957
Epoch 350, Batch 600/1000, Loss: 7.83837366104126, Uncertainty: 3.5649375915527344
Epoch 350, Batch 700/1000, Loss: 10.158695220947266, Uncertainty: 6.99915885925293
Epoch 350, Batch 800/1000, Loss: 7.2902512550354, Uncertainty: 5.649242877960205
Epoch 350, Batch 900/1000, Loss: 10.502145767211914, Uncertainty: 8.026599884033203
Epoch 350, Batch 1000/1000, Loss: 9.110004425048828, Uncertainty: 5.961474418640137
Epoch 102, Batch 700/3125, Loss: 1.217193365097046, Uncertainty: 1.5192279815673828

Training and Validation Results of Epoch 350:
================================
Training Loss: 8.656071642160416, Training Uncertainty: 5.7698226011991505, time: 8.744420766830444
Validation Loss: 10.294739771842957, Validation Uncertainty: 9.395873027801514, time: 1.128427267074585
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 2, Batch 1400/3125, Loss: 11.046937942504883, Uncertainty: 2.8762154579162598
Epoch 351, Batch 100/1000, Loss: 8.366796493530273, Uncertainty: 7.45947790145874
Epoch 351, Batch 200/1000, Loss: 9.735021591186523, Uncertainty: 6.997833251953125
Epoch 351, Batch 300/1000, Loss: 13.15971851348877, Uncertainty: 5.416343688964844
Epoch 351, Batch 400/1000, Loss: 7.7357096672058105, Uncertainty: 6.9766693115234375
Epoch 351, Batch 500/1000, Loss: 8.275819778442383, Uncertainty: 5.491545677185059
Epoch 351, Batch 600/1000, Loss: 7.826904773712158, Uncertainty: 3.5924882888793945
Epoch 351, Batch 700/1000, Loss: 10.19040584564209, Uncertainty: 7.0579514503479
Epoch 102, Batch 800/3125, Loss: 1.3672757148742676, Uncertainty: 1.6557157039642334
Epoch 2, Batch 1500/3125, Loss: 11.770528793334961, Uncertainty: 2.2154343128204346
Epoch 351, Batch 800/1000, Loss: 7.2952680587768555, Uncertainty: 5.614344596862793
Epoch 351, Batch 900/1000, Loss: 10.503936767578125, Uncertainty: 8.022297859191895
Epoch 351, Batch 1000/1000, Loss: 9.107892990112305, Uncertainty: 5.979340553283691

Training and Validation Results of Epoch 351:
================================
Training Loss: 8.653674863100052, Training Uncertainty: 5.76950347006321, time: 8.992061614990234
Validation Loss: 10.294841220855712, Validation Uncertainty: 9.40306820678711, time: 1.114828109741211
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 352, Batch 100/1000, Loss: 8.368404388427734, Uncertainty: 7.4313435554504395
Epoch 352, Batch 200/1000, Loss: 9.7267484664917, Uncertainty: 6.991060733795166
Epoch 352, Batch 300/1000, Loss: 13.163982391357422, Uncertainty: 5.423623085021973
Epoch 2, Batch 1600/3125, Loss: 10.800825119018555, Uncertainty: 2.41760516166687
Epoch 102, Batch 900/3125, Loss: 1.395105242729187, Uncertainty: 1.6102685928344727
Epoch 352, Batch 400/1000, Loss: 7.748026371002197, Uncertainty: 7.0048112869262695
Epoch 352, Batch 500/1000, Loss: 8.288854598999023, Uncertainty: 5.522217750549316
Epoch 352, Batch 600/1000, Loss: 7.817387104034424, Uncertainty: 3.6127147674560547
Epoch 352, Batch 700/1000, Loss: 10.176004409790039, Uncertainty: 7.057689666748047
Epoch 352, Batch 800/1000, Loss: 7.276894569396973, Uncertainty: 5.639521598815918
Epoch 352, Batch 900/1000, Loss: 10.497305870056152, Uncertainty: 8.036996841430664
Epoch 352, Batch 1000/1000, Loss: 9.08205509185791, Uncertainty: 5.9586181640625
Epoch 2, Batch 1700/3125, Loss: 10.35348892211914, Uncertainty: 2.7367639541625977
Epoch 102, Batch 1000/3125, Loss: 1.1070491075515747, Uncertainty: 1.3067617416381836

Training and Validation Results of Epoch 352:
================================
Training Loss: 8.651943960666657, Training Uncertainty: 5.772291218757629, time: 8.812559843063354
Validation Loss: 10.293793687820434, Validation Uncertainty: 9.401088544845582, time: 3.5969951152801514
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 353, Batch 100/1000, Loss: 8.366449356079102, Uncertainty: 7.407005786895752
Epoch 353, Batch 200/1000, Loss: 9.72571849822998, Uncertainty: 6.96830415725708
Epoch 353, Batch 300/1000, Loss: 13.164878845214844, Uncertainty: 5.439610481262207
Epoch 2, Batch 1800/3125, Loss: 10.862159729003906, Uncertainty: 2.246924877166748
Epoch 353, Batch 400/1000, Loss: 7.7386322021484375, Uncertainty: 6.992429256439209
Epoch 353, Batch 500/1000, Loss: 8.274198532104492, Uncertainty: 5.503288269042969
Epoch 353, Batch 600/1000, Loss: 7.825841903686523, Uncertainty: 3.6339335441589355
Epoch 353, Batch 700/1000, Loss: 10.192895889282227, Uncertainty: 7.092520236968994
Epoch 102, Batch 1100/3125, Loss: 1.2232885360717773, Uncertainty: 1.4635038375854492
Epoch 353, Batch 800/1000, Loss: 7.306499004364014, Uncertainty: 5.637258529663086
Epoch 353, Batch 900/1000, Loss: 10.498802185058594, Uncertainty: 8.114358901977539
Epoch 353, Batch 1000/1000, Loss: 9.090141296386719, Uncertainty: 5.97861385345459
Epoch 2, Batch 1900/3125, Loss: 11.269956588745117, Uncertainty: 1.9866349697113037

Training and Validation Results of Epoch 353:
================================
Training Loss: 8.650410195112228, Training Uncertainty: 5.77171890592575, time: 8.904462337493896
Validation Loss: 10.294269486427307, Validation Uncertainty: 9.404027578353881, time: 1.1220016479492188
Number of predictions within uncertainty interval: 555/2000 (27.75%)

Epoch 354, Batch 100/1000, Loss: 8.361412048339844, Uncertainty: 7.4053192138671875
Epoch 354, Batch 200/1000, Loss: 9.707303047180176, Uncertainty: 6.976946830749512
Epoch 354, Batch 300/1000, Loss: 13.177854537963867, Uncertainty: 5.433743000030518
Epoch 102, Batch 1200/3125, Loss: 1.3082263469696045, Uncertainty: 1.6600830554962158
Epoch 354, Batch 400/1000, Loss: 7.739548206329346, Uncertainty: 7.011241912841797
Epoch 354, Batch 500/1000, Loss: 8.28254508972168, Uncertainty: 5.533830642700195
Epoch 2, Batch 2000/3125, Loss: 10.456287384033203, Uncertainty: 2.3781075477600098
Epoch 354, Batch 600/1000, Loss: 7.82983922958374, Uncertainty: 3.6453189849853516
Epoch 354, Batch 700/1000, Loss: 10.181171417236328, Uncertainty: 7.09580135345459
Epoch 354, Batch 800/1000, Loss: 7.272116661071777, Uncertainty: 5.66207218170166
Epoch 354, Batch 900/1000, Loss: 10.49420166015625, Uncertainty: 8.061056137084961
Epoch 354, Batch 1000/1000, Loss: 9.09264850616455, Uncertainty: 5.995268821716309
Epoch 102, Batch 1300/3125, Loss: 1.187129259109497, Uncertainty: 1.3537118434906006

Training and Validation Results of Epoch 354:
================================
Training Loss: 8.648794031620026, Training Uncertainty: 5.772693861722946, time: 8.750725030899048
Validation Loss: 10.294381870269776, Validation Uncertainty: 9.406217407226562, time: 1.1165645122528076
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 355, Batch 100/1000, Loss: 8.373308181762695, Uncertainty: 7.371908187866211
Epoch 2, Batch 2100/3125, Loss: 10.336920738220215, Uncertainty: 2.324984073638916
Epoch 355, Batch 200/1000, Loss: 9.708944320678711, Uncertainty: 7.008920669555664
Epoch 355, Batch 300/1000, Loss: 13.174749374389648, Uncertainty: 5.418473243713379
Epoch 355, Batch 400/1000, Loss: 7.758444786071777, Uncertainty: 7.011361122131348
Epoch 355, Batch 500/1000, Loss: 8.288309097290039, Uncertainty: 5.502630233764648
Epoch 355, Batch 600/1000, Loss: 7.832157135009766, Uncertainty: 3.6266353130340576
Epoch 102, Batch 1400/3125, Loss: 1.1836130619049072, Uncertainty: 1.553504228591919
Epoch 355, Batch 700/1000, Loss: 10.197044372558594, Uncertainty: 7.148556709289551
Epoch 355, Batch 800/1000, Loss: 7.277613162994385, Uncertainty: 5.675394058227539
Epoch 355, Batch 900/1000, Loss: 10.488065719604492, Uncertainty: 8.048073768615723
Epoch 2, Batch 2200/3125, Loss: 10.403337478637695, Uncertainty: 3.717888832092285
Epoch 355, Batch 1000/1000, Loss: 9.080267906188965, Uncertainty: 5.972220420837402

Training and Validation Results of Epoch 355:
================================
Training Loss: 8.647119446754456, Training Uncertainty: 5.774037760615349, time: 8.812675714492798
Validation Loss: 10.294409633636475, Validation Uncertainty: 9.410253461837769, time: 1.1182985305786133
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 356, Batch 100/1000, Loss: 8.363896369934082, Uncertainty: 7.395407676696777
Epoch 356, Batch 200/1000, Loss: 9.698674201965332, Uncertainty: 6.967018127441406
Epoch 102, Batch 1500/3125, Loss: 1.3911325931549072, Uncertainty: 1.5518732070922852
Epoch 356, Batch 300/1000, Loss: 13.173257827758789, Uncertainty: 5.423953533172607
Epoch 356, Batch 400/1000, Loss: 7.7196197509765625, Uncertainty: 6.975713729858398
Epoch 2, Batch 2300/3125, Loss: 10.012414932250977, Uncertainty: 3.202922821044922
Epoch 356, Batch 500/1000, Loss: 8.279115676879883, Uncertainty: 5.505794525146484
Epoch 356, Batch 600/1000, Loss: 7.813037872314453, Uncertainty: 3.640580654144287
Epoch 356, Batch 700/1000, Loss: 10.18939208984375, Uncertainty: 7.152858734130859
Epoch 356, Batch 800/1000, Loss: 7.281171798706055, Uncertainty: 5.65227746963501
Epoch 356, Batch 900/1000, Loss: 10.475726127624512, Uncertainty: 8.130970001220703
Epoch 356, Batch 1000/1000, Loss: 9.080739974975586, Uncertainty: 5.963765621185303
Epoch 102, Batch 1600/3125, Loss: 1.053189754486084, Uncertainty: 1.2907764911651611

Training and Validation Results of Epoch 356:
================================
Training Loss: 8.644748370885848, Training Uncertainty: 5.774949687480927, time: 8.786415815353394
Validation Loss: 10.293872620582581, Validation Uncertainty: 9.406572666168213, time: 1.1037986278533936
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 2, Batch 2400/3125, Loss: 11.137367248535156, Uncertainty: 2.5744926929473877
Epoch 357, Batch 100/1000, Loss: 8.353372573852539, Uncertainty: 7.361955642700195
Epoch 357, Batch 200/1000, Loss: 9.700700759887695, Uncertainty: 6.993080139160156
Epoch 357, Batch 300/1000, Loss: 13.16864013671875, Uncertainty: 5.408828258514404
Epoch 357, Batch 400/1000, Loss: 7.740693092346191, Uncertainty: 7.000272274017334
Epoch 357, Batch 500/1000, Loss: 8.274636268615723, Uncertainty: 5.522348403930664
Epoch 357, Batch 600/1000, Loss: 7.811873912811279, Uncertainty: 3.6403684616088867
Epoch 102, Batch 1700/3125, Loss: 1.1608386039733887, Uncertainty: 1.4534345865249634
Epoch 357, Batch 700/1000, Loss: 10.182167053222656, Uncertainty: 7.144937515258789
Epoch 2, Batch 2500/3125, Loss: 11.114055633544922, Uncertainty: 2.721757650375366
Epoch 357, Batch 800/1000, Loss: 7.269869327545166, Uncertainty: 5.65502405166626
Epoch 357, Batch 900/1000, Loss: 10.484166145324707, Uncertainty: 8.110836029052734
Epoch 357, Batch 1000/1000, Loss: 9.083934783935547, Uncertainty: 5.98591423034668

Training and Validation Results of Epoch 357:
================================
Training Loss: 8.643785629749297, Training Uncertainty: 5.774043906927108, time: 8.913919687271118
Validation Loss: 10.293871748924255, Validation Uncertainty: 9.411751426696778, time: 1.138288974761963
Number of predictions within uncertainty interval: 557/2000 (27.85%)

Epoch 358, Batch 100/1000, Loss: 8.372090339660645, Uncertainty: 7.39300537109375
Epoch 358, Batch 200/1000, Loss: 9.68572998046875, Uncertainty: 6.948742389678955
Epoch 102, Batch 1800/3125, Loss: 1.3801261186599731, Uncertainty: 1.793678879737854
Epoch 2, Batch 2600/3125, Loss: 11.018061637878418, Uncertainty: 2.6276893615722656
Epoch 358, Batch 300/1000, Loss: 13.176432609558105, Uncertainty: 5.426476955413818
Epoch 358, Batch 400/1000, Loss: 7.740689277648926, Uncertainty: 7.0014848709106445
Epoch 358, Batch 500/1000, Loss: 8.287487983703613, Uncertainty: 5.536287307739258
Epoch 358, Batch 600/1000, Loss: 7.817689418792725, Uncertainty: 3.6609458923339844
Epoch 358, Batch 700/1000, Loss: 10.1834135055542, Uncertainty: 7.18742561340332
Epoch 358, Batch 800/1000, Loss: 7.276152610778809, Uncertainty: 5.670703887939453
Epoch 358, Batch 900/1000, Loss: 10.472639083862305, Uncertainty: 8.107641220092773
Epoch 358, Batch 1000/1000, Loss: 9.087776184082031, Uncertainty: 5.995963096618652
Epoch 2, Batch 2700/3125, Loss: 10.451419830322266, Uncertainty: 2.7177743911743164
Epoch 102, Batch 1900/3125, Loss: 1.0895276069641113, Uncertainty: 1.4174911975860596

Training and Validation Results of Epoch 358:
================================
Training Loss: 8.642054208040237, Training Uncertainty: 5.775840325593949, time: 8.891140222549438
Validation Loss: 10.29322303199768, Validation Uncertainty: 9.415528970718384, time: 1.0950310230255127
Number of predictions within uncertainty interval: 557/2000 (27.85%)

Epoch 359, Batch 100/1000, Loss: 8.359567642211914, Uncertainty: 7.355555057525635
Epoch 359, Batch 200/1000, Loss: 9.6950044631958, Uncertainty: 7.006007671356201
Epoch 359, Batch 300/1000, Loss: 13.17067813873291, Uncertainty: 5.435110569000244
Epoch 359, Batch 400/1000, Loss: 7.731812953948975, Uncertainty: 6.983968734741211
Epoch 359, Batch 500/1000, Loss: 8.279096603393555, Uncertainty: 5.514665126800537
Epoch 359, Batch 600/1000, Loss: 7.805165767669678, Uncertainty: 3.6570205688476562
Epoch 2, Batch 2800/3125, Loss: 11.012590408325195, Uncertainty: 3.736271619796753
Epoch 102, Batch 2000/3125, Loss: 1.2663915157318115, Uncertainty: 1.5613646507263184
Epoch 359, Batch 700/1000, Loss: 10.216043472290039, Uncertainty: 7.175100803375244
Epoch 359, Batch 800/1000, Loss: 7.273682594299316, Uncertainty: 5.6985182762146
Epoch 359, Batch 900/1000, Loss: 10.460527420043945, Uncertainty: 8.073877334594727
Epoch 359, Batch 1000/1000, Loss: 9.077495574951172, Uncertainty: 5.980708122253418
Learning rate changed to: 1.0000000000000002e-06

Training and Validation Results of Epoch 359:
================================
Training Loss: 8.639690981626512, Training Uncertainty: 5.7764139391183855, time: 8.551578044891357
Validation Loss: 10.294182363510131, Validation Uncertainty: 9.419579889297486, time: 1.1026873588562012
Number of predictions within uncertainty interval: 557/2000 (27.85%)

Epoch 360, Batch 100/1000, Loss: 8.34105110168457, Uncertainty: 7.213443279266357
Epoch 360, Batch 200/1000, Loss: 9.709098815917969, Uncertainty: 6.76048469543457
Epoch 2, Batch 2900/3125, Loss: 10.808578491210938, Uncertainty: 3.9133639335632324
Epoch 102, Batch 2100/3125, Loss: 1.451669692993164, Uncertainty: 1.5889668464660645
Epoch 360, Batch 300/1000, Loss: 13.14993667602539, Uncertainty: 5.514492511749268
Epoch 360, Batch 400/1000, Loss: 7.724769115447998, Uncertainty: 6.758523941040039
Epoch 360, Batch 500/1000, Loss: 8.495889663696289, Uncertainty: 5.728355407714844
Epoch 360, Batch 600/1000, Loss: 7.906292915344238, Uncertainty: 3.666476249694824
Epoch 360, Batch 700/1000, Loss: 10.232095718383789, Uncertainty: 6.932000637054443
Epoch 360, Batch 800/1000, Loss: 7.301437854766846, Uncertainty: 5.528102874755859
Epoch 360, Batch 900/1000, Loss: 10.513504028320312, Uncertainty: 7.992727279663086
Epoch 2, Batch 3000/3125, Loss: 10.541000366210938, Uncertainty: 2.4725613594055176
Epoch 360, Batch 1000/1000, Loss: 9.052115440368652, Uncertainty: 5.956158638000488
Epoch 102, Batch 2200/3125, Loss: 1.0127068758010864, Uncertainty: 1.2695181369781494

Training and Validation Results of Epoch 360:
================================
Training Loss: 8.628694494962692, Training Uncertainty: 5.773849673867225, time: 8.712042331695557
Validation Loss: 10.293538257598877, Validation Uncertainty: 9.416065790176392, time: 1.1099286079406738
Number of predictions within uncertainty interval: 559/2000 (27.95%)

Epoch 361, Batch 100/1000, Loss: 8.348766326904297, Uncertainty: 7.254523277282715
Epoch 361, Batch 200/1000, Loss: 9.702180862426758, Uncertainty: 6.84627628326416
Epoch 361, Batch 300/1000, Loss: 13.143268585205078, Uncertainty: 5.484485626220703
Epoch 361, Batch 400/1000, Loss: 7.727967262268066, Uncertainty: 6.756035804748535
Epoch 361, Batch 500/1000, Loss: 8.477937698364258, Uncertainty: 5.691045761108398
Epoch 2, Batch 3100/3125, Loss: 10.967472076416016, Uncertainty: 2.5599265098571777
Epoch 361, Batch 600/1000, Loss: 7.894989013671875, Uncertainty: 3.69340181350708
Epoch 102, Batch 2300/3125, Loss: 1.3456616401672363, Uncertainty: 1.83489990234375
Epoch 361, Batch 700/1000, Loss: 10.241979598999023, Uncertainty: 6.948250770568848
Epoch 361, Batch 800/1000, Loss: 7.296651840209961, Uncertainty: 5.51503849029541
Epoch 361, Batch 900/1000, Loss: 10.525917053222656, Uncertainty: 8.018636703491211
Epoch 361, Batch 1000/1000, Loss: 9.041738510131836, Uncertainty: 5.962960720062256

Training and Validation Results of Epoch 361:
================================
Training Loss: 8.627352163791656, Training Uncertainty: 5.770798416614532, time: 8.943220138549805
Validation Loss: 10.293125487327575, Validation Uncertainty: 9.414410509109498, time: 1.084944725036621
Number of predictions within uncertainty interval: 559/2000 (27.95%)

Epoch 362, Batch 100/1000, Loss: 8.352935791015625, Uncertainty: 7.280941963195801
Epoch 362, Batch 200/1000, Loss: 9.696025848388672, Uncertainty: 6.912232875823975
Epoch 362, Batch 300/1000, Loss: 13.139266967773438, Uncertainty: 5.467217922210693
Epoch 102, Batch 2400/3125, Loss: 1.3541854619979858, Uncertainty: 1.823368787765503
Epoch 362, Batch 400/1000, Loss: 7.729396820068359, Uncertainty: 6.760149955749512
Epoch 362, Batch 500/1000, Loss: 8.466655731201172, Uncertainty: 5.66928243637085
Epoch 362, Batch 600/1000, Loss: 7.888339042663574, Uncertainty: 3.7119321823120117
Epoch 362, Batch 700/1000, Loss: 10.247236251831055, Uncertainty: 6.957195281982422
Epoch 362, Batch 800/1000, Loss: 7.293563365936279, Uncertainty: 5.509971618652344
Epoch 362, Batch 900/1000, Loss: 10.534830093383789, Uncertainty: 8.035323143005371
Epoch 362, Batch 1000/1000, Loss: 9.036632537841797, Uncertainty: 5.969325065612793
Epoch 102, Batch 2500/3125, Loss: 1.1055941581726074, Uncertainty: 1.3834911584854126

Training and Validation Results of Epoch 362:
================================
Training Loss: 8.626675258874894, Training Uncertainty: 5.769019828438759, time: 8.55172085762024
Validation Loss: 10.292928811073303, Validation Uncertainty: 9.413578218460083, time: 1.1139686107635498
Number of predictions within uncertainty interval: 559/2000 (27.95%)

Epoch 363, Batch 100/1000, Loss: 8.356534957885742, Uncertainty: 7.296757698059082
Epoch 363, Batch 200/1000, Loss: 9.687535285949707, Uncertainty: 6.952542304992676
Epoch 363, Batch 300/1000, Loss: 13.13624095916748, Uncertainty: 5.454520225524902
Epoch 363, Batch 400/1000, Loss: 7.729912757873535, Uncertainty: 6.7614922523498535
Epoch 363, Batch 500/1000, Loss: 8.457773208618164, Uncertainty: 5.654250144958496
Epoch 102, Batch 2600/3125, Loss: 1.2154203653335571, Uncertainty: 1.452265739440918
Epoch 363, Batch 600/1000, Loss: 7.88537073135376, Uncertainty: 3.726200580596924
Epoch 363, Batch 700/1000, Loss: 10.250341415405273, Uncertainty: 6.9670515060424805
Epoch 363, Batch 800/1000, Loss: 7.287069797515869, Uncertainty: 5.505441665649414
Epoch 363, Batch 900/1000, Loss: 10.5428466796875, Uncertainty: 8.045438766479492
Epoch 363, Batch 1000/1000, Loss: 9.033024787902832, Uncertainty: 5.975550174713135

Training and Validation Results of Epoch 363:
================================
Training Loss: 8.626279676914216, Training Uncertainty: 5.767844836473465, time: 9.938829183578491
Validation Loss: 10.292759497642518, Validation Uncertainty: 9.412942365646362, time: 1.4194645881652832
Number of predictions within uncertainty interval: 559/2000 (27.95%)

Epoch 364, Batch 100/1000, Loss: 8.359001159667969, Uncertainty: 7.306600093841553
Epoch 102, Batch 2700/3125, Loss: 1.36622953414917, Uncertainty: 1.7827446460723877
Epoch 364, Batch 200/1000, Loss: 9.679097175598145, Uncertainty: 6.986913204193115
Epoch 364, Batch 300/1000, Loss: 13.134631156921387, Uncertainty: 5.444835662841797
Epoch 364, Batch 400/1000, Loss: 7.729369163513184, Uncertainty: 6.763219356536865
Epoch 364, Batch 500/1000, Loss: 8.452127456665039, Uncertainty: 5.6440815925598145
Epoch 364, Batch 600/1000, Loss: 7.882688522338867, Uncertainty: 3.7363739013671875
Epoch 364, Batch 700/1000, Loss: 10.251163482666016, Uncertainty: 6.976347923278809
Epoch 364, Batch 800/1000, Loss: 7.28769588470459, Uncertainty: 5.5043816566467285
Epoch 364, Batch 900/1000, Loss: 10.549640655517578, Uncertainty: 8.04865837097168
Epoch 102, Batch 2800/3125, Loss: 1.1441991329193115, Uncertainty: 1.3768057823181152
Epoch 364, Batch 1000/1000, Loss: 9.030929565429688, Uncertainty: 5.977697372436523

Training and Validation Results of Epoch 364:
================================
Training Loss: 8.625941049098968, Training Uncertainty: 5.76725050508976, time: 8.978210926055908
Validation Loss: 10.292592379570006, Validation Uncertainty: 9.41281780052185, time: 1.1352477073669434
Number of predictions within uncertainty interval: 558/2000 (27.90%)

Epoch 365, Batch 100/1000, Loss: 8.361645698547363, Uncertainty: 7.311890125274658
Epoch 365, Batch 200/1000, Loss: 9.672079086303711, Uncertainty: 7.0115556716918945
Epoch 365, Batch 300/1000, Loss: 13.13357925415039, Uncertainty: 5.441493034362793
Epoch 365, Batch 400/1000, Loss: 7.728282928466797, Uncertainty: 6.763411521911621
Epoch 365, Batch 500/1000, Loss: 8.4476318359375, Uncertainty: 5.635653495788574
Epoch 102, Batch 2900/3125, Loss: 1.2433772087097168, Uncertainty: 1.5904937982559204
Epoch 365, Batch 600/1000, Loss: 7.880481719970703, Uncertainty: 3.743823766708374
Epoch 365, Batch 700/1000, Loss: 10.250896453857422, Uncertainty: 6.984353065490723
Epoch 365, Batch 800/1000, Loss: 7.286545753479004, Uncertainty: 5.507015228271484
Epoch 365, Batch 900/1000, Loss: 10.554342269897461, Uncertainty: 8.052445411682129
Epoch 365, Batch 1000/1000, Loss: 9.02861213684082, Uncertainty: 5.983056545257568

Training and Validation Results of Epoch 2:
================================
Training Loss: 10.979575676269532, Training Uncertainty: 2.585940940513611, time: 194.3910689353943
Validation Loss: 10.79458799752433, Validation Uncertainty: 4.56805107294751, time: 44.17520213127136
Number of predictions within uncertainty interval: 26803/200000 (13.40%)


Training and Validation Results of Epoch 365:
================================
Training Loss: 8.62560945892334, Training Uncertainty: 5.766986568450927, time: 8.935027837753296
Validation Loss: 10.292507070541381, Validation Uncertainty: 9.41269415473938, time: 1.1622052192687988
Number of predictions within uncertainty interval: 557/2000 (27.85%)

Epoch 366, Batch 100/1000, Loss: 8.365882873535156, Uncertainty: 7.315972805023193
Epoch 366, Batch 200/1000, Loss: 9.665548324584961, Uncertainty: 7.030860900878906
Epoch 102, Batch 3000/3125, Loss: 1.3554668426513672, Uncertainty: 1.564375877380371
Epoch 366, Batch 300/1000, Loss: 13.131744384765625, Uncertainty: 5.436201095581055
Epoch 366, Batch 400/1000, Loss: 7.7283525466918945, Uncertainty: 6.76480770111084
Epoch 366, Batch 500/1000, Loss: 8.444000244140625, Uncertainty: 5.6269636154174805
Epoch 3, Batch 100/3125, Loss: 11.328658103942871, Uncertainty: 2.8011550903320312
Epoch 366, Batch 600/1000, Loss: 7.879436016082764, Uncertainty: 3.748290538787842
Epoch 366, Batch 700/1000, Loss: 10.251132011413574, Uncertainty: 6.985142230987549
Epoch 366, Batch 800/1000, Loss: 7.285402774810791, Uncertainty: 5.512686252593994
Epoch 366, Batch 900/1000, Loss: 10.556175231933594, Uncertainty: 8.055438995361328
Epoch 102, Batch 3100/3125, Loss: 1.169097900390625, Uncertainty: 1.3761249780654907
Epoch 366, Batch 1000/1000, Loss: 9.0277099609375, Uncertainty: 5.988924980163574

Training and Validation Results of Epoch 366:
================================
Training Loss: 8.625253310918808, Training Uncertainty: 5.766936568140983, time: 8.781899690628052
Validation Loss: 10.292533839225769, Validation Uncertainty: 9.413111589431763, time: 1.1422929763793945
Number of predictions within uncertainty interval: 556/2000 (27.80%)

Epoch 367, Batch 100/1000, Loss: 8.367626190185547, Uncertainty: 7.321804523468018
Epoch 3, Batch 200/3125, Loss: 9.391331672668457, Uncertainty: 3.273634910583496
Epoch 367, Batch 200/1000, Loss: 9.660270690917969, Uncertainty: 7.0430006980896
Epoch 367, Batch 300/1000, Loss: 13.129860877990723, Uncertainty: 5.433172225952148
Epoch 367, Batch 400/1000, Loss: 7.728764057159424, Uncertainty: 6.765424728393555
Epoch 367, Batch 500/1000, Loss: 8.441654205322266, Uncertainty: 5.622737407684326
Epoch 367, Batch 600/1000, Loss: 7.878410339355469, Uncertainty: 3.7511515617370605
Epoch 367, Batch 700/1000, Loss: 10.250770568847656, Uncertainty: 6.98702335357666
Epoch 367, Batch 800/1000, Loss: 7.284300804138184, Uncertainty: 5.514423370361328
Epoch 3, Batch 300/3125, Loss: 10.807960510253906, Uncertainty: 2.6920230388641357
Epoch 367, Batch 900/1000, Loss: 10.557840347290039, Uncertainty: 8.0563383102417
Epoch 367, Batch 1000/1000, Loss: 9.024955749511719, Uncertainty: 5.989274024963379

Training and Validation Results of Epoch 367:
================================
Training Loss: 8.624953755617142, Training Uncertainty: 5.766873092651367, time: 8.595974683761597
Validation Loss: 10.292474798202514, Validation Uncertainty: 9.413000486373901, time: 1.1322979927062988
Number of predictions within uncertainty interval: 554/2000 (27.70%)

Epoch 368, Batch 100/1000, Loss: 8.369876861572266, Uncertainty: 7.3237199783325195
Epoch 368, Batch 200/1000, Loss: 9.657292366027832, Uncertainty: 7.053187370300293
Epoch 368, Batch 300/1000, Loss: 13.127845764160156, Uncertainty: 5.4286346435546875
Epoch 368, Batch 400/1000, Loss: 7.729842185974121, Uncertainty: 6.770852565765381
Epoch 3, Batch 400/3125, Loss: 10.130892753601074, Uncertainty: 3.0750651359558105
Epoch 368, Batch 500/1000, Loss: 8.438234329223633, Uncertainty: 5.620787620544434
Epoch 368, Batch 600/1000, Loss: 7.877913951873779, Uncertainty: 3.754831314086914
Epoch 368, Batch 700/1000, Loss: 10.251659393310547, Uncertainty: 6.988980293273926
Epoch 368, Batch 800/1000, Loss: 7.283060550689697, Uncertainty: 5.517807960510254
Epoch 368, Batch 900/1000, Loss: 10.55960750579834, Uncertainty: 8.057329177856445
Epoch 368, Batch 1000/1000, Loss: 9.022649765014648, Uncertainty: 5.990609169006348

Training and Validation Results of Epoch 368:
================================
Training Loss: 8.624619288682938, Training Uncertainty: 5.767052879095077, time: 9.0458242893219
Validation Loss: 10.292473608016968, Validation Uncertainty: 9.41324927330017, time: 1.111396074295044
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 3, Batch 500/3125, Loss: 10.4273099899292, Uncertainty: 3.6073789596557617
Epoch 369, Batch 100/1000, Loss: 8.371139526367188, Uncertainty: 7.327975749969482
Epoch 369, Batch 200/1000, Loss: 9.655599594116211, Uncertainty: 7.066610336303711
Epoch 369, Batch 300/1000, Loss: 13.128497123718262, Uncertainty: 5.430750370025635
Epoch 369, Batch 400/1000, Loss: 7.729092597961426, Uncertainty: 6.774115085601807
Epoch 369, Batch 500/1000, Loss: 8.435739517211914, Uncertainty: 5.619174957275391
Epoch 369, Batch 600/1000, Loss: 7.8777756690979, Uncertainty: 3.7559075355529785
Epoch 369, Batch 700/1000, Loss: 10.251338005065918, Uncertainty: 6.991591453552246
Epoch 3, Batch 600/3125, Loss: 11.663973808288574, Uncertainty: 3.361722469329834
Epoch 369, Batch 800/1000, Loss: 7.282034873962402, Uncertainty: 5.521186828613281
Epoch 369, Batch 900/1000, Loss: 10.56014633178711, Uncertainty: 8.059410095214844
Epoch 369, Batch 1000/1000, Loss: 9.023038864135742, Uncertainty: 5.991738796234131

Training and Validation Results of Epoch 369:
================================
Training Loss: 8.624348051548004, Training Uncertainty: 5.767055733680725, time: 8.506556987762451
Validation Loss: 10.292544487953187, Validation Uncertainty: 9.413347864151001, time: 1.0807933807373047
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 370, Batch 100/1000, Loss: 8.37370777130127, Uncertainty: 7.3239054679870605
Epoch 370, Batch 200/1000, Loss: 9.65329360961914, Uncertainty: 7.071852684020996
Epoch 370, Batch 300/1000, Loss: 13.127692222595215, Uncertainty: 5.4308624267578125
Epoch 3, Batch 700/3125, Loss: 10.549205780029297, Uncertainty: 2.5519118309020996
Epoch 370, Batch 400/1000, Loss: 7.730557441711426, Uncertainty: 6.77810001373291
Epoch 370, Batch 500/1000, Loss: 8.434258460998535, Uncertainty: 5.619029998779297
Epoch 370, Batch 600/1000, Loss: 7.87713623046875, Uncertainty: 3.7575347423553467
Epoch 370, Batch 700/1000, Loss: 10.250144004821777, Uncertainty: 6.990124702453613
Epoch 370, Batch 800/1000, Loss: 7.279961585998535, Uncertainty: 5.5232672691345215
Epoch 370, Batch 900/1000, Loss: 10.562176704406738, Uncertainty: 8.057060241699219
Epoch 370, Batch 1000/1000, Loss: 9.021265983581543, Uncertainty: 5.991361618041992
Epoch 3, Batch 800/3125, Loss: 9.724267959594727, Uncertainty: 4.475494384765625

Training and Validation Results of Epoch 370:
================================
Training Loss: 8.624054449558258, Training Uncertainty: 5.767328744292259, time: 8.55981183052063
Validation Loss: 10.292537608146667, Validation Uncertainty: 9.413456546783447, time: 1.14963698387146
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 371, Batch 100/1000, Loss: 8.374635696411133, Uncertainty: 7.325102806091309
Epoch 371, Batch 200/1000, Loss: 9.651798248291016, Uncertainty: 7.078983783721924
Epoch 371, Batch 300/1000, Loss: 13.12607192993164, Uncertainty: 5.430137634277344
Epoch 371, Batch 400/1000, Loss: 7.728913307189941, Uncertainty: 6.7789106369018555
Epoch 371, Batch 500/1000, Loss: 8.433120727539062, Uncertainty: 5.618426322937012
Epoch 371, Batch 600/1000, Loss: 7.876013278961182, Uncertainty: 3.759108066558838
Epoch 3, Batch 900/3125, Loss: 10.35389518737793, Uncertainty: 2.753164768218994
Epoch 371, Batch 700/1000, Loss: 10.250547409057617, Uncertainty: 6.99504280090332
Epoch 371, Batch 800/1000, Loss: 7.278731822967529, Uncertainty: 5.527364730834961
Epoch 371, Batch 900/1000, Loss: 10.562207221984863, Uncertainty: 8.058692932128906

Training and Validation Results of Epoch 102:
================================
Training Loss: 1.01422826669693, Training Uncertainty: 1.5399945959091186, time: 209.02003741264343
Validation Loss: 0.8949272367350586, Validation Uncertainty: 2.184787628443345, time: 47.05579233169556
Number of predictions within uncertainty interval: 124643/200000 (62.32%)

Epoch 371, Batch 1000/1000, Loss: 9.022150039672852, Uncertainty: 5.996020793914795

Training and Validation Results of Epoch 371:
================================
Training Loss: 8.623875569820404, Training Uncertainty: 5.767277761459351, time: 8.696954250335693
Validation Loss: 10.292508623123169, Validation Uncertainty: 9.413469123840333, time: 1.0889222621917725
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 372, Batch 100/1000, Loss: 8.3744535446167, Uncertainty: 7.324070930480957
Epoch 372, Batch 200/1000, Loss: 9.649540901184082, Uncertainty: 7.084568500518799
Epoch 3, Batch 1000/3125, Loss: 10.187843322753906, Uncertainty: 2.904334783554077
Epoch 372, Batch 300/1000, Loss: 13.124848365783691, Uncertainty: 5.43151330947876
Epoch 372, Batch 400/1000, Loss: 7.730218887329102, Uncertainty: 6.782541275024414
Epoch 372, Batch 500/1000, Loss: 8.431827545166016, Uncertainty: 5.620081424713135
Epoch 103, Batch 100/3125, Loss: 1.0731960535049438, Uncertainty: 1.339005708694458
Epoch 372, Batch 600/1000, Loss: 7.87484073638916, Uncertainty: 3.760796546936035
Epoch 372, Batch 700/1000, Loss: 10.249519348144531, Uncertainty: 6.9931640625
Epoch 372, Batch 800/1000, Loss: 7.2761664390563965, Uncertainty: 5.529733657836914
Epoch 3, Batch 1100/3125, Loss: 11.464115142822266, Uncertainty: 3.9828481674194336
Epoch 372, Batch 900/1000, Loss: 10.56277847290039, Uncertainty: 8.056391716003418
Epoch 372, Batch 1000/1000, Loss: 9.020488739013672, Uncertainty: 5.995882987976074

Training and Validation Results of Epoch 372:
================================
Training Loss: 8.623602768659591, Training Uncertainty: 5.7674743512868885, time: 8.889243841171265
Validation Loss: 10.29243495464325, Validation Uncertainty: 9.413545837402344, time: 1.106989860534668
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 373, Batch 100/1000, Loss: 8.373806953430176, Uncertainty: 7.326712608337402
Epoch 103, Batch 200/3125, Loss: 1.238901972770691, Uncertainty: 1.5395944118499756
Epoch 373, Batch 200/1000, Loss: 9.64855670928955, Uncertainty: 7.0948381423950195
Epoch 373, Batch 300/1000, Loss: 13.124734878540039, Uncertainty: 5.433206558227539
Epoch 373, Batch 400/1000, Loss: 7.729169845581055, Uncertainty: 6.784663200378418
Epoch 3, Batch 1200/3125, Loss: 10.223539352416992, Uncertainty: 3.247851848602295
Epoch 373, Batch 500/1000, Loss: 8.430513381958008, Uncertainty: 5.618757247924805
Epoch 373, Batch 600/1000, Loss: 7.875671863555908, Uncertainty: 3.764434337615967
Epoch 373, Batch 700/1000, Loss: 10.250380516052246, Uncertainty: 6.995404243469238
Epoch 373, Batch 800/1000, Loss: 7.275213241577148, Uncertainty: 5.526154518127441
Epoch 103, Batch 300/3125, Loss: 1.3233076333999634, Uncertainty: 1.4293464422225952
Epoch 373, Batch 900/1000, Loss: 10.563928604125977, Uncertainty: 8.057117462158203
Epoch 373, Batch 1000/1000, Loss: 9.02012825012207, Uncertainty: 5.997093200683594

Training and Validation Results of Epoch 373:
================================
Training Loss: 8.623364313602448, Training Uncertainty: 5.767628229498863, time: 8.863799810409546
Validation Loss: 10.292391724586487, Validation Uncertainty: 9.413438468933105, time: 1.1079540252685547
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 3, Batch 1300/3125, Loss: 10.217838287353516, Uncertainty: 3.249748468399048
Epoch 374, Batch 100/1000, Loss: 8.3748779296875, Uncertainty: 7.323230743408203
Epoch 374, Batch 200/1000, Loss: 9.647418975830078, Uncertainty: 7.101611137390137
Epoch 374, Batch 300/1000, Loss: 13.124015808105469, Uncertainty: 5.4350457191467285
Epoch 374, Batch 400/1000, Loss: 7.729009628295898, Uncertainty: 6.787347793579102
Epoch 103, Batch 400/3125, Loss: 1.100383996963501, Uncertainty: 1.4128193855285645
Epoch 374, Batch 500/1000, Loss: 8.429483413696289, Uncertainty: 5.617465972900391
Epoch 374, Batch 600/1000, Loss: 7.87568473815918, Uncertainty: 3.7625160217285156
Epoch 374, Batch 700/1000, Loss: 10.249135971069336, Uncertainty: 6.99135684967041
Epoch 3, Batch 1400/3125, Loss: 10.62308120727539, Uncertainty: 3.229072332382202
Epoch 374, Batch 800/1000, Loss: 7.273478984832764, Uncertainty: 5.530837535858154
Epoch 374, Batch 900/1000, Loss: 10.56119441986084, Uncertainty: 8.05396556854248
Epoch 374, Batch 1000/1000, Loss: 9.019516944885254, Uncertainty: 5.998658657073975

Training and Validation Results of Epoch 374:
================================
Training Loss: 8.623119644880294, Training Uncertainty: 5.767654438734055, time: 8.471323251724243
Validation Loss: 10.292344958305359, Validation Uncertainty: 9.414029897689819, time: 1.1238462924957275
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 375, Batch 100/1000, Loss: 8.374605178833008, Uncertainty: 7.327247619628906
Epoch 103, Batch 500/3125, Loss: 1.217266321182251, Uncertainty: 1.5467478036880493
Epoch 375, Batch 200/1000, Loss: 9.646949768066406, Uncertainty: 7.106781959533691
Epoch 375, Batch 300/1000, Loss: 13.123863220214844, Uncertainty: 5.438136577606201
Epoch 3, Batch 1500/3125, Loss: 11.18759536743164, Uncertainty: 2.202249526977539
Epoch 375, Batch 400/1000, Loss: 7.7283148765563965, Uncertainty: 6.791826248168945
Epoch 375, Batch 500/1000, Loss: 8.427574157714844, Uncertainty: 5.617856979370117
Epoch 375, Batch 600/1000, Loss: 7.875984191894531, Uncertainty: 3.76564884185791
Epoch 375, Batch 700/1000, Loss: 10.249395370483398, Uncertainty: 6.993038654327393
Epoch 375, Batch 800/1000, Loss: 7.271612167358398, Uncertainty: 5.532422065734863
Epoch 103, Batch 600/3125, Loss: 1.4086253643035889, Uncertainty: 1.5887858867645264
Epoch 375, Batch 900/1000, Loss: 10.562702178955078, Uncertainty: 8.056971549987793
Epoch 375, Batch 1000/1000, Loss: 9.01888656616211, Uncertainty: 6.000832557678223
Epoch 3, Batch 1600/3125, Loss: 10.750171661376953, Uncertainty: 2.6041293144226074

Training and Validation Results of Epoch 375:
================================
Training Loss: 8.622907108545304, Training Uncertainty: 5.767883651256561, time: 8.800976753234863
Validation Loss: 10.292359977722167, Validation Uncertainty: 9.414322324752808, time: 1.1357002258300781
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 376, Batch 100/1000, Loss: 8.37442684173584, Uncertainty: 7.325198173522949
Epoch 376, Batch 200/1000, Loss: 9.646427154541016, Uncertainty: 7.113649368286133
Epoch 376, Batch 300/1000, Loss: 13.122413635253906, Uncertainty: 5.437597274780273
Epoch 376, Batch 400/1000, Loss: 7.729143142700195, Uncertainty: 6.795165061950684
Epoch 103, Batch 700/3125, Loss: 1.2149351835250854, Uncertainty: 1.5097813606262207
Epoch 376, Batch 500/1000, Loss: 8.42596435546875, Uncertainty: 5.619525909423828
Epoch 376, Batch 600/1000, Loss: 7.874736785888672, Uncertainty: 3.76794171333313
Epoch 3, Batch 1700/3125, Loss: 10.296730995178223, Uncertainty: 3.396963357925415
Epoch 376, Batch 700/1000, Loss: 10.24852180480957, Uncertainty: 6.992855072021484
Epoch 376, Batch 800/1000, Loss: 7.27087926864624, Uncertainty: 5.534377098083496
Epoch 376, Batch 900/1000, Loss: 10.560182571411133, Uncertainty: 8.054092407226562
Epoch 376, Batch 1000/1000, Loss: 9.018157958984375, Uncertainty: 6.0014495849609375

Training and Validation Results of Epoch 376:
================================
Training Loss: 8.622622113227845, Training Uncertainty: 5.768141867518425, time: 8.763079404830933
Validation Loss: 10.292360324859619, Validation Uncertainty: 9.414822170257569, time: 1.084895372390747
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 103, Batch 800/3125, Loss: 1.3629539012908936, Uncertainty: 1.539658546447754
Epoch 377, Batch 100/1000, Loss: 8.373971939086914, Uncertainty: 7.32726526260376
Epoch 377, Batch 200/1000, Loss: 9.645767211914062, Uncertainty: 7.115114688873291
Epoch 3, Batch 1800/3125, Loss: 10.37755298614502, Uncertainty: 2.8069229125976562
Epoch 377, Batch 300/1000, Loss: 13.122171401977539, Uncertainty: 5.4392781257629395
Epoch 377, Batch 400/1000, Loss: 7.72845458984375, Uncertainty: 6.798172950744629
Epoch 377, Batch 500/1000, Loss: 8.425806045532227, Uncertainty: 5.622237682342529
Epoch 377, Batch 600/1000, Loss: 7.873476982116699, Uncertainty: 3.7676589488983154
Epoch 377, Batch 700/1000, Loss: 10.248120307922363, Uncertainty: 6.991124629974365
Epoch 377, Batch 800/1000, Loss: 7.268001556396484, Uncertainty: 5.535992622375488
Epoch 103, Batch 900/3125, Loss: 1.4001471996307373, Uncertainty: 1.5922510623931885
Epoch 377, Batch 900/1000, Loss: 10.559892654418945, Uncertainty: 8.05578899383545
Epoch 3, Batch 1900/3125, Loss: 11.06749153137207, Uncertainty: 2.671335458755493
Epoch 377, Batch 1000/1000, Loss: 9.019367218017578, Uncertainty: 6.002494812011719

Training and Validation Results of Epoch 377:
================================
Training Loss: 8.622381631851196, Training Uncertainty: 5.768351481676102, time: 8.692622184753418
Validation Loss: 10.292391898155213, Validation Uncertainty: 9.41545323562622, time: 1.099388837814331
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 378, Batch 100/1000, Loss: 8.373963356018066, Uncertainty: 7.326257705688477
Epoch 378, Batch 200/1000, Loss: 9.643959999084473, Uncertainty: 7.118137359619141
Epoch 378, Batch 300/1000, Loss: 13.121877670288086, Uncertainty: 5.440720558166504
Epoch 378, Batch 400/1000, Loss: 7.727735996246338, Uncertainty: 6.798727512359619
Epoch 103, Batch 1000/3125, Loss: 1.1132136583328247, Uncertainty: 1.3803327083587646
Epoch 378, Batch 500/1000, Loss: 8.425073623657227, Uncertainty: 5.622952461242676
Epoch 3, Batch 2000/3125, Loss: 10.396598815917969, Uncertainty: 2.603644609451294
Epoch 378, Batch 600/1000, Loss: 7.873340129852295, Uncertainty: 3.768357753753662
Epoch 378, Batch 700/1000, Loss: 10.247404098510742, Uncertainty: 6.9956955909729
Epoch 378, Batch 800/1000, Loss: 7.268918991088867, Uncertainty: 5.535068035125732
Epoch 378, Batch 900/1000, Loss: 10.55904769897461, Uncertainty: 8.056544303894043
Epoch 378, Batch 1000/1000, Loss: 9.017969131469727, Uncertainty: 6.000855922698975

Training and Validation Results of Epoch 378:
================================
Training Loss: 8.62214266204834, Training Uncertainty: 5.768707721948624, time: 8.720114946365356
Validation Loss: 10.292345369338989, Validation Uncertainty: 9.415541137695312, time: 1.1147546768188477
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 103, Batch 1100/3125, Loss: 1.176941156387329, Uncertainty: 1.4582635164260864
Epoch 3, Batch 2100/3125, Loss: 10.0438814163208, Uncertainty: 2.876469612121582
Epoch 379, Batch 100/1000, Loss: 8.371814727783203, Uncertainty: 7.327689170837402
Epoch 379, Batch 200/1000, Loss: 9.644266128540039, Uncertainty: 7.123774528503418
Epoch 379, Batch 300/1000, Loss: 13.122406005859375, Uncertainty: 5.442404747009277
Epoch 379, Batch 400/1000, Loss: 7.7287068367004395, Uncertainty: 6.802004337310791
Epoch 379, Batch 500/1000, Loss: 8.42557144165039, Uncertainty: 5.6249799728393555
Epoch 379, Batch 600/1000, Loss: 7.872178077697754, Uncertainty: 3.771322727203369
Epoch 379, Batch 700/1000, Loss: 10.247385025024414, Uncertainty: 6.989466190338135
Epoch 379, Batch 800/1000, Loss: 7.266718864440918, Uncertainty: 5.53697395324707
Epoch 3, Batch 2200/3125, Loss: 9.917257308959961, Uncertainty: 3.5078659057617188
Epoch 103, Batch 1200/3125, Loss: 1.3275656700134277, Uncertainty: 1.7316288948059082
Epoch 379, Batch 900/1000, Loss: 10.558511734008789, Uncertainty: 8.05605411529541
Epoch 379, Batch 1000/1000, Loss: 9.018363952636719, Uncertainty: 6.002579689025879

Training and Validation Results of Epoch 379:
================================
Training Loss: 8.621921848297118, Training Uncertainty: 5.768790979027748, time: 8.470418930053711
Validation Loss: 10.292319630622863, Validation Uncertainty: 9.416185674667359, time: 1.062274694442749
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 380, Batch 100/1000, Loss: 8.371437072753906, Uncertainty: 7.328950881958008
Epoch 380, Batch 200/1000, Loss: 9.6436128616333, Uncertainty: 7.125150680541992
Epoch 380, Batch 300/1000, Loss: 13.121094703674316, Uncertainty: 5.4446539878845215
Epoch 380, Batch 400/1000, Loss: 7.728873252868652, Uncertainty: 6.804142951965332
Epoch 3, Batch 2300/3125, Loss: 9.948819160461426, Uncertainty: 3.241082191467285
Epoch 103, Batch 1300/3125, Loss: 1.1322433948516846, Uncertainty: 1.2732255458831787
Epoch 380, Batch 500/1000, Loss: 8.425880432128906, Uncertainty: 5.623898506164551
Epoch 380, Batch 600/1000, Loss: 7.8713788986206055, Uncertainty: 3.770524501800537
Epoch 380, Batch 700/1000, Loss: 10.247255325317383, Uncertainty: 6.994683265686035
Epoch 380, Batch 800/1000, Loss: 7.267092704772949, Uncertainty: 5.538473129272461
Epoch 380, Batch 900/1000, Loss: 10.55871295928955, Uncertainty: 8.05428695678711
Epoch 380, Batch 1000/1000, Loss: 9.017557144165039, Uncertainty: 6.00291633605957

Training and Validation Results of Epoch 380:
================================
Training Loss: 8.621680854082108, Training Uncertainty: 5.769258855104447, time: 8.528889894485474
Validation Loss: 10.292252058029176, Validation Uncertainty: 9.41635036087036, time: 1.1205437183380127
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 3, Batch 2400/3125, Loss: 10.818710327148438, Uncertainty: 2.932429313659668
Epoch 103, Batch 1400/3125, Loss: 1.2022919654846191, Uncertainty: 1.5728025436401367
Epoch 381, Batch 100/1000, Loss: 8.37198257446289, Uncertainty: 7.325811386108398
Epoch 381, Batch 200/1000, Loss: 9.643253326416016, Uncertainty: 7.13521671295166
Epoch 381, Batch 300/1000, Loss: 13.121164321899414, Uncertainty: 5.446646213531494
Epoch 381, Batch 400/1000, Loss: 7.729787349700928, Uncertainty: 6.803985595703125
Epoch 381, Batch 500/1000, Loss: 8.424732208251953, Uncertainty: 5.625262260437012
Epoch 381, Batch 600/1000, Loss: 7.870141983032227, Uncertainty: 3.7730255126953125
Epoch 381, Batch 700/1000, Loss: 10.247030258178711, Uncertainty: 6.993306636810303
Epoch 3, Batch 2500/3125, Loss: 10.65455436706543, Uncertainty: 2.9563825130462646
Epoch 381, Batch 800/1000, Loss: 7.26515007019043, Uncertainty: 5.539185523986816
Epoch 103, Batch 1500/3125, Loss: 1.3733562231063843, Uncertainty: 1.5099396705627441
Epoch 381, Batch 900/1000, Loss: 10.558300018310547, Uncertainty: 8.055549621582031
Epoch 381, Batch 1000/1000, Loss: 9.017964363098145, Uncertainty: 6.000862121582031

Training and Validation Results of Epoch 381:
================================
Training Loss: 8.621477324724198, Training Uncertainty: 5.76927687215805, time: 8.97870683670044
Validation Loss: 10.292226809501647, Validation Uncertainty: 9.416828149795533, time: 1.1274044513702393
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 382, Batch 100/1000, Loss: 8.371092796325684, Uncertainty: 7.329319477081299
Epoch 382, Batch 200/1000, Loss: 9.642224311828613, Uncertainty: 7.133413314819336
Epoch 3, Batch 2600/3125, Loss: 10.796982765197754, Uncertainty: 3.0367519855499268
Epoch 382, Batch 300/1000, Loss: 13.121011734008789, Uncertainty: 5.446375846862793
Epoch 382, Batch 400/1000, Loss: 7.729515552520752, Uncertainty: 6.805384159088135
Epoch 103, Batch 1600/3125, Loss: 1.0438306331634521, Uncertainty: 1.2912518978118896
Epoch 382, Batch 500/1000, Loss: 8.424490928649902, Uncertainty: 5.624614715576172
Epoch 382, Batch 600/1000, Loss: 7.8711066246032715, Uncertainty: 3.77494215965271
Epoch 382, Batch 700/1000, Loss: 10.247239112854004, Uncertainty: 6.990515232086182
Epoch 382, Batch 800/1000, Loss: 7.264327049255371, Uncertainty: 5.541473865509033
Epoch 382, Batch 900/1000, Loss: 10.55661392211914, Uncertainty: 8.054850578308105
Epoch 382, Batch 1000/1000, Loss: 9.017841339111328, Uncertainty: 6.003166198730469
Epoch 3, Batch 2700/3125, Loss: 9.842864990234375, Uncertainty: 2.796827793121338
Learning rate changed to: 1.0000000000000002e-07

Training and Validation Results of Epoch 382:
================================
Training Loss: 8.621282687664031, Training Uncertainty: 5.769351956248284, time: 8.714841604232788
Validation Loss: 10.292214651107788, Validation Uncertainty: 9.41735340309143, time: 1.102985143661499
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 103, Batch 1700/3125, Loss: 1.2307512760162354, Uncertainty: 1.6427497863769531
Epoch 383, Batch 100/1000, Loss: 8.36877155303955, Uncertainty: 7.31459379196167
Epoch 383, Batch 200/1000, Loss: 9.640982627868652, Uncertainty: 7.1249847412109375
Epoch 383, Batch 300/1000, Loss: 13.115795135498047, Uncertainty: 5.440499782562256
Epoch 383, Batch 400/1000, Loss: 7.729604721069336, Uncertainty: 6.771022796630859
Epoch 383, Batch 500/1000, Loss: 8.443025588989258, Uncertainty: 5.643467903137207
Epoch 383, Batch 600/1000, Loss: 7.8724365234375, Uncertainty: 3.7551791667938232
Epoch 3, Batch 2800/3125, Loss: 10.797430038452148, Uncertainty: 3.824493885040283
Epoch 383, Batch 700/1000, Loss: 10.241870880126953, Uncertainty: 6.957772731781006
Epoch 383, Batch 800/1000, Loss: 7.2706708908081055, Uncertainty: 5.535209655761719
Epoch 103, Batch 1800/3125, Loss: 1.3487639427185059, Uncertainty: 1.7236580848693848
Epoch 383, Batch 900/1000, Loss: 10.556191444396973, Uncertainty: 8.029712677001953
Epoch 383, Batch 1000/1000, Loss: 9.016633987426758, Uncertainty: 6.002349376678467

Training and Validation Results of Epoch 383:
================================
Training Loss: 8.618847393989563, Training Uncertainty: 5.769218161225319, time: 8.572084665298462
Validation Loss: 10.292211090087891, Validation Uncertainty: 9.417428199768066, time: 1.1051805019378662
Number of predictions within uncertainty interval: 553/2000 (27.65%)

Epoch 384, Batch 100/1000, Loss: 8.369010925292969, Uncertainty: 7.315117835998535
Epoch 384, Batch 200/1000, Loss: 9.640681266784668, Uncertainty: 7.12702751159668
Epoch 3, Batch 2900/3125, Loss: 10.555146217346191, Uncertainty: 4.178421974182129
Epoch 384, Batch 300/1000, Loss: 13.115598678588867, Uncertainty: 5.43934965133667
Epoch 384, Batch 400/1000, Loss: 7.73018741607666, Uncertainty: 6.772024154663086
Epoch 103, Batch 1900/3125, Loss: 1.0584056377410889, Uncertainty: 1.4166325330734253
Epoch 384, Batch 500/1000, Loss: 8.442769050598145, Uncertainty: 5.642622947692871
Epoch 384, Batch 600/1000, Loss: 7.872237682342529, Uncertainty: 3.756490707397461
Epoch 384, Batch 700/1000, Loss: 10.242082595825195, Uncertainty: 6.9585981369018555
Epoch 384, Batch 800/1000, Loss: 7.270508766174316, Uncertainty: 5.535007476806641
Epoch 3, Batch 3000/3125, Loss: 10.01605224609375, Uncertainty: 3.822309970855713
Epoch 384, Batch 900/1000, Loss: 10.556888580322266, Uncertainty: 8.030864715576172
Epoch 384, Batch 1000/1000, Loss: 9.01614761352539, Uncertainty: 6.0020551681518555

Training and Validation Results of Epoch 384:
================================
Training Loss: 8.61882608628273, Training Uncertainty: 5.769210852503776, time: 9.005650997161865
Validation Loss: 10.292212063789368, Validation Uncertainty: 9.41747995376587, time: 1.1484479904174805
Number of predictions within uncertainty interval: 552/2000 (27.60%)

Epoch 103, Batch 2000/3125, Loss: 1.2344874143600464, Uncertainty: 1.4343072175979614
Epoch 385, Batch 100/1000, Loss: 8.369392395019531, Uncertainty: 7.315280914306641
Epoch 385, Batch 200/1000, Loss: 9.640308380126953, Uncertainty: 7.128884792327881
Epoch 385, Batch 300/1000, Loss: 13.11536979675293, Uncertainty: 5.438129425048828
Epoch 385, Batch 400/1000, Loss: 7.730843544006348, Uncertainty: 6.772919654846191
Epoch 3, Batch 3100/3125, Loss: 10.557764053344727, Uncertainty: 2.894501209259033
Epoch 385, Batch 500/1000, Loss: 8.442522048950195, Uncertainty: 5.641829967498779
Epoch 385, Batch 600/1000, Loss: 7.872057914733887, Uncertainty: 3.7577922344207764
Epoch 385, Batch 700/1000, Loss: 10.24223804473877, Uncertainty: 6.959151268005371
Epoch 385, Batch 800/1000, Loss: 7.270257949829102, Uncertainty: 5.534947872161865
Epoch 103, Batch 2100/3125, Loss: 1.4296255111694336, Uncertainty: 1.5659849643707275
Epoch 385, Batch 900/1000, Loss: 10.557504653930664, Uncertainty: 8.031952857971191
Epoch 385, Batch 1000/1000, Loss: 9.015613555908203, Uncertainty: 6.001827239990234

Training and Validation Results of Epoch 385:
================================
Training Loss: 8.618805646896362, Training Uncertainty: 5.769208611011505, time: 8.827723026275635
Validation Loss: 10.292214963912963, Validation Uncertainty: 9.417544454574585, time: 1.1291613578796387
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 386, Batch 100/1000, Loss: 8.369680404663086, Uncertainty: 7.315741539001465
Epoch 386, Batch 200/1000, Loss: 9.64004898071289, Uncertainty: 7.13069486618042
Epoch 386, Batch 300/1000, Loss: 13.115196228027344, Uncertainty: 5.437106132507324
Epoch 386, Batch 400/1000, Loss: 7.731414794921875, Uncertainty: 6.773674011230469
Epoch 103, Batch 2200/3125, Loss: 1.0234689712524414, Uncertainty: 1.2706305980682373
Epoch 386, Batch 500/1000, Loss: 8.442370414733887, Uncertainty: 5.640929222106934
Epoch 386, Batch 600/1000, Loss: 7.871818542480469, Uncertainty: 3.7590694427490234
Epoch 386, Batch 700/1000, Loss: 10.242338180541992, Uncertainty: 6.959747791290283
Epoch 386, Batch 800/1000, Loss: 7.2700629234313965, Uncertainty: 5.534795761108398
Epoch 386, Batch 900/1000, Loss: 10.558073043823242, Uncertainty: 8.032936096191406
Epoch 386, Batch 1000/1000, Loss: 9.015203475952148, Uncertainty: 6.001698017120361

Training and Validation Results of Epoch 386:
================================
Training Loss: 8.618779486656189, Training Uncertainty: 5.769227883577347, time: 8.71497106552124
Validation Loss: 10.29221849155426, Validation Uncertainty: 9.417622617721557, time: 1.0975403785705566
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 103, Batch 2300/3125, Loss: 1.2949724197387695, Uncertainty: 1.7054446935653687
Epoch 387, Batch 100/1000, Loss: 8.369994163513184, Uncertainty: 7.315982818603516
Epoch 387, Batch 200/1000, Loss: 9.639719009399414, Uncertainty: 7.132519721984863
Epoch 387, Batch 300/1000, Loss: 13.115058898925781, Uncertainty: 5.436163902282715
Epoch 387, Batch 400/1000, Loss: 7.731912136077881, Uncertainty: 6.774425506591797
Epoch 387, Batch 500/1000, Loss: 8.441995620727539, Uncertainty: 5.640130043029785
Epoch 387, Batch 600/1000, Loss: 7.871640682220459, Uncertainty: 3.760446548461914
Epoch 387, Batch 700/1000, Loss: 10.242437362670898, Uncertainty: 6.960307598114014
Epoch 103, Batch 2400/3125, Loss: 1.2777516841888428, Uncertainty: 1.6089446544647217
Epoch 387, Batch 800/1000, Loss: 7.2697954177856445, Uncertainty: 5.534844398498535
Epoch 387, Batch 900/1000, Loss: 10.558679580688477, Uncertainty: 8.03373908996582
Epoch 387, Batch 1000/1000, Loss: 9.014738082885742, Uncertainty: 6.00146484375

Training and Validation Results of Epoch 387:
================================
Training Loss: 8.61875580406189, Training Uncertainty: 5.7692369830608365, time: 8.568301439285278
Validation Loss: 10.292216745376587, Validation Uncertainty: 9.417691331863404, time: 1.1747097969055176
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 388, Batch 100/1000, Loss: 8.370196342468262, Uncertainty: 7.316457271575928
Epoch 388, Batch 200/1000, Loss: 9.639566421508789, Uncertainty: 7.13432502746582
Epoch 388, Batch 300/1000, Loss: 13.114943504333496, Uncertainty: 5.43527889251709
Epoch 388, Batch 400/1000, Loss: 7.732415199279785, Uncertainty: 6.775233268737793
Epoch 103, Batch 2500/3125, Loss: 1.3121291399002075, Uncertainty: 1.847524881362915
Epoch 388, Batch 500/1000, Loss: 8.44184398651123, Uncertainty: 5.639235496520996
Epoch 388, Batch 600/1000, Loss: 7.871501922607422, Uncertainty: 3.761807918548584
Epoch 388, Batch 700/1000, Loss: 10.24262809753418, Uncertainty: 6.96070671081543
Epoch 388, Batch 800/1000, Loss: 7.2696332931518555, Uncertainty: 5.534300804138184
Epoch 388, Batch 900/1000, Loss: 10.55925464630127, Uncertainty: 8.034586906433105
Epoch 388, Batch 1000/1000, Loss: 9.014406204223633, Uncertainty: 6.001214027404785

Training and Validation Results of Epoch 388:
================================
Training Loss: 8.61873158478737, Training Uncertainty: 5.769266893863678, time: 8.466065406799316
Validation Loss: 10.292214422225952, Validation Uncertainty: 9.417782274246216, time: 1.101546049118042
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 103, Batch 2600/3125, Loss: 1.2060604095458984, Uncertainty: 1.4318068027496338
Epoch 389, Batch 100/1000, Loss: 8.370352745056152, Uncertainty: 7.316734313964844
Epoch 389, Batch 200/1000, Loss: 9.63919448852539, Uncertainty: 7.1358489990234375
Epoch 389, Batch 300/1000, Loss: 13.114870071411133, Uncertainty: 5.43456506729126
Epoch 389, Batch 400/1000, Loss: 7.7328267097473145, Uncertainty: 6.77579402923584
Epoch 389, Batch 500/1000, Loss: 8.441619873046875, Uncertainty: 5.638578414916992
Epoch 389, Batch 600/1000, Loss: 7.87130069732666, Uncertainty: 3.763157844543457
Epoch 389, Batch 700/1000, Loss: 10.24278736114502, Uncertainty: 6.961050033569336
Epoch 103, Batch 2700/3125, Loss: 1.371817946434021, Uncertainty: 1.7739719152450562
Epoch 389, Batch 800/1000, Loss: 7.269354343414307, Uncertainty: 5.534137725830078
Epoch 389, Batch 900/1000, Loss: 10.559730529785156, Uncertainty: 8.035289764404297
Epoch 389, Batch 1000/1000, Loss: 9.014145851135254, Uncertainty: 6.001007556915283

Training and Validation Results of Epoch 389:
================================
Training Loss: 8.61870445084572, Training Uncertainty: 5.76929159617424, time: 8.645068168640137
Validation Loss: 10.292212804794312, Validation Uncertainty: 9.417897254943847, time: 1.0936322212219238
Number of predictions within uncertainty interval: 550/2000 (27.50%)


Training and Validation Results of Epoch 3:
================================
Training Loss: 10.623620476074219, Training Uncertainty: 3.249148331375122, time: 193.4124641418457
Validation Loss: 10.335961868695895, Validation Uncertainty: 6.7805688192167555, time: 44.03983187675476
Number of predictions within uncertainty interval: 40622/200000 (20.31%)

Epoch 390, Batch 100/1000, Loss: 8.370477676391602, Uncertainty: 7.317215919494629
Epoch 390, Batch 200/1000, Loss: 9.638900756835938, Uncertainty: 7.137182235717773
Epoch 390, Batch 300/1000, Loss: 13.114774703979492, Uncertainty: 5.433793067932129
Epoch 390, Batch 400/1000, Loss: 7.733272075653076, Uncertainty: 6.776450157165527
Epoch 103, Batch 2800/3125, Loss: 1.208715558052063, Uncertainty: 1.3533704280853271
Epoch 390, Batch 500/1000, Loss: 8.441475868225098, Uncertainty: 5.63784122467041
Epoch 390, Batch 600/1000, Loss: 7.871113300323486, Uncertainty: 3.7644119262695312
Epoch 390, Batch 700/1000, Loss: 10.242941856384277, Uncertainty: 6.961447238922119
Epoch 390, Batch 800/1000, Loss: 7.269072532653809, Uncertainty: 5.533685684204102
Epoch 4, Batch 100/3125, Loss: 10.986308097839355, Uncertainty: 3.4653172492980957
Epoch 390, Batch 900/1000, Loss: 10.560247421264648, Uncertainty: 8.036094665527344
Epoch 390, Batch 1000/1000, Loss: 9.013856887817383, Uncertainty: 6.000883102416992

Training and Validation Results of Epoch 390:
================================
Training Loss: 8.618679063558579, Training Uncertainty: 5.769327389001846, time: 8.64658522605896
Validation Loss: 10.292210585594177, Validation Uncertainty: 9.41800686264038, time: 1.1435785293579102
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 103, Batch 2900/3125, Loss: 1.2780706882476807, Uncertainty: 1.6113619804382324
Epoch 391, Batch 100/1000, Loss: 8.370668411254883, Uncertainty: 7.317563056945801
Epoch 391, Batch 200/1000, Loss: 9.638561248779297, Uncertainty: 7.138624668121338
Epoch 391, Batch 300/1000, Loss: 13.114730834960938, Uncertainty: 5.433082103729248
Epoch 4, Batch 200/3125, Loss: 8.735786437988281, Uncertainty: 3.646759033203125
Epoch 391, Batch 400/1000, Loss: 7.7336106300354, Uncertainty: 6.776917457580566
Epoch 391, Batch 500/1000, Loss: 8.441267013549805, Uncertainty: 5.637164115905762
Epoch 391, Batch 600/1000, Loss: 7.870881080627441, Uncertainty: 3.765495777130127
Epoch 391, Batch 700/1000, Loss: 10.243003845214844, Uncertainty: 6.961986064910889
Epoch 103, Batch 3000/3125, Loss: 1.308922290802002, Uncertainty: 1.532397985458374
Epoch 391, Batch 800/1000, Loss: 7.2688703536987305, Uncertainty: 5.5334882736206055
Epoch 391, Batch 900/1000, Loss: 10.560649871826172, Uncertainty: 8.036465644836426
Epoch 391, Batch 1000/1000, Loss: 9.013594627380371, Uncertainty: 6.000742435455322
Epoch 4, Batch 300/3125, Loss: 10.62533950805664, Uncertainty: 3.7040467262268066

Training and Validation Results of Epoch 391:
================================
Training Loss: 8.618651390075684, Training Uncertainty: 5.769362125873566, time: 8.776590824127197
Validation Loss: 10.292210689544678, Validation Uncertainty: 9.418078969955443, time: 1.1039106845855713
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 392, Batch 100/1000, Loss: 8.370847702026367, Uncertainty: 7.317975997924805
Epoch 392, Batch 200/1000, Loss: 9.638263702392578, Uncertainty: 7.139928340911865
Epoch 392, Batch 300/1000, Loss: 13.114714622497559, Uncertainty: 5.432483196258545
Epoch 103, Batch 3100/3125, Loss: 1.1931991577148438, Uncertainty: 1.496267557144165
Epoch 392, Batch 400/1000, Loss: 7.7338361740112305, Uncertainty: 6.777289867401123
Epoch 392, Batch 500/1000, Loss: 8.44110107421875, Uncertainty: 5.636507034301758
Epoch 392, Batch 600/1000, Loss: 7.870691776275635, Uncertainty: 3.766494035720825
Epoch 4, Batch 400/3125, Loss: 9.760453224182129, Uncertainty: 3.0693893432617188
Epoch 392, Batch 700/1000, Loss: 10.243049621582031, Uncertainty: 6.962205410003662
Epoch 392, Batch 800/1000, Loss: 7.268556594848633, Uncertainty: 5.5331315994262695
Epoch 392, Batch 900/1000, Loss: 10.56098747253418, Uncertainty: 8.036949157714844
Epoch 392, Batch 1000/1000, Loss: 9.013578414916992, Uncertainty: 6.000906944274902

Training and Validation Results of Epoch 392:
================================
Training Loss: 8.618629656791686, Training Uncertainty: 5.7693868738412855, time: 8.708355188369751
Validation Loss: 10.292209436416625, Validation Uncertainty: 9.418171506881714, time: 1.1179325580596924
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 393, Batch 100/1000, Loss: 8.3709716796875, Uncertainty: 7.3182783126831055
Epoch 393, Batch 200/1000, Loss: 9.63786792755127, Uncertainty: 7.141317367553711
Epoch 4, Batch 500/3125, Loss: 10.007819175720215, Uncertainty: 3.9822750091552734
Epoch 393, Batch 300/1000, Loss: 13.114633560180664, Uncertainty: 5.431851863861084
Epoch 393, Batch 400/1000, Loss: 7.734015464782715, Uncertainty: 6.777402877807617
Epoch 393, Batch 500/1000, Loss: 8.440844535827637, Uncertainty: 5.635925769805908
Epoch 393, Batch 600/1000, Loss: 7.870429992675781, Uncertainty: 3.7674641609191895
Epoch 393, Batch 700/1000, Loss: 10.243118286132812, Uncertainty: 6.962559223175049
Epoch 393, Batch 800/1000, Loss: 7.268274307250977, Uncertainty: 5.533074378967285
Epoch 393, Batch 900/1000, Loss: 10.56132984161377, Uncertainty: 8.037422180175781
Epoch 4, Batch 600/3125, Loss: 11.277663230895996, Uncertainty: 3.4504292011260986
Epoch 393, Batch 1000/1000, Loss: 9.013422012329102, Uncertainty: 6.001134872436523

Training and Validation Results of Epoch 393:
================================
Training Loss: 8.618607533693314, Training Uncertainty: 5.769404215931893, time: 8.816490173339844
Validation Loss: 10.292208326339722, Validation Uncertainty: 9.41826670074463, time: 1.1445350646972656
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 394, Batch 100/1000, Loss: 8.370990753173828, Uncertainty: 7.318890571594238
Epoch 394, Batch 200/1000, Loss: 9.637645721435547, Uncertainty: 7.142853260040283
Epoch 394, Batch 300/1000, Loss: 13.114606857299805, Uncertainty: 5.431362152099609
Epoch 394, Batch 400/1000, Loss: 7.734172821044922, Uncertainty: 6.777555465698242
Epoch 394, Batch 500/1000, Loss: 8.44068717956543, Uncertainty: 5.635340213775635
Epoch 4, Batch 700/3125, Loss: 10.579452514648438, Uncertainty: 3.581003189086914
Epoch 394, Batch 600/1000, Loss: 7.870162487030029, Uncertainty: 3.7684237957000732
Epoch 394, Batch 700/1000, Loss: 10.243234634399414, Uncertainty: 6.962949752807617
Epoch 394, Batch 800/1000, Loss: 7.268306732177734, Uncertainty: 5.532914161682129
Epoch 394, Batch 900/1000, Loss: 10.561656951904297, Uncertainty: 8.037784576416016
Epoch 394, Batch 1000/1000, Loss: 9.01341438293457, Uncertainty: 6.001178741455078

Training and Validation Results of Epoch 394:
================================
Training Loss: 8.618580768108368, Training Uncertainty: 5.769439514279366, time: 8.742763042449951
Validation Loss: 10.29220917892456, Validation Uncertainty: 9.418372905731202, time: 1.0981545448303223
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 395, Batch 100/1000, Loss: 8.37108325958252, Uncertainty: 7.318951606750488
Epoch 4, Batch 800/3125, Loss: 9.388792037963867, Uncertainty: 3.9921939373016357
Epoch 395, Batch 200/1000, Loss: 9.637269973754883, Uncertainty: 7.143711090087891
Epoch 395, Batch 300/1000, Loss: 13.114564895629883, Uncertainty: 5.430951118469238
Epoch 395, Batch 400/1000, Loss: 7.734385967254639, Uncertainty: 6.777713775634766
Epoch 395, Batch 500/1000, Loss: 8.440511703491211, Uncertainty: 5.635036945343018
Epoch 395, Batch 600/1000, Loss: 7.869857311248779, Uncertainty: 3.7693192958831787
Epoch 395, Batch 700/1000, Loss: 10.24324893951416, Uncertainty: 6.962892532348633
Epoch 395, Batch 800/1000, Loss: 7.2679972648620605, Uncertainty: 5.5330610275268555
Epoch 4, Batch 900/3125, Loss: 10.000885963439941, Uncertainty: 3.880056381225586
Epoch 395, Batch 900/1000, Loss: 10.561960220336914, Uncertainty: 8.037961959838867
Epoch 395, Batch 1000/1000, Loss: 9.013425827026367, Uncertainty: 6.001228332519531

Training and Validation Results of Epoch 395:
================================
Training Loss: 8.618555439949036, Training Uncertainty: 5.769464247226715, time: 8.706315040588379
Validation Loss: 10.292209047317504, Validation Uncertainty: 9.418456335067749, time: 1.1177864074707031
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 396, Batch 100/1000, Loss: 8.371078491210938, Uncertainty: 7.319517135620117
Epoch 396, Batch 200/1000, Loss: 9.637068748474121, Uncertainty: 7.144865989685059
Epoch 396, Batch 300/1000, Loss: 13.114498138427734, Uncertainty: 5.4307050704956055
Epoch 396, Batch 400/1000, Loss: 7.734555244445801, Uncertainty: 6.777956008911133
Epoch 4, Batch 1000/3125, Loss: 9.568907737731934, Uncertainty: 2.901444911956787
Epoch 396, Batch 500/1000, Loss: 8.44041633605957, Uncertainty: 5.634690284729004
Epoch 396, Batch 600/1000, Loss: 7.869579315185547, Uncertainty: 3.770071268081665
Epoch 396, Batch 700/1000, Loss: 10.243337631225586, Uncertainty: 6.963190078735352
Epoch 396, Batch 800/1000, Loss: 7.268007755279541, Uncertainty: 5.5330705642700195
Epoch 396, Batch 900/1000, Loss: 10.562261581420898, Uncertainty: 8.038156509399414
Epoch 396, Batch 1000/1000, Loss: 9.013298988342285, Uncertainty: 6.00129508972168

Training and Validation Results of Epoch 396:
================================
Training Loss: 8.61852999663353, Training Uncertainty: 5.769497960567475, time: 8.776886224746704
Validation Loss: 10.292208813667298, Validation Uncertainty: 9.418526828765868, time: 1.0869569778442383
Number of predictions within uncertainty interval: 550/2000 (27.50%)

Epoch 4, Batch 1100/3125, Loss: 11.271045684814453, Uncertainty: 4.2989020347595215
Epoch 397, Batch 100/1000, Loss: 8.371017456054688, Uncertainty: 7.3202290534973145
Epoch 397, Batch 200/1000, Loss: 9.636892318725586, Uncertainty: 7.145998477935791
Epoch 397, Batch 300/1000, Loss: 13.114469528198242, Uncertainty: 5.430495738983154

Training and Validation Results of Epoch 103:
================================
Training Loss: 1.0038750633049012, Training Uncertainty: 1.5346365968704223, time: 203.12139678001404
Validation Loss: 0.8816197202028826, Validation Uncertainty: 2.1867147903613118, time: 47.56156134605408
Number of predictions within uncertainty interval: 125745/200000 (62.87%)

Epoch 397, Batch 400/1000, Loss: 7.734737873077393, Uncertainty: 6.7782182693481445
Epoch 397, Batch 500/1000, Loss: 8.440404891967773, Uncertainty: 5.63410758972168
Epoch 397, Batch 600/1000, Loss: 7.869369029998779, Uncertainty: 3.770883560180664
Epoch 397, Batch 700/1000, Loss: 10.243511199951172, Uncertainty: 6.963481903076172
Epoch 4, Batch 1200/3125, Loss: 10.019402503967285, Uncertainty: 5.109228134155273
Epoch 397, Batch 800/1000, Loss: 7.268007755279541, Uncertainty: 5.532711982727051
Epoch 397, Batch 900/1000, Loss: 10.56261920928955, Uncertainty: 8.03842544555664
Epoch 397, Batch 1000/1000, Loss: 9.01323127746582, Uncertainty: 6.001404285430908
Epoch 104, Batch 100/3125, Loss: 1.0420656204223633, Uncertainty: 1.2700484991073608

Training and Validation Results of Epoch 397:
================================
Training Loss: 8.61850773024559, Training Uncertainty: 5.769525127410889, time: 8.647371530532837
Validation Loss: 10.29220957660675, Validation Uncertainty: 9.418609338760376, time: 1.0711405277252197
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 398, Batch 100/1000, Loss: 8.371179580688477, Uncertainty: 7.320441722869873
Epoch 398, Batch 200/1000, Loss: 9.636526107788086, Uncertainty: 7.14674711227417
Epoch 398, Batch 300/1000, Loss: 13.11442756652832, Uncertainty: 5.4301934242248535
Epoch 4, Batch 1300/3125, Loss: 9.67092514038086, Uncertainty: 3.59836483001709
Epoch 398, Batch 400/1000, Loss: 7.73491096496582, Uncertainty: 6.778409004211426
Epoch 398, Batch 500/1000, Loss: 8.440189361572266, Uncertainty: 5.633888244628906
Epoch 398, Batch 600/1000, Loss: 7.869089126586914, Uncertainty: 3.7718148231506348
Epoch 398, Batch 700/1000, Loss: 10.243583679199219, Uncertainty: 6.963521480560303
Epoch 104, Batch 200/3125, Loss: 1.2264430522918701, Uncertainty: 1.5363715887069702
Epoch 398, Batch 800/1000, Loss: 7.267726898193359, Uncertainty: 5.532545566558838
Epoch 398, Batch 900/1000, Loss: 10.562896728515625, Uncertainty: 8.038541793823242
Epoch 398, Batch 1000/1000, Loss: 9.013182640075684, Uncertainty: 6.001399993896484
Epoch 4, Batch 1400/3125, Loss: 10.167652130126953, Uncertainty: 4.179316997528076

Training and Validation Results of Epoch 398:
================================
Training Loss: 8.618483789682388, Training Uncertainty: 5.769548831105232, time: 8.907102584838867
Validation Loss: 10.292208364486694, Validation Uncertainty: 9.418709812164307, time: 1.111933946609497
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 399, Batch 100/1000, Loss: 8.371097564697266, Uncertainty: 7.321141242980957
Epoch 399, Batch 200/1000, Loss: 9.636402130126953, Uncertainty: 7.147697925567627
Epoch 399, Batch 300/1000, Loss: 13.114371299743652, Uncertainty: 5.42987060546875
Epoch 104, Batch 300/3125, Loss: 1.3269537687301636, Uncertainty: 1.5123281478881836
Epoch 399, Batch 400/1000, Loss: 7.735112190246582, Uncertainty: 6.77878475189209
Epoch 399, Batch 500/1000, Loss: 8.440156936645508, Uncertainty: 5.633424758911133
Epoch 399, Batch 600/1000, Loss: 7.868925094604492, Uncertainty: 3.7726778984069824
Epoch 4, Batch 1500/3125, Loss: 11.072992324829102, Uncertainty: 4.2981038093566895
Epoch 399, Batch 700/1000, Loss: 10.243790626525879, Uncertainty: 6.963449001312256
Epoch 399, Batch 800/1000, Loss: 7.267727851867676, Uncertainty: 5.532238960266113
Epoch 399, Batch 900/1000, Loss: 10.563241958618164, Uncertainty: 8.038928031921387
Epoch 399, Batch 1000/1000, Loss: 9.013204574584961, Uncertainty: 6.001399993896484
Epoch 104, Batch 400/3125, Loss: 1.0905014276504517, Uncertainty: 1.3778165578842163

Training and Validation Results of Epoch 399:
================================
Training Loss: 8.618459252357482, Training Uncertainty: 5.769575031280517, time: 8.699276208877563
Validation Loss: 10.29220213508606, Validation Uncertainty: 9.418790840148926, time: 1.1087214946746826
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 400, Batch 100/1000, Loss: 8.371129989624023, Uncertainty: 7.321712493896484
Epoch 4, Batch 1600/3125, Loss: 10.339177131652832, Uncertainty: 3.4712095260620117
Epoch 400, Batch 200/1000, Loss: 9.63606071472168, Uncertainty: 7.148449897766113
Epoch 400, Batch 300/1000, Loss: 13.114400863647461, Uncertainty: 5.429793357849121
Epoch 400, Batch 400/1000, Loss: 7.735260009765625, Uncertainty: 6.77906608581543
Epoch 400, Batch 500/1000, Loss: 8.440019607543945, Uncertainty: 5.6331787109375
Epoch 400, Batch 600/1000, Loss: 7.86872673034668, Uncertainty: 3.7734360694885254
Epoch 104, Batch 500/3125, Loss: 1.2060434818267822, Uncertainty: 1.4780991077423096
Epoch 400, Batch 700/1000, Loss: 10.243860244750977, Uncertainty: 6.963499069213867
Epoch 400, Batch 800/1000, Loss: 7.267482757568359, Uncertainty: 5.532315731048584
Epoch 4, Batch 1700/3125, Loss: 9.7515869140625, Uncertainty: 4.359282493591309
Epoch 400, Batch 900/1000, Loss: 10.563451766967773, Uncertainty: 8.039134979248047
Epoch 400, Batch 1000/1000, Loss: 9.01308536529541, Uncertainty: 6.001491069793701

Training and Validation Results of Epoch 400:
================================
Training Loss: 8.618434577941894, Training Uncertainty: 5.769595314145088, time: 8.857487678527832
Validation Loss: 10.292204569816588, Validation Uncertainty: 9.418899723052979, time: 1.1042373180389404
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 401, Batch 100/1000, Loss: 8.371194839477539, Uncertainty: 7.322133541107178
Epoch 401, Batch 200/1000, Loss: 9.635902404785156, Uncertainty: 7.14916467666626
Epoch 401, Batch 300/1000, Loss: 13.1143798828125, Uncertainty: 5.429538726806641
Epoch 104, Batch 600/3125, Loss: 1.3910651206970215, Uncertainty: 1.508427619934082
Epoch 401, Batch 400/1000, Loss: 7.735528469085693, Uncertainty: 6.779499530792236
Epoch 4, Batch 1800/3125, Loss: 10.000848770141602, Uncertainty: 3.384190320968628
Epoch 401, Batch 500/1000, Loss: 8.439847946166992, Uncertainty: 5.633161544799805
Epoch 401, Batch 600/1000, Loss: 7.8685526847839355, Uncertainty: 3.7740535736083984
Epoch 401, Batch 700/1000, Loss: 10.244050025939941, Uncertainty: 6.964066505432129
Epoch 401, Batch 800/1000, Loss: 7.267399787902832, Uncertainty: 5.532191753387451
Epoch 401, Batch 900/1000, Loss: 10.56365966796875, Uncertainty: 8.039308547973633
Epoch 401, Batch 1000/1000, Loss: 9.013051986694336, Uncertainty: 6.001619338989258
Epoch 104, Batch 700/3125, Loss: 1.2284101247787476, Uncertainty: 1.4882020950317383

Training and Validation Results of Epoch 401:
================================
Training Loss: 8.618406450986862, Training Uncertainty: 5.769634443044662, time: 8.530856370925903
Validation Loss: 10.292199215888978, Validation Uncertainty: 9.41891640663147, time: 1.0911445617675781
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 4, Batch 1900/3125, Loss: 10.481657981872559, Uncertainty: 3.1984472274780273
Epoch 402, Batch 100/1000, Loss: 8.371103286743164, Uncertainty: 7.322343826293945
Epoch 402, Batch 200/1000, Loss: 9.635786056518555, Uncertainty: 7.150156021118164
Epoch 402, Batch 300/1000, Loss: 13.114394187927246, Uncertainty: 5.429477691650391
Epoch 402, Batch 400/1000, Loss: 7.735681533813477, Uncertainty: 6.779731750488281
Epoch 402, Batch 500/1000, Loss: 8.439712524414062, Uncertainty: 5.633174896240234
Epoch 402, Batch 600/1000, Loss: 7.868353366851807, Uncertainty: 3.7747387886047363
Epoch 104, Batch 800/3125, Loss: 1.367082118988037, Uncertainty: 1.818131923675537
Epoch 402, Batch 700/1000, Loss: 10.244240760803223, Uncertainty: 6.964395523071289
Epoch 402, Batch 800/1000, Loss: 7.267185688018799, Uncertainty: 5.5322585105896
Epoch 4, Batch 2000/3125, Loss: 9.651545524597168, Uncertainty: 3.404092311859131
Epoch 402, Batch 900/1000, Loss: 10.563812255859375, Uncertainty: 8.039608001708984
Epoch 402, Batch 1000/1000, Loss: 9.012979507446289, Uncertainty: 6.001791000366211

Training and Validation Results of Epoch 402:
================================
Training Loss: 8.618384228467942, Training Uncertainty: 5.769647496938705, time: 8.744247436523438
Validation Loss: 10.292202242851257, Validation Uncertainty: 9.41898203086853, time: 1.1251575946807861
Number of predictions within uncertainty interval: 551/2000 (27.55%)

Epoch 403, Batch 100/1000, Loss: 8.371091842651367, Uncertainty: 7.3226118087768555
Epoch 403, Batch 200/1000, Loss: 9.63570785522461, Uncertainty: 7.150588512420654
Epoch 104, Batch 900/3125, Loss: 1.3783221244812012, Uncertainty: 1.7382280826568604
Epoch 403, Batch 300/1000, Loss: 13.114423751831055, Uncertainty: 5.429312705993652
Epoch 4, Batch 2100/3125, Loss: 9.84836483001709, Uncertainty: 3.665581703186035
Epoch 403, Batch 400/1000, Loss: 7.735901832580566, Uncertainty: 6.780271530151367
Epoch 403, Batch 500/1000, Loss: 8.43954086303711, Uncertainty: 5.633203983306885
Epoch 403, Batch 600/1000, Loss: 7.86827278137207, Uncertainty: 3.77522611618042
Epoch 403, Batch 700/1000, Loss: 10.244331359863281, Uncertainty: 6.964380264282227
Epoch 403, Batch 800/1000, Loss: 7.267100811004639, Uncertainty: 5.532022476196289
Epoch 403, Batch 900/1000, Loss: 10.56400203704834, Uncertainty: 8.039663314819336
Epoch 403, Batch 1000/1000, Loss: 9.012969970703125, Uncertainty: 6.001700401306152
Epoch 104, Batch 1000/3125, Loss: 1.0966284275054932, Uncertainty: 1.275365948677063
Epoch 4, Batch 2200/3125, Loss: 9.623114585876465, Uncertainty: 3.5310797691345215
Learning rate changed to: 1.0000000000000004e-08
Epoch 104, Batch 1100/3125, Loss: 1.2551060914993286, Uncertainty: 1.4340537786483765
Epoch 4, Batch 2300/3125, Loss: 9.615243911743164, Uncertainty: 4.513121128082275
Learning rate is below minimum, stopping training
Epoch 4, Batch 2400/3125, Loss: 10.453437805175781, Uncertainty: 4.095220565795898
Epoch 104, Batch 1200/3125, Loss: 1.3901450634002686, Uncertainty: 1.9699444770812988
Epoch 4, Batch 2500/3125, Loss: 10.199090957641602, Uncertainty: 3.4719958305358887
Epoch 104, Batch 1300/3125, Loss: 1.1170904636383057, Uncertainty: 1.242995023727417
Epoch 4, Batch 2600/3125, Loss: 9.957468032836914, Uncertainty: 4.312739372253418
Epoch 104, Batch 1400/3125, Loss: 1.2395836114883423, Uncertainty: 1.692108154296875
Epoch 4, Batch 2700/3125, Loss: 9.2972412109375, Uncertainty: 4.3105573654174805
Epoch 104, Batch 1500/3125, Loss: 1.3835042715072632, Uncertainty: 1.5651148557662964
Epoch 4, Batch 2800/3125, Loss: 10.588592529296875, Uncertainty: 3.7316524982452393
Epoch 104, Batch 1600/3125, Loss: 1.091559886932373, Uncertainty: 1.4433748722076416
Epoch 4, Batch 2900/3125, Loss: 10.464681625366211, Uncertainty: 5.262617111206055
Epoch 104, Batch 1700/3125, Loss: 1.199775218963623, Uncertainty: 1.5712835788726807
Epoch 4, Batch 3000/3125, Loss: 9.573358535766602, Uncertainty: 4.483992576599121
Epoch 104, Batch 1800/3125, Loss: 1.297471284866333, Uncertainty: 1.6468329429626465
Epoch 4, Batch 3100/3125, Loss: 10.13729476928711, Uncertainty: 3.208934783935547

============================= JOB FEEDBACK =============================

NodeName=uc2n507
Job ID: 23975413
Cluster: uc2
User/Group: fq0795/iti
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 10
CPU Utilized: 01:11:28
CPU Efficiency: 9.60% of 12:24:10 core-walltime
Job Wall-clock time: 01:14:25
Memory Utilized: 1.31 GB
Memory Efficiency: 1.43% of 91.80 GB
Epoch 104, Batch 1900/3125, Loss: 1.0130730867385864, Uncertainty: 1.3366060256958008
Epoch 104, Batch 2000/3125, Loss: 1.2324273586273193, Uncertainty: 1.4211218357086182
Epoch 104, Batch 2100/3125, Loss: 1.430550217628479, Uncertainty: 1.5548145771026611
Epoch 104, Batch 2200/3125, Loss: 1.0157757997512817, Uncertainty: 1.2411324977874756
Epoch 104, Batch 2300/3125, Loss: 1.261834740638733, Uncertainty: 1.578063726425171
Epoch 104, Batch 2400/3125, Loss: 1.243798851966858, Uncertainty: 1.5208508968353271
Epoch 104, Batch 2500/3125, Loss: 1.2548139095306396, Uncertainty: 1.7673685550689697

Training and Validation Results of Epoch 4:
================================
Training Loss: 10.19389010772705, Training Uncertainty: 3.911597449874878, time: 194.10931491851807
Validation Loss: 9.88036625464554, Validation Uncertainty: 5.732128930518694, time: 44.48400282859802
Number of predictions within uncertainty interval: 36706/200000 (18.35%)

Epoch 104, Batch 2600/3125, Loss: 1.2053062915802002, Uncertainty: 1.4091286659240723
Epoch 5, Batch 100/3125, Loss: 10.676390647888184, Uncertainty: 3.93296217918396
Epoch 104, Batch 2700/3125, Loss: 1.3662574291229248, Uncertainty: 1.7492212057113647
Epoch 5, Batch 200/3125, Loss: 8.551301956176758, Uncertainty: 5.585052490234375
Epoch 104, Batch 2800/3125, Loss: 1.1655076742172241, Uncertainty: 1.3531522750854492
Epoch 5, Batch 300/3125, Loss: 10.19625186920166, Uncertainty: 5.177654266357422
Epoch 104, Batch 2900/3125, Loss: 1.2192386388778687, Uncertainty: 1.5661194324493408
Epoch 5, Batch 400/3125, Loss: 9.514726638793945, Uncertainty: 3.2654788494110107
Epoch 104, Batch 3000/3125, Loss: 1.3399851322174072, Uncertainty: 1.5291111469268799
Epoch 5, Batch 500/3125, Loss: 9.408905029296875, Uncertainty: 4.286147117614746
Epoch 104, Batch 3100/3125, Loss: 1.1597402095794678, Uncertainty: 1.45583176612854
Epoch 5, Batch 600/3125, Loss: 11.027887344360352, Uncertainty: 4.093902587890625
Epoch 5, Batch 700/3125, Loss: 10.445802688598633, Uncertainty: 3.8232736587524414
Epoch 5, Batch 800/3125, Loss: 9.071741104125977, Uncertainty: 4.61232852935791
Epoch 5, Batch 900/3125, Loss: 9.872539520263672, Uncertainty: 4.780646324157715
Epoch 5, Batch 1000/3125, Loss: 9.20551872253418, Uncertainty: 3.038909673690796
Epoch 5, Batch 1100/3125, Loss: 10.948322296142578, Uncertainty: 3.9193477630615234
Epoch 5, Batch 1200/3125, Loss: 9.329408645629883, Uncertainty: 4.535041809082031
Epoch 5, Batch 1300/3125, Loss: 9.49970531463623, Uncertainty: 4.0806427001953125

Training and Validation Results of Epoch 104:
================================
Training Loss: 1.0011073114585876, Training Uncertainty: 1.5338038608551026, time: 204.88970947265625
Validation Loss: 0.9306133310203357, Validation Uncertainty: 2.286780820478259, time: 47.23987364768982
Number of predictions within uncertainty interval: 125588/200000 (62.79%)

Epoch 5, Batch 1400/3125, Loss: 10.056804656982422, Uncertainty: 4.012755393981934
Epoch 105, Batch 100/3125, Loss: 1.0323607921600342, Uncertainty: 1.257830023765564
Epoch 5, Batch 1500/3125, Loss: 10.594422340393066, Uncertainty: 5.581585884094238
Epoch 105, Batch 200/3125, Loss: 1.2119526863098145, Uncertainty: 1.5585401058197021
Epoch 5, Batch 1600/3125, Loss: 10.078609466552734, Uncertainty: 3.702146053314209
Epoch 105, Batch 300/3125, Loss: 1.3659313917160034, Uncertainty: 1.7304099798202515
Epoch 5, Batch 1700/3125, Loss: 9.397947311401367, Uncertainty: 4.582691192626953
Epoch 105, Batch 400/3125, Loss: 1.1430253982543945, Uncertainty: 1.4828203916549683
Epoch 5, Batch 1800/3125, Loss: 9.92883014678955, Uncertainty: 4.611412525177002
Epoch 105, Batch 500/3125, Loss: 1.1652284860610962, Uncertainty: 1.4477587938308716
Epoch 5, Batch 1900/3125, Loss: 10.15990161895752, Uncertainty: 4.092993259429932
Epoch 5, Batch 2000/3125, Loss: 9.41964340209961, Uncertainty: 4.37882137298584
Epoch 105, Batch 600/3125, Loss: 1.372413158416748, Uncertainty: 1.4666476249694824
Epoch 5, Batch 2100/3125, Loss: 9.482431411743164, Uncertainty: 4.481778144836426
Epoch 105, Batch 700/3125, Loss: 1.2655258178710938, Uncertainty: 1.6387369632720947
Epoch 5, Batch 2200/3125, Loss: 9.30140209197998, Uncertainty: 3.664431571960449
Epoch 105, Batch 800/3125, Loss: 1.2836573123931885, Uncertainty: 1.4585298299789429
Epoch 5, Batch 2300/3125, Loss: 9.436311721801758, Uncertainty: 4.918303966522217
Epoch 105, Batch 900/3125, Loss: 1.3507976531982422, Uncertainty: 1.5776612758636475
Epoch 5, Batch 2400/3125, Loss: 10.29554557800293, Uncertainty: 4.996886253356934
Epoch 105, Batch 1000/3125, Loss: 1.080866813659668, Uncertainty: 1.3153645992279053
Epoch 5, Batch 2500/3125, Loss: 9.69780158996582, Uncertainty: 4.642229080200195
Epoch 105, Batch 1100/3125, Loss: 1.1740573644638062, Uncertainty: 1.4318454265594482
Epoch 5, Batch 2600/3125, Loss: 9.842613220214844, Uncertainty: 4.3328166007995605
Epoch 105, Batch 1200/3125, Loss: 1.3171790838241577, Uncertainty: 1.6897761821746826
Epoch 5, Batch 2700/3125, Loss: 9.131329536437988, Uncertainty: 4.258180141448975
Epoch 105, Batch 1300/3125, Loss: 1.1253666877746582, Uncertainty: 1.319164514541626
Epoch 5, Batch 2800/3125, Loss: 10.144023895263672, Uncertainty: 3.915382146835327
Epoch 105, Batch 1400/3125, Loss: 1.192065715789795, Uncertainty: 1.540928602218628
Epoch 5, Batch 2900/3125, Loss: 10.120644569396973, Uncertainty: 5.570563316345215
Epoch 105, Batch 1500/3125, Loss: 1.369722604751587, Uncertainty: 1.5534666776657104
Epoch 5, Batch 3000/3125, Loss: 9.358745574951172, Uncertainty: 4.932519912719727
Epoch 105, Batch 1600/3125, Loss: 1.1045446395874023, Uncertainty: 1.4344477653503418
Epoch 5, Batch 3100/3125, Loss: 9.648355484008789, Uncertainty: 3.7353036403656006
Epoch 105, Batch 1700/3125, Loss: 1.1269018650054932, Uncertainty: 1.4578421115875244
Epoch 105, Batch 1800/3125, Loss: 1.4049837589263916, Uncertainty: 1.9537653923034668
Epoch 105, Batch 1900/3125, Loss: 1.0649116039276123, Uncertainty: 1.444061040878296
Epoch 105, Batch 2000/3125, Loss: 1.2376292943954468, Uncertainty: 1.4592719078063965
Epoch 105, Batch 2100/3125, Loss: 1.3898475170135498, Uncertainty: 1.5796525478363037
Epoch 105, Batch 2200/3125, Loss: 1.0093762874603271, Uncertainty: 1.246460199356079
Epoch 105, Batch 2300/3125, Loss: 1.273328185081482, Uncertainty: 1.6577485799789429

Training and Validation Results of Epoch 5:
================================
Training Loss: 9.761334148864746, Training Uncertainty: 4.448589691085815, time: 193.7896580696106
Validation Loss: 9.47882403742017, Validation Uncertainty: 7.314206926414119, time: 44.958181619644165
Number of predictions within uncertainty interval: 47541/200000 (23.77%)

Epoch 105, Batch 2400/3125, Loss: 1.3245501518249512, Uncertainty: 1.6654998064041138
Epoch 6, Batch 100/3125, Loss: 10.03905200958252, Uncertainty: 4.284090518951416
Epoch 105, Batch 2500/3125, Loss: 1.1885554790496826, Uncertainty: 1.5898017883300781
Epoch 6, Batch 200/3125, Loss: 8.38086223602295, Uncertainty: 5.812535285949707
Epoch 105, Batch 2600/3125, Loss: 1.2068798542022705, Uncertainty: 1.4495868682861328
Epoch 6, Batch 300/3125, Loss: 10.011919021606445, Uncertainty: 5.1532793045043945
Epoch 105, Batch 2700/3125, Loss: 1.405839443206787, Uncertainty: 1.8276093006134033
Epoch 6, Batch 400/3125, Loss: 8.93612289428711, Uncertainty: 4.368523120880127
Epoch 105, Batch 2800/3125, Loss: 1.1295156478881836, Uncertainty: 1.308824896812439
Epoch 6, Batch 500/3125, Loss: 9.180814743041992, Uncertainty: 4.513473033905029
Epoch 105, Batch 2900/3125, Loss: 1.2352200746536255, Uncertainty: 1.6056722402572632
Epoch 6, Batch 600/3125, Loss: 10.450164794921875, Uncertainty: 4.706010341644287
Epoch 105, Batch 3000/3125, Loss: 1.2892080545425415, Uncertainty: 1.4996062517166138
Epoch 6, Batch 700/3125, Loss: 9.98430347442627, Uncertainty: 3.9416842460632324
Epoch 105, Batch 3100/3125, Loss: 1.1845335960388184, Uncertainty: 1.5215201377868652
Epoch 6, Batch 800/3125, Loss: 9.092569351196289, Uncertainty: 5.331250190734863
Epoch 6, Batch 900/3125, Loss: 9.734560012817383, Uncertainty: 4.9679646492004395
Epoch 6, Batch 1000/3125, Loss: 8.888093948364258, Uncertainty: 4.327291011810303
Epoch 6, Batch 1100/3125, Loss: 10.641460418701172, Uncertainty: 5.057894706726074
Epoch 6, Batch 1200/3125, Loss: 9.299232482910156, Uncertainty: 5.439638137817383
Epoch 6, Batch 1300/3125, Loss: 8.99809455871582, Uncertainty: 4.481886863708496
Epoch 6, Batch 1400/3125, Loss: 9.544082641601562, Uncertainty: 4.146675109863281
Epoch 6, Batch 1500/3125, Loss: 10.221120834350586, Uncertainty: 5.460302352905273

Training and Validation Results of Epoch 105:
================================
Training Loss: 0.9932702999687195, Training Uncertainty: 1.5127513388061524, time: 203.65641713142395
Validation Loss: 0.8713400479015487, Validation Uncertainty: 2.1879655703559253, time: 47.35108494758606
Number of predictions within uncertainty interval: 126955/200000 (63.48%)

Epoch 6, Batch 1600/3125, Loss: 9.47395133972168, Uncertainty: 3.6722443103790283
Epoch 106, Batch 100/3125, Loss: 1.0386366844177246, Uncertainty: 1.2684526443481445
Epoch 6, Batch 1700/3125, Loss: 9.01303482055664, Uncertainty: 4.349238395690918
Epoch 106, Batch 200/3125, Loss: 1.2145352363586426, Uncertainty: 1.5119991302490234
Epoch 6, Batch 1800/3125, Loss: 9.304786682128906, Uncertainty: 4.62238883972168
Epoch 106, Batch 300/3125, Loss: 1.3168500661849976, Uncertainty: 1.5978891849517822
Epoch 6, Batch 1900/3125, Loss: 9.855985641479492, Uncertainty: 4.142595291137695
Epoch 106, Batch 400/3125, Loss: 1.0795230865478516, Uncertainty: 1.3553929328918457
Epoch 6, Batch 2000/3125, Loss: 9.119572639465332, Uncertainty: 3.7129273414611816
Epoch 106, Batch 500/3125, Loss: 1.130098581314087, Uncertainty: 1.4142820835113525
Epoch 6, Batch 2100/3125, Loss: 9.162443161010742, Uncertainty: 4.2693891525268555
Epoch 6, Batch 2200/3125, Loss: 9.255556106567383, Uncertainty: 5.785670280456543
Epoch 106, Batch 600/3125, Loss: 1.3851808309555054, Uncertainty: 1.583768606185913
Epoch 6, Batch 2300/3125, Loss: 9.916593551635742, Uncertainty: 6.396830081939697
Epoch 106, Batch 700/3125, Loss: 1.1951816082000732, Uncertainty: 1.4573109149932861
Epoch 6, Batch 2400/3125, Loss: 9.847193717956543, Uncertainty: 4.406205177307129
Epoch 106, Batch 800/3125, Loss: 1.361480712890625, Uncertainty: 1.661271572113037
Epoch 6, Batch 2500/3125, Loss: 9.668987274169922, Uncertainty: 5.831355094909668
Epoch 106, Batch 900/3125, Loss: 1.364931583404541, Uncertainty: 1.6735625267028809
Epoch 6, Batch 2600/3125, Loss: 9.082719802856445, Uncertainty: 4.448411464691162
Epoch 106, Batch 1000/3125, Loss: 1.0953189134597778, Uncertainty: 1.3021554946899414
Epoch 6, Batch 2700/3125, Loss: 8.879316329956055, Uncertainty: 4.423331260681152
Epoch 106, Batch 1100/3125, Loss: 1.1305270195007324, Uncertainty: 1.4099714756011963
Epoch 6, Batch 2800/3125, Loss: 9.623711585998535, Uncertainty: 4.999073028564453
Epoch 106, Batch 1200/3125, Loss: 1.343153715133667, Uncertainty: 1.7217016220092773
Epoch 6, Batch 2900/3125, Loss: 9.88498592376709, Uncertainty: 5.529240608215332
Epoch 106, Batch 1300/3125, Loss: 1.103297472000122, Uncertainty: 1.2658090591430664
Epoch 6, Batch 3000/3125, Loss: 9.140023231506348, Uncertainty: 5.831249237060547
Epoch 106, Batch 1400/3125, Loss: 1.1653833389282227, Uncertainty: 1.5398008823394775
Epoch 6, Batch 3100/3125, Loss: 9.362922668457031, Uncertainty: 4.33878231048584
Epoch 106, Batch 1500/3125, Loss: 1.3578155040740967, Uncertainty: 1.5497629642486572
Epoch 106, Batch 1600/3125, Loss: 1.0731769800186157, Uncertainty: 1.4008599519729614
Epoch 106, Batch 1700/3125, Loss: 1.1886048316955566, Uncertainty: 1.659907341003418
Epoch 106, Batch 1800/3125, Loss: 1.2900789976119995, Uncertainty: 1.6179611682891846
Epoch 106, Batch 1900/3125, Loss: 1.0238008499145508, Uncertainty: 1.4216309785842896
Epoch 106, Batch 2000/3125, Loss: 1.1802455186843872, Uncertainty: 1.417768955230713
Epoch 106, Batch 2100/3125, Loss: 1.3651208877563477, Uncertainty: 1.5271897315979004
Epoch 106, Batch 2200/3125, Loss: 1.037964105606079, Uncertainty: 1.2864692211151123

Training and Validation Results of Epoch 6:
================================
Training Loss: 9.330528913726807, Training Uncertainty: 4.7122488869476316, time: 194.12714290618896
Validation Loss: 9.011149475946452, Validation Uncertainty: 6.6591297391125615, time: 49.8116192817688
Number of predictions within uncertainty interval: 46155/200000 (23.08%)

Epoch 106, Batch 2300/3125, Loss: 1.2645092010498047, Uncertainty: 1.651222586631775
Epoch 7, Batch 100/3125, Loss: 9.609550476074219, Uncertainty: 4.473570346832275
Epoch 106, Batch 2400/3125, Loss: 1.2716374397277832, Uncertainty: 1.5791964530944824
Epoch 7, Batch 200/3125, Loss: 7.830239772796631, Uncertainty: 4.953150749206543
Epoch 106, Batch 2500/3125, Loss: 1.165053129196167, Uncertainty: 1.5729514360427856
Epoch 7, Batch 300/3125, Loss: 9.654622077941895, Uncertainty: 5.086897850036621
Epoch 106, Batch 2600/3125, Loss: 1.3078192472457886, Uncertainty: 1.7863619327545166
Epoch 7, Batch 400/3125, Loss: 8.534368515014648, Uncertainty: 4.835979461669922
Epoch 106, Batch 2700/3125, Loss: 1.3959002494812012, Uncertainty: 1.8407726287841797
Epoch 7, Batch 500/3125, Loss: 8.685477256774902, Uncertainty: 4.471219539642334
Epoch 106, Batch 2800/3125, Loss: 1.1112217903137207, Uncertainty: 1.3373825550079346
Epoch 7, Batch 600/3125, Loss: 10.069208145141602, Uncertainty: 5.149335861206055
Epoch 7, Batch 700/3125, Loss: 9.538965225219727, Uncertainty: 4.325453281402588
Epoch 106, Batch 2900/3125, Loss: 1.220606803894043, Uncertainty: 1.5391384363174438
Epoch 7, Batch 800/3125, Loss: 8.556854248046875, Uncertainty: 4.347287178039551
Epoch 106, Batch 3000/3125, Loss: 1.2674027681350708, Uncertainty: 1.4960920810699463
Epoch 7, Batch 900/3125, Loss: 9.6834077835083, Uncertainty: 4.777012825012207
Epoch 106, Batch 3100/3125, Loss: 1.1253676414489746, Uncertainty: 1.3690826892852783
Epoch 7, Batch 1000/3125, Loss: 8.660409927368164, Uncertainty: 5.19807243347168
Epoch 7, Batch 1100/3125, Loss: 10.396393775939941, Uncertainty: 5.757369041442871
Epoch 7, Batch 1200/3125, Loss: 9.14140510559082, Uncertainty: 4.8083271980285645
Epoch 7, Batch 1300/3125, Loss: 8.339178085327148, Uncertainty: 3.6948883533477783
Epoch 7, Batch 1400/3125, Loss: 9.495224952697754, Uncertainty: 5.452099323272705
Epoch 7, Batch 1500/3125, Loss: 9.677726745605469, Uncertainty: 5.625940799713135
Epoch 7, Batch 1600/3125, Loss: 9.094667434692383, Uncertainty: 4.446521282196045
Epoch 7, Batch 1700/3125, Loss: 8.84077262878418, Uncertainty: 4.8388776779174805

Training and Validation Results of Epoch 106:
================================
Training Loss: 0.9874610792732239, Training Uncertainty: 1.500075457763672, time: 205.04310154914856
Validation Loss: 0.864230924173999, Validation Uncertainty: 2.1683272339803787, time: 48.09755563735962
Number of predictions within uncertainty interval: 126565/200000 (63.28%)

Epoch 7, Batch 1800/3125, Loss: 9.027559280395508, Uncertainty: 4.674184799194336
Epoch 107, Batch 100/3125, Loss: 1.0244148969650269, Uncertainty: 1.2263188362121582
Epoch 7, Batch 1900/3125, Loss: 9.54452896118164, Uncertainty: 5.6667070388793945
Epoch 107, Batch 200/3125, Loss: 1.1914541721343994, Uncertainty: 1.5065408945083618
Epoch 7, Batch 2000/3125, Loss: 8.268009185791016, Uncertainty: 4.290892124176025
Epoch 107, Batch 300/3125, Loss: 1.3406651020050049, Uncertainty: 1.4050393104553223
Epoch 7, Batch 2100/3125, Loss: 8.86948013305664, Uncertainty: 4.596497535705566
Epoch 107, Batch 400/3125, Loss: 1.0894842147827148, Uncertainty: 1.3550008535385132
Epoch 7, Batch 2200/3125, Loss: 8.77702522277832, Uncertainty: 3.698431968688965
Epoch 107, Batch 500/3125, Loss: 1.2551339864730835, Uncertainty: 1.637571930885315
Epoch 7, Batch 2300/3125, Loss: 8.945548057556152, Uncertainty: 5.388866424560547
Epoch 107, Batch 600/3125, Loss: 1.390517234802246, Uncertainty: 1.5497021675109863
Epoch 7, Batch 2400/3125, Loss: 9.427663803100586, Uncertainty: 4.713047981262207
Epoch 107, Batch 700/3125, Loss: 1.1996734142303467, Uncertainty: 1.5309064388275146
Epoch 7, Batch 2500/3125, Loss: 9.144187927246094, Uncertainty: 4.7398295402526855
Epoch 107, Batch 800/3125, Loss: 1.2525599002838135, Uncertainty: 1.4881432056427002
Epoch 7, Batch 2600/3125, Loss: 9.035593032836914, Uncertainty: 5.059281349182129
Epoch 107, Batch 900/3125, Loss: 1.352039098739624, Uncertainty: 1.5744926929473877
Epoch 7, Batch 2700/3125, Loss: 8.33869457244873, Uncertainty: 4.190473556518555
Epoch 107, Batch 1000/3125, Loss: 1.0705769062042236, Uncertainty: 1.252903699874878
Epoch 7, Batch 2800/3125, Loss: 9.228723526000977, Uncertainty: 4.722469806671143
Epoch 7, Batch 2900/3125, Loss: 9.565680503845215, Uncertainty: 4.788736343383789
Epoch 107, Batch 1100/3125, Loss: 1.1345531940460205, Uncertainty: 1.4298040866851807
Epoch 7, Batch 3000/3125, Loss: 9.202417373657227, Uncertainty: 6.061244487762451
Epoch 107, Batch 1200/3125, Loss: 1.2844699621200562, Uncertainty: 1.6701093912124634
Epoch 7, Batch 3100/3125, Loss: 8.75946044921875, Uncertainty: 3.9675936698913574
Epoch 107, Batch 1300/3125, Loss: 1.2606130838394165, Uncertainty: 1.4509717226028442
Epoch 107, Batch 1400/3125, Loss: 1.1155190467834473, Uncertainty: 1.4464695453643799
Epoch 107, Batch 1500/3125, Loss: 1.3583056926727295, Uncertainty: 1.5841825008392334
Epoch 107, Batch 1600/3125, Loss: 1.037851333618164, Uncertainty: 1.2894951105117798
Epoch 107, Batch 1700/3125, Loss: 1.1299868822097778, Uncertainty: 1.4973351955413818
Epoch 107, Batch 1800/3125, Loss: 1.3351149559020996, Uncertainty: 1.8203253746032715
Epoch 107, Batch 1900/3125, Loss: 1.0354678630828857, Uncertainty: 1.446320652961731

Training and Validation Results of Epoch 7:
================================
Training Loss: 8.907261511383057, Training Uncertainty: 4.688941772079468, time: 194.7336699962616
Validation Loss: 8.70085763992251, Validation Uncertainty: 6.6286815475015075, time: 44.186819314956665
Number of predictions within uncertainty interval: 47412/200000 (23.71%)

Epoch 107, Batch 2000/3125, Loss: 1.238140344619751, Uncertainty: 1.4267001152038574
Epoch 8, Batch 100/3125, Loss: 10.258312225341797, Uncertainty: 7.084997177124023
Epoch 107, Batch 2100/3125, Loss: 1.3847264051437378, Uncertainty: 1.6020681858062744
Epoch 8, Batch 200/3125, Loss: 7.637150287628174, Uncertainty: 4.161831855773926
Epoch 107, Batch 2200/3125, Loss: 1.0123465061187744, Uncertainty: 1.267167091369629
Epoch 8, Batch 300/3125, Loss: 9.776392936706543, Uncertainty: 6.5923871994018555
Epoch 107, Batch 2300/3125, Loss: 1.2502423524856567, Uncertainty: 1.6196238994598389
Epoch 8, Batch 400/3125, Loss: 8.140116691589355, Uncertainty: 4.830883026123047
Epoch 107, Batch 2400/3125, Loss: 1.3065634965896606, Uncertainty: 1.6291260719299316
Epoch 8, Batch 500/3125, Loss: 8.398097038269043, Uncertainty: 4.107761859893799
Epoch 107, Batch 2500/3125, Loss: 1.117836356163025, Uncertainty: 1.328063726425171
Epoch 8, Batch 600/3125, Loss: 9.67346477508545, Uncertainty: 5.627695083618164
Epoch 107, Batch 2600/3125, Loss: 1.2326985597610474, Uncertainty: 1.607437252998352
Epoch 8, Batch 700/3125, Loss: 9.26571273803711, Uncertainty: 3.5072078704833984
Epoch 107, Batch 2700/3125, Loss: 1.3882100582122803, Uncertainty: 1.8653664588928223
Epoch 8, Batch 800/3125, Loss: 8.547079086303711, Uncertainty: 4.233872890472412
Epoch 107, Batch 2800/3125, Loss: 1.1463162899017334, Uncertainty: 1.3081225156784058
Epoch 8, Batch 900/3125, Loss: 9.311281204223633, Uncertainty: 4.005000114440918
Epoch 107, Batch 2900/3125, Loss: 1.233346700668335, Uncertainty: 1.658812403678894
Epoch 8, Batch 1000/3125, Loss: 8.37870979309082, Uncertainty: 3.5131547451019287
Epoch 107, Batch 3000/3125, Loss: 1.2660679817199707, Uncertainty: 1.4999463558197021
Epoch 8, Batch 1100/3125, Loss: 9.113393783569336, Uncertainty: 4.325579643249512
Epoch 107, Batch 3100/3125, Loss: 1.1383271217346191, Uncertainty: 1.4048120975494385
Epoch 8, Batch 1200/3125, Loss: 8.79726791381836, Uncertainty: 4.568561553955078
Epoch 8, Batch 1300/3125, Loss: 8.144109725952148, Uncertainty: 3.6833953857421875
Epoch 8, Batch 1400/3125, Loss: 8.67017936706543, Uncertainty: 4.334620475769043
Epoch 8, Batch 1500/3125, Loss: 9.463737487792969, Uncertainty: 5.260488986968994
Epoch 8, Batch 1600/3125, Loss: 8.821702003479004, Uncertainty: 4.347818374633789
Epoch 8, Batch 1700/3125, Loss: 8.446287155151367, Uncertainty: 4.655040740966797
Epoch 8, Batch 1800/3125, Loss: 8.437084197998047, Uncertainty: 3.8314321041107178
Epoch 8, Batch 1900/3125, Loss: 9.140734672546387, Uncertainty: 4.129915237426758

Training and Validation Results of Epoch 107:
================================
Training Loss: 0.9804224696922302, Training Uncertainty: 1.5065548922348022, time: 206.72132015228271
Validation Loss: 0.8523328279900124, Validation Uncertainty: 2.182487138854268, time: 48.05996870994568
Number of predictions within uncertainty interval: 128446/200000 (64.22%)

Epoch 8, Batch 2000/3125, Loss: 8.577110290527344, Uncertainty: 4.35414457321167
Epoch 108, Batch 100/3125, Loss: 1.0059624910354614, Uncertainty: 1.224440097808838
Epoch 8, Batch 2100/3125, Loss: 8.583894729614258, Uncertainty: 4.612307548522949
Epoch 108, Batch 200/3125, Loss: 1.216193437576294, Uncertainty: 1.583817720413208
Epoch 8, Batch 2200/3125, Loss: 8.372140884399414, Uncertainty: 3.371901273727417
Epoch 108, Batch 300/3125, Loss: 1.298018455505371, Uncertainty: 1.5257147550582886
Epoch 8, Batch 2300/3125, Loss: 7.9298906326293945, Uncertainty: 4.660860538482666
Epoch 8, Batch 2400/3125, Loss: 9.042304992675781, Uncertainty: 4.73453426361084
Epoch 108, Batch 400/3125, Loss: 1.0781937837600708, Uncertainty: 1.3655877113342285
Epoch 8, Batch 2500/3125, Loss: 8.760101318359375, Uncertainty: 4.199690818786621
Epoch 108, Batch 500/3125, Loss: 1.2684199810028076, Uncertainty: 1.6725655794143677
Epoch 8, Batch 2600/3125, Loss: 8.846829414367676, Uncertainty: 4.526970863342285
Epoch 108, Batch 600/3125, Loss: 1.3261220455169678, Uncertainty: 1.446218490600586
Epoch 8, Batch 2700/3125, Loss: 8.090147972106934, Uncertainty: 4.308815002441406
Epoch 108, Batch 700/3125, Loss: 1.1719306707382202, Uncertainty: 1.465391755104065
Epoch 8, Batch 2800/3125, Loss: 8.6358642578125, Uncertainty: 4.528484344482422
Epoch 108, Batch 800/3125, Loss: 1.2983052730560303, Uncertainty: 1.6510813236236572
Epoch 8, Batch 2900/3125, Loss: 9.08978271484375, Uncertainty: 4.675606727600098
Epoch 108, Batch 900/3125, Loss: 1.3161027431488037, Uncertainty: 1.6122119426727295
Epoch 8, Batch 3000/3125, Loss: 9.06082820892334, Uncertainty: 5.526412010192871
Epoch 108, Batch 1000/3125, Loss: 1.0860639810562134, Uncertainty: 1.3392397165298462
Epoch 8, Batch 3100/3125, Loss: 8.361800193786621, Uncertainty: 4.280138969421387
Epoch 108, Batch 1100/3125, Loss: 1.2562764883041382, Uncertainty: 1.7652455568313599
Epoch 108, Batch 1200/3125, Loss: 1.2797504663467407, Uncertainty: 1.5714950561523438
Epoch 108, Batch 1300/3125, Loss: 1.129725456237793, Uncertainty: 1.2070093154907227
Epoch 108, Batch 1400/3125, Loss: 1.196195363998413, Uncertainty: 1.4389548301696777
Epoch 108, Batch 1500/3125, Loss: 1.3432116508483887, Uncertainty: 1.5472668409347534
Epoch 108, Batch 1600/3125, Loss: 1.0091454982757568, Uncertainty: 1.2500274181365967
Epoch 108, Batch 1700/3125, Loss: 1.1350808143615723, Uncertainty: 1.5369505882263184

Training and Validation Results of Epoch 8:
================================
Training Loss: 8.524718247833253, Training Uncertainty: 4.643574007034302, time: 193.2158179283142
Validation Loss: 8.313165425644506, Validation Uncertainty: 7.491541650898926, time: 44.65630078315735
Number of predictions within uncertainty interval: 54776/200000 (27.39%)

Epoch 108, Batch 1800/3125, Loss: 1.312437891960144, Uncertainty: 1.6879615783691406
Epoch 9, Batch 100/3125, Loss: 8.684723854064941, Uncertainty: 3.8687403202056885
Epoch 108, Batch 1900/3125, Loss: 1.096035122871399, Uncertainty: 1.2785441875457764
Epoch 9, Batch 200/3125, Loss: 7.487892150878906, Uncertainty: 5.20850133895874
Epoch 108, Batch 2000/3125, Loss: 1.178131103515625, Uncertainty: 1.435014009475708
Epoch 9, Batch 300/3125, Loss: 8.530405044555664, Uncertainty: 4.462641716003418
Epoch 108, Batch 2100/3125, Loss: 1.3466088771820068, Uncertainty: 1.5137425661087036
Epoch 9, Batch 400/3125, Loss: 7.708399772644043, Uncertainty: 4.542975425720215
Epoch 108, Batch 2200/3125, Loss: 0.9877352714538574, Uncertainty: 1.2293858528137207
Epoch 9, Batch 500/3125, Loss: 7.98685359954834, Uncertainty: 4.494672775268555
Epoch 108, Batch 2300/3125, Loss: 1.2273483276367188, Uncertainty: 1.5992761850357056
Epoch 9, Batch 600/3125, Loss: 9.324560165405273, Uncertainty: 7.177931785583496
Epoch 108, Batch 2400/3125, Loss: 1.2978951930999756, Uncertainty: 1.662641167640686
Epoch 9, Batch 700/3125, Loss: 8.834062576293945, Uncertainty: 4.297522068023682
Epoch 108, Batch 2500/3125, Loss: 1.1680269241333008, Uncertainty: 1.4809542894363403
Epoch 9, Batch 800/3125, Loss: 8.047886848449707, Uncertainty: 4.414274215698242
Epoch 108, Batch 2600/3125, Loss: 1.1879897117614746, Uncertainty: 1.4088492393493652
Epoch 9, Batch 900/3125, Loss: 8.793832778930664, Uncertainty: 4.445573806762695
Epoch 108, Batch 2700/3125, Loss: 1.3310067653656006, Uncertainty: 1.7434487342834473
Epoch 9, Batch 1000/3125, Loss: 8.122705459594727, Uncertainty: 4.596155166625977
Epoch 108, Batch 2800/3125, Loss: 1.0778486728668213, Uncertainty: 1.307645559310913
Epoch 9, Batch 1100/3125, Loss: 8.74661636352539, Uncertainty: 4.612550258636475
Epoch 108, Batch 2900/3125, Loss: 1.1951713562011719, Uncertainty: 1.5543127059936523
Epoch 9, Batch 1200/3125, Loss: 8.509572982788086, Uncertainty: 5.4449992179870605
Epoch 108, Batch 3000/3125, Loss: 1.2488126754760742, Uncertainty: 1.4824776649475098
Epoch 9, Batch 1300/3125, Loss: 8.011669158935547, Uncertainty: 3.969444513320923
Epoch 108, Batch 3100/3125, Loss: 1.1427690982818604, Uncertainty: 1.4129414558410645
Epoch 9, Batch 1400/3125, Loss: 8.53207778930664, Uncertainty: 5.077709197998047
Epoch 9, Batch 1500/3125, Loss: 9.070253372192383, Uncertainty: 5.695435523986816
Epoch 9, Batch 1600/3125, Loss: 8.462111473083496, Uncertainty: 5.670974254608154
Epoch 9, Batch 1700/3125, Loss: 8.323840141296387, Uncertainty: 5.951807975769043
Epoch 9, Batch 1800/3125, Loss: 7.933010578155518, Uncertainty: 3.995288848876953
Epoch 9, Batch 1900/3125, Loss: 8.804654121398926, Uncertainty: 4.957097053527832
Epoch 9, Batch 2000/3125, Loss: 7.760843276977539, Uncertainty: 4.659550189971924
Epoch 9, Batch 2100/3125, Loss: 8.031120300292969, Uncertainty: 4.288425445556641

Training and Validation Results of Epoch 108:
================================
Training Loss: 0.9734137316322327, Training Uncertainty: 1.4997350658416748, time: 203.89954161643982
Validation Loss: 0.8506564345506146, Validation Uncertainty: 2.1327017175267113, time: 47.19273900985718
Number of predictions within uncertainty interval: 126169/200000 (63.08%)

Epoch 9, Batch 2200/3125, Loss: 7.957161903381348, Uncertainty: 3.4068715572357178
Epoch 109, Batch 100/3125, Loss: 1.006857991218567, Uncertainty: 1.2156959772109985
Epoch 9, Batch 2300/3125, Loss: 7.543187618255615, Uncertainty: 5.185093879699707
Epoch 9, Batch 2400/3125, Loss: 8.600790977478027, Uncertainty: 4.7550554275512695
Epoch 109, Batch 200/3125, Loss: 1.2220518589019775, Uncertainty: 1.5870256423950195
Epoch 9, Batch 2500/3125, Loss: 8.228527069091797, Uncertainty: 4.558209419250488
Epoch 109, Batch 300/3125, Loss: 1.2818529605865479, Uncertainty: 1.4949902296066284
Epoch 9, Batch 2600/3125, Loss: 8.24574089050293, Uncertainty: 4.7111992835998535
Epoch 109, Batch 400/3125, Loss: 1.1214749813079834, Uncertainty: 1.3563001155853271
Epoch 9, Batch 2700/3125, Loss: 7.4553422927856445, Uncertainty: 4.118630409240723
Epoch 109, Batch 500/3125, Loss: 1.1180312633514404, Uncertainty: 1.3891929388046265
Epoch 9, Batch 2800/3125, Loss: 8.256898880004883, Uncertainty: 4.885891914367676
Epoch 109, Batch 600/3125, Loss: 1.321428894996643, Uncertainty: 1.4504796266555786
Epoch 9, Batch 2900/3125, Loss: 8.591727256774902, Uncertainty: 5.258760452270508
Epoch 109, Batch 700/3125, Loss: 1.1764864921569824, Uncertainty: 1.4977238178253174
Epoch 9, Batch 3000/3125, Loss: 8.331100463867188, Uncertainty: 5.922794342041016
Epoch 109, Batch 800/3125, Loss: 1.3048770427703857, Uncertainty: 1.5311604738235474
Epoch 9, Batch 3100/3125, Loss: 8.366844177246094, Uncertainty: 4.095294952392578
Epoch 109, Batch 900/3125, Loss: 1.3410100936889648, Uncertainty: 1.7330408096313477
Epoch 109, Batch 1000/3125, Loss: 1.0735390186309814, Uncertainty: 1.313713550567627
Epoch 109, Batch 1100/3125, Loss: 1.2093589305877686, Uncertainty: 1.6016316413879395
Epoch 109, Batch 1200/3125, Loss: 1.3523015975952148, Uncertainty: 1.9514906406402588
Epoch 109, Batch 1300/3125, Loss: 1.0729354619979858, Uncertainty: 1.222546935081482
Epoch 109, Batch 1400/3125, Loss: 1.201625108718872, Uncertainty: 1.498640537261963
Epoch 109, Batch 1500/3125, Loss: 1.3132219314575195, Uncertainty: 1.4569008350372314

Training and Validation Results of Epoch 9:
================================
Training Loss: 8.067210520629883, Training Uncertainty: 4.792701206054687, time: 192.9416642189026
Validation Loss: 7.669257121927598, Validation Uncertainty: 7.367808466372282, time: 43.628687381744385
Number of predictions within uncertainty interval: 58904/200000 (29.45%)

Epoch 109, Batch 1600/3125, Loss: 0.9988396167755127, Uncertainty: 1.2486402988433838
Epoch 10, Batch 100/3125, Loss: 9.107275009155273, Uncertainty: 4.80677604675293
Epoch 109, Batch 1700/3125, Loss: 1.1807055473327637, Uncertainty: 1.6407575607299805
Epoch 10, Batch 200/3125, Loss: 7.274089336395264, Uncertainty: 4.612592697143555
Epoch 109, Batch 1800/3125, Loss: 1.3820672035217285, Uncertainty: 1.9559649229049683
Epoch 10, Batch 300/3125, Loss: 8.184309959411621, Uncertainty: 4.722464561462402
Epoch 109, Batch 1900/3125, Loss: 1.0117077827453613, Uncertainty: 1.3239771127700806
Epoch 10, Batch 400/3125, Loss: 7.376571178436279, Uncertainty: 4.369102954864502
Epoch 109, Batch 2000/3125, Loss: 1.2185523509979248, Uncertainty: 1.3801554441452026
Epoch 10, Batch 500/3125, Loss: 7.460422992706299, Uncertainty: 4.594670295715332
Epoch 109, Batch 2100/3125, Loss: 1.373733401298523, Uncertainty: 1.5336511135101318
Epoch 10, Batch 600/3125, Loss: 8.025443077087402, Uncertainty: 4.877617359161377
Epoch 109, Batch 2200/3125, Loss: 0.9877058267593384, Uncertainty: 1.2114598751068115
Epoch 10, Batch 700/3125, Loss: 8.316910743713379, Uncertainty: 4.5436692237854
Epoch 109, Batch 2300/3125, Loss: 1.2291436195373535, Uncertainty: 1.532228946685791
Epoch 10, Batch 800/3125, Loss: 7.566810607910156, Uncertainty: 4.68665885925293
Epoch 109, Batch 2400/3125, Loss: 1.2485748529434204, Uncertainty: 1.5397577285766602
Epoch 10, Batch 900/3125, Loss: 8.151037216186523, Uncertainty: 5.444705963134766
Epoch 109, Batch 2500/3125, Loss: 1.2203319072723389, Uncertainty: 1.5823999643325806
Epoch 10, Batch 1000/3125, Loss: 7.617056846618652, Uncertainty: 5.2654829025268555
Epoch 10, Batch 1100/3125, Loss: 8.340108871459961, Uncertainty: 6.089877605438232
Epoch 109, Batch 2600/3125, Loss: 1.1561875343322754, Uncertainty: 1.3955738544464111
Epoch 10, Batch 1200/3125, Loss: 7.662485122680664, Uncertainty: 4.699532985687256
Epoch 109, Batch 2700/3125, Loss: 1.3287696838378906, Uncertainty: 1.7475354671478271
Epoch 10, Batch 1300/3125, Loss: 7.738825798034668, Uncertainty: 3.8183999061584473
Epoch 109, Batch 2800/3125, Loss: 1.0878770351409912, Uncertainty: 1.3114328384399414
Epoch 10, Batch 1400/3125, Loss: 7.6944427490234375, Uncertainty: 4.8683013916015625
Epoch 109, Batch 2900/3125, Loss: 1.1913813352584839, Uncertainty: 1.4961328506469727
Epoch 10, Batch 1500/3125, Loss: 8.42418098449707, Uncertainty: 4.8066630363464355
Epoch 109, Batch 3000/3125, Loss: 1.2296797037124634, Uncertainty: 1.450484275817871
Epoch 10, Batch 1600/3125, Loss: 7.489217758178711, Uncertainty: 4.979515552520752
Epoch 109, Batch 3100/3125, Loss: 1.1194286346435547, Uncertainty: 1.3629860877990723
Epoch 10, Batch 1700/3125, Loss: 7.889588356018066, Uncertainty: 5.27583122253418
Epoch 10, Batch 1800/3125, Loss: 8.33443832397461, Uncertainty: 5.755369186401367
Epoch 10, Batch 1900/3125, Loss: 9.044795036315918, Uncertainty: 5.422302722930908
Epoch 10, Batch 2000/3125, Loss: 7.149689674377441, Uncertainty: 4.5597124099731445
Epoch 10, Batch 2100/3125, Loss: 7.6157546043396, Uncertainty: 4.377064228057861
Epoch 10, Batch 2200/3125, Loss: 7.730581760406494, Uncertainty: 4.591882705688477
Epoch 10, Batch 2300/3125, Loss: 7.391993999481201, Uncertainty: 5.265098571777344
Epoch 10, Batch 2400/3125, Loss: 8.421077728271484, Uncertainty: 5.734489440917969

Training and Validation Results of Epoch 109:
================================
Training Loss: 0.9695241091537475, Training Uncertainty: 1.4866733808135986, time: 202.86491703987122
Validation Loss: 0.843230609927336, Validation Uncertainty: 2.141114117239442, time: 48.100788831710815
Number of predictions within uncertainty interval: 127225/200000 (63.61%)

Epoch 10, Batch 2500/3125, Loss: 7.889813423156738, Uncertainty: 4.525819778442383
Epoch 110, Batch 100/3125, Loss: 0.996816873550415, Uncertainty: 1.194838285446167
Epoch 10, Batch 2600/3125, Loss: 7.792241096496582, Uncertainty: 4.850033760070801
Epoch 110, Batch 200/3125, Loss: 1.1785789728164673, Uncertainty: 1.5169041156768799
Epoch 10, Batch 2700/3125, Loss: 6.978370666503906, Uncertainty: 4.253133773803711
Epoch 110, Batch 300/3125, Loss: 1.2996413707733154, Uncertainty: 1.5076926946640015
Epoch 10, Batch 2800/3125, Loss: 7.460667610168457, Uncertainty: 4.397478103637695
Epoch 110, Batch 400/3125, Loss: 1.1622414588928223, Uncertainty: 1.497571349143982
Epoch 10, Batch 2900/3125, Loss: 8.013509750366211, Uncertainty: 5.045564651489258
Epoch 110, Batch 500/3125, Loss: 1.117479681968689, Uncertainty: 1.4207334518432617
Epoch 10, Batch 3000/3125, Loss: 7.817111015319824, Uncertainty: 5.221185684204102
Epoch 110, Batch 600/3125, Loss: 1.3474600315093994, Uncertainty: 1.4450634717941284
Epoch 10, Batch 3100/3125, Loss: 8.163215637207031, Uncertainty: 6.004424095153809
Epoch 110, Batch 700/3125, Loss: 1.1695410013198853, Uncertainty: 1.3946926593780518
Epoch 110, Batch 800/3125, Loss: 1.3312026262283325, Uncertainty: 1.737818717956543
Epoch 110, Batch 900/3125, Loss: 1.3559503555297852, Uncertainty: 1.5515453815460205
Epoch 110, Batch 1000/3125, Loss: 1.0544419288635254, Uncertainty: 1.2895574569702148
Epoch 110, Batch 1100/3125, Loss: 1.1984905004501343, Uncertainty: 1.5479239225387573
Epoch 110, Batch 1200/3125, Loss: 1.25052809715271, Uncertainty: 1.559256672859192
Epoch 110, Batch 1300/3125, Loss: 1.108909010887146, Uncertainty: 1.2394847869873047

Training and Validation Results of Epoch 10:
================================
Training Loss: 7.565180713348389, Training Uncertainty: 4.94238270652771, time: 191.73683071136475
Validation Loss: 7.136726809889459, Validation Uncertainty: 7.722362892706986, time: 44.968095779418945
Number of predictions within uncertainty interval: 65678/200000 (32.84%)

Epoch 110, Batch 1400/3125, Loss: 1.1476998329162598, Uncertainty: 1.5142946243286133
Epoch 11, Batch 100/3125, Loss: 7.866214752197266, Uncertainty: 4.5555219650268555
Epoch 110, Batch 1500/3125, Loss: 1.3085505962371826, Uncertainty: 1.4814655780792236
Epoch 11, Batch 200/3125, Loss: 7.011030197143555, Uncertainty: 4.7743425369262695
Epoch 110, Batch 1600/3125, Loss: 1.0049879550933838, Uncertainty: 1.281485915184021
Epoch 11, Batch 300/3125, Loss: 8.030220031738281, Uncertainty: 5.516294479370117
Epoch 110, Batch 1700/3125, Loss: 1.136400818824768, Uncertainty: 1.5110453367233276
Epoch 11, Batch 400/3125, Loss: 6.7717132568359375, Uncertainty: 4.449161052703857
Epoch 110, Batch 1800/3125, Loss: 1.338405966758728, Uncertainty: 1.795480489730835
Epoch 11, Batch 500/3125, Loss: 7.210838794708252, Uncertainty: 5.653547286987305
Epoch 110, Batch 1900/3125, Loss: 1.0312155485153198, Uncertainty: 1.4342707395553589
Epoch 11, Batch 600/3125, Loss: 7.505365371704102, Uncertainty: 4.662224769592285
Epoch 110, Batch 2000/3125, Loss: 1.1282811164855957, Uncertainty: 1.3985655307769775
Epoch 11, Batch 700/3125, Loss: 7.812915802001953, Uncertainty: 4.223211288452148
Epoch 110, Batch 2100/3125, Loss: 1.3462411165237427, Uncertainty: 1.5234335660934448
Epoch 11, Batch 800/3125, Loss: 7.271631240844727, Uncertainty: 5.104729175567627
Epoch 11, Batch 900/3125, Loss: 7.60918664932251, Uncertainty: 4.920537948608398
Epoch 110, Batch 2200/3125, Loss: 0.9911741018295288, Uncertainty: 1.2406606674194336
Epoch 11, Batch 1000/3125, Loss: 7.558295249938965, Uncertainty: 7.636471748352051
Epoch 110, Batch 2300/3125, Loss: 1.2691816091537476, Uncertainty: 1.6579097509384155
Epoch 11, Batch 1100/3125, Loss: 7.5067138671875, Uncertainty: 4.422065734863281
Epoch 110, Batch 2400/3125, Loss: 1.2717816829681396, Uncertainty: 1.5519204139709473
Epoch 11, Batch 1200/3125, Loss: 7.128308296203613, Uncertainty: 5.144768714904785
Epoch 110, Batch 2500/3125, Loss: 1.1670348644256592, Uncertainty: 1.6597366333007812
Epoch 11, Batch 1300/3125, Loss: 6.885934829711914, Uncertainty: 4.0243048667907715
Epoch 110, Batch 2600/3125, Loss: 1.2688887119293213, Uncertainty: 1.5841304063796997
Epoch 11, Batch 1400/3125, Loss: 7.1042375564575195, Uncertainty: 4.800239562988281
Epoch 110, Batch 2700/3125, Loss: 1.3355302810668945, Uncertainty: 1.72999906539917
Epoch 11, Batch 1500/3125, Loss: 7.547856330871582, Uncertainty: 4.700619697570801
Epoch 110, Batch 2800/3125, Loss: 1.0794594287872314, Uncertainty: 1.2775707244873047
Epoch 11, Batch 1600/3125, Loss: 7.010320663452148, Uncertainty: 4.972649097442627
Epoch 110, Batch 2900/3125, Loss: 1.206392526626587, Uncertainty: 1.48128342628479
Epoch 11, Batch 1700/3125, Loss: 7.232542991638184, Uncertainty: 5.258716583251953
Epoch 110, Batch 3000/3125, Loss: 1.2320241928100586, Uncertainty: 1.4642667770385742
Epoch 11, Batch 1800/3125, Loss: 7.159793853759766, Uncertainty: 4.42267370223999
Epoch 110, Batch 3100/3125, Loss: 1.100527286529541, Uncertainty: 1.2938774824142456
Epoch 11, Batch 1900/3125, Loss: 8.378459930419922, Uncertainty: 5.207369804382324
Epoch 11, Batch 2000/3125, Loss: 6.8988037109375, Uncertainty: 6.621973991394043
Epoch 11, Batch 2100/3125, Loss: 7.009565830230713, Uncertainty: 4.815895080566406
Epoch 11, Batch 2200/3125, Loss: 7.014621734619141, Uncertainty: 4.795549392700195
Epoch 11, Batch 2300/3125, Loss: 6.948624610900879, Uncertainty: 4.491373062133789
Epoch 11, Batch 2400/3125, Loss: 7.487029075622559, Uncertainty: 5.071401119232178
Epoch 11, Batch 2500/3125, Loss: 7.2783050537109375, Uncertainty: 4.1051716804504395
Epoch 11, Batch 2600/3125, Loss: 7.77921724319458, Uncertainty: 4.3772783279418945

Training and Validation Results of Epoch 110:
================================
Training Loss: 0.9636716820335388, Training Uncertainty: 1.4698877551269531, time: 205.72101211547852
Validation Loss: 0.8404820665831456, Validation Uncertainty: 2.150112929246615, time: 47.881348848342896
Number of predictions within uncertainty interval: 128121/200000 (64.06%)

Epoch 11, Batch 2700/3125, Loss: 6.674404144287109, Uncertainty: 4.942880630493164
Epoch 111, Batch 100/3125, Loss: 0.9992341995239258, Uncertainty: 1.1845693588256836
Epoch 11, Batch 2800/3125, Loss: 7.212283611297607, Uncertainty: 5.390933990478516
Epoch 111, Batch 200/3125, Loss: 1.1657180786132812, Uncertainty: 1.4494102001190186
Epoch 11, Batch 2900/3125, Loss: 7.46426248550415, Uncertainty: 4.8471832275390625
Epoch 11, Batch 3000/3125, Loss: 7.378546714782715, Uncertainty: 4.68900203704834
Epoch 111, Batch 300/3125, Loss: 1.2901246547698975, Uncertainty: 1.4348912239074707
Epoch 11, Batch 3100/3125, Loss: 7.140614986419678, Uncertainty: 4.340723991394043
Epoch 111, Batch 400/3125, Loss: 1.0882601737976074, Uncertainty: 1.3467092514038086
Epoch 111, Batch 500/3125, Loss: 1.2247276306152344, Uncertainty: 1.7111741304397583
Epoch 111, Batch 600/3125, Loss: 1.324007272720337, Uncertainty: 1.5029693841934204
Epoch 111, Batch 700/3125, Loss: 1.165793538093567, Uncertainty: 1.3510829210281372
Epoch 111, Batch 800/3125, Loss: 1.3790514469146729, Uncertainty: 1.8235101699829102
Epoch 111, Batch 900/3125, Loss: 1.3887014389038086, Uncertainty: 1.532204270362854
Epoch 111, Batch 1000/3125, Loss: 1.069297432899475, Uncertainty: 1.2799406051635742

Training and Validation Results of Epoch 11:
================================
Training Loss: 7.010508678131104, Training Uncertainty: 4.974653400878906, time: 194.19825410842896
Validation Loss: 6.5934784266040145, Validation Uncertainty: 7.536002108508058, time: 44.56210207939148
Number of predictions within uncertainty interval: 70221/200000 (35.11%)

Epoch 111, Batch 1100/3125, Loss: 1.1733109951019287, Uncertainty: 1.5964391231536865
Epoch 12, Batch 100/3125, Loss: 7.288405418395996, Uncertainty: 4.640903949737549
Epoch 111, Batch 1200/3125, Loss: 1.324593424797058, Uncertainty: 1.5393836498260498
Epoch 12, Batch 200/3125, Loss: 6.834780693054199, Uncertainty: 4.579468727111816
Epoch 111, Batch 1300/3125, Loss: 1.1085526943206787, Uncertainty: 1.3719346523284912
Epoch 12, Batch 300/3125, Loss: 6.844155311584473, Uncertainty: 4.511749267578125
Epoch 111, Batch 1400/3125, Loss: 1.1317025423049927, Uncertainty: 1.3961477279663086
Epoch 12, Batch 400/3125, Loss: 6.6625590324401855, Uncertainty: 4.643557548522949
Epoch 111, Batch 1500/3125, Loss: 1.2789218425750732, Uncertainty: 1.4223103523254395
Epoch 12, Batch 500/3125, Loss: 6.532106399536133, Uncertainty: 4.195249080657959
Epoch 111, Batch 1600/3125, Loss: 1.0200402736663818, Uncertainty: 1.2756516933441162
Epoch 12, Batch 600/3125, Loss: 7.1939005851745605, Uncertainty: 4.504949569702148
Epoch 111, Batch 1700/3125, Loss: 1.1626291275024414, Uncertainty: 1.5739847421646118
Epoch 12, Batch 700/3125, Loss: 7.3821306228637695, Uncertainty: 4.5576982498168945
Epoch 111, Batch 1800/3125, Loss: 1.2891044616699219, Uncertainty: 1.7050704956054688
Epoch 12, Batch 800/3125, Loss: 6.780097007751465, Uncertainty: 4.643571376800537
Epoch 111, Batch 1900/3125, Loss: 0.9758516550064087, Uncertainty: 1.282006025314331
Epoch 12, Batch 900/3125, Loss: 7.177196502685547, Uncertainty: 6.2593560218811035
Epoch 111, Batch 2000/3125, Loss: 1.1292717456817627, Uncertainty: 1.3980498313903809
Epoch 12, Batch 1000/3125, Loss: 6.998141288757324, Uncertainty: 7.703993797302246
Epoch 111, Batch 2100/3125, Loss: 1.4113644361495972, Uncertainty: 1.6607232093811035
Epoch 12, Batch 1100/3125, Loss: 6.9217376708984375, Uncertainty: 4.542529106140137
Epoch 111, Batch 2200/3125, Loss: 1.0197407007217407, Uncertainty: 1.2573158740997314
Epoch 12, Batch 1200/3125, Loss: 7.061007022857666, Uncertainty: 5.999063014984131
Epoch 111, Batch 2300/3125, Loss: 1.2166041135787964, Uncertainty: 1.523087501525879
Epoch 12, Batch 1300/3125, Loss: 6.612805366516113, Uncertainty: 4.363886833190918
Epoch 111, Batch 2400/3125, Loss: 1.560389518737793, Uncertainty: 2.534940719604492
Epoch 12, Batch 1400/3125, Loss: 6.6222310066223145, Uncertainty: 4.172187805175781
Epoch 111, Batch 2500/3125, Loss: 1.0446205139160156, Uncertainty: 1.313277244567871
Epoch 12, Batch 1500/3125, Loss: 6.868852615356445, Uncertainty: 4.411637306213379
Epoch 111, Batch 2600/3125, Loss: 1.2688980102539062, Uncertainty: 1.6179404258728027
Epoch 12, Batch 1600/3125, Loss: 6.956686019897461, Uncertainty: 4.737818241119385
Epoch 111, Batch 2700/3125, Loss: 1.3145846128463745, Uncertainty: 1.6994898319244385
Epoch 12, Batch 1700/3125, Loss: 6.759584426879883, Uncertainty: 4.7895379066467285
Epoch 111, Batch 2800/3125, Loss: 1.0898902416229248, Uncertainty: 1.3378044366836548
Epoch 12, Batch 1800/3125, Loss: 7.136811256408691, Uncertainty: 5.881627559661865
Epoch 111, Batch 2900/3125, Loss: 1.195049524307251, Uncertainty: 1.4966000318527222
Epoch 12, Batch 1900/3125, Loss: 7.69508171081543, Uncertainty: 5.822643280029297
Epoch 111, Batch 3000/3125, Loss: 1.2661503553390503, Uncertainty: 1.4919283390045166
Epoch 12, Batch 2000/3125, Loss: 6.316229820251465, Uncertainty: 5.037387371063232
Epoch 111, Batch 3100/3125, Loss: 1.1045050621032715, Uncertainty: 1.3664178848266602
Epoch 12, Batch 2100/3125, Loss: 6.67140007019043, Uncertainty: 5.667603969573975
Epoch 12, Batch 2200/3125, Loss: 6.352721691131592, Uncertainty: 4.166411399841309
Epoch 12, Batch 2300/3125, Loss: 6.828202247619629, Uncertainty: 5.061223030090332
Epoch 12, Batch 2400/3125, Loss: 7.867936611175537, Uncertainty: 5.998752117156982
Epoch 12, Batch 2500/3125, Loss: 6.580350875854492, Uncertainty: 4.56819486618042
Epoch 12, Batch 2600/3125, Loss: 7.293911933898926, Uncertainty: 4.086577892303467
Epoch 12, Batch 2700/3125, Loss: 6.588237762451172, Uncertainty: 6.129655838012695
Epoch 12, Batch 2800/3125, Loss: 6.619032859802246, Uncertainty: 5.619807720184326

Training and Validation Results of Epoch 111:
================================
Training Loss: 0.9570988043022156, Training Uncertainty: 1.4759561429595947, time: 203.7811677455902
Validation Loss: 0.8416600312723224, Validation Uncertainty: 2.094664418788822, time: 47.22842073440552
Number of predictions within uncertainty interval: 126457/200000 (63.23%)

Epoch 12, Batch 2900/3125, Loss: 6.921088218688965, Uncertainty: 4.8625946044921875
Epoch 112, Batch 100/3125, Loss: 0.9776489734649658, Uncertainty: 1.173818826675415
Epoch 12, Batch 3000/3125, Loss: 6.52706241607666, Uncertainty: 4.297364711761475
Epoch 112, Batch 200/3125, Loss: 1.1785573959350586, Uncertainty: 1.4738796949386597
Epoch 12, Batch 3100/3125, Loss: 6.635509490966797, Uncertainty: 4.657284736633301
Epoch 112, Batch 300/3125, Loss: 1.2675613164901733, Uncertainty: 1.482250690460205
Epoch 112, Batch 400/3125, Loss: 1.1317791938781738, Uncertainty: 1.392558217048645
Epoch 112, Batch 500/3125, Loss: 1.111466407775879, Uncertainty: 1.3802576065063477
Epoch 112, Batch 600/3125, Loss: 1.3685004711151123, Uncertainty: 1.6051421165466309
Epoch 112, Batch 700/3125, Loss: 1.126420021057129, Uncertainty: 1.3534014225006104
Epoch 112, Batch 800/3125, Loss: 1.2208070755004883, Uncertainty: 1.4264273643493652
Epoch 112, Batch 900/3125, Loss: 1.3108632564544678, Uncertainty: 1.6666827201843262

Training and Validation Results of Epoch 12:
================================
Training Loss: 6.522936371612549, Training Uncertainty: 4.935031226425171, time: 194.14488339424133
Validation Loss: 6.183050078809109, Validation Uncertainty: 7.049194621308075, time: 44.35561966896057
Number of predictions within uncertainty interval: 69377/200000 (34.69%)

Epoch 112, Batch 1000/3125, Loss: 1.0463355779647827, Uncertainty: 1.2281363010406494
Epoch 13, Batch 100/3125, Loss: 6.691206932067871, Uncertainty: 4.292201995849609
Epoch 112, Batch 1100/3125, Loss: 1.1600158214569092, Uncertainty: 1.5880804061889648
Epoch 13, Batch 200/3125, Loss: 6.399874210357666, Uncertainty: 4.116933822631836
Epoch 112, Batch 1200/3125, Loss: 1.2387028932571411, Uncertainty: 1.5183897018432617
Epoch 13, Batch 300/3125, Loss: 6.485785484313965, Uncertainty: 4.749962329864502
Epoch 112, Batch 1300/3125, Loss: 1.0605669021606445, Uncertainty: 1.2766512632369995
Epoch 13, Batch 400/3125, Loss: 6.588022232055664, Uncertainty: 6.3411545753479
Epoch 112, Batch 1400/3125, Loss: 1.1414029598236084, Uncertainty: 1.431924819946289
Epoch 13, Batch 500/3125, Loss: 6.644344329833984, Uncertainty: 4.649304389953613
Epoch 112, Batch 1500/3125, Loss: 1.2661021947860718, Uncertainty: 1.3489649295806885
Epoch 13, Batch 600/3125, Loss: 6.614489555358887, Uncertainty: 4.566760063171387
Epoch 112, Batch 1600/3125, Loss: 1.0195927619934082, Uncertainty: 1.3249353170394897
Epoch 13, Batch 700/3125, Loss: 6.815554618835449, Uncertainty: 4.395446300506592
Epoch 112, Batch 1700/3125, Loss: 1.2037074565887451, Uncertainty: 1.7721428871154785
Epoch 13, Batch 800/3125, Loss: 6.417518615722656, Uncertainty: 4.055776119232178
Epoch 112, Batch 1800/3125, Loss: 1.2877252101898193, Uncertainty: 1.685160517692566
Epoch 13, Batch 900/3125, Loss: 6.451842308044434, Uncertainty: 4.6053242683410645
Epoch 112, Batch 1900/3125, Loss: 1.0065257549285889, Uncertainty: 1.3932400941848755
Epoch 13, Batch 1000/3125, Loss: 6.571691513061523, Uncertainty: 4.3025593757629395
Epoch 112, Batch 2000/3125, Loss: 1.1348776817321777, Uncertainty: 1.3936786651611328
Epoch 13, Batch 1100/3125, Loss: 6.474369049072266, Uncertainty: 4.536768913269043
Epoch 112, Batch 2100/3125, Loss: 1.3399686813354492, Uncertainty: 1.5491223335266113
Epoch 13, Batch 1200/3125, Loss: 6.629831314086914, Uncertainty: 4.903354167938232
Epoch 112, Batch 2200/3125, Loss: 1.0165033340454102, Uncertainty: 1.205366611480713
Epoch 13, Batch 1300/3125, Loss: 6.160556793212891, Uncertainty: 4.685349941253662
Epoch 112, Batch 2300/3125, Loss: 1.242799997329712, Uncertainty: 1.6365151405334473
Epoch 13, Batch 1400/3125, Loss: 6.477540969848633, Uncertainty: 4.146334648132324
Epoch 112, Batch 2400/3125, Loss: 1.233596920967102, Uncertainty: 1.5924959182739258
Epoch 13, Batch 1500/3125, Loss: 6.405888080596924, Uncertainty: 4.897197246551514
Epoch 112, Batch 2500/3125, Loss: 1.2600901126861572, Uncertainty: 1.8244500160217285
Epoch 13, Batch 1600/3125, Loss: 6.452070713043213, Uncertainty: 4.434566974639893
Epoch 112, Batch 2600/3125, Loss: 1.1995766162872314, Uncertainty: 1.5775136947631836
Epoch 13, Batch 1700/3125, Loss: 6.372254371643066, Uncertainty: 3.857847213745117
Epoch 112, Batch 2700/3125, Loss: 1.283310890197754, Uncertainty: 1.6357297897338867
Epoch 13, Batch 1800/3125, Loss: 6.6389970779418945, Uncertainty: 4.857591152191162
Epoch 13, Batch 1900/3125, Loss: 6.70886754989624, Uncertainty: 4.126827716827393
Epoch 112, Batch 2800/3125, Loss: 1.0993340015411377, Uncertainty: 1.3760778903961182
Epoch 13, Batch 2000/3125, Loss: 6.717825889587402, Uncertainty: 5.435310363769531
Epoch 112, Batch 2900/3125, Loss: 1.1859427690505981, Uncertainty: 1.445318341255188
Epoch 13, Batch 2100/3125, Loss: 6.13065242767334, Uncertainty: 4.958373069763184
Epoch 112, Batch 3000/3125, Loss: 1.2466503381729126, Uncertainty: 1.5659388303756714
Epoch 13, Batch 2200/3125, Loss: 6.245595932006836, Uncertainty: 4.801486015319824
Epoch 112, Batch 3100/3125, Loss: 1.0763472318649292, Uncertainty: 1.2965949773788452
Epoch 13, Batch 2300/3125, Loss: 6.25311279296875, Uncertainty: 4.912312030792236
Epoch 13, Batch 2400/3125, Loss: 6.720458030700684, Uncertainty: 5.14039945602417
Epoch 13, Batch 2500/3125, Loss: 6.521190643310547, Uncertainty: 4.857600688934326
Epoch 13, Batch 2600/3125, Loss: 7.012569904327393, Uncertainty: 5.043569564819336
Epoch 13, Batch 2700/3125, Loss: 5.693306922912598, Uncertainty: 4.4244384765625
Epoch 13, Batch 2800/3125, Loss: 6.106317043304443, Uncertainty: 4.8130998611450195
Epoch 13, Batch 2900/3125, Loss: 6.719913482666016, Uncertainty: 5.361388206481934

Training and Validation Results of Epoch 112:
================================
Training Loss: 0.9488130506896972, Training Uncertainty: 1.4734111302185058, time: 203.3990125656128
Validation Loss: 0.8349349314294507, Validation Uncertainty: 2.0767063836917243, time: 45.52304697036743
Number of predictions within uncertainty interval: 126114/200000 (63.06%)

Epoch 13, Batch 3000/3125, Loss: 6.246700286865234, Uncertainty: 4.518425941467285
Epoch 113, Batch 100/3125, Loss: 1.0186258554458618, Uncertainty: 1.1676145792007446
Epoch 13, Batch 3100/3125, Loss: 6.000287055969238, Uncertainty: 3.6646876335144043
Epoch 113, Batch 200/3125, Loss: 1.1868510246276855, Uncertainty: 1.558648943901062
Epoch 113, Batch 300/3125, Loss: 1.2583792209625244, Uncertainty: 1.4095245599746704
Epoch 113, Batch 400/3125, Loss: 1.054605484008789, Uncertainty: 1.351816177368164
Epoch 113, Batch 500/3125, Loss: 1.1733381748199463, Uncertainty: 1.5600762367248535
Epoch 113, Batch 600/3125, Loss: 1.3292431831359863, Uncertainty: 1.4152177572250366
Epoch 113, Batch 700/3125, Loss: 1.229825735092163, Uncertainty: 1.405561923980713
Epoch 113, Batch 800/3125, Loss: 1.4009515047073364, Uncertainty: 2.0127573013305664

Training and Validation Results of Epoch 13:
================================
Training Loss: 6.166333071899414, Training Uncertainty: 4.877210471572876, time: 198.5625684261322
Validation Loss: 5.8104903643088575, Validation Uncertainty: 8.994059668782421, time: 44.76509189605713
Number of predictions within uncertainty interval: 89784/200000 (44.89%)

Epoch 113, Batch 900/3125, Loss: 1.2806308269500732, Uncertainty: 1.5134620666503906
Epoch 14, Batch 100/3125, Loss: 6.112277030944824, Uncertainty: 5.063893795013428
Epoch 113, Batch 1000/3125, Loss: 1.0345890522003174, Uncertainty: 1.2316834926605225
Epoch 14, Batch 200/3125, Loss: 6.45142936706543, Uncertainty: 4.248744964599609
Epoch 113, Batch 1100/3125, Loss: 1.188965082168579, Uncertainty: 1.6645088195800781
Epoch 14, Batch 300/3125, Loss: 6.035780429840088, Uncertainty: 4.521955966949463
Epoch 113, Batch 1200/3125, Loss: 1.2592462301254272, Uncertainty: 1.5370097160339355
Epoch 14, Batch 400/3125, Loss: 6.271996021270752, Uncertainty: 6.279925346374512
Epoch 113, Batch 1300/3125, Loss: 1.0784437656402588, Uncertainty: 1.236641526222229
Epoch 14, Batch 500/3125, Loss: 6.29133415222168, Uncertainty: 4.27833366394043
Epoch 14, Batch 600/3125, Loss: 6.209210395812988, Uncertainty: 4.703784942626953
Epoch 113, Batch 1400/3125, Loss: 1.1585021018981934, Uncertainty: 1.5460121631622314
Epoch 14, Batch 700/3125, Loss: 6.466599464416504, Uncertainty: 4.39932107925415
Epoch 113, Batch 1500/3125, Loss: 1.2955679893493652, Uncertainty: 1.4891016483306885
Epoch 14, Batch 800/3125, Loss: 6.186332702636719, Uncertainty: 4.939708709716797
Epoch 113, Batch 1600/3125, Loss: 1.0219159126281738, Uncertainty: 1.2281371355056763
Epoch 14, Batch 900/3125, Loss: 6.421286106109619, Uncertainty: 4.585120677947998
Epoch 113, Batch 1700/3125, Loss: 1.1029136180877686, Uncertainty: 1.4868614673614502
Epoch 14, Batch 1000/3125, Loss: 6.186068534851074, Uncertainty: 4.157871246337891
Epoch 113, Batch 1800/3125, Loss: 1.2433397769927979, Uncertainty: 1.6031696796417236
Epoch 14, Batch 1100/3125, Loss: 6.325139045715332, Uncertainty: 4.085015296936035
Epoch 113, Batch 1900/3125, Loss: 0.9848273396492004, Uncertainty: 1.3111674785614014
Epoch 14, Batch 1200/3125, Loss: 6.276084899902344, Uncertainty: 4.572380542755127
Epoch 113, Batch 2000/3125, Loss: 1.1089248657226562, Uncertainty: 1.3587734699249268
Epoch 14, Batch 1300/3125, Loss: 5.995548248291016, Uncertainty: 4.7958664894104
Epoch 113, Batch 2100/3125, Loss: 1.353806972503662, Uncertainty: 1.5086811780929565
Epoch 14, Batch 1400/3125, Loss: 5.989286422729492, Uncertainty: 3.5649168491363525
Epoch 113, Batch 2200/3125, Loss: 0.9980016946792603, Uncertainty: 1.1879702806472778
Epoch 14, Batch 1500/3125, Loss: 6.434398651123047, Uncertainty: 5.961281776428223
Epoch 113, Batch 2300/3125, Loss: 1.2078138589859009, Uncertainty: 1.515803337097168
Epoch 14, Batch 1600/3125, Loss: 6.4000396728515625, Uncertainty: 4.202504634857178
Epoch 113, Batch 2400/3125, Loss: 1.339930772781372, Uncertainty: 1.8259732723236084
Epoch 14, Batch 1700/3125, Loss: 6.392155647277832, Uncertainty: 6.043280601501465
Epoch 113, Batch 2500/3125, Loss: 1.1641300916671753, Uncertainty: 1.6995123624801636
Epoch 14, Batch 1800/3125, Loss: 6.184327125549316, Uncertainty: 4.168109893798828
Epoch 113, Batch 2600/3125, Loss: 1.2518932819366455, Uncertainty: 1.703458547592163
Epoch 14, Batch 1900/3125, Loss: 6.243809700012207, Uncertainty: 4.296706199645996
Epoch 113, Batch 2700/3125, Loss: 1.294438123703003, Uncertainty: 1.6529546976089478
Epoch 14, Batch 2000/3125, Loss: 6.0151777267456055, Uncertainty: 4.830423355102539
Epoch 113, Batch 2800/3125, Loss: 1.1265593767166138, Uncertainty: 1.3333048820495605
Epoch 14, Batch 2100/3125, Loss: 6.501877307891846, Uncertainty: 7.778470039367676
Epoch 113, Batch 2900/3125, Loss: 1.1704473495483398, Uncertainty: 1.4672235250473022
Epoch 14, Batch 2200/3125, Loss: 5.7441606521606445, Uncertainty: 4.1078362464904785
Epoch 113, Batch 3000/3125, Loss: 1.2370725870132446, Uncertainty: 1.425470232963562
Epoch 14, Batch 2300/3125, Loss: 5.882888317108154, Uncertainty: 3.7199790477752686
Epoch 14, Batch 2400/3125, Loss: 6.795231819152832, Uncertainty: 6.1571946144104
Epoch 113, Batch 3100/3125, Loss: 1.0804471969604492, Uncertainty: 1.3125518560409546
Epoch 14, Batch 2500/3125, Loss: 6.456948757171631, Uncertainty: 6.092940330505371
Epoch 14, Batch 2600/3125, Loss: 6.659790992736816, Uncertainty: 5.282310962677002
Epoch 14, Batch 2700/3125, Loss: 6.145094871520996, Uncertainty: 6.413281440734863
Epoch 14, Batch 2800/3125, Loss: 6.218916893005371, Uncertainty: 4.640995025634766
Epoch 14, Batch 2900/3125, Loss: 6.443078994750977, Uncertainty: 4.989459991455078
Epoch 14, Batch 3000/3125, Loss: 6.079560279846191, Uncertainty: 4.111356735229492
Epoch 14, Batch 3100/3125, Loss: 6.0671563148498535, Uncertainty: 3.8953299522399902

Training and Validation Results of Epoch 113:
================================
Training Loss: 0.9459308068084716, Training Uncertainty: 1.4619666550636292, time: 205.18030309677124
Validation Loss: 0.8275906749241188, Validation Uncertainty: 2.070415283255565, time: 47.139081716537476
Number of predictions within uncertainty interval: 126420/200000 (63.21%)

Epoch 114, Batch 100/3125, Loss: 1.027700662612915, Uncertainty: 1.1676188707351685
Epoch 114, Batch 200/3125, Loss: 1.146644115447998, Uncertainty: 1.444678783416748
Epoch 114, Batch 300/3125, Loss: 1.2622148990631104, Uncertainty: 1.4225385189056396
Epoch 114, Batch 400/3125, Loss: 1.0856138467788696, Uncertainty: 1.3879103660583496
Epoch 114, Batch 500/3125, Loss: 1.1255707740783691, Uncertainty: 1.3638584613800049
Epoch 114, Batch 600/3125, Loss: 1.283223032951355, Uncertainty: 1.4024884700775146

Training and Validation Results of Epoch 14:
================================
Training Loss: 5.927353402404785, Training Uncertainty: 4.793641598205566, time: 194.1950967311859
Validation Loss: 5.535299139559421, Validation Uncertainty: 6.8564172858167485, time: 44.65572428703308
Number of predictions within uncertainty interval: 72233/200000 (36.12%)

Epoch 114, Batch 700/3125, Loss: 1.1796319484710693, Uncertainty: 1.3820406198501587
Epoch 15, Batch 100/3125, Loss: 6.119449615478516, Uncertainty: 3.785874128341675
Epoch 114, Batch 800/3125, Loss: 1.1880067586898804, Uncertainty: 1.3899017572402954
Epoch 15, Batch 200/3125, Loss: 5.990859508514404, Uncertainty: 4.663397789001465
Epoch 114, Batch 900/3125, Loss: 1.3518741130828857, Uncertainty: 1.6370553970336914
Epoch 15, Batch 300/3125, Loss: 5.7607831954956055, Uncertainty: 4.145790100097656
Epoch 114, Batch 1000/3125, Loss: 1.0227179527282715, Uncertainty: 1.2124974727630615
Epoch 15, Batch 400/3125, Loss: 5.98807430267334, Uncertainty: 4.167229652404785
Epoch 114, Batch 1100/3125, Loss: 1.178022861480713, Uncertainty: 1.5598061084747314
Epoch 15, Batch 500/3125, Loss: 5.982295989990234, Uncertainty: 4.452356338500977
Epoch 114, Batch 1200/3125, Loss: 1.2364697456359863, Uncertainty: 1.5001914501190186
Epoch 15, Batch 600/3125, Loss: 5.964313983917236, Uncertainty: 4.378308296203613
Epoch 114, Batch 1300/3125, Loss: 1.0512738227844238, Uncertainty: 1.1918096542358398
Epoch 15, Batch 700/3125, Loss: 6.092776298522949, Uncertainty: 4.214996814727783
Epoch 114, Batch 1400/3125, Loss: 1.1162124872207642, Uncertainty: 1.4295133352279663
Epoch 15, Batch 800/3125, Loss: 6.121862888336182, Uncertainty: 4.1458330154418945
Epoch 114, Batch 1500/3125, Loss: 1.2617390155792236, Uncertainty: 1.3812835216522217
Epoch 15, Batch 900/3125, Loss: 6.245221138000488, Uncertainty: 5.214977264404297
Epoch 114, Batch 1600/3125, Loss: 0.984968364238739, Uncertainty: 1.2299606800079346
Epoch 15, Batch 1000/3125, Loss: 5.849067687988281, Uncertainty: 4.1362385749816895
Epoch 15, Batch 1100/3125, Loss: 6.142293930053711, Uncertainty: 4.088681221008301
Epoch 114, Batch 1700/3125, Loss: 1.0805665254592896, Uncertainty: 1.4065282344818115
Epoch 15, Batch 1200/3125, Loss: 5.859681606292725, Uncertainty: 3.9426496028900146
Epoch 114, Batch 1800/3125, Loss: 1.3130614757537842, Uncertainty: 1.8327581882476807
Epoch 15, Batch 1300/3125, Loss: 6.432879447937012, Uncertainty: 3.8483123779296875
Epoch 114, Batch 1900/3125, Loss: 0.9895472526550293, Uncertainty: 1.3723896741867065
Epoch 15, Batch 1400/3125, Loss: 5.942500114440918, Uncertainty: 4.100495338439941
Epoch 114, Batch 2000/3125, Loss: 1.1235527992248535, Uncertainty: 1.3865352869033813
Epoch 15, Batch 1500/3125, Loss: 6.148956775665283, Uncertainty: 5.568389892578125
Epoch 114, Batch 2100/3125, Loss: 1.3105833530426025, Uncertainty: 1.5151222944259644
Epoch 15, Batch 1600/3125, Loss: 5.831448554992676, Uncertainty: 3.6987311840057373
Epoch 114, Batch 2200/3125, Loss: 1.1286660432815552, Uncertainty: 1.2735096216201782
Epoch 15, Batch 1700/3125, Loss: 5.957691192626953, Uncertainty: 5.065249443054199
Epoch 114, Batch 2300/3125, Loss: 1.2319636344909668, Uncertainty: 1.5633912086486816
Epoch 15, Batch 1800/3125, Loss: 6.003655433654785, Uncertainty: 3.7360148429870605
Epoch 114, Batch 2400/3125, Loss: 1.3565608263015747, Uncertainty: 1.659518837928772
Epoch 15, Batch 1900/3125, Loss: 6.04791259765625, Uncertainty: 4.307711601257324
Epoch 114, Batch 2500/3125, Loss: 1.1450430154800415, Uncertainty: 1.6134883165359497
Epoch 15, Batch 2000/3125, Loss: 5.924676418304443, Uncertainty: 4.550137519836426
Epoch 114, Batch 2600/3125, Loss: 1.2460720539093018, Uncertainty: 1.5477771759033203
Epoch 15, Batch 2100/3125, Loss: 5.612949371337891, Uncertainty: 4.873624801635742
Epoch 114, Batch 2700/3125, Loss: 1.2638576030731201, Uncertainty: 1.6224563121795654
Epoch 15, Batch 2200/3125, Loss: 5.601120948791504, Uncertainty: 4.717422008514404
Epoch 114, Batch 2800/3125, Loss: 1.0389004945755005, Uncertainty: 1.339003562927246
Epoch 15, Batch 2300/3125, Loss: 5.889128684997559, Uncertainty: 5.1401286125183105
Epoch 114, Batch 2900/3125, Loss: 1.1979998350143433, Uncertainty: 1.4496240615844727
Epoch 15, Batch 2400/3125, Loss: 6.817904472351074, Uncertainty: 6.3784708976745605
Epoch 114, Batch 3000/3125, Loss: 1.219340205192566, Uncertainty: 1.4258276224136353
Epoch 15, Batch 2500/3125, Loss: 6.139249324798584, Uncertainty: 3.957540988922119
Epoch 114, Batch 3100/3125, Loss: 1.0882518291473389, Uncertainty: 1.3520140647888184
Epoch 15, Batch 2600/3125, Loss: 6.490656852722168, Uncertainty: 6.013507843017578
Epoch 15, Batch 2700/3125, Loss: 6.174924850463867, Uncertainty: 6.869110107421875
Epoch 15, Batch 2800/3125, Loss: 5.9523701667785645, Uncertainty: 4.823277473449707
Epoch 15, Batch 2900/3125, Loss: 6.233098030090332, Uncertainty: 4.40974235534668
Epoch 15, Batch 3000/3125, Loss: 5.907960891723633, Uncertainty: 4.001307487487793
Epoch 15, Batch 3100/3125, Loss: 5.701058387756348, Uncertainty: 3.412074089050293

Training and Validation Results of Epoch 114:
================================
Training Loss: 0.9439037190818786, Training Uncertainty: 1.4553214346313477, time: 202.24326634407043
Validation Loss: 0.8185275383007801, Validation Uncertainty: 2.0436057158748206, time: 48.15283489227295
Number of predictions within uncertainty interval: 126293/200000 (63.15%)

Epoch 115, Batch 100/3125, Loss: 0.9935387969017029, Uncertainty: 1.1807494163513184
Epoch 115, Batch 200/3125, Loss: 1.163557529449463, Uncertainty: 1.5164072513580322
Epoch 115, Batch 300/3125, Loss: 1.2623963356018066, Uncertainty: 1.5098931789398193
Epoch 115, Batch 400/3125, Loss: 1.3406472206115723, Uncertainty: 1.7199690341949463
Epoch 115, Batch 500/3125, Loss: 1.177348256111145, Uncertainty: 1.5915744304656982

Training and Validation Results of Epoch 15:
================================
Training Loss: 5.719874998626709, Training Uncertainty: 4.719021161956787, time: 194.14039134979248
Validation Loss: 5.483459195822401, Validation Uncertainty: 6.087052279421131, time: 52.57092356681824
Number of predictions within uncertainty interval: 66731/200000 (33.37%)

Epoch 115, Batch 600/3125, Loss: 1.3281993865966797, Uncertainty: 1.5465340614318848
Epoch 115, Batch 700/3125, Loss: 1.2915235757827759, Uncertainty: 1.3541033267974854
Epoch 16, Batch 100/3125, Loss: 5.8867011070251465, Uncertainty: 4.213338375091553
Epoch 115, Batch 800/3125, Loss: 1.2365607023239136, Uncertainty: 1.5000524520874023
Epoch 16, Batch 200/3125, Loss: 6.041845321655273, Uncertainty: 4.968539237976074
Epoch 115, Batch 900/3125, Loss: 1.299394130706787, Uncertainty: 1.739434003829956
Epoch 16, Batch 300/3125, Loss: 5.6381988525390625, Uncertainty: 4.480809688568115
Epoch 115, Batch 1000/3125, Loss: 1.0233211517333984, Uncertainty: 1.2074123620986938
Epoch 16, Batch 400/3125, Loss: 5.703195095062256, Uncertainty: 4.368606090545654
Epoch 115, Batch 1100/3125, Loss: 1.1478197574615479, Uncertainty: 1.636417269706726
Epoch 16, Batch 500/3125, Loss: 5.656677722930908, Uncertainty: 3.9367449283599854
Epoch 115, Batch 1200/3125, Loss: 1.2700998783111572, Uncertainty: 1.5106589794158936
Epoch 16, Batch 600/3125, Loss: 5.7340779304504395, Uncertainty: 4.516194820404053
Epoch 115, Batch 1300/3125, Loss: 1.0653802156448364, Uncertainty: 1.2325562238693237
Epoch 16, Batch 700/3125, Loss: 5.698527812957764, Uncertainty: 4.088958263397217
Epoch 115, Batch 1400/3125, Loss: 1.1358473300933838, Uncertainty: 1.4959313869476318
Epoch 115, Batch 1500/3125, Loss: 1.2490997314453125, Uncertainty: 1.361403465270996
Epoch 16, Batch 800/3125, Loss: 5.889791488647461, Uncertainty: 4.00377082824707
Epoch 115, Batch 1600/3125, Loss: 1.0638351440429688, Uncertainty: 1.2165038585662842
Epoch 16, Batch 900/3125, Loss: 6.146143913269043, Uncertainty: 6.209968090057373
Epoch 115, Batch 1700/3125, Loss: 1.2646734714508057, Uncertainty: 1.8805603981018066
Epoch 16, Batch 1000/3125, Loss: 5.6661577224731445, Uncertainty: 4.009746551513672
Epoch 115, Batch 1800/3125, Loss: 1.1754693984985352, Uncertainty: 1.3966935873031616
Epoch 16, Batch 1100/3125, Loss: 6.108548164367676, Uncertainty: 4.369342803955078
Epoch 115, Batch 1900/3125, Loss: 1.065056562423706, Uncertainty: 1.40457022190094
Epoch 16, Batch 1200/3125, Loss: 5.848016738891602, Uncertainty: 4.040156364440918
Epoch 115, Batch 2000/3125, Loss: 1.10874605178833, Uncertainty: 1.3605341911315918
Epoch 115, Batch 2100/3125, Loss: 1.2998887300491333, Uncertainty: 1.4902572631835938
Epoch 16, Batch 1300/3125, Loss: 5.698077201843262, Uncertainty: 3.6397342681884766
Epoch 115, Batch 2200/3125, Loss: 0.9911431670188904, Uncertainty: 1.19683837890625
Epoch 16, Batch 1400/3125, Loss: 5.761250019073486, Uncertainty: 4.37209415435791
Epoch 115, Batch 2300/3125, Loss: 1.1929090023040771, Uncertainty: 1.4777274131774902
Epoch 16, Batch 1500/3125, Loss: 5.839878082275391, Uncertainty: 4.149766445159912
Epoch 115, Batch 2400/3125, Loss: 1.424086093902588, Uncertainty: 2.1964223384857178
Epoch 16, Batch 1600/3125, Loss: 6.0153117179870605, Uncertainty: 4.278927803039551
Epoch 115, Batch 2500/3125, Loss: 1.2634227275848389, Uncertainty: 1.8356989622116089
Epoch 16, Batch 1700/3125, Loss: 6.103766441345215, Uncertainty: 6.155445098876953
Epoch 115, Batch 2600/3125, Loss: 1.2291218042373657, Uncertainty: 1.648756980895996
Epoch 16, Batch 1800/3125, Loss: 6.117159366607666, Uncertainty: 4.284472465515137
Epoch 115, Batch 2700/3125, Loss: 1.2695541381835938, Uncertainty: 1.6231868267059326
Epoch 115, Batch 2800/3125, Loss: 1.004744529724121, Uncertainty: 1.3280463218688965
Epoch 16, Batch 1900/3125, Loss: 5.777107238769531, Uncertainty: 4.810390472412109
Epoch 115, Batch 2900/3125, Loss: 1.2042789459228516, Uncertainty: 1.559624195098877
Epoch 16, Batch 2000/3125, Loss: 5.814755916595459, Uncertainty: 4.3228912353515625
Epoch 115, Batch 3000/3125, Loss: 1.247572660446167, Uncertainty: 1.4906213283538818
Epoch 16, Batch 2100/3125, Loss: 5.3188557624816895, Uncertainty: 3.936660051345825
Epoch 115, Batch 3100/3125, Loss: 1.118721842765808, Uncertainty: 1.4283201694488525
Epoch 16, Batch 2200/3125, Loss: 5.7581329345703125, Uncertainty: 5.811643600463867
Epoch 16, Batch 2300/3125, Loss: 6.105814456939697, Uncertainty: 3.7487776279449463
Epoch 16, Batch 2400/3125, Loss: 6.168447017669678, Uncertainty: 5.263242721557617
Epoch 16, Batch 2500/3125, Loss: 5.6316094398498535, Uncertainty: 4.2742719650268555
Epoch 16, Batch 2600/3125, Loss: 6.0132856369018555, Uncertainty: 3.750001907348633
Epoch 16, Batch 2700/3125, Loss: 5.443249702453613, Uncertainty: 4.387055397033691
Epoch 16, Batch 2800/3125, Loss: 5.908761024475098, Uncertainty: 5.245075225830078

Training and Validation Results of Epoch 115:
================================
Training Loss: 0.9363618123435974, Training Uncertainty: 1.4574980410957337, time: 176.24711537361145
Validation Loss: 0.8439434108221927, Validation Uncertainty: 2.149486345403335, time: 41.47897815704346
Number of predictions within uncertainty interval: 128558/200000 (64.28%)

Epoch 16, Batch 2900/3125, Loss: 6.091703414916992, Uncertainty: 5.364561557769775
Epoch 116, Batch 100/3125, Loss: 1.0518395900726318, Uncertainty: 1.3418070077896118
Epoch 16, Batch 3000/3125, Loss: 5.730138301849365, Uncertainty: 4.025200843811035
Epoch 116, Batch 200/3125, Loss: 1.1681678295135498, Uncertainty: 1.571408987045288
Epoch 16, Batch 3100/3125, Loss: 5.458466053009033, Uncertainty: 3.4698057174682617
Epoch 116, Batch 300/3125, Loss: 1.2520419359207153, Uncertainty: 1.394606590270996
Epoch 116, Batch 400/3125, Loss: 1.2832956314086914, Uncertainty: 1.8117047548294067
Epoch 116, Batch 500/3125, Loss: 1.1031827926635742, Uncertainty: 1.436591386795044
Epoch 116, Batch 600/3125, Loss: 1.2961559295654297, Uncertainty: 1.4046525955200195
Epoch 116, Batch 700/3125, Loss: 1.1686437129974365, Uncertainty: 1.4647066593170166
Epoch 116, Batch 800/3125, Loss: 1.227674961090088, Uncertainty: 1.475959062576294
Epoch 116, Batch 900/3125, Loss: 1.276519536972046, Uncertainty: 1.6714720726013184
Epoch 116, Batch 1000/3125, Loss: 1.0395840406417847, Uncertainty: 1.2213215827941895
Epoch 116, Batch 1100/3125, Loss: 1.2077401876449585, Uncertainty: 1.6663968563079834

Training and Validation Results of Epoch 16:
================================
Training Loss: 5.565573234710693, Training Uncertainty: 4.67716534362793, time: 198.52224135398865
Validation Loss: 5.222809601927657, Validation Uncertainty: 7.677022408341508, time: 44.66202640533447
Number of predictions within uncertainty interval: 86728/200000 (43.36%)

Epoch 116, Batch 1200/3125, Loss: 1.2688941955566406, Uncertainty: 1.5346959829330444
Epoch 17, Batch 100/3125, Loss: 5.343832015991211, Uncertainty: 3.816023588180542
Epoch 116, Batch 1300/3125, Loss: 1.0447335243225098, Uncertainty: 1.2370142936706543
Epoch 17, Batch 200/3125, Loss: 5.807050704956055, Uncertainty: 4.2720794677734375
Epoch 116, Batch 1400/3125, Loss: 1.1643011569976807, Uncertainty: 1.4368855953216553
Epoch 17, Batch 300/3125, Loss: 5.568770885467529, Uncertainty: 4.4998698234558105
Epoch 116, Batch 1500/3125, Loss: 1.2637150287628174, Uncertainty: 1.360383152961731
Epoch 116, Batch 1600/3125, Loss: 0.9667983055114746, Uncertainty: 1.257946491241455
Epoch 17, Batch 400/3125, Loss: 5.607882976531982, Uncertainty: 3.6268270015716553
Epoch 116, Batch 1700/3125, Loss: 1.1103483438491821, Uncertainty: 1.4782016277313232
Epoch 17, Batch 500/3125, Loss: 5.623708248138428, Uncertainty: 4.643989562988281
Epoch 116, Batch 1800/3125, Loss: 1.2185503244400024, Uncertainty: 1.5867807865142822
Epoch 17, Batch 600/3125, Loss: 5.771562576293945, Uncertainty: 4.92039680480957
Epoch 116, Batch 1900/3125, Loss: 0.952796220779419, Uncertainty: 1.271571397781372
Epoch 17, Batch 700/3125, Loss: 5.759076118469238, Uncertainty: 4.096813201904297
Epoch 116, Batch 2000/3125, Loss: 1.1159579753875732, Uncertainty: 1.4180822372436523
Epoch 17, Batch 800/3125, Loss: 5.877684593200684, Uncertainty: 4.983548164367676
Epoch 116, Batch 2100/3125, Loss: 1.306650996208191, Uncertainty: 1.5020596981048584
Epoch 17, Batch 900/3125, Loss: 5.776162147521973, Uncertainty: 4.400674343109131
Epoch 116, Batch 2200/3125, Loss: 0.9542279839515686, Uncertainty: 1.1631958484649658
Epoch 116, Batch 2300/3125, Loss: 1.1994514465332031, Uncertainty: 1.5211275815963745
Epoch 17, Batch 1000/3125, Loss: 5.930342674255371, Uncertainty: 5.039867401123047
Epoch 116, Batch 2400/3125, Loss: 1.288656234741211, Uncertainty: 1.775038719177246
Epoch 17, Batch 1100/3125, Loss: 5.787975311279297, Uncertainty: 4.137753486633301
Epoch 116, Batch 2500/3125, Loss: 1.1406116485595703, Uncertainty: 1.6349539756774902
Epoch 17, Batch 1200/3125, Loss: 5.684687614440918, Uncertainty: 4.224367141723633
Epoch 116, Batch 2600/3125, Loss: 1.2853035926818848, Uncertainty: 1.8702090978622437
Epoch 17, Batch 1300/3125, Loss: 5.400467872619629, Uncertainty: 3.8113465309143066
Epoch 116, Batch 2700/3125, Loss: 1.3212461471557617, Uncertainty: 1.6939281225204468
Epoch 17, Batch 1400/3125, Loss: 5.422368049621582, Uncertainty: 3.7652432918548584
Epoch 116, Batch 2800/3125, Loss: 0.9960993528366089, Uncertainty: 1.2811498641967773
Epoch 17, Batch 1500/3125, Loss: 5.785892486572266, Uncertainty: 4.689506530761719
Epoch 116, Batch 2900/3125, Loss: 1.1485812664031982, Uncertainty: 1.4513585567474365
Epoch 116, Batch 3000/3125, Loss: 1.3178870677947998, Uncertainty: 1.4156484603881836
Epoch 17, Batch 1600/3125, Loss: 5.644477844238281, Uncertainty: 3.8280272483825684
Epoch 116, Batch 3100/3125, Loss: 1.0746123790740967, Uncertainty: 1.2862497568130493
Epoch 17, Batch 1700/3125, Loss: 5.627720832824707, Uncertainty: 4.550293922424316
Epoch 17, Batch 1800/3125, Loss: 5.764750003814697, Uncertainty: 4.103155136108398
Epoch 17, Batch 1900/3125, Loss: 6.022466659545898, Uncertainty: 5.526430130004883
Epoch 17, Batch 2000/3125, Loss: 5.889793872833252, Uncertainty: 4.930219650268555
Epoch 17, Batch 2100/3125, Loss: 5.682190895080566, Uncertainty: 4.793779373168945
Epoch 17, Batch 2200/3125, Loss: 5.344459056854248, Uncertainty: 4.0284600257873535
Epoch 17, Batch 2300/3125, Loss: 5.724363327026367, Uncertainty: 4.608479976654053

Training and Validation Results of Epoch 116:
================================
Training Loss: 0.9326812784957885, Training Uncertainty: 1.4496323151397705, time: 167.65120720863342
Validation Loss: 0.8119617218861495, Validation Uncertainty: 2.0397709469356196, time: 38.65311646461487
Number of predictions within uncertainty interval: 126392/200000 (63.20%)

Epoch 17, Batch 2400/3125, Loss: 6.242810249328613, Uncertainty: 5.676098346710205
Epoch 117, Batch 100/3125, Loss: 0.9490688443183899, Uncertainty: 1.1379280090332031
Epoch 117, Batch 200/3125, Loss: 1.1847738027572632, Uncertainty: 1.5447158813476562
Epoch 17, Batch 2500/3125, Loss: 5.475434303283691, Uncertainty: 4.474178791046143
Epoch 117, Batch 300/3125, Loss: 1.2240166664123535, Uncertainty: 1.383234977722168
Epoch 17, Batch 2600/3125, Loss: 5.9660844802856445, Uncertainty: 4.803186416625977
Epoch 117, Batch 400/3125, Loss: 1.1745860576629639, Uncertainty: 1.4710750579833984
Epoch 17, Batch 2700/3125, Loss: 5.30992317199707, Uncertainty: 3.9237794876098633
Epoch 117, Batch 500/3125, Loss: 1.1229188442230225, Uncertainty: 1.4924414157867432
Epoch 17, Batch 2800/3125, Loss: 5.7707319259643555, Uncertainty: 5.77872896194458
Epoch 117, Batch 600/3125, Loss: 1.4415709972381592, Uncertainty: 1.8205145597457886
Epoch 17, Batch 2900/3125, Loss: 5.838576316833496, Uncertainty: 3.9908547401428223
Epoch 117, Batch 700/3125, Loss: 1.14402174949646, Uncertainty: 1.3295230865478516
Epoch 17, Batch 3000/3125, Loss: 5.5034284591674805, Uncertainty: 4.089362144470215
Epoch 117, Batch 800/3125, Loss: 1.2627321481704712, Uncertainty: 1.4057031869888306
Epoch 17, Batch 3100/3125, Loss: 5.32235860824585, Uncertainty: 3.7035017013549805
Epoch 117, Batch 900/3125, Loss: 1.3901216983795166, Uncertainty: 1.6152639389038086
Epoch 117, Batch 1000/3125, Loss: 1.0282269716262817, Uncertainty: 1.2358503341674805
Epoch 117, Batch 1100/3125, Loss: 1.131120204925537, Uncertainty: 1.4668015241622925
Epoch 117, Batch 1200/3125, Loss: 1.211890459060669, Uncertainty: 1.4912428855895996
Epoch 117, Batch 1300/3125, Loss: 1.0692987442016602, Uncertainty: 1.1433994770050049
Epoch 117, Batch 1400/3125, Loss: 1.1772992610931396, Uncertainty: 1.6487500667572021
Epoch 117, Batch 1500/3125, Loss: 1.2395403385162354, Uncertainty: 1.3694860935211182
Epoch 117, Batch 1600/3125, Loss: 0.9711502194404602, Uncertainty: 1.2103033065795898
Epoch 117, Batch 1700/3125, Loss: 1.0785315036773682, Uncertainty: 1.4245235919952393

Training and Validation Results of Epoch 17:
================================
Training Loss: 5.393660106658936, Training Uncertainty: 4.550196378555298, time: 193.50300097465515
Validation Loss: 5.113485343620905, Validation Uncertainty: 6.8185695168917135, time: 44.44331932067871
Number of predictions within uncertainty interval: 76890/200000 (38.44%)

Epoch 117, Batch 1800/3125, Loss: 1.2552845478057861, Uncertainty: 1.6520543098449707
Epoch 18, Batch 100/3125, Loss: 5.513654708862305, Uncertainty: 4.0358476638793945
Epoch 117, Batch 1900/3125, Loss: 0.9632999897003174, Uncertainty: 1.3186421394348145
Epoch 18, Batch 200/3125, Loss: 5.6860222816467285, Uncertainty: 4.314972877502441
Epoch 117, Batch 2000/3125, Loss: 1.0892930030822754, Uncertainty: 1.3453242778778076
Epoch 117, Batch 2100/3125, Loss: 1.2954528331756592, Uncertainty: 1.5064747333526611
Epoch 18, Batch 300/3125, Loss: 5.304504871368408, Uncertainty: 4.319021224975586
Epoch 117, Batch 2200/3125, Loss: 0.9750298261642456, Uncertainty: 1.141509771347046
Epoch 18, Batch 400/3125, Loss: 5.346055030822754, Uncertainty: 4.117223739624023
Epoch 117, Batch 2300/3125, Loss: 1.1921565532684326, Uncertainty: 1.5581612586975098
Epoch 18, Batch 500/3125, Loss: 5.798133373260498, Uncertainty: 5.456149101257324
Epoch 117, Batch 2400/3125, Loss: 1.2730504274368286, Uncertainty: 1.4834922552108765
Epoch 18, Batch 600/3125, Loss: 5.703598976135254, Uncertainty: 4.862054824829102
Epoch 117, Batch 2500/3125, Loss: 1.050544261932373, Uncertainty: 1.3929948806762695
Epoch 18, Batch 700/3125, Loss: 5.594440460205078, Uncertainty: 4.791220188140869
Epoch 117, Batch 2600/3125, Loss: 1.2121158838272095, Uncertainty: 1.6069107055664062
Epoch 18, Batch 800/3125, Loss: 5.775883674621582, Uncertainty: 4.104115962982178
Epoch 117, Batch 2700/3125, Loss: 1.2632694244384766, Uncertainty: 1.6653717756271362
Epoch 18, Batch 900/3125, Loss: 5.542028427124023, Uncertainty: 4.078155994415283
Epoch 117, Batch 2800/3125, Loss: 0.9867534041404724, Uncertainty: 1.2503396272659302
Epoch 117, Batch 2900/3125, Loss: 1.1334127187728882, Uncertainty: 1.4234435558319092
Epoch 18, Batch 1000/3125, Loss: 5.5913496017456055, Uncertainty: 5.665355205535889
Epoch 117, Batch 3000/3125, Loss: 1.204695463180542, Uncertainty: 1.418865442276001
Epoch 18, Batch 1100/3125, Loss: 5.670894622802734, Uncertainty: 4.3636908531188965
Epoch 117, Batch 3100/3125, Loss: 1.0992364883422852, Uncertainty: 1.3485134840011597
Epoch 18, Batch 1200/3125, Loss: 5.867349624633789, Uncertainty: 4.326388359069824
Epoch 18, Batch 1300/3125, Loss: 5.691012382507324, Uncertainty: 3.95334529876709
Epoch 18, Batch 1400/3125, Loss: 5.346707344055176, Uncertainty: 3.913766860961914
Epoch 18, Batch 1500/3125, Loss: 5.424322128295898, Uncertainty: 4.16241455078125
Epoch 18, Batch 1600/3125, Loss: 5.882027626037598, Uncertainty: 6.82594108581543
Epoch 18, Batch 1700/3125, Loss: 5.351410865783691, Uncertainty: 4.2890625
Epoch 18, Batch 1800/3125, Loss: 6.273988723754883, Uncertainty: 6.773800849914551

Training and Validation Results of Epoch 117:
================================
Training Loss: 0.9328420643806458, Training Uncertainty: 1.440076875190735, time: 167.18945980072021
Validation Loss: 0.8156679203290769, Validation Uncertainty: 2.0667172240479217, time: 43.437352895736694
Number of predictions within uncertainty interval: 127444/200000 (63.72%)

Epoch 18, Batch 1900/3125, Loss: 5.692761421203613, Uncertainty: 4.720607757568359
Epoch 118, Batch 100/3125, Loss: 0.9399517774581909, Uncertainty: 1.1175618171691895
Epoch 18, Batch 2000/3125, Loss: 5.794898986816406, Uncertainty: 4.194271564483643
Epoch 118, Batch 200/3125, Loss: 1.1527576446533203, Uncertainty: 1.3831851482391357
Epoch 18, Batch 2100/3125, Loss: 5.4754109382629395, Uncertainty: 4.146146774291992
Epoch 118, Batch 300/3125, Loss: 1.268242359161377, Uncertainty: 1.3966673612594604
Epoch 18, Batch 2200/3125, Loss: 5.101993083953857, Uncertainty: 3.821488380432129
Epoch 118, Batch 400/3125, Loss: 1.0846757888793945, Uncertainty: 1.4144947528839111
Epoch 18, Batch 2300/3125, Loss: 5.298255920410156, Uncertainty: 3.6052255630493164
Epoch 118, Batch 500/3125, Loss: 1.1470433473587036, Uncertainty: 1.536686658859253
Epoch 18, Batch 2400/3125, Loss: 6.080391883850098, Uncertainty: 6.517831325531006
Epoch 118, Batch 600/3125, Loss: 1.3729891777038574, Uncertainty: 1.5713433027267456
Epoch 118, Batch 700/3125, Loss: 1.0881446599960327, Uncertainty: 1.3292014598846436
Epoch 18, Batch 2500/3125, Loss: 5.493067741394043, Uncertainty: 5.345905303955078
Epoch 118, Batch 800/3125, Loss: 1.2745801210403442, Uncertainty: 1.6569048166275024
Epoch 18, Batch 2600/3125, Loss: 6.185574054718018, Uncertainty: 5.121462345123291
Epoch 118, Batch 900/3125, Loss: 1.363817572593689, Uncertainty: 1.576607346534729
Epoch 18, Batch 2700/3125, Loss: 5.412103176116943, Uncertainty: 3.8007607460021973
Epoch 118, Batch 1000/3125, Loss: 1.0196635723114014, Uncertainty: 1.2419917583465576
Epoch 18, Batch 2800/3125, Loss: 5.565465927124023, Uncertainty: 4.626774787902832
Epoch 118, Batch 1100/3125, Loss: 1.0950708389282227, Uncertainty: 1.4826595783233643
Epoch 18, Batch 2900/3125, Loss: 6.2324957847595215, Uncertainty: 6.348637104034424
Epoch 118, Batch 1200/3125, Loss: 1.20513117313385, Uncertainty: 1.5045469999313354
Epoch 18, Batch 3000/3125, Loss: 5.645374298095703, Uncertainty: 3.992974042892456
Epoch 118, Batch 1300/3125, Loss: 1.0490930080413818, Uncertainty: 1.1850574016571045
Epoch 18, Batch 3100/3125, Loss: 5.445321083068848, Uncertainty: 3.8006646633148193
Epoch 118, Batch 1400/3125, Loss: 1.2072224617004395, Uncertainty: 1.7515664100646973
Epoch 118, Batch 1500/3125, Loss: 1.2235422134399414, Uncertainty: 1.3396286964416504
Epoch 118, Batch 1600/3125, Loss: 0.9875892400741577, Uncertainty: 1.2845768928527832
Epoch 118, Batch 1700/3125, Loss: 1.2882107496261597, Uncertainty: 2.043145179748535
Epoch 118, Batch 1800/3125, Loss: 1.228194236755371, Uncertainty: 1.6377458572387695
Epoch 118, Batch 1900/3125, Loss: 0.9874587655067444, Uncertainty: 1.3777523040771484
Epoch 118, Batch 2000/3125, Loss: 1.0776764154434204, Uncertainty: 1.326627254486084
Epoch 118, Batch 2100/3125, Loss: 1.2980934381484985, Uncertainty: 1.5164545774459839
Epoch 118, Batch 2200/3125, Loss: 0.9813476800918579, Uncertainty: 1.2038111686706543

Training and Validation Results of Epoch 18:
================================
Training Loss: 5.243255717620849, Training Uncertainty: 4.548022256851196, time: 193.22806596755981
Validation Loss: 4.925840596103912, Validation Uncertainty: 6.040915306876688, time: 44.119393825531006
Number of predictions within uncertainty interval: 72941/200000 (36.47%)

Epoch 118, Batch 2300/3125, Loss: 1.2141309976577759, Uncertainty: 1.4965531826019287
Epoch 19, Batch 100/3125, Loss: 5.074407577514648, Uncertainty: 3.7822072505950928
Epoch 118, Batch 2400/3125, Loss: 1.2940247058868408, Uncertainty: 1.76701021194458
Epoch 19, Batch 200/3125, Loss: 5.561650276184082, Uncertainty: 4.497613906860352
Epoch 118, Batch 2500/3125, Loss: 1.1228764057159424, Uncertainty: 1.5714932680130005
Epoch 19, Batch 300/3125, Loss: 5.08682918548584, Uncertainty: 3.5621461868286133
Epoch 118, Batch 2600/3125, Loss: 1.2510210275650024, Uncertainty: 1.7129735946655273
Epoch 118, Batch 2700/3125, Loss: 1.2454087734222412, Uncertainty: 1.601166009902954
Epoch 19, Batch 400/3125, Loss: 5.088983535766602, Uncertainty: 3.821120023727417
Epoch 118, Batch 2800/3125, Loss: 1.0421632528305054, Uncertainty: 1.2748770713806152
Epoch 19, Batch 500/3125, Loss: 5.189988136291504, Uncertainty: 3.9458460807800293
Epoch 118, Batch 2900/3125, Loss: 1.1219823360443115, Uncertainty: 1.4122533798217773
Epoch 19, Batch 600/3125, Loss: 5.290882110595703, Uncertainty: 3.83125638961792
Epoch 118, Batch 3000/3125, Loss: 1.218002200126648, Uncertainty: 1.4908244609832764
Epoch 19, Batch 700/3125, Loss: 5.161489963531494, Uncertainty: 3.4695019721984863
Epoch 118, Batch 3100/3125, Loss: 1.0840423107147217, Uncertainty: 1.3447844982147217
Epoch 19, Batch 800/3125, Loss: 5.672214031219482, Uncertainty: 4.278031349182129
Epoch 19, Batch 900/3125, Loss: 5.592201232910156, Uncertainty: 4.397316932678223
Epoch 19, Batch 1000/3125, Loss: 5.649572372436523, Uncertainty: 5.200369834899902
Epoch 19, Batch 1100/3125, Loss: 5.667207717895508, Uncertainty: 3.924830675125122
Epoch 19, Batch 1200/3125, Loss: 6.117135047912598, Uncertainty: 7.367607593536377
Epoch 19, Batch 1300/3125, Loss: 5.319782257080078, Uncertainty: 4.771355628967285

Training and Validation Results of Epoch 118:
================================
Training Loss: 0.9262116383361816, Training Uncertainty: 1.4320721069145204, time: 167.34266304969788
Validation Loss: 0.8000607506545914, Validation Uncertainty: 2.055277746809108, time: 38.52973222732544
Number of predictions within uncertainty interval: 128209/200000 (64.10%)

Epoch 19, Batch 1400/3125, Loss: 5.449704170227051, Uncertainty: 3.959059953689575
Epoch 119, Batch 100/3125, Loss: 0.9529169797897339, Uncertainty: 1.136427402496338
Epoch 19, Batch 1500/3125, Loss: 5.593452453613281, Uncertainty: 4.0707478523254395
Epoch 119, Batch 200/3125, Loss: 1.1202912330627441, Uncertainty: 1.3698519468307495
Epoch 19, Batch 1600/3125, Loss: 5.263263702392578, Uncertainty: 4.165216445922852
Epoch 119, Batch 300/3125, Loss: 1.3061470985412598, Uncertainty: 1.6544291973114014
Epoch 19, Batch 1700/3125, Loss: 5.304129600524902, Uncertainty: 4.205014705657959
Epoch 119, Batch 400/3125, Loss: 1.255760908126831, Uncertainty: 1.7706291675567627
Epoch 19, Batch 1800/3125, Loss: 5.690976142883301, Uncertainty: 3.7453408241271973
Epoch 119, Batch 500/3125, Loss: 1.1312391757965088, Uncertainty: 1.4984116554260254
Epoch 19, Batch 1900/3125, Loss: 5.676482200622559, Uncertainty: 4.83568000793457
Epoch 119, Batch 600/3125, Loss: 1.2838749885559082, Uncertainty: 1.4515795707702637
Epoch 119, Batch 700/3125, Loss: 1.160331130027771, Uncertainty: 1.329362154006958
Epoch 19, Batch 2000/3125, Loss: 5.406022071838379, Uncertainty: 4.5167741775512695
Epoch 119, Batch 800/3125, Loss: 1.173184871673584, Uncertainty: 1.3257488012313843
Epoch 19, Batch 2100/3125, Loss: 5.256894111633301, Uncertainty: 5.0469207763671875
Epoch 119, Batch 900/3125, Loss: 1.318904995918274, Uncertainty: 1.841485857963562
Epoch 19, Batch 2200/3125, Loss: 5.056479454040527, Uncertainty: 3.5691678524017334
Epoch 119, Batch 1000/3125, Loss: 1.0359572172164917, Uncertainty: 1.2092987298965454
Epoch 19, Batch 2300/3125, Loss: 5.774538993835449, Uncertainty: 6.534036636352539
Epoch 119, Batch 1100/3125, Loss: 1.17854905128479, Uncertainty: 1.6958112716674805
Epoch 19, Batch 2400/3125, Loss: 5.5425920486450195, Uncertainty: 4.681344509124756
Epoch 119, Batch 1200/3125, Loss: 1.2207924127578735, Uncertainty: 1.4720633029937744
Epoch 119, Batch 1300/3125, Loss: 1.018686294555664, Uncertainty: 1.163783311843872
Epoch 119, Batch 1400/3125, Loss: 1.1366026401519775, Uncertainty: 1.4448845386505127
Epoch 19, Batch 2500/3125, Loss: 5.783119201660156, Uncertainty: 6.974244117736816
Epoch 119, Batch 1500/3125, Loss: 1.2184643745422363, Uncertainty: 1.352632999420166
Epoch 19, Batch 2600/3125, Loss: 5.544066905975342, Uncertainty: 4.1883649826049805
Epoch 119, Batch 1600/3125, Loss: 0.9900847673416138, Uncertainty: 1.1741943359375
Epoch 19, Batch 2700/3125, Loss: 5.290361404418945, Uncertainty: 3.9480700492858887
Epoch 119, Batch 1700/3125, Loss: 1.105578064918518, Uncertainty: 1.4767471551895142
Epoch 19, Batch 2800/3125, Loss: 5.414804458618164, Uncertainty: 4.838894844055176
Epoch 119, Batch 1800/3125, Loss: 1.2211483716964722, Uncertainty: 1.6045644283294678
Epoch 19, Batch 2900/3125, Loss: 5.418319225311279, Uncertainty: 3.536891460418701
Epoch 119, Batch 1900/3125, Loss: 0.989987850189209, Uncertainty: 1.413835048675537
Epoch 119, Batch 2000/3125, Loss: 1.0787711143493652, Uncertainty: 1.333491325378418
Epoch 19, Batch 3000/3125, Loss: 5.171598434448242, Uncertainty: 3.466184616088867
Epoch 119, Batch 2100/3125, Loss: 1.3044207096099854, Uncertainty: 1.5048644542694092
Epoch 19, Batch 3100/3125, Loss: 5.178788185119629, Uncertainty: 3.8026795387268066
Epoch 119, Batch 2200/3125, Loss: 0.9406642913818359, Uncertainty: 1.134336233139038
Epoch 119, Batch 2300/3125, Loss: 1.1558878421783447, Uncertainty: 1.4956563711166382
Epoch 119, Batch 2400/3125, Loss: 1.3226613998413086, Uncertainty: 1.933882236480713
Epoch 119, Batch 2500/3125, Loss: 1.2125439643859863, Uncertainty: 1.8367671966552734
Epoch 119, Batch 2600/3125, Loss: 1.1985371112823486, Uncertainty: 1.5593470335006714
Epoch 119, Batch 2700/3125, Loss: 1.2695190906524658, Uncertainty: 1.6664272546768188
Epoch 119, Batch 2800/3125, Loss: 1.0376489162445068, Uncertainty: 1.459418773651123
Epoch 119, Batch 2900/3125, Loss: 1.130824089050293, Uncertainty: 1.4228215217590332

Training and Validation Results of Epoch 19:
================================
Training Loss: 5.106496146697998, Training Uncertainty: 4.4679119683074955, time: 200.14236116409302
Validation Loss: 4.8074160427083745, Validation Uncertainty: 5.71747685393409, time: 44.14344525337219
Number of predictions within uncertainty interval: 72235/200000 (36.12%)

Epoch 119, Batch 3000/3125, Loss: 1.2070037126541138, Uncertainty: 1.3821561336517334
Epoch 20, Batch 100/3125, Loss: 5.11715030670166, Uncertainty: 3.9254534244537354
Epoch 119, Batch 3100/3125, Loss: 1.0488539934158325, Uncertainty: 1.2753504514694214
Epoch 20, Batch 200/3125, Loss: 6.199779987335205, Uncertainty: 4.589142799377441
Epoch 20, Batch 300/3125, Loss: 5.065715312957764, Uncertainty: 3.707338333129883
Epoch 20, Batch 400/3125, Loss: 4.998040199279785, Uncertainty: 4.283611297607422
Epoch 20, Batch 500/3125, Loss: 5.184012413024902, Uncertainty: 4.051993370056152
Epoch 20, Batch 600/3125, Loss: 5.322094917297363, Uncertainty: 4.244479179382324
Epoch 20, Batch 700/3125, Loss: 5.020562171936035, Uncertainty: 3.8346920013427734

Training and Validation Results of Epoch 119:
================================
Training Loss: 0.9214591867065429, Training Uncertainty: 1.4394297248458863, time: 167.14022016525269
Validation Loss: 0.796303815244104, Validation Uncertainty: 2.0134131132489275, time: 38.61743521690369
Number of predictions within uncertainty interval: 127494/200000 (63.75%)

Epoch 20, Batch 800/3125, Loss: 5.309262275695801, Uncertainty: 3.9318487644195557
Epoch 120, Batch 100/3125, Loss: 1.0552473068237305, Uncertainty: 1.1460987329483032
Epoch 20, Batch 900/3125, Loss: 5.4394097328186035, Uncertainty: 3.6781015396118164
Epoch 120, Batch 200/3125, Loss: 1.1079504489898682, Uncertainty: 1.3861753940582275
Epoch 20, Batch 1000/3125, Loss: 5.85577917098999, Uncertainty: 6.252829551696777
Epoch 120, Batch 300/3125, Loss: 1.2330540418624878, Uncertainty: 1.5354357957839966
Epoch 20, Batch 1100/3125, Loss: 5.361155033111572, Uncertainty: 3.757233142852783
Epoch 120, Batch 400/3125, Loss: 1.0642342567443848, Uncertainty: 1.4240210056304932
Epoch 120, Batch 500/3125, Loss: 1.0800901651382446, Uncertainty: 1.4272162914276123
Epoch 20, Batch 1200/3125, Loss: 5.505476474761963, Uncertainty: 4.4170074462890625
Epoch 120, Batch 600/3125, Loss: 1.362549066543579, Uncertainty: 1.5961854457855225
Epoch 20, Batch 1300/3125, Loss: 4.913775444030762, Uncertainty: 3.4406354427337646
Epoch 120, Batch 700/3125, Loss: 1.097001552581787, Uncertainty: 1.2831816673278809
Epoch 20, Batch 1400/3125, Loss: 5.143559455871582, Uncertainty: 3.426851987838745
Epoch 120, Batch 800/3125, Loss: 1.1513535976409912, Uncertainty: 1.313895344734192
Epoch 20, Batch 1500/3125, Loss: 5.548629283905029, Uncertainty: 3.8413877487182617
Epoch 120, Batch 900/3125, Loss: 1.2536447048187256, Uncertainty: 1.567995309829712
Epoch 20, Batch 1600/3125, Loss: 4.577402591705322, Uncertainty: 3.0880048274993896
Epoch 120, Batch 1000/3125, Loss: 1.0270016193389893, Uncertainty: 1.2276124954223633
Epoch 20, Batch 1700/3125, Loss: 5.197323799133301, Uncertainty: 4.383480548858643
Epoch 120, Batch 1100/3125, Loss: 1.201522707939148, Uncertainty: 1.627063512802124
Epoch 20, Batch 1800/3125, Loss: 5.932844161987305, Uncertainty: 6.123273849487305
Epoch 120, Batch 1200/3125, Loss: 1.1748037338256836, Uncertainty: 1.505866289138794
Epoch 120, Batch 1300/3125, Loss: 1.0302774906158447, Uncertainty: 1.2082792520523071
Epoch 20, Batch 1900/3125, Loss: 5.720264434814453, Uncertainty: 5.119940757751465
Epoch 120, Batch 1400/3125, Loss: 1.104534387588501, Uncertainty: 1.3715946674346924
Epoch 20, Batch 2000/3125, Loss: 5.3329973220825195, Uncertainty: 3.8097143173217773
Epoch 120, Batch 1500/3125, Loss: 1.2105934619903564, Uncertainty: 1.3279120922088623
Epoch 20, Batch 2100/3125, Loss: 5.428194522857666, Uncertainty: 5.5134406089782715
Epoch 120, Batch 1600/3125, Loss: 0.9683936834335327, Uncertainty: 1.2721457481384277
Epoch 20, Batch 2200/3125, Loss: 4.712875843048096, Uncertainty: 3.8708438873291016
Epoch 120, Batch 1700/3125, Loss: 1.2033507823944092, Uncertainty: 1.8163594007492065
Epoch 20, Batch 2300/3125, Loss: 5.011802673339844, Uncertainty: 3.2886619567871094
Epoch 120, Batch 1800/3125, Loss: 1.2078624963760376, Uncertainty: 1.585644006729126
Epoch 20, Batch 2400/3125, Loss: 5.49434757232666, Uncertainty: 4.288918495178223
Epoch 120, Batch 1900/3125, Loss: 1.0139979124069214, Uncertainty: 1.4782027006149292
Epoch 20, Batch 2500/3125, Loss: 5.255114555358887, Uncertainty: 5.064906120300293
Epoch 120, Batch 2000/3125, Loss: 1.0901210308074951, Uncertainty: 1.352051019668579
Epoch 120, Batch 2100/3125, Loss: 1.2817459106445312, Uncertainty: 1.4790239334106445
Epoch 20, Batch 2600/3125, Loss: 6.462203025817871, Uncertainty: 4.300626754760742
Epoch 120, Batch 2200/3125, Loss: 0.9780017137527466, Uncertainty: 1.2179735898971558
Epoch 20, Batch 2700/3125, Loss: 5.027967929840088, Uncertainty: 4.091763496398926
Epoch 120, Batch 2300/3125, Loss: 1.1732758283615112, Uncertainty: 1.4490687847137451
Epoch 20, Batch 2800/3125, Loss: 5.7963995933532715, Uncertainty: 5.22672176361084
Epoch 120, Batch 2400/3125, Loss: 1.3498640060424805, Uncertainty: 1.964911937713623
Epoch 20, Batch 2900/3125, Loss: 5.511199951171875, Uncertainty: 4.061150074005127
Epoch 120, Batch 2500/3125, Loss: 1.1045281887054443, Uncertainty: 1.4625883102416992
Epoch 20, Batch 3000/3125, Loss: 5.110068321228027, Uncertainty: 4.098292350769043
Epoch 120, Batch 2600/3125, Loss: 1.1808592081069946, Uncertainty: 1.5394343137741089
Epoch 20, Batch 3100/3125, Loss: 5.767430305480957, Uncertainty: 6.992794036865234
Epoch 120, Batch 2700/3125, Loss: 1.254887580871582, Uncertainty: 1.6135523319244385
Epoch 120, Batch 2800/3125, Loss: 1.0686933994293213, Uncertainty: 1.278229832649231
Epoch 120, Batch 2900/3125, Loss: 1.1500320434570312, Uncertainty: 1.4113240242004395
Epoch 120, Batch 3000/3125, Loss: 1.2216225862503052, Uncertainty: 1.405090093612671
Epoch 120, Batch 3100/3125, Loss: 1.0613501071929932, Uncertainty: 1.3112149238586426

Training and Validation Results of Epoch 20:
================================
Training Loss: 4.981510538940429, Training Uncertainty: 4.429963382568359, time: 192.4911367893219
Validation Loss: 4.740573507440669, Validation Uncertainty: 6.342956775289667, time: 44.30365252494812
Number of predictions within uncertainty interval: 79363/200000 (39.68%)

Epoch 21, Batch 100/3125, Loss: 4.641573429107666, Uncertainty: 3.371448040008545
Epoch 21, Batch 200/3125, Loss: 5.9974846839904785, Uncertainty: 5.475727081298828
Epoch 21, Batch 300/3125, Loss: 4.9232378005981445, Uncertainty: 4.061885356903076

Training and Validation Results of Epoch 120:
================================
Training Loss: 0.9184058662796021, Training Uncertainty: 1.4305238018989563, time: 170.30360627174377
Validation Loss: 0.8298215776148354, Validation Uncertainty: 2.033544411744608, time: 38.886072874069214
Number of predictions within uncertainty interval: 125029/200000 (62.51%)

Epoch 121, Batch 100/3125, Loss: 0.9560352563858032, Uncertainty: 1.1692829132080078
Epoch 21, Batch 400/3125, Loss: 4.9973602294921875, Uncertainty: 3.805511951446533
Epoch 121, Batch 200/3125, Loss: 1.1006639003753662, Uncertainty: 1.3801946640014648
Epoch 21, Batch 500/3125, Loss: 5.135410308837891, Uncertainty: 3.714742422103882
Epoch 121, Batch 300/3125, Loss: 1.259873867034912, Uncertainty: 1.6249666213989258
Epoch 21, Batch 600/3125, Loss: 5.454869270324707, Uncertainty: 4.141739845275879
Epoch 121, Batch 400/3125, Loss: 1.0700833797454834, Uncertainty: 1.3472872972488403
Epoch 21, Batch 700/3125, Loss: 4.894270896911621, Uncertainty: 3.9309701919555664
Epoch 121, Batch 500/3125, Loss: 1.0908052921295166, Uncertainty: 1.423758625984192
Epoch 21, Batch 800/3125, Loss: 5.374178409576416, Uncertainty: 4.1182355880737305
Epoch 121, Batch 600/3125, Loss: 1.457126498222351, Uncertainty: 1.6653766632080078
Epoch 21, Batch 900/3125, Loss: 5.660400390625, Uncertainty: 5.635604381561279
Epoch 121, Batch 700/3125, Loss: 1.0915693044662476, Uncertainty: 1.2800438404083252
Epoch 21, Batch 1000/3125, Loss: 6.026485443115234, Uncertainty: 7.985867977142334
Epoch 121, Batch 800/3125, Loss: 1.205234408378601, Uncertainty: 1.5114487409591675
Epoch 21, Batch 1100/3125, Loss: 5.314878463745117, Uncertainty: 3.9785823822021484
Epoch 121, Batch 900/3125, Loss: 1.1837315559387207, Uncertainty: 1.4472591876983643
Epoch 121, Batch 1000/3125, Loss: 1.1621394157409668, Uncertainty: 1.4209024906158447
Epoch 21, Batch 1200/3125, Loss: 5.3362579345703125, Uncertainty: 4.6840291023254395
Epoch 121, Batch 1100/3125, Loss: 1.1670045852661133, Uncertainty: 1.659673810005188
Epoch 21, Batch 1300/3125, Loss: 5.025237560272217, Uncertainty: 3.4763803482055664
Epoch 121, Batch 1200/3125, Loss: 1.3274760246276855, Uncertainty: 1.9782688617706299
Epoch 21, Batch 1400/3125, Loss: 5.262059211730957, Uncertainty: 4.614328861236572
Epoch 121, Batch 1300/3125, Loss: 1.0516760349273682, Uncertainty: 1.3071837425231934
Epoch 21, Batch 1500/3125, Loss: 5.180267333984375, Uncertainty: 4.651127815246582
Epoch 121, Batch 1400/3125, Loss: 1.155590534210205, Uncertainty: 1.3568047285079956
Epoch 21, Batch 1600/3125, Loss: 5.056005477905273, Uncertainty: 3.7918484210968018
Epoch 121, Batch 1500/3125, Loss: 1.1915135383605957, Uncertainty: 1.3067400455474854
Epoch 21, Batch 1700/3125, Loss: 5.752813816070557, Uncertainty: 4.247809410095215
Epoch 121, Batch 1600/3125, Loss: 0.9574123024940491, Uncertainty: 1.1781500577926636
Epoch 21, Batch 1800/3125, Loss: 5.585833549499512, Uncertainty: 4.313503265380859
Epoch 121, Batch 1700/3125, Loss: 1.123084545135498, Uncertainty: 1.563399076461792
Epoch 121, Batch 1800/3125, Loss: 1.1997801065444946, Uncertainty: 1.5486130714416504
Epoch 21, Batch 1900/3125, Loss: 5.260763168334961, Uncertainty: 3.7782187461853027
Epoch 121, Batch 1900/3125, Loss: 1.1498043537139893, Uncertainty: 1.7122225761413574
Epoch 21, Batch 2000/3125, Loss: 5.276611328125, Uncertainty: 3.962639331817627
Epoch 121, Batch 2000/3125, Loss: 1.0714577436447144, Uncertainty: 1.3570225238800049
Epoch 21, Batch 2100/3125, Loss: 5.025246620178223, Uncertainty: 4.171528339385986
Epoch 121, Batch 2100/3125, Loss: 1.297345519065857, Uncertainty: 1.4555532932281494
Epoch 21, Batch 2200/3125, Loss: 5.037020206451416, Uncertainty: 4.364032745361328
Epoch 121, Batch 2200/3125, Loss: 0.96923828125, Uncertainty: 1.1424858570098877
Epoch 21, Batch 2300/3125, Loss: 5.278474807739258, Uncertainty: 5.989060878753662
Epoch 121, Batch 2300/3125, Loss: 1.1527953147888184, Uncertainty: 1.4762089252471924
Epoch 21, Batch 2400/3125, Loss: 5.3028388023376465, Uncertainty: 4.165188789367676
Epoch 121, Batch 2400/3125, Loss: 1.191435694694519, Uncertainty: 1.4240682125091553
Epoch 121, Batch 2500/3125, Loss: 1.0565564632415771, Uncertainty: 1.3949477672576904
Epoch 21, Batch 2500/3125, Loss: 4.981078147888184, Uncertainty: 4.160953521728516
Epoch 121, Batch 2600/3125, Loss: 1.1624099016189575, Uncertainty: 1.555256962776184
Epoch 21, Batch 2600/3125, Loss: 5.835273742675781, Uncertainty: 5.762824058532715
Epoch 121, Batch 2700/3125, Loss: 1.2370498180389404, Uncertainty: 1.574365258216858
Epoch 21, Batch 2700/3125, Loss: 4.955623149871826, Uncertainty: 4.261219501495361
Epoch 121, Batch 2800/3125, Loss: 1.0058602094650269, Uncertainty: 1.3698844909667969
Epoch 21, Batch 2800/3125, Loss: 4.858488082885742, Uncertainty: 3.825223922729492
Epoch 121, Batch 2900/3125, Loss: 1.1609597206115723, Uncertainty: 1.5149288177490234
Epoch 21, Batch 2900/3125, Loss: 5.318726539611816, Uncertainty: 3.4900295734405518
Epoch 121, Batch 3000/3125, Loss: 1.1990909576416016, Uncertainty: 1.4301769733428955
Epoch 21, Batch 3000/3125, Loss: 5.353043556213379, Uncertainty: 4.677556037902832
Epoch 121, Batch 3100/3125, Loss: 1.175945520401001, Uncertainty: 1.6015079021453857
Epoch 21, Batch 3100/3125, Loss: 4.860254287719727, Uncertainty: 3.748434066772461

Training and Validation Results of Epoch 121:
================================
Training Loss: 0.9150057304954529, Training Uncertainty: 1.4254694207572938, time: 169.06761860847473
Validation Loss: 0.7879148720170531, Validation Uncertainty: 2.0358348760153633, time: 40.45598030090332
Number of predictions within uncertainty interval: 129538/200000 (64.77%)

Epoch 122, Batch 100/3125, Loss: 1.1042832136154175, Uncertainty: 1.1839141845703125

Training and Validation Results of Epoch 21:
================================
Training Loss: 4.872450005264282, Training Uncertainty: 4.4011358957672115, time: 193.30952763557434
Validation Loss: 4.563491750251302, Validation Uncertainty: 6.276609829319712, time: 44.211472511291504
Number of predictions within uncertainty interval: 80278/200000 (40.14%)

Epoch 122, Batch 200/3125, Loss: 1.08782160282135, Uncertainty: 1.3396250009536743
Epoch 22, Batch 100/3125, Loss: 4.697454452514648, Uncertainty: 3.3750388622283936
Epoch 122, Batch 300/3125, Loss: 1.2264602184295654, Uncertainty: 1.4251015186309814
Epoch 22, Batch 200/3125, Loss: 5.631449222564697, Uncertainty: 4.270657539367676
Epoch 122, Batch 400/3125, Loss: 1.047980785369873, Uncertainty: 1.278581142425537
Epoch 122, Batch 500/3125, Loss: 1.0773717164993286, Uncertainty: 1.421398639678955
Epoch 22, Batch 300/3125, Loss: 4.806784152984619, Uncertainty: 4.433208465576172
Epoch 122, Batch 600/3125, Loss: 1.2576457262039185, Uncertainty: 1.322495698928833
Epoch 22, Batch 400/3125, Loss: 4.712809085845947, Uncertainty: 3.5331592559814453
Epoch 122, Batch 700/3125, Loss: 1.056003212928772, Uncertainty: 1.2750186920166016
Epoch 22, Batch 500/3125, Loss: 5.234419822692871, Uncertainty: 4.331873416900635
Epoch 122, Batch 800/3125, Loss: 1.1252039670944214, Uncertainty: 1.2724957466125488
Epoch 22, Batch 600/3125, Loss: 5.367612838745117, Uncertainty: 6.345621585845947
Epoch 122, Batch 900/3125, Loss: 1.218470811843872, Uncertainty: 1.472130537033081
Epoch 22, Batch 700/3125, Loss: 5.418776512145996, Uncertainty: 5.622255325317383
Epoch 122, Batch 1000/3125, Loss: 1.0101702213287354, Uncertainty: 1.17637300491333
Epoch 22, Batch 800/3125, Loss: 5.01558256149292, Uncertainty: 3.7554588317871094
Epoch 122, Batch 1100/3125, Loss: 1.0920195579528809, Uncertainty: 1.423585295677185
Epoch 122, Batch 1200/3125, Loss: 1.2201008796691895, Uncertainty: 1.5314009189605713
Epoch 22, Batch 900/3125, Loss: 5.090263843536377, Uncertainty: 3.9094531536102295
Epoch 122, Batch 1300/3125, Loss: 1.0532156229019165, Uncertainty: 1.3036633729934692
Epoch 22, Batch 1000/3125, Loss: 5.896721839904785, Uncertainty: 8.059906005859375
Epoch 122, Batch 1400/3125, Loss: 1.1147937774658203, Uncertainty: 1.3570632934570312
Epoch 22, Batch 1100/3125, Loss: 5.754946708679199, Uncertainty: 6.4579668045043945
Epoch 122, Batch 1500/3125, Loss: 1.2001293897628784, Uncertainty: 1.350423812866211
Epoch 22, Batch 1200/3125, Loss: 5.075571060180664, Uncertainty: 4.254019737243652
Epoch 122, Batch 1600/3125, Loss: 0.9852796792984009, Uncertainty: 1.3031208515167236
Epoch 22, Batch 1300/3125, Loss: 4.887500762939453, Uncertainty: 4.346012115478516
Epoch 122, Batch 1700/3125, Loss: 1.2916150093078613, Uncertainty: 1.9885356426239014
Epoch 22, Batch 1400/3125, Loss: 5.013758659362793, Uncertainty: 3.476104736328125
Epoch 122, Batch 1800/3125, Loss: 1.2327854633331299, Uncertainty: 1.7385313510894775
Epoch 22, Batch 1500/3125, Loss: 5.2883124351501465, Uncertainty: 4.552434921264648
Epoch 122, Batch 1900/3125, Loss: 1.0343458652496338, Uncertainty: 1.4961071014404297
Epoch 22, Batch 1600/3125, Loss: 5.0967793464660645, Uncertainty: 5.244098663330078
Epoch 122, Batch 2000/3125, Loss: 1.0765049457550049, Uncertainty: 1.3339147567749023
Epoch 22, Batch 1700/3125, Loss: 5.644526481628418, Uncertainty: 5.484807968139648
Epoch 122, Batch 2100/3125, Loss: 1.2762655019760132, Uncertainty: 1.4307854175567627
Epoch 22, Batch 1800/3125, Loss: 5.252928733825684, Uncertainty: 2.8577847480773926
Epoch 122, Batch 2200/3125, Loss: 0.9747275710105896, Uncertainty: 1.3072783946990967
Epoch 22, Batch 1900/3125, Loss: 5.759847640991211, Uncertainty: 5.6136016845703125
Epoch 122, Batch 2300/3125, Loss: 1.1542704105377197, Uncertainty: 1.4471771717071533
Epoch 122, Batch 2400/3125, Loss: 1.1581439971923828, Uncertainty: 1.4102723598480225
Epoch 22, Batch 2000/3125, Loss: 5.160661697387695, Uncertainty: 3.7317709922790527
Epoch 122, Batch 2500/3125, Loss: 1.1160893440246582, Uncertainty: 1.6116154193878174
Epoch 22, Batch 2100/3125, Loss: 4.8870744705200195, Uncertainty: 4.356035232543945
Epoch 122, Batch 2600/3125, Loss: 1.1574640274047852, Uncertainty: 1.5946227312088013
Epoch 22, Batch 2200/3125, Loss: 4.9375810623168945, Uncertainty: 4.885258197784424
Epoch 122, Batch 2700/3125, Loss: 1.2799458503723145, Uncertainty: 1.6654082536697388
Epoch 22, Batch 2300/3125, Loss: 5.028110504150391, Uncertainty: 2.9745588302612305
Epoch 122, Batch 2800/3125, Loss: 0.9435803890228271, Uncertainty: 1.2589164972305298
Epoch 22, Batch 2400/3125, Loss: 5.151984214782715, Uncertainty: 4.319789409637451
Epoch 122, Batch 2900/3125, Loss: 1.1061723232269287, Uncertainty: 1.4380314350128174
Epoch 22, Batch 2500/3125, Loss: 5.012655258178711, Uncertainty: 4.524237155914307
Epoch 122, Batch 3000/3125, Loss: 1.1917059421539307, Uncertainty: 1.5122023820877075
Epoch 22, Batch 2600/3125, Loss: 5.720195770263672, Uncertainty: 4.28417444229126
Epoch 122, Batch 3100/3125, Loss: 1.1221895217895508, Uncertainty: 1.3507481813430786
Epoch 22, Batch 2700/3125, Loss: 5.192304611206055, Uncertainty: 3.724916458129883
Epoch 22, Batch 2800/3125, Loss: 4.788451194763184, Uncertainty: 4.121976375579834
Epoch 22, Batch 2900/3125, Loss: 5.2177510261535645, Uncertainty: 3.640604257583618
Epoch 22, Batch 3000/3125, Loss: 5.748195171356201, Uncertainty: 5.734733581542969
Epoch 22, Batch 3100/3125, Loss: 5.21849250793457, Uncertainty: 3.943057060241699

Training and Validation Results of Epoch 122:
================================
Training Loss: 0.9055062950897217, Training Uncertainty: 1.4081578441238403, time: 171.82268571853638
Validation Loss: 0.7941540539112237, Validation Uncertainty: 2.016863750222394, time: 39.229345083236694
Number of predictions within uncertainty interval: 128037/200000 (64.02%)

Epoch 123, Batch 100/3125, Loss: 1.12337064743042, Uncertainty: 1.131253719329834
Epoch 123, Batch 200/3125, Loss: 1.1118221282958984, Uncertainty: 1.4087152481079102
Epoch 123, Batch 300/3125, Loss: 1.181929588317871, Uncertainty: 1.3426294326782227
Epoch 123, Batch 400/3125, Loss: 1.092531681060791, Uncertainty: 1.3033486604690552
Epoch 123, Batch 500/3125, Loss: 1.104677677154541, Uncertainty: 1.4951406717300415
Epoch 123, Batch 600/3125, Loss: 1.2408009767532349, Uncertainty: 1.344843864440918

Training and Validation Results of Epoch 22:
================================
Training Loss: 4.765311202392578, Training Uncertainty: 4.381216466751098, time: 194.00781226158142
Validation Loss: 4.453331177191966, Validation Uncertainty: 5.8757202485028435, time: 44.27100610733032
Number of predictions within uncertainty interval: 76835/200000 (38.42%)

Epoch 123, Batch 700/3125, Loss: 1.1194474697113037, Uncertainty: 1.3021934032440186
Epoch 23, Batch 100/3125, Loss: 4.840383529663086, Uncertainty: 3.3657758235931396
Epoch 123, Batch 800/3125, Loss: 1.1667845249176025, Uncertainty: 1.4221742153167725
Epoch 23, Batch 200/3125, Loss: 6.019523620605469, Uncertainty: 4.993104457855225
Epoch 123, Batch 900/3125, Loss: 1.2047159671783447, Uncertainty: 1.4597443342208862
Epoch 23, Batch 300/3125, Loss: 4.775852203369141, Uncertainty: 3.604734420776367
Epoch 123, Batch 1000/3125, Loss: 1.0119061470031738, Uncertainty: 1.207284688949585
Epoch 123, Batch 1100/3125, Loss: 1.1190872192382812, Uncertainty: 1.355992078781128
Epoch 23, Batch 400/3125, Loss: 5.406583309173584, Uncertainty: 3.7755911350250244
Epoch 123, Batch 1200/3125, Loss: 1.2254668474197388, Uncertainty: 1.5361313819885254
Epoch 23, Batch 500/3125, Loss: 4.945810317993164, Uncertainty: 3.5770339965820312
Epoch 123, Batch 1300/3125, Loss: 1.0284175872802734, Uncertainty: 1.1615569591522217
Epoch 23, Batch 600/3125, Loss: 5.049110412597656, Uncertainty: 4.875426769256592
Epoch 123, Batch 1400/3125, Loss: 1.1429991722106934, Uncertainty: 1.5021326541900635
Epoch 23, Batch 700/3125, Loss: 4.883554458618164, Uncertainty: 3.455947160720825
Epoch 123, Batch 1500/3125, Loss: 1.2007399797439575, Uncertainty: 1.2945570945739746
Epoch 23, Batch 800/3125, Loss: 4.989884376525879, Uncertainty: 3.8584976196289062
Epoch 123, Batch 1600/3125, Loss: 0.9626708626747131, Uncertainty: 1.2788293361663818
Epoch 23, Batch 900/3125, Loss: 5.789487838745117, Uncertainty: 4.0573015213012695
Epoch 123, Batch 1700/3125, Loss: 1.1648741960525513, Uncertainty: 1.7452750205993652
Epoch 23, Batch 1000/3125, Loss: 4.917178153991699, Uncertainty: 4.510990142822266
Epoch 123, Batch 1800/3125, Loss: 1.1739588975906372, Uncertainty: 1.5135562419891357
Epoch 23, Batch 1100/3125, Loss: 4.96614408493042, Uncertainty: 3.3976316452026367
Epoch 123, Batch 1900/3125, Loss: 1.1383628845214844, Uncertainty: 1.6945443153381348
Epoch 23, Batch 1200/3125, Loss: 5.629691123962402, Uncertainty: 4.688108444213867
Epoch 123, Batch 2000/3125, Loss: 1.0527832508087158, Uncertainty: 1.3312289714813232
Epoch 23, Batch 1300/3125, Loss: 4.534458637237549, Uncertainty: 3.3283393383026123
Epoch 123, Batch 2100/3125, Loss: 1.2670316696166992, Uncertainty: 1.4795372486114502
Epoch 23, Batch 1400/3125, Loss: 5.292614936828613, Uncertainty: 3.7317488193511963
Epoch 123, Batch 2200/3125, Loss: 0.9531927108764648, Uncertainty: 1.1217595338821411
Epoch 23, Batch 1500/3125, Loss: 5.201552867889404, Uncertainty: 4.378456115722656
Epoch 123, Batch 2300/3125, Loss: 1.1732035875320435, Uncertainty: 1.5229687690734863
Epoch 23, Batch 1600/3125, Loss: 4.3792290687561035, Uncertainty: 3.410691976547241
Epoch 123, Batch 2400/3125, Loss: 1.172347068786621, Uncertainty: 1.4677425622940063
Epoch 23, Batch 1700/3125, Loss: 4.8050642013549805, Uncertainty: 4.13955545425415
Epoch 123, Batch 2500/3125, Loss: 1.0583863258361816, Uncertainty: 1.5091993808746338
Epoch 23, Batch 1800/3125, Loss: 5.065681457519531, Uncertainty: 3.308255910873413
Epoch 123, Batch 2600/3125, Loss: 1.1905664205551147, Uncertainty: 1.6529479026794434
Epoch 23, Batch 1900/3125, Loss: 5.1956634521484375, Uncertainty: 4.066249847412109
Epoch 123, Batch 2700/3125, Loss: 1.2256834506988525, Uncertainty: 1.5956647396087646
Epoch 123, Batch 2800/3125, Loss: 0.9492665529251099, Uncertainty: 1.2232685089111328
Epoch 23, Batch 2000/3125, Loss: 5.31123161315918, Uncertainty: 5.533463001251221
Epoch 123, Batch 2900/3125, Loss: 1.1213897466659546, Uncertainty: 1.3634523153305054
Epoch 23, Batch 2100/3125, Loss: 4.7241129875183105, Uncertainty: 3.959624767303467
Epoch 123, Batch 3000/3125, Loss: 1.1633132696151733, Uncertainty: 1.4045424461364746
Epoch 23, Batch 2200/3125, Loss: 4.370256423950195, Uncertainty: 3.5448601245880127
Epoch 123, Batch 3100/3125, Loss: 1.065584421157837, Uncertainty: 1.2960379123687744
Epoch 23, Batch 2300/3125, Loss: 4.493926048278809, Uncertainty: 3.2254183292388916
Epoch 23, Batch 2400/3125, Loss: 4.961767196655273, Uncertainty: 4.492487907409668
Epoch 23, Batch 2500/3125, Loss: 4.720632553100586, Uncertainty: 4.394447326660156
Epoch 23, Batch 2600/3125, Loss: 5.479241847991943, Uncertainty: 4.354443550109863
Epoch 23, Batch 2700/3125, Loss: 4.728178024291992, Uncertainty: 3.702225685119629
Epoch 23, Batch 2800/3125, Loss: 5.127433776855469, Uncertainty: 4.167690277099609
Epoch 23, Batch 2900/3125, Loss: 5.16024923324585, Uncertainty: 3.5662195682525635

Training and Validation Results of Epoch 123:
================================
Training Loss: 0.9097279502296448, Training Uncertainty: 1.4155332864379884, time: 178.0956916809082
Validation Loss: 0.7801916615280045, Validation Uncertainty: 1.989446827517751, time: 41.34566950798035
Number of predictions within uncertainty interval: 128005/200000 (64.00%)

Epoch 23, Batch 3000/3125, Loss: 5.098391532897949, Uncertainty: 4.5148468017578125
Epoch 124, Batch 100/3125, Loss: 0.9388774633407593, Uncertainty: 1.0995174646377563
Epoch 23, Batch 3100/3125, Loss: 4.924487113952637, Uncertainty: 3.989633321762085
Epoch 124, Batch 200/3125, Loss: 1.0920979976654053, Uncertainty: 1.3257923126220703
Epoch 124, Batch 300/3125, Loss: 1.2187385559082031, Uncertainty: 1.4458117485046387
Epoch 124, Batch 400/3125, Loss: 1.0521912574768066, Uncertainty: 1.2836663722991943
Epoch 124, Batch 500/3125, Loss: 1.0852973461151123, Uncertainty: 1.458561897277832
Epoch 124, Batch 600/3125, Loss: 1.2400286197662354, Uncertainty: 1.3259766101837158
Epoch 124, Batch 700/3125, Loss: 1.0496735572814941, Uncertainty: 1.2571536302566528
Epoch 124, Batch 800/3125, Loss: 1.2766141891479492, Uncertainty: 1.7863048315048218
Epoch 124, Batch 900/3125, Loss: 1.208195447921753, Uncertainty: 1.5078903436660767

Training and Validation Results of Epoch 23:
================================
Training Loss: 4.639668431091309, Training Uncertainty: 4.32714482131958, time: 193.83957076072693
Validation Loss: 4.245831533161271, Validation Uncertainty: 6.149397344540452, time: 44.316102027893066
Number of predictions within uncertainty interval: 85816/200000 (42.91%)

Epoch 124, Batch 1000/3125, Loss: 0.9852108955383301, Uncertainty: 1.1697055101394653
Epoch 24, Batch 100/3125, Loss: 4.750574588775635, Uncertainty: 5.123883247375488
Epoch 124, Batch 1100/3125, Loss: 1.1103971004486084, Uncertainty: 1.5135538578033447
Epoch 24, Batch 200/3125, Loss: 5.082826614379883, Uncertainty: 4.3493781089782715
Epoch 124, Batch 1200/3125, Loss: 1.1572628021240234, Uncertainty: 1.4052481651306152
Epoch 24, Batch 300/3125, Loss: 4.516080856323242, Uncertainty: 3.723726987838745
Epoch 124, Batch 1300/3125, Loss: 1.0115242004394531, Uncertainty: 1.1505606174468994
Epoch 24, Batch 400/3125, Loss: 4.645992755889893, Uncertainty: 4.695934295654297
Epoch 124, Batch 1400/3125, Loss: 1.0614893436431885, Uncertainty: 1.4050824642181396
Epoch 24, Batch 500/3125, Loss: 5.670895099639893, Uncertainty: 4.752786159515381
Epoch 124, Batch 1500/3125, Loss: 1.1843976974487305, Uncertainty: 1.3268563747406006
Epoch 124, Batch 1600/3125, Loss: 0.9213963747024536, Uncertainty: 1.1403493881225586
Epoch 24, Batch 600/3125, Loss: 5.149827480316162, Uncertainty: 4.182785987854004
Epoch 124, Batch 1700/3125, Loss: 1.1486988067626953, Uncertainty: 1.6758344173431396
Epoch 24, Batch 700/3125, Loss: 4.628570556640625, Uncertainty: 3.8930251598358154
Epoch 124, Batch 1800/3125, Loss: 1.234300971031189, Uncertainty: 1.7617888450622559
Epoch 24, Batch 800/3125, Loss: 4.8987274169921875, Uncertainty: 3.928140640258789
Epoch 124, Batch 1900/3125, Loss: 0.9184155464172363, Uncertainty: 1.2384581565856934
Epoch 24, Batch 900/3125, Loss: 5.556577682495117, Uncertainty: 7.038169860839844
Epoch 124, Batch 2000/3125, Loss: 1.1008288860321045, Uncertainty: 1.3777074813842773
Epoch 24, Batch 1000/3125, Loss: 5.893091678619385, Uncertainty: 8.248004913330078
Epoch 124, Batch 2100/3125, Loss: 1.47286856174469, Uncertainty: 1.8157728910446167
Epoch 24, Batch 1100/3125, Loss: 5.166221618652344, Uncertainty: 4.741462230682373
Epoch 124, Batch 2200/3125, Loss: 0.9878994822502136, Uncertainty: 1.2149548530578613
Epoch 24, Batch 1200/3125, Loss: 5.0923027992248535, Uncertainty: 5.1314377784729
Epoch 124, Batch 2300/3125, Loss: 1.1200995445251465, Uncertainty: 1.4059686660766602
Epoch 24, Batch 1300/3125, Loss: 4.757652759552002, Uncertainty: 4.539862632751465
Epoch 124, Batch 2400/3125, Loss: 1.3384692668914795, Uncertainty: 1.8856446743011475
Epoch 24, Batch 1400/3125, Loss: 4.764850616455078, Uncertainty: 3.418184280395508
Epoch 124, Batch 2500/3125, Loss: 1.127300500869751, Uncertainty: 1.6602075099945068
Epoch 24, Batch 1500/3125, Loss: 4.192080497741699, Uncertainty: 4.132696628570557
Epoch 124, Batch 2600/3125, Loss: 1.2197229862213135, Uncertainty: 1.674743413925171
Epoch 24, Batch 1600/3125, Loss: 4.308359146118164, Uncertainty: 3.635279893875122
Epoch 124, Batch 2700/3125, Loss: 1.235724925994873, Uncertainty: 1.582162857055664
Epoch 24, Batch 1700/3125, Loss: 4.680149078369141, Uncertainty: 3.641425132751465
Epoch 124, Batch 2800/3125, Loss: 0.9606866836547852, Uncertainty: 1.2730507850646973
Epoch 24, Batch 1800/3125, Loss: 4.627494812011719, Uncertainty: 4.135015487670898
Epoch 124, Batch 2900/3125, Loss: 1.1639506816864014, Uncertainty: 1.373786449432373
Epoch 24, Batch 1900/3125, Loss: 4.4601263999938965, Uncertainty: 4.206269264221191
Epoch 124, Batch 3000/3125, Loss: 1.1793789863586426, Uncertainty: 1.4337538480758667
Epoch 24, Batch 2000/3125, Loss: 5.051957130432129, Uncertainty: 4.23369026184082
Epoch 124, Batch 3100/3125, Loss: 1.0235157012939453, Uncertainty: 1.2549896240234375
Epoch 24, Batch 2100/3125, Loss: 4.596691131591797, Uncertainty: 4.761960983276367
Epoch 24, Batch 2200/3125, Loss: 4.376079559326172, Uncertainty: 4.549651145935059
Epoch 24, Batch 2300/3125, Loss: 4.766216278076172, Uncertainty: 3.324463129043579
Epoch 24, Batch 2400/3125, Loss: 4.589364051818848, Uncertainty: 4.020744323730469
Epoch 24, Batch 2500/3125, Loss: 4.406102180480957, Uncertainty: 4.777895450592041
Epoch 24, Batch 2600/3125, Loss: 5.351666450500488, Uncertainty: 5.185312271118164
Epoch 24, Batch 2700/3125, Loss: 4.680874824523926, Uncertainty: 4.958415508270264

Training and Validation Results of Epoch 124:
================================
Training Loss: 0.9025765142059327, Training Uncertainty: 1.4103509754943848, time: 180.63381695747375
Validation Loss: 0.7795300345744014, Validation Uncertainty: 1.9773298573615912, time: 42.55058836936951
Number of predictions within uncertainty interval: 127578/200000 (63.79%)

Epoch 24, Batch 2800/3125, Loss: 4.903535842895508, Uncertainty: 3.9731740951538086
Epoch 125, Batch 100/3125, Loss: 0.9882463216781616, Uncertainty: 1.111770749092102
Epoch 24, Batch 2900/3125, Loss: 5.083686351776123, Uncertainty: 3.9218225479125977
Epoch 125, Batch 200/3125, Loss: 1.075899600982666, Uncertainty: 1.3574599027633667
Epoch 24, Batch 3000/3125, Loss: 5.0677924156188965, Uncertainty: 6.016202926635742
Epoch 125, Batch 300/3125, Loss: 1.3239121437072754, Uncertainty: 1.7033135890960693
Epoch 24, Batch 3100/3125, Loss: 4.868851661682129, Uncertainty: 4.773064613342285
Epoch 125, Batch 400/3125, Loss: 1.2867457866668701, Uncertainty: 1.8766975402832031
Epoch 125, Batch 500/3125, Loss: 1.0366899967193604, Uncertainty: 1.2935264110565186
Epoch 125, Batch 600/3125, Loss: 1.2419612407684326, Uncertainty: 1.3694136142730713
Epoch 125, Batch 700/3125, Loss: 1.065528392791748, Uncertainty: 1.2652270793914795
Epoch 125, Batch 800/3125, Loss: 1.161248803138733, Uncertainty: 1.2978148460388184
Epoch 125, Batch 900/3125, Loss: 1.1693193912506104, Uncertainty: 1.4039865732192993
Epoch 125, Batch 1000/3125, Loss: 1.010953426361084, Uncertainty: 1.247814655303955
Epoch 125, Batch 1100/3125, Loss: 1.0535880327224731, Uncertainty: 1.3706462383270264
Epoch 125, Batch 1200/3125, Loss: 1.1994061470031738, Uncertainty: 1.4758307933807373

Training and Validation Results of Epoch 24:
================================
Training Loss: 4.393882343597412, Training Uncertainty: 4.477328553085327, time: 192.68159556388855
Validation Loss: 3.931198839336405, Validation Uncertainty: 6.114133192755072, time: 43.83792591094971
Number of predictions within uncertainty interval: 89258/200000 (44.63%)

Epoch 125, Batch 1300/3125, Loss: 1.0199708938598633, Uncertainty: 1.235000729560852
Epoch 25, Batch 100/3125, Loss: 4.497708797454834, Uncertainty: 4.213435173034668
Epoch 125, Batch 1400/3125, Loss: 1.0927097797393799, Uncertainty: 1.4024063348770142
Epoch 25, Batch 200/3125, Loss: 5.126996994018555, Uncertainty: 4.205691814422607
Epoch 125, Batch 1500/3125, Loss: 1.1909838914871216, Uncertainty: 1.2835798263549805
Epoch 25, Batch 300/3125, Loss: 4.053817272186279, Uncertainty: 3.6266326904296875
Epoch 125, Batch 1600/3125, Loss: 0.9397220015525818, Uncertainty: 1.1765071153640747
Epoch 25, Batch 400/3125, Loss: 3.954136848449707, Uncertainty: 3.6951704025268555
Epoch 125, Batch 1700/3125, Loss: 1.0299451351165771, Uncertainty: 1.361748218536377
Epoch 25, Batch 500/3125, Loss: 5.48088264465332, Uncertainty: 5.514077186584473
Epoch 125, Batch 1800/3125, Loss: 1.2464137077331543, Uncertainty: 1.730753779411316
Epoch 25, Batch 600/3125, Loss: 4.335639953613281, Uncertainty: 4.383030891418457
Epoch 125, Batch 1900/3125, Loss: 1.1275081634521484, Uncertainty: 1.5940380096435547
Epoch 25, Batch 700/3125, Loss: 4.318359851837158, Uncertainty: 3.706871509552002
Epoch 125, Batch 2000/3125, Loss: 1.1256024837493896, Uncertainty: 1.4734758138656616
Epoch 125, Batch 2100/3125, Loss: 1.302201509475708, Uncertainty: 1.5646300315856934
Epoch 25, Batch 800/3125, Loss: 4.733247756958008, Uncertainty: 3.3575427532196045
Epoch 125, Batch 2200/3125, Loss: 0.963657021522522, Uncertainty: 1.0851224660873413
Epoch 25, Batch 900/3125, Loss: 4.294214248657227, Uncertainty: 3.6404333114624023
Epoch 125, Batch 2300/3125, Loss: 1.128808617591858, Uncertainty: 1.4148274660110474
Epoch 25, Batch 1000/3125, Loss: 4.223994731903076, Uncertainty: 3.8814845085144043
Epoch 125, Batch 2400/3125, Loss: 1.2150187492370605, Uncertainty: 1.5823450088500977
Epoch 25, Batch 1100/3125, Loss: 4.843803405761719, Uncertainty: 4.461014270782471
Epoch 125, Batch 2500/3125, Loss: 1.053154706954956, Uncertainty: 1.5505938529968262
Epoch 25, Batch 1200/3125, Loss: 4.5005950927734375, Uncertainty: 5.000705718994141
Epoch 125, Batch 2600/3125, Loss: 1.1974263191223145, Uncertainty: 1.6030256748199463
Epoch 25, Batch 1300/3125, Loss: 4.425586700439453, Uncertainty: 4.02437686920166
Epoch 125, Batch 2700/3125, Loss: 1.2243614196777344, Uncertainty: 1.5871012210845947
Epoch 25, Batch 1400/3125, Loss: 4.6020731925964355, Uncertainty: 4.458416938781738
Epoch 125, Batch 2800/3125, Loss: 0.9408482313156128, Uncertainty: 1.2351289987564087
Epoch 25, Batch 1500/3125, Loss: 4.293028831481934, Uncertainty: 3.8733856678009033
Epoch 125, Batch 2900/3125, Loss: 1.1200858354568481, Uncertainty: 1.3860998153686523
Epoch 125, Batch 3000/3125, Loss: 1.1486984491348267, Uncertainty: 1.3708206415176392
Epoch 25, Batch 1600/3125, Loss: 5.038690567016602, Uncertainty: 7.037755012512207
Epoch 125, Batch 3100/3125, Loss: 1.10836923122406, Uncertainty: 1.4947669506072998
Epoch 25, Batch 1700/3125, Loss: 4.597085952758789, Uncertainty: 3.7151713371276855
Epoch 25, Batch 1800/3125, Loss: 4.519371509552002, Uncertainty: 4.410762786865234
Epoch 25, Batch 1900/3125, Loss: 4.30760383605957, Uncertainty: 4.336740493774414
Epoch 25, Batch 2000/3125, Loss: 4.612306594848633, Uncertainty: 3.813542604446411
Epoch 25, Batch 2100/3125, Loss: 4.4954118728637695, Uncertainty: 5.038206577301025
Epoch 25, Batch 2200/3125, Loss: 3.9463815689086914, Uncertainty: 3.9858880043029785
Epoch 25, Batch 2300/3125, Loss: 4.935768127441406, Uncertainty: 6.415604591369629

Training and Validation Results of Epoch 125:
================================
Training Loss: 0.8981393139076232, Training Uncertainty: 1.4089965340423585, time: 173.72079277038574
Validation Loss: 0.7802433307518435, Validation Uncertainty: 2.0638058575827753, time: 39.66665863990784
Number of predictions within uncertainty interval: 131289/200000 (65.64%)

Epoch 25, Batch 2400/3125, Loss: 4.5771613121032715, Uncertainty: 4.4552507400512695
Epoch 126, Batch 100/3125, Loss: 1.0208723545074463, Uncertainty: 1.1816551685333252
Epoch 25, Batch 2500/3125, Loss: 4.110321044921875, Uncertainty: 4.502806663513184
Epoch 126, Batch 200/3125, Loss: 1.0753271579742432, Uncertainty: 1.3273595571517944
Epoch 25, Batch 2600/3125, Loss: 5.247527122497559, Uncertainty: 3.9595394134521484
Epoch 126, Batch 300/3125, Loss: 1.2674224376678467, Uncertainty: 1.666534423828125
Epoch 25, Batch 2700/3125, Loss: 4.359841346740723, Uncertainty: 3.9330673217773438
Epoch 126, Batch 400/3125, Loss: 1.126817226409912, Uncertainty: 1.512333869934082
Epoch 126, Batch 500/3125, Loss: 1.0859860181808472, Uncertainty: 1.3665739297866821
Epoch 25, Batch 2800/3125, Loss: 3.8867101669311523, Uncertainty: 3.8142006397247314
Epoch 126, Batch 600/3125, Loss: 1.2294859886169434, Uncertainty: 1.3795526027679443
Epoch 25, Batch 2900/3125, Loss: 4.554630279541016, Uncertainty: 4.379783630371094
Epoch 126, Batch 700/3125, Loss: 1.0658056735992432, Uncertainty: 1.241870403289795
Epoch 25, Batch 3000/3125, Loss: 4.975596904754639, Uncertainty: 4.7446489334106445
Epoch 126, Batch 800/3125, Loss: 1.2070986032485962, Uncertainty: 1.3926331996917725
Epoch 25, Batch 3100/3125, Loss: 3.962224006652832, Uncertainty: 3.7515907287597656
Epoch 126, Batch 900/3125, Loss: 1.154077410697937, Uncertainty: 1.4111474752426147
Epoch 126, Batch 1000/3125, Loss: 1.00588059425354, Uncertainty: 1.1807435750961304
Epoch 126, Batch 1100/3125, Loss: 1.073030948638916, Uncertainty: 1.4771411418914795
Epoch 126, Batch 1200/3125, Loss: 1.144152045249939, Uncertainty: 1.4551039934158325
Epoch 126, Batch 1300/3125, Loss: 1.0003490447998047, Uncertainty: 1.1344327926635742
Epoch 126, Batch 1400/3125, Loss: 1.0814564228057861, Uncertainty: 1.3637382984161377
Epoch 126, Batch 1500/3125, Loss: 1.1912460327148438, Uncertainty: 1.3255280256271362
Epoch 126, Batch 1600/3125, Loss: 0.9497320652008057, Uncertainty: 1.232816219329834
Epoch 126, Batch 1700/3125, Loss: 1.0748370885849, Uncertainty: 1.5154564380645752

Training and Validation Results of Epoch 25:
================================
Training Loss: 4.075283952102661, Training Uncertainty: 4.505870923690796, time: 193.41702461242676
Validation Loss: 3.7742236846548214, Validation Uncertainty: 7.281297133096953, time: 48.55311942100525
Number of predictions within uncertainty interval: 102841/200000 (51.42%)

Epoch 126, Batch 1800/3125, Loss: 1.2540466785430908, Uncertainty: 1.594320297241211
Epoch 26, Batch 100/3125, Loss: 4.020517349243164, Uncertainty: 3.7830471992492676
Epoch 126, Batch 1900/3125, Loss: 1.0083481073379517, Uncertainty: 1.4882786273956299
Epoch 26, Batch 200/3125, Loss: 4.492469310760498, Uncertainty: 4.974715232849121
Epoch 126, Batch 2000/3125, Loss: 1.0374823808670044, Uncertainty: 1.3155412673950195
Epoch 26, Batch 300/3125, Loss: 3.870208740234375, Uncertainty: 3.8756730556488037
Epoch 126, Batch 2100/3125, Loss: 1.2596790790557861, Uncertainty: 1.470581293106079
Epoch 26, Batch 400/3125, Loss: 3.7771801948547363, Uncertainty: 4.0862274169921875
Epoch 126, Batch 2200/3125, Loss: 1.0779049396514893, Uncertainty: 1.1881332397460938
Epoch 126, Batch 2300/3125, Loss: 1.2051258087158203, Uncertainty: 1.4353466033935547
Epoch 26, Batch 500/3125, Loss: 4.551156520843506, Uncertainty: 4.160946846008301
Epoch 126, Batch 2400/3125, Loss: 1.212156891822815, Uncertainty: 1.6238808631896973
Epoch 26, Batch 600/3125, Loss: 5.054587364196777, Uncertainty: 6.786634922027588
Epoch 126, Batch 2500/3125, Loss: 1.033384084701538, Uncertainty: 1.4832098484039307
Epoch 26, Batch 700/3125, Loss: 4.0392680168151855, Uncertainty: 3.509366989135742
Epoch 126, Batch 2600/3125, Loss: 1.3164398670196533, Uncertainty: 1.933760166168213
Epoch 26, Batch 800/3125, Loss: 4.369106769561768, Uncertainty: 3.3246374130249023
Epoch 126, Batch 2700/3125, Loss: 1.2444156408309937, Uncertainty: 1.6256897449493408
Epoch 26, Batch 900/3125, Loss: 5.518584251403809, Uncertainty: 8.823373794555664
Epoch 126, Batch 2800/3125, Loss: 1.01246976852417, Uncertainty: 1.5003435611724854
Epoch 26, Batch 1000/3125, Loss: 4.338615417480469, Uncertainty: 4.85244607925415
Epoch 126, Batch 2900/3125, Loss: 1.0625085830688477, Uncertainty: 1.3276907205581665
Epoch 26, Batch 1100/3125, Loss: 4.511736869812012, Uncertainty: 4.678449630737305
Epoch 126, Batch 3000/3125, Loss: 1.167663335800171, Uncertainty: 1.4035708904266357
Epoch 126, Batch 3100/3125, Loss: 1.088064432144165, Uncertainty: 1.3480589389801025
Epoch 26, Batch 1200/3125, Loss: 3.8115267753601074, Uncertainty: 3.962930679321289
Epoch 26, Batch 1300/3125, Loss: 3.9429664611816406, Uncertainty: 3.425004005432129
Epoch 26, Batch 1400/3125, Loss: 4.28570556640625, Uncertainty: 3.7192301750183105
Epoch 26, Batch 1500/3125, Loss: 4.29364013671875, Uncertainty: 5.348439693450928
Epoch 26, Batch 1600/3125, Loss: 4.001497268676758, Uncertainty: 4.712368488311768
Epoch 26, Batch 1700/3125, Loss: 4.188775539398193, Uncertainty: 3.8881664276123047
Epoch 26, Batch 1800/3125, Loss: 4.025747776031494, Uncertainty: 4.31450080871582

Training and Validation Results of Epoch 126:
================================
Training Loss: 0.8952106208992004, Training Uncertainty: 1.399798872680664, time: 172.55187034606934
Validation Loss: 0.797737968852148, Validation Uncertainty: 2.002714772358575, time: 39.91571283340454
Number of predictions within uncertainty interval: 127089/200000 (63.54%)

Epoch 26, Batch 1900/3125, Loss: 3.8002138137817383, Uncertainty: 3.576096534729004
Epoch 127, Batch 100/3125, Loss: 1.085936427116394, Uncertainty: 1.101240634918213
Epoch 26, Batch 2000/3125, Loss: 4.818666934967041, Uncertainty: 5.398468971252441
Epoch 127, Batch 200/3125, Loss: 1.0779211521148682, Uncertainty: 1.3321375846862793
Epoch 26, Batch 2100/3125, Loss: 4.311820983886719, Uncertainty: 4.399892807006836
Epoch 127, Batch 300/3125, Loss: 1.1827080249786377, Uncertainty: 1.4166569709777832
Epoch 26, Batch 2200/3125, Loss: 3.7307705879211426, Uncertainty: 4.015409469604492
Epoch 127, Batch 400/3125, Loss: 1.0368270874023438, Uncertainty: 1.4157919883728027
Epoch 26, Batch 2300/3125, Loss: 4.336112976074219, Uncertainty: 4.29690408706665
Epoch 127, Batch 500/3125, Loss: 1.0554512739181519, Uncertainty: 1.3886134624481201
Epoch 26, Batch 2400/3125, Loss: 4.01763916015625, Uncertainty: 4.056730270385742
Epoch 127, Batch 600/3125, Loss: 1.2345876693725586, Uncertainty: 1.3541874885559082
Epoch 127, Batch 700/3125, Loss: 1.0517977476119995, Uncertainty: 1.2389981746673584
Epoch 26, Batch 2500/3125, Loss: 3.6370317935943604, Uncertainty: 3.7861194610595703
Epoch 127, Batch 800/3125, Loss: 1.1266553401947021, Uncertainty: 1.3539479970932007
Epoch 26, Batch 2600/3125, Loss: 4.725680351257324, Uncertainty: 5.01777982711792
Epoch 127, Batch 900/3125, Loss: 1.228112816810608, Uncertainty: 1.4931910037994385
Epoch 26, Batch 2700/3125, Loss: 4.6279802322387695, Uncertainty: 3.977517604827881
Epoch 127, Batch 1000/3125, Loss: 0.9930713176727295, Uncertainty: 1.172210454940796
Epoch 26, Batch 2800/3125, Loss: 3.886406898498535, Uncertainty: 3.6644468307495117
Epoch 127, Batch 1100/3125, Loss: 1.0143691301345825, Uncertainty: 1.3165210485458374
Epoch 26, Batch 2900/3125, Loss: 4.692814350128174, Uncertainty: 5.333329677581787
Epoch 127, Batch 1200/3125, Loss: 1.1964566707611084, Uncertainty: 1.42038094997406
Epoch 26, Batch 3000/3125, Loss: 3.9826464653015137, Uncertainty: 3.871692657470703
Epoch 127, Batch 1300/3125, Loss: 0.9890300035476685, Uncertainty: 1.1201553344726562
Epoch 26, Batch 3100/3125, Loss: 3.5040297508239746, Uncertainty: 3.576016902923584
Epoch 127, Batch 1400/3125, Loss: 1.1400535106658936, Uncertainty: 1.5747236013412476
Epoch 127, Batch 1500/3125, Loss: 1.2042202949523926, Uncertainty: 1.292914867401123
Epoch 127, Batch 1600/3125, Loss: 0.9519846439361572, Uncertainty: 1.238904595375061
Epoch 127, Batch 1700/3125, Loss: 1.1795541048049927, Uncertainty: 1.7725462913513184
Epoch 127, Batch 1800/3125, Loss: 1.156633734703064, Uncertainty: 1.507487416267395
Epoch 127, Batch 1900/3125, Loss: 0.9403469562530518, Uncertainty: 1.3503684997558594
Epoch 127, Batch 2000/3125, Loss: 1.0365831851959229, Uncertainty: 1.2969417572021484
Epoch 127, Batch 2100/3125, Loss: 1.2328892946243286, Uncertainty: 1.4203890562057495

Training and Validation Results of Epoch 26:
================================
Training Loss: 3.7687639986419676, Training Uncertainty: 4.421664957504272, time: 192.36511278152466
Validation Loss: 3.4625048850808304, Validation Uncertainty: 5.991843675408522, time: 43.41370463371277
Number of predictions within uncertainty interval: 92558/200000 (46.28%)

Epoch 127, Batch 2200/3125, Loss: 0.9830659031867981, Uncertainty: 1.2166675329208374
Epoch 27, Batch 100/3125, Loss: 3.738279104232788, Uncertainty: 3.539283275604248
Epoch 127, Batch 2300/3125, Loss: 1.137739896774292, Uncertainty: 1.4243106842041016
Epoch 127, Batch 2400/3125, Loss: 1.3131318092346191, Uncertainty: 1.7437474727630615
Epoch 27, Batch 200/3125, Loss: 5.114645004272461, Uncertainty: 5.112788200378418
Epoch 127, Batch 2500/3125, Loss: 1.1210362911224365, Uncertainty: 1.6454813480377197
Epoch 27, Batch 300/3125, Loss: 3.8485703468322754, Uncertainty: 4.37617826461792
Epoch 127, Batch 2600/3125, Loss: 1.2418577671051025, Uncertainty: 1.7619097232818604
Epoch 27, Batch 400/3125, Loss: 3.593672752380371, Uncertainty: 3.4825525283813477
Epoch 127, Batch 2700/3125, Loss: 1.2151789665222168, Uncertainty: 1.5913677215576172
Epoch 27, Batch 500/3125, Loss: 4.296725749969482, Uncertainty: 4.288168907165527
Epoch 127, Batch 2800/3125, Loss: 0.9396906495094299, Uncertainty: 1.1966354846954346
Epoch 27, Batch 600/3125, Loss: 4.445293426513672, Uncertainty: 4.663402080535889
Epoch 127, Batch 2900/3125, Loss: 1.2625105381011963, Uncertainty: 1.4050425291061401
Epoch 127, Batch 3000/3125, Loss: 1.1645095348358154, Uncertainty: 1.3532153367996216
Epoch 27, Batch 700/3125, Loss: 3.7753522396087646, Uncertainty: 3.980085611343384
Epoch 127, Batch 3100/3125, Loss: 1.099097490310669, Uncertainty: 1.4018983840942383
Epoch 27, Batch 800/3125, Loss: 4.526736259460449, Uncertainty: 3.7002694606781006
Epoch 27, Batch 900/3125, Loss: 3.781296968460083, Uncertainty: 4.2978997230529785
Epoch 27, Batch 1000/3125, Loss: 3.841705322265625, Uncertainty: 3.6065752506256104
Epoch 27, Batch 1100/3125, Loss: 4.227971076965332, Uncertainty: 4.259071350097656
Epoch 27, Batch 1200/3125, Loss: 4.291084289550781, Uncertainty: 4.43948221206665
Epoch 27, Batch 1300/3125, Loss: 3.7891294956207275, Uncertainty: 4.544099807739258
Epoch 27, Batch 1400/3125, Loss: 4.064359664916992, Uncertainty: 3.581425189971924

Training and Validation Results of Epoch 127:
================================
Training Loss: 0.8912120347213746, Training Uncertainty: 1.4033784871292114, time: 171.84129095077515
Validation Loss: 0.7807113083884539, Validation Uncertainty: 1.9497262684585492, time: 39.979161977767944
Number of predictions within uncertainty interval: 126817/200000 (63.41%)

Epoch 27, Batch 1500/3125, Loss: 3.5845160484313965, Uncertainty: 3.702281951904297
Epoch 128, Batch 100/3125, Loss: 0.939332902431488, Uncertainty: 1.1185542345046997
Epoch 128, Batch 200/3125, Loss: 1.0647164583206177, Uncertainty: 1.3437787294387817
Epoch 27, Batch 1600/3125, Loss: 4.717079162597656, Uncertainty: 5.012921333312988
Epoch 128, Batch 300/3125, Loss: 1.205142855644226, Uncertainty: 1.463017463684082
Epoch 27, Batch 1700/3125, Loss: 4.077672481536865, Uncertainty: 4.1837310791015625
Epoch 128, Batch 400/3125, Loss: 1.0632739067077637, Uncertainty: 1.2894096374511719
Epoch 27, Batch 1800/3125, Loss: 4.4068145751953125, Uncertainty: 5.622282028198242
Epoch 128, Batch 500/3125, Loss: 1.043027400970459, Uncertainty: 1.3099207878112793
Epoch 27, Batch 1900/3125, Loss: 4.435441970825195, Uncertainty: 4.061152458190918
Epoch 128, Batch 600/3125, Loss: 1.2942893505096436, Uncertainty: 1.4607129096984863
Epoch 27, Batch 2000/3125, Loss: 4.3357038497924805, Uncertainty: 3.7033252716064453
Epoch 128, Batch 700/3125, Loss: 1.0753421783447266, Uncertainty: 1.2480077743530273
Epoch 27, Batch 2100/3125, Loss: 3.986079454421997, Uncertainty: 4.3706769943237305
Epoch 128, Batch 800/3125, Loss: 1.1146800518035889, Uncertainty: 1.2812132835388184
Epoch 27, Batch 2200/3125, Loss: 3.1338253021240234, Uncertainty: 3.1660895347595215
Epoch 128, Batch 900/3125, Loss: 1.1917545795440674, Uncertainty: 1.4992910623550415
Epoch 27, Batch 2300/3125, Loss: 3.722376585006714, Uncertainty: 3.712131977081299
Epoch 27, Batch 2400/3125, Loss: 4.366288661956787, Uncertainty: 4.013450622558594
Epoch 128, Batch 1000/3125, Loss: 0.9993045330047607, Uncertainty: 1.1822513341903687
Epoch 27, Batch 2500/3125, Loss: 3.5069527626037598, Uncertainty: 3.6338326930999756
Epoch 128, Batch 1100/3125, Loss: 1.032232642173767, Uncertainty: 1.3099427223205566
Epoch 27, Batch 2600/3125, Loss: 4.576294898986816, Uncertainty: 5.837413787841797
Epoch 128, Batch 1200/3125, Loss: 1.1781007051467896, Uncertainty: 1.4476816654205322
Epoch 27, Batch 2700/3125, Loss: 4.150324821472168, Uncertainty: 3.5352344512939453
Epoch 128, Batch 1300/3125, Loss: 0.9801253080368042, Uncertainty: 1.0857079029083252
Epoch 27, Batch 2800/3125, Loss: 3.7095563411712646, Uncertainty: 4.03015661239624
Epoch 128, Batch 1400/3125, Loss: 1.1325281858444214, Uncertainty: 1.5599663257598877
Epoch 128, Batch 1500/3125, Loss: 1.1473722457885742, Uncertainty: 1.260892629623413
Epoch 27, Batch 2900/3125, Loss: 4.143930435180664, Uncertainty: 4.857066631317139
Epoch 128, Batch 1600/3125, Loss: 0.9797541499137878, Uncertainty: 1.3786330223083496
Epoch 27, Batch 3000/3125, Loss: 4.963335037231445, Uncertainty: 7.433593273162842
Epoch 128, Batch 1700/3125, Loss: 1.0836080312728882, Uncertainty: 1.5638768672943115
Epoch 27, Batch 3100/3125, Loss: 3.5328102111816406, Uncertainty: 3.689453601837158
Epoch 128, Batch 1800/3125, Loss: 1.2039021253585815, Uncertainty: 1.630678415298462
Epoch 128, Batch 1900/3125, Loss: 0.9459483623504639, Uncertainty: 1.3587026596069336
Epoch 128, Batch 2000/3125, Loss: 1.1803499460220337, Uncertainty: 1.4850399494171143
Epoch 128, Batch 2100/3125, Loss: 1.2543785572052002, Uncertainty: 1.413638710975647
Epoch 128, Batch 2200/3125, Loss: 0.9487463235855103, Uncertainty: 1.067777156829834
Epoch 128, Batch 2300/3125, Loss: 1.1490973234176636, Uncertainty: 1.5028129816055298
Epoch 128, Batch 2400/3125, Loss: 1.2183867692947388, Uncertainty: 1.6601471900939941
Epoch 128, Batch 2500/3125, Loss: 0.9949997663497925, Uncertainty: 1.3460800647735596

Training and Validation Results of Epoch 27:
================================
Training Loss: 3.52618739692688, Training Uncertainty: 4.290728022766113, time: 195.69508576393127
Validation Loss: 2.95553853048388, Validation Uncertainty: 5.48586425330023, time: 45.09684085845947
Number of predictions within uncertainty interval: 102064/200000 (51.03%)

Epoch 128, Batch 2600/3125, Loss: 1.094152569770813, Uncertainty: 1.4212634563446045
Epoch 28, Batch 100/3125, Loss: 3.6447508335113525, Uncertainty: 3.5313878059387207
Epoch 128, Batch 2700/3125, Loss: 1.1933672428131104, Uncertainty: 1.5314033031463623
Epoch 28, Batch 200/3125, Loss: 3.786294460296631, Uncertainty: 3.7390379905700684
Epoch 128, Batch 2800/3125, Loss: 0.9519184231758118, Uncertainty: 1.2591831684112549
Epoch 128, Batch 2900/3125, Loss: 1.081291913986206, Uncertainty: 1.3362888097763062
Epoch 28, Batch 300/3125, Loss: 4.234854221343994, Uncertainty: 4.266946792602539
Epoch 128, Batch 3000/3125, Loss: 1.1541619300842285, Uncertainty: 1.3791736364364624
Epoch 28, Batch 400/3125, Loss: 3.2768797874450684, Uncertainty: 3.060563325881958
Epoch 128, Batch 3100/3125, Loss: 1.0717085599899292, Uncertainty: 1.4269311428070068
Epoch 28, Batch 500/3125, Loss: 4.036481857299805, Uncertainty: 3.948387622833252
Epoch 28, Batch 600/3125, Loss: 4.166801452636719, Uncertainty: 3.8423895835876465
Epoch 28, Batch 700/3125, Loss: 3.5736255645751953, Uncertainty: 3.492392063140869
Epoch 28, Batch 800/3125, Loss: 4.1766743659973145, Uncertainty: 4.039609909057617
Epoch 28, Batch 900/3125, Loss: 3.7603867053985596, Uncertainty: 4.253622531890869
Epoch 28, Batch 1000/3125, Loss: 3.7183949947357178, Uncertainty: 3.180361747741699
Epoch 28, Batch 1100/3125, Loss: 4.14339542388916, Uncertainty: 3.9141430854797363

Training and Validation Results of Epoch 128:
================================
Training Loss: 0.8907504949188232, Training Uncertainty: 1.3944618346214295, time: 179.16467547416687
Validation Loss: 0.7698502680834602, Validation Uncertainty: 2.0819235637669675, time: 39.6509051322937
Number of predictions within uncertainty interval: 132537/200000 (66.27%)

Epoch 28, Batch 1200/3125, Loss: 4.002758979797363, Uncertainty: 3.9275736808776855
Epoch 129, Batch 100/3125, Loss: 1.1391710042953491, Uncertainty: 1.1856889724731445
Epoch 28, Batch 1300/3125, Loss: 3.546204090118408, Uncertainty: 4.168418884277344
Epoch 129, Batch 200/3125, Loss: 1.0633959770202637, Uncertainty: 1.3103865385055542
Epoch 28, Batch 1400/3125, Loss: 3.9349372386932373, Uncertainty: 3.541839838027954
Epoch 129, Batch 300/3125, Loss: 1.2527320384979248, Uncertainty: 1.6887719631195068
Epoch 28, Batch 1500/3125, Loss: 3.567171335220337, Uncertainty: 3.8373472690582275
Epoch 129, Batch 400/3125, Loss: 1.0540475845336914, Uncertainty: 1.274107575416565
Epoch 129, Batch 500/3125, Loss: 1.0316271781921387, Uncertainty: 1.2991297245025635
Epoch 28, Batch 1600/3125, Loss: 3.4802403450012207, Uncertainty: 3.6390044689178467
Epoch 129, Batch 600/3125, Loss: 1.2038018703460693, Uncertainty: 1.3019256591796875
Epoch 28, Batch 1700/3125, Loss: 3.5790557861328125, Uncertainty: 3.170578956604004
Epoch 129, Batch 700/3125, Loss: 1.173117995262146, Uncertainty: 1.3169407844543457
Epoch 28, Batch 1800/3125, Loss: 4.176423072814941, Uncertainty: 4.348288536071777
Epoch 129, Batch 800/3125, Loss: 1.1896687746047974, Uncertainty: 1.4813365936279297
Epoch 28, Batch 1900/3125, Loss: 3.5866568088531494, Uncertainty: 3.6400747299194336
Epoch 129, Batch 900/3125, Loss: 1.147547721862793, Uncertainty: 1.401627779006958
Epoch 28, Batch 2000/3125, Loss: 4.65907096862793, Uncertainty: 5.513388633728027
Epoch 129, Batch 1000/3125, Loss: 1.0228767395019531, Uncertainty: 1.2381675243377686
Epoch 28, Batch 2100/3125, Loss: 4.25590705871582, Uncertainty: 5.187739849090576
Epoch 129, Batch 1100/3125, Loss: 1.0577178001403809, Uncertainty: 1.3501508235931396
Epoch 28, Batch 2200/3125, Loss: 3.338411331176758, Uncertainty: 3.5311427116394043
Epoch 129, Batch 1200/3125, Loss: 1.1549419164657593, Uncertainty: 1.415420651435852
Epoch 28, Batch 2300/3125, Loss: 3.6130876541137695, Uncertainty: 3.3923120498657227
Epoch 129, Batch 1300/3125, Loss: 1.018927812576294, Uncertainty: 1.272850751876831
Epoch 28, Batch 2400/3125, Loss: 4.170968055725098, Uncertainty: 3.66142201423645
Epoch 129, Batch 1400/3125, Loss: 1.1123725175857544, Uncertainty: 1.5208561420440674
Epoch 129, Batch 1500/3125, Loss: 1.2037837505340576, Uncertainty: 1.3620593547821045
Epoch 28, Batch 2500/3125, Loss: 3.7237112522125244, Uncertainty: 3.4190115928649902
Epoch 129, Batch 1600/3125, Loss: 0.8965778350830078, Uncertainty: 1.1368716955184937
Epoch 28, Batch 2600/3125, Loss: 4.292887210845947, Uncertainty: 3.5063109397888184
Epoch 129, Batch 1700/3125, Loss: 1.150129795074463, Uncertainty: 1.7526838779449463
Epoch 28, Batch 2700/3125, Loss: 4.307496070861816, Uncertainty: 3.9269447326660156
Epoch 129, Batch 1800/3125, Loss: 1.169539213180542, Uncertainty: 1.574242353439331
Epoch 28, Batch 2800/3125, Loss: 3.4900174140930176, Uncertainty: 3.536174774169922
Epoch 129, Batch 1900/3125, Loss: 0.9568150043487549, Uncertainty: 1.411177158355713
Epoch 28, Batch 2900/3125, Loss: 4.098116874694824, Uncertainty: 3.5571329593658447
Epoch 129, Batch 2000/3125, Loss: 1.0674464702606201, Uncertainty: 1.4118291139602661
Epoch 28, Batch 3000/3125, Loss: 4.210193157196045, Uncertainty: 5.2006072998046875
Epoch 129, Batch 2100/3125, Loss: 1.2389116287231445, Uncertainty: 1.4431178569793701
Epoch 28, Batch 3100/3125, Loss: 3.337491273880005, Uncertainty: 3.106444835662842
Epoch 129, Batch 2200/3125, Loss: 0.9536423683166504, Uncertainty: 1.185121774673462
Epoch 129, Batch 2300/3125, Loss: 1.1241185665130615, Uncertainty: 1.4650276899337769
Epoch 129, Batch 2400/3125, Loss: 1.1398272514343262, Uncertainty: 1.3328263759613037
Epoch 129, Batch 2500/3125, Loss: 1.0319442749023438, Uncertainty: 1.4787945747375488
Epoch 129, Batch 2600/3125, Loss: 1.2394819259643555, Uncertainty: 1.660011887550354
Epoch 129, Batch 2700/3125, Loss: 1.2012003660202026, Uncertainty: 1.5198848247528076
Epoch 129, Batch 2800/3125, Loss: 0.9232628345489502, Uncertainty: 1.2381772994995117
Epoch 129, Batch 2900/3125, Loss: 1.1107792854309082, Uncertainty: 1.4588404893875122

Training and Validation Results of Epoch 28:
================================
Training Loss: 3.3607949138641358, Training Uncertainty: 4.0386742907714845, time: 190.60799932479858
Validation Loss: 2.8590479997722693, Validation Uncertainty: 5.8245927598470315, time: 43.629212379455566
Number of predictions within uncertainty interval: 110676/200000 (55.34%)

Epoch 129, Batch 3000/3125, Loss: 1.1831436157226562, Uncertainty: 1.393506646156311
Epoch 29, Batch 100/3125, Loss: 3.90017032623291, Uncertainty: 3.6036019325256348
Epoch 129, Batch 3100/3125, Loss: 1.0956897735595703, Uncertainty: 1.2798763513565063
Epoch 29, Batch 200/3125, Loss: 3.877591848373413, Uncertainty: 4.529646396636963
Epoch 29, Batch 300/3125, Loss: 3.2828269004821777, Uncertainty: 3.2890467643737793
Epoch 29, Batch 400/3125, Loss: 3.734592914581299, Uncertainty: 3.295893430709839
Epoch 29, Batch 500/3125, Loss: 3.6811814308166504, Uncertainty: 4.139755725860596
Epoch 29, Batch 600/3125, Loss: 4.016066551208496, Uncertainty: 3.6001036167144775
Epoch 29, Batch 700/3125, Loss: 3.1926321983337402, Uncertainty: 2.956493377685547

Training and Validation Results of Epoch 129:
================================
Training Loss: 0.8846846230316162, Training Uncertainty: 1.3956130701065064, time: 172.13962650299072
Validation Loss: 0.8351633291110359, Validation Uncertainty: 1.997809999281793, time: 39.69099545478821
Number of predictions within uncertainty interval: 122928/200000 (61.46%)

Epoch 29, Batch 800/3125, Loss: 4.163018703460693, Uncertainty: 3.7368621826171875
Epoch 130, Batch 100/3125, Loss: 0.9772763252258301, Uncertainty: 1.1551761627197266
Epoch 29, Batch 900/3125, Loss: 3.937197208404541, Uncertainty: 3.8362271785736084
Epoch 130, Batch 200/3125, Loss: 1.0668632984161377, Uncertainty: 1.3668386936187744
Epoch 29, Batch 1000/3125, Loss: 3.5571370124816895, Uncertainty: 3.743699789047241
Epoch 130, Batch 300/3125, Loss: 1.1834542751312256, Uncertainty: 1.4563031196594238
Epoch 29, Batch 1100/3125, Loss: 3.7885582447052, Uncertainty: 3.6671247482299805
Epoch 130, Batch 400/3125, Loss: 1.0278247594833374, Uncertainty: 1.2894542217254639
Epoch 29, Batch 1200/3125, Loss: 4.108758926391602, Uncertainty: 5.964267253875732
Epoch 130, Batch 500/3125, Loss: 1.0692650079727173, Uncertainty: 1.4088761806488037
Epoch 29, Batch 1300/3125, Loss: 3.258490562438965, Uncertainty: 3.5402419567108154
Epoch 130, Batch 600/3125, Loss: 1.2991819381713867, Uncertainty: 1.496500015258789
Epoch 29, Batch 1400/3125, Loss: 5.147461414337158, Uncertainty: 6.191235065460205
Epoch 130, Batch 700/3125, Loss: 1.1553846597671509, Uncertainty: 1.4435458183288574
Epoch 29, Batch 1500/3125, Loss: 3.2862114906311035, Uncertainty: 3.293511390686035
Epoch 130, Batch 800/3125, Loss: 1.111114263534546, Uncertainty: 1.3422820568084717
Epoch 130, Batch 900/3125, Loss: 1.2598930597305298, Uncertainty: 1.6145226955413818
Epoch 29, Batch 1600/3125, Loss: 4.044721603393555, Uncertainty: 5.312957763671875
Epoch 130, Batch 1000/3125, Loss: 1.0053631067276, Uncertainty: 1.2203402519226074
Epoch 29, Batch 1700/3125, Loss: 3.779702663421631, Uncertainty: 4.453810691833496
Epoch 130, Batch 1100/3125, Loss: 1.0464988946914673, Uncertainty: 1.3126112222671509
Epoch 29, Batch 1800/3125, Loss: 3.5651440620422363, Uncertainty: 3.5432381629943848
Epoch 130, Batch 1200/3125, Loss: 1.1636793613433838, Uncertainty: 1.392505407333374
Epoch 29, Batch 1900/3125, Loss: 4.051044464111328, Uncertainty: 4.04036283493042
Epoch 130, Batch 1300/3125, Loss: 1.01057767868042, Uncertainty: 1.2306026220321655
Epoch 29, Batch 2000/3125, Loss: 3.8754472732543945, Uncertainty: 4.1385345458984375
Epoch 130, Batch 1400/3125, Loss: 1.2328739166259766, Uncertainty: 1.80344557762146
Epoch 29, Batch 2100/3125, Loss: 3.7884631156921387, Uncertainty: 4.456144332885742
Epoch 130, Batch 1500/3125, Loss: 1.1524372100830078, Uncertainty: 1.326620101928711
Epoch 29, Batch 2200/3125, Loss: 3.5713958740234375, Uncertainty: 4.555905342102051
Epoch 130, Batch 1600/3125, Loss: 0.907685399055481, Uncertainty: 1.1290299892425537
Epoch 29, Batch 2300/3125, Loss: 4.472179412841797, Uncertainty: 6.301798343658447
Epoch 130, Batch 1700/3125, Loss: 1.1089608669281006, Uncertainty: 1.6668552160263062
Epoch 29, Batch 2400/3125, Loss: 3.7295725345611572, Uncertainty: 3.478069543838501
Epoch 130, Batch 1800/3125, Loss: 1.172978162765503, Uncertainty: 1.5701806545257568
Epoch 130, Batch 1900/3125, Loss: 0.9378470182418823, Uncertainty: 1.3401801586151123
Epoch 29, Batch 2500/3125, Loss: 3.323631763458252, Uncertainty: 3.591445207595825
Epoch 130, Batch 2000/3125, Loss: 1.066248893737793, Uncertainty: 1.412100911140442
Epoch 29, Batch 2600/3125, Loss: 3.996030569076538, Uncertainty: 3.722231388092041
Epoch 130, Batch 2100/3125, Loss: 1.274522304534912, Uncertainty: 1.4938864707946777
Epoch 29, Batch 2700/3125, Loss: 4.254860877990723, Uncertainty: 3.159111499786377
Epoch 130, Batch 2200/3125, Loss: 0.9077376127243042, Uncertainty: 1.1019566059112549
Epoch 29, Batch 2800/3125, Loss: 3.291600227355957, Uncertainty: 3.340590715408325
Epoch 130, Batch 2300/3125, Loss: 1.1100574731826782, Uncertainty: 1.4068461656570435
Epoch 29, Batch 2900/3125, Loss: 3.85408091545105, Uncertainty: 4.62093448638916
Epoch 130, Batch 2400/3125, Loss: 1.225163459777832, Uncertainty: 1.717018961906433
Epoch 29, Batch 3000/3125, Loss: 3.7104434967041016, Uncertainty: 4.4368791580200195
Epoch 130, Batch 2500/3125, Loss: 1.0983262062072754, Uncertainty: 1.6701183319091797
Epoch 29, Batch 3100/3125, Loss: 3.385734796524048, Uncertainty: 3.219898223876953
Epoch 130, Batch 2600/3125, Loss: 1.1591517925262451, Uncertainty: 1.612774133682251
Epoch 130, Batch 2700/3125, Loss: 1.2187683582305908, Uncertainty: 1.5389446020126343
Epoch 130, Batch 2800/3125, Loss: 0.9353363513946533, Uncertainty: 1.2628743648529053
Epoch 130, Batch 2900/3125, Loss: 1.0675163269042969, Uncertainty: 1.3677456378936768
Epoch 130, Batch 3000/3125, Loss: 1.1529262065887451, Uncertainty: 1.3963041305541992
Epoch 130, Batch 3100/3125, Loss: 0.990965723991394, Uncertainty: 1.1718345880508423

Training and Validation Results of Epoch 29:
================================
Training Loss: 3.2494813374328615, Training Uncertainty: 4.000932486038208, time: 190.57534337043762
Validation Loss: 2.8682157121351004, Validation Uncertainty: 6.02044547244411, time: 43.716556787490845
Number of predictions within uncertainty interval: 115253/200000 (57.63%)

Epoch 30, Batch 100/3125, Loss: 3.8155517578125, Uncertainty: 3.771860361099243
Epoch 30, Batch 200/3125, Loss: 3.44614315032959, Uncertainty: 3.3992700576782227
Epoch 30, Batch 300/3125, Loss: 3.281123638153076, Uncertainty: 3.207221508026123
Epoch 30, Batch 400/3125, Loss: 3.2677817344665527, Uncertainty: 3.518744945526123

Training and Validation Results of Epoch 130:
================================
Training Loss: 0.8822146666526794, Training Uncertainty: 1.3894678620910645, time: 171.9452052116394
Validation Loss: 0.7558183756935627, Validation Uncertainty: 1.9335073596986054, time: 39.78109264373779
Number of predictions within uncertainty interval: 128227/200000 (64.11%)

Epoch 131, Batch 100/3125, Loss: 1.0247349739074707, Uncertainty: 1.0744547843933105
Epoch 30, Batch 500/3125, Loss: 3.5501668453216553, Uncertainty: 3.641740083694458
Epoch 131, Batch 200/3125, Loss: 1.070460319519043, Uncertainty: 1.351105809211731
Epoch 30, Batch 600/3125, Loss: 3.728431224822998, Uncertainty: 3.6308112144470215
Epoch 131, Batch 300/3125, Loss: 1.202256441116333, Uncertainty: 1.3009986877441406
Epoch 30, Batch 700/3125, Loss: 3.4937233924865723, Uncertainty: 3.95279860496521
Epoch 131, Batch 400/3125, Loss: 1.0082685947418213, Uncertainty: 1.2610208988189697
Epoch 30, Batch 800/3125, Loss: 3.930297613143921, Uncertainty: 3.9355850219726562
Epoch 131, Batch 500/3125, Loss: 1.087160348892212, Uncertainty: 1.3403449058532715
Epoch 30, Batch 900/3125, Loss: 4.337371349334717, Uncertainty: 5.934872627258301
Epoch 131, Batch 600/3125, Loss: 1.404735803604126, Uncertainty: 1.631736159324646
Epoch 30, Batch 1000/3125, Loss: 3.495853900909424, Uncertainty: 3.0936033725738525
Epoch 131, Batch 700/3125, Loss: 1.0199484825134277, Uncertainty: 1.2788984775543213
Epoch 30, Batch 1100/3125, Loss: 3.8948283195495605, Uncertainty: 4.261916160583496
Epoch 131, Batch 800/3125, Loss: 1.258724570274353, Uncertainty: 1.7499444484710693
Epoch 30, Batch 1200/3125, Loss: 3.3698325157165527, Uncertainty: 3.6995255947113037
Epoch 131, Batch 900/3125, Loss: 1.1683638095855713, Uncertainty: 1.382985234260559
Epoch 131, Batch 1000/3125, Loss: 0.9751580357551575, Uncertainty: 1.1332886219024658
Epoch 30, Batch 1300/3125, Loss: 3.082609176635742, Uncertainty: 2.972891330718994
Epoch 131, Batch 1100/3125, Loss: 1.0841253995895386, Uncertainty: 1.4760035276412964
Epoch 30, Batch 1400/3125, Loss: 4.28826379776001, Uncertainty: 4.306607246398926
Epoch 131, Batch 1200/3125, Loss: 1.1229404211044312, Uncertainty: 1.4132559299468994
Epoch 30, Batch 1500/3125, Loss: 3.0358123779296875, Uncertainty: 2.996161937713623
Epoch 131, Batch 1300/3125, Loss: 1.0355968475341797, Uncertainty: 1.3233245611190796
Epoch 30, Batch 1600/3125, Loss: 3.14778470993042, Uncertainty: 3.117417335510254
Epoch 131, Batch 1400/3125, Loss: 1.0965168476104736, Uncertainty: 1.4662904739379883
Epoch 30, Batch 1700/3125, Loss: 3.5384597778320312, Uncertainty: 3.3930487632751465
Epoch 131, Batch 1500/3125, Loss: 1.1645587682724, Uncertainty: 1.353783369064331
Epoch 30, Batch 1800/3125, Loss: 3.1842164993286133, Uncertainty: 3.128237247467041
Epoch 131, Batch 1600/3125, Loss: 0.8889775276184082, Uncertainty: 1.1337096691131592
Epoch 30, Batch 1900/3125, Loss: 3.4206981658935547, Uncertainty: 3.8432295322418213
Epoch 131, Batch 1700/3125, Loss: 1.1769649982452393, Uncertainty: 1.8402321338653564
Epoch 131, Batch 1800/3125, Loss: 1.1518064737319946, Uncertainty: 1.49249267578125
Epoch 30, Batch 2000/3125, Loss: 3.8845767974853516, Uncertainty: 4.474743843078613
Epoch 131, Batch 1900/3125, Loss: 0.9152896404266357, Uncertainty: 1.2244123220443726
Epoch 30, Batch 2100/3125, Loss: 3.523306131362915, Uncertainty: 3.252540349960327
Epoch 131, Batch 2000/3125, Loss: 1.1436240673065186, Uncertainty: 1.5925511121749878
Epoch 30, Batch 2200/3125, Loss: 3.3648300170898438, Uncertainty: 3.9179720878601074
Epoch 131, Batch 2100/3125, Loss: 1.2123737335205078, Uncertainty: 1.3958933353424072
Epoch 30, Batch 2300/3125, Loss: 3.6576476097106934, Uncertainty: 3.624011516571045
Epoch 131, Batch 2200/3125, Loss: 1.0108827352523804, Uncertainty: 1.0585873126983643
Epoch 30, Batch 2400/3125, Loss: 4.118251800537109, Uncertainty: 3.312739849090576
Epoch 131, Batch 2300/3125, Loss: 1.1349135637283325, Uncertainty: 1.4897962808609009
Epoch 30, Batch 2500/3125, Loss: 3.1652379035949707, Uncertainty: 3.0781655311584473
Epoch 131, Batch 2400/3125, Loss: 1.1204919815063477, Uncertainty: 1.402116060256958
Epoch 30, Batch 2600/3125, Loss: 4.172649383544922, Uncertainty: 5.357271194458008
Epoch 131, Batch 2500/3125, Loss: 1.0567030906677246, Uncertainty: 1.5272929668426514
Epoch 131, Batch 2600/3125, Loss: 1.3297157287597656, Uncertainty: 1.9876978397369385
Epoch 30, Batch 2700/3125, Loss: 4.437611103057861, Uncertainty: 3.1215643882751465
Epoch 131, Batch 2700/3125, Loss: 1.2067153453826904, Uncertainty: 1.5532058477401733
Epoch 30, Batch 2800/3125, Loss: 3.3674657344818115, Uncertainty: 3.4778666496276855
Epoch 131, Batch 2800/3125, Loss: 0.9190507531166077, Uncertainty: 1.1922364234924316
Epoch 30, Batch 2900/3125, Loss: 3.4856085777282715, Uncertainty: 3.9705655574798584
Epoch 131, Batch 2900/3125, Loss: 1.2152540683746338, Uncertainty: 1.546512484550476
Epoch 30, Batch 3000/3125, Loss: 4.36587381362915, Uncertainty: 3.4085655212402344
Epoch 131, Batch 3000/3125, Loss: 1.1535046100616455, Uncertainty: 1.3709241151809692
Epoch 30, Batch 3100/3125, Loss: 3.0191712379455566, Uncertainty: 2.9231152534484863
Epoch 131, Batch 3100/3125, Loss: 1.101277470588684, Uncertainty: 1.2455836534500122

Training and Validation Results of Epoch 30:
================================
Training Loss: 3.1427664086151124, Training Uncertainty: 3.817624325942993, time: 194.5735523700714
Validation Loss: 2.74591130978616, Validation Uncertainty: 5.055013888327362, time: 44.51560616493225
Number of predictions within uncertainty interval: 105986/200000 (52.99%)


Training and Validation Results of Epoch 131:
================================
Training Loss: 0.8808814299583435, Training Uncertainty: 1.3903271576690674, time: 172.80143308639526
Validation Loss: 0.7922956448076935, Validation Uncertainty: 1.9570827365226453, time: 41.57508587837219
Number of predictions within uncertainty interval: 126128/200000 (63.06%)

Epoch 132, Batch 100/3125, Loss: 1.053002119064331, Uncertainty: 1.3101279735565186
Epoch 31, Batch 100/3125, Loss: 3.734189033508301, Uncertainty: 4.979490280151367
Epoch 132, Batch 200/3125, Loss: 1.0588858127593994, Uncertainty: 1.2856298685073853
Epoch 31, Batch 200/3125, Loss: 4.038229942321777, Uncertainty: 3.4535531997680664
Epoch 132, Batch 300/3125, Loss: 1.2733149528503418, Uncertainty: 1.718916416168213
Epoch 31, Batch 300/3125, Loss: 3.021529197692871, Uncertainty: 2.712340831756592
Epoch 132, Batch 400/3125, Loss: 0.9955137372016907, Uncertainty: 1.2286484241485596
Epoch 31, Batch 400/3125, Loss: 3.877535581588745, Uncertainty: 5.537270545959473
Epoch 132, Batch 500/3125, Loss: 1.0573004484176636, Uncertainty: 1.4244548082351685
Epoch 31, Batch 500/3125, Loss: 3.67738676071167, Uncertainty: 3.374389171600342
Epoch 132, Batch 600/3125, Loss: 1.3224904537200928, Uncertainty: 1.5051480531692505
Epoch 31, Batch 600/3125, Loss: 3.9912304878234863, Uncertainty: 5.527904510498047
Epoch 132, Batch 700/3125, Loss: 1.0342432260513306, Uncertainty: 1.2968761920928955
Epoch 31, Batch 700/3125, Loss: 3.0751349925994873, Uncertainty: 3.0088400840759277
Epoch 132, Batch 800/3125, Loss: 1.1593210697174072, Uncertainty: 1.4534893035888672
Epoch 31, Batch 800/3125, Loss: 3.6695985794067383, Uncertainty: 3.348501682281494
Epoch 132, Batch 900/3125, Loss: 1.251623511314392, Uncertainty: 1.6696631908416748
Epoch 31, Batch 900/3125, Loss: 3.3758440017700195, Uncertainty: 3.2854089736938477
Epoch 132, Batch 1000/3125, Loss: 1.0058094263076782, Uncertainty: 1.2216789722442627
Epoch 132, Batch 1100/3125, Loss: 1.0501691102981567, Uncertainty: 1.3663225173950195
Epoch 31, Batch 1000/3125, Loss: 3.243119716644287, Uncertainty: 2.804511547088623
Epoch 132, Batch 1200/3125, Loss: 1.1340831518173218, Uncertainty: 1.3993765115737915
Epoch 31, Batch 1100/3125, Loss: 4.145008087158203, Uncertainty: 5.137269973754883
Epoch 132, Batch 1300/3125, Loss: 0.9862774610519409, Uncertainty: 1.079355001449585
Epoch 31, Batch 1200/3125, Loss: 3.2786149978637695, Uncertainty: 2.931311845779419
Epoch 132, Batch 1400/3125, Loss: 1.0706779956817627, Uncertainty: 1.404691457748413
Epoch 31, Batch 1300/3125, Loss: 3.1521778106689453, Uncertainty: 2.761368751525879
Epoch 132, Batch 1500/3125, Loss: 1.1409400701522827, Uncertainty: 1.295899748802185
Epoch 31, Batch 1400/3125, Loss: 4.305027008056641, Uncertainty: 6.396194934844971
Epoch 132, Batch 1600/3125, Loss: 0.9047132730484009, Uncertainty: 1.1763026714324951
Epoch 31, Batch 1500/3125, Loss: 3.1564173698425293, Uncertainty: 3.396171808242798
Epoch 132, Batch 1700/3125, Loss: 1.1155372858047485, Uncertainty: 1.6708095073699951
Epoch 31, Batch 1600/3125, Loss: 3.6629507541656494, Uncertainty: 3.1791152954101562
Epoch 132, Batch 1800/3125, Loss: 1.1855093240737915, Uncertainty: 1.661961555480957
Epoch 31, Batch 1700/3125, Loss: 3.2521162033081055, Uncertainty: 3.7356154918670654
Epoch 132, Batch 1900/3125, Loss: 0.9241754412651062, Uncertainty: 1.3080061674118042
Epoch 132, Batch 2000/3125, Loss: 1.0155400037765503, Uncertainty: 1.2769813537597656
Epoch 31, Batch 1800/3125, Loss: 3.7556469440460205, Uncertainty: 5.136648178100586
Epoch 132, Batch 2100/3125, Loss: 1.259570837020874, Uncertainty: 1.4794158935546875
Epoch 31, Batch 1900/3125, Loss: 3.4578499794006348, Uncertainty: 4.239131927490234
Epoch 132, Batch 2200/3125, Loss: 0.9299266934394836, Uncertainty: 1.059938907623291
Epoch 31, Batch 2000/3125, Loss: 3.4895825386047363, Uncertainty: 3.2267374992370605
Epoch 132, Batch 2300/3125, Loss: 1.1109874248504639, Uncertainty: 1.3961279392242432
Epoch 31, Batch 2100/3125, Loss: 3.3210537433624268, Uncertainty: 3.5426135063171387
Epoch 132, Batch 2400/3125, Loss: 1.4103587865829468, Uncertainty: 2.2182259559631348
Epoch 31, Batch 2200/3125, Loss: 3.3945698738098145, Uncertainty: 3.3796465396881104
Epoch 132, Batch 2500/3125, Loss: 1.164525032043457, Uncertainty: 1.7620152235031128
Epoch 31, Batch 2300/3125, Loss: 3.603670120239258, Uncertainty: 3.744900703430176
Epoch 132, Batch 2600/3125, Loss: 1.3470704555511475, Uncertainty: 2.082284450531006
Epoch 31, Batch 2400/3125, Loss: 3.00627064704895, Uncertainty: 3.103610038757324
Epoch 132, Batch 2700/3125, Loss: 1.2185816764831543, Uncertainty: 1.6237328052520752
Epoch 31, Batch 2500/3125, Loss: 3.7082409858703613, Uncertainty: 5.268428325653076
Epoch 132, Batch 2800/3125, Loss: 0.9115170240402222, Uncertainty: 1.2407455444335938
Epoch 132, Batch 2900/3125, Loss: 1.0966781377792358, Uncertainty: 1.483595371246338
Epoch 31, Batch 2600/3125, Loss: 3.4733800888061523, Uncertainty: 3.2390246391296387
Epoch 132, Batch 3000/3125, Loss: 1.164985179901123, Uncertainty: 1.3738210201263428
Epoch 31, Batch 2700/3125, Loss: 4.4223785400390625, Uncertainty: 5.561851501464844
Epoch 132, Batch 3100/3125, Loss: 0.9782559871673584, Uncertainty: 1.1647179126739502
Epoch 31, Batch 2800/3125, Loss: 3.6632237434387207, Uncertainty: 4.28871488571167
Epoch 31, Batch 2900/3125, Loss: 3.1452107429504395, Uncertainty: 2.876420497894287
Epoch 31, Batch 3000/3125, Loss: 4.75778865814209, Uncertainty: 7.923800945281982
Epoch 31, Batch 3100/3125, Loss: 3.1388704776763916, Uncertainty: 3.319464683532715

Training and Validation Results of Epoch 132:
================================
Training Loss: 0.8773045675849914, Training Uncertainty: 1.375812297706604, time: 172.99287295341492
Validation Loss: 0.7530614964644927, Validation Uncertainty: 1.9742861603531996, time: 39.786217212677
Number of predictions within uncertainty interval: 130424/200000 (65.21%)

Epoch 133, Batch 100/3125, Loss: 1.107926845550537, Uncertainty: 1.1936002969741821
Epoch 133, Batch 200/3125, Loss: 1.0648865699768066, Uncertainty: 1.352238655090332
Epoch 133, Batch 300/3125, Loss: 1.2651188373565674, Uncertainty: 1.5346508026123047
Epoch 133, Batch 400/3125, Loss: 1.0063321590423584, Uncertainty: 1.204545021057129

Training and Validation Results of Epoch 31:
================================
Training Loss: 3.037251956100464, Training Uncertainty: 3.7371649751281737, time: 193.8478229045868
Validation Loss: 2.6044673986752014, Validation Uncertainty: 6.401121982223238, time: 44.36049151420593
Number of predictions within uncertainty interval: 128938/200000 (64.47%)

Epoch 133, Batch 500/3125, Loss: 1.0084359645843506, Uncertainty: 1.2821452617645264
Epoch 32, Batch 100/3125, Loss: 3.1378278732299805, Uncertainty: 2.772437810897827
Epoch 133, Batch 600/3125, Loss: 1.2404147386550903, Uncertainty: 1.4437294006347656
Epoch 32, Batch 200/3125, Loss: 3.1561427116394043, Uncertainty: 3.0626416206359863
Epoch 133, Batch 700/3125, Loss: 1.0741045475006104, Uncertainty: 1.2543504238128662
Epoch 32, Batch 300/3125, Loss: 3.020595073699951, Uncertainty: 3.0181918144226074
Epoch 133, Batch 800/3125, Loss: 1.077438235282898, Uncertainty: 1.2545777559280396
Epoch 133, Batch 900/3125, Loss: 1.1545222997665405, Uncertainty: 1.4151842594146729
Epoch 32, Batch 400/3125, Loss: 3.1354217529296875, Uncertainty: 3.134246826171875
Epoch 133, Batch 1000/3125, Loss: 0.9968681931495667, Uncertainty: 1.1783521175384521
Epoch 133, Batch 1100/3125, Loss: 0.9780048727989197, Uncertainty: 1.222653865814209
Epoch 32, Batch 500/3125, Loss: 3.3102221488952637, Uncertainty: 3.3096506595611572
Epoch 133, Batch 1200/3125, Loss: 1.2583768367767334, Uncertainty: 1.5484062433242798
Epoch 32, Batch 600/3125, Loss: 3.4954748153686523, Uncertainty: 3.577805995941162
Epoch 133, Batch 1300/3125, Loss: 0.9725611805915833, Uncertainty: 1.1090097427368164
Epoch 32, Batch 700/3125, Loss: 2.9883687496185303, Uncertainty: 2.8549225330352783
Epoch 133, Batch 1400/3125, Loss: 1.1189063787460327, Uncertainty: 1.5678060054779053
Epoch 32, Batch 800/3125, Loss: 3.96073055267334, Uncertainty: 5.066060543060303
Epoch 133, Batch 1500/3125, Loss: 1.1621603965759277, Uncertainty: 1.2927708625793457
Epoch 32, Batch 900/3125, Loss: 3.816117763519287, Uncertainty: 5.237264633178711
Epoch 133, Batch 1600/3125, Loss: 0.9300881624221802, Uncertainty: 1.1500778198242188
Epoch 32, Batch 1000/3125, Loss: 3.600036144256592, Uncertainty: 2.8604493141174316
Epoch 133, Batch 1700/3125, Loss: 1.11549973487854, Uncertainty: 1.6712379455566406
Epoch 32, Batch 1100/3125, Loss: 3.61940598487854, Uncertainty: 3.796642780303955
Epoch 133, Batch 1800/3125, Loss: 1.1179062128067017, Uncertainty: 1.4102401733398438
Epoch 32, Batch 1200/3125, Loss: 3.1608643531799316, Uncertainty: 2.9388022422790527
Epoch 133, Batch 1900/3125, Loss: 0.9134193658828735, Uncertainty: 1.2911276817321777
Epoch 133, Batch 2000/3125, Loss: 1.0287889242172241, Uncertainty: 1.279739260673523
Epoch 32, Batch 1300/3125, Loss: 3.0377421379089355, Uncertainty: 3.2582643032073975
Epoch 133, Batch 2100/3125, Loss: 1.2013230323791504, Uncertainty: 1.3535897731781006
Epoch 32, Batch 1400/3125, Loss: 3.4515652656555176, Uncertainty: 3.4239792823791504
Epoch 133, Batch 2200/3125, Loss: 1.011728286743164, Uncertainty: 1.2807495594024658
Epoch 32, Batch 1500/3125, Loss: 2.9443624019622803, Uncertainty: 2.988999605178833
Epoch 133, Batch 2300/3125, Loss: 1.104858160018921, Uncertainty: 1.372516393661499
Epoch 32, Batch 1600/3125, Loss: 2.947298049926758, Uncertainty: 2.615727424621582
Epoch 133, Batch 2400/3125, Loss: 1.1640206575393677, Uncertainty: 1.5814626216888428
Epoch 32, Batch 1700/3125, Loss: 3.1166951656341553, Uncertainty: 2.8714656829833984
Epoch 133, Batch 2500/3125, Loss: 0.9753963351249695, Uncertainty: 1.3637993335723877
Epoch 32, Batch 1800/3125, Loss: 3.603473663330078, Uncertainty: 3.978675365447998
Epoch 133, Batch 2600/3125, Loss: 1.1018521785736084, Uncertainty: 1.483518362045288
Epoch 32, Batch 1900/3125, Loss: 3.0763888359069824, Uncertainty: 2.9221315383911133
Epoch 133, Batch 2700/3125, Loss: 1.1817516088485718, Uncertainty: 1.5099294185638428
Epoch 32, Batch 2000/3125, Loss: 3.6593713760375977, Uncertainty: 4.043462753295898
Epoch 133, Batch 2800/3125, Loss: 0.9240124821662903, Uncertainty: 1.179342269897461
Epoch 32, Batch 2100/3125, Loss: 3.550564765930176, Uncertainty: 3.868959426879883
Epoch 133, Batch 2900/3125, Loss: 1.0785441398620605, Uncertainty: 1.3949775695800781
Epoch 133, Batch 3000/3125, Loss: 1.2233116626739502, Uncertainty: 1.3455331325531006
Epoch 32, Batch 2200/3125, Loss: 3.030268669128418, Uncertainty: 2.9272730350494385
Epoch 133, Batch 3100/3125, Loss: 1.00514554977417, Uncertainty: 1.1867926120758057
Epoch 32, Batch 2300/3125, Loss: 3.249912738800049, Uncertainty: 3.335066795349121
Epoch 32, Batch 2400/3125, Loss: 3.894117832183838, Uncertainty: 5.043522834777832
Epoch 32, Batch 2500/3125, Loss: 3.036494731903076, Uncertainty: 3.205258369445801
Epoch 32, Batch 2600/3125, Loss: 3.472501754760742, Uncertainty: 3.140430450439453
Epoch 32, Batch 2700/3125, Loss: 4.610651016235352, Uncertainty: 2.541496753692627
Epoch 32, Batch 2800/3125, Loss: 3.089188814163208, Uncertainty: 3.081392288208008

Training and Validation Results of Epoch 133:
================================
Training Loss: 0.8756086054039002, Training Uncertainty: 1.3807404139900208, time: 171.8245084285736
Validation Loss: 0.7506322161773281, Validation Uncertainty: 1.9104046664579446, time: 39.59614443778992
Number of predictions within uncertainty interval: 127476/200000 (63.74%)

Epoch 32, Batch 2900/3125, Loss: 3.141390800476074, Uncertainty: 2.912174701690674
Epoch 134, Batch 100/3125, Loss: 0.9929403066635132, Uncertainty: 1.0925955772399902
Epoch 32, Batch 3000/3125, Loss: 3.3109383583068848, Uncertainty: 2.9840922355651855
Epoch 134, Batch 200/3125, Loss: 1.0330623388290405, Uncertainty: 1.275238037109375
Epoch 32, Batch 3100/3125, Loss: 2.9723782539367676, Uncertainty: 2.866154670715332
Epoch 134, Batch 300/3125, Loss: 1.1558570861816406, Uncertainty: 1.3698973655700684
Epoch 134, Batch 400/3125, Loss: 0.9803122282028198, Uncertainty: 1.2685825824737549
Epoch 134, Batch 500/3125, Loss: 1.108586072921753, Uncertainty: 1.4952278137207031
Epoch 134, Batch 600/3125, Loss: 1.2322851419448853, Uncertainty: 1.3888394832611084
Epoch 134, Batch 700/3125, Loss: 1.0385661125183105, Uncertainty: 1.2343870401382446
Epoch 134, Batch 800/3125, Loss: 1.0830376148223877, Uncertainty: 1.2692105770111084
Epoch 134, Batch 900/3125, Loss: 1.1376209259033203, Uncertainty: 1.397467851638794
Epoch 134, Batch 1000/3125, Loss: 0.9950699806213379, Uncertainty: 1.159440517425537

Training and Validation Results of Epoch 32:
================================
Training Loss: 2.951987975311279, Training Uncertainty: 3.599875789871216, time: 200.16358304023743
Validation Loss: 2.587406638943021, Validation Uncertainty: 6.280336132439811, time: 43.9025821685791
Number of predictions within uncertainty interval: 125555/200000 (62.78%)

Epoch 134, Batch 1100/3125, Loss: 1.0549883842468262, Uncertainty: 1.3844292163848877
Epoch 33, Batch 100/3125, Loss: 3.1432526111602783, Uncertainty: 2.985988140106201
Epoch 134, Batch 1200/3125, Loss: 1.113782525062561, Uncertainty: 1.3755338191986084
Epoch 33, Batch 200/3125, Loss: 3.768150806427002, Uncertainty: 3.195949077606201
Epoch 134, Batch 1300/3125, Loss: 0.9470193982124329, Uncertainty: 1.095250129699707
Epoch 33, Batch 300/3125, Loss: 3.280665874481201, Uncertainty: 2.8517379760742188
Epoch 134, Batch 1400/3125, Loss: 1.169730544090271, Uncertainty: 1.6462525129318237
Epoch 33, Batch 400/3125, Loss: 3.5146613121032715, Uncertainty: 4.656135559082031
Epoch 134, Batch 1500/3125, Loss: 1.1249572038650513, Uncertainty: 1.2507455348968506
Epoch 33, Batch 500/3125, Loss: 3.5528085231781006, Uncertainty: 3.685187578201294
Epoch 134, Batch 1600/3125, Loss: 0.9386699199676514, Uncertainty: 1.2661207914352417
Epoch 134, Batch 1700/3125, Loss: 1.1913816928863525, Uncertainty: 1.8364295959472656
Epoch 33, Batch 600/3125, Loss: 3.322803258895874, Uncertainty: 3.023256778717041
Epoch 134, Batch 1800/3125, Loss: 1.1747472286224365, Uncertainty: 1.5929157733917236
Epoch 33, Batch 700/3125, Loss: 3.153592824935913, Uncertainty: 3.1580381393432617
Epoch 134, Batch 1900/3125, Loss: 0.9089733958244324, Uncertainty: 1.1672735214233398
Epoch 33, Batch 800/3125, Loss: 3.450035572052002, Uncertainty: 3.1269116401672363
Epoch 134, Batch 2000/3125, Loss: 1.035351276397705, Uncertainty: 1.4173743724822998
Epoch 33, Batch 900/3125, Loss: 3.2892849445343018, Uncertainty: 3.5821776390075684
Epoch 134, Batch 2100/3125, Loss: 1.2068846225738525, Uncertainty: 1.4183330535888672
Epoch 33, Batch 1000/3125, Loss: 3.4273018836975098, Uncertainty: 3.3188343048095703
Epoch 134, Batch 2200/3125, Loss: 0.9337741136550903, Uncertainty: 1.2186537981033325
Epoch 33, Batch 1100/3125, Loss: 3.3887016773223877, Uncertainty: 3.51627779006958
Epoch 134, Batch 2300/3125, Loss: 1.1206541061401367, Uncertainty: 1.354039192199707
Epoch 33, Batch 1200/3125, Loss: 4.807984828948975, Uncertainty: 7.702372074127197
Epoch 134, Batch 2400/3125, Loss: 1.1008689403533936, Uncertainty: 1.3042556047439575
Epoch 33, Batch 1300/3125, Loss: 3.0729684829711914, Uncertainty: 2.9374642372131348
Epoch 134, Batch 2500/3125, Loss: 1.0449105501174927, Uncertainty: 1.5654640197753906
Epoch 33, Batch 1400/3125, Loss: 3.3520727157592773, Uncertainty: 3.282996654510498
Epoch 134, Batch 2600/3125, Loss: 1.1228148937225342, Uncertainty: 1.5513966083526611
Epoch 134, Batch 2700/3125, Loss: 1.3401856422424316, Uncertainty: 1.7199485301971436
Epoch 33, Batch 1500/3125, Loss: 3.2166571617126465, Uncertainty: 3.884868621826172
Epoch 134, Batch 2800/3125, Loss: 0.9057580232620239, Uncertainty: 1.1695891618728638
Epoch 33, Batch 1600/3125, Loss: 3.018801689147949, Uncertainty: 2.8233134746551514
Epoch 134, Batch 2900/3125, Loss: 1.0562562942504883, Uncertainty: 1.350472331047058
Epoch 33, Batch 1700/3125, Loss: 3.0188467502593994, Uncertainty: 2.981398582458496
Epoch 134, Batch 3000/3125, Loss: 1.257624626159668, Uncertainty: 1.3352956771850586
Epoch 33, Batch 1800/3125, Loss: 3.7343297004699707, Uncertainty: 3.0736851692199707
Epoch 134, Batch 3100/3125, Loss: 1.0169713497161865, Uncertainty: 1.2718195915222168
Epoch 33, Batch 1900/3125, Loss: 3.033555030822754, Uncertainty: 2.6298434734344482
Epoch 33, Batch 2000/3125, Loss: 3.432783603668213, Uncertainty: 3.4723100662231445
Epoch 33, Batch 2100/3125, Loss: 3.847566604614258, Uncertainty: 5.923090934753418
Epoch 33, Batch 2200/3125, Loss: 3.0965213775634766, Uncertainty: 4.031030654907227
Epoch 33, Batch 2300/3125, Loss: 3.1003901958465576, Uncertainty: 2.950913190841675
Epoch 33, Batch 2400/3125, Loss: 3.1078805923461914, Uncertainty: 3.147491931915283
Epoch 33, Batch 2500/3125, Loss: 2.9952120780944824, Uncertainty: 2.7793021202087402

Training and Validation Results of Epoch 134:
================================
Training Loss: 0.8710086780548095, Training Uncertainty: 1.3705489122009278, time: 172.9619255065918
Validation Loss: 0.7494049768161286, Validation Uncertainty: 1.9141153060566738, time: 39.89205455780029
Number of predictions within uncertainty interval: 128299/200000 (64.15%)

Epoch 33, Batch 2600/3125, Loss: 4.365966796875, Uncertainty: 6.683746337890625
Epoch 135, Batch 100/3125, Loss: 1.156416893005371, Uncertainty: 1.1996238231658936
Epoch 33, Batch 2700/3125, Loss: 3.2034058570861816, Uncertainty: 2.9393136501312256
Epoch 135, Batch 200/3125, Loss: 1.1034221649169922, Uncertainty: 1.4852920770645142
Epoch 135, Batch 300/3125, Loss: 1.2238543033599854, Uncertainty: 1.5923433303833008
Epoch 33, Batch 2800/3125, Loss: 3.0853915214538574, Uncertainty: 2.765249013900757
Epoch 135, Batch 400/3125, Loss: 1.13689386844635, Uncertainty: 1.3010833263397217
Epoch 33, Batch 2900/3125, Loss: 3.4195847511291504, Uncertainty: 4.6938934326171875
Epoch 135, Batch 500/3125, Loss: 1.0336573123931885, Uncertainty: 1.274079442024231
Epoch 33, Batch 3000/3125, Loss: 3.708508253097534, Uncertainty: 4.637593746185303
Epoch 135, Batch 600/3125, Loss: 1.341549277305603, Uncertainty: 1.7859055995941162
Epoch 33, Batch 3100/3125, Loss: 3.1053690910339355, Uncertainty: 3.106240749359131
Epoch 135, Batch 700/3125, Loss: 1.0079941749572754, Uncertainty: 1.2092437744140625
Epoch 135, Batch 800/3125, Loss: 1.2884601354599, Uncertainty: 1.9158989191055298
Epoch 135, Batch 900/3125, Loss: 1.1383979320526123, Uncertainty: 1.3688496351242065
Epoch 135, Batch 1000/3125, Loss: 0.9802652597427368, Uncertainty: 1.1776344776153564
Epoch 135, Batch 1100/3125, Loss: 1.0663187503814697, Uncertainty: 1.4774408340454102
Epoch 135, Batch 1200/3125, Loss: 1.1384787559509277, Uncertainty: 1.3456242084503174
Epoch 135, Batch 1300/3125, Loss: 0.9422687292098999, Uncertainty: 1.0756797790527344
Epoch 135, Batch 1400/3125, Loss: 1.1672534942626953, Uncertainty: 1.2988500595092773

Training and Validation Results of Epoch 33:
================================
Training Loss: 2.901530323410034, Training Uncertainty: 3.547003282775879, time: 191.35037565231323
Validation Loss: 2.6322293510217496, Validation Uncertainty: 6.92634982831033, time: 43.831499099731445
Number of predictions within uncertainty interval: 134604/200000 (67.30%)

Epoch 135, Batch 1500/3125, Loss: 1.1841320991516113, Uncertainty: 1.393437147140503
Epoch 34, Batch 100/3125, Loss: 3.106649398803711, Uncertainty: 2.841930627822876
Epoch 135, Batch 1600/3125, Loss: 0.950574517250061, Uncertainty: 1.2832508087158203
Epoch 34, Batch 200/3125, Loss: 3.150162935256958, Uncertainty: 3.4343347549438477
Epoch 135, Batch 1700/3125, Loss: 1.020005226135254, Uncertainty: 1.405803918838501
Epoch 34, Batch 300/3125, Loss: 3.137721538543701, Uncertainty: 3.815011978149414
Epoch 135, Batch 1800/3125, Loss: 1.1069793701171875, Uncertainty: 1.392661452293396
Epoch 34, Batch 400/3125, Loss: 3.2686502933502197, Uncertainty: 3.0731043815612793
Epoch 135, Batch 1900/3125, Loss: 0.948052704334259, Uncertainty: 1.3529279232025146
Epoch 34, Batch 500/3125, Loss: 3.4931492805480957, Uncertainty: 3.894704818725586
Epoch 135, Batch 2000/3125, Loss: 1.029101848602295, Uncertainty: 1.2978280782699585
Epoch 34, Batch 600/3125, Loss: 3.0693740844726562, Uncertainty: 2.9615883827209473
Epoch 135, Batch 2100/3125, Loss: 1.2423702478408813, Uncertainty: 1.4951345920562744
Epoch 34, Batch 700/3125, Loss: 3.2587475776672363, Uncertainty: 2.635965347290039
Epoch 135, Batch 2200/3125, Loss: 0.9026122093200684, Uncertainty: 1.0328400135040283
Epoch 34, Batch 800/3125, Loss: 3.6459879875183105, Uncertainty: 3.8526952266693115
Epoch 135, Batch 2300/3125, Loss: 1.1216645240783691, Uncertainty: 1.3557913303375244
Epoch 135, Batch 2400/3125, Loss: 1.2691926956176758, Uncertainty: 1.4852110147476196
Epoch 34, Batch 900/3125, Loss: 3.5825021266937256, Uncertainty: 4.787303924560547
Epoch 135, Batch 2500/3125, Loss: 1.0287013053894043, Uncertainty: 1.4464919567108154
Epoch 34, Batch 1000/3125, Loss: 3.2901721000671387, Uncertainty: 3.2854180335998535
Epoch 135, Batch 2600/3125, Loss: 1.1710708141326904, Uncertainty: 1.6499497890472412
Epoch 34, Batch 1100/3125, Loss: 3.558917760848999, Uncertainty: 3.848841667175293
Epoch 135, Batch 2700/3125, Loss: 1.1821417808532715, Uncertainty: 1.5023212432861328
Epoch 34, Batch 1200/3125, Loss: 3.6362392902374268, Uncertainty: 4.4375739097595215
Epoch 135, Batch 2800/3125, Loss: 0.9232940673828125, Uncertainty: 1.2815827131271362
Epoch 34, Batch 1300/3125, Loss: 3.0393853187561035, Uncertainty: 3.3417091369628906
Epoch 135, Batch 2900/3125, Loss: 1.0698332786560059, Uncertainty: 1.3384310007095337
Epoch 34, Batch 1400/3125, Loss: 3.2804040908813477, Uncertainty: 3.4123103618621826
Epoch 135, Batch 3000/3125, Loss: 1.1954306364059448, Uncertainty: 1.360811471939087
Epoch 34, Batch 1500/3125, Loss: 2.948582649230957, Uncertainty: 2.6216015815734863
Epoch 135, Batch 3100/3125, Loss: 1.0445072650909424, Uncertainty: 1.2593703269958496
Epoch 34, Batch 1600/3125, Loss: 3.1357312202453613, Uncertainty: 3.074336051940918
Epoch 34, Batch 1700/3125, Loss: 3.3474268913269043, Uncertainty: 4.230944633483887
Epoch 34, Batch 1800/3125, Loss: 3.838231086730957, Uncertainty: 5.859005451202393
Epoch 34, Batch 1900/3125, Loss: 3.0838937759399414, Uncertainty: 3.363703727722168
Epoch 34, Batch 2000/3125, Loss: 3.301351308822632, Uncertainty: 2.8938472270965576
Epoch 34, Batch 2100/3125, Loss: 3.1806163787841797, Uncertainty: 3.2252612113952637
Epoch 34, Batch 2200/3125, Loss: 2.9948763847351074, Uncertainty: 2.877701759338379

Training and Validation Results of Epoch 135:
================================
Training Loss: 0.8748507888603211, Training Uncertainty: 1.3677162089920043, time: 175.40698194503784
Validation Loss: 0.7585757037867671, Validation Uncertainty: 1.9165453076972376, time: 40.03225898742676
Number of predictions within uncertainty interval: 127320/200000 (63.66%)

Epoch 136, Batch 100/3125, Loss: 1.0612189769744873, Uncertainty: 1.1141715049743652
Epoch 34, Batch 2300/3125, Loss: 3.0644640922546387, Uncertainty: 3.031757116317749
Epoch 136, Batch 200/3125, Loss: 1.0934207439422607, Uncertainty: 1.4261603355407715
Epoch 34, Batch 2400/3125, Loss: 3.074681282043457, Uncertainty: 3.264127254486084
Epoch 136, Batch 300/3125, Loss: 1.31039297580719, Uncertainty: 1.7673041820526123
Epoch 34, Batch 2500/3125, Loss: 3.0723071098327637, Uncertainty: 3.4301061630249023
Epoch 136, Batch 400/3125, Loss: 1.1242592334747314, Uncertainty: 1.3694756031036377
Epoch 34, Batch 2600/3125, Loss: 3.8168468475341797, Uncertainty: 5.201038360595703
Epoch 136, Batch 500/3125, Loss: 1.0640368461608887, Uncertainty: 1.3298676013946533
Epoch 34, Batch 2700/3125, Loss: 3.449918508529663, Uncertainty: 2.5236549377441406
Epoch 136, Batch 600/3125, Loss: 1.1889703273773193, Uncertainty: 1.3011554479599
Epoch 34, Batch 2800/3125, Loss: 3.0846214294433594, Uncertainty: 3.0024964809417725
Epoch 136, Batch 700/3125, Loss: 1.0394665002822876, Uncertainty: 1.2293401956558228
Epoch 34, Batch 2900/3125, Loss: 3.442335605621338, Uncertainty: 4.834019660949707
Epoch 136, Batch 800/3125, Loss: 1.109346628189087, Uncertainty: 1.3647617101669312
Epoch 34, Batch 3000/3125, Loss: 3.4446356296539307, Uncertainty: 3.3063106536865234
Epoch 136, Batch 900/3125, Loss: 1.195496916770935, Uncertainty: 1.5342872142791748
Epoch 34, Batch 3100/3125, Loss: 3.0655100345611572, Uncertainty: 3.1294403076171875
Epoch 136, Batch 1000/3125, Loss: 0.9583721160888672, Uncertainty: 1.1219066381454468
Epoch 136, Batch 1100/3125, Loss: 0.9907763004302979, Uncertainty: 1.3065489530563354
Epoch 136, Batch 1200/3125, Loss: 1.1349222660064697, Uncertainty: 1.3546521663665771
Epoch 136, Batch 1300/3125, Loss: 0.9585403203964233, Uncertainty: 1.1165173053741455
Epoch 136, Batch 1400/3125, Loss: 1.1920080184936523, Uncertainty: 1.4975125789642334
Epoch 136, Batch 1500/3125, Loss: 1.1379536390304565, Uncertainty: 1.2847603559494019
Epoch 136, Batch 1600/3125, Loss: 0.9829089045524597, Uncertainty: 1.362815022468567
Epoch 136, Batch 1700/3125, Loss: 1.1542422771453857, Uncertainty: 1.8093903064727783
Epoch 136, Batch 1800/3125, Loss: 1.1603314876556396, Uncertainty: 1.5561481714248657

Training and Validation Results of Epoch 34:
================================
Training Loss: 2.8608555980682375, Training Uncertainty: 3.4662882595062254, time: 191.52994298934937
Validation Loss: 2.8985418380069, Validation Uncertainty: 4.889801051610571, time: 43.72866344451904
Number of predictions within uncertainty interval: 90015/200000 (45.01%)

Epoch 136, Batch 1900/3125, Loss: 0.8896707892417908, Uncertainty: 1.2628021240234375
Epoch 35, Batch 100/3125, Loss: 3.9985766410827637, Uncertainty: 4.770992279052734
Epoch 136, Batch 2000/3125, Loss: 1.0598028898239136, Uncertainty: 1.4362181425094604
Epoch 35, Batch 200/3125, Loss: 3.0540008544921875, Uncertainty: 3.013036012649536
Epoch 136, Batch 2100/3125, Loss: 1.2064114809036255, Uncertainty: 1.431879997253418
Epoch 35, Batch 300/3125, Loss: 2.8740508556365967, Uncertainty: 2.5973591804504395
Epoch 136, Batch 2200/3125, Loss: 1.0238864421844482, Uncertainty: 1.304211139678955
Epoch 35, Batch 400/3125, Loss: 3.268299102783203, Uncertainty: 4.4370036125183105
Epoch 136, Batch 2300/3125, Loss: 1.1189641952514648, Uncertainty: 1.3526782989501953
Epoch 35, Batch 500/3125, Loss: 3.2925379276275635, Uncertainty: 3.6230666637420654
Epoch 136, Batch 2400/3125, Loss: 1.2576236724853516, Uncertainty: 1.8448176383972168
Epoch 35, Batch 600/3125, Loss: 3.1860151290893555, Uncertainty: 3.2934658527374268
Epoch 136, Batch 2500/3125, Loss: 1.0781524181365967, Uncertainty: 1.6558537483215332
Epoch 136, Batch 2600/3125, Loss: 1.1748696565628052, Uncertainty: 1.7068383693695068
Epoch 35, Batch 700/3125, Loss: 3.2681963443756104, Uncertainty: 4.076597690582275
Epoch 136, Batch 2700/3125, Loss: 1.1928365230560303, Uncertainty: 1.5147124528884888
Epoch 35, Batch 800/3125, Loss: 3.543123245239258, Uncertainty: 3.267642021179199
Epoch 136, Batch 2800/3125, Loss: 0.8883511424064636, Uncertainty: 1.1527271270751953
Epoch 35, Batch 900/3125, Loss: 3.5222856998443604, Uncertainty: 3.206007719039917
Epoch 136, Batch 2900/3125, Loss: 1.0450550317764282, Uncertainty: 1.327207326889038
Epoch 35, Batch 1000/3125, Loss: 3.5626883506774902, Uncertainty: 3.8176774978637695
Epoch 136, Batch 3000/3125, Loss: 1.1681697368621826, Uncertainty: 1.353137493133545
Epoch 35, Batch 1100/3125, Loss: 3.274026393890381, Uncertainty: 3.3398208618164062
Epoch 136, Batch 3100/3125, Loss: 1.006829023361206, Uncertainty: 1.229058861732483
Epoch 35, Batch 1200/3125, Loss: 3.9465112686157227, Uncertainty: 5.300417423248291
Epoch 35, Batch 1300/3125, Loss: 3.1756949424743652, Uncertainty: 3.855673313140869
Epoch 35, Batch 1400/3125, Loss: 4.395043849945068, Uncertainty: 6.040933609008789
Epoch 35, Batch 1500/3125, Loss: 3.100809097290039, Uncertainty: 2.940092086791992
Epoch 35, Batch 1600/3125, Loss: 2.922990083694458, Uncertainty: 2.662242889404297
Epoch 35, Batch 1700/3125, Loss: 2.7730703353881836, Uncertainty: 2.9285807609558105
Epoch 35, Batch 1800/3125, Loss: 3.566720485687256, Uncertainty: 4.880698204040527

Training and Validation Results of Epoch 136:
================================
Training Loss: 0.8646990383529664, Training Uncertainty: 1.3859444900512696, time: 172.48047542572021
Validation Loss: 0.7581758052491776, Validation Uncertainty: 1.918651695141707, time: 39.682058811187744
Number of predictions within uncertainty interval: 127701/200000 (63.85%)

Epoch 35, Batch 1900/3125, Loss: 2.9791316986083984, Uncertainty: 3.0049080848693848
Epoch 137, Batch 100/3125, Loss: 1.0829195976257324, Uncertainty: 1.158571720123291
Epoch 137, Batch 200/3125, Loss: 1.0440391302108765, Uncertainty: 1.2786543369293213
Epoch 35, Batch 2000/3125, Loss: 3.453207492828369, Uncertainty: 4.228283882141113
Epoch 137, Batch 300/3125, Loss: 1.140244960784912, Uncertainty: 1.3857817649841309
Epoch 35, Batch 2100/3125, Loss: 3.1391332149505615, Uncertainty: 3.3228704929351807
Epoch 137, Batch 400/3125, Loss: 1.0096409320831299, Uncertainty: 1.2189717292785645
Epoch 35, Batch 2200/3125, Loss: 3.192646026611328, Uncertainty: 3.4681787490844727
Epoch 137, Batch 500/3125, Loss: 1.0157148838043213, Uncertainty: 1.2922213077545166
Epoch 35, Batch 2300/3125, Loss: 2.9175631999969482, Uncertainty: 2.7909326553344727
Epoch 137, Batch 600/3125, Loss: 1.2590720653533936, Uncertainty: 1.3614497184753418
Epoch 35, Batch 2400/3125, Loss: 3.164559841156006, Uncertainty: 3.05428147315979
Epoch 137, Batch 700/3125, Loss: 1.0274405479431152, Uncertainty: 1.1989734172821045
Epoch 35, Batch 2500/3125, Loss: 2.837825298309326, Uncertainty: 2.5702362060546875
Epoch 137, Batch 800/3125, Loss: 1.1622722148895264, Uncertainty: 1.379732370376587
Epoch 35, Batch 2600/3125, Loss: 3.2575831413269043, Uncertainty: 3.1709909439086914
Epoch 137, Batch 900/3125, Loss: 1.1167383193969727, Uncertainty: 1.3362610340118408
Epoch 35, Batch 2700/3125, Loss: 2.892594814300537, Uncertainty: 2.6362786293029785
Epoch 137, Batch 1000/3125, Loss: 0.978712797164917, Uncertainty: 1.2145648002624512
Epoch 35, Batch 2800/3125, Loss: 2.8063859939575195, Uncertainty: 2.614058017730713
Epoch 137, Batch 1100/3125, Loss: 0.9857672452926636, Uncertainty: 1.253232479095459
Epoch 137, Batch 1200/3125, Loss: 1.1129997968673706, Uncertainty: 1.39509916305542
Epoch 35, Batch 2900/3125, Loss: 2.932760715484619, Uncertainty: 2.868645191192627
Epoch 137, Batch 1300/3125, Loss: 0.9822231531143188, Uncertainty: 1.2140729427337646
Epoch 35, Batch 3000/3125, Loss: 3.6783065795898438, Uncertainty: 3.133378505706787
Epoch 137, Batch 1400/3125, Loss: 1.1001408100128174, Uncertainty: 1.3125455379486084
Epoch 35, Batch 3100/3125, Loss: 3.1088480949401855, Uncertainty: 2.979065179824829
Epoch 137, Batch 1500/3125, Loss: 1.1394253969192505, Uncertainty: 1.3309000730514526
Epoch 137, Batch 1600/3125, Loss: 0.893925666809082, Uncertainty: 1.1373764276504517
Epoch 137, Batch 1700/3125, Loss: 1.0304923057556152, Uncertainty: 1.4327224493026733
Epoch 137, Batch 1800/3125, Loss: 1.1284576654434204, Uncertainty: 1.5084166526794434
Epoch 137, Batch 1900/3125, Loss: 0.8541457653045654, Uncertainty: 1.1511502265930176
Epoch 137, Batch 2000/3125, Loss: 1.044776201248169, Uncertainty: 1.4384416341781616
Epoch 137, Batch 2100/3125, Loss: 1.2428371906280518, Uncertainty: 1.4028598070144653
Epoch 137, Batch 2200/3125, Loss: 0.8792831897735596, Uncertainty: 1.0908148288726807

Training and Validation Results of Epoch 35:
================================
Training Loss: 2.8031827278900145, Training Uncertainty: 3.422158404159546, time: 191.60393476486206
Validation Loss: 2.9396783793368915, Validation Uncertainty: 4.989667300373087, time: 43.778016567230225
Number of predictions within uncertainty interval: 89996/200000 (45.00%)

Epoch 137, Batch 2300/3125, Loss: 1.1103289127349854, Uncertainty: 1.3810484409332275
Epoch 36, Batch 100/3125, Loss: 3.0992956161499023, Uncertainty: 3.2769856452941895
Epoch 137, Batch 2400/3125, Loss: 1.2334789037704468, Uncertainty: 1.426647424697876
Epoch 36, Batch 200/3125, Loss: 3.1647162437438965, Uncertainty: 3.7704529762268066
Epoch 137, Batch 2500/3125, Loss: 1.0041441917419434, Uncertainty: 1.3610141277313232
Epoch 36, Batch 300/3125, Loss: 3.0104169845581055, Uncertainty: 2.7396678924560547
Epoch 137, Batch 2600/3125, Loss: 1.2300834655761719, Uncertainty: 1.8708478212356567
Epoch 137, Batch 2700/3125, Loss: 1.2871968746185303, Uncertainty: 1.494452953338623
Epoch 36, Batch 400/3125, Loss: 4.124526023864746, Uncertainty: 6.754316806793213
Epoch 137, Batch 2800/3125, Loss: 0.8877770304679871, Uncertainty: 1.1484507322311401
Epoch 36, Batch 500/3125, Loss: 3.9989991188049316, Uncertainty: 3.582507610321045
Epoch 137, Batch 2900/3125, Loss: 1.0429916381835938, Uncertainty: 1.3012089729309082
Epoch 36, Batch 600/3125, Loss: 3.169656753540039, Uncertainty: 3.73250675201416
Epoch 137, Batch 3000/3125, Loss: 1.21340811252594, Uncertainty: 1.3622100353240967
Epoch 36, Batch 700/3125, Loss: 2.992197036743164, Uncertainty: 2.7066922187805176
Epoch 137, Batch 3100/3125, Loss: 0.9811795353889465, Uncertainty: 1.16725754737854
Epoch 36, Batch 800/3125, Loss: 3.134532928466797, Uncertainty: 2.68214750289917
Epoch 36, Batch 900/3125, Loss: 3.4739058017730713, Uncertainty: 2.652928590774536
Epoch 36, Batch 1000/3125, Loss: 3.109416961669922, Uncertainty: 3.4420547485351562
Epoch 36, Batch 1100/3125, Loss: 3.2297589778900146, Uncertainty: 3.417349338531494
Epoch 36, Batch 1200/3125, Loss: 2.9491395950317383, Uncertainty: 2.669255018234253
Epoch 36, Batch 1300/3125, Loss: 2.9063968658447266, Uncertainty: 3.5644259452819824
Epoch 36, Batch 1400/3125, Loss: 3.9597625732421875, Uncertainty: 4.719452381134033

Training and Validation Results of Epoch 137:
================================
Training Loss: 0.8682546963310241, Training Uncertainty: 1.362474167098999, time: 171.8296799659729
Validation Loss: 0.7511253227358279, Validation Uncertainty: 1.8889909321084961, time: 39.90199303627014
Number of predictions within uncertainty interval: 126984/200000 (63.49%)

Epoch 36, Batch 1500/3125, Loss: 2.8368754386901855, Uncertainty: 2.658670425415039
Epoch 138, Batch 100/3125, Loss: 0.9229205846786499, Uncertainty: 1.0771900415420532
Epoch 36, Batch 1600/3125, Loss: 2.94771671295166, Uncertainty: 3.2588579654693604
Epoch 138, Batch 200/3125, Loss: 1.046668529510498, Uncertainty: 1.3163350820541382
Epoch 138, Batch 300/3125, Loss: 1.1433955430984497, Uncertainty: 1.4706811904907227
Epoch 36, Batch 1700/3125, Loss: 2.9348337650299072, Uncertainty: 2.91762113571167
Epoch 138, Batch 400/3125, Loss: 1.0607447624206543, Uncertainty: 1.5352143049240112
Epoch 36, Batch 1800/3125, Loss: 2.7778468132019043, Uncertainty: 2.772451400756836
Epoch 138, Batch 500/3125, Loss: 1.001885175704956, Uncertainty: 1.2779886722564697
Epoch 36, Batch 1900/3125, Loss: 2.9949049949645996, Uncertainty: 3.3749349117279053
Epoch 138, Batch 600/3125, Loss: 1.239806890487671, Uncertainty: 1.5632634162902832
Epoch 36, Batch 2000/3125, Loss: 2.9178900718688965, Uncertainty: 3.131019353866577
Epoch 138, Batch 700/3125, Loss: 1.045912742614746, Uncertainty: 1.201765775680542
Epoch 36, Batch 2100/3125, Loss: 3.408238410949707, Uncertainty: 3.5552635192871094
Epoch 138, Batch 800/3125, Loss: 1.085491418838501, Uncertainty: 1.2691316604614258
Epoch 36, Batch 2200/3125, Loss: 2.5487303733825684, Uncertainty: 2.5566859245300293
Epoch 138, Batch 900/3125, Loss: 1.1072680950164795, Uncertainty: 1.3300952911376953
Epoch 36, Batch 2300/3125, Loss: 2.8403146266937256, Uncertainty: 2.8620502948760986
Epoch 138, Batch 1000/3125, Loss: 0.9829717874526978, Uncertainty: 1.2663486003875732
Epoch 36, Batch 2400/3125, Loss: 3.322388172149658, Uncertainty: 3.201636791229248
Epoch 138, Batch 1100/3125, Loss: 0.9643937349319458, Uncertainty: 1.207371711730957
Epoch 138, Batch 1200/3125, Loss: 1.115195393562317, Uncertainty: 1.3650375604629517
Epoch 36, Batch 2500/3125, Loss: 2.7731518745422363, Uncertainty: 2.6067709922790527
Epoch 138, Batch 1300/3125, Loss: 0.954491376876831, Uncertainty: 1.1275193691253662
Epoch 36, Batch 2600/3125, Loss: 3.5655436515808105, Uncertainty: 3.135918140411377
Epoch 138, Batch 1400/3125, Loss: 0.9911532402038574, Uncertainty: 1.28107488155365
Epoch 36, Batch 2700/3125, Loss: 2.978445529937744, Uncertainty: 2.4825050830841064
Epoch 138, Batch 1500/3125, Loss: 1.1201341152191162, Uncertainty: 1.272698998451233
Epoch 36, Batch 2800/3125, Loss: 3.7431070804595947, Uncertainty: 2.7509031295776367
Epoch 138, Batch 1600/3125, Loss: 0.8664866089820862, Uncertainty: 1.0935953855514526
Epoch 36, Batch 2900/3125, Loss: 3.4751944541931152, Uncertainty: 4.357845306396484
Epoch 138, Batch 1700/3125, Loss: 1.1078777313232422, Uncertainty: 1.662711501121521
Epoch 36, Batch 3000/3125, Loss: 3.542139768600464, Uncertainty: 5.1875104904174805
Epoch 138, Batch 1800/3125, Loss: 1.1629431247711182, Uncertainty: 1.5528873205184937
Epoch 36, Batch 3100/3125, Loss: 2.8603157997131348, Uncertainty: 2.625622272491455
Epoch 138, Batch 1900/3125, Loss: 0.9796271324157715, Uncertainty: 1.3120111227035522
Epoch 138, Batch 2000/3125, Loss: 1.0247912406921387, Uncertainty: 1.3778729438781738
Epoch 138, Batch 2100/3125, Loss: 1.2474737167358398, Uncertainty: 1.5525368452072144
Epoch 138, Batch 2200/3125, Loss: 1.015815258026123, Uncertainty: 1.1544166803359985
Epoch 138, Batch 2300/3125, Loss: 1.1524624824523926, Uncertainty: 1.5627027750015259
Epoch 138, Batch 2400/3125, Loss: 1.2947719097137451, Uncertainty: 1.3897563219070435
Epoch 138, Batch 2500/3125, Loss: 1.020803689956665, Uncertainty: 1.4402730464935303
Epoch 138, Batch 2600/3125, Loss: 1.1873563528060913, Uncertainty: 1.681943655014038
Epoch 138, Batch 2700/3125, Loss: 1.162189245223999, Uncertainty: 1.4721755981445312

Training and Validation Results of Epoch 36:
================================
Training Loss: 2.7403435233306883, Training Uncertainty: 3.3616913138580324, time: 194.04412937164307
Validation Loss: 2.385516350226634, Validation Uncertainty: 4.419073507304081, time: 44.32554268836975
Number of predictions within uncertainty interval: 101496/200000 (50.75%)

Epoch 138, Batch 2800/3125, Loss: 0.8831477165222168, Uncertainty: 1.1543657779693604
Epoch 37, Batch 100/3125, Loss: 3.296414852142334, Uncertainty: 3.0562825202941895
Epoch 138, Batch 2900/3125, Loss: 1.2125186920166016, Uncertainty: 1.8683006763458252
Epoch 37, Batch 200/3125, Loss: 3.122835636138916, Uncertainty: 3.9707658290863037
Epoch 138, Batch 3000/3125, Loss: 1.1355664730072021, Uncertainty: 1.3407588005065918
Epoch 37, Batch 300/3125, Loss: 2.6617817878723145, Uncertainty: 2.6083197593688965
Epoch 138, Batch 3100/3125, Loss: 0.988238513469696, Uncertainty: 1.213836431503296
Epoch 37, Batch 400/3125, Loss: 2.810689926147461, Uncertainty: 2.8696937561035156
Epoch 37, Batch 500/3125, Loss: 3.088526725769043, Uncertainty: 3.274834156036377
Epoch 37, Batch 600/3125, Loss: 3.4276297092437744, Uncertainty: 2.7171921730041504
Epoch 37, Batch 700/3125, Loss: 2.876427173614502, Uncertainty: 2.8723387718200684
Epoch 37, Batch 800/3125, Loss: 3.0044593811035156, Uncertainty: 2.7699780464172363
Epoch 37, Batch 900/3125, Loss: 3.607485771179199, Uncertainty: 2.8066067695617676
Epoch 37, Batch 1000/3125, Loss: 2.969212293624878, Uncertainty: 2.6270580291748047

Training and Validation Results of Epoch 138:
================================
Training Loss: 0.8623432052230835, Training Uncertainty: 1.3607448662757873, time: 172.0388560295105
Validation Loss: 0.7372335558352263, Validation Uncertainty: 1.9006158718672554, time: 39.89726114273071
Number of predictions within uncertainty interval: 128843/200000 (64.42%)

Epoch 37, Batch 1100/3125, Loss: 3.6984670162200928, Uncertainty: 4.694909572601318
Epoch 139, Batch 100/3125, Loss: 0.9996541738510132, Uncertainty: 1.0596643686294556
Epoch 37, Batch 1200/3125, Loss: 4.411730766296387, Uncertainty: 7.279163837432861
Epoch 139, Batch 200/3125, Loss: 1.0916705131530762, Uncertainty: 1.3727644681930542
Epoch 37, Batch 1300/3125, Loss: 2.829934597015381, Uncertainty: 3.127359390258789
Epoch 139, Batch 300/3125, Loss: 1.154650092124939, Uncertainty: 1.3652710914611816
Epoch 37, Batch 1400/3125, Loss: 3.519744634628296, Uncertainty: 4.2288289070129395
Epoch 139, Batch 400/3125, Loss: 1.0180811882019043, Uncertainty: 1.1835532188415527
Epoch 37, Batch 1500/3125, Loss: 2.5240533351898193, Uncertainty: 2.401087999343872
Epoch 139, Batch 500/3125, Loss: 1.0133273601531982, Uncertainty: 1.2976329326629639
Epoch 37, Batch 1600/3125, Loss: 2.9999048709869385, Uncertainty: 3.058258056640625
Epoch 139, Batch 600/3125, Loss: 1.1836206912994385, Uncertainty: 1.3175880908966064
Epoch 37, Batch 1700/3125, Loss: 2.8879828453063965, Uncertainty: 2.9888477325439453
Epoch 139, Batch 700/3125, Loss: 0.9894497990608215, Uncertainty: 1.2195931673049927
Epoch 139, Batch 800/3125, Loss: 1.1083440780639648, Uncertainty: 1.3342068195343018
Epoch 37, Batch 1800/3125, Loss: 3.758984327316284, Uncertainty: 2.816228151321411
Epoch 139, Batch 900/3125, Loss: 1.1704497337341309, Uncertainty: 1.4905602931976318
Epoch 37, Batch 1900/3125, Loss: 2.974475860595703, Uncertainty: 3.3464221954345703
Epoch 139, Batch 1000/3125, Loss: 0.9611351490020752, Uncertainty: 1.1615961790084839
Epoch 37, Batch 2000/3125, Loss: 2.915830135345459, Uncertainty: 2.812107563018799
Epoch 139, Batch 1100/3125, Loss: 0.9916529655456543, Uncertainty: 1.3000402450561523
Epoch 37, Batch 2100/3125, Loss: 3.3178515434265137, Uncertainty: 3.574004650115967
Epoch 139, Batch 1200/3125, Loss: 1.1089324951171875, Uncertainty: 1.334857702255249
Epoch 37, Batch 2200/3125, Loss: 3.0227885246276855, Uncertainty: 3.224282741546631
Epoch 139, Batch 1300/3125, Loss: 0.9513267874717712, Uncertainty: 1.0961430072784424
Epoch 37, Batch 2300/3125, Loss: 2.682340621948242, Uncertainty: 2.711973190307617
Epoch 139, Batch 1400/3125, Loss: 1.2955191135406494, Uncertainty: 1.4506886005401611
Epoch 37, Batch 2400/3125, Loss: 3.1242165565490723, Uncertainty: 4.0106635093688965
Epoch 139, Batch 1500/3125, Loss: 1.136101245880127, Uncertainty: 1.2945873737335205
Epoch 37, Batch 2500/3125, Loss: 2.7038514614105225, Uncertainty: 2.7627105712890625
Epoch 139, Batch 1600/3125, Loss: 0.9125549793243408, Uncertainty: 1.204691767692566
Epoch 139, Batch 1700/3125, Loss: 0.9927639961242676, Uncertainty: 1.3385450839996338
Epoch 37, Batch 2600/3125, Loss: 3.045107841491699, Uncertainty: 3.4405765533447266
Epoch 139, Batch 1800/3125, Loss: 1.1904805898666382, Uncertainty: 1.6968104839324951
Epoch 37, Batch 2700/3125, Loss: 3.0111560821533203, Uncertainty: 3.576686382293701
Epoch 139, Batch 1900/3125, Loss: 0.9490545988082886, Uncertainty: 1.3223450183868408
Epoch 37, Batch 2800/3125, Loss: 2.770354747772217, Uncertainty: 2.7791223526000977
Epoch 139, Batch 2000/3125, Loss: 1.211708664894104, Uncertainty: 1.2628153562545776
Epoch 37, Batch 2900/3125, Loss: 3.024273157119751, Uncertainty: 3.677082061767578
Epoch 139, Batch 2100/3125, Loss: 1.1940478086471558, Uncertainty: 1.419370412826538
Epoch 37, Batch 3000/3125, Loss: 3.3065457344055176, Uncertainty: 2.3311023712158203
Epoch 139, Batch 2200/3125, Loss: 1.0911130905151367, Uncertainty: 1.2239971160888672
Epoch 37, Batch 3100/3125, Loss: 2.8004465103149414, Uncertainty: 2.634383201599121
Epoch 139, Batch 2300/3125, Loss: 1.0954800844192505, Uncertainty: 1.350174903869629
Epoch 139, Batch 2400/3125, Loss: 1.3282378911972046, Uncertainty: 2.0459518432617188
Epoch 139, Batch 2500/3125, Loss: 1.0920050144195557, Uncertainty: 1.6311618089675903
Epoch 139, Batch 2600/3125, Loss: 1.1167303323745728, Uncertainty: 1.5924752950668335
Epoch 139, Batch 2700/3125, Loss: 1.206969976425171, Uncertainty: 1.6115646362304688
Epoch 139, Batch 2800/3125, Loss: 0.8961170315742493, Uncertainty: 1.166832447052002
Epoch 139, Batch 2900/3125, Loss: 1.0667701959609985, Uncertainty: 1.2644429206848145
Epoch 139, Batch 3000/3125, Loss: 1.1564834117889404, Uncertainty: 1.350088357925415

Training and Validation Results of Epoch 37:
================================
Training Loss: 2.7035503018188476, Training Uncertainty: 3.3092025903320312, time: 192.7839801311493
Validation Loss: 2.35149310723595, Validation Uncertainty: 5.730279596870208, time: 44.317116022109985
Number of predictions within uncertainty interval: 128886/200000 (64.44%)

Epoch 139, Batch 3100/3125, Loss: 1.191420555114746, Uncertainty: 1.7802481651306152
Epoch 38, Batch 100/3125, Loss: 2.949629545211792, Uncertainty: 2.5705811977386475
Epoch 38, Batch 200/3125, Loss: 3.106703996658325, Uncertainty: 4.018975257873535
Epoch 38, Batch 300/3125, Loss: 2.8869729042053223, Uncertainty: 3.0051889419555664
Epoch 38, Batch 400/3125, Loss: 2.933344841003418, Uncertainty: 2.7417986392974854
Epoch 38, Batch 500/3125, Loss: 3.332848310470581, Uncertainty: 2.7528882026672363
Epoch 38, Batch 600/3125, Loss: 3.0905017852783203, Uncertainty: 3.222825288772583

Training and Validation Results of Epoch 139:
================================
Training Loss: 0.8619716966438293, Training Uncertainty: 1.3611648280525208, time: 176.7878897190094
Validation Loss: 0.7400406288826252, Validation Uncertainty: 1.9176385013953499, time: 39.95346260070801
Number of predictions within uncertainty interval: 129106/200000 (64.55%)

Epoch 38, Batch 700/3125, Loss: 2.824644088745117, Uncertainty: 2.7049829959869385
Epoch 140, Batch 100/3125, Loss: 0.964381217956543, Uncertainty: 1.0428402423858643
Epoch 38, Batch 800/3125, Loss: 3.299626350402832, Uncertainty: 3.698093891143799
Epoch 140, Batch 200/3125, Loss: 1.0587952136993408, Uncertainty: 1.305961012840271
Epoch 38, Batch 900/3125, Loss: 3.1663084030151367, Uncertainty: 2.502747058868408
Epoch 140, Batch 300/3125, Loss: 1.1513923406600952, Uncertainty: 1.4454461336135864
Epoch 38, Batch 1000/3125, Loss: 3.195810556411743, Uncertainty: 3.3498692512512207
Epoch 140, Batch 400/3125, Loss: 1.0573481321334839, Uncertainty: 1.2863552570343018
Epoch 38, Batch 1100/3125, Loss: 3.354393482208252, Uncertainty: 3.1720709800720215
Epoch 140, Batch 500/3125, Loss: 1.0793230533599854, Uncertainty: 1.2643918991088867
Epoch 38, Batch 1200/3125, Loss: 3.0880610942840576, Uncertainty: 2.8206472396850586
Epoch 140, Batch 600/3125, Loss: 1.1612718105316162, Uncertainty: 1.2625375986099243
Epoch 140, Batch 700/3125, Loss: 0.9845771193504333, Uncertainty: 1.1910343170166016
Epoch 38, Batch 1300/3125, Loss: 3.1836094856262207, Uncertainty: 3.7834489345550537
Epoch 140, Batch 800/3125, Loss: 1.1527082920074463, Uncertainty: 1.4915920495986938
Epoch 38, Batch 1400/3125, Loss: 3.822613477706909, Uncertainty: 4.9820733070373535
Epoch 140, Batch 900/3125, Loss: 1.2335267066955566, Uncertainty: 1.6969022750854492
Epoch 38, Batch 1500/3125, Loss: 2.7400870323181152, Uncertainty: 2.42484188079834
Epoch 140, Batch 1000/3125, Loss: 0.9882127046585083, Uncertainty: 1.12276029586792
Epoch 38, Batch 1600/3125, Loss: 3.0984740257263184, Uncertainty: 3.6993024349212646
Epoch 140, Batch 1100/3125, Loss: 1.0487492084503174, Uncertainty: 1.2079685926437378
Epoch 38, Batch 1700/3125, Loss: 2.9988067150115967, Uncertainty: 3.314108371734619
Epoch 140, Batch 1200/3125, Loss: 1.11147940158844, Uncertainty: 1.3446592092514038
Epoch 38, Batch 1800/3125, Loss: 2.7395946979522705, Uncertainty: 2.7397518157958984
Epoch 140, Batch 1300/3125, Loss: 0.9604049921035767, Uncertainty: 1.172303557395935
Epoch 38, Batch 1900/3125, Loss: 2.5901341438293457, Uncertainty: 2.5218467712402344
Epoch 140, Batch 1400/3125, Loss: 1.0717835426330566, Uncertainty: 1.446737289428711
Epoch 38, Batch 2000/3125, Loss: 3.222391128540039, Uncertainty: 2.7821125984191895
Epoch 140, Batch 1500/3125, Loss: 1.0923864841461182, Uncertainty: 1.194643259048462
Epoch 140, Batch 1600/3125, Loss: 0.8753465414047241, Uncertainty: 1.1245112419128418
Epoch 38, Batch 2100/3125, Loss: 3.2927920818328857, Uncertainty: 3.8418755531311035
Epoch 140, Batch 1700/3125, Loss: 1.0670362710952759, Uncertainty: 1.497859001159668
Epoch 38, Batch 2200/3125, Loss: 2.5800418853759766, Uncertainty: 2.6206421852111816
Epoch 140, Batch 1800/3125, Loss: 1.129115343093872, Uncertainty: 1.4865553379058838
Epoch 38, Batch 2300/3125, Loss: 3.040712833404541, Uncertainty: 3.638288974761963
Epoch 140, Batch 1900/3125, Loss: 1.1189695596694946, Uncertainty: 1.6947988271713257
Epoch 38, Batch 2400/3125, Loss: 3.8584706783294678, Uncertainty: 3.126394510269165
Epoch 140, Batch 2000/3125, Loss: 1.0307393074035645, Uncertainty: 1.4384732246398926
Epoch 140, Batch 2100/3125, Loss: 1.2064801454544067, Uncertainty: 1.3774834871292114
Epoch 38, Batch 2500/3125, Loss: 2.6392014026641846, Uncertainty: 2.871926784515381
Epoch 140, Batch 2200/3125, Loss: 0.978877604007721, Uncertainty: 1.269532322883606
Epoch 38, Batch 2600/3125, Loss: 3.302722454071045, Uncertainty: 4.021770477294922
Epoch 140, Batch 2300/3125, Loss: 1.0841408967971802, Uncertainty: 1.3299369812011719
Epoch 38, Batch 2700/3125, Loss: 3.046342134475708, Uncertainty: 2.518634557723999
Epoch 140, Batch 2400/3125, Loss: 1.2413878440856934, Uncertainty: 1.8447792530059814
Epoch 38, Batch 2800/3125, Loss: 3.2041821479797363, Uncertainty: 3.8930749893188477
Epoch 140, Batch 2500/3125, Loss: 1.1299903392791748, Uncertainty: 1.6866326332092285
Epoch 38, Batch 2900/3125, Loss: 3.2403714656829834, Uncertainty: 4.617173194885254
Epoch 140, Batch 2600/3125, Loss: 1.1520664691925049, Uncertainty: 1.6573857069015503
Epoch 140, Batch 2700/3125, Loss: 1.2028452157974243, Uncertainty: 1.5371568202972412
Epoch 38, Batch 3000/3125, Loss: 3.0029354095458984, Uncertainty: 2.6796202659606934
Epoch 140, Batch 2800/3125, Loss: 0.9103376865386963, Uncertainty: 1.2059681415557861
Epoch 38, Batch 3100/3125, Loss: 2.9626588821411133, Uncertainty: 2.7428135871887207
Epoch 140, Batch 2900/3125, Loss: 1.019775390625, Uncertainty: 1.3055171966552734
Epoch 140, Batch 3000/3125, Loss: 1.1557809114456177, Uncertainty: 1.3029696941375732
Epoch 140, Batch 3100/3125, Loss: 0.9931663274765015, Uncertainty: 1.2328288555145264

Training and Validation Results of Epoch 38:
================================
Training Loss: 2.664192019882202, Training Uncertainty: 3.262877189254761, time: 198.56533336639404
Validation Loss: 2.397679372669181, Validation Uncertainty: 4.438536958621286, time: 44.13800096511841
Number of predictions within uncertainty interval: 106428/200000 (53.21%)

Epoch 39, Batch 100/3125, Loss: 2.798128604888916, Uncertainty: 2.7810144424438477

Training and Validation Results of Epoch 140:
================================
Training Loss: 0.8577979305839538, Training Uncertainty: 1.357332497806549, time: 172.1428017616272
Validation Loss: 0.735375482103099, Validation Uncertainty: 1.8798919788102055, time: 39.82919931411743
Number of predictions within uncertainty interval: 128204/200000 (64.10%)

Epoch 39, Batch 200/3125, Loss: 3.38026762008667, Uncertainty: 2.5378177165985107
Epoch 141, Batch 100/3125, Loss: 1.0110435485839844, Uncertainty: 1.1195859909057617
Epoch 39, Batch 300/3125, Loss: 2.974743366241455, Uncertainty: 2.7872045040130615
Epoch 141, Batch 200/3125, Loss: 1.1322698593139648, Uncertainty: 1.586478352546692
Epoch 39, Batch 400/3125, Loss: 3.2491447925567627, Uncertainty: 3.964465618133545
Epoch 141, Batch 300/3125, Loss: 1.2128231525421143, Uncertainty: 1.5974124670028687
Epoch 39, Batch 500/3125, Loss: 2.8906073570251465, Uncertainty: 2.6740612983703613
Epoch 141, Batch 400/3125, Loss: 1.2914143800735474, Uncertainty: 1.7945749759674072
Epoch 39, Batch 600/3125, Loss: 3.054989814758301, Uncertainty: 3.7926387786865234
Epoch 141, Batch 500/3125, Loss: 0.9760284423828125, Uncertainty: 1.2326812744140625
Epoch 39, Batch 700/3125, Loss: 2.757669448852539, Uncertainty: 2.3539888858795166
Epoch 141, Batch 600/3125, Loss: 1.1556581258773804, Uncertainty: 1.271395206451416
Epoch 39, Batch 800/3125, Loss: 3.6788697242736816, Uncertainty: 4.720975875854492
Epoch 141, Batch 700/3125, Loss: 1.031806230545044, Uncertainty: 1.1642391681671143
Epoch 141, Batch 800/3125, Loss: 1.050399661064148, Uncertainty: 1.2589294910430908
Epoch 39, Batch 900/3125, Loss: 2.9278340339660645, Uncertainty: 3.018893003463745
Epoch 141, Batch 900/3125, Loss: 1.1703870296478271, Uncertainty: 1.5427340269088745
Epoch 39, Batch 1000/3125, Loss: 2.9082717895507812, Uncertainty: 3.1557412147521973
Epoch 141, Batch 1000/3125, Loss: 0.9528515934944153, Uncertainty: 1.146559476852417
Epoch 39, Batch 1100/3125, Loss: 3.2082200050354004, Uncertainty: 3.052722930908203
Epoch 141, Batch 1100/3125, Loss: 0.9629942178726196, Uncertainty: 1.221348762512207
Epoch 39, Batch 1200/3125, Loss: 3.0539438724517822, Uncertainty: 3.1975064277648926
Epoch 141, Batch 1200/3125, Loss: 1.0945911407470703, Uncertainty: 1.3265571594238281
Epoch 39, Batch 1300/3125, Loss: 2.710869073867798, Uncertainty: 3.038851737976074
Epoch 141, Batch 1300/3125, Loss: 1.0623352527618408, Uncertainty: 1.454622507095337
Epoch 39, Batch 1400/3125, Loss: 3.31019926071167, Uncertainty: 3.8281357288360596
Epoch 141, Batch 1400/3125, Loss: 1.0640723705291748, Uncertainty: 1.4305145740509033
Epoch 39, Batch 1500/3125, Loss: 3.4185099601745605, Uncertainty: 5.608238220214844
Epoch 141, Batch 1500/3125, Loss: 1.1290180683135986, Uncertainty: 1.246277093887329
Epoch 39, Batch 1600/3125, Loss: 3.1049132347106934, Uncertainty: 2.709691047668457
Epoch 141, Batch 1600/3125, Loss: 0.9939329028129578, Uncertainty: 1.229064702987671
Epoch 141, Batch 1700/3125, Loss: 1.0439109802246094, Uncertainty: 1.4609863758087158
Epoch 39, Batch 1700/3125, Loss: 2.9756085872650146, Uncertainty: 3.211320400238037
Epoch 141, Batch 1800/3125, Loss: 1.1014662981033325, Uncertainty: 1.44228994846344
Epoch 39, Batch 1800/3125, Loss: 2.7985332012176514, Uncertainty: 2.867305278778076
Epoch 141, Batch 1900/3125, Loss: 0.8826519846916199, Uncertainty: 1.1608628034591675
Epoch 39, Batch 1900/3125, Loss: 2.6872925758361816, Uncertainty: 2.785306453704834
Epoch 141, Batch 2000/3125, Loss: 1.0449566841125488, Uncertainty: 1.3559842109680176
Epoch 39, Batch 2000/3125, Loss: 3.3635077476501465, Uncertainty: 2.501643657684326
Epoch 141, Batch 2100/3125, Loss: 1.192246437072754, Uncertainty: 1.4037878513336182
Epoch 39, Batch 2100/3125, Loss: 3.1766111850738525, Uncertainty: 3.918262481689453
Epoch 141, Batch 2200/3125, Loss: 0.880990743637085, Uncertainty: 1.075049877166748
Epoch 39, Batch 2200/3125, Loss: 2.712015151977539, Uncertainty: 2.709397315979004
Epoch 141, Batch 2300/3125, Loss: 1.1254217624664307, Uncertainty: 1.3864175081253052
Epoch 39, Batch 2300/3125, Loss: 2.9945755004882812, Uncertainty: 3.1061899662017822
Epoch 141, Batch 2400/3125, Loss: 1.0969935655593872, Uncertainty: 1.2564241886138916
Epoch 39, Batch 2400/3125, Loss: 2.693986415863037, Uncertainty: 2.928107261657715
Epoch 141, Batch 2500/3125, Loss: 1.2379064559936523, Uncertainty: 1.887319803237915
Epoch 39, Batch 2500/3125, Loss: 2.710383415222168, Uncertainty: 2.3251631259918213
Epoch 141, Batch 2600/3125, Loss: 1.0595765113830566, Uncertainty: 1.3476794958114624
Epoch 141, Batch 2700/3125, Loss: 1.1669180393218994, Uncertainty: 1.4796292781829834
Epoch 39, Batch 2600/3125, Loss: 3.216799020767212, Uncertainty: 3.512932300567627
Epoch 141, Batch 2800/3125, Loss: 0.8815622925758362, Uncertainty: 1.178244709968567
Epoch 39, Batch 2700/3125, Loss: 3.7578186988830566, Uncertainty: 2.529934883117676
Epoch 141, Batch 2900/3125, Loss: 1.0360828638076782, Uncertainty: 1.3424564599990845
Epoch 39, Batch 2800/3125, Loss: 2.8024888038635254, Uncertainty: 2.534731388092041
Epoch 141, Batch 3000/3125, Loss: 1.1218557357788086, Uncertainty: 1.4003567695617676
Epoch 39, Batch 2900/3125, Loss: 2.723132610321045, Uncertainty: 2.683035373687744
Epoch 141, Batch 3100/3125, Loss: 1.0087261199951172, Uncertainty: 1.2845854759216309
Epoch 39, Batch 3000/3125, Loss: 2.6462910175323486, Uncertainty: 2.4319722652435303
Epoch 39, Batch 3100/3125, Loss: 3.04105281829834, Uncertainty: 3.4236371517181396

Training and Validation Results of Epoch 141:
================================
Training Loss: 0.8539079803466797, Training Uncertainty: 1.3591600849723815, time: 172.1920301914215
Validation Loss: 0.727980957464184, Validation Uncertainty: 1.9368630908334348, time: 39.90605044364929
Number of predictions within uncertainty interval: 131194/200000 (65.60%)

Epoch 142, Batch 100/3125, Loss: 1.0722095966339111, Uncertainty: 1.1189610958099365
Epoch 142, Batch 200/3125, Loss: 1.0470613241195679, Uncertainty: 1.3613252639770508

Training and Validation Results of Epoch 39:
================================
Training Loss: 2.6080670091247558, Training Uncertainty: 3.2387902951812744, time: 192.7574074268341
Validation Loss: 2.4390520573881886, Validation Uncertainty: 5.220819482413094, time: 44.09752631187439
Number of predictions within uncertainty interval: 112781/200000 (56.39%)

Epoch 142, Batch 300/3125, Loss: 1.1447702646255493, Uncertainty: 1.3868156671524048
Epoch 40, Batch 100/3125, Loss: 2.8804683685302734, Uncertainty: 2.5900230407714844
Epoch 142, Batch 400/3125, Loss: 0.9744181632995605, Uncertainty: 1.2046074867248535
Epoch 40, Batch 200/3125, Loss: 3.41180682182312, Uncertainty: 5.248985290527344
Epoch 142, Batch 500/3125, Loss: 1.025619387626648, Uncertainty: 1.3607932329177856
Epoch 40, Batch 300/3125, Loss: 2.967343330383301, Uncertainty: 2.770723342895508
Epoch 142, Batch 600/3125, Loss: 1.1850013732910156, Uncertainty: 1.280603289604187
Epoch 40, Batch 400/3125, Loss: 2.9179301261901855, Uncertainty: 2.862304925918579
Epoch 142, Batch 700/3125, Loss: 1.0607709884643555, Uncertainty: 1.158097505569458
Epoch 142, Batch 800/3125, Loss: 1.0740007162094116, Uncertainty: 1.2420259714126587
Epoch 40, Batch 500/3125, Loss: 3.353574752807617, Uncertainty: 4.359173774719238
Epoch 142, Batch 900/3125, Loss: 1.1752033233642578, Uncertainty: 1.557384967803955
Epoch 40, Batch 600/3125, Loss: 2.802386999130249, Uncertainty: 2.7347798347473145
Epoch 142, Batch 1000/3125, Loss: 0.9967892169952393, Uncertainty: 1.1202059984207153
Epoch 40, Batch 700/3125, Loss: 2.866088390350342, Uncertainty: 3.335236072540283
Epoch 142, Batch 1100/3125, Loss: 0.9604690074920654, Uncertainty: 1.2294559478759766
Epoch 40, Batch 800/3125, Loss: 2.957491397857666, Uncertainty: 3.229393482208252
Epoch 142, Batch 1200/3125, Loss: 1.1411380767822266, Uncertainty: 1.2908596992492676
Epoch 40, Batch 900/3125, Loss: 3.1957054138183594, Uncertainty: 2.641087293624878
Epoch 142, Batch 1300/3125, Loss: 1.0118539333343506, Uncertainty: 1.0951231718063354
Epoch 40, Batch 1000/3125, Loss: 2.790231466293335, Uncertainty: 2.9203927516937256
Epoch 142, Batch 1400/3125, Loss: 1.0312561988830566, Uncertainty: 1.277733325958252
Epoch 40, Batch 1100/3125, Loss: 2.9296298027038574, Uncertainty: 2.644700527191162
Epoch 142, Batch 1500/3125, Loss: 1.0975171327590942, Uncertainty: 1.2723026275634766
Epoch 40, Batch 1200/3125, Loss: 2.9806792736053467, Uncertainty: 2.676485300064087
Epoch 142, Batch 1600/3125, Loss: 0.8509474992752075, Uncertainty: 1.0880603790283203
Epoch 142, Batch 1700/3125, Loss: 1.0978379249572754, Uncertainty: 1.6989957094192505
Epoch 40, Batch 1300/3125, Loss: 2.6001696586608887, Uncertainty: 2.7126235961914062
Epoch 142, Batch 1800/3125, Loss: 1.1453211307525635, Uncertainty: 1.578511118888855
Epoch 40, Batch 1400/3125, Loss: 2.713322401046753, Uncertainty: 2.6694018840789795
Epoch 142, Batch 1900/3125, Loss: 0.9574060440063477, Uncertainty: 1.3683451414108276
Epoch 40, Batch 1500/3125, Loss: 2.870490074157715, Uncertainty: 2.2567646503448486
Epoch 142, Batch 2000/3125, Loss: 1.0750741958618164, Uncertainty: 1.44523286819458
Epoch 40, Batch 1600/3125, Loss: 2.7457075119018555, Uncertainty: 2.693556308746338
Epoch 142, Batch 2100/3125, Loss: 1.3061816692352295, Uncertainty: 1.6712652444839478
Epoch 40, Batch 1700/3125, Loss: 2.6281466484069824, Uncertainty: 2.8225350379943848
Epoch 142, Batch 2200/3125, Loss: 0.9118167757987976, Uncertainty: 1.045148491859436
Epoch 40, Batch 1800/3125, Loss: 3.282848358154297, Uncertainty: 3.654489040374756
Epoch 142, Batch 2300/3125, Loss: 1.0747016668319702, Uncertainty: 1.3470205068588257
Epoch 40, Batch 1900/3125, Loss: 2.6969377994537354, Uncertainty: 2.899867534637451
Epoch 142, Batch 2400/3125, Loss: 1.0826094150543213, Uncertainty: 1.2870826721191406
Epoch 142, Batch 2500/3125, Loss: 0.9354934692382812, Uncertainty: 1.2771530151367188
Epoch 40, Batch 2000/3125, Loss: 3.0714638233184814, Uncertainty: 2.941488027572632
Epoch 142, Batch 2600/3125, Loss: 1.0938398838043213, Uncertainty: 1.5021026134490967
Epoch 40, Batch 2100/3125, Loss: 3.5870258808135986, Uncertainty: 5.5109052658081055
Epoch 142, Batch 2700/3125, Loss: 1.486610770225525, Uncertainty: 2.176572799682617
Epoch 40, Batch 2200/3125, Loss: 2.559782028198242, Uncertainty: 2.612532615661621
Epoch 142, Batch 2800/3125, Loss: 0.8853229284286499, Uncertainty: 1.1808297634124756
Epoch 40, Batch 2300/3125, Loss: 2.768812656402588, Uncertainty: 2.9263226985931396
Epoch 142, Batch 2900/3125, Loss: 1.0488826036453247, Uncertainty: 1.420617699623108
Epoch 40, Batch 2400/3125, Loss: 3.088043212890625, Uncertainty: 2.7390546798706055
Epoch 142, Batch 3000/3125, Loss: 1.1742608547210693, Uncertainty: 1.5989806652069092
Epoch 40, Batch 2500/3125, Loss: 2.757779836654663, Uncertainty: 2.637860059738159
Epoch 142, Batch 3100/3125, Loss: 0.9554893374443054, Uncertainty: 1.144404411315918
Epoch 40, Batch 2600/3125, Loss: 2.8915486335754395, Uncertainty: 2.6476147174835205
Epoch 40, Batch 2700/3125, Loss: 3.9320993423461914, Uncertainty: 5.203228950500488
Epoch 40, Batch 2800/3125, Loss: 3.073472499847412, Uncertainty: 3.446958541870117
Epoch 40, Batch 2900/3125, Loss: 3.4254403114318848, Uncertainty: 3.2078893184661865
Epoch 40, Batch 3000/3125, Loss: 3.666433811187744, Uncertainty: 3.97398042678833
Epoch 40, Batch 3100/3125, Loss: 2.8367738723754883, Uncertainty: 2.867759943008423

Training and Validation Results of Epoch 142:
================================
Training Loss: 0.8548473390960694, Training Uncertainty: 1.3437198514175415, time: 171.81458640098572
Validation Loss: 0.7334447473363803, Validation Uncertainty: 1.9285504662472268, time: 39.81158256530762
Number of predictions within uncertainty interval: 130714/200000 (65.36%)

Epoch 143, Batch 100/3125, Loss: 0.962993323802948, Uncertainty: 1.1126487255096436
Epoch 143, Batch 200/3125, Loss: 1.0426836013793945, Uncertainty: 1.254016637802124
Epoch 143, Batch 300/3125, Loss: 1.1025075912475586, Uncertainty: 1.2604094743728638
Epoch 143, Batch 400/3125, Loss: 1.0037403106689453, Uncertainty: 1.189424991607666
Epoch 143, Batch 500/3125, Loss: 0.9797275066375732, Uncertainty: 1.263931155204773
Epoch 143, Batch 600/3125, Loss: 1.186661720275879, Uncertainty: 1.3472301959991455
Epoch 143, Batch 700/3125, Loss: 0.9864746332168579, Uncertainty: 1.1933510303497314

Training and Validation Results of Epoch 40:
================================
Training Loss: 2.5749167138671876, Training Uncertainty: 3.1863911290740967, time: 193.21531295776367
Validation Loss: 2.2966867342324515, Validation Uncertainty: 5.168136954612439, time: 44.01607823371887
Number of predictions within uncertainty interval: 124180/200000 (62.09%)

Epoch 143, Batch 800/3125, Loss: 1.0879313945770264, Uncertainty: 1.2870652675628662
Epoch 41, Batch 100/3125, Loss: 3.0985748767852783, Uncertainty: 2.5837342739105225
Epoch 143, Batch 900/3125, Loss: 1.1530593633651733, Uncertainty: 1.4995629787445068
Epoch 41, Batch 200/3125, Loss: 2.9218833446502686, Uncertainty: 3.255833625793457
Epoch 143, Batch 1000/3125, Loss: 1.0588377714157104, Uncertainty: 1.2055493593215942
Epoch 41, Batch 300/3125, Loss: 2.5705389976501465, Uncertainty: 2.4125990867614746
Epoch 143, Batch 1100/3125, Loss: 0.9889227151870728, Uncertainty: 1.2708380222320557
Epoch 41, Batch 400/3125, Loss: 2.6344146728515625, Uncertainty: 2.5236661434173584
Epoch 143, Batch 1200/3125, Loss: 1.109944462776184, Uncertainty: 1.3364644050598145
Epoch 41, Batch 500/3125, Loss: 2.9653704166412354, Uncertainty: 2.8719558715820312
Epoch 143, Batch 1300/3125, Loss: 0.9267377853393555, Uncertainty: 1.0653883218765259
Epoch 41, Batch 600/3125, Loss: 2.8183672428131104, Uncertainty: 3.2457375526428223
Epoch 143, Batch 1400/3125, Loss: 1.1415023803710938, Uncertainty: 1.2954541444778442
Epoch 143, Batch 1500/3125, Loss: 1.0788601636886597, Uncertainty: 1.2218410968780518
Epoch 41, Batch 700/3125, Loss: 2.9743502140045166, Uncertainty: 2.708933115005493
Epoch 143, Batch 1600/3125, Loss: 1.1616730690002441, Uncertainty: 1.5911211967468262
Epoch 41, Batch 800/3125, Loss: 2.9484102725982666, Uncertainty: 3.207139015197754
Epoch 143, Batch 1700/3125, Loss: 0.9443002939224243, Uncertainty: 1.2469429969787598
Epoch 41, Batch 900/3125, Loss: 2.984762668609619, Uncertainty: 3.6304221153259277
Epoch 143, Batch 1800/3125, Loss: 1.137712836265564, Uncertainty: 1.5213189125061035
Epoch 41, Batch 1000/3125, Loss: 3.2059450149536133, Uncertainty: 3.771244764328003
Epoch 143, Batch 1900/3125, Loss: 0.8407055139541626, Uncertainty: 1.1058728694915771
Epoch 41, Batch 1100/3125, Loss: 3.0941574573516846, Uncertainty: 2.7469027042388916
Epoch 143, Batch 2000/3125, Loss: 1.0355229377746582, Uncertainty: 1.3146095275878906
Epoch 41, Batch 1200/3125, Loss: 2.875065326690674, Uncertainty: 2.778747081756592
Epoch 143, Batch 2100/3125, Loss: 1.3688969612121582, Uncertainty: 1.7817206382751465
Epoch 41, Batch 1300/3125, Loss: 2.722276210784912, Uncertainty: 3.4669275283813477
Epoch 143, Batch 2200/3125, Loss: 0.9017149209976196, Uncertainty: 1.0599334239959717
Epoch 41, Batch 1400/3125, Loss: 3.0850419998168945, Uncertainty: 3.794229030609131
Epoch 143, Batch 2300/3125, Loss: 1.0752253532409668, Uncertainty: 1.3166567087173462
Epoch 41, Batch 1500/3125, Loss: 2.6792922019958496, Uncertainty: 2.65541410446167
Epoch 143, Batch 2400/3125, Loss: 1.147791862487793, Uncertainty: 1.520829439163208
Epoch 143, Batch 2500/3125, Loss: 1.3573555946350098, Uncertainty: 2.2368433475494385
Epoch 41, Batch 1600/3125, Loss: 2.7430930137634277, Uncertainty: 2.7860794067382812
Epoch 143, Batch 2600/3125, Loss: 1.2862639427185059, Uncertainty: 1.9828683137893677
Epoch 41, Batch 1700/3125, Loss: 2.760058879852295, Uncertainty: 3.480121612548828
Epoch 143, Batch 2700/3125, Loss: 1.2833772897720337, Uncertainty: 1.536118745803833
Epoch 41, Batch 1800/3125, Loss: 2.6430962085723877, Uncertainty: 2.5662243366241455
Epoch 143, Batch 2800/3125, Loss: 0.8681035041809082, Uncertainty: 1.1227107048034668
Epoch 41, Batch 1900/3125, Loss: 2.7055182456970215, Uncertainty: 2.6800107955932617
Epoch 143, Batch 2900/3125, Loss: 1.020749568939209, Uncertainty: 1.2893606424331665
Epoch 41, Batch 2000/3125, Loss: 3.129979372024536, Uncertainty: 4.113466262817383
Epoch 143, Batch 3000/3125, Loss: 1.226555347442627, Uncertainty: 1.3037128448486328
Epoch 41, Batch 2100/3125, Loss: 3.4492104053497314, Uncertainty: 3.68281888961792
Epoch 143, Batch 3100/3125, Loss: 0.97272789478302, Uncertainty: 1.178612470626831
Epoch 41, Batch 2200/3125, Loss: 2.4940173625946045, Uncertainty: 2.8743128776550293
Epoch 41, Batch 2300/3125, Loss: 3.4372706413269043, Uncertainty: 4.633283615112305
Epoch 41, Batch 2400/3125, Loss: 2.8332605361938477, Uncertainty: 3.1838953495025635
Epoch 41, Batch 2500/3125, Loss: 2.9575588703155518, Uncertainty: 3.8268113136291504
Epoch 41, Batch 2600/3125, Loss: 3.0252633094787598, Uncertainty: 2.767672061920166
Epoch 41, Batch 2700/3125, Loss: 3.3637232780456543, Uncertainty: 2.521463394165039

Training and Validation Results of Epoch 143:
================================
Training Loss: 0.8530560431480407, Training Uncertainty: 1.3449455847740173, time: 171.78160643577576
Validation Loss: 0.7331745943145069, Validation Uncertainty: 1.8683318401236668, time: 39.492013931274414
Number of predictions within uncertainty interval: 127799/200000 (63.90%)

Epoch 41, Batch 2800/3125, Loss: 2.8218424320220947, Uncertainty: 3.253833293914795
Epoch 144, Batch 100/3125, Loss: 0.949326753616333, Uncertainty: 1.0642694234848022
Epoch 41, Batch 2900/3125, Loss: 2.809337615966797, Uncertainty: 2.879164457321167
Epoch 144, Batch 200/3125, Loss: 1.1091210842132568, Uncertainty: 1.5782939195632935
Epoch 41, Batch 3000/3125, Loss: 2.82783842086792, Uncertainty: 2.4565834999084473
Epoch 144, Batch 300/3125, Loss: 1.1512868404388428, Uncertainty: 1.5361413955688477
Epoch 41, Batch 3100/3125, Loss: 2.9934239387512207, Uncertainty: 2.937634229660034
Epoch 144, Batch 400/3125, Loss: 0.9685066938400269, Uncertainty: 1.1576745510101318
Epoch 144, Batch 500/3125, Loss: 1.0092145204544067, Uncertainty: 1.3367245197296143
Epoch 144, Batch 600/3125, Loss: 1.1507408618927002, Uncertainty: 1.2642943859100342
Epoch 144, Batch 700/3125, Loss: 0.9763171672821045, Uncertainty: 1.1922931671142578
Epoch 144, Batch 800/3125, Loss: 1.0750861167907715, Uncertainty: 1.3197534084320068
Epoch 144, Batch 900/3125, Loss: 1.167328119277954, Uncertainty: 1.3789753913879395
Epoch 144, Batch 1000/3125, Loss: 0.967124879360199, Uncertainty: 1.1683671474456787
Epoch 144, Batch 1100/3125, Loss: 1.0690274238586426, Uncertainty: 1.5451853275299072
Epoch 144, Batch 1200/3125, Loss: 1.1973352432250977, Uncertainty: 1.3878188133239746

Training and Validation Results of Epoch 41:
================================
Training Loss: 2.5518948666381838, Training Uncertainty: 3.1445851317596434, time: 192.24822402000427
Validation Loss: 2.2211802838098667, Validation Uncertainty: 6.471970086207476, time: 46.971609592437744
Number of predictions within uncertainty interval: 143610/200000 (71.81%)

Epoch 144, Batch 1300/3125, Loss: 1.0799899101257324, Uncertainty: 1.565691590309143
Epoch 42, Batch 100/3125, Loss: 2.7325921058654785, Uncertainty: 2.538364887237549
Epoch 144, Batch 1400/3125, Loss: 1.1909379959106445, Uncertainty: 1.7151426076889038
Epoch 42, Batch 200/3125, Loss: 3.2303757667541504, Uncertainty: 3.704207420349121
Epoch 144, Batch 1500/3125, Loss: 1.1253063678741455, Uncertainty: 1.2828786373138428
Epoch 42, Batch 300/3125, Loss: 2.6716363430023193, Uncertainty: 2.6711909770965576
Epoch 144, Batch 1600/3125, Loss: 0.9162188768386841, Uncertainty: 1.2258427143096924
Epoch 42, Batch 400/3125, Loss: 2.490034818649292, Uncertainty: 2.4777677059173584
Epoch 144, Batch 1700/3125, Loss: 1.0153322219848633, Uncertainty: 1.4287031888961792
Epoch 144, Batch 1800/3125, Loss: 1.1899094581604004, Uncertainty: 1.7752985954284668
Epoch 42, Batch 500/3125, Loss: 3.1848981380462646, Uncertainty: 3.0408995151519775
Epoch 144, Batch 1900/3125, Loss: 0.9394644498825073, Uncertainty: 1.3922299146652222
Epoch 42, Batch 600/3125, Loss: 2.946530818939209, Uncertainty: 3.3012044429779053
Epoch 144, Batch 2000/3125, Loss: 0.9883702993392944, Uncertainty: 1.221686601638794
Epoch 42, Batch 700/3125, Loss: 2.934239149093628, Uncertainty: 2.716597080230713
Epoch 144, Batch 2100/3125, Loss: 1.1708956956863403, Uncertainty: 1.4051542282104492
Epoch 42, Batch 800/3125, Loss: 3.5571203231811523, Uncertainty: 2.857938766479492
Epoch 144, Batch 2200/3125, Loss: 0.9556897878646851, Uncertainty: 1.079655408859253
Epoch 42, Batch 900/3125, Loss: 2.860182285308838, Uncertainty: 2.8916568756103516
Epoch 144, Batch 2300/3125, Loss: 1.090374231338501, Uncertainty: 1.4166665077209473
Epoch 42, Batch 1000/3125, Loss: 3.2027902603149414, Uncertainty: 3.9091153144836426
Epoch 144, Batch 2400/3125, Loss: 1.2651447057724, Uncertainty: 1.5473216772079468
Epoch 42, Batch 1100/3125, Loss: 2.9233341217041016, Uncertainty: 2.7157204151153564
Epoch 144, Batch 2500/3125, Loss: 0.9806252121925354, Uncertainty: 1.4170341491699219
Epoch 42, Batch 1200/3125, Loss: 2.609649181365967, Uncertainty: 2.478827714920044
Epoch 144, Batch 2600/3125, Loss: 1.1638950109481812, Uncertainty: 1.702359676361084
Epoch 144, Batch 2700/3125, Loss: 1.1309351921081543, Uncertainty: 1.446271538734436
Epoch 42, Batch 1300/3125, Loss: 2.6579737663269043, Uncertainty: 2.8874659538269043
Epoch 144, Batch 2800/3125, Loss: 0.8694366812705994, Uncertainty: 1.1286935806274414
Epoch 42, Batch 1400/3125, Loss: 2.9411673545837402, Uncertainty: 3.246828079223633
Epoch 144, Batch 2900/3125, Loss: 1.0153709650039673, Uncertainty: 1.2951509952545166
Epoch 42, Batch 1500/3125, Loss: 2.6026523113250732, Uncertainty: 2.6448793411254883
Epoch 144, Batch 3000/3125, Loss: 1.1265859603881836, Uncertainty: 1.3218722343444824
Epoch 42, Batch 1600/3125, Loss: 2.9483487606048584, Uncertainty: 2.4800069332122803
Epoch 144, Batch 3100/3125, Loss: 0.9584259390830994, Uncertainty: 1.1415200233459473
Epoch 42, Batch 1700/3125, Loss: 2.8042593002319336, Uncertainty: 2.7995567321777344
Epoch 42, Batch 1800/3125, Loss: 2.509890556335449, Uncertainty: 2.62040376663208
Epoch 42, Batch 1900/3125, Loss: 2.428396701812744, Uncertainty: 2.3485167026519775
Epoch 42, Batch 2000/3125, Loss: 2.923407554626465, Uncertainty: 2.5417022705078125
Epoch 42, Batch 2100/3125, Loss: 3.337482452392578, Uncertainty: 3.544355869293213
Epoch 42, Batch 2200/3125, Loss: 2.5878448486328125, Uncertainty: 2.208002805709839
Epoch 42, Batch 2300/3125, Loss: 2.831559658050537, Uncertainty: 3.608743667602539

Training and Validation Results of Epoch 144:
================================
Training Loss: 0.8465000724601746, Training Uncertainty: 1.339239632320404, time: 171.6993477344513
Validation Loss: 0.7216428095269996, Validation Uncertainty: 1.8854429014503498, time: 39.778942346572876
Number of predictions within uncertainty interval: 129885/200000 (64.94%)

Epoch 145, Batch 100/3125, Loss: 1.0535004138946533, Uncertainty: 1.05047607421875
Epoch 42, Batch 2400/3125, Loss: 3.001157283782959, Uncertainty: 2.9129626750946045
Epoch 145, Batch 200/3125, Loss: 1.0788670778274536, Uncertainty: 1.467679738998413
Epoch 42, Batch 2500/3125, Loss: 2.740886926651001, Uncertainty: 2.4641225337982178
Epoch 145, Batch 300/3125, Loss: 1.1575709581375122, Uncertainty: 1.4694972038269043
Epoch 42, Batch 2600/3125, Loss: 3.0397417545318604, Uncertainty: 2.8224992752075195
Epoch 145, Batch 400/3125, Loss: 0.9835318922996521, Uncertainty: 1.23714280128479
Epoch 42, Batch 2700/3125, Loss: 3.0651471614837646, Uncertainty: 3.7957944869995117
Epoch 145, Batch 500/3125, Loss: 1.0328468084335327, Uncertainty: 1.2478291988372803
Epoch 42, Batch 2800/3125, Loss: 2.7981081008911133, Uncertainty: 2.481027603149414
Epoch 145, Batch 600/3125, Loss: 1.204451084136963, Uncertainty: 1.4338675737380981
Epoch 42, Batch 2900/3125, Loss: 2.5528411865234375, Uncertainty: 2.694214344024658
Epoch 145, Batch 700/3125, Loss: 1.0404280424118042, Uncertainty: 1.238476037979126
Epoch 42, Batch 3000/3125, Loss: 3.1012611389160156, Uncertainty: 2.9241814613342285
Epoch 145, Batch 800/3125, Loss: 1.0504781007766724, Uncertainty: 1.228671908378601
Epoch 145, Batch 900/3125, Loss: 1.340132236480713, Uncertainty: 1.996119737625122
Epoch 42, Batch 3100/3125, Loss: 2.886340618133545, Uncertainty: 3.254753589630127
Epoch 145, Batch 1000/3125, Loss: 1.0581870079040527, Uncertainty: 1.4639604091644287
Epoch 145, Batch 1100/3125, Loss: 0.938864529132843, Uncertainty: 1.1843669414520264
Epoch 145, Batch 1200/3125, Loss: 1.1087982654571533, Uncertainty: 1.3372637033462524
Epoch 145, Batch 1300/3125, Loss: 0.9192094802856445, Uncertainty: 1.0639805793762207
Epoch 145, Batch 1400/3125, Loss: 1.0815117359161377, Uncertainty: 1.5459266901016235
Epoch 145, Batch 1500/3125, Loss: 1.118538498878479, Uncertainty: 1.3116525411605835
Epoch 145, Batch 1600/3125, Loss: 0.8505902290344238, Uncertainty: 1.0655204057693481
Epoch 145, Batch 1700/3125, Loss: 0.9894406795501709, Uncertainty: 1.3530575037002563

Training and Validation Results of Epoch 42:
================================
Training Loss: 2.5029197399902343, Training Uncertainty: 3.1042166373062132, time: 195.24487590789795
Validation Loss: 2.2643580959581047, Validation Uncertainty: 3.8223661909932676, time: 43.80585241317749
Number of predictions within uncertainty interval: 92207/200000 (46.10%)

Epoch 145, Batch 1800/3125, Loss: 1.1743898391723633, Uncertainty: 1.7153294086456299
Epoch 43, Batch 100/3125, Loss: 3.28867244720459, Uncertainty: 3.046577215194702
Epoch 145, Batch 1900/3125, Loss: 0.9204310178756714, Uncertainty: 1.3235344886779785
Epoch 43, Batch 200/3125, Loss: 2.5815839767456055, Uncertainty: 2.8060290813446045
Epoch 145, Batch 2000/3125, Loss: 1.1166815757751465, Uncertainty: 1.5655467510223389
Epoch 43, Batch 300/3125, Loss: 2.638118267059326, Uncertainty: 2.2871851921081543
Epoch 145, Batch 2100/3125, Loss: 1.1672654151916504, Uncertainty: 1.3411591053009033
Epoch 43, Batch 400/3125, Loss: 2.7617621421813965, Uncertainty: 2.2710297107696533
Epoch 145, Batch 2200/3125, Loss: 0.9593902826309204, Uncertainty: 1.1911075115203857
Epoch 43, Batch 500/3125, Loss: 2.656639575958252, Uncertainty: 2.715488910675049
Epoch 145, Batch 2300/3125, Loss: 1.0672869682312012, Uncertainty: 1.2974836826324463
Epoch 43, Batch 600/3125, Loss: 3.6165659427642822, Uncertainty: 4.494245529174805
Epoch 145, Batch 2400/3125, Loss: 1.0639421939849854, Uncertainty: 1.2357592582702637
Epoch 145, Batch 2500/3125, Loss: 1.0296435356140137, Uncertainty: 1.4805577993392944
Epoch 43, Batch 700/3125, Loss: 2.850017547607422, Uncertainty: 3.2693657875061035
Epoch 145, Batch 2600/3125, Loss: 1.1461076736450195, Uncertainty: 1.6959664821624756
Epoch 43, Batch 800/3125, Loss: 3.2403783798217773, Uncertainty: 2.8413100242614746
Epoch 145, Batch 2700/3125, Loss: 1.2192208766937256, Uncertainty: 1.581725835800171
Epoch 43, Batch 900/3125, Loss: 3.435011386871338, Uncertainty: 2.5402536392211914
Epoch 145, Batch 2800/3125, Loss: 0.8648130893707275, Uncertainty: 1.1260031461715698
Epoch 43, Batch 1000/3125, Loss: 3.3272900581359863, Uncertainty: 4.7608795166015625
Epoch 145, Batch 2900/3125, Loss: 1.1018353700637817, Uncertainty: 1.5792365074157715
Epoch 43, Batch 1100/3125, Loss: 2.7920680046081543, Uncertainty: 2.8399972915649414
Epoch 145, Batch 3000/3125, Loss: 1.095859408378601, Uncertainty: 1.3570849895477295
Epoch 43, Batch 1200/3125, Loss: 2.656900405883789, Uncertainty: 2.6264331340789795
Epoch 145, Batch 3100/3125, Loss: 0.9511905908584595, Uncertainty: 1.1307727098464966
Epoch 43, Batch 1300/3125, Loss: 2.8717336654663086, Uncertainty: 3.4329466819763184
Epoch 43, Batch 1400/3125, Loss: 2.665226459503174, Uncertainty: 2.7957916259765625
Epoch 43, Batch 1500/3125, Loss: 2.397488594055176, Uncertainty: 2.2974586486816406
Epoch 43, Batch 1600/3125, Loss: 2.6896705627441406, Uncertainty: 3.2771401405334473
Epoch 43, Batch 1700/3125, Loss: 2.496656894683838, Uncertainty: 2.661782741546631
Epoch 43, Batch 1800/3125, Loss: 2.8563833236694336, Uncertainty: 2.9430131912231445

Training and Validation Results of Epoch 145:
================================
Training Loss: 0.8459524476051331, Training Uncertainty: 1.3405018195724487, time: 171.6572597026825
Validation Loss: 0.7220160759928281, Validation Uncertainty: 1.9020870725821961, time: 39.67204523086548
Number of predictions within uncertainty interval: 130396/200000 (65.20%)

Epoch 43, Batch 1900/3125, Loss: 3.0262441635131836, Uncertainty: 2.4825901985168457
Epoch 146, Batch 100/3125, Loss: 1.0229253768920898, Uncertainty: 1.0923389196395874
Epoch 43, Batch 2000/3125, Loss: 3.0033352375030518, Uncertainty: 3.346508264541626
Epoch 146, Batch 200/3125, Loss: 1.0858503580093384, Uncertainty: 1.4906775951385498
Epoch 146, Batch 300/3125, Loss: 1.1266402006149292, Uncertainty: 1.3857085704803467
Epoch 43, Batch 2100/3125, Loss: 2.9763569831848145, Uncertainty: 3.832045555114746
Epoch 146, Batch 400/3125, Loss: 1.0324348211288452, Uncertainty: 1.1390588283538818
Epoch 43, Batch 2200/3125, Loss: 2.4805541038513184, Uncertainty: 2.6631362438201904
Epoch 146, Batch 500/3125, Loss: 1.0130715370178223, Uncertainty: 1.3628162145614624
Epoch 43, Batch 2300/3125, Loss: 2.6662793159484863, Uncertainty: 2.686584949493408
Epoch 146, Batch 600/3125, Loss: 1.1710569858551025, Uncertainty: 1.3268928527832031
Epoch 43, Batch 2400/3125, Loss: 2.549316883087158, Uncertainty: 2.7244367599487305
Epoch 146, Batch 700/3125, Loss: 1.008096694946289, Uncertainty: 1.1853249073028564
Epoch 43, Batch 2500/3125, Loss: 3.344862699508667, Uncertainty: 5.403971195220947
Epoch 146, Batch 800/3125, Loss: 1.299344778060913, Uncertainty: 1.9791417121887207
Epoch 43, Batch 2600/3125, Loss: 3.419797420501709, Uncertainty: 3.9121031761169434
Epoch 146, Batch 900/3125, Loss: 1.2691898345947266, Uncertainty: 1.6252834796905518
Epoch 43, Batch 2700/3125, Loss: 3.312321186065674, Uncertainty: 2.8632149696350098
Epoch 146, Batch 1000/3125, Loss: 0.9575818181037903, Uncertainty: 1.160463809967041
Epoch 43, Batch 2800/3125, Loss: 2.555997371673584, Uncertainty: 2.705562114715576
Epoch 146, Batch 1100/3125, Loss: 0.9985223412513733, Uncertainty: 1.3240084648132324
Epoch 43, Batch 2900/3125, Loss: 2.7364320755004883, Uncertainty: 3.250281810760498
Epoch 146, Batch 1200/3125, Loss: 1.060394525527954, Uncertainty: 1.3056560754776
Epoch 146, Batch 1300/3125, Loss: 0.9252166748046875, Uncertainty: 1.0645818710327148
Epoch 43, Batch 3000/3125, Loss: 3.478489398956299, Uncertainty: 2.198693037033081
Epoch 146, Batch 1400/3125, Loss: 1.015528917312622, Uncertainty: 1.3404902219772339
Epoch 43, Batch 3100/3125, Loss: 3.060486316680908, Uncertainty: 3.915078639984131
Epoch 146, Batch 1500/3125, Loss: 1.1004116535186768, Uncertainty: 1.2344810962677002
Epoch 146, Batch 1600/3125, Loss: 0.8796567916870117, Uncertainty: 1.131051778793335
Epoch 146, Batch 1700/3125, Loss: 1.2495845556259155, Uncertainty: 2.052724838256836
Epoch 146, Batch 1800/3125, Loss: 1.104954719543457, Uncertainty: 1.3917042016983032
Epoch 146, Batch 1900/3125, Loss: 0.8434542417526245, Uncertainty: 1.1805106401443481
Epoch 146, Batch 2000/3125, Loss: 1.0267305374145508, Uncertainty: 1.3458805084228516
Epoch 146, Batch 2100/3125, Loss: 1.3222532272338867, Uncertainty: 1.9101183414459229
Epoch 146, Batch 2200/3125, Loss: 0.9442261457443237, Uncertainty: 1.1243938207626343

Training and Validation Results of Epoch 43:
================================
Training Loss: 2.4590413372802735, Training Uncertainty: 3.095261265411377, time: 195.7255048751831
Validation Loss: 2.1937756049053747, Validation Uncertainty: 3.9950671744773456, time: 44.65543174743652
Number of predictions within uncertainty interval: 100123/200000 (50.06%)

Epoch 146, Batch 2300/3125, Loss: 1.1594264507293701, Uncertainty: 1.5936346054077148
Epoch 44, Batch 100/3125, Loss: 2.944145679473877, Uncertainty: 2.6896920204162598
Epoch 146, Batch 2400/3125, Loss: 1.1847527027130127, Uncertainty: 1.743085503578186
Epoch 44, Batch 200/3125, Loss: 3.6362733840942383, Uncertainty: 6.095164775848389
Epoch 146, Batch 2500/3125, Loss: 1.0530407428741455, Uncertainty: 1.5369889736175537
Epoch 44, Batch 300/3125, Loss: 2.4184494018554688, Uncertainty: 2.0750694274902344
Epoch 146, Batch 2600/3125, Loss: 1.1550369262695312, Uncertainty: 1.7408685684204102
Epoch 44, Batch 400/3125, Loss: 3.259031057357788, Uncertainty: 2.5572214126586914
Epoch 146, Batch 2700/3125, Loss: 1.1437090635299683, Uncertainty: 1.471239447593689
Epoch 146, Batch 2800/3125, Loss: 0.8782289028167725, Uncertainty: 1.1218204498291016
Epoch 44, Batch 500/3125, Loss: 3.2617950439453125, Uncertainty: 2.8016083240509033
Epoch 146, Batch 2900/3125, Loss: 1.0576872825622559, Uncertainty: 1.4424362182617188
Epoch 44, Batch 600/3125, Loss: 3.305023431777954, Uncertainty: 2.808093547821045
Epoch 146, Batch 3000/3125, Loss: 1.1735029220581055, Uncertainty: 1.3195619583129883
Epoch 44, Batch 700/3125, Loss: 2.555738925933838, Uncertainty: 2.296536445617676
Epoch 146, Batch 3100/3125, Loss: 1.0042016506195068, Uncertainty: 1.188063144683838
Epoch 44, Batch 800/3125, Loss: 2.8092384338378906, Uncertainty: 2.65411114692688
Epoch 44, Batch 900/3125, Loss: 3.1747889518737793, Uncertainty: 2.602126359939575
Epoch 44, Batch 1000/3125, Loss: 2.819983720779419, Uncertainty: 2.8641579151153564
Epoch 44, Batch 1100/3125, Loss: 3.048631191253662, Uncertainty: 2.769505262374878
Epoch 44, Batch 1200/3125, Loss: 4.28486442565918, Uncertainty: 5.389822006225586
Epoch 44, Batch 1300/3125, Loss: 2.705458641052246, Uncertainty: 3.442835569381714
Epoch 44, Batch 1400/3125, Loss: 2.856889247894287, Uncertainty: 2.5538439750671387

Training and Validation Results of Epoch 146:
================================
Training Loss: 0.8447320310401917, Training Uncertainty: 1.3403639465713502, time: 172.4845244884491
Validation Loss: 0.7963642420061409, Validation Uncertainty: 1.827678933625331, time: 39.71236872673035
Number of predictions within uncertainty interval: 118871/200000 (59.44%)

Epoch 44, Batch 1500/3125, Loss: 2.6957011222839355, Uncertainty: 3.32246732711792
Epoch 147, Batch 100/3125, Loss: 1.0661600828170776, Uncertainty: 1.050874948501587
Epoch 44, Batch 1600/3125, Loss: 2.51682186126709, Uncertainty: 2.688082218170166
Epoch 147, Batch 200/3125, Loss: 1.08846116065979, Uncertainty: 1.5348851680755615
Epoch 147, Batch 300/3125, Loss: 1.2098636627197266, Uncertainty: 1.650327205657959
Epoch 44, Batch 1700/3125, Loss: 2.5586905479431152, Uncertainty: 2.6552813053131104
Epoch 147, Batch 400/3125, Loss: 1.2860345840454102, Uncertainty: 1.7283120155334473
Epoch 44, Batch 1800/3125, Loss: 3.080204486846924, Uncertainty: 4.021762371063232
Epoch 147, Batch 500/3125, Loss: 1.0015259981155396, Uncertainty: 1.3098640441894531
Epoch 44, Batch 1900/3125, Loss: 2.4742345809936523, Uncertainty: 2.38096284866333
Epoch 147, Batch 600/3125, Loss: 1.1707324981689453, Uncertainty: 1.319901943206787
Epoch 44, Batch 2000/3125, Loss: 3.2776942253112793, Uncertainty: 2.4668140411376953
Epoch 147, Batch 700/3125, Loss: 1.006079912185669, Uncertainty: 1.1491793394088745
Epoch 44, Batch 2100/3125, Loss: 2.9216561317443848, Uncertainty: 3.3961105346679688
Epoch 147, Batch 800/3125, Loss: 1.0683863162994385, Uncertainty: 1.3570244312286377
Epoch 44, Batch 2200/3125, Loss: 3.14219331741333, Uncertainty: 2.4081921577453613
Epoch 147, Batch 900/3125, Loss: 1.1321988105773926, Uncertainty: 1.2987675666809082
Epoch 44, Batch 2300/3125, Loss: 2.5162410736083984, Uncertainty: 2.855945110321045
Epoch 147, Batch 1000/3125, Loss: 0.9867184162139893, Uncertainty: 1.2556917667388916
Epoch 44, Batch 2400/3125, Loss: 3.173841714859009, Uncertainty: 4.732484817504883
Epoch 147, Batch 1100/3125, Loss: 1.0414159297943115, Uncertainty: 1.3635834455490112
Epoch 147, Batch 1200/3125, Loss: 1.1378129720687866, Uncertainty: 1.3405296802520752
Epoch 44, Batch 2500/3125, Loss: 3.1922245025634766, Uncertainty: 2.6218619346618652
Epoch 147, Batch 1300/3125, Loss: 0.9192715287208557, Uncertainty: 1.05929696559906
Epoch 44, Batch 2600/3125, Loss: 2.887927532196045, Uncertainty: 3.0904531478881836
Epoch 147, Batch 1400/3125, Loss: 1.063495397567749, Uncertainty: 1.2517049312591553
Epoch 44, Batch 2700/3125, Loss: 2.7857186794281006, Uncertainty: 2.965466022491455
Epoch 147, Batch 1500/3125, Loss: 1.1121010780334473, Uncertainty: 1.3304132223129272
Epoch 44, Batch 2800/3125, Loss: 2.811337947845459, Uncertainty: 3.0400376319885254
Epoch 147, Batch 1600/3125, Loss: 0.9181559681892395, Uncertainty: 1.2338857650756836
Epoch 44, Batch 2900/3125, Loss: 2.538600444793701, Uncertainty: 2.4805800914764404
Epoch 147, Batch 1700/3125, Loss: 1.0110108852386475, Uncertainty: 1.4406189918518066
Epoch 44, Batch 3000/3125, Loss: 2.9994630813598633, Uncertainty: 2.2484915256500244
Epoch 147, Batch 1800/3125, Loss: 1.1464653015136719, Uncertainty: 1.653900384902954
Epoch 44, Batch 3100/3125, Loss: 2.5416932106018066, Uncertainty: 2.547290325164795
Epoch 147, Batch 1900/3125, Loss: 0.8982957601547241, Uncertainty: 1.2529363632202148
Epoch 147, Batch 2000/3125, Loss: 0.9941082000732422, Uncertainty: 1.2506481409072876
Epoch 147, Batch 2100/3125, Loss: 1.382583498954773, Uncertainty: 1.7779182195663452
Epoch 147, Batch 2200/3125, Loss: 0.9716396331787109, Uncertainty: 1.00596022605896
Epoch 147, Batch 2300/3125, Loss: 1.055116057395935, Uncertainty: 1.340552568435669
Epoch 147, Batch 2400/3125, Loss: 1.1069306135177612, Uncertainty: 1.3317410945892334
Epoch 147, Batch 2500/3125, Loss: 1.3398833274841309, Uncertainty: 2.2285304069519043
Epoch 147, Batch 2600/3125, Loss: 1.1154974699020386, Uncertainty: 1.6026848554611206

Training and Validation Results of Epoch 44:
================================
Training Loss: 2.4423635263061523, Training Uncertainty: 3.1034829161453246, time: 192.51288509368896
Validation Loss: 2.1625546596544174, Validation Uncertainty: 4.948151686612298, time: 43.27121043205261
Number of predictions within uncertainty interval: 116201/200000 (58.10%)

Epoch 147, Batch 2700/3125, Loss: 1.3031270503997803, Uncertainty: 1.760263442993164
Epoch 45, Batch 100/3125, Loss: 2.712326765060425, Uncertainty: 2.4282329082489014
Epoch 147, Batch 2800/3125, Loss: 0.871467113494873, Uncertainty: 1.163724660873413
Epoch 147, Batch 2900/3125, Loss: 1.0483171939849854, Uncertainty: 1.4174654483795166
Epoch 45, Batch 200/3125, Loss: 2.6807327270507812, Uncertainty: 3.1978607177734375
Epoch 147, Batch 3000/3125, Loss: 1.0786899328231812, Uncertainty: 1.3592644929885864
Epoch 45, Batch 300/3125, Loss: 2.692328929901123, Uncertainty: 2.392179250717163
Epoch 147, Batch 3100/3125, Loss: 0.9428805112838745, Uncertainty: 1.1632015705108643
Epoch 45, Batch 400/3125, Loss: 3.143939971923828, Uncertainty: 3.7608039379119873
Epoch 45, Batch 500/3125, Loss: 3.209890842437744, Uncertainty: 2.9752817153930664
Epoch 45, Batch 600/3125, Loss: 3.1215672492980957, Uncertainty: 4.304312229156494
Epoch 45, Batch 700/3125, Loss: 2.8847854137420654, Uncertainty: 2.064889907836914
Epoch 45, Batch 800/3125, Loss: 3.030041217803955, Uncertainty: 3.2090916633605957
Epoch 45, Batch 900/3125, Loss: 2.8713927268981934, Uncertainty: 3.2693703174591064
Epoch 45, Batch 1000/3125, Loss: 3.008700370788574, Uncertainty: 3.833095073699951

Training and Validation Results of Epoch 147:
================================
Training Loss: 0.8428757859802246, Training Uncertainty: 1.3302625117492677, time: 171.68610453605652
Validation Loss: 0.7200826775387424, Validation Uncertainty: 1.8856416757759231, time: 39.80082440376282
Number of predictions within uncertainty interval: 129876/200000 (64.94%)

Epoch 45, Batch 1100/3125, Loss: 2.74009370803833, Uncertainty: 2.6913704872131348
Epoch 148, Batch 100/3125, Loss: 0.8747382760047913, Uncertainty: 1.0153124332427979
Epoch 45, Batch 1200/3125, Loss: 3.212280750274658, Uncertainty: 4.40974235534668
Epoch 148, Batch 200/3125, Loss: 1.1174616813659668, Uncertainty: 1.6112616062164307
Epoch 45, Batch 1300/3125, Loss: 2.84224796295166, Uncertainty: 2.938666820526123
Epoch 148, Batch 300/3125, Loss: 1.1313679218292236, Uncertainty: 1.4454594850540161
Epoch 45, Batch 1400/3125, Loss: 2.8344831466674805, Uncertainty: 2.7323389053344727
Epoch 148, Batch 400/3125, Loss: 1.0568705797195435, Uncertainty: 1.1134952306747437
Epoch 45, Batch 1500/3125, Loss: 2.647965908050537, Uncertainty: 2.7255403995513916
Epoch 148, Batch 500/3125, Loss: 1.0952093601226807, Uncertainty: 1.1971571445465088
Epoch 45, Batch 1600/3125, Loss: 2.3429112434387207, Uncertainty: 2.4032068252563477
Epoch 148, Batch 600/3125, Loss: 1.3419063091278076, Uncertainty: 1.8465030193328857
Epoch 148, Batch 700/3125, Loss: 0.9796360731124878, Uncertainty: 1.1591663360595703
Epoch 45, Batch 1700/3125, Loss: 2.3774986267089844, Uncertainty: 2.4482421875
Epoch 148, Batch 800/3125, Loss: 1.0539743900299072, Uncertainty: 1.26676607131958
Epoch 45, Batch 1800/3125, Loss: 3.0306143760681152, Uncertainty: 3.171029567718506
Epoch 148, Batch 900/3125, Loss: 1.1534525156021118, Uncertainty: 1.4947407245635986
Epoch 45, Batch 1900/3125, Loss: 2.5382628440856934, Uncertainty: 2.296950340270996
Epoch 148, Batch 1000/3125, Loss: 0.9400768280029297, Uncertainty: 1.084993600845337
Epoch 45, Batch 2000/3125, Loss: 2.8768744468688965, Uncertainty: 3.761575222015381
Epoch 148, Batch 1100/3125, Loss: 1.0613548755645752, Uncertainty: 1.3793902397155762
Epoch 45, Batch 2100/3125, Loss: 3.0178003311157227, Uncertainty: 3.1894140243530273
Epoch 148, Batch 1200/3125, Loss: 1.1481661796569824, Uncertainty: 1.2917978763580322
Epoch 45, Batch 2200/3125, Loss: 2.725895404815674, Uncertainty: 3.488184928894043
Epoch 148, Batch 1300/3125, Loss: 0.9522784948348999, Uncertainty: 1.1524975299835205
Epoch 45, Batch 2300/3125, Loss: 3.2048096656799316, Uncertainty: 4.574557304382324
Epoch 148, Batch 1400/3125, Loss: 1.0258187055587769, Uncertainty: 1.2892389297485352
Epoch 148, Batch 1500/3125, Loss: 1.121995449066162, Uncertainty: 1.2241427898406982
Epoch 45, Batch 2400/3125, Loss: 2.7213635444641113, Uncertainty: 2.620328426361084
Epoch 148, Batch 1600/3125, Loss: 0.8508955240249634, Uncertainty: 1.0669209957122803
Epoch 45, Batch 2500/3125, Loss: 2.417978048324585, Uncertainty: 2.3840994834899902
Epoch 148, Batch 1700/3125, Loss: 1.0419633388519287, Uncertainty: 1.5230114459991455
Epoch 45, Batch 2600/3125, Loss: 2.7525596618652344, Uncertainty: 2.747096061706543
Epoch 148, Batch 1800/3125, Loss: 1.0951951742172241, Uncertainty: 1.4691193103790283
Epoch 45, Batch 2700/3125, Loss: 2.762112617492676, Uncertainty: 2.4001617431640625
Epoch 148, Batch 1900/3125, Loss: 0.8361650705337524, Uncertainty: 1.0953518152236938
Epoch 45, Batch 2800/3125, Loss: 2.5753071308135986, Uncertainty: 2.8104281425476074
Epoch 148, Batch 2000/3125, Loss: 1.0595276355743408, Uncertainty: 1.4679324626922607
Epoch 45, Batch 2900/3125, Loss: 3.103158950805664, Uncertainty: 4.627789497375488
Epoch 148, Batch 2100/3125, Loss: 1.1671621799468994, Uncertainty: 1.340093970298767
Epoch 148, Batch 2200/3125, Loss: 0.9044422507286072, Uncertainty: 1.1930608749389648
Epoch 45, Batch 3000/3125, Loss: 3.821629524230957, Uncertainty: 5.521707534790039
Epoch 148, Batch 2300/3125, Loss: 1.0938960313796997, Uncertainty: 1.4484864473342896
Epoch 45, Batch 3100/3125, Loss: 2.848332405090332, Uncertainty: 2.733081340789795
Epoch 148, Batch 2400/3125, Loss: 1.0933384895324707, Uncertainty: 1.285582423210144
Epoch 148, Batch 2500/3125, Loss: 0.9069557189941406, Uncertainty: 1.1945853233337402
Epoch 148, Batch 2600/3125, Loss: 1.315505862236023, Uncertainty: 2.128237247467041
Epoch 148, Batch 2700/3125, Loss: 1.1510703563690186, Uncertainty: 1.4635210037231445
Epoch 148, Batch 2800/3125, Loss: 0.8713924884796143, Uncertainty: 1.1338434219360352
Epoch 148, Batch 2900/3125, Loss: 1.0748322010040283, Uncertainty: 1.5029152631759644
Epoch 148, Batch 3000/3125, Loss: 1.0885847806930542, Uncertainty: 1.3675150871276855
Epoch 148, Batch 3100/3125, Loss: 1.0308067798614502, Uncertainty: 1.294740915298462

Training and Validation Results of Epoch 45:
================================
Training Loss: 2.4030207374191286, Training Uncertainty: 3.0634266212463377, time: 192.59826374053955
Validation Loss: 2.0323670530868005, Validation Uncertainty: 4.091176398574849, time: 50.53200101852417
Number of predictions within uncertainty interval: 112944/200000 (56.47%)

Epoch 46, Batch 100/3125, Loss: 2.5802741050720215, Uncertainty: 2.5221805572509766
Epoch 46, Batch 200/3125, Loss: 2.6659133434295654, Uncertainty: 2.69331431388855
Epoch 46, Batch 300/3125, Loss: 2.448513984680176, Uncertainty: 2.4416141510009766
Epoch 46, Batch 400/3125, Loss: 2.5697824954986572, Uncertainty: 2.8944356441497803
Epoch 46, Batch 500/3125, Loss: 2.7344799041748047, Uncertainty: 3.188307762145996
Epoch 46, Batch 600/3125, Loss: 2.6277074813842773, Uncertainty: 2.9547648429870605

Training and Validation Results of Epoch 148:
================================
Training Loss: 0.8415535831069946, Training Uncertainty: 1.3360821226119994, time: 178.74739050865173
Validation Loss: 0.7309659154671232, Validation Uncertainty: 1.8170859688688117, time: 39.62645697593689
Number of predictions within uncertainty interval: 124492/200000 (62.25%)

Epoch 46, Batch 700/3125, Loss: 2.8082308769226074, Uncertainty: 2.865483283996582
Epoch 149, Batch 100/3125, Loss: 0.9963113069534302, Uncertainty: 1.0309805870056152
Epoch 149, Batch 200/3125, Loss: 1.0540425777435303, Uncertainty: 1.2423149347305298
Epoch 46, Batch 800/3125, Loss: 2.9687340259552, Uncertainty: 3.7164173126220703
Epoch 149, Batch 300/3125, Loss: 1.101167917251587, Uncertainty: 1.2292304039001465
Epoch 46, Batch 900/3125, Loss: 3.2078988552093506, Uncertainty: 2.6517796516418457
Epoch 149, Batch 400/3125, Loss: 0.9828755855560303, Uncertainty: 1.1710429191589355
Epoch 46, Batch 1000/3125, Loss: 2.5184526443481445, Uncertainty: 2.589165210723877
Epoch 149, Batch 500/3125, Loss: 1.0871257781982422, Uncertainty: 1.3877395391464233
Epoch 46, Batch 1100/3125, Loss: 3.040480136871338, Uncertainty: 2.6339855194091797
Epoch 149, Batch 600/3125, Loss: 1.1159043312072754, Uncertainty: 1.2030439376831055
Epoch 46, Batch 1200/3125, Loss: 2.6706061363220215, Uncertainty: 3.1199915409088135
Epoch 149, Batch 700/3125, Loss: 0.9805504083633423, Uncertainty: 1.2570104598999023
Epoch 46, Batch 1300/3125, Loss: 2.3586807250976562, Uncertainty: 2.4020090103149414
Epoch 149, Batch 800/3125, Loss: 1.0601202249526978, Uncertainty: 1.2857208251953125
Epoch 149, Batch 900/3125, Loss: 1.135774850845337, Uncertainty: 1.3902511596679688
Epoch 46, Batch 1400/3125, Loss: 2.5649161338806152, Uncertainty: 2.643744468688965
Epoch 149, Batch 1000/3125, Loss: 0.9645466208457947, Uncertainty: 1.1671829223632812
Epoch 46, Batch 1500/3125, Loss: 3.0424578189849854, Uncertainty: 3.05810546875
Epoch 149, Batch 1100/3125, Loss: 0.947149932384491, Uncertainty: 1.1656147241592407
Epoch 46, Batch 1600/3125, Loss: 2.5363051891326904, Uncertainty: 2.5040977001190186
Epoch 149, Batch 1200/3125, Loss: 1.1645170450210571, Uncertainty: 1.2621533870697021
Epoch 46, Batch 1700/3125, Loss: 2.598578691482544, Uncertainty: 2.849414110183716
Epoch 149, Batch 1300/3125, Loss: 1.0370941162109375, Uncertainty: 1.0850118398666382
Epoch 46, Batch 1800/3125, Loss: 2.5717763900756836, Uncertainty: 2.467183828353882
Epoch 149, Batch 1400/3125, Loss: 0.9980001449584961, Uncertainty: 1.2742167711257935
Epoch 46, Batch 1900/3125, Loss: 2.6140453815460205, Uncertainty: 3.6156606674194336
Epoch 149, Batch 1500/3125, Loss: 1.099815845489502, Uncertainty: 1.188324213027954
Epoch 46, Batch 2000/3125, Loss: 2.714031219482422, Uncertainty: 2.5909743309020996
Epoch 149, Batch 1600/3125, Loss: 0.8817776441574097, Uncertainty: 1.1515496969223022
Epoch 149, Batch 1700/3125, Loss: 0.9539806842803955, Uncertainty: 1.313442587852478
Epoch 46, Batch 2100/3125, Loss: 3.0288772583007812, Uncertainty: 2.728527545928955
Epoch 149, Batch 1800/3125, Loss: 1.1581648588180542, Uncertainty: 1.462567687034607
Epoch 46, Batch 2200/3125, Loss: 2.5186266899108887, Uncertainty: 3.1114351749420166
Epoch 149, Batch 1900/3125, Loss: 0.8256685733795166, Uncertainty: 1.124117136001587
Epoch 46, Batch 2300/3125, Loss: 2.4931983947753906, Uncertainty: 2.9634881019592285
Epoch 149, Batch 2000/3125, Loss: 1.0582603216171265, Uncertainty: 1.5160444974899292
Epoch 46, Batch 2400/3125, Loss: 2.524965286254883, Uncertainty: 2.4725356101989746
Epoch 149, Batch 2100/3125, Loss: 1.2851014137268066, Uncertainty: 1.7323002815246582
Epoch 46, Batch 2500/3125, Loss: 2.4538514614105225, Uncertainty: 2.1769356727600098
Epoch 149, Batch 2200/3125, Loss: 0.8431090116500854, Uncertainty: 1.000969409942627
Epoch 46, Batch 2600/3125, Loss: 2.8156163692474365, Uncertainty: 2.876239061355591
Epoch 149, Batch 2300/3125, Loss: 1.101800799369812, Uncertainty: 1.3552930355072021
Epoch 46, Batch 2700/3125, Loss: 2.4667720794677734, Uncertainty: 2.4079179763793945
Epoch 149, Batch 2400/3125, Loss: 1.1679847240447998, Uncertainty: 1.6200037002563477
Epoch 46, Batch 2800/3125, Loss: 2.89959716796875, Uncertainty: 2.6623611450195312
Epoch 149, Batch 2500/3125, Loss: 0.9551606178283691, Uncertainty: 1.367007851600647
Epoch 149, Batch 2600/3125, Loss: 1.181567907333374, Uncertainty: 1.7989238500595093
Epoch 46, Batch 2900/3125, Loss: 2.6972768306732178, Uncertainty: 3.3404502868652344
Epoch 149, Batch 2700/3125, Loss: 1.3013863563537598, Uncertainty: 1.4477403163909912
Epoch 46, Batch 3000/3125, Loss: 2.7893307209014893, Uncertainty: 2.4189977645874023
Epoch 149, Batch 2800/3125, Loss: 0.8538888692855835, Uncertainty: 1.1116609573364258
Epoch 46, Batch 3100/3125, Loss: 2.4799163341522217, Uncertainty: 2.560603141784668
Epoch 149, Batch 2900/3125, Loss: 1.0174286365509033, Uncertainty: 1.2729976177215576
Epoch 149, Batch 3000/3125, Loss: 1.1009622812271118, Uncertainty: 1.3432717323303223
Epoch 149, Batch 3100/3125, Loss: 1.057608962059021, Uncertainty: 1.2607018947601318

Training and Validation Results of Epoch 46:
================================
Training Loss: 2.3533959827423097, Training Uncertainty: 3.0291758180618285, time: 195.92499804496765
Validation Loss: 1.9588406849700166, Validation Uncertainty: 6.044029224864053, time: 44.09396290779114
Number of predictions within uncertainty interval: 145846/200000 (72.92%)

Epoch 47, Batch 100/3125, Loss: 2.380460262298584, Uncertainty: 2.314631938934326

Training and Validation Results of Epoch 149:
================================
Training Loss: 0.8406496728515624, Training Uncertainty: 1.3282601549720765, time: 171.86248779296875
Validation Loss: 0.7176607979837891, Validation Uncertainty: 1.909013819511589, time: 39.579171895980835
Number of predictions within uncertainty interval: 131429/200000 (65.71%)

Epoch 47, Batch 200/3125, Loss: 2.586469888687134, Uncertainty: 2.554058074951172
Epoch 47, Batch 300/3125, Loss: 2.322938919067383, Uncertainty: 2.2803847789764404
Epoch 47, Batch 400/3125, Loss: 2.516352653503418, Uncertainty: 2.466517925262451
Epoch 47, Batch 500/3125, Loss: 2.8036129474639893, Uncertainty: 3.2706384658813477
Epoch 47, Batch 600/3125, Loss: 2.4596548080444336, Uncertainty: 2.791363000869751
Epoch 47, Batch 700/3125, Loss: 2.5738844871520996, Uncertainty: 3.113347291946411
Epoch 47, Batch 800/3125, Loss: 3.1635031700134277, Uncertainty: 4.009869575500488
Epoch 47, Batch 900/3125, Loss: 3.4222960472106934, Uncertainty: 2.686337947845459
Epoch 47, Batch 1000/3125, Loss: 2.5718154907226562, Uncertainty: 2.3862414360046387
Epoch 47, Batch 1100/3125, Loss: 2.880462408065796, Uncertainty: 2.8036720752716064
Epoch 47, Batch 1200/3125, Loss: 3.334956645965576, Uncertainty: 4.759476184844971
Epoch 47, Batch 1300/3125, Loss: 2.77242112159729, Uncertainty: 3.1400561332702637
Epoch 47, Batch 1400/3125, Loss: 3.5144710540771484, Uncertainty: 5.297115325927734

============================= JOB FEEDBACK =============================

NodeName=uc2n507
Job ID: 23972308
Cluster: uc2
User/Group: fq0795/iti
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 10
CPU Utilized: 10:13:37
CPU Efficiency: 9.94% of 4-06:53:20 core-walltime
Job Wall-clock time: 10:17:20
Memory Utilized: 10.94 GB
Memory Efficiency: 11.92% of 91.80 GB
Epoch 47, Batch 1500/3125, Loss: 2.760690689086914, Uncertainty: 2.4882493019104004
Epoch 47, Batch 1600/3125, Loss: 2.4455249309539795, Uncertainty: 2.5408380031585693
Epoch 47, Batch 1700/3125, Loss: 2.6733639240264893, Uncertainty: 2.7243170738220215
Epoch 47, Batch 1800/3125, Loss: 2.544483184814453, Uncertainty: 2.6676034927368164
Epoch 47, Batch 1900/3125, Loss: 2.5035147666931152, Uncertainty: 3.1946794986724854
Epoch 47, Batch 2000/3125, Loss: 3.0011754035949707, Uncertainty: 3.0323193073272705
Epoch 47, Batch 2100/3125, Loss: 2.578634738922119, Uncertainty: 2.507364273071289
Epoch 47, Batch 2200/3125, Loss: 3.207767963409424, Uncertainty: 4.23569917678833
Epoch 47, Batch 2300/3125, Loss: 2.4176268577575684, Uncertainty: 2.254829168319702
Epoch 47, Batch 2400/3125, Loss: 2.552835464477539, Uncertainty: 2.5105679035186768
Epoch 47, Batch 2500/3125, Loss: 2.4642601013183594, Uncertainty: 2.49257230758667
Epoch 47, Batch 2600/3125, Loss: 2.6988205909729004, Uncertainty: 2.64912486076355
Epoch 47, Batch 2700/3125, Loss: 2.586116313934326, Uncertainty: 2.1710920333862305
Epoch 47, Batch 2800/3125, Loss: 2.4294819831848145, Uncertainty: 2.398256301879883
Epoch 47, Batch 2900/3125, Loss: 2.3008852005004883, Uncertainty: 2.2432641983032227
Epoch 47, Batch 3000/3125, Loss: 2.7411675453186035, Uncertainty: 3.066701889038086
Epoch 47, Batch 3100/3125, Loss: 2.908308744430542, Uncertainty: 2.9138097763061523

Training and Validation Results of Epoch 47:
================================
Training Loss: 2.312360030593872, Training Uncertainty: 3.010138186416626, time: 195.22110247612
Validation Loss: 1.9827082413236807, Validation Uncertainty: 3.666080391620431, time: 44.618104457855225
Number of predictions within uncertainty interval: 102634/200000 (51.32%)

Epoch 48, Batch 100/3125, Loss: 2.430835247039795, Uncertainty: 2.763709783554077
Epoch 48, Batch 200/3125, Loss: 2.2883644104003906, Uncertainty: 2.5464894771575928
Epoch 48, Batch 300/3125, Loss: 2.169863700866699, Uncertainty: 2.112839698791504
Epoch 48, Batch 400/3125, Loss: 2.918914318084717, Uncertainty: 3.6521477699279785
Epoch 48, Batch 500/3125, Loss: 2.746495246887207, Uncertainty: 2.983859062194824
Epoch 48, Batch 600/3125, Loss: 2.8036751747131348, Uncertainty: 3.5159430503845215
Epoch 48, Batch 700/3125, Loss: 2.672476291656494, Uncertainty: 2.381563186645508
Epoch 48, Batch 800/3125, Loss: 2.7962875366210938, Uncertainty: 2.5789682865142822
Epoch 48, Batch 900/3125, Loss: 2.6100172996520996, Uncertainty: 3.0045809745788574
Epoch 48, Batch 1000/3125, Loss: 2.775346279144287, Uncertainty: 2.6212635040283203
Epoch 48, Batch 1100/3125, Loss: 2.7136406898498535, Uncertainty: 2.8004343509674072
Epoch 48, Batch 1200/3125, Loss: 2.4224822521209717, Uncertainty: 2.590132236480713
Epoch 48, Batch 1300/3125, Loss: 2.7420620918273926, Uncertainty: 3.5648999214172363
Epoch 48, Batch 1400/3125, Loss: 2.489732503890991, Uncertainty: 2.803520917892456
Epoch 48, Batch 1500/3125, Loss: 2.8480491638183594, Uncertainty: 2.7688260078430176
Epoch 48, Batch 1600/3125, Loss: 2.610400676727295, Uncertainty: 2.6078848838806152
Epoch 48, Batch 1700/3125, Loss: 2.3394947052001953, Uncertainty: 2.419536828994751
Epoch 48, Batch 1800/3125, Loss: 3.9165709018707275, Uncertainty: 3.281212568283081
Epoch 48, Batch 1900/3125, Loss: 2.7600107192993164, Uncertainty: 3.307471752166748
Epoch 48, Batch 2000/3125, Loss: 2.724325656890869, Uncertainty: 2.7448437213897705
Epoch 48, Batch 2100/3125, Loss: 2.7476072311401367, Uncertainty: 2.815692901611328
Epoch 48, Batch 2200/3125, Loss: 2.902331829071045, Uncertainty: 3.480447292327881
Epoch 48, Batch 2300/3125, Loss: 2.721604347229004, Uncertainty: 2.273547649383545
Epoch 48, Batch 2400/3125, Loss: 2.618431568145752, Uncertainty: 3.574328899383545
Epoch 48, Batch 2500/3125, Loss: 2.3186137676239014, Uncertainty: 2.5110960006713867
Epoch 48, Batch 2600/3125, Loss: 3.0300045013427734, Uncertainty: 2.50191593170166
Epoch 48, Batch 2700/3125, Loss: 3.0236165523529053, Uncertainty: 2.235703945159912
Epoch 48, Batch 2800/3125, Loss: 2.4770238399505615, Uncertainty: 2.410280466079712
Epoch 48, Batch 2900/3125, Loss: 2.7236411571502686, Uncertainty: 3.502852439880371
Epoch 48, Batch 3000/3125, Loss: 2.797313690185547, Uncertainty: 2.984180450439453
Epoch 48, Batch 3100/3125, Loss: 2.9078986644744873, Uncertainty: 2.910588026046753

Training and Validation Results of Epoch 48:
================================
Training Loss: 2.2807671238708496, Training Uncertainty: 2.9533360903549193, time: 193.47076773643494
Validation Loss: 1.8657828276724462, Validation Uncertainty: 4.823272738615265, time: 45.208380937576294
Number of predictions within uncertainty interval: 132568/200000 (66.28%)

Epoch 49, Batch 100/3125, Loss: 2.681485652923584, Uncertainty: 3.2889275550842285
Epoch 49, Batch 200/3125, Loss: 2.250941514968872, Uncertainty: 2.5440683364868164
Epoch 49, Batch 300/3125, Loss: 2.2685608863830566, Uncertainty: 2.402310609817505
Epoch 49, Batch 400/3125, Loss: 2.311958074569702, Uncertainty: 2.8864052295684814
Epoch 49, Batch 500/3125, Loss: 3.2461280822753906, Uncertainty: 3.670907497406006
Epoch 49, Batch 600/3125, Loss: 2.9623098373413086, Uncertainty: 3.5430355072021484
Epoch 49, Batch 700/3125, Loss: 2.598942279815674, Uncertainty: 2.6452136039733887
Epoch 49, Batch 800/3125, Loss: 3.0867514610290527, Uncertainty: 3.073643207550049
Epoch 49, Batch 900/3125, Loss: 2.9860239028930664, Uncertainty: 2.9777445793151855
Epoch 49, Batch 1000/3125, Loss: 2.5453052520751953, Uncertainty: 2.7483859062194824
Epoch 49, Batch 1100/3125, Loss: 2.838625907897949, Uncertainty: 2.4578707218170166
Epoch 49, Batch 1200/3125, Loss: 2.538639545440674, Uncertainty: 2.897613048553467
Epoch 49, Batch 1300/3125, Loss: 2.476262092590332, Uncertainty: 2.974384069442749
Epoch 49, Batch 1400/3125, Loss: 2.6160120964050293, Uncertainty: 2.5202584266662598
Epoch 49, Batch 1500/3125, Loss: 2.2202720642089844, Uncertainty: 2.343437910079956
Epoch 49, Batch 1600/3125, Loss: 3.878772735595703, Uncertainty: 5.972835540771484
Epoch 49, Batch 1700/3125, Loss: 2.3009917736053467, Uncertainty: 2.3166918754577637
Epoch 49, Batch 1800/3125, Loss: 2.5909066200256348, Uncertainty: 2.505371570587158
Epoch 49, Batch 1900/3125, Loss: 2.5024404525756836, Uncertainty: 2.5577902793884277
Epoch 49, Batch 2000/3125, Loss: 2.711960792541504, Uncertainty: 2.8730502128601074
Epoch 49, Batch 2100/3125, Loss: 2.4279425144195557, Uncertainty: 2.7575860023498535
Epoch 49, Batch 2200/3125, Loss: 2.21567964553833, Uncertainty: 2.5151400566101074
Epoch 49, Batch 2300/3125, Loss: 2.4225614070892334, Uncertainty: 2.963623523712158
Epoch 49, Batch 2400/3125, Loss: 2.6479101181030273, Uncertainty: 3.193063497543335
Epoch 49, Batch 2500/3125, Loss: 2.384415626525879, Uncertainty: 2.326127767562866
Epoch 49, Batch 2600/3125, Loss: 3.060209035873413, Uncertainty: 3.7692980766296387
Epoch 49, Batch 2700/3125, Loss: 2.478386402130127, Uncertainty: 2.91079044342041
Epoch 49, Batch 2800/3125, Loss: 2.700561046600342, Uncertainty: 3.16727876663208
Epoch 49, Batch 2900/3125, Loss: 2.4764487743377686, Uncertainty: 2.425050973892212
Epoch 49, Batch 3000/3125, Loss: 2.4773874282836914, Uncertainty: 2.6483049392700195
Epoch 49, Batch 3100/3125, Loss: 2.413814067840576, Uncertainty: 2.7855217456817627

Training and Validation Results of Epoch 49:
================================
Training Loss: 2.2383222120285033, Training Uncertainty: 2.9641715853118895, time: 196.52721881866455
Validation Loss: 1.8233841297876499, Validation Uncertainty: 4.183231349796285, time: 45.70500946044922
Number of predictions within uncertainty interval: 120369/200000 (60.18%)

Epoch 50, Batch 100/3125, Loss: 2.3901724815368652, Uncertainty: 2.8112025260925293
Epoch 50, Batch 200/3125, Loss: 2.614924907684326, Uncertainty: 2.4182353019714355
Epoch 50, Batch 300/3125, Loss: 2.3543856143951416, Uncertainty: 2.347862482070923
Epoch 50, Batch 400/3125, Loss: 2.9077982902526855, Uncertainty: 4.2221503257751465
Epoch 50, Batch 500/3125, Loss: 2.7107036113739014, Uncertainty: 2.578042507171631
Epoch 50, Batch 600/3125, Loss: 2.3388843536376953, Uncertainty: 2.340125799179077
Epoch 50, Batch 700/3125, Loss: 2.457963228225708, Uncertainty: 2.227630138397217
Epoch 50, Batch 800/3125, Loss: 2.59830904006958, Uncertainty: 3.2730374336242676
Epoch 50, Batch 900/3125, Loss: 2.570488929748535, Uncertainty: 2.7713840007781982
Epoch 50, Batch 1000/3125, Loss: 2.7882840633392334, Uncertainty: 3.4337167739868164
Epoch 50, Batch 1100/3125, Loss: 2.681873321533203, Uncertainty: 2.611544132232666
Epoch 50, Batch 1200/3125, Loss: 2.3966293334960938, Uncertainty: 2.467203140258789
Epoch 50, Batch 1300/3125, Loss: 2.237640857696533, Uncertainty: 2.435508966445923
Epoch 50, Batch 1400/3125, Loss: 2.5608134269714355, Uncertainty: 3.127772569656372
Epoch 50, Batch 1500/3125, Loss: 2.3565196990966797, Uncertainty: 2.492218017578125
Epoch 50, Batch 1600/3125, Loss: 2.302125930786133, Uncertainty: 2.5289530754089355
Epoch 50, Batch 1700/3125, Loss: 2.831472396850586, Uncertainty: 2.8382930755615234
Epoch 50, Batch 1800/3125, Loss: 3.183675765991211, Uncertainty: 2.4798672199249268
Epoch 50, Batch 1900/3125, Loss: 2.2483959197998047, Uncertainty: 2.4136929512023926
Epoch 50, Batch 2000/3125, Loss: 2.6542294025421143, Uncertainty: 2.8377346992492676
Epoch 50, Batch 2100/3125, Loss: 3.4271278381347656, Uncertainty: 3.756958246231079
Epoch 50, Batch 2200/3125, Loss: 2.6426851749420166, Uncertainty: 3.575596332550049
Epoch 50, Batch 2300/3125, Loss: 3.023432731628418, Uncertainty: 4.82792329788208
Epoch 50, Batch 2400/3125, Loss: 2.940927028656006, Uncertainty: 3.7463574409484863
Epoch 50, Batch 2500/3125, Loss: 2.3200631141662598, Uncertainty: 2.6306841373443604
Epoch 50, Batch 2600/3125, Loss: 2.733081817626953, Uncertainty: 3.310276508331299
Epoch 50, Batch 2700/3125, Loss: 3.1835243701934814, Uncertainty: 2.4377260208129883
Epoch 50, Batch 2800/3125, Loss: 2.560974597930908, Uncertainty: 2.882338047027588
Epoch 50, Batch 2900/3125, Loss: 2.734365701675415, Uncertainty: 3.8381428718566895
Epoch 50, Batch 3000/3125, Loss: 2.4420065879821777, Uncertainty: 2.3244471549987793
Epoch 50, Batch 3100/3125, Loss: 2.374051332473755, Uncertainty: 2.4589686393737793

Training and Validation Results of Epoch 50:
================================
Training Loss: 2.190978451309204, Training Uncertainty: 2.937340303192139, time: 194.60672616958618
Validation Loss: 1.97297829770676, Validation Uncertainty: 4.685202261371076, time: 44.806978702545166
Number of predictions within uncertainty interval: 120063/200000 (60.03%)

Epoch 51, Batch 100/3125, Loss: 2.2692503929138184, Uncertainty: 2.644690990447998
Epoch 51, Batch 200/3125, Loss: 2.362616539001465, Uncertainty: 2.6934165954589844
Epoch 51, Batch 300/3125, Loss: 2.2259180545806885, Uncertainty: 2.4364020824432373
Epoch 51, Batch 400/3125, Loss: 2.2121267318725586, Uncertainty: 2.6166129112243652
Epoch 51, Batch 500/3125, Loss: 2.6615540981292725, Uncertainty: 2.877281665802002
Epoch 51, Batch 600/3125, Loss: 2.9448413848876953, Uncertainty: 2.647373676300049
Epoch 51, Batch 700/3125, Loss: 2.2570831775665283, Uncertainty: 2.3747544288635254
Epoch 51, Batch 800/3125, Loss: 2.9940097332000732, Uncertainty: 4.663693904876709
Epoch 51, Batch 900/3125, Loss: 3.3282597064971924, Uncertainty: 2.5162577629089355
Epoch 51, Batch 1000/3125, Loss: 2.7892699241638184, Uncertainty: 3.8559277057647705
Epoch 51, Batch 1100/3125, Loss: 2.7110722064971924, Uncertainty: 2.5923337936401367
Epoch 51, Batch 1200/3125, Loss: 2.5571813583374023, Uncertainty: 2.9766030311584473
Epoch 51, Batch 1300/3125, Loss: 2.3327910900115967, Uncertainty: 2.612823486328125
Epoch 51, Batch 1400/3125, Loss: 2.34689998626709, Uncertainty: 2.1915512084960938
Epoch 51, Batch 1500/3125, Loss: 3.0394210815429688, Uncertainty: 2.6853342056274414
Epoch 51, Batch 1600/3125, Loss: 2.2366647720336914, Uncertainty: 2.514932632446289
Epoch 51, Batch 1700/3125, Loss: 2.3958170413970947, Uncertainty: 2.394761562347412
Epoch 51, Batch 1800/3125, Loss: 2.849609375, Uncertainty: 4.183239936828613
Epoch 51, Batch 1900/3125, Loss: 2.455214023590088, Uncertainty: 2.8001341819763184
Epoch 51, Batch 2000/3125, Loss: 2.6541075706481934, Uncertainty: 2.4198238849639893
Epoch 51, Batch 2100/3125, Loss: 2.723968982696533, Uncertainty: 3.7593741416931152
Epoch 51, Batch 2200/3125, Loss: 2.2586894035339355, Uncertainty: 2.4833459854125977
Epoch 51, Batch 2300/3125, Loss: 2.305814266204834, Uncertainty: 2.565453052520752
Epoch 51, Batch 2400/3125, Loss: 2.3308637142181396, Uncertainty: 2.7950704097747803
Epoch 51, Batch 2500/3125, Loss: 2.618476629257202, Uncertainty: 3.4100141525268555
Epoch 51, Batch 2600/3125, Loss: 2.3995938301086426, Uncertainty: 2.4205827713012695
Epoch 51, Batch 2700/3125, Loss: 2.3995771408081055, Uncertainty: 2.9742283821105957
Epoch 51, Batch 2800/3125, Loss: 2.3861656188964844, Uncertainty: 2.930847644805908
Epoch 51, Batch 2900/3125, Loss: 2.434819221496582, Uncertainty: 2.3728103637695312
Epoch 51, Batch 3000/3125, Loss: 2.9298322200775146, Uncertainty: 3.303093194961548
Epoch 51, Batch 3100/3125, Loss: 2.4883034229278564, Uncertainty: 2.4241814613342285

Training and Validation Results of Epoch 51:
================================
Training Loss: 2.144628427238464, Training Uncertainty: 2.9178383809661863, time: 195.54482865333557
Validation Loss: 2.1029008183332967, Validation Uncertainty: 4.490261041294888, time: 44.4826238155365
Number of predictions within uncertainty interval: 110178/200000 (55.09%)

Epoch 52, Batch 100/3125, Loss: 2.2043943405151367, Uncertainty: 2.2158713340759277
Epoch 52, Batch 200/3125, Loss: 2.3738179206848145, Uncertainty: 2.521040439605713
Epoch 52, Batch 300/3125, Loss: 2.5033082962036133, Uncertainty: 3.215991973876953
Epoch 52, Batch 400/3125, Loss: 2.6089565753936768, Uncertainty: 3.704298973083496
Epoch 52, Batch 500/3125, Loss: 2.398444890975952, Uncertainty: 2.6418094635009766
Epoch 52, Batch 600/3125, Loss: 2.404106616973877, Uncertainty: 3.2221083641052246
Epoch 52, Batch 700/3125, Loss: 2.2907447814941406, Uncertainty: 2.1695871353149414
Epoch 52, Batch 800/3125, Loss: 2.687397003173828, Uncertainty: 2.6681318283081055
Epoch 52, Batch 900/3125, Loss: 3.31010103225708, Uncertainty: 3.3995800018310547
Epoch 52, Batch 1000/3125, Loss: 2.3607723712921143, Uncertainty: 2.3119683265686035
Epoch 52, Batch 1100/3125, Loss: 2.7192108631134033, Uncertainty: 3.344245195388794
Epoch 52, Batch 1200/3125, Loss: 2.823834180831909, Uncertainty: 3.42266845703125
Epoch 52, Batch 1300/3125, Loss: 2.28334379196167, Uncertainty: 2.592653274536133
Epoch 52, Batch 1400/3125, Loss: 2.772324562072754, Uncertainty: 3.5006299018859863
Epoch 52, Batch 1500/3125, Loss: 2.920912265777588, Uncertainty: 4.547270774841309
Epoch 52, Batch 1600/3125, Loss: 2.20401668548584, Uncertainty: 2.6409807205200195
Epoch 52, Batch 1700/3125, Loss: 2.388758659362793, Uncertainty: 2.878011703491211
Epoch 52, Batch 1800/3125, Loss: 2.264570713043213, Uncertainty: 2.7948837280273438
Epoch 52, Batch 1900/3125, Loss: 2.4853293895721436, Uncertainty: 2.64121150970459
Epoch 52, Batch 2000/3125, Loss: 2.451045513153076, Uncertainty: 2.747926712036133
Epoch 52, Batch 2100/3125, Loss: 2.727820873260498, Uncertainty: 3.7912509441375732
Epoch 52, Batch 2200/3125, Loss: 2.1949448585510254, Uncertainty: 2.443216323852539
Epoch 52, Batch 2300/3125, Loss: 2.3063712120056152, Uncertainty: 2.3392114639282227
Epoch 52, Batch 2400/3125, Loss: 2.8298587799072266, Uncertainty: 2.4791336059570312
Epoch 52, Batch 2500/3125, Loss: 3.1749765872955322, Uncertainty: 2.874330997467041
Epoch 52, Batch 2600/3125, Loss: 2.6955785751342773, Uncertainty: 3.098177909851074
Epoch 52, Batch 2700/3125, Loss: 2.5197272300720215, Uncertainty: 2.947624683380127
Epoch 52, Batch 2800/3125, Loss: 2.8200106620788574, Uncertainty: 3.3074376583099365
Epoch 52, Batch 2900/3125, Loss: 2.5167598724365234, Uncertainty: 2.639366626739502
Epoch 52, Batch 3000/3125, Loss: 2.6033103466033936, Uncertainty: 2.215031862258911
Epoch 52, Batch 3100/3125, Loss: 2.4370267391204834, Uncertainty: 2.6594839096069336

Training and Validation Results of Epoch 52:
================================
Training Loss: 2.0985536532592772, Training Uncertainty: 2.936642160835266, time: 200.58295249938965
Validation Loss: 1.7438245641301051, Validation Uncertainty: 4.514040902447517, time: 44.364969968795776
Number of predictions within uncertainty interval: 131523/200000 (65.76%)

Epoch 53, Batch 100/3125, Loss: 3.078552007675171, Uncertainty: 4.163923263549805
Epoch 53, Batch 200/3125, Loss: 2.0445258617401123, Uncertainty: 2.4212441444396973
Epoch 53, Batch 300/3125, Loss: 2.1851301193237305, Uncertainty: 2.1992669105529785
Epoch 53, Batch 400/3125, Loss: 2.652188301086426, Uncertainty: 2.7751400470733643
Epoch 53, Batch 500/3125, Loss: 2.803518772125244, Uncertainty: 3.3976242542266846
Epoch 53, Batch 600/3125, Loss: 2.320026397705078, Uncertainty: 2.6397085189819336
Epoch 53, Batch 700/3125, Loss: 2.118269205093384, Uncertainty: 2.4510092735290527
Epoch 53, Batch 800/3125, Loss: 2.204801082611084, Uncertainty: 2.3475165367126465
Epoch 53, Batch 900/3125, Loss: 3.1983141899108887, Uncertainty: 2.365931510925293
Epoch 53, Batch 1000/3125, Loss: 2.502936840057373, Uncertainty: 2.4345498085021973
Epoch 53, Batch 1100/3125, Loss: 2.532377004623413, Uncertainty: 2.6980228424072266
Epoch 53, Batch 1200/3125, Loss: 2.7544825077056885, Uncertainty: 4.1833367347717285
Epoch 53, Batch 1300/3125, Loss: 2.7923645973205566, Uncertainty: 2.8994555473327637
Epoch 53, Batch 1400/3125, Loss: 2.3180065155029297, Uncertainty: 2.6569924354553223
Epoch 53, Batch 1500/3125, Loss: 2.1780803203582764, Uncertainty: 2.329033613204956
Epoch 53, Batch 1600/3125, Loss: 2.258772373199463, Uncertainty: 2.583735466003418
Epoch 53, Batch 1700/3125, Loss: 2.1921019554138184, Uncertainty: 2.7204933166503906
Epoch 53, Batch 1800/3125, Loss: 2.674004554748535, Uncertainty: 2.7305092811584473
Epoch 53, Batch 1900/3125, Loss: 2.232400894165039, Uncertainty: 2.283492088317871
Epoch 53, Batch 2000/3125, Loss: 2.253474235534668, Uncertainty: 2.402451753616333
Epoch 53, Batch 2100/3125, Loss: 2.913820266723633, Uncertainty: 4.510202407836914
Epoch 53, Batch 2200/3125, Loss: 2.5579919815063477, Uncertainty: 3.9439449310302734
Epoch 53, Batch 2300/3125, Loss: 2.5854365825653076, Uncertainty: 2.679410934448242
Epoch 53, Batch 2400/3125, Loss: 2.171177387237549, Uncertainty: 2.1968584060668945
Epoch 53, Batch 2500/3125, Loss: 2.1300745010375977, Uncertainty: 2.363602638244629
Epoch 53, Batch 2600/3125, Loss: 2.4990148544311523, Uncertainty: 2.9079179763793945
Epoch 53, Batch 2700/3125, Loss: 2.8267552852630615, Uncertainty: 2.426571846008301
Epoch 53, Batch 2800/3125, Loss: 2.2373952865600586, Uncertainty: 2.3984107971191406
Epoch 53, Batch 2900/3125, Loss: 2.524301767349243, Uncertainty: 2.839864492416382
Epoch 53, Batch 3000/3125, Loss: 2.307025194168091, Uncertainty: 2.8702316284179688
Epoch 53, Batch 3100/3125, Loss: 2.3908071517944336, Uncertainty: 2.949845314025879

Training and Validation Results of Epoch 53:
================================
Training Loss: 2.0294613134384156, Training Uncertainty: 2.85922978767395, time: 193.83643126487732
Validation Loss: 1.6913868124832583, Validation Uncertainty: 4.71193183230622, time: 45.01407718658447
Number of predictions within uncertainty interval: 137778/200000 (68.89%)

Epoch 54, Batch 100/3125, Loss: 2.246643543243408, Uncertainty: 2.4324779510498047
Epoch 54, Batch 200/3125, Loss: 2.153196334838867, Uncertainty: 2.5355587005615234
Epoch 54, Batch 300/3125, Loss: 2.08670973777771, Uncertainty: 2.1375136375427246
Epoch 54, Batch 400/3125, Loss: 2.1441421508789062, Uncertainty: 2.487248182296753
Epoch 54, Batch 500/3125, Loss: 2.4595611095428467, Uncertainty: 3.391976833343506
Epoch 54, Batch 600/3125, Loss: 2.3493034839630127, Uncertainty: 2.496936321258545
Epoch 54, Batch 700/3125, Loss: 2.112710475921631, Uncertainty: 2.0468616485595703
Epoch 54, Batch 800/3125, Loss: 2.6151349544525146, Uncertainty: 3.9499311447143555
Epoch 54, Batch 900/3125, Loss: 2.7988381385803223, Uncertainty: 3.6886746883392334
Epoch 54, Batch 1000/3125, Loss: 2.328601837158203, Uncertainty: 2.3632595539093018
Epoch 54, Batch 1100/3125, Loss: 2.4055099487304688, Uncertainty: 2.720647096633911
Epoch 54, Batch 1200/3125, Loss: 2.11456561088562, Uncertainty: 2.0053510665893555
Epoch 54, Batch 1300/3125, Loss: 2.824516773223877, Uncertainty: 4.605435848236084
Epoch 54, Batch 1400/3125, Loss: 2.4702510833740234, Uncertainty: 2.6718690395355225
Epoch 54, Batch 1500/3125, Loss: 1.9925628900527954, Uncertainty: 2.286457061767578
Epoch 54, Batch 1600/3125, Loss: 2.7442145347595215, Uncertainty: 2.906553268432617
Epoch 54, Batch 1700/3125, Loss: 2.846669912338257, Uncertainty: 4.009883880615234
Epoch 54, Batch 1800/3125, Loss: 2.286170244216919, Uncertainty: 2.3624184131622314
Epoch 54, Batch 1900/3125, Loss: 2.1200056076049805, Uncertainty: 2.5023210048675537
Epoch 54, Batch 2000/3125, Loss: 2.0051932334899902, Uncertainty: 2.298064708709717
Epoch 54, Batch 2100/3125, Loss: 2.46781587600708, Uncertainty: 2.758720874786377
Epoch 54, Batch 2200/3125, Loss: 2.964639902114868, Uncertainty: 3.5012125968933105
Epoch 54, Batch 2300/3125, Loss: 2.571751594543457, Uncertainty: 2.957855701446533
Epoch 54, Batch 2400/3125, Loss: 2.168142080307007, Uncertainty: 2.832202672958374
Epoch 54, Batch 2500/3125, Loss: 2.230212688446045, Uncertainty: 2.6937808990478516
Epoch 54, Batch 2600/3125, Loss: 2.7818384170532227, Uncertainty: 3.399524211883545
Epoch 54, Batch 2700/3125, Loss: 2.490683078765869, Uncertainty: 3.9538397789001465
Epoch 54, Batch 2800/3125, Loss: 2.3703200817108154, Uncertainty: 2.426042079925537
Epoch 54, Batch 2900/3125, Loss: 2.15230393409729, Uncertainty: 2.4070212841033936
Epoch 54, Batch 3000/3125, Loss: 2.218751907348633, Uncertainty: 2.6598548889160156
Epoch 54, Batch 3100/3125, Loss: 2.436614513397217, Uncertainty: 2.4591920375823975

Training and Validation Results of Epoch 54:
================================
Training Loss: 1.9558572616958618, Training Uncertainty: 2.8623875884628296, time: 195.43693137168884
Validation Loss: 1.6822963352398494, Validation Uncertainty: 3.7257674597108457, time: 52.33766841888428
Number of predictions within uncertainty interval: 114284/200000 (57.14%)

Epoch 55, Batch 100/3125, Loss: 3.063711166381836, Uncertainty: 4.036764144897461
Epoch 55, Batch 200/3125, Loss: 2.1711597442626953, Uncertainty: 3.0729174613952637
Epoch 55, Batch 300/3125, Loss: 2.557588577270508, Uncertainty: 4.022664546966553
Epoch 55, Batch 400/3125, Loss: 2.263289451599121, Uncertainty: 2.0881006717681885
Epoch 55, Batch 500/3125, Loss: 2.756852626800537, Uncertainty: 2.842193603515625
Epoch 55, Batch 600/3125, Loss: 2.071835517883301, Uncertainty: 2.5370373725891113
Epoch 55, Batch 700/3125, Loss: 2.325115442276001, Uncertainty: 2.308302879333496
Epoch 55, Batch 800/3125, Loss: 2.508021831512451, Uncertainty: 2.3700461387634277
Epoch 55, Batch 900/3125, Loss: 2.281100034713745, Uncertainty: 2.3685922622680664
Epoch 55, Batch 1000/3125, Loss: 2.5894317626953125, Uncertainty: 3.845649003982544
Epoch 55, Batch 1100/3125, Loss: 2.6104705333709717, Uncertainty: 3.6356654167175293
Epoch 55, Batch 1200/3125, Loss: 2.308377742767334, Uncertainty: 2.626985549926758
Epoch 55, Batch 1300/3125, Loss: 2.3979954719543457, Uncertainty: 3.2034969329833984
Epoch 55, Batch 1400/3125, Loss: 2.1455154418945312, Uncertainty: 2.4832749366760254
Epoch 55, Batch 1500/3125, Loss: 2.4968934059143066, Uncertainty: 3.5428824424743652
Epoch 55, Batch 1600/3125, Loss: 2.1030473709106445, Uncertainty: 2.1739501953125
Epoch 55, Batch 1700/3125, Loss: 2.1262543201446533, Uncertainty: 2.490029811859131
Epoch 55, Batch 1800/3125, Loss: 2.5659775733947754, Uncertainty: 2.777498722076416
Epoch 55, Batch 1900/3125, Loss: 2.4956018924713135, Uncertainty: 3.0215816497802734
Epoch 55, Batch 2000/3125, Loss: 2.0733706951141357, Uncertainty: 2.5792336463928223
Epoch 55, Batch 2100/3125, Loss: 2.6681950092315674, Uncertainty: 2.9750890731811523
Epoch 55, Batch 2200/3125, Loss: 2.1268444061279297, Uncertainty: 2.120384931564331
Epoch 55, Batch 2300/3125, Loss: 2.106247901916504, Uncertainty: 2.267876148223877
Epoch 55, Batch 2400/3125, Loss: 3.113920211791992, Uncertainty: 2.8662729263305664
Epoch 55, Batch 2500/3125, Loss: 2.042757272720337, Uncertainty: 2.280869960784912
Epoch 55, Batch 2600/3125, Loss: 2.128389596939087, Uncertainty: 2.358734130859375
Epoch 55, Batch 2700/3125, Loss: 2.4107041358947754, Uncertainty: 3.4534847736358643
Epoch 55, Batch 2800/3125, Loss: 2.2586703300476074, Uncertainty: 2.5510072708129883
Epoch 55, Batch 2900/3125, Loss: 2.420398712158203, Uncertainty: 2.172382354736328
Epoch 55, Batch 3000/3125, Loss: 2.3459038734436035, Uncertainty: 2.244300365447998
Epoch 55, Batch 3100/3125, Loss: 2.4887967109680176, Uncertainty: 2.5513854026794434

Training and Validation Results of Epoch 55:
================================
Training Loss: 1.8963353742218017, Training Uncertainty: 2.8208560306167603, time: 197.55587458610535
Validation Loss: 1.567837998995086, Validation Uncertainty: 4.439675692097305, time: 44.47469401359558
Number of predictions within uncertainty interval: 136925/200000 (68.46%)

Epoch 56, Batch 100/3125, Loss: 2.055917263031006, Uncertainty: 2.4228312969207764
Epoch 56, Batch 200/3125, Loss: 1.989275574684143, Uncertainty: 2.1898598670959473
Epoch 56, Batch 300/3125, Loss: 2.386305570602417, Uncertainty: 2.5274648666381836
Epoch 56, Batch 400/3125, Loss: 2.120114803314209, Uncertainty: 2.7963640689849854
Epoch 56, Batch 500/3125, Loss: 2.051786422729492, Uncertainty: 2.1307060718536377
Epoch 56, Batch 600/3125, Loss: 2.951200008392334, Uncertainty: 2.5238704681396484
Epoch 56, Batch 700/3125, Loss: 2.4351048469543457, Uncertainty: 3.2271792888641357
Epoch 56, Batch 800/3125, Loss: 2.994877338409424, Uncertainty: 3.0478248596191406
Epoch 56, Batch 900/3125, Loss: 2.0904712677001953, Uncertainty: 2.223297119140625
Epoch 56, Batch 1000/3125, Loss: 2.3058910369873047, Uncertainty: 2.1331863403320312
Epoch 56, Batch 1100/3125, Loss: 2.3889715671539307, Uncertainty: 3.249558687210083
Epoch 56, Batch 1200/3125, Loss: 2.189588785171509, Uncertainty: 2.5715978145599365
Epoch 56, Batch 1300/3125, Loss: 2.059319019317627, Uncertainty: 2.438304901123047
Epoch 56, Batch 1400/3125, Loss: 2.51924991607666, Uncertainty: 2.4661002159118652
Epoch 56, Batch 1500/3125, Loss: 2.313445806503296, Uncertainty: 3.239698886871338
Epoch 56, Batch 1600/3125, Loss: 2.0309929847717285, Uncertainty: 2.209381580352783
Epoch 56, Batch 1700/3125, Loss: 2.0259556770324707, Uncertainty: 2.36099910736084
Epoch 56, Batch 1800/3125, Loss: 2.9594595432281494, Uncertainty: 4.7025041580200195
Epoch 56, Batch 1900/3125, Loss: 2.052950382232666, Uncertainty: 2.709066867828369
Epoch 56, Batch 2000/3125, Loss: 2.130974531173706, Uncertainty: 2.9370474815368652
Epoch 56, Batch 2100/3125, Loss: 2.3302226066589355, Uncertainty: 2.353400707244873
Epoch 56, Batch 2200/3125, Loss: 2.277891159057617, Uncertainty: 2.1557564735412598
Epoch 56, Batch 2300/3125, Loss: 2.2626640796661377, Uncertainty: 3.1633095741271973
Epoch 56, Batch 2400/3125, Loss: 2.198367118835449, Uncertainty: 2.765511989593506
Epoch 56, Batch 2500/3125, Loss: 1.960452914237976, Uncertainty: 1.999634027481079
Epoch 56, Batch 2600/3125, Loss: 2.372962713241577, Uncertainty: 2.596776247024536
Epoch 56, Batch 2700/3125, Loss: 2.172886371612549, Uncertainty: 2.438004970550537
Epoch 56, Batch 2800/3125, Loss: 2.2494993209838867, Uncertainty: 2.879359483718872
Epoch 56, Batch 2900/3125, Loss: 2.963278293609619, Uncertainty: 4.810928821563721
Epoch 56, Batch 3000/3125, Loss: 5.114291191101074, Uncertainty: 7.915635108947754
Epoch 56, Batch 3100/3125, Loss: 2.8833730220794678, Uncertainty: 3.8732283115386963

Training and Validation Results of Epoch 56:
================================
Training Loss: 1.8857255277252196, Training Uncertainty: 2.820849030647278, time: 196.11800956726074
Validation Loss: 1.546911987044927, Validation Uncertainty: 4.0032812594757665, time: 44.402265548706055
Number of predictions within uncertainty interval: 128233/200000 (64.12%)

Epoch 57, Batch 100/3125, Loss: 2.428138017654419, Uncertainty: 3.8146419525146484
Epoch 57, Batch 200/3125, Loss: 2.0401487350463867, Uncertainty: 3.0280003547668457
Epoch 57, Batch 300/3125, Loss: 1.9700030088424683, Uncertainty: 2.4371891021728516
Epoch 57, Batch 400/3125, Loss: 2.2466821670532227, Uncertainty: 2.378133773803711
Epoch 57, Batch 500/3125, Loss: 2.243173837661743, Uncertainty: 2.3335001468658447
Epoch 57, Batch 600/3125, Loss: 2.0688061714172363, Uncertainty: 2.3369908332824707
Epoch 57, Batch 700/3125, Loss: 2.3622443675994873, Uncertainty: 2.2707712650299072
Epoch 57, Batch 800/3125, Loss: 2.556452751159668, Uncertainty: 2.76172137260437
Epoch 57, Batch 900/3125, Loss: 2.8274548053741455, Uncertainty: 2.9174280166625977
Epoch 57, Batch 1000/3125, Loss: 2.1369071006774902, Uncertainty: 2.530118703842163
Epoch 57, Batch 1100/3125, Loss: 2.3940484523773193, Uncertainty: 2.487656593322754
Epoch 57, Batch 1200/3125, Loss: 2.0173840522766113, Uncertainty: 2.2004590034484863
Epoch 57, Batch 1300/3125, Loss: 2.59273624420166, Uncertainty: 3.877671718597412
Epoch 57, Batch 1400/3125, Loss: 2.2151782512664795, Uncertainty: 2.4786500930786133
Epoch 57, Batch 1500/3125, Loss: 2.5911409854888916, Uncertainty: 3.6025686264038086
Epoch 57, Batch 1600/3125, Loss: 1.7834841012954712, Uncertainty: 2.0821545124053955
Epoch 57, Batch 1700/3125, Loss: 1.9629541635513306, Uncertainty: 2.3121349811553955
Epoch 57, Batch 1800/3125, Loss: 2.5651094913482666, Uncertainty: 2.5532171726226807
Epoch 57, Batch 1900/3125, Loss: 1.7095415592193604, Uncertainty: 1.9573701620101929
Epoch 57, Batch 2000/3125, Loss: 2.469064712524414, Uncertainty: 3.460468053817749
Epoch 57, Batch 2100/3125, Loss: 2.3546886444091797, Uncertainty: 3.000149726867676
Epoch 57, Batch 2200/3125, Loss: 2.274653434753418, Uncertainty: 3.449641704559326
Epoch 57, Batch 2300/3125, Loss: 2.2980823516845703, Uncertainty: 3.238751173019409
Epoch 57, Batch 2400/3125, Loss: 2.977743148803711, Uncertainty: 2.4306933879852295
Epoch 57, Batch 2500/3125, Loss: 2.074000835418701, Uncertainty: 2.4354355335235596
Epoch 57, Batch 2600/3125, Loss: 2.3663835525512695, Uncertainty: 3.0552704334259033
Epoch 57, Batch 2700/3125, Loss: 2.19866943359375, Uncertainty: 2.518944263458252
Epoch 57, Batch 2800/3125, Loss: 2.138260841369629, Uncertainty: 2.2452878952026367
Epoch 57, Batch 2900/3125, Loss: 2.289731502532959, Uncertainty: 3.1646344661712646
Epoch 57, Batch 3000/3125, Loss: 2.1627306938171387, Uncertainty: 2.7685070037841797
Epoch 57, Batch 3100/3125, Loss: 2.854973554611206, Uncertainty: 3.717796802520752

Training and Validation Results of Epoch 57:
================================
Training Loss: 1.802601828994751, Training Uncertainty: 2.7396074145126343, time: 195.71906757354736
Validation Loss: 1.4854150425137767, Validation Uncertainty: 3.964284202631782, time: 45.049031019210815
Number of predictions within uncertainty interval: 130601/200000 (65.30%)

Epoch 58, Batch 100/3125, Loss: 2.203174591064453, Uncertainty: 3.1745803356170654
Epoch 58, Batch 200/3125, Loss: 2.011359930038452, Uncertainty: 2.8391361236572266
Epoch 58, Batch 300/3125, Loss: 2.097585678100586, Uncertainty: 2.9562606811523438
Epoch 58, Batch 400/3125, Loss: 2.086888313293457, Uncertainty: 2.955756187438965
Epoch 58, Batch 500/3125, Loss: 2.3062872886657715, Uncertainty: 3.2738571166992188
Epoch 58, Batch 600/3125, Loss: 2.243427276611328, Uncertainty: 2.4994466304779053
Epoch 58, Batch 700/3125, Loss: 1.895520567893982, Uncertainty: 2.0298895835876465
Epoch 58, Batch 800/3125, Loss: 2.0184664726257324, Uncertainty: 2.197998046875
Epoch 58, Batch 900/3125, Loss: 2.6043479442596436, Uncertainty: 3.1482720375061035
Epoch 58, Batch 1000/3125, Loss: 2.169402599334717, Uncertainty: 2.679980516433716
Epoch 58, Batch 1100/3125, Loss: 2.2874295711517334, Uncertainty: 2.9320969581604004
Epoch 58, Batch 1200/3125, Loss: 2.1173458099365234, Uncertainty: 2.3861308097839355
Epoch 58, Batch 1300/3125, Loss: 2.1509084701538086, Uncertainty: 2.4212379455566406
Epoch 58, Batch 1400/3125, Loss: 2.2229602336883545, Uncertainty: 2.2199225425720215
Epoch 58, Batch 1500/3125, Loss: 2.5231564044952393, Uncertainty: 2.994173765182495
Epoch 58, Batch 1600/3125, Loss: 2.043024778366089, Uncertainty: 2.6379406452178955
Epoch 58, Batch 1700/3125, Loss: 3.2160654067993164, Uncertainty: 5.893215656280518
Epoch 58, Batch 1800/3125, Loss: 2.539067506790161, Uncertainty: 3.9196338653564453
Epoch 58, Batch 1900/3125, Loss: 1.9924452304840088, Uncertainty: 2.5199520587921143
Epoch 58, Batch 2000/3125, Loss: 2.175752639770508, Uncertainty: 2.8379855155944824
Epoch 58, Batch 2100/3125, Loss: 2.1156005859375, Uncertainty: 2.3467133045196533
Epoch 58, Batch 2200/3125, Loss: 2.2138195037841797, Uncertainty: 2.4298274517059326
Epoch 58, Batch 2300/3125, Loss: 2.2313270568847656, Uncertainty: 2.455735921859741
Epoch 58, Batch 2400/3125, Loss: 2.3562803268432617, Uncertainty: 2.6469051837921143
Epoch 58, Batch 2500/3125, Loss: 2.229086399078369, Uncertainty: 3.1794815063476562
Epoch 58, Batch 2600/3125, Loss: 2.2438697814941406, Uncertainty: 2.4826087951660156
Epoch 58, Batch 2700/3125, Loss: 1.9906888008117676, Uncertainty: 2.1837925910949707
Epoch 58, Batch 2800/3125, Loss: 1.9019439220428467, Uncertainty: 2.284641742706299
Epoch 58, Batch 2900/3125, Loss: 2.2600183486938477, Uncertainty: 2.501049518585205
Epoch 58, Batch 3000/3125, Loss: 2.1678953170776367, Uncertainty: 2.152332305908203
Epoch 58, Batch 3100/3125, Loss: 2.2567286491394043, Uncertainty: 2.49489426612854

Training and Validation Results of Epoch 58:
================================
Training Loss: 1.7699923811340332, Training Uncertainty: 2.7317593282318113, time: 199.81520891189575
Validation Loss: 1.8178890127964946, Validation Uncertainty: 4.199849606474952, time: 44.36801886558533
Number of predictions within uncertainty interval: 114315/200000 (57.16%)

Epoch 59, Batch 100/3125, Loss: 2.2144289016723633, Uncertainty: 2.2139809131622314
Epoch 59, Batch 200/3125, Loss: 1.8207505941390991, Uncertainty: 2.107203483581543
Epoch 59, Batch 300/3125, Loss: 2.1873631477355957, Uncertainty: 3.013584613800049
Epoch 59, Batch 400/3125, Loss: 1.8757305145263672, Uncertainty: 1.9867782592773438
Epoch 59, Batch 500/3125, Loss: 2.1646018028259277, Uncertainty: 2.61161470413208
Epoch 59, Batch 600/3125, Loss: 2.2236504554748535, Uncertainty: 3.293745994567871
Epoch 59, Batch 700/3125, Loss: 2.529630422592163, Uncertainty: 3.640603542327881
Epoch 59, Batch 800/3125, Loss: 2.082623243331909, Uncertainty: 2.2059149742126465
Epoch 59, Batch 900/3125, Loss: 2.362208843231201, Uncertainty: 2.869326591491699
Epoch 59, Batch 1000/3125, Loss: 2.0340757369995117, Uncertainty: 2.4999256134033203
Epoch 59, Batch 1100/3125, Loss: 2.290074348449707, Uncertainty: 2.774296283721924
Epoch 59, Batch 1200/3125, Loss: 2.1002516746520996, Uncertainty: 2.093204975128174
Epoch 59, Batch 1300/3125, Loss: 2.5901756286621094, Uncertainty: 3.871145725250244
Epoch 59, Batch 1400/3125, Loss: 2.054265022277832, Uncertainty: 2.751887798309326
Epoch 59, Batch 1500/3125, Loss: 2.1762735843658447, Uncertainty: 2.497061014175415
Epoch 59, Batch 1600/3125, Loss: 2.134155750274658, Uncertainty: 1.9160594940185547
Epoch 59, Batch 1700/3125, Loss: 1.9616339206695557, Uncertainty: 2.7282309532165527
Epoch 59, Batch 1800/3125, Loss: 2.49446439743042, Uncertainty: 2.7509779930114746
Epoch 59, Batch 1900/3125, Loss: 2.1652767658233643, Uncertainty: 2.2551655769348145
Epoch 59, Batch 2000/3125, Loss: 2.2770018577575684, Uncertainty: 2.3876638412475586
Epoch 59, Batch 2100/3125, Loss: 2.8235654830932617, Uncertainty: 4.6265459060668945
Epoch 59, Batch 2200/3125, Loss: 2.880449056625366, Uncertainty: 2.1425509452819824
Epoch 59, Batch 2300/3125, Loss: 1.9272141456604004, Uncertainty: 2.2380716800689697
Epoch 59, Batch 2400/3125, Loss: 2.1899237632751465, Uncertainty: 2.8634839057922363
Epoch 59, Batch 2500/3125, Loss: 1.9801080226898193, Uncertainty: 2.378695011138916
Epoch 59, Batch 2600/3125, Loss: 2.0887069702148438, Uncertainty: 2.079625129699707
Epoch 59, Batch 2700/3125, Loss: 2.1048996448516846, Uncertainty: 2.3914222717285156
Epoch 59, Batch 2800/3125, Loss: 2.311354875564575, Uncertainty: 2.669179916381836
Epoch 59, Batch 2900/3125, Loss: 2.01401686668396, Uncertainty: 2.4056622982025146
Epoch 59, Batch 3000/3125, Loss: 2.082520008087158, Uncertainty: 2.604323625564575
Epoch 59, Batch 3100/3125, Loss: 2.0744171142578125, Uncertainty: 2.1989898681640625

Training and Validation Results of Epoch 59:
================================
Training Loss: 1.763737767829895, Training Uncertainty: 2.7236504944229125, time: 195.8662109375
Validation Loss: 1.4052656257853788, Validation Uncertainty: 4.290048497107327, time: 44.2350389957428
Number of predictions within uncertainty interval: 143539/200000 (71.77%)

Epoch 60, Batch 100/3125, Loss: 1.8679008483886719, Uncertainty: 2.4773001670837402
Epoch 60, Batch 200/3125, Loss: 1.7339715957641602, Uncertainty: 2.3669543266296387
Epoch 60, Batch 300/3125, Loss: 1.777134895324707, Uncertainty: 2.0148329734802246
Epoch 60, Batch 400/3125, Loss: 1.7552331686019897, Uncertainty: 2.061439037322998
Epoch 60, Batch 500/3125, Loss: 1.8673655986785889, Uncertainty: 2.0597527027130127
Epoch 60, Batch 600/3125, Loss: 2.2853167057037354, Uncertainty: 3.3911781311035156
Epoch 60, Batch 700/3125, Loss: 1.9600567817687988, Uncertainty: 1.998644471168518
Epoch 60, Batch 800/3125, Loss: 2.4492669105529785, Uncertainty: 2.836404323577881
Epoch 60, Batch 900/3125, Loss: 2.2546393871307373, Uncertainty: 2.106536626815796
Epoch 60, Batch 1000/3125, Loss: 1.9432096481323242, Uncertainty: 2.095815658569336
Epoch 60, Batch 1100/3125, Loss: 2.2447197437286377, Uncertainty: 2.773219108581543
Epoch 60, Batch 1200/3125, Loss: 2.1679601669311523, Uncertainty: 2.7642250061035156
Epoch 60, Batch 1300/3125, Loss: 1.9251139163970947, Uncertainty: 2.4947335720062256
Epoch 60, Batch 1400/3125, Loss: 2.14711856842041, Uncertainty: 2.5144662857055664
Epoch 60, Batch 1500/3125, Loss: 2.6175551414489746, Uncertainty: 2.593036651611328
Epoch 60, Batch 1600/3125, Loss: 1.7507719993591309, Uncertainty: 1.8072532415390015
Epoch 60, Batch 1700/3125, Loss: 2.173339366912842, Uncertainty: 2.673322916030884
Epoch 60, Batch 1800/3125, Loss: 1.8943326473236084, Uncertainty: 2.334658622741699
Epoch 60, Batch 1900/3125, Loss: 1.9373064041137695, Uncertainty: 2.3210840225219727
Epoch 60, Batch 2000/3125, Loss: 2.2736010551452637, Uncertainty: 2.248782157897949
Epoch 60, Batch 2100/3125, Loss: 2.1610450744628906, Uncertainty: 2.4711923599243164
Epoch 60, Batch 2200/3125, Loss: 1.9539101123809814, Uncertainty: 2.044942855834961
Epoch 60, Batch 2300/3125, Loss: 1.9931269884109497, Uncertainty: 2.4924392700195312
Epoch 60, Batch 2400/3125, Loss: 1.8340013027191162, Uncertainty: 1.9904224872589111
Epoch 60, Batch 2500/3125, Loss: 1.9657824039459229, Uncertainty: 2.4572436809539795
Epoch 60, Batch 2600/3125, Loss: 2.0682413578033447, Uncertainty: 2.5797250270843506
Epoch 60, Batch 2700/3125, Loss: 2.105788469314575, Uncertainty: 2.25610613822937
Epoch 60, Batch 2800/3125, Loss: 2.367574691772461, Uncertainty: 2.1229748725891113
Epoch 60, Batch 2900/3125, Loss: 2.0832180976867676, Uncertainty: 2.695080518722534
Epoch 60, Batch 3000/3125, Loss: 2.308662176132202, Uncertainty: 2.897538900375366
Epoch 60, Batch 3100/3125, Loss: 2.1811366081237793, Uncertainty: 2.5788745880126953

Training and Validation Results of Epoch 60:
================================
Training Loss: 1.7452482465362549, Training Uncertainty: 2.7017486297988893, time: 195.96516013145447
Validation Loss: 1.3963695569416446, Validation Uncertainty: 4.925558393263755, time: 44.94360375404358
Number of predictions within uncertainty interval: 152628/200000 (76.31%)

Epoch 61, Batch 100/3125, Loss: 1.8339776992797852, Uncertainty: 2.316246509552002
Epoch 61, Batch 200/3125, Loss: 2.330456256866455, Uncertainty: 3.569807529449463
Epoch 61, Batch 300/3125, Loss: 2.207998752593994, Uncertainty: 2.5267934799194336
Epoch 61, Batch 400/3125, Loss: 1.8319652080535889, Uncertainty: 1.9896920919418335
Epoch 61, Batch 500/3125, Loss: 2.086744546890259, Uncertainty: 2.5693697929382324
Epoch 61, Batch 600/3125, Loss: 2.389847755432129, Uncertainty: 3.293783664703369
Epoch 61, Batch 700/3125, Loss: 2.131812572479248, Uncertainty: 1.9970948696136475
Epoch 61, Batch 800/3125, Loss: 2.327589988708496, Uncertainty: 3.5685176849365234
Epoch 61, Batch 900/3125, Loss: 2.284836530685425, Uncertainty: 3.3332109451293945
Epoch 61, Batch 1000/3125, Loss: 2.324313163757324, Uncertainty: 2.9674525260925293
Epoch 61, Batch 1100/3125, Loss: 2.384636640548706, Uncertainty: 3.1273293495178223
Epoch 61, Batch 1200/3125, Loss: 1.9584678411483765, Uncertainty: 2.585829734802246
Epoch 61, Batch 1300/3125, Loss: 2.193336009979248, Uncertainty: 2.526810646057129
Epoch 61, Batch 1400/3125, Loss: 1.8675596714019775, Uncertainty: 2.087794065475464
Epoch 61, Batch 1500/3125, Loss: 2.22982120513916, Uncertainty: 2.4643397331237793
Epoch 61, Batch 1600/3125, Loss: 2.1617331504821777, Uncertainty: 2.493039608001709
Epoch 61, Batch 1700/3125, Loss: 1.965592622756958, Uncertainty: 2.1785573959350586
Epoch 61, Batch 1800/3125, Loss: 2.19962215423584, Uncertainty: 2.836606979370117
Epoch 61, Batch 1900/3125, Loss: 2.221503734588623, Uncertainty: 2.455502510070801
Epoch 61, Batch 2000/3125, Loss: 1.9246141910552979, Uncertainty: 2.3507113456726074
Epoch 61, Batch 2100/3125, Loss: 2.6473822593688965, Uncertainty: 4.021310329437256
Epoch 61, Batch 2200/3125, Loss: 2.6235599517822266, Uncertainty: 4.5258588790893555
Epoch 61, Batch 2300/3125, Loss: 2.027653217315674, Uncertainty: 2.66441011428833
Epoch 61, Batch 2400/3125, Loss: 2.054572343826294, Uncertainty: 2.671170711517334
Epoch 61, Batch 2500/3125, Loss: 2.4033594131469727, Uncertainty: 3.501675605773926
Epoch 61, Batch 2600/3125, Loss: 1.9972906112670898, Uncertainty: 2.2667810916900635
Epoch 61, Batch 2700/3125, Loss: 1.980966329574585, Uncertainty: 2.3857405185699463
Epoch 61, Batch 2800/3125, Loss: 1.8787174224853516, Uncertainty: 2.5238704681396484
Epoch 61, Batch 2900/3125, Loss: 1.8036150932312012, Uncertainty: 1.8525501489639282
Epoch 61, Batch 3000/3125, Loss: 2.525421142578125, Uncertainty: 3.421910285949707
Epoch 61, Batch 3100/3125, Loss: 2.642094135284424, Uncertainty: 4.336674690246582

Training and Validation Results of Epoch 61:
================================
Training Loss: 1.7057258586120605, Training Uncertainty: 2.6736876752090453, time: 194.41636419296265
Validation Loss: 1.3480046554599576, Validation Uncertainty: 3.598105106207416, time: 45.42443108558655
Number of predictions within uncertainty interval: 132150/200000 (66.07%)

Epoch 62, Batch 100/3125, Loss: 1.741239070892334, Uncertainty: 2.1934423446655273
Epoch 62, Batch 200/3125, Loss: 2.4577977657318115, Uncertainty: 2.297142505645752
Epoch 62, Batch 300/3125, Loss: 1.9572274684906006, Uncertainty: 2.3489646911621094
Epoch 62, Batch 400/3125, Loss: 2.2091445922851562, Uncertainty: 2.363870143890381
Epoch 62, Batch 500/3125, Loss: 2.0345749855041504, Uncertainty: 2.42084002494812
Epoch 62, Batch 600/3125, Loss: 1.9958009719848633, Uncertainty: 2.4331436157226562
Epoch 62, Batch 700/3125, Loss: 1.817948341369629, Uncertainty: 1.9850175380706787
Epoch 62, Batch 800/3125, Loss: 1.925443410873413, Uncertainty: 2.0737380981445312
Epoch 62, Batch 900/3125, Loss: 1.819967269897461, Uncertainty: 2.2783524990081787
Epoch 62, Batch 1000/3125, Loss: 2.400543689727783, Uncertainty: 3.494678258895874
Epoch 62, Batch 1100/3125, Loss: 2.2883894443511963, Uncertainty: 2.3756110668182373
Epoch 62, Batch 1200/3125, Loss: 2.2915637493133545, Uncertainty: 3.1938743591308594
Epoch 62, Batch 1300/3125, Loss: 1.973743200302124, Uncertainty: 2.202441692352295
Epoch 62, Batch 1400/3125, Loss: 1.795067548751831, Uncertainty: 1.957747220993042
Epoch 62, Batch 1500/3125, Loss: 2.0540542602539062, Uncertainty: 2.5286569595336914
Epoch 62, Batch 1600/3125, Loss: 2.7322587966918945, Uncertainty: 2.733677864074707
Epoch 62, Batch 1700/3125, Loss: 1.86138916015625, Uncertainty: 2.5533459186553955
Epoch 62, Batch 1800/3125, Loss: 1.8526055812835693, Uncertainty: 2.0375704765319824
Epoch 62, Batch 1900/3125, Loss: 1.7847774028778076, Uncertainty: 2.096219062805176
Epoch 62, Batch 2000/3125, Loss: 2.49397873878479, Uncertainty: 3.753525733947754
Epoch 62, Batch 2100/3125, Loss: 2.1701860427856445, Uncertainty: 2.840019941329956
Epoch 62, Batch 2200/3125, Loss: 2.137381076812744, Uncertainty: 2.6112990379333496
Epoch 62, Batch 2300/3125, Loss: 2.0375144481658936, Uncertainty: 2.686591148376465
Epoch 62, Batch 2400/3125, Loss: 2.3454132080078125, Uncertainty: 3.7303051948547363
Epoch 62, Batch 2500/3125, Loss: 1.9627165794372559, Uncertainty: 2.5145621299743652
Epoch 62, Batch 2600/3125, Loss: 2.0154645442962646, Uncertainty: 2.249446392059326
Epoch 62, Batch 2700/3125, Loss: 2.127654552459717, Uncertainty: 2.885991096496582
Epoch 62, Batch 2800/3125, Loss: 2.012861967086792, Uncertainty: 2.722025156021118
Epoch 62, Batch 2900/3125, Loss: 2.2314038276672363, Uncertainty: 2.81134295463562
Epoch 62, Batch 3000/3125, Loss: 1.8708889484405518, Uncertainty: 2.3855292797088623
Epoch 62, Batch 3100/3125, Loss: 2.271115779876709, Uncertainty: 3.2285265922546387

Training and Validation Results of Epoch 62:
================================
Training Loss: 1.6885422257995606, Training Uncertainty: 2.6575372201919554, time: 194.495267868042
Validation Loss: 1.518626191731914, Validation Uncertainty: 4.012274381754648, time: 45.15874719619751
Number of predictions within uncertainty interval: 133253/200000 (66.63%)

Epoch 63, Batch 100/3125, Loss: 2.2507429122924805, Uncertainty: 3.4670088291168213
Epoch 63, Batch 200/3125, Loss: 1.838170051574707, Uncertainty: 2.177018165588379
Epoch 63, Batch 300/3125, Loss: 1.774789571762085, Uncertainty: 2.020620346069336
Epoch 63, Batch 400/3125, Loss: 2.166079521179199, Uncertainty: 2.5596494674682617
Epoch 63, Batch 500/3125, Loss: 2.23028564453125, Uncertainty: 2.397090196609497
Epoch 63, Batch 600/3125, Loss: 2.4454197883605957, Uncertainty: 2.9476075172424316
Epoch 63, Batch 700/3125, Loss: 2.0303592681884766, Uncertainty: 2.857761859893799
Epoch 63, Batch 800/3125, Loss: 2.133326292037964, Uncertainty: 2.1747326850891113
Epoch 63, Batch 900/3125, Loss: 1.9801210165023804, Uncertainty: 2.134276866912842
Epoch 63, Batch 1000/3125, Loss: 2.0268688201904297, Uncertainty: 2.4071903228759766
Epoch 63, Batch 1100/3125, Loss: 2.179002285003662, Uncertainty: 2.785338878631592
Epoch 63, Batch 1200/3125, Loss: 2.5531821250915527, Uncertainty: 2.2303414344787598
Epoch 63, Batch 1300/3125, Loss: 2.0395617485046387, Uncertainty: 2.337052345275879
Epoch 63, Batch 1400/3125, Loss: 1.8604799509048462, Uncertainty: 2.338837146759033
Epoch 63, Batch 1500/3125, Loss: 2.1710689067840576, Uncertainty: 2.213717460632324
Epoch 63, Batch 1600/3125, Loss: 1.892974615097046, Uncertainty: 2.3485026359558105
Epoch 63, Batch 1700/3125, Loss: 1.865940809249878, Uncertainty: 2.3068156242370605
Epoch 63, Batch 1800/3125, Loss: 1.9909112453460693, Uncertainty: 2.1820225715637207
Epoch 63, Batch 1900/3125, Loss: 1.7797578573226929, Uncertainty: 2.2921581268310547
Epoch 63, Batch 2000/3125, Loss: 2.074589252471924, Uncertainty: 2.656744956970215
Epoch 63, Batch 2100/3125, Loss: 2.0756266117095947, Uncertainty: 2.578564167022705
Epoch 63, Batch 2200/3125, Loss: 2.423344135284424, Uncertainty: 2.285687208175659
Epoch 63, Batch 2300/3125, Loss: 2.4111719131469727, Uncertainty: 2.13380765914917
Epoch 63, Batch 2400/3125, Loss: 2.0905227661132812, Uncertainty: 2.6922621726989746
Epoch 63, Batch 2500/3125, Loss: 2.023491382598877, Uncertainty: 2.240431547164917
Epoch 63, Batch 2600/3125, Loss: 2.0876779556274414, Uncertainty: 2.853104591369629
Epoch 63, Batch 2700/3125, Loss: 1.7935007810592651, Uncertainty: 1.8872112035751343
Epoch 63, Batch 2800/3125, Loss: 2.185227870941162, Uncertainty: 2.9838056564331055
Epoch 63, Batch 2900/3125, Loss: 1.945784568786621, Uncertainty: 2.6194043159484863
Epoch 63, Batch 3000/3125, Loss: 2.5765671730041504, Uncertainty: 2.5162792205810547
Epoch 63, Batch 3100/3125, Loss: 1.861842155456543, Uncertainty: 2.1153547763824463

Training and Validation Results of Epoch 63:
================================
Training Loss: 1.6659129579544067, Training Uncertainty: 2.611471632080078, time: 193.31929349899292
Validation Loss: 1.3705079171358776, Validation Uncertainty: 4.4045363948168355, time: 44.22927951812744
Number of predictions within uncertainty interval: 149834/200000 (74.92%)

Epoch 64, Batch 100/3125, Loss: 2.0177016258239746, Uncertainty: 1.9895483255386353
Epoch 64, Batch 200/3125, Loss: 2.4847354888916016, Uncertainty: 4.024297714233398
Epoch 64, Batch 300/3125, Loss: 1.8497514724731445, Uncertainty: 2.2837090492248535
Epoch 64, Batch 400/3125, Loss: 2.018275260925293, Uncertainty: 2.8399159908294678
Epoch 64, Batch 500/3125, Loss: 2.0737380981445312, Uncertainty: 2.5495688915252686
Epoch 64, Batch 600/3125, Loss: 1.9068512916564941, Uncertainty: 2.519552230834961
Epoch 64, Batch 700/3125, Loss: 1.8494454622268677, Uncertainty: 2.252876043319702
Epoch 64, Batch 800/3125, Loss: 2.403961658477783, Uncertainty: 3.5447707176208496
Epoch 64, Batch 900/3125, Loss: 2.24623441696167, Uncertainty: 3.7642765045166016
Epoch 64, Batch 1000/3125, Loss: 2.0233407020568848, Uncertainty: 2.4626994132995605
Epoch 64, Batch 1100/3125, Loss: 2.1586241722106934, Uncertainty: 2.757965087890625
Epoch 64, Batch 1200/3125, Loss: 2.034421682357788, Uncertainty: 2.2729671001434326
Epoch 64, Batch 1300/3125, Loss: 1.7308282852172852, Uncertainty: 2.2796010971069336
Epoch 64, Batch 1400/3125, Loss: 2.6646790504455566, Uncertainty: 2.7557430267333984
Epoch 64, Batch 1500/3125, Loss: 2.0899453163146973, Uncertainty: 2.941453456878662
Epoch 64, Batch 1600/3125, Loss: 2.008420467376709, Uncertainty: 2.3321356773376465
Epoch 64, Batch 1700/3125, Loss: 1.869254469871521, Uncertainty: 2.2392616271972656
Epoch 64, Batch 1800/3125, Loss: 2.2175161838531494, Uncertainty: 3.105257511138916
Epoch 64, Batch 1900/3125, Loss: 1.7760921716690063, Uncertainty: 2.025312900543213
Epoch 64, Batch 2000/3125, Loss: 1.8383395671844482, Uncertainty: 2.4101767539978027
Epoch 64, Batch 2100/3125, Loss: 2.0456929206848145, Uncertainty: 2.6273226737976074
Epoch 64, Batch 2200/3125, Loss: 2.0040090084075928, Uncertainty: 2.4105353355407715
Epoch 64, Batch 2300/3125, Loss: 1.7687010765075684, Uncertainty: 2.178906202316284
Epoch 64, Batch 2400/3125, Loss: 1.9796850681304932, Uncertainty: 2.2243127822875977
Epoch 64, Batch 2500/3125, Loss: 1.9289567470550537, Uncertainty: 2.158494234085083
Epoch 64, Batch 2600/3125, Loss: 2.64534330368042, Uncertainty: 4.396110534667969
Epoch 64, Batch 2700/3125, Loss: 2.1192240715026855, Uncertainty: 2.1585288047790527
Epoch 64, Batch 2800/3125, Loss: 1.8574912548065186, Uncertainty: 2.3502159118652344
Epoch 64, Batch 2900/3125, Loss: 1.7366364002227783, Uncertainty: 2.2159059047698975
Epoch 64, Batch 3000/3125, Loss: 2.3079354763031006, Uncertainty: 3.6488935947418213
Epoch 64, Batch 3100/3125, Loss: 2.0924606323242188, Uncertainty: 2.3815860748291016

Training and Validation Results of Epoch 64:
================================
Training Loss: 1.648143186225891, Training Uncertainty: 2.564924417114258, time: 196.47847294807434
Validation Loss: 1.658699686874819, Validation Uncertainty: 3.680355513492204, time: 46.07226085662842
Number of predictions within uncertainty interval: 112810/200000 (56.40%)

Epoch 65, Batch 100/3125, Loss: 2.023632287979126, Uncertainty: 2.4347991943359375
Epoch 65, Batch 200/3125, Loss: 1.866612434387207, Uncertainty: 2.2871532440185547
Epoch 65, Batch 300/3125, Loss: 1.891355037689209, Uncertainty: 2.184901237487793
Epoch 65, Batch 400/3125, Loss: 2.1984660625457764, Uncertainty: 2.581468105316162
Epoch 65, Batch 500/3125, Loss: 1.9459315538406372, Uncertainty: 2.059974193572998
Epoch 65, Batch 600/3125, Loss: 2.0342471599578857, Uncertainty: 2.519953489303589
Epoch 65, Batch 700/3125, Loss: 1.890289306640625, Uncertainty: 2.2317068576812744
Epoch 65, Batch 800/3125, Loss: 2.858616352081299, Uncertainty: 2.1156039237976074
Epoch 65, Batch 900/3125, Loss: 2.093986988067627, Uncertainty: 2.3165693283081055
Epoch 65, Batch 1000/3125, Loss: 2.430500030517578, Uncertainty: 4.038819789886475
Epoch 65, Batch 1100/3125, Loss: 2.1384053230285645, Uncertainty: 2.6259448528289795
Epoch 65, Batch 1200/3125, Loss: 2.6782097816467285, Uncertainty: 4.0444793701171875
Epoch 65, Batch 1300/3125, Loss: 1.9657025337219238, Uncertainty: 2.61719012260437
Epoch 65, Batch 1400/3125, Loss: 2.356581687927246, Uncertainty: 3.8053319454193115
Epoch 65, Batch 1500/3125, Loss: 1.9511089324951172, Uncertainty: 2.1487412452697754
Epoch 65, Batch 1600/3125, Loss: 2.0847980976104736, Uncertainty: 2.5600051879882812
Epoch 65, Batch 1700/3125, Loss: 2.0185799598693848, Uncertainty: 2.8429667949676514
Epoch 65, Batch 1800/3125, Loss: 2.024174690246582, Uncertainty: 2.2415213584899902
Epoch 65, Batch 1900/3125, Loss: 1.8612715005874634, Uncertainty: 2.5008702278137207
Epoch 65, Batch 2000/3125, Loss: 1.9395852088928223, Uncertainty: 2.3599867820739746
Epoch 65, Batch 2100/3125, Loss: 2.3063416481018066, Uncertainty: 2.7751405239105225
Epoch 65, Batch 2200/3125, Loss: 1.7549901008605957, Uncertainty: 1.8680649995803833
Epoch 65, Batch 2300/3125, Loss: 1.6665217876434326, Uncertainty: 1.9679521322250366
Epoch 65, Batch 2400/3125, Loss: 1.7699940204620361, Uncertainty: 2.0189170837402344
Epoch 65, Batch 2500/3125, Loss: 2.0836267471313477, Uncertainty: 2.412297487258911
Epoch 65, Batch 2600/3125, Loss: 2.0296058654785156, Uncertainty: 2.1273112297058105
Epoch 65, Batch 2700/3125, Loss: 2.069720983505249, Uncertainty: 2.551112174987793
Epoch 65, Batch 2800/3125, Loss: 2.0346717834472656, Uncertainty: 2.82437801361084
Epoch 65, Batch 2900/3125, Loss: 1.7525298595428467, Uncertainty: 2.1677255630493164
Epoch 65, Batch 3000/3125, Loss: 2.095749855041504, Uncertainty: 2.854557752609253
Epoch 65, Batch 3100/3125, Loss: 1.9736541509628296, Uncertainty: 1.9887100458145142

Training and Validation Results of Epoch 65:
================================
Training Loss: 1.6156101150894164, Training Uncertainty: 2.553457320404053, time: 201.48750472068787
Validation Loss: 1.4350603283823604, Validation Uncertainty: 3.675820286926406, time: 46.07418131828308
Number of predictions within uncertainty interval: 129558/200000 (64.78%)

Epoch 66, Batch 100/3125, Loss: 1.9256465435028076, Uncertainty: 2.110682964324951
Epoch 66, Batch 200/3125, Loss: 2.0527524948120117, Uncertainty: 3.056520462036133
Epoch 66, Batch 300/3125, Loss: 1.9353394508361816, Uncertainty: 2.53507661819458
Epoch 66, Batch 400/3125, Loss: 1.8912851810455322, Uncertainty: 2.2288763523101807
Epoch 66, Batch 500/3125, Loss: 2.2599267959594727, Uncertainty: 2.939824342727661
Epoch 66, Batch 600/3125, Loss: 2.4383983612060547, Uncertainty: 3.24558162689209
Epoch 66, Batch 700/3125, Loss: 2.23573899269104, Uncertainty: 2.505882978439331
Epoch 66, Batch 800/3125, Loss: 2.051631450653076, Uncertainty: 2.935736656188965
Epoch 66, Batch 900/3125, Loss: 2.018439769744873, Uncertainty: 2.5702595710754395
Epoch 66, Batch 1000/3125, Loss: 2.7418899536132812, Uncertainty: 3.6798932552337646
Epoch 66, Batch 1100/3125, Loss: 2.0953187942504883, Uncertainty: 2.8192625045776367
Epoch 66, Batch 1200/3125, Loss: 3.4118337631225586, Uncertainty: 2.0512020587921143
Epoch 66, Batch 1300/3125, Loss: 1.765658974647522, Uncertainty: 2.1067562103271484
Epoch 66, Batch 1400/3125, Loss: 2.1401076316833496, Uncertainty: 2.332692861557007
Epoch 66, Batch 1500/3125, Loss: 2.373904228210449, Uncertainty: 2.8256893157958984
Epoch 66, Batch 1600/3125, Loss: 1.9136085510253906, Uncertainty: 2.22786808013916
Epoch 66, Batch 1700/3125, Loss: 1.8548353910446167, Uncertainty: 2.0648653507232666
Epoch 66, Batch 1800/3125, Loss: 1.957456350326538, Uncertainty: 2.6089606285095215
Epoch 66, Batch 1900/3125, Loss: 2.113337516784668, Uncertainty: 2.515868663787842
Epoch 66, Batch 2000/3125, Loss: 1.9348961114883423, Uncertainty: 2.0620908737182617
Epoch 66, Batch 2100/3125, Loss: 1.9817123413085938, Uncertainty: 2.450618267059326
Epoch 66, Batch 2200/3125, Loss: 2.1464314460754395, Uncertainty: 2.404853582382202
Epoch 66, Batch 2300/3125, Loss: 2.059570074081421, Uncertainty: 2.488440752029419
Epoch 66, Batch 2400/3125, Loss: 2.4143688678741455, Uncertainty: 2.3557097911834717
Epoch 66, Batch 2500/3125, Loss: 1.741333246231079, Uncertainty: 2.068666696548462
Epoch 66, Batch 2600/3125, Loss: 1.9183380603790283, Uncertainty: 2.4061450958251953
Epoch 66, Batch 2700/3125, Loss: 1.9015681743621826, Uncertainty: 1.9597289562225342
Epoch 66, Batch 2800/3125, Loss: 2.3930439949035645, Uncertainty: 2.277498960494995
Epoch 66, Batch 2900/3125, Loss: 2.035078525543213, Uncertainty: 2.8128445148468018
Epoch 66, Batch 3000/3125, Loss: 2.2178750038146973, Uncertainty: 1.9713886976242065
Epoch 66, Batch 3100/3125, Loss: 2.0082011222839355, Uncertainty: 2.6426453590393066

Training and Validation Results of Epoch 66:
================================
Training Loss: 1.680243546257019, Training Uncertainty: 2.6964046690368653, time: 200.89253067970276
Validation Loss: 1.2847898416506969, Validation Uncertainty: 3.4320200306680197, time: 45.933568477630615
Number of predictions within uncertainty interval: 131022/200000 (65.51%)

Epoch 67, Batch 100/3125, Loss: 1.704782485961914, Uncertainty: 2.3732080459594727
Epoch 67, Batch 200/3125, Loss: 1.8199154138565063, Uncertainty: 2.1241443157196045
Epoch 67, Batch 300/3125, Loss: 2.153653860092163, Uncertainty: 2.4197893142700195
Epoch 67, Batch 400/3125, Loss: 1.9171178340911865, Uncertainty: 2.576651096343994
Epoch 67, Batch 500/3125, Loss: 2.094322919845581, Uncertainty: 2.780144691467285
Epoch 67, Batch 600/3125, Loss: 2.1976680755615234, Uncertainty: 3.2480573654174805
Epoch 67, Batch 700/3125, Loss: 2.9019229412078857, Uncertainty: 2.5883498191833496
Epoch 67, Batch 800/3125, Loss: 1.7880022525787354, Uncertainty: 2.126741409301758
Epoch 67, Batch 900/3125, Loss: 1.7851977348327637, Uncertainty: 2.223975658416748
Epoch 67, Batch 1000/3125, Loss: 2.0350568294525146, Uncertainty: 2.9695825576782227
Epoch 67, Batch 1100/3125, Loss: 1.8936522006988525, Uncertainty: 2.2102952003479004
Epoch 67, Batch 1200/3125, Loss: 1.8537492752075195, Uncertainty: 2.4057679176330566
Epoch 67, Batch 1300/3125, Loss: 1.7630565166473389, Uncertainty: 2.157560348510742
Epoch 67, Batch 1400/3125, Loss: 1.9489004611968994, Uncertainty: 2.7176833152770996
Epoch 67, Batch 1500/3125, Loss: 1.9697935581207275, Uncertainty: 2.144705295562744
Epoch 67, Batch 1600/3125, Loss: 1.7717173099517822, Uncertainty: 1.8312698602676392
Epoch 67, Batch 1700/3125, Loss: 1.8307623863220215, Uncertainty: 2.1734652519226074
Epoch 67, Batch 1800/3125, Loss: 1.884055495262146, Uncertainty: 2.4023079872131348
Epoch 67, Batch 1900/3125, Loss: 2.1699087619781494, Uncertainty: 2.0155465602874756
Epoch 67, Batch 2000/3125, Loss: 1.7259392738342285, Uncertainty: 2.07143497467041
Epoch 67, Batch 2100/3125, Loss: 1.9540871381759644, Uncertainty: 2.0188097953796387
Epoch 67, Batch 2200/3125, Loss: 2.3669233322143555, Uncertainty: 2.0851094722747803
Epoch 67, Batch 2300/3125, Loss: 1.8884642124176025, Uncertainty: 2.3548383712768555
Epoch 67, Batch 2400/3125, Loss: 2.4560651779174805, Uncertainty: 3.6949386596679688
Epoch 67, Batch 2500/3125, Loss: 1.9309407472610474, Uncertainty: 2.6481423377990723
Epoch 67, Batch 2600/3125, Loss: 1.8800565004348755, Uncertainty: 1.995113730430603
Epoch 67, Batch 2700/3125, Loss: 1.9612243175506592, Uncertainty: 2.814417839050293
Epoch 67, Batch 2800/3125, Loss: 2.0944740772247314, Uncertainty: 2.062403917312622
Epoch 67, Batch 2900/3125, Loss: 1.9277923107147217, Uncertainty: 2.2900214195251465
Epoch 67, Batch 3000/3125, Loss: 1.9528543949127197, Uncertainty: 2.746041774749756
Epoch 67, Batch 3100/3125, Loss: 2.146365165710449, Uncertainty: 2.52917742729187

Training and Validation Results of Epoch 67:
================================
Training Loss: 1.5806139925765992, Training Uncertainty: 2.5275261629104615, time: 198.7818968296051
Validation Loss: 1.2583405946374244, Validation Uncertainty: 3.546974064444032, time: 45.94118142127991
Number of predictions within uncertainty interval: 136220/200000 (68.11%)

Epoch 68, Batch 100/3125, Loss: 1.8289589881896973, Uncertainty: 2.2345666885375977
Epoch 68, Batch 200/3125, Loss: 1.7368648052215576, Uncertainty: 2.2363553047180176
Epoch 68, Batch 300/3125, Loss: 1.6035364866256714, Uncertainty: 1.8736729621887207
Epoch 68, Batch 400/3125, Loss: 1.8262391090393066, Uncertainty: 2.307098865509033
Epoch 68, Batch 500/3125, Loss: 1.709686279296875, Uncertainty: 1.8990364074707031
Epoch 68, Batch 600/3125, Loss: 1.9443275928497314, Uncertainty: 2.3576228618621826
Epoch 68, Batch 700/3125, Loss: 1.8220621347427368, Uncertainty: 2.3057339191436768
Epoch 68, Batch 800/3125, Loss: 1.6197822093963623, Uncertainty: 2.120126485824585
Epoch 68, Batch 900/3125, Loss: 2.527282476425171, Uncertainty: 2.014435291290283
Epoch 68, Batch 1000/3125, Loss: 1.8739337921142578, Uncertainty: 2.2358367443084717
Epoch 68, Batch 1100/3125, Loss: 2.1525661945343018, Uncertainty: 2.664278268814087
Epoch 68, Batch 1200/3125, Loss: 2.4999608993530273, Uncertainty: 4.021078109741211
Epoch 68, Batch 1300/3125, Loss: 2.2249369621276855, Uncertainty: 2.7010674476623535
Epoch 68, Batch 1400/3125, Loss: 1.6667308807373047, Uncertainty: 1.9549319744110107
Epoch 68, Batch 1500/3125, Loss: 1.8890472650527954, Uncertainty: 2.5191502571105957
Epoch 68, Batch 1600/3125, Loss: 1.884793996810913, Uncertainty: 1.8752708435058594
Epoch 68, Batch 1700/3125, Loss: 1.9186365604400635, Uncertainty: 2.2654855251312256
Epoch 68, Batch 1800/3125, Loss: 2.2495527267456055, Uncertainty: 2.9879462718963623
Epoch 68, Batch 1900/3125, Loss: 1.710207462310791, Uncertainty: 2.3577775955200195
Epoch 68, Batch 2000/3125, Loss: 1.961471676826477, Uncertainty: 2.404209852218628
Epoch 68, Batch 2100/3125, Loss: 2.161844253540039, Uncertainty: 2.8201160430908203
Epoch 68, Batch 2200/3125, Loss: 1.9399282932281494, Uncertainty: 2.5795302391052246
Epoch 68, Batch 2300/3125, Loss: 1.7620465755462646, Uncertainty: 2.215294361114502
Epoch 68, Batch 2400/3125, Loss: 2.64346981048584, Uncertainty: 4.316713333129883
Epoch 68, Batch 2500/3125, Loss: 1.6111705303192139, Uncertainty: 2.121316909790039
Epoch 68, Batch 2600/3125, Loss: 2.168977737426758, Uncertainty: 2.6212313175201416
Epoch 68, Batch 2700/3125, Loss: 1.753828525543213, Uncertainty: 1.9326553344726562
Epoch 68, Batch 2800/3125, Loss: 1.8493722677230835, Uncertainty: 2.41257381439209
Epoch 68, Batch 2900/3125, Loss: 1.9996252059936523, Uncertainty: 2.182037830352783
Epoch 68, Batch 3000/3125, Loss: 2.077718734741211, Uncertainty: 1.9667320251464844
Epoch 68, Batch 3100/3125, Loss: 1.925980806350708, Uncertainty: 2.115753173828125

Training and Validation Results of Epoch 68:
================================
Training Loss: 1.5624122694778442, Training Uncertainty: 2.50491601272583, time: 200.87300753593445
Validation Loss: 1.2707564330771757, Validation Uncertainty: 3.575873662748605, time: 44.81754922866821
Number of predictions within uncertainty interval: 136518/200000 (68.26%)

Epoch 69, Batch 100/3125, Loss: 1.6489686965942383, Uncertainty: 1.9026111364364624
Epoch 69, Batch 200/3125, Loss: 1.924034595489502, Uncertainty: 2.6264514923095703
Epoch 69, Batch 300/3125, Loss: 1.9255059957504272, Uncertainty: 2.4043984413146973
Epoch 69, Batch 400/3125, Loss: 1.790711522102356, Uncertainty: 2.437265634536743
Epoch 69, Batch 500/3125, Loss: 1.9048259258270264, Uncertainty: 1.916082501411438
Epoch 69, Batch 600/3125, Loss: 2.0714526176452637, Uncertainty: 2.706235885620117
Epoch 69, Batch 700/3125, Loss: 1.6393582820892334, Uncertainty: 2.051121711730957
Epoch 69, Batch 800/3125, Loss: 2.793081283569336, Uncertainty: 5.046627521514893
Epoch 69, Batch 900/3125, Loss: 2.096235513687134, Uncertainty: 2.0865023136138916
Epoch 69, Batch 1000/3125, Loss: 1.867074728012085, Uncertainty: 2.6928954124450684
Epoch 69, Batch 1100/3125, Loss: 2.069906234741211, Uncertainty: 2.84652042388916
Epoch 69, Batch 1200/3125, Loss: 2.212855815887451, Uncertainty: 2.0174689292907715
Epoch 69, Batch 1300/3125, Loss: 1.7891356945037842, Uncertainty: 1.870971441268921
Epoch 69, Batch 1400/3125, Loss: 1.964365005493164, Uncertainty: 2.8970534801483154
Epoch 69, Batch 1500/3125, Loss: 2.310502290725708, Uncertainty: 2.35642671585083
Epoch 69, Batch 1600/3125, Loss: 1.9357330799102783, Uncertainty: 2.4985833168029785
Epoch 69, Batch 1700/3125, Loss: 1.9958348274230957, Uncertainty: 2.664022445678711
Epoch 69, Batch 1800/3125, Loss: 2.2269277572631836, Uncertainty: 2.860050678253174
Epoch 69, Batch 1900/3125, Loss: 1.9040136337280273, Uncertainty: 2.160893201828003
Epoch 69, Batch 2000/3125, Loss: 2.3554701805114746, Uncertainty: 3.0611484050750732
Epoch 69, Batch 2100/3125, Loss: 1.8185170888900757, Uncertainty: 2.089512825012207
Epoch 69, Batch 2200/3125, Loss: 1.7767202854156494, Uncertainty: 1.8616639375686646
Epoch 69, Batch 2300/3125, Loss: 1.961626648902893, Uncertainty: 2.251368522644043
Epoch 69, Batch 2400/3125, Loss: 2.0784854888916016, Uncertainty: 3.0922749042510986
Epoch 69, Batch 2500/3125, Loss: 1.829524278640747, Uncertainty: 2.4457027912139893
Epoch 69, Batch 2600/3125, Loss: 1.9364650249481201, Uncertainty: 2.585522174835205
Epoch 69, Batch 2700/3125, Loss: 1.648940086364746, Uncertainty: 2.0362136363983154
Epoch 69, Batch 2800/3125, Loss: 2.156259536743164, Uncertainty: 2.349803924560547
Epoch 69, Batch 2900/3125, Loss: 1.9632866382598877, Uncertainty: 2.79677677154541
Epoch 69, Batch 3000/3125, Loss: 1.8286904096603394, Uncertainty: 2.1522958278656006
Epoch 69, Batch 3100/3125, Loss: 2.298999786376953, Uncertainty: 3.0406477451324463

Training and Validation Results of Epoch 69:
================================
Training Loss: 1.5493485611724853, Training Uncertainty: 2.49906098815918, time: 197.45203971862793
Validation Loss: 1.4057904693781567, Validation Uncertainty: 3.8933624513923664, time: 46.384512186050415
Number of predictions within uncertainty interval: 135678/200000 (67.84%)

Epoch 70, Batch 100/3125, Loss: 1.7395126819610596, Uncertainty: 2.019008159637451
Epoch 70, Batch 200/3125, Loss: 2.1449670791625977, Uncertainty: 3.424999237060547
Epoch 70, Batch 300/3125, Loss: 2.012629508972168, Uncertainty: 3.1067957878112793
Epoch 70, Batch 400/3125, Loss: 1.5506515502929688, Uncertainty: 2.1914238929748535
Epoch 70, Batch 500/3125, Loss: 2.149413585662842, Uncertainty: 3.274078607559204
Epoch 70, Batch 600/3125, Loss: 2.0447258949279785, Uncertainty: 3.003849506378174
Epoch 70, Batch 700/3125, Loss: 2.0598678588867188, Uncertainty: 2.804774761199951
Epoch 70, Batch 800/3125, Loss: 1.6475393772125244, Uncertainty: 1.9450697898864746
Epoch 70, Batch 900/3125, Loss: 2.0970702171325684, Uncertainty: 2.7985129356384277
Epoch 70, Batch 1000/3125, Loss: 1.7422878742218018, Uncertainty: 2.1131885051727295
Epoch 70, Batch 1100/3125, Loss: 1.9654366970062256, Uncertainty: 2.5959668159484863
Epoch 70, Batch 1200/3125, Loss: 1.6262457370758057, Uncertainty: 1.9989842176437378
Epoch 70, Batch 1300/3125, Loss: 1.6608905792236328, Uncertainty: 1.995404601097107
Epoch 70, Batch 1400/3125, Loss: 2.069174289703369, Uncertainty: 2.2120304107666016
Epoch 70, Batch 1500/3125, Loss: 1.771898627281189, Uncertainty: 2.2191030979156494
Epoch 70, Batch 1600/3125, Loss: 2.020113468170166, Uncertainty: 2.149160861968994
Epoch 70, Batch 1700/3125, Loss: 2.233652114868164, Uncertainty: 2.317760467529297
Epoch 70, Batch 1800/3125, Loss: 1.8041472434997559, Uncertainty: 2.1179251670837402
Epoch 70, Batch 1900/3125, Loss: 1.6070932149887085, Uncertainty: 2.1147849559783936
Epoch 70, Batch 2000/3125, Loss: 2.009157180786133, Uncertainty: 2.802673816680908
Epoch 70, Batch 2100/3125, Loss: 2.1531002521514893, Uncertainty: 2.725325107574463
Epoch 70, Batch 2200/3125, Loss: 1.887685775756836, Uncertainty: 2.762181282043457
Epoch 70, Batch 2300/3125, Loss: 1.877634882926941, Uncertainty: 2.2060189247131348
Epoch 70, Batch 2400/3125, Loss: 1.9675703048706055, Uncertainty: 3.0591063499450684
Epoch 70, Batch 2500/3125, Loss: 1.9113726615905762, Uncertainty: 2.3437366485595703
Epoch 70, Batch 2600/3125, Loss: 2.174750804901123, Uncertainty: 3.066147804260254
Epoch 70, Batch 2700/3125, Loss: 1.810801386833191, Uncertainty: 2.3704874515533447
Epoch 70, Batch 2800/3125, Loss: 1.9525810480117798, Uncertainty: 2.3268542289733887
Epoch 70, Batch 2900/3125, Loss: 2.062533378601074, Uncertainty: 2.0390658378601074
Epoch 70, Batch 3000/3125, Loss: 1.8783856630325317, Uncertainty: 2.481611728668213
Epoch 70, Batch 3100/3125, Loss: 1.8751280307769775, Uncertainty: 2.3105697631835938

Training and Validation Results of Epoch 70:
================================
Training Loss: 1.5241166030883788, Training Uncertainty: 2.4927508548355104, time: 198.4383203983307
Validation Loss: 1.178288832726076, Validation Uncertainty: 3.43194261841152, time: 47.80907082557678
Number of predictions within uncertainty interval: 136727/200000 (68.36%)

Epoch 71, Batch 100/3125, Loss: 1.737015724182129, Uncertainty: 2.1619300842285156
Epoch 71, Batch 200/3125, Loss: 1.5952000617980957, Uncertainty: 1.894909143447876
Epoch 71, Batch 300/3125, Loss: 1.651541829109192, Uncertainty: 2.0403048992156982
Epoch 71, Batch 400/3125, Loss: 1.798271656036377, Uncertainty: 2.1125073432922363
Epoch 71, Batch 500/3125, Loss: 1.943427324295044, Uncertainty: 2.6997783184051514
Epoch 71, Batch 600/3125, Loss: 2.441673755645752, Uncertainty: 2.0326197147369385
Epoch 71, Batch 700/3125, Loss: 2.045745372772217, Uncertainty: 2.773143768310547
Epoch 71, Batch 800/3125, Loss: 1.8537750244140625, Uncertainty: 1.91641366481781
Epoch 71, Batch 900/3125, Loss: 2.506351947784424, Uncertainty: 3.906670570373535
Epoch 71, Batch 1000/3125, Loss: 1.957777976989746, Uncertainty: 2.424038887023926
Epoch 71, Batch 1100/3125, Loss: 1.8301682472229004, Uncertainty: 2.12315034866333
Epoch 71, Batch 1200/3125, Loss: 2.3780713081359863, Uncertainty: 3.720533847808838
Epoch 71, Batch 1300/3125, Loss: 1.636336326599121, Uncertainty: 2.218427896499634
Epoch 71, Batch 1400/3125, Loss: 2.179215431213379, Uncertainty: 3.1157166957855225
Epoch 71, Batch 1500/3125, Loss: 1.8781101703643799, Uncertainty: 2.376459836959839
Epoch 71, Batch 1600/3125, Loss: 1.685295581817627, Uncertainty: 2.0221829414367676
Epoch 71, Batch 1700/3125, Loss: 1.7887574434280396, Uncertainty: 2.151639461517334
Epoch 71, Batch 1800/3125, Loss: 1.791114330291748, Uncertainty: 1.8982969522476196
Epoch 71, Batch 1900/3125, Loss: 2.020565986633301, Uncertainty: 2.961890459060669
Epoch 71, Batch 2000/3125, Loss: 2.048111915588379, Uncertainty: 2.7451236248016357
Epoch 71, Batch 2100/3125, Loss: 2.1221351623535156, Uncertainty: 2.20515513420105
Epoch 71, Batch 2200/3125, Loss: 2.270164966583252, Uncertainty: 3.413407564163208
Epoch 71, Batch 2300/3125, Loss: 2.0810859203338623, Uncertainty: 2.9167981147766113
Epoch 71, Batch 2400/3125, Loss: 2.101564884185791, Uncertainty: 2.7838187217712402
Epoch 71, Batch 2500/3125, Loss: 1.9483822584152222, Uncertainty: 2.55924391746521
Epoch 71, Batch 2600/3125, Loss: 1.8902698755264282, Uncertainty: 2.366272449493408
Epoch 71, Batch 2700/3125, Loss: 1.8619837760925293, Uncertainty: 2.7058167457580566
Epoch 71, Batch 2800/3125, Loss: 1.9594626426696777, Uncertainty: 2.6291213035583496
Epoch 71, Batch 2900/3125, Loss: 1.9405770301818848, Uncertainty: 2.798886775970459
Epoch 71, Batch 3000/3125, Loss: 1.6923449039459229, Uncertainty: 1.9767749309539795
Epoch 71, Batch 3100/3125, Loss: 1.9336426258087158, Uncertainty: 2.2214975357055664

Training and Validation Results of Epoch 71:
================================
Training Loss: 1.5184201970291138, Training Uncertainty: 2.4730508864974974, time: 198.92479848861694
Validation Loss: 1.2171286522884808, Validation Uncertainty: 3.650328135551394, time: 45.87095665931702
Number of predictions within uncertainty interval: 142244/200000 (71.12%)

Epoch 72, Batch 100/3125, Loss: 1.9328372478485107, Uncertainty: 3.0537610054016113
Epoch 72, Batch 200/3125, Loss: 2.107027530670166, Uncertainty: 3.0426437854766846
Epoch 72, Batch 300/3125, Loss: 1.767134428024292, Uncertainty: 2.187990188598633
Epoch 72, Batch 400/3125, Loss: 1.6635607481002808, Uncertainty: 1.9900836944580078
Epoch 72, Batch 500/3125, Loss: 2.053460121154785, Uncertainty: 1.9736158847808838
Epoch 72, Batch 600/3125, Loss: 1.9946274757385254, Uncertainty: 2.6156530380249023
Epoch 72, Batch 700/3125, Loss: 1.5713356733322144, Uncertainty: 1.94682776927948
Epoch 72, Batch 800/3125, Loss: 1.9768354892730713, Uncertainty: 2.413301944732666
Epoch 72, Batch 900/3125, Loss: 1.6878876686096191, Uncertainty: 2.2746379375457764
Epoch 72, Batch 1000/3125, Loss: 1.8372923135757446, Uncertainty: 1.8929359912872314
Epoch 72, Batch 1100/3125, Loss: 1.807121753692627, Uncertainty: 2.1677117347717285
Epoch 72, Batch 1200/3125, Loss: 2.0214128494262695, Uncertainty: 2.8246817588806152
Epoch 72, Batch 1300/3125, Loss: 1.7657105922698975, Uncertainty: 1.9409089088439941
Epoch 72, Batch 1400/3125, Loss: 2.1613550186157227, Uncertainty: 2.980294942855835
Epoch 72, Batch 1500/3125, Loss: 2.1570374965667725, Uncertainty: 3.532402992248535
Epoch 72, Batch 1600/3125, Loss: 1.902065634727478, Uncertainty: 2.3389248847961426
Epoch 72, Batch 1700/3125, Loss: 2.2307400703430176, Uncertainty: 2.970874071121216
Epoch 72, Batch 1800/3125, Loss: 1.9392911195755005, Uncertainty: 2.5402920246124268
Epoch 72, Batch 1900/3125, Loss: 1.5856505632400513, Uncertainty: 1.9754176139831543
Epoch 72, Batch 2000/3125, Loss: 2.4600167274475098, Uncertainty: 2.8753063678741455
Epoch 72, Batch 2100/3125, Loss: 2.3403706550598145, Uncertainty: 3.448894500732422
Epoch 72, Batch 2200/3125, Loss: 2.0588765144348145, Uncertainty: 3.0780715942382812
Epoch 72, Batch 2300/3125, Loss: 1.8430708646774292, Uncertainty: 2.4849441051483154
Epoch 72, Batch 2400/3125, Loss: 1.7484647035598755, Uncertainty: 2.031137704849243
Epoch 72, Batch 2500/3125, Loss: 1.723660945892334, Uncertainty: 2.1634464263916016
Epoch 72, Batch 2600/3125, Loss: 1.975428819656372, Uncertainty: 2.0592634677886963
Epoch 72, Batch 2700/3125, Loss: 1.7945019006729126, Uncertainty: 2.1314187049865723
Epoch 72, Batch 2800/3125, Loss: 1.9476368427276611, Uncertainty: 2.806459665298462
Epoch 72, Batch 2900/3125, Loss: 1.7298381328582764, Uncertainty: 2.2201955318450928
Epoch 72, Batch 3000/3125, Loss: 1.869401454925537, Uncertainty: 2.5167503356933594
Epoch 72, Batch 3100/3125, Loss: 2.209798574447632, Uncertainty: 2.195427179336548

Training and Validation Results of Epoch 72:
================================
Training Loss: 1.5054926837158202, Training Uncertainty: 2.445325523109436, time: 204.82686853408813
Validation Loss: 1.4382636412940062, Validation Uncertainty: 3.3254672511459313, time: 44.9696147441864
Number of predictions within uncertainty interval: 116182/200000 (58.09%)

Epoch 73, Batch 100/3125, Loss: 1.932377815246582, Uncertainty: 1.8428711891174316
Epoch 73, Batch 200/3125, Loss: 1.6142082214355469, Uncertainty: 1.8575090169906616
Epoch 73, Batch 300/3125, Loss: 1.6716840267181396, Uncertainty: 2.2172043323516846
Epoch 73, Batch 400/3125, Loss: 1.5603151321411133, Uncertainty: 2.0230846405029297
Epoch 73, Batch 500/3125, Loss: 1.605576992034912, Uncertainty: 2.0367820262908936
Epoch 73, Batch 600/3125, Loss: 1.8182823657989502, Uncertainty: 2.0935821533203125
Epoch 73, Batch 700/3125, Loss: 1.7191917896270752, Uncertainty: 2.076535224914551
Epoch 73, Batch 800/3125, Loss: 1.6274802684783936, Uncertainty: 1.9318974018096924
Epoch 73, Batch 900/3125, Loss: 2.567345142364502, Uncertainty: 3.5999507904052734
Epoch 73, Batch 1000/3125, Loss: 1.6489324569702148, Uncertainty: 2.2035064697265625
Epoch 73, Batch 1100/3125, Loss: 2.0884058475494385, Uncertainty: 2.705961227416992
Epoch 73, Batch 1200/3125, Loss: 2.4552342891693115, Uncertainty: 3.7254786491394043
Epoch 73, Batch 1300/3125, Loss: 2.1386165618896484, Uncertainty: 1.7336809635162354
Epoch 73, Batch 1400/3125, Loss: 2.0922019481658936, Uncertainty: 2.7050318717956543
Epoch 73, Batch 1500/3125, Loss: 2.0692906379699707, Uncertainty: 2.9233875274658203
Epoch 73, Batch 1600/3125, Loss: 1.8966524600982666, Uncertainty: 2.5759971141815186
Epoch 73, Batch 1700/3125, Loss: 1.7577569484710693, Uncertainty: 1.9389266967773438
Epoch 73, Batch 1800/3125, Loss: 1.973425030708313, Uncertainty: 2.583314895629883
Epoch 73, Batch 1900/3125, Loss: 1.839076042175293, Uncertainty: 2.2346749305725098
Epoch 73, Batch 2000/3125, Loss: 2.313654899597168, Uncertainty: 3.495968818664551
Epoch 73, Batch 2100/3125, Loss: 2.2097911834716797, Uncertainty: 3.3313426971435547
Epoch 73, Batch 2200/3125, Loss: 1.9867606163024902, Uncertainty: 2.5396718978881836
Epoch 73, Batch 2300/3125, Loss: 2.1009790897369385, Uncertainty: 3.2567038536071777
Epoch 73, Batch 2400/3125, Loss: 2.15492844581604, Uncertainty: 3.476881504058838
Epoch 73, Batch 2500/3125, Loss: 1.7406988143920898, Uncertainty: 2.147902488708496
Epoch 73, Batch 2600/3125, Loss: 1.8756632804870605, Uncertainty: 2.00083065032959
Epoch 73, Batch 2700/3125, Loss: 1.7264935970306396, Uncertainty: 2.211897134780884
Epoch 73, Batch 2800/3125, Loss: 1.6294636726379395, Uncertainty: 2.101034164428711
Epoch 73, Batch 2900/3125, Loss: 1.5380011796951294, Uncertainty: 1.7607624530792236
Epoch 73, Batch 3000/3125, Loss: 1.7810367345809937, Uncertainty: 2.0280075073242188
Epoch 73, Batch 3100/3125, Loss: 1.6469849348068237, Uncertainty: 1.7166138887405396

Training and Validation Results of Epoch 73:
================================
Training Loss: 1.4866623751068115, Training Uncertainty: 2.4179259510040283, time: 199.12367939949036
Validation Loss: 1.2267631344173267, Validation Uncertainty: 3.8925788085478956, time: 45.3048300743103
Number of predictions within uncertainty interval: 146214/200000 (73.11%)

Epoch 74, Batch 100/3125, Loss: 1.4720534086227417, Uncertainty: 1.792698621749878
Epoch 74, Batch 200/3125, Loss: 1.5428612232208252, Uncertainty: 1.8766201734542847
Epoch 74, Batch 300/3125, Loss: 2.055176019668579, Uncertainty: 2.609886646270752
Epoch 74, Batch 400/3125, Loss: 1.6750357151031494, Uncertainty: 2.4754414558410645
Epoch 74, Batch 500/3125, Loss: 1.7831158638000488, Uncertainty: 2.566744327545166
Epoch 74, Batch 600/3125, Loss: 2.1033310890197754, Uncertainty: 2.8789477348327637
Epoch 74, Batch 700/3125, Loss: 5.982473373413086, Uncertainty: 10.051568984985352
Epoch 74, Batch 800/3125, Loss: 1.8555924892425537, Uncertainty: 1.8984761238098145
Epoch 74, Batch 900/3125, Loss: 2.7612760066986084, Uncertainty: 2.395907402038574
Epoch 74, Batch 1000/3125, Loss: 1.8885016441345215, Uncertainty: 2.3612794876098633
Epoch 74, Batch 1100/3125, Loss: 1.8566851615905762, Uncertainty: 2.190922975540161
Epoch 74, Batch 1200/3125, Loss: 2.053694725036621, Uncertainty: 2.6697120666503906
Epoch 74, Batch 1300/3125, Loss: 1.7757598161697388, Uncertainty: 2.352700710296631
Epoch 74, Batch 1400/3125, Loss: 1.724718451499939, Uncertainty: 2.285813570022583
Epoch 74, Batch 1500/3125, Loss: 1.9285876750946045, Uncertainty: 2.3032126426696777
Epoch 74, Batch 1600/3125, Loss: 1.928251028060913, Uncertainty: 2.308579206466675
Epoch 74, Batch 1700/3125, Loss: 1.887511134147644, Uncertainty: 2.451826572418213
Epoch 74, Batch 1800/3125, Loss: 2.4084701538085938, Uncertainty: 2.7891478538513184
Epoch 74, Batch 1900/3125, Loss: 1.6300454139709473, Uncertainty: 2.095142364501953
Epoch 74, Batch 2000/3125, Loss: 1.8031377792358398, Uncertainty: 2.5137007236480713
Epoch 74, Batch 2100/3125, Loss: 2.898754119873047, Uncertainty: 3.3003129959106445
Epoch 74, Batch 2200/3125, Loss: 1.7547056674957275, Uncertainty: 2.0736074447631836
Epoch 74, Batch 2300/3125, Loss: 2.7914047241210938, Uncertainty: 2.1263744831085205
Epoch 74, Batch 2400/3125, Loss: 1.8621830940246582, Uncertainty: 2.7583107948303223
Epoch 74, Batch 2500/3125, Loss: 1.7295658588409424, Uncertainty: 2.3809893131256104
Epoch 74, Batch 2600/3125, Loss: 1.6702797412872314, Uncertainty: 2.2094712257385254
Epoch 74, Batch 2700/3125, Loss: 1.9291363954544067, Uncertainty: 2.3704352378845215
Epoch 74, Batch 2800/3125, Loss: 1.8578972816467285, Uncertainty: 2.6229023933410645
Epoch 74, Batch 2900/3125, Loss: 1.8933850526809692, Uncertainty: 2.0590357780456543
Epoch 74, Batch 3000/3125, Loss: 2.278944969177246, Uncertainty: 2.528876304626465
Epoch 74, Batch 3100/3125, Loss: 1.6966389417648315, Uncertainty: 1.9375795125961304

Training and Validation Results of Epoch 74:
================================
Training Loss: 1.657731953239441, Training Uncertainty: 2.754146528892517, time: 196.8266487121582
Validation Loss: 1.2576153539025876, Validation Uncertainty: 3.7282922203888367, time: 45.37879252433777
Number of predictions within uncertainty interval: 139318/200000 (69.66%)

Epoch 75, Batch 100/3125, Loss: 2.128857135772705, Uncertainty: 1.7988122701644897
Epoch 75, Batch 200/3125, Loss: 2.4863715171813965, Uncertainty: 3.9305307865142822
Epoch 75, Batch 300/3125, Loss: 2.0050225257873535, Uncertainty: 3.162412643432617
Epoch 75, Batch 400/3125, Loss: 1.9452509880065918, Uncertainty: 2.0125041007995605
Epoch 75, Batch 500/3125, Loss: 1.7375209331512451, Uncertainty: 1.9971718788146973
Epoch 75, Batch 600/3125, Loss: 2.0196638107299805, Uncertainty: 2.904916286468506
Epoch 75, Batch 700/3125, Loss: 1.7347015142440796, Uncertainty: 2.3252758979797363
Epoch 75, Batch 800/3125, Loss: 1.6413512229919434, Uncertainty: 2.0563831329345703
Epoch 75, Batch 900/3125, Loss: 2.1311357021331787, Uncertainty: 3.220097541809082
Epoch 75, Batch 1000/3125, Loss: 1.5857939720153809, Uncertainty: 1.748600721359253
Epoch 75, Batch 1100/3125, Loss: 1.9667996168136597, Uncertainty: 2.4952216148376465
Epoch 75, Batch 1200/3125, Loss: 1.9502357244491577, Uncertainty: 2.858488082885742
Epoch 75, Batch 1300/3125, Loss: 1.6820422410964966, Uncertainty: 1.7774436473846436
Epoch 75, Batch 1400/3125, Loss: 1.7522168159484863, Uncertainty: 2.138334274291992
Epoch 75, Batch 1500/3125, Loss: 2.094249725341797, Uncertainty: 2.749673843383789
Epoch 75, Batch 1600/3125, Loss: 1.645045518875122, Uncertainty: 2.0658621788024902
Epoch 75, Batch 1700/3125, Loss: 1.6396607160568237, Uncertainty: 1.9750752449035645
Epoch 75, Batch 1800/3125, Loss: 2.1215128898620605, Uncertainty: 2.2732150554656982
Epoch 75, Batch 1900/3125, Loss: 1.660557746887207, Uncertainty: 2.377779960632324
Epoch 75, Batch 2000/3125, Loss: 1.692652702331543, Uncertainty: 2.1545937061309814
Epoch 75, Batch 2100/3125, Loss: 1.8181960582733154, Uncertainty: 2.2897794246673584
Epoch 75, Batch 2200/3125, Loss: 1.8338054418563843, Uncertainty: 2.0578393936157227
Epoch 75, Batch 2300/3125, Loss: 2.1136903762817383, Uncertainty: 2.7647500038146973
Epoch 75, Batch 2400/3125, Loss: 1.9187581539154053, Uncertainty: 2.2609329223632812
Epoch 75, Batch 2500/3125, Loss: 1.789156198501587, Uncertainty: 2.226963520050049
Epoch 75, Batch 2600/3125, Loss: 1.8679413795471191, Uncertainty: 2.7550482749938965
Epoch 75, Batch 2700/3125, Loss: 2.037043571472168, Uncertainty: 3.243173599243164
Epoch 75, Batch 2800/3125, Loss: 1.682142972946167, Uncertainty: 2.156959056854248
Epoch 75, Batch 2900/3125, Loss: 1.688039779663086, Uncertainty: 2.2381668090820312
Epoch 75, Batch 3000/3125, Loss: 2.2011468410491943, Uncertainty: 2.1576881408691406
Epoch 75, Batch 3100/3125, Loss: 1.6417477130889893, Uncertainty: 2.035097360610962

Training and Validation Results of Epoch 75:
================================
Training Loss: 1.4661931456184387, Training Uncertainty: 2.405030096092224, time: 198.7045612335205
Validation Loss: 1.271406756490088, Validation Uncertainty: 3.1010693128761426, time: 45.895740032196045
Number of predictions within uncertainty interval: 125985/200000 (62.99%)

Epoch 76, Batch 100/3125, Loss: 1.7301100492477417, Uncertainty: 1.8200010061264038
Epoch 76, Batch 200/3125, Loss: 1.5063393115997314, Uncertainty: 1.9058916568756104
Epoch 76, Batch 300/3125, Loss: 1.9882123470306396, Uncertainty: 2.9215621948242188
Epoch 76, Batch 400/3125, Loss: 1.7483153343200684, Uncertainty: 2.5509324073791504
Epoch 76, Batch 500/3125, Loss: 1.875005841255188, Uncertainty: 2.22544527053833
Epoch 76, Batch 600/3125, Loss: 1.7665358781814575, Uncertainty: 2.5685231685638428
Epoch 76, Batch 700/3125, Loss: 1.601640224456787, Uncertainty: 1.9276468753814697
Epoch 76, Batch 800/3125, Loss: 1.6762079000473022, Uncertainty: 1.9740822315216064
Epoch 76, Batch 900/3125, Loss: 1.782332420349121, Uncertainty: 2.0892393589019775
Epoch 76, Batch 1000/3125, Loss: 1.6275529861450195, Uncertainty: 1.9743400812149048
Epoch 76, Batch 1100/3125, Loss: 2.0241856575012207, Uncertainty: 2.7450437545776367
Epoch 76, Batch 1200/3125, Loss: 2.216306209564209, Uncertainty: 2.802342176437378
Epoch 76, Batch 1300/3125, Loss: 1.711430311203003, Uncertainty: 2.3302645683288574
Epoch 76, Batch 1400/3125, Loss: 2.648432970046997, Uncertainty: 2.445554256439209
Epoch 76, Batch 1500/3125, Loss: 2.2465133666992188, Uncertainty: 2.862272262573242
Epoch 76, Batch 1600/3125, Loss: 2.165541172027588, Uncertainty: 3.4819176197052
Epoch 76, Batch 1700/3125, Loss: 1.811711072921753, Uncertainty: 2.198317050933838
Epoch 76, Batch 1800/3125, Loss: 1.618776798248291, Uncertainty: 2.0617175102233887
Epoch 76, Batch 1900/3125, Loss: 2.1215476989746094, Uncertainty: 3.414005756378174
Epoch 76, Batch 2000/3125, Loss: 1.783003807067871, Uncertainty: 2.5527071952819824
Epoch 76, Batch 2100/3125, Loss: 2.2084150314331055, Uncertainty: 3.2473487854003906
Epoch 76, Batch 2200/3125, Loss: 2.0254483222961426, Uncertainty: 2.6835780143737793
Epoch 76, Batch 2300/3125, Loss: 1.8912763595581055, Uncertainty: 1.977308750152588
Epoch 76, Batch 2400/3125, Loss: 2.06851863861084, Uncertainty: 2.705059051513672
Epoch 76, Batch 2500/3125, Loss: 1.466275691986084, Uncertainty: 1.6971454620361328
Epoch 76, Batch 2600/3125, Loss: 2.189145565032959, Uncertainty: 2.94789981842041
Epoch 76, Batch 2700/3125, Loss: 2.02166748046875, Uncertainty: 2.4820168018341064
Epoch 76, Batch 2800/3125, Loss: 1.708363652229309, Uncertainty: 2.1303601264953613
Epoch 76, Batch 2900/3125, Loss: 1.5836999416351318, Uncertainty: 1.9962376356124878
Epoch 76, Batch 3000/3125, Loss: 1.8049118518829346, Uncertainty: 2.2177600860595703
Epoch 76, Batch 3100/3125, Loss: 1.8265025615692139, Uncertainty: 2.4323313236236572

Training and Validation Results of Epoch 76:
================================
Training Loss: 1.4507152907943726, Training Uncertainty: 2.3842724698638915, time: 199.53911638259888
Validation Loss: 1.1457949892791641, Validation Uncertainty: 3.476055684296981, time: 44.770230293273926
Number of predictions within uncertainty interval: 142365/200000 (71.18%)

Epoch 77, Batch 100/3125, Loss: 1.4475035667419434, Uncertainty: 1.850266456604004
Epoch 77, Batch 200/3125, Loss: 1.6264421939849854, Uncertainty: 2.2536277770996094
Epoch 77, Batch 300/3125, Loss: 1.6694889068603516, Uncertainty: 1.9920539855957031
Epoch 77, Batch 400/3125, Loss: 1.8360828161239624, Uncertainty: 1.7964609861373901
Epoch 77, Batch 500/3125, Loss: 1.708709955215454, Uncertainty: 2.234269142150879
Epoch 77, Batch 600/3125, Loss: 2.035645008087158, Uncertainty: 2.857043743133545
Epoch 77, Batch 700/3125, Loss: 1.7936198711395264, Uncertainty: 2.0551400184631348
Epoch 77, Batch 800/3125, Loss: 2.2158312797546387, Uncertainty: 2.395052433013916
Epoch 77, Batch 900/3125, Loss: 1.6620268821716309, Uncertainty: 1.903526782989502
Epoch 77, Batch 1000/3125, Loss: 1.7242894172668457, Uncertainty: 1.879668116569519
Epoch 77, Batch 1100/3125, Loss: 1.942162275314331, Uncertainty: 2.353055000305176
Epoch 77, Batch 1200/3125, Loss: 1.9491603374481201, Uncertainty: 2.130136489868164
Epoch 77, Batch 1300/3125, Loss: 1.462640643119812, Uncertainty: 1.9867548942565918
Epoch 77, Batch 1400/3125, Loss: 2.0456676483154297, Uncertainty: 3.0257554054260254
Epoch 77, Batch 1500/3125, Loss: 2.0636696815490723, Uncertainty: 3.225342035293579
Epoch 77, Batch 1600/3125, Loss: 1.7446019649505615, Uncertainty: 2.0869107246398926
Epoch 77, Batch 1700/3125, Loss: 1.7339985370635986, Uncertainty: 2.319514751434326
Epoch 77, Batch 1800/3125, Loss: 1.9248771667480469, Uncertainty: 1.6640644073486328
Epoch 77, Batch 1900/3125, Loss: 1.7445454597473145, Uncertainty: 2.127506732940674
Epoch 77, Batch 2000/3125, Loss: 1.644417405128479, Uncertainty: 2.112617254257202
Epoch 77, Batch 2100/3125, Loss: 2.121021032333374, Uncertainty: 2.833115577697754
Epoch 77, Batch 2200/3125, Loss: 1.930455207824707, Uncertainty: 2.5195939540863037
Epoch 77, Batch 2300/3125, Loss: 1.9206867218017578, Uncertainty: 1.9707106351852417
Epoch 77, Batch 2400/3125, Loss: 1.6852936744689941, Uncertainty: 2.2177581787109375
Epoch 77, Batch 2500/3125, Loss: 1.8047425746917725, Uncertainty: 2.094970226287842
Epoch 77, Batch 2600/3125, Loss: 1.6365039348602295, Uncertainty: 1.7175943851470947
Epoch 77, Batch 2700/3125, Loss: 1.6660642623901367, Uncertainty: 2.20928692817688
Epoch 77, Batch 2800/3125, Loss: 1.6806470155715942, Uncertainty: 2.1390492916107178
Epoch 77, Batch 2900/3125, Loss: 1.918285608291626, Uncertainty: 2.3497354984283447
Epoch 77, Batch 3000/3125, Loss: 1.5979433059692383, Uncertainty: 1.9165644645690918
Epoch 77, Batch 3100/3125, Loss: 1.7145321369171143, Uncertainty: 1.748683214187622

Training and Validation Results of Epoch 77:
================================
Training Loss: 1.4523328045272828, Training Uncertainty: 2.37967134223938, time: 199.43590307235718
Validation Loss: 1.1234869664282445, Validation Uncertainty: 3.2217811010682675, time: 45.29558873176575
Number of predictions within uncertainty interval: 138038/200000 (69.02%)

Epoch 78, Batch 100/3125, Loss: 1.9810190200805664, Uncertainty: 2.2972569465637207
Epoch 78, Batch 200/3125, Loss: 1.5187554359436035, Uncertainty: 2.0637733936309814
Epoch 78, Batch 300/3125, Loss: 1.6788345575332642, Uncertainty: 2.2139086723327637
Epoch 78, Batch 400/3125, Loss: 1.47481107711792, Uncertainty: 1.9616100788116455
Epoch 78, Batch 500/3125, Loss: 1.4446287155151367, Uncertainty: 1.764723539352417
Epoch 78, Batch 600/3125, Loss: 2.0539112091064453, Uncertainty: 2.4964332580566406
Epoch 78, Batch 700/3125, Loss: 1.8394378423690796, Uncertainty: 2.0410103797912598
Epoch 78, Batch 800/3125, Loss: 1.9099698066711426, Uncertainty: 3.036795139312744
Epoch 78, Batch 900/3125, Loss: 1.8103396892547607, Uncertainty: 2.429539442062378
Epoch 78, Batch 1000/3125, Loss: 1.575871229171753, Uncertainty: 1.9917593002319336
Epoch 78, Batch 1100/3125, Loss: 1.8093334436416626, Uncertainty: 2.1431174278259277
Epoch 78, Batch 1200/3125, Loss: 1.6115515232086182, Uncertainty: 2.0187065601348877
Epoch 78, Batch 1300/3125, Loss: 1.768533706665039, Uncertainty: 2.1084823608398438
Epoch 78, Batch 1400/3125, Loss: 2.0125248432159424, Uncertainty: 2.537538528442383
Epoch 78, Batch 1500/3125, Loss: 2.157543659210205, Uncertainty: 2.2472667694091797
Epoch 78, Batch 1600/3125, Loss: 1.783844232559204, Uncertainty: 2.2459895610809326
Epoch 78, Batch 1700/3125, Loss: 1.6283369064331055, Uncertainty: 2.0523083209991455
Epoch 78, Batch 1800/3125, Loss: 1.5904121398925781, Uncertainty: 1.7775242328643799
Epoch 78, Batch 1900/3125, Loss: 2.0440587997436523, Uncertainty: 2.8788540363311768
Epoch 78, Batch 2000/3125, Loss: 1.6846821308135986, Uncertainty: 2.1871886253356934
Epoch 78, Batch 2100/3125, Loss: 1.8731749057769775, Uncertainty: 2.2572526931762695
Epoch 78, Batch 2200/3125, Loss: 2.122227191925049, Uncertainty: 2.84995174407959
Epoch 78, Batch 2300/3125, Loss: 1.857905387878418, Uncertainty: 2.551703929901123
Epoch 78, Batch 2400/3125, Loss: 1.8772777318954468, Uncertainty: 2.650761604309082
Epoch 78, Batch 2500/3125, Loss: 1.523552656173706, Uncertainty: 1.9753155708312988
Epoch 78, Batch 2600/3125, Loss: 1.7485921382904053, Uncertainty: 2.117004871368408
Epoch 78, Batch 2700/3125, Loss: 1.7486681938171387, Uncertainty: 2.222999095916748
Epoch 78, Batch 2800/3125, Loss: 2.2096447944641113, Uncertainty: 2.0950875282287598
Epoch 78, Batch 2900/3125, Loss: 1.5748008489608765, Uncertainty: 1.8939318656921387
Epoch 78, Batch 3000/3125, Loss: 1.8675048351287842, Uncertainty: 2.5152673721313477
Epoch 78, Batch 3100/3125, Loss: 1.6713588237762451, Uncertainty: 2.1490793228149414

Training and Validation Results of Epoch 78:
================================
Training Loss: 1.4256746938705445, Training Uncertainty: 2.3550005246353147, time: 199.04957389831543
Validation Loss: 1.217127033511696, Validation Uncertainty: 3.154273040154401, time: 44.807092905044556
Number of predictions within uncertainty interval: 131260/200000 (65.63%)

Epoch 79, Batch 100/3125, Loss: 2.2342162132263184, Uncertainty: 3.1391184329986572
Epoch 79, Batch 200/3125, Loss: 2.176626682281494, Uncertainty: 3.189548969268799
Epoch 79, Batch 300/3125, Loss: 1.708718180656433, Uncertainty: 2.381415367126465
Epoch 79, Batch 400/3125, Loss: 1.6201601028442383, Uncertainty: 2.191202402114868
Epoch 79, Batch 500/3125, Loss: 2.1254725456237793, Uncertainty: 2.9997847080230713
Epoch 79, Batch 600/3125, Loss: 1.813028335571289, Uncertainty: 2.206494092941284
Epoch 79, Batch 700/3125, Loss: 1.6185956001281738, Uncertainty: 2.044617176055908
Epoch 79, Batch 800/3125, Loss: 1.7515262365341187, Uncertainty: 2.2136411666870117
Epoch 79, Batch 900/3125, Loss: 1.8364341259002686, Uncertainty: 1.9654146432876587
Epoch 79, Batch 1000/3125, Loss: 1.7915546894073486, Uncertainty: 1.894173502922058
Epoch 79, Batch 1100/3125, Loss: 2.33241868019104, Uncertainty: 3.386549949645996
Epoch 79, Batch 1200/3125, Loss: 2.4946885108947754, Uncertainty: 2.1668825149536133
Epoch 79, Batch 1300/3125, Loss: 1.5737497806549072, Uncertainty: 2.26432466506958
Epoch 79, Batch 1400/3125, Loss: 1.6376357078552246, Uncertainty: 1.88807213306427
Epoch 79, Batch 1500/3125, Loss: 1.8409574031829834, Uncertainty: 2.065150260925293
Epoch 79, Batch 1600/3125, Loss: 1.7328715324401855, Uncertainty: 2.1126046180725098
Epoch 79, Batch 1700/3125, Loss: 1.7334400415420532, Uncertainty: 2.1334381103515625
Epoch 79, Batch 1800/3125, Loss: 1.6804041862487793, Uncertainty: 2.0313868522644043
Epoch 79, Batch 1900/3125, Loss: 1.7778027057647705, Uncertainty: 2.061798334121704
Epoch 79, Batch 2000/3125, Loss: 1.6929830312728882, Uncertainty: 2.205214023590088
Epoch 79, Batch 2100/3125, Loss: 1.7154018878936768, Uncertainty: 1.9880014657974243
Epoch 79, Batch 2200/3125, Loss: 1.6848399639129639, Uncertainty: 2.1637167930603027
Epoch 79, Batch 2300/3125, Loss: 1.6253581047058105, Uncertainty: 1.921322226524353
Epoch 79, Batch 2400/3125, Loss: 2.0359530448913574, Uncertainty: 2.4454782009124756
Epoch 79, Batch 2500/3125, Loss: 1.83808434009552, Uncertainty: 2.541335105895996
Epoch 79, Batch 2600/3125, Loss: 1.8944875001907349, Uncertainty: 2.0838935375213623
Epoch 79, Batch 2700/3125, Loss: 1.9453210830688477, Uncertainty: 3.034384250640869
Epoch 79, Batch 2800/3125, Loss: 1.6546903848648071, Uncertainty: 2.021519899368286
Epoch 79, Batch 2900/3125, Loss: 1.6564750671386719, Uncertainty: 1.9217844009399414
Epoch 79, Batch 3000/3125, Loss: 1.647602915763855, Uncertainty: 2.1454951763153076
Epoch 79, Batch 3100/3125, Loss: 1.6646959781646729, Uncertainty: 2.0741682052612305

Training and Validation Results of Epoch 79:
================================
Training Loss: 1.4159532908248902, Training Uncertainty: 2.3666484177017213, time: 196.51981949806213
Validation Loss: 1.1646132815981765, Validation Uncertainty: 3.5716504937852434, time: 45.38960027694702
Number of predictions within uncertainty interval: 144538/200000 (72.27%)

Epoch 80, Batch 100/3125, Loss: 1.7200779914855957, Uncertainty: 2.63252592086792
Epoch 80, Batch 200/3125, Loss: 1.5282658338546753, Uncertainty: 1.892680048942566
Epoch 80, Batch 300/3125, Loss: 2.3406426906585693, Uncertainty: 2.7788352966308594
Epoch 80, Batch 400/3125, Loss: 1.7097069025039673, Uncertainty: 2.4130330085754395
Epoch 80, Batch 500/3125, Loss: 1.6919729709625244, Uncertainty: 2.1090290546417236
Epoch 80, Batch 600/3125, Loss: 2.2847585678100586, Uncertainty: 2.6015753746032715
Epoch 80, Batch 700/3125, Loss: 1.7924691438674927, Uncertainty: 2.26483154296875
Epoch 80, Batch 800/3125, Loss: 1.5162005424499512, Uncertainty: 1.8812642097473145
Epoch 80, Batch 900/3125, Loss: 2.066830635070801, Uncertainty: 3.5064215660095215
Epoch 80, Batch 1000/3125, Loss: 1.6222556829452515, Uncertainty: 2.1912848949432373
Epoch 80, Batch 1100/3125, Loss: 1.8651525974273682, Uncertainty: 2.5111308097839355
Epoch 80, Batch 1200/3125, Loss: 1.7248525619506836, Uncertainty: 2.0966999530792236
Epoch 80, Batch 1300/3125, Loss: 1.5973211526870728, Uncertainty: 2.2270641326904297
Epoch 80, Batch 1400/3125, Loss: 1.9535841941833496, Uncertainty: 3.0080857276916504
Epoch 80, Batch 1500/3125, Loss: 1.9428927898406982, Uncertainty: 2.432652473449707
Epoch 80, Batch 1600/3125, Loss: 1.8778313398361206, Uncertainty: 2.3417515754699707
Epoch 80, Batch 1700/3125, Loss: 1.8461791276931763, Uncertainty: 2.8797545433044434
Epoch 80, Batch 1800/3125, Loss: 2.2485098838806152, Uncertainty: 3.6454572677612305
Epoch 80, Batch 1900/3125, Loss: 1.565483808517456, Uncertainty: 2.1165332794189453
Epoch 80, Batch 2000/3125, Loss: 1.5241976976394653, Uncertainty: 1.9798083305358887
Epoch 80, Batch 2100/3125, Loss: 1.6678898334503174, Uncertainty: 2.137054920196533
Epoch 80, Batch 2200/3125, Loss: 1.994182825088501, Uncertainty: 3.0728795528411865
Epoch 80, Batch 2300/3125, Loss: 1.8050684928894043, Uncertainty: 1.7439112663269043
Epoch 80, Batch 2400/3125, Loss: 1.9688643217086792, Uncertainty: 2.7813754081726074
Epoch 80, Batch 2500/3125, Loss: 1.5087218284606934, Uncertainty: 1.7292038202285767
Epoch 80, Batch 2600/3125, Loss: 1.848621129989624, Uncertainty: 2.61543607711792
Epoch 80, Batch 2700/3125, Loss: 1.6918175220489502, Uncertainty: 1.8443801403045654
Epoch 80, Batch 2800/3125, Loss: 1.5823941230773926, Uncertainty: 2.025721549987793
Epoch 80, Batch 2900/3125, Loss: 1.6645677089691162, Uncertainty: 1.9341163635253906
Epoch 80, Batch 3000/3125, Loss: 1.7484626770019531, Uncertainty: 2.4518656730651855
Epoch 80, Batch 3100/3125, Loss: 1.685762882232666, Uncertainty: 2.347407102584839

Training and Validation Results of Epoch 80:
================================
Training Loss: 1.409220540447235, Training Uncertainty: 2.3275035514450075, time: 207.1510181427002
Validation Loss: 1.174035635750617, Validation Uncertainty: 3.1732523615098063, time: 44.23868656158447
Number of predictions within uncertainty interval: 133017/200000 (66.51%)

Epoch 81, Batch 100/3125, Loss: 1.6901063919067383, Uncertainty: 2.276271104812622
Epoch 81, Batch 200/3125, Loss: 1.8073099851608276, Uncertainty: 2.814854145050049
Epoch 81, Batch 300/3125, Loss: 1.9007195234298706, Uncertainty: 2.5030672550201416
Epoch 81, Batch 400/3125, Loss: 1.4530000686645508, Uncertainty: 1.7758524417877197
Epoch 81, Batch 500/3125, Loss: 1.6918634176254272, Uncertainty: 2.3079347610473633
Epoch 81, Batch 600/3125, Loss: 1.9967081546783447, Uncertainty: 3.06369686126709
Epoch 81, Batch 700/3125, Loss: 1.7527824640274048, Uncertainty: 2.5473885536193848
Epoch 81, Batch 800/3125, Loss: 1.6632256507873535, Uncertainty: 2.3844852447509766
Epoch 81, Batch 900/3125, Loss: 1.6214600801467896, Uncertainty: 2.191588878631592
Epoch 81, Batch 1000/3125, Loss: 2.04733943939209, Uncertainty: 3.2299695014953613
Epoch 81, Batch 1100/3125, Loss: 1.8835365772247314, Uncertainty: 2.618044376373291
Epoch 81, Batch 1200/3125, Loss: 2.1867475509643555, Uncertainty: 3.4626080989837646
Epoch 81, Batch 1300/3125, Loss: 1.813772439956665, Uncertainty: 2.870048999786377
Epoch 81, Batch 1400/3125, Loss: 2.035842180252075, Uncertainty: 2.1816043853759766
Epoch 81, Batch 1500/3125, Loss: 1.566544771194458, Uncertainty: 1.8422280550003052
Epoch 81, Batch 1600/3125, Loss: 1.736323356628418, Uncertainty: 2.2236056327819824
Epoch 81, Batch 1700/3125, Loss: 1.6771240234375, Uncertainty: 2.2663135528564453
Epoch 81, Batch 1800/3125, Loss: 1.858852505683899, Uncertainty: 2.701361656188965
Epoch 81, Batch 1900/3125, Loss: 1.6863737106323242, Uncertainty: 2.14846134185791
Epoch 81, Batch 2000/3125, Loss: 1.701218605041504, Uncertainty: 1.9641754627227783
Epoch 81, Batch 2100/3125, Loss: 1.9280681610107422, Uncertainty: 2.1728265285491943
Epoch 81, Batch 2200/3125, Loss: 1.8911383152008057, Uncertainty: 2.874359607696533
Epoch 81, Batch 2300/3125, Loss: 1.5485427379608154, Uncertainty: 2.135615825653076
Epoch 81, Batch 2400/3125, Loss: 1.8408164978027344, Uncertainty: 1.8426845073699951
Epoch 81, Batch 2500/3125, Loss: 2.020825147628784, Uncertainty: 2.922640323638916
Epoch 81, Batch 2600/3125, Loss: 1.5365917682647705, Uncertainty: 1.790459394454956
Epoch 81, Batch 2700/3125, Loss: 1.8109153509140015, Uncertainty: 2.038252592086792
Epoch 81, Batch 2800/3125, Loss: 3.424647569656372, Uncertainty: 3.5995500087738037
Epoch 81, Batch 2900/3125, Loss: 1.8258390426635742, Uncertainty: 2.4980883598327637
Epoch 81, Batch 3000/3125, Loss: 1.8431251049041748, Uncertainty: 1.9182212352752686
Epoch 81, Batch 3100/3125, Loss: 1.5542020797729492, Uncertainty: 1.8202224969863892

Training and Validation Results of Epoch 81:
================================
Training Loss: 1.3989184032058717, Training Uncertainty: 2.3593620417022705, time: 195.45317673683167
Validation Loss: 1.142258903407075, Validation Uncertainty: 3.7783568097502376, time: 44.733731269836426
Number of predictions within uncertainty interval: 149969/200000 (74.98%)

Epoch 82, Batch 100/3125, Loss: 1.62149977684021, Uncertainty: 2.276428461074829
Epoch 82, Batch 200/3125, Loss: 1.6279799938201904, Uncertainty: 2.2277097702026367
Epoch 82, Batch 300/3125, Loss: 1.7125887870788574, Uncertainty: 2.0259597301483154
Epoch 82, Batch 400/3125, Loss: 1.6543993949890137, Uncertainty: 2.1234145164489746
Epoch 82, Batch 500/3125, Loss: 1.923187017440796, Uncertainty: 2.792962074279785
Epoch 82, Batch 600/3125, Loss: 1.8297264575958252, Uncertainty: 2.6878676414489746
Epoch 82, Batch 700/3125, Loss: 1.7654542922973633, Uncertainty: 2.507450819015503
Epoch 82, Batch 800/3125, Loss: 1.6068928241729736, Uncertainty: 2.0882272720336914
Epoch 82, Batch 900/3125, Loss: 1.8713037967681885, Uncertainty: 2.683779001235962
Epoch 82, Batch 1000/3125, Loss: 2.0002715587615967, Uncertainty: 3.3663182258605957
Epoch 82, Batch 1100/3125, Loss: 1.9333412647247314, Uncertainty: 2.5307304859161377
Epoch 82, Batch 1200/3125, Loss: 1.647801160812378, Uncertainty: 2.0141613483428955
Epoch 82, Batch 1300/3125, Loss: 1.929982304573059, Uncertainty: 2.5454912185668945
Epoch 82, Batch 1400/3125, Loss: 1.8401111364364624, Uncertainty: 1.9144357442855835
Epoch 82, Batch 1500/3125, Loss: 1.7723815441131592, Uncertainty: 1.9101841449737549
Epoch 82, Batch 1600/3125, Loss: 1.565582036972046, Uncertainty: 1.8907792568206787
Epoch 82, Batch 1700/3125, Loss: 1.7470459938049316, Uncertainty: 2.434169292449951
Epoch 82, Batch 1800/3125, Loss: 1.7196890115737915, Uncertainty: 1.801170825958252
Epoch 82, Batch 1900/3125, Loss: 1.5908706188201904, Uncertainty: 1.9541985988616943
Epoch 82, Batch 2000/3125, Loss: 1.902166485786438, Uncertainty: 2.7919249534606934
Epoch 82, Batch 2100/3125, Loss: 1.7512332201004028, Uncertainty: 2.1026439666748047
Epoch 82, Batch 2200/3125, Loss: 1.903236746788025, Uncertainty: 1.9753713607788086
Epoch 82, Batch 2300/3125, Loss: 1.7905313968658447, Uncertainty: 1.9131592512130737
Epoch 82, Batch 2400/3125, Loss: 1.8613022565841675, Uncertainty: 2.430267333984375
Epoch 82, Batch 2500/3125, Loss: 1.8740549087524414, Uncertainty: 2.130136489868164
Epoch 82, Batch 2600/3125, Loss: 1.897728681564331, Uncertainty: 2.422926187515259
Epoch 82, Batch 2700/3125, Loss: 1.9891846179962158, Uncertainty: 3.3355085849761963
Epoch 82, Batch 2800/3125, Loss: 1.6872159242630005, Uncertainty: 2.3005809783935547
Epoch 82, Batch 2900/3125, Loss: 1.7838464975357056, Uncertainty: 2.1079518795013428
Epoch 82, Batch 3000/3125, Loss: 1.7929054498672485, Uncertainty: 2.1938719749450684
Epoch 82, Batch 3100/3125, Loss: 1.8765778541564941, Uncertainty: 2.1847968101501465

Training and Validation Results of Epoch 82:
================================
Training Loss: 1.3906960444259644, Training Uncertainty: 2.3000207146835328, time: 194.86067938804626
Validation Loss: 1.189956343997165, Validation Uncertainty: 4.110704836638077, time: 44.30613422393799
Number of predictions within uncertainty interval: 150759/200000 (75.38%)

Epoch 83, Batch 100/3125, Loss: 1.5836999416351318, Uncertainty: 2.1009273529052734
Epoch 83, Batch 200/3125, Loss: 1.577765941619873, Uncertainty: 2.10628080368042
Epoch 83, Batch 300/3125, Loss: 1.7906312942504883, Uncertainty: 2.0303566455841064
Epoch 83, Batch 400/3125, Loss: 1.5868009328842163, Uncertainty: 2.1938233375549316
Epoch 83, Batch 500/3125, Loss: 1.5400031805038452, Uncertainty: 1.5297462940216064
Epoch 83, Batch 600/3125, Loss: 2.0252318382263184, Uncertainty: 2.875702142715454
Epoch 83, Batch 700/3125, Loss: 2.09049129486084, Uncertainty: 3.112063407897949
Epoch 83, Batch 800/3125, Loss: 1.890805959701538, Uncertainty: 2.5898666381835938
Epoch 83, Batch 900/3125, Loss: 1.753014087677002, Uncertainty: 1.8661426305770874
Epoch 83, Batch 1000/3125, Loss: 1.9738229513168335, Uncertainty: 2.973660945892334
Epoch 83, Batch 1100/3125, Loss: 1.9812551736831665, Uncertainty: 2.5415382385253906
Epoch 83, Batch 1200/3125, Loss: 1.5827610492706299, Uncertainty: 2.0952939987182617
Epoch 83, Batch 1300/3125, Loss: 1.7414298057556152, Uncertainty: 2.5905959606170654
Epoch 83, Batch 1400/3125, Loss: 1.8642183542251587, Uncertainty: 2.517014265060425
Epoch 83, Batch 1500/3125, Loss: 1.8922350406646729, Uncertainty: 2.7148218154907227
Epoch 83, Batch 1600/3125, Loss: 1.5732065439224243, Uncertainty: 1.8946361541748047
Epoch 83, Batch 1700/3125, Loss: 1.5061416625976562, Uncertainty: 2.042879343032837
Epoch 83, Batch 1800/3125, Loss: 2.0411601066589355, Uncertainty: 2.907055377960205
Epoch 83, Batch 1900/3125, Loss: 1.7384848594665527, Uncertainty: 2.397033214569092
Epoch 83, Batch 2000/3125, Loss: 1.6567697525024414, Uncertainty: 2.0588221549987793
Epoch 83, Batch 2100/3125, Loss: 1.7575596570968628, Uncertainty: 1.9814075231552124
Epoch 83, Batch 2200/3125, Loss: 1.7958797216415405, Uncertainty: 2.288367509841919
Epoch 83, Batch 2300/3125, Loss: 1.6746938228607178, Uncertainty: 2.0330235958099365
Epoch 83, Batch 2400/3125, Loss: 1.5452206134796143, Uncertainty: 1.7871813774108887
Epoch 83, Batch 2500/3125, Loss: 1.8038996458053589, Uncertainty: 2.701162576675415
Epoch 83, Batch 2600/3125, Loss: 1.9413816928863525, Uncertainty: 2.670565605163574
Epoch 83, Batch 2700/3125, Loss: 1.9617352485656738, Uncertainty: 2.1912920475006104
Epoch 83, Batch 2800/3125, Loss: 1.6797608137130737, Uncertainty: 2.063872814178467
Epoch 83, Batch 2900/3125, Loss: 1.8818466663360596, Uncertainty: 3.108139991760254
Epoch 83, Batch 3000/3125, Loss: 1.7366321086883545, Uncertainty: 2.1998825073242188
Epoch 83, Batch 3100/3125, Loss: 1.719301462173462, Uncertainty: 1.950688123703003

Training and Validation Results of Epoch 83:
================================
Training Loss: 1.3747653180122374, Training Uncertainty: 2.294124512252808, time: 201.14724922180176
Validation Loss: 1.075230602794291, Validation Uncertainty: 2.9921028668923144, time: 45.170260429382324
Number of predictions within uncertainty interval: 134598/200000 (67.30%)

Epoch 84, Batch 100/3125, Loss: 1.4629305601119995, Uncertainty: 1.8436245918273926
Epoch 84, Batch 200/3125, Loss: 1.6781573295593262, Uncertainty: 1.8173774480819702
Epoch 84, Batch 300/3125, Loss: 1.9061470031738281, Uncertainty: 2.5759501457214355
Epoch 84, Batch 400/3125, Loss: 1.5313537120819092, Uncertainty: 1.8801026344299316
Epoch 84, Batch 500/3125, Loss: 1.7503705024719238, Uncertainty: 2.127129077911377
Epoch 84, Batch 600/3125, Loss: 1.6716389656066895, Uncertainty: 2.281663417816162
Epoch 84, Batch 700/3125, Loss: 1.7002606391906738, Uncertainty: 2.5165162086486816
Epoch 84, Batch 800/3125, Loss: 1.8875794410705566, Uncertainty: 2.1896138191223145
Epoch 84, Batch 900/3125, Loss: 1.7114896774291992, Uncertainty: 2.549724817276001
Epoch 84, Batch 1000/3125, Loss: 1.705314040184021, Uncertainty: 2.009871482849121
Epoch 84, Batch 1100/3125, Loss: 1.9136378765106201, Uncertainty: 2.532266139984131
Epoch 84, Batch 1200/3125, Loss: 1.7541431188583374, Uncertainty: 1.834320306777954
Epoch 84, Batch 1300/3125, Loss: 1.999465823173523, Uncertainty: 3.072676658630371
Epoch 84, Batch 1400/3125, Loss: 2.1860499382019043, Uncertainty: 2.1611382961273193
Epoch 84, Batch 1500/3125, Loss: 1.9183094501495361, Uncertainty: 2.811619758605957
Epoch 84, Batch 1600/3125, Loss: 1.8027100563049316, Uncertainty: 2.1600840091705322
Epoch 84, Batch 1700/3125, Loss: 1.7749369144439697, Uncertainty: 2.3771729469299316
Epoch 84, Batch 1800/3125, Loss: 1.6692008972167969, Uncertainty: 1.9318771362304688
Epoch 84, Batch 1900/3125, Loss: 1.4847705364227295, Uncertainty: 1.8280125856399536
Epoch 84, Batch 2000/3125, Loss: 1.6962306499481201, Uncertainty: 2.2563230991363525
Epoch 84, Batch 2100/3125, Loss: 2.2380828857421875, Uncertainty: 2.9594528675079346
Epoch 84, Batch 2200/3125, Loss: 1.562585473060608, Uncertainty: 1.9507955312728882
Epoch 84, Batch 2300/3125, Loss: 1.8267022371292114, Uncertainty: 2.0791540145874023
Epoch 84, Batch 2400/3125, Loss: 2.2342844009399414, Uncertainty: 3.5082578659057617
Epoch 84, Batch 2500/3125, Loss: 1.8856332302093506, Uncertainty: 2.7513911724090576
Epoch 84, Batch 2600/3125, Loss: 1.802083969116211, Uncertainty: 1.9747885465621948
Epoch 84, Batch 2700/3125, Loss: 1.4624810218811035, Uncertainty: 2.0431318283081055
Epoch 84, Batch 2800/3125, Loss: 2.05998158454895, Uncertainty: 2.6014888286590576
Epoch 84, Batch 2900/3125, Loss: 1.7187459468841553, Uncertainty: 2.488119602203369
Epoch 84, Batch 3000/3125, Loss: 2.272974967956543, Uncertainty: 2.0488181114196777
Epoch 84, Batch 3100/3125, Loss: 1.6203172206878662, Uncertainty: 1.9652283191680908

Training and Validation Results of Epoch 84:
================================
Training Loss: 1.369927991104126, Training Uncertainty: 2.2831804804229736, time: 193.49604535102844
Validation Loss: 1.1184335019429932, Validation Uncertainty: 3.4577063172674545, time: 43.97045397758484
Number of predictions within uncertainty interval: 139898/200000 (69.95%)

Epoch 85, Batch 100/3125, Loss: 1.5397357940673828, Uncertainty: 1.6572046279907227
Epoch 85, Batch 200/3125, Loss: 1.6304538249969482, Uncertainty: 1.9168637990951538
Epoch 85, Batch 300/3125, Loss: 1.778796672821045, Uncertainty: 2.508586883544922
Epoch 85, Batch 400/3125, Loss: 1.4406940937042236, Uncertainty: 1.7570481300354004
Epoch 85, Batch 500/3125, Loss: 2.338326930999756, Uncertainty: 4.155309677124023
Epoch 85, Batch 600/3125, Loss: 1.5449827909469604, Uncertainty: 2.236358404159546
Epoch 85, Batch 700/3125, Loss: 1.5785624980926514, Uncertainty: 1.9838199615478516
Epoch 85, Batch 800/3125, Loss: 1.8280658721923828, Uncertainty: 2.9075605869293213
Epoch 85, Batch 900/3125, Loss: 1.9673280715942383, Uncertainty: 2.5442376136779785
Epoch 85, Batch 1000/3125, Loss: 1.8396755456924438, Uncertainty: 2.3177037239074707
Epoch 85, Batch 1100/3125, Loss: 1.6676783561706543, Uncertainty: 2.1310787200927734
Epoch 85, Batch 1200/3125, Loss: 1.7111684083938599, Uncertainty: 2.4446468353271484
Epoch 85, Batch 1300/3125, Loss: 1.9019280672073364, Uncertainty: 3.200101375579834
Epoch 85, Batch 1400/3125, Loss: 1.793304443359375, Uncertainty: 2.1417055130004883
Epoch 85, Batch 1500/3125, Loss: 1.6226348876953125, Uncertainty: 1.848253607749939
Epoch 85, Batch 1600/3125, Loss: 1.7900636196136475, Uncertainty: 2.076934337615967
Epoch 85, Batch 1700/3125, Loss: 1.6526057720184326, Uncertainty: 2.228623867034912
Epoch 85, Batch 1800/3125, Loss: 1.761608362197876, Uncertainty: 2.451458215713501
Epoch 85, Batch 1900/3125, Loss: 1.6605191230773926, Uncertainty: 2.2598750591278076
Epoch 85, Batch 2000/3125, Loss: 1.8050892353057861, Uncertainty: 2.6559855937957764
Epoch 85, Batch 2100/3125, Loss: 1.7373954057693481, Uncertainty: 1.7554538249969482
Epoch 85, Batch 2200/3125, Loss: 1.9022654294967651, Uncertainty: 2.5473034381866455
Epoch 85, Batch 2300/3125, Loss: 1.933125615119934, Uncertainty: 2.6188864707946777
Epoch 85, Batch 2400/3125, Loss: 1.920433759689331, Uncertainty: 2.5642917156219482
Epoch 85, Batch 2500/3125, Loss: 1.585204839706421, Uncertainty: 1.7432671785354614
Epoch 85, Batch 2600/3125, Loss: 1.637202501296997, Uncertainty: 1.9821319580078125
Epoch 85, Batch 2700/3125, Loss: 1.469181776046753, Uncertainty: 1.7341418266296387
Epoch 85, Batch 2800/3125, Loss: 1.6989552974700928, Uncertainty: 2.2094273567199707
Epoch 85, Batch 2900/3125, Loss: 1.9351048469543457, Uncertainty: 2.567415237426758
Epoch 85, Batch 3000/3125, Loss: 2.046302080154419, Uncertainty: 2.4899308681488037
Epoch 85, Batch 3100/3125, Loss: 1.8055388927459717, Uncertainty: 2.2816245555877686

Training and Validation Results of Epoch 85:
================================
Training Loss: 1.3481019329071044, Training Uncertainty: 2.267041975326538, time: 195.50943756103516
Validation Loss: 1.1309440437790073, Validation Uncertainty: 3.605194891505229, time: 44.0429949760437
Number of predictions within uncertainty interval: 146556/200000 (73.28%)

Epoch 86, Batch 100/3125, Loss: 1.5283482074737549, Uncertainty: 1.8508919477462769
Epoch 86, Batch 200/3125, Loss: 1.5669828653335571, Uncertainty: 2.234121322631836
Epoch 86, Batch 300/3125, Loss: 1.7037014961242676, Uncertainty: 1.7781463861465454
Epoch 86, Batch 400/3125, Loss: 1.9089295864105225, Uncertainty: 2.0012216567993164
Epoch 86, Batch 500/3125, Loss: 1.7403236627578735, Uncertainty: 2.6718530654907227
Epoch 86, Batch 600/3125, Loss: 1.8296921253204346, Uncertainty: 2.6690244674682617
Epoch 86, Batch 700/3125, Loss: 2.11779522895813, Uncertainty: 3.2538952827453613
Epoch 86, Batch 800/3125, Loss: 1.8306527137756348, Uncertainty: 2.4987220764160156
Epoch 86, Batch 900/3125, Loss: 1.6869395971298218, Uncertainty: 2.0255720615386963
Epoch 86, Batch 1000/3125, Loss: 1.897783637046814, Uncertainty: 2.7305078506469727
Epoch 86, Batch 1100/3125, Loss: 1.9513190984725952, Uncertainty: 2.633270740509033
Epoch 86, Batch 1200/3125, Loss: 1.837074637413025, Uncertainty: 2.7116174697875977
Epoch 86, Batch 1300/3125, Loss: 1.588247299194336, Uncertainty: 2.333850383758545
Epoch 86, Batch 1400/3125, Loss: 1.599738359451294, Uncertainty: 1.9822266101837158
Epoch 86, Batch 1500/3125, Loss: 1.9168071746826172, Uncertainty: 2.170825958251953
Epoch 86, Batch 1600/3125, Loss: 1.636042594909668, Uncertainty: 2.044949531555176
Epoch 86, Batch 1700/3125, Loss: 1.5376439094543457, Uncertainty: 2.0875062942504883
Epoch 86, Batch 1800/3125, Loss: 1.775202751159668, Uncertainty: 2.2089478969573975
Epoch 86, Batch 1900/3125, Loss: 1.6757831573486328, Uncertainty: 1.9309256076812744
Epoch 86, Batch 2000/3125, Loss: 1.8928219079971313, Uncertainty: 2.602508544921875
Epoch 86, Batch 2100/3125, Loss: 1.6957497596740723, Uncertainty: 1.826244592666626
Epoch 86, Batch 2200/3125, Loss: 1.877314805984497, Uncertainty: 1.9005677700042725
Epoch 86, Batch 2300/3125, Loss: 2.2990164756774902, Uncertainty: 3.691683053970337
Epoch 86, Batch 2400/3125, Loss: 2.2150449752807617, Uncertainty: 2.7768521308898926
Epoch 86, Batch 2500/3125, Loss: 1.7567017078399658, Uncertainty: 2.0529139041900635
Epoch 86, Batch 2600/3125, Loss: 1.4680883884429932, Uncertainty: 1.9425790309906006
Epoch 86, Batch 2700/3125, Loss: 2.2355549335479736, Uncertainty: 4.060539722442627
Epoch 86, Batch 2800/3125, Loss: 1.9010647535324097, Uncertainty: 2.3907761573791504
Epoch 86, Batch 2900/3125, Loss: 1.5900744199752808, Uncertainty: 1.8310153484344482
Epoch 86, Batch 3000/3125, Loss: 1.6750600337982178, Uncertainty: 2.2039175033569336
Epoch 86, Batch 3100/3125, Loss: 1.4610824584960938, Uncertainty: 1.7380895614624023

Training and Validation Results of Epoch 86:
================================
Training Loss: 1.3406390761756897, Training Uncertainty: 2.2759919910049438, time: 194.20197653770447
Validation Loss: 1.4284567947277937, Validation Uncertainty: 4.04839141350573, time: 43.84552884101868
Number of predictions within uncertainty interval: 139188/200000 (69.59%)

Epoch 87, Batch 100/3125, Loss: 1.565270185470581, Uncertainty: 2.3705830574035645
Epoch 87, Batch 200/3125, Loss: 1.4507205486297607, Uncertainty: 1.882326602935791
Epoch 87, Batch 300/3125, Loss: 1.8668365478515625, Uncertainty: 2.1366991996765137
Epoch 87, Batch 400/3125, Loss: 1.981360673904419, Uncertainty: 2.394505500793457
Epoch 87, Batch 500/3125, Loss: 1.597483515739441, Uncertainty: 1.8349820375442505
Epoch 87, Batch 600/3125, Loss: 2.0417330265045166, Uncertainty: 2.4488413333892822
Epoch 87, Batch 700/3125, Loss: 1.4367995262145996, Uncertainty: 1.729546070098877
Epoch 87, Batch 800/3125, Loss: 1.7182860374450684, Uncertainty: 2.193920135498047
Epoch 87, Batch 900/3125, Loss: 1.8588285446166992, Uncertainty: 2.3855576515197754
Epoch 87, Batch 1000/3125, Loss: 1.600966453552246, Uncertainty: 1.8299202919006348
Epoch 87, Batch 1100/3125, Loss: 1.6275544166564941, Uncertainty: 2.019680976867676
Epoch 87, Batch 1200/3125, Loss: 1.829270362854004, Uncertainty: 2.073399305343628
Epoch 87, Batch 1300/3125, Loss: 1.589043378829956, Uncertainty: 2.1949079036712646
Epoch 87, Batch 1400/3125, Loss: 1.4978587627410889, Uncertainty: 1.8551013469696045
Epoch 87, Batch 1500/3125, Loss: 1.6969587802886963, Uncertainty: 2.0729568004608154
Epoch 87, Batch 1600/3125, Loss: 1.738738775253296, Uncertainty: 2.2726120948791504
Epoch 87, Batch 1700/3125, Loss: 1.6318295001983643, Uncertainty: 1.985871434211731
Epoch 87, Batch 1800/3125, Loss: 1.6107509136199951, Uncertainty: 2.1093533039093018
Epoch 87, Batch 1900/3125, Loss: 1.5600745677947998, Uncertainty: 2.1013903617858887
Epoch 87, Batch 2000/3125, Loss: 1.4975314140319824, Uncertainty: 2.0409915447235107
Epoch 87, Batch 2100/3125, Loss: 1.6633760929107666, Uncertainty: 2.068453311920166
Epoch 87, Batch 2200/3125, Loss: 1.6389821767807007, Uncertainty: 2.2282350063323975
Epoch 87, Batch 2300/3125, Loss: 1.988675832748413, Uncertainty: 2.8529176712036133
Epoch 87, Batch 2400/3125, Loss: 1.8113512992858887, Uncertainty: 2.196349620819092
Epoch 87, Batch 2500/3125, Loss: 1.5904390811920166, Uncertainty: 2.271754741668701
Epoch 87, Batch 2600/3125, Loss: 1.5635418891906738, Uncertainty: 2.1008152961730957
Epoch 87, Batch 2700/3125, Loss: 1.4940440654754639, Uncertainty: 1.9878339767456055
Epoch 87, Batch 2800/3125, Loss: 2.031428098678589, Uncertainty: 2.0209686756134033
Epoch 87, Batch 2900/3125, Loss: 1.8652762174606323, Uncertainty: 2.306593894958496
Epoch 87, Batch 3000/3125, Loss: 1.6278821229934692, Uncertainty: 1.8487346172332764
Epoch 87, Batch 3100/3125, Loss: 1.70546555519104, Uncertainty: 2.251345634460449

Training and Validation Results of Epoch 87:
================================
Training Loss: 1.3341780262947083, Training Uncertainty: 2.248759990234375, time: 194.18671441078186
Validation Loss: 1.04346768127378, Validation Uncertainty: 3.249925954872385, time: 44.782745599746704
Number of predictions within uncertainty interval: 145481/200000 (72.74%)

Epoch 88, Batch 100/3125, Loss: 1.4105956554412842, Uncertainty: 1.8860292434692383
Epoch 88, Batch 200/3125, Loss: 1.4141643047332764, Uncertainty: 1.7907617092132568
Epoch 88, Batch 300/3125, Loss: 1.7187004089355469, Uncertainty: 2.2385053634643555
Epoch 88, Batch 400/3125, Loss: 1.778167963027954, Uncertainty: 2.4845938682556152
Epoch 88, Batch 500/3125, Loss: 2.1229143142700195, Uncertainty: 1.860807180404663
Epoch 88, Batch 600/3125, Loss: 1.8467743396759033, Uncertainty: 2.3238272666931152
Epoch 88, Batch 700/3125, Loss: 1.7987380027770996, Uncertainty: 2.335925579071045
Epoch 88, Batch 800/3125, Loss: 1.9915217161178589, Uncertainty: 1.981142520904541
Epoch 88, Batch 900/3125, Loss: 1.8322674036026, Uncertainty: 2.319599151611328
Epoch 88, Batch 1000/3125, Loss: 1.938237190246582, Uncertainty: 2.8716464042663574
Epoch 88, Batch 1100/3125, Loss: 1.6750391721725464, Uncertainty: 2.132516384124756
Epoch 88, Batch 1200/3125, Loss: 1.737582802772522, Uncertainty: 1.9516704082489014
Epoch 88, Batch 1300/3125, Loss: 1.4952622652053833, Uncertainty: 1.918210744857788
Epoch 88, Batch 1400/3125, Loss: 1.3929498195648193, Uncertainty: 1.7984589338302612
Epoch 88, Batch 1500/3125, Loss: 1.718950867652893, Uncertainty: 1.9923973083496094
Epoch 88, Batch 1600/3125, Loss: 1.8613895177841187, Uncertainty: 2.0992398262023926
Epoch 88, Batch 1700/3125, Loss: 1.852602243423462, Uncertainty: 2.4020867347717285
Epoch 88, Batch 1800/3125, Loss: 1.641937017440796, Uncertainty: 2.2039732933044434
Epoch 88, Batch 1900/3125, Loss: 1.6011444330215454, Uncertainty: 2.1154580116271973
Epoch 88, Batch 2000/3125, Loss: 1.6484400033950806, Uncertainty: 2.4904065132141113
Epoch 88, Batch 2100/3125, Loss: 1.6268479824066162, Uncertainty: 1.9178223609924316
Epoch 88, Batch 2200/3125, Loss: 1.6472065448760986, Uncertainty: 1.9828861951828003
Epoch 88, Batch 2300/3125, Loss: 1.8459808826446533, Uncertainty: 2.3494479656219482
Epoch 88, Batch 2400/3125, Loss: 1.7152835130691528, Uncertainty: 2.4757022857666016
Epoch 88, Batch 2500/3125, Loss: 1.7324148416519165, Uncertainty: 2.5538835525512695
Epoch 88, Batch 2600/3125, Loss: 1.5433564186096191, Uncertainty: 1.8480987548828125
Epoch 88, Batch 2700/3125, Loss: 1.850128173828125, Uncertainty: 2.0852468013763428
Epoch 88, Batch 2800/3125, Loss: 1.631793737411499, Uncertainty: 1.9284788370132446
Epoch 88, Batch 2900/3125, Loss: 1.5866221189498901, Uncertainty: 1.8942428827285767
Epoch 88, Batch 3000/3125, Loss: 1.6043651103973389, Uncertainty: 2.10986590385437
Epoch 88, Batch 3100/3125, Loss: 2.100116491317749, Uncertainty: 2.146777629852295

Training and Validation Results of Epoch 88:
================================
Training Loss: 1.3228001317977904, Training Uncertainty: 2.2315067626953127, time: 200.85867285728455
Validation Loss: 1.392035326536964, Validation Uncertainty: 3.306619796606586, time: 45.200218200683594
Number of predictions within uncertainty interval: 122892/200000 (61.45%)

Epoch 89, Batch 100/3125, Loss: 1.579566478729248, Uncertainty: 2.4971632957458496
Epoch 89, Batch 200/3125, Loss: 1.7400240898132324, Uncertainty: 2.7708089351654053
Epoch 89, Batch 300/3125, Loss: 1.9952467679977417, Uncertainty: 1.9792495965957642
Epoch 89, Batch 400/3125, Loss: 1.5516029596328735, Uncertainty: 1.6743571758270264
Epoch 89, Batch 500/3125, Loss: 1.5633013248443604, Uncertainty: 1.7558908462524414
Epoch 89, Batch 600/3125, Loss: 1.8872272968292236, Uncertainty: 2.224912643432617
Epoch 89, Batch 700/3125, Loss: 1.6582295894622803, Uncertainty: 1.8321192264556885
Epoch 89, Batch 800/3125, Loss: 1.6538413763046265, Uncertainty: 2.0598528385162354
Epoch 89, Batch 900/3125, Loss: 1.596773624420166, Uncertainty: 1.8083229064941406
Epoch 89, Batch 1000/3125, Loss: 1.6354856491088867, Uncertainty: 2.375852346420288
Epoch 89, Batch 1100/3125, Loss: 1.7136013507843018, Uncertainty: 2.1360626220703125
Epoch 89, Batch 1200/3125, Loss: 1.6668436527252197, Uncertainty: 2.181013345718384
Epoch 89, Batch 1300/3125, Loss: 1.357149362564087, Uncertainty: 1.7375099658966064
Epoch 89, Batch 1400/3125, Loss: 1.4223337173461914, Uncertainty: 1.9313994646072388
Epoch 89, Batch 1500/3125, Loss: 1.577815294265747, Uncertainty: 1.9041838645935059
Epoch 89, Batch 1600/3125, Loss: 1.5973451137542725, Uncertainty: 1.4996182918548584
Epoch 89, Batch 1700/3125, Loss: 1.678208589553833, Uncertainty: 2.1321074962615967
Epoch 89, Batch 1800/3125, Loss: 1.5789343118667603, Uncertainty: 1.9539111852645874
Epoch 89, Batch 1900/3125, Loss: 1.5730657577514648, Uncertainty: 2.083432197570801
Epoch 89, Batch 2000/3125, Loss: 1.3575201034545898, Uncertainty: 1.6117111444473267
Epoch 89, Batch 2100/3125, Loss: 1.8073086738586426, Uncertainty: 1.7024123668670654
Epoch 89, Batch 2200/3125, Loss: 1.8281140327453613, Uncertainty: 2.4146251678466797
Epoch 89, Batch 2300/3125, Loss: 1.6561484336853027, Uncertainty: 2.3617730140686035
Epoch 89, Batch 2400/3125, Loss: 2.0340325832366943, Uncertainty: 3.320101022720337
Epoch 89, Batch 2500/3125, Loss: 1.7693274021148682, Uncertainty: 2.4438509941101074
Epoch 89, Batch 2600/3125, Loss: 1.6713868379592896, Uncertainty: 2.310824394226074
Epoch 89, Batch 2700/3125, Loss: 1.5955034494400024, Uncertainty: 2.108304500579834
Epoch 89, Batch 2800/3125, Loss: 1.6300033330917358, Uncertainty: 2.107440233230591
Epoch 89, Batch 2900/3125, Loss: 1.9383213520050049, Uncertainty: 3.059946060180664
Epoch 89, Batch 3000/3125, Loss: 2.550814390182495, Uncertainty: 3.0911524295806885
Epoch 89, Batch 3100/3125, Loss: 1.7542322874069214, Uncertainty: 2.372751474380493

Training and Validation Results of Epoch 89:
================================
Training Loss: 1.3220079285812378, Training Uncertainty: 2.227979930038452, time: 193.57439398765564
Validation Loss: 1.108306687963588, Validation Uncertainty: 3.738533175205026, time: 44.089898109436035
Number of predictions within uncertainty interval: 147631/200000 (73.82%)

Epoch 90, Batch 100/3125, Loss: 1.6540741920471191, Uncertainty: 2.4194138050079346
Epoch 90, Batch 200/3125, Loss: 1.5133891105651855, Uncertainty: 2.178982734680176
Epoch 90, Batch 300/3125, Loss: 1.7400223016738892, Uncertainty: 2.055598497390747
Epoch 90, Batch 400/3125, Loss: 1.742037057876587, Uncertainty: 1.939495325088501
Epoch 90, Batch 500/3125, Loss: 1.6281954050064087, Uncertainty: 2.2735841274261475
Epoch 90, Batch 600/3125, Loss: 1.4938552379608154, Uncertainty: 2.0571393966674805
Epoch 90, Batch 700/3125, Loss: 1.6540089845657349, Uncertainty: 2.102774143218994
Epoch 90, Batch 800/3125, Loss: 1.5390145778656006, Uncertainty: 2.0485095977783203
Epoch 90, Batch 900/3125, Loss: 1.597820520401001, Uncertainty: 1.8175464868545532
Epoch 90, Batch 1000/3125, Loss: 1.647968053817749, Uncertainty: 1.8226243257522583
Epoch 90, Batch 1100/3125, Loss: 1.8810503482818604, Uncertainty: 2.6036548614501953
Epoch 90, Batch 1200/3125, Loss: 1.787864327430725, Uncertainty: 2.6850664615631104
Epoch 90, Batch 1300/3125, Loss: 2.1375396251678467, Uncertainty: 2.539741277694702
Epoch 90, Batch 1400/3125, Loss: 1.502455711364746, Uncertainty: 1.9689635038375854
Epoch 90, Batch 1500/3125, Loss: 1.5368454456329346, Uncertainty: 1.9049983024597168
Epoch 90, Batch 1600/3125, Loss: 1.782611608505249, Uncertainty: 2.609154224395752
Epoch 90, Batch 1700/3125, Loss: 1.5220388174057007, Uncertainty: 2.0546226501464844
Epoch 90, Batch 1800/3125, Loss: 1.6569297313690186, Uncertainty: 2.1160848140716553
Epoch 90, Batch 1900/3125, Loss: 1.7020045518875122, Uncertainty: 2.123532772064209
Epoch 90, Batch 2000/3125, Loss: 1.4948387145996094, Uncertainty: 2.0168392658233643
Epoch 90, Batch 2100/3125, Loss: 1.6983532905578613, Uncertainty: 2.3220486640930176
Epoch 90, Batch 2200/3125, Loss: 1.7041374444961548, Uncertainty: 2.0876646041870117
Epoch 90, Batch 2300/3125, Loss: 1.3851311206817627, Uncertainty: 1.6885313987731934
Epoch 90, Batch 2400/3125, Loss: 1.3762600421905518, Uncertainty: 1.6415177583694458
Epoch 90, Batch 2500/3125, Loss: 1.9668184518814087, Uncertainty: 2.280113458633423
Epoch 90, Batch 2600/3125, Loss: 1.8481745719909668, Uncertainty: 2.523383140563965
Epoch 90, Batch 2700/3125, Loss: 1.4886044263839722, Uncertainty: 1.87978196144104
Epoch 90, Batch 2800/3125, Loss: 1.5543203353881836, Uncertainty: 1.9286223649978638
Epoch 90, Batch 2900/3125, Loss: 1.8980441093444824, Uncertainty: 2.674363851547241
Epoch 90, Batch 3000/3125, Loss: 1.5792468786239624, Uncertainty: 1.9768465757369995
Epoch 90, Batch 3100/3125, Loss: 1.8419263362884521, Uncertainty: 2.0968174934387207

Training and Validation Results of Epoch 90:
================================
Training Loss: 1.3232189179229736, Training Uncertainty: 2.218549536514282, time: 194.50575351715088
Validation Loss: 1.0381823698882862, Validation Uncertainty: 3.410395456092132, time: 43.92041540145874
Number of predictions within uncertainty interval: 147214/200000 (73.61%)

Epoch 91, Batch 100/3125, Loss: 1.644381046295166, Uncertainty: 1.7361037731170654
Epoch 91, Batch 200/3125, Loss: 1.6269843578338623, Uncertainty: 2.456997871398926
Epoch 91, Batch 300/3125, Loss: 1.4876779317855835, Uncertainty: 1.9115341901779175
Epoch 91, Batch 400/3125, Loss: 1.5127806663513184, Uncertainty: 1.8188419342041016
Epoch 91, Batch 500/3125, Loss: 2.0913639068603516, Uncertainty: 2.2091941833496094
Epoch 91, Batch 600/3125, Loss: 1.5559101104736328, Uncertainty: 1.8708324432373047
Epoch 91, Batch 700/3125, Loss: 1.628355622291565, Uncertainty: 2.4336395263671875
Epoch 91, Batch 800/3125, Loss: 1.7739617824554443, Uncertainty: 1.9300081729888916
Epoch 91, Batch 900/3125, Loss: 1.6282715797424316, Uncertainty: 1.92742919921875
Epoch 91, Batch 1000/3125, Loss: 1.873531460762024, Uncertainty: 1.8032581806182861
Epoch 91, Batch 1100/3125, Loss: 1.7400071620941162, Uncertainty: 2.245180606842041
Epoch 91, Batch 1200/3125, Loss: 1.6510075330734253, Uncertainty: 2.1269659996032715
Epoch 91, Batch 1300/3125, Loss: 1.5919787883758545, Uncertainty: 2.1878509521484375
Epoch 91, Batch 1400/3125, Loss: 1.7907699346542358, Uncertainty: 2.1346027851104736
Epoch 91, Batch 1500/3125, Loss: 1.7416942119598389, Uncertainty: 1.9022033214569092
Epoch 91, Batch 1600/3125, Loss: 1.6112626791000366, Uncertainty: 1.7428853511810303
Epoch 91, Batch 1700/3125, Loss: 1.6006526947021484, Uncertainty: 2.1132490634918213
Epoch 91, Batch 1800/3125, Loss: 1.5935752391815186, Uncertainty: 2.0211594104766846
Epoch 91, Batch 1900/3125, Loss: 1.6347882747650146, Uncertainty: 2.4085869789123535
Epoch 91, Batch 2000/3125, Loss: 1.4904499053955078, Uncertainty: 1.938504934310913
Epoch 91, Batch 2100/3125, Loss: 1.6087021827697754, Uncertainty: 2.0782501697540283
Epoch 91, Batch 2200/3125, Loss: 2.2022597789764404, Uncertainty: 3.3552632331848145
Epoch 91, Batch 2300/3125, Loss: 1.652628779411316, Uncertainty: 2.267340660095215
Epoch 91, Batch 2400/3125, Loss: 1.7610085010528564, Uncertainty: 2.832359790802002
Epoch 91, Batch 2500/3125, Loss: 1.9253904819488525, Uncertainty: 2.2612648010253906
Epoch 91, Batch 2600/3125, Loss: 1.746368646621704, Uncertainty: 2.4827401638031006
Epoch 91, Batch 2700/3125, Loss: 1.5054855346679688, Uncertainty: 1.6988341808319092
Epoch 91, Batch 2800/3125, Loss: 1.5276132822036743, Uncertainty: 1.8253120183944702
Epoch 91, Batch 2900/3125, Loss: 1.8484320640563965, Uncertainty: 2.360020875930786
Epoch 91, Batch 3000/3125, Loss: 1.8095147609710693, Uncertainty: 1.8426132202148438
Epoch 91, Batch 3100/3125, Loss: 1.6805706024169922, Uncertainty: 2.0402750968933105

Training and Validation Results of Epoch 91:
================================
Training Loss: 1.2990989667320252, Training Uncertainty: 2.1865245715332033, time: 194.50635361671448
Validation Loss: 1.2699434366982307, Validation Uncertainty: 3.459092844782583, time: 44.17954659461975
Number of predictions within uncertainty interval: 133675/200000 (66.84%)

Epoch 92, Batch 100/3125, Loss: 1.6946866512298584, Uncertainty: 2.593585968017578
Epoch 92, Batch 200/3125, Loss: 1.5931209325790405, Uncertainty: 1.7878055572509766
Epoch 92, Batch 300/3125, Loss: 1.5176169872283936, Uncertainty: 1.9171173572540283
Epoch 92, Batch 400/3125, Loss: 1.8053498268127441, Uncertainty: 1.9437485933303833
Epoch 92, Batch 500/3125, Loss: 1.6307101249694824, Uncertainty: 1.821439504623413
Epoch 92, Batch 600/3125, Loss: 1.753328561782837, Uncertainty: 2.496992826461792
Epoch 92, Batch 700/3125, Loss: 1.735439419746399, Uncertainty: 2.497134208679199
Epoch 92, Batch 800/3125, Loss: 1.5381779670715332, Uncertainty: 1.8100202083587646
Epoch 92, Batch 900/3125, Loss: 1.6661059856414795, Uncertainty: 2.178431510925293
Epoch 92, Batch 1000/3125, Loss: 1.5345479249954224, Uncertainty: 1.7270841598510742
Epoch 92, Batch 1100/3125, Loss: 2.286276340484619, Uncertainty: 2.336587429046631
Epoch 92, Batch 1200/3125, Loss: 1.8582631349563599, Uncertainty: 2.7020740509033203
Epoch 92, Batch 1300/3125, Loss: 1.7850134372711182, Uncertainty: 2.8831605911254883
Epoch 92, Batch 1400/3125, Loss: 1.520307183265686, Uncertainty: 1.9568004608154297
Epoch 92, Batch 1500/3125, Loss: 1.6271612644195557, Uncertainty: 2.2877559661865234
Epoch 92, Batch 1600/3125, Loss: 1.4650170803070068, Uncertainty: 1.7192237377166748
Epoch 92, Batch 1700/3125, Loss: 1.6106024980545044, Uncertainty: 1.750375509262085
Epoch 92, Batch 1800/3125, Loss: 1.6003026962280273, Uncertainty: 2.101128101348877
Epoch 92, Batch 1900/3125, Loss: 1.4403587579727173, Uncertainty: 1.9333596229553223
Epoch 92, Batch 2000/3125, Loss: 1.7384461164474487, Uncertainty: 2.3800580501556396
Epoch 92, Batch 2100/3125, Loss: 1.7045557498931885, Uncertainty: 2.158099889755249
Epoch 92, Batch 2200/3125, Loss: 1.4649410247802734, Uncertainty: 1.8423776626586914
Epoch 92, Batch 2300/3125, Loss: 1.972583293914795, Uncertainty: 2.787703514099121
Epoch 92, Batch 2400/3125, Loss: 1.8268227577209473, Uncertainty: 2.8282198905944824
Epoch 92, Batch 2500/3125, Loss: 1.4183311462402344, Uncertainty: 1.8760411739349365
Epoch 92, Batch 2600/3125, Loss: 1.7107633352279663, Uncertainty: 2.3621623516082764
Epoch 92, Batch 2700/3125, Loss: 1.4866399765014648, Uncertainty: 1.7094146013259888
Epoch 92, Batch 2800/3125, Loss: 1.7747035026550293, Uncertainty: 2.034681797027588
Epoch 92, Batch 2900/3125, Loss: 1.7615325450897217, Uncertainty: 2.4164509773254395
Epoch 92, Batch 3000/3125, Loss: 1.4435646533966064, Uncertainty: 1.9124062061309814
Epoch 92, Batch 3100/3125, Loss: 1.5479629039764404, Uncertainty: 1.9269757270812988

Training and Validation Results of Epoch 92:
================================
Training Loss: 1.2932958173179627, Training Uncertainty: 2.1981022065353395, time: 194.20383667945862
Validation Loss: 0.99018918972491, Validation Uncertainty: 3.0815706304881885, time: 44.65038514137268
Number of predictions within uncertainty interval: 141512/200000 (70.76%)

Epoch 93, Batch 100/3125, Loss: 1.3526194095611572, Uncertainty: 1.850085735321045
Epoch 93, Batch 200/3125, Loss: 1.8085966110229492, Uncertainty: 2.798016309738159
Epoch 93, Batch 300/3125, Loss: 1.6364187002182007, Uncertainty: 2.0209078788757324
Epoch 93, Batch 400/3125, Loss: 1.3176240921020508, Uncertainty: 1.581647515296936
Epoch 93, Batch 500/3125, Loss: 1.7614829540252686, Uncertainty: 2.6564035415649414
Epoch 93, Batch 600/3125, Loss: 1.7166508436203003, Uncertainty: 2.712352991104126
Epoch 93, Batch 700/3125, Loss: 1.57968008518219, Uncertainty: 1.8262603282928467
Epoch 93, Batch 800/3125, Loss: 1.623146891593933, Uncertainty: 2.158994674682617
Epoch 93, Batch 900/3125, Loss: 2.0029616355895996, Uncertainty: 2.5110840797424316
Epoch 93, Batch 1000/3125, Loss: 1.808097004890442, Uncertainty: 1.594012975692749
Epoch 93, Batch 1100/3125, Loss: 1.6937646865844727, Uncertainty: 1.9005824327468872
Epoch 93, Batch 1200/3125, Loss: 1.6845275163650513, Uncertainty: 1.895641803741455
Epoch 93, Batch 1300/3125, Loss: 1.660641074180603, Uncertainty: 2.6377596855163574
Epoch 93, Batch 1400/3125, Loss: 1.8557724952697754, Uncertainty: 2.8254966735839844
Epoch 93, Batch 1500/3125, Loss: 1.4609003067016602, Uncertainty: 2.0408966541290283
Epoch 93, Batch 1600/3125, Loss: 2.270260810852051, Uncertainty: 3.2068796157836914
Epoch 93, Batch 1700/3125, Loss: 1.7017238140106201, Uncertainty: 2.680204391479492
Epoch 93, Batch 1800/3125, Loss: 1.5858500003814697, Uncertainty: 1.8737249374389648
Epoch 93, Batch 1900/3125, Loss: 1.5434386730194092, Uncertainty: 2.147918701171875
Epoch 93, Batch 2000/3125, Loss: 1.462870478630066, Uncertainty: 1.8121740818023682
Epoch 93, Batch 2100/3125, Loss: 1.9495445489883423, Uncertainty: 1.700636386871338
Epoch 93, Batch 2200/3125, Loss: 1.7815172672271729, Uncertainty: 2.1882243156433105
Epoch 93, Batch 2300/3125, Loss: 1.559644341468811, Uncertainty: 1.9300873279571533
Epoch 93, Batch 2400/3125, Loss: 1.698882818222046, Uncertainty: 2.0139505863189697
Epoch 93, Batch 2500/3125, Loss: 1.4234473705291748, Uncertainty: 1.897961974143982
Epoch 93, Batch 2600/3125, Loss: 1.6296396255493164, Uncertainty: 2.2267308235168457
Epoch 93, Batch 2700/3125, Loss: 1.442362666130066, Uncertainty: 2.045529842376709
Epoch 93, Batch 2800/3125, Loss: 1.5293934345245361, Uncertainty: 2.012910842895508
Epoch 93, Batch 2900/3125, Loss: 1.868852138519287, Uncertainty: 2.3559765815734863
Epoch 93, Batch 3000/3125, Loss: 1.5465924739837646, Uncertainty: 1.8306212425231934
Epoch 93, Batch 3100/3125, Loss: 1.7449146509170532, Uncertainty: 2.1208300590515137

Training and Validation Results of Epoch 93:
================================
Training Loss: 1.287569236087799, Training Uncertainty: 2.196214793701172, time: 194.3933744430542
Validation Loss: 1.2174996851045456, Validation Uncertainty: 2.948001666751969, time: 45.464903354644775
Number of predictions within uncertainty interval: 125099/200000 (62.55%)

Epoch 94, Batch 100/3125, Loss: 1.6666576862335205, Uncertainty: 1.953080177307129
Epoch 94, Batch 200/3125, Loss: 1.4903424978256226, Uncertainty: 1.973576545715332
Epoch 94, Batch 300/3125, Loss: 1.6949799060821533, Uncertainty: 2.4568562507629395
Epoch 94, Batch 400/3125, Loss: 1.5679576396942139, Uncertainty: 2.2885022163391113
Epoch 94, Batch 500/3125, Loss: 1.6087325811386108, Uncertainty: 2.218493700027466
Epoch 94, Batch 600/3125, Loss: 1.6648173332214355, Uncertainty: 2.27042818069458
Epoch 94, Batch 700/3125, Loss: 1.3636984825134277, Uncertainty: 1.6056747436523438
Epoch 94, Batch 800/3125, Loss: 1.8006038665771484, Uncertainty: 1.9223159551620483
Epoch 94, Batch 900/3125, Loss: 1.85297691822052, Uncertainty: 2.127094268798828
Epoch 94, Batch 1000/3125, Loss: 2.136749744415283, Uncertainty: 1.934521198272705
Epoch 94, Batch 1100/3125, Loss: 1.9092869758605957, Uncertainty: 2.2791478633880615
Epoch 94, Batch 1200/3125, Loss: 1.666081428527832, Uncertainty: 1.6430597305297852
Epoch 94, Batch 1300/3125, Loss: 1.4544066190719604, Uncertainty: 1.899379014968872
Epoch 94, Batch 1400/3125, Loss: 1.638314962387085, Uncertainty: 2.326234817504883
Epoch 94, Batch 1500/3125, Loss: 1.7306816577911377, Uncertainty: 2.632544994354248
Epoch 94, Batch 1600/3125, Loss: 1.6751046180725098, Uncertainty: 2.2164602279663086
Epoch 94, Batch 1700/3125, Loss: 1.8837101459503174, Uncertainty: 2.0156900882720947
Epoch 94, Batch 1800/3125, Loss: 1.4365403652191162, Uncertainty: 1.802348017692566
Epoch 94, Batch 1900/3125, Loss: 1.7589850425720215, Uncertainty: 2.6189935207366943
Epoch 94, Batch 2000/3125, Loss: 1.4154307842254639, Uncertainty: 1.8975671529769897
Epoch 94, Batch 2100/3125, Loss: 1.7140250205993652, Uncertainty: 1.9460300207138062
Epoch 94, Batch 2200/3125, Loss: 1.8410186767578125, Uncertainty: 2.2484071254730225
Epoch 94, Batch 2300/3125, Loss: 1.790816068649292, Uncertainty: 2.0594608783721924
Epoch 94, Batch 2400/3125, Loss: 1.7781522274017334, Uncertainty: 2.515415668487549
Epoch 94, Batch 2500/3125, Loss: 1.6277772188186646, Uncertainty: 1.6571152210235596
Epoch 94, Batch 2600/3125, Loss: 1.434435248374939, Uncertainty: 1.839589238166809
Epoch 94, Batch 2700/3125, Loss: 1.8322079181671143, Uncertainty: 2.896101951599121
Epoch 94, Batch 2800/3125, Loss: 1.7759119272232056, Uncertainty: 2.6794941425323486
Epoch 94, Batch 2900/3125, Loss: 1.8680925369262695, Uncertainty: 2.9770328998565674
Epoch 94, Batch 3000/3125, Loss: 2.0232977867126465, Uncertainty: 2.9308383464813232
Epoch 94, Batch 3100/3125, Loss: 1.9641106128692627, Uncertainty: 2.12927508354187

Training and Validation Results of Epoch 94:
================================
Training Loss: 1.2762437957000732, Training Uncertainty: 2.180581251373291, time: 192.89045572280884
Validation Loss: 1.017340854458187, Validation Uncertainty: 2.835917158200003, time: 44.24903726577759
Number of predictions within uncertainty interval: 132940/200000 (66.47%)

Epoch 95, Batch 100/3125, Loss: 1.4448955059051514, Uncertainty: 1.9809045791625977
Epoch 95, Batch 200/3125, Loss: 1.7138891220092773, Uncertainty: 2.685962438583374
Epoch 95, Batch 300/3125, Loss: 1.6522811651229858, Uncertainty: 2.0350663661956787
Epoch 95, Batch 400/3125, Loss: 1.6448004245758057, Uncertainty: 2.1592905521392822
Epoch 95, Batch 500/3125, Loss: 1.6607716083526611, Uncertainty: 2.439420223236084
Epoch 95, Batch 600/3125, Loss: 1.7718256711959839, Uncertainty: 2.9199540615081787
Epoch 95, Batch 700/3125, Loss: 1.5661436319351196, Uncertainty: 1.858642339706421
Epoch 95, Batch 800/3125, Loss: 1.555755376815796, Uncertainty: 1.9343886375427246
Epoch 95, Batch 900/3125, Loss: 1.754733681678772, Uncertainty: 2.009035348892212
Epoch 95, Batch 1000/3125, Loss: 1.8303804397583008, Uncertainty: 1.9660089015960693
Epoch 95, Batch 1100/3125, Loss: 1.855384349822998, Uncertainty: 2.6519083976745605
Epoch 95, Batch 1200/3125, Loss: 1.8327504396438599, Uncertainty: 2.05250883102417
Epoch 95, Batch 1300/3125, Loss: 1.936264991760254, Uncertainty: 2.2655997276306152
Epoch 95, Batch 1400/3125, Loss: 1.490846037864685, Uncertainty: 1.9607563018798828
Epoch 95, Batch 1500/3125, Loss: 1.640697956085205, Uncertainty: 1.9765264987945557
Epoch 95, Batch 1600/3125, Loss: 1.7646613121032715, Uncertainty: 1.529382348060608
Epoch 95, Batch 1700/3125, Loss: 1.5260841846466064, Uncertainty: 2.2069032192230225
Epoch 95, Batch 1800/3125, Loss: 1.6146769523620605, Uncertainty: 2.053856372833252
Epoch 95, Batch 1900/3125, Loss: 1.866880178451538, Uncertainty: 2.179330348968506
Epoch 95, Batch 2000/3125, Loss: 1.5346897840499878, Uncertainty: 2.030283212661743
Epoch 95, Batch 2100/3125, Loss: 1.7202321290969849, Uncertainty: 2.335844039916992
Epoch 95, Batch 2200/3125, Loss: 2.053351640701294, Uncertainty: 2.9641408920288086
Epoch 95, Batch 2300/3125, Loss: 1.551863193511963, Uncertainty: 1.969231128692627
Epoch 95, Batch 2400/3125, Loss: 2.343876361846924, Uncertainty: 2.138322591781616
Epoch 95, Batch 2500/3125, Loss: 1.5619091987609863, Uncertainty: 2.085710048675537
Epoch 95, Batch 2600/3125, Loss: 1.5568616390228271, Uncertainty: 1.9065417051315308
Epoch 95, Batch 2700/3125, Loss: 1.8194642066955566, Uncertainty: 2.8991971015930176
Epoch 95, Batch 2800/3125, Loss: 1.5257028341293335, Uncertainty: 1.7479006052017212
Epoch 95, Batch 2900/3125, Loss: 1.403656005859375, Uncertainty: 1.7187005281448364
Epoch 95, Batch 3000/3125, Loss: 1.8804373741149902, Uncertainty: 2.57615327835083
Epoch 95, Batch 3100/3125, Loss: 1.5976545810699463, Uncertainty: 2.033749580383301

Training and Validation Results of Epoch 95:
================================
Training Loss: 1.273794173336029, Training Uncertainty: 2.1563764291000367, time: 199.8940680027008
Validation Loss: 1.056438755120158, Validation Uncertainty: 4.144651424549425, time: 44.035284757614136
Number of predictions within uncertainty interval: 161123/200000 (80.56%)

Epoch 96, Batch 100/3125, Loss: 1.4461705684661865, Uncertainty: 1.7995558977127075
Epoch 96, Batch 200/3125, Loss: 1.3988091945648193, Uncertainty: 1.8979301452636719
Epoch 96, Batch 300/3125, Loss: 1.6320149898529053, Uncertainty: 1.7988594770431519
Epoch 96, Batch 400/3125, Loss: 1.5764954090118408, Uncertainty: 2.1489713191986084
Epoch 96, Batch 500/3125, Loss: 1.3318274021148682, Uncertainty: 1.7415764331817627
Epoch 96, Batch 600/3125, Loss: 1.698319435119629, Uncertainty: 2.537250280380249
Epoch 96, Batch 700/3125, Loss: 1.5350369215011597, Uncertainty: 1.990694284439087
Epoch 96, Batch 800/3125, Loss: 1.4299571514129639, Uncertainty: 1.8230036497116089
Epoch 96, Batch 900/3125, Loss: 1.67555832862854, Uncertainty: 2.1362764835357666
Epoch 96, Batch 1000/3125, Loss: 1.4734548330307007, Uncertainty: 1.6716705560684204
Epoch 96, Batch 1100/3125, Loss: 1.7247395515441895, Uncertainty: 2.310976982116699
Epoch 96, Batch 1200/3125, Loss: 1.7354700565338135, Uncertainty: 2.2519562244415283
Epoch 96, Batch 1300/3125, Loss: 1.7198610305786133, Uncertainty: 2.3454036712646484
Epoch 96, Batch 1400/3125, Loss: 1.6760363578796387, Uncertainty: 2.177429676055908
Epoch 96, Batch 1500/3125, Loss: 1.796632170677185, Uncertainty: 2.749513864517212
Epoch 96, Batch 1600/3125, Loss: 1.6271662712097168, Uncertainty: 2.0837619304656982
Epoch 96, Batch 1700/3125, Loss: 1.6415019035339355, Uncertainty: 2.2532730102539062
Epoch 96, Batch 1800/3125, Loss: 1.4989644289016724, Uncertainty: 1.7299158573150635
Epoch 96, Batch 1900/3125, Loss: 1.8094264268875122, Uncertainty: 2.339871406555176
Epoch 96, Batch 2000/3125, Loss: 1.4871822595596313, Uncertainty: 1.854461431503296
Epoch 96, Batch 2100/3125, Loss: 1.7648255825042725, Uncertainty: 2.2352118492126465
Epoch 96, Batch 2200/3125, Loss: 2.1140079498291016, Uncertainty: 3.446518898010254
Epoch 96, Batch 2300/3125, Loss: 1.5346267223358154, Uncertainty: 1.8291770219802856
Epoch 96, Batch 2400/3125, Loss: 2.270771026611328, Uncertainty: 3.1252918243408203
Epoch 96, Batch 2500/3125, Loss: 1.4489853382110596, Uncertainty: 1.5971481800079346
Epoch 96, Batch 2600/3125, Loss: 1.4180490970611572, Uncertainty: 1.9308297634124756
Epoch 96, Batch 2700/3125, Loss: 1.8882253170013428, Uncertainty: 1.9290072917938232
Epoch 96, Batch 2800/3125, Loss: 1.4700758457183838, Uncertainty: 1.759673833847046
Epoch 96, Batch 2900/3125, Loss: 1.5035297870635986, Uncertainty: 1.9898037910461426
Epoch 96, Batch 3000/3125, Loss: 1.4959925413131714, Uncertainty: 1.919111728668213
Epoch 96, Batch 3100/3125, Loss: 1.5681719779968262, Uncertainty: 2.0106444358825684

Training and Validation Results of Epoch 96:
================================
Training Loss: 1.2699252342033387, Training Uncertainty: 2.1597730274581908, time: 194.93079447746277
Validation Loss: 0.9668870992825159, Validation Uncertainty: 4.838864634408975, time: 45.76858687400818
Number of predictions within uncertainty interval: 175515/200000 (87.76%)

Epoch 97, Batch 100/3125, Loss: 1.259636402130127, Uncertainty: 1.6963125467300415
Epoch 97, Batch 200/3125, Loss: 1.7948272228240967, Uncertainty: 2.8164639472961426
Epoch 97, Batch 300/3125, Loss: 1.4158915281295776, Uncertainty: 1.8284528255462646
Epoch 97, Batch 400/3125, Loss: 1.576361894607544, Uncertainty: 2.53262996673584
Epoch 97, Batch 500/3125, Loss: 1.3983116149902344, Uncertainty: 1.8263556957244873
Epoch 97, Batch 600/3125, Loss: 1.7576864957809448, Uncertainty: 2.5211129188537598
Epoch 97, Batch 700/3125, Loss: 1.5163952112197876, Uncertainty: 1.8615026473999023
Epoch 97, Batch 800/3125, Loss: 1.9165396690368652, Uncertainty: 3.0511484146118164
Epoch 97, Batch 900/3125, Loss: 1.8480706214904785, Uncertainty: 2.7168827056884766
Epoch 97, Batch 1000/3125, Loss: 1.535017967224121, Uncertainty: 1.6900925636291504
Epoch 97, Batch 1100/3125, Loss: 1.934688687324524, Uncertainty: 2.4253828525543213
Epoch 97, Batch 1200/3125, Loss: 1.6295850276947021, Uncertainty: 1.711875319480896
Epoch 97, Batch 1300/3125, Loss: 1.8489069938659668, Uncertainty: 2.6763992309570312
Epoch 97, Batch 1400/3125, Loss: 1.4619220495224, Uncertainty: 1.7778360843658447
Epoch 97, Batch 1500/3125, Loss: 1.5925992727279663, Uncertainty: 1.7861939668655396
Epoch 97, Batch 1600/3125, Loss: 1.4360339641571045, Uncertainty: 1.8395253419876099
Epoch 97, Batch 1700/3125, Loss: 1.8750413656234741, Uncertainty: 2.2319040298461914
Epoch 97, Batch 1800/3125, Loss: 1.6141072511672974, Uncertainty: 2.4326601028442383
Epoch 97, Batch 1900/3125, Loss: 1.5322723388671875, Uncertainty: 2.045039176940918
Epoch 97, Batch 2000/3125, Loss: 1.6565388441085815, Uncertainty: 2.2731661796569824
Epoch 97, Batch 2100/3125, Loss: 2.046200752258301, Uncertainty: 2.147533416748047
Epoch 97, Batch 2200/3125, Loss: 1.7765777111053467, Uncertainty: 2.392118453979492
Epoch 97, Batch 2300/3125, Loss: 1.6420481204986572, Uncertainty: 2.242879867553711
Epoch 97, Batch 2400/3125, Loss: 1.837785005569458, Uncertainty: 2.144573211669922
Epoch 97, Batch 2500/3125, Loss: 2.0928380489349365, Uncertainty: 1.7483725547790527
Epoch 97, Batch 2600/3125, Loss: 1.5396968126296997, Uncertainty: 2.2572779655456543
Epoch 97, Batch 2700/3125, Loss: 1.6327404975891113, Uncertainty: 2.321861505508423
Epoch 97, Batch 2800/3125, Loss: 1.6297500133514404, Uncertainty: 2.3132007122039795
Epoch 97, Batch 2900/3125, Loss: 2.022404670715332, Uncertainty: 3.4906678199768066
Epoch 97, Batch 3000/3125, Loss: 1.9227087497711182, Uncertainty: 2.141885757446289
Epoch 97, Batch 3100/3125, Loss: 1.8479629755020142, Uncertainty: 2.434164524078369

Training and Validation Results of Epoch 97:
================================
Training Loss: 1.244059661693573, Training Uncertainty: 2.1171437562942503, time: 197.79844045639038
Validation Loss: 0.9998428098990789, Validation Uncertainty: 4.2987660934858, time: 46.13150668144226
Number of predictions within uncertainty interval: 165882/200000 (82.94%)

Epoch 98, Batch 100/3125, Loss: 1.5765138864517212, Uncertainty: 2.1892948150634766
Epoch 98, Batch 200/3125, Loss: 1.766316294670105, Uncertainty: 2.7667078971862793
Epoch 98, Batch 300/3125, Loss: 2.0779848098754883, Uncertainty: 2.2428181171417236
Epoch 98, Batch 400/3125, Loss: 1.5048465728759766, Uncertainty: 1.9144484996795654
Epoch 98, Batch 500/3125, Loss: 1.5081363916397095, Uncertainty: 2.1967179775238037
Epoch 98, Batch 600/3125, Loss: 1.7303348779678345, Uncertainty: 2.043750762939453
Epoch 98, Batch 700/3125, Loss: 1.3541581630706787, Uncertainty: 1.8084557056427002
Epoch 98, Batch 800/3125, Loss: 1.4638160467147827, Uncertainty: 2.047750949859619
Epoch 98, Batch 900/3125, Loss: 1.5849313735961914, Uncertainty: 1.9671648740768433
Epoch 98, Batch 1000/3125, Loss: 1.7133386135101318, Uncertainty: 1.8299107551574707
Epoch 98, Batch 1100/3125, Loss: 1.7202874422073364, Uncertainty: 2.2278318405151367
Epoch 98, Batch 1200/3125, Loss: 1.4643981456756592, Uncertainty: 1.8572134971618652
Epoch 98, Batch 1300/3125, Loss: 1.4803082942962646, Uncertainty: 2.020270824432373
Epoch 98, Batch 1400/3125, Loss: 1.5755822658538818, Uncertainty: 2.190397024154663
Epoch 98, Batch 1500/3125, Loss: 1.5550384521484375, Uncertainty: 1.911082148551941
Epoch 98, Batch 1600/3125, Loss: 1.6832282543182373, Uncertainty: 2.142155170440674
Epoch 98, Batch 1700/3125, Loss: 1.4573132991790771, Uncertainty: 1.8389101028442383
Epoch 98, Batch 1800/3125, Loss: 1.48838472366333, Uncertainty: 1.7105140686035156
Epoch 98, Batch 1900/3125, Loss: 1.463852047920227, Uncertainty: 2.0871152877807617
Epoch 98, Batch 2000/3125, Loss: 1.3967963457107544, Uncertainty: 1.5889288187026978
Epoch 98, Batch 2100/3125, Loss: 1.687893271446228, Uncertainty: 2.348879814147949
Epoch 98, Batch 2200/3125, Loss: 1.2712616920471191, Uncertainty: 1.5773981809616089
Epoch 98, Batch 2300/3125, Loss: 1.6075618267059326, Uncertainty: 2.2184414863586426
Epoch 98, Batch 2400/3125, Loss: 2.2862942218780518, Uncertainty: 3.8396811485290527
Epoch 98, Batch 2500/3125, Loss: 1.5454117059707642, Uncertainty: 2.3185439109802246
Epoch 98, Batch 2600/3125, Loss: 1.7645113468170166, Uncertainty: 1.8300507068634033
Epoch 98, Batch 2700/3125, Loss: 1.6477874517440796, Uncertainty: 2.244645118713379
Epoch 98, Batch 2800/3125, Loss: 1.3188517093658447, Uncertainty: 1.7418473958969116
Epoch 98, Batch 2900/3125, Loss: 1.690277099609375, Uncertainty: 2.1575326919555664
Epoch 98, Batch 3000/3125, Loss: 1.808670163154602, Uncertainty: 2.473588466644287
Epoch 98, Batch 3100/3125, Loss: 1.4722092151641846, Uncertainty: 1.6770356893539429

Training and Validation Results of Epoch 98:
================================
Training Loss: 1.2450520936775207, Training Uncertainty: 2.1107822758102417, time: 197.89167141914368
Validation Loss: 1.421430294013694, Validation Uncertainty: 3.6974365906337336, time: 46.01261878013611
Number of predictions within uncertainty interval: 131944/200000 (65.97%)

Epoch 99, Batch 100/3125, Loss: 1.468787670135498, Uncertainty: 1.8216028213500977
Epoch 99, Batch 200/3125, Loss: 1.4607229232788086, Uncertainty: 2.040386915206909
Epoch 99, Batch 300/3125, Loss: 1.7405009269714355, Uncertainty: 2.4079842567443848
Epoch 99, Batch 400/3125, Loss: 1.3068029880523682, Uncertainty: 1.6427342891693115
Epoch 99, Batch 500/3125, Loss: 1.4843610525131226, Uncertainty: 1.9961481094360352
Epoch 99, Batch 600/3125, Loss: 1.7863976955413818, Uncertainty: 2.3379557132720947
Epoch 99, Batch 700/3125, Loss: 1.6225483417510986, Uncertainty: 1.8997228145599365
Epoch 99, Batch 800/3125, Loss: 1.6501295566558838, Uncertainty: 2.297405958175659
Epoch 99, Batch 900/3125, Loss: 1.6863012313842773, Uncertainty: 2.132929801940918
Epoch 99, Batch 1000/3125, Loss: 1.6173650026321411, Uncertainty: 1.9392189979553223
Epoch 99, Batch 1100/3125, Loss: 1.528759241104126, Uncertainty: 1.8677366971969604
Epoch 99, Batch 1200/3125, Loss: 1.7333331108093262, Uncertainty: 2.6290512084960938
Epoch 99, Batch 1300/3125, Loss: 1.416621208190918, Uncertainty: 1.8644016981124878
Epoch 99, Batch 1400/3125, Loss: 1.499997615814209, Uncertainty: 1.9534642696380615
Epoch 99, Batch 1500/3125, Loss: 1.8039109706878662, Uncertainty: 1.8594179153442383
Epoch 99, Batch 1600/3125, Loss: 1.6240154504776, Uncertainty: 2.2004623413085938
Epoch 99, Batch 1700/3125, Loss: 1.583409309387207, Uncertainty: 2.1405911445617676
Epoch 99, Batch 1800/3125, Loss: 1.6975957155227661, Uncertainty: 2.112635612487793
Epoch 99, Batch 1900/3125, Loss: 1.8783063888549805, Uncertainty: 2.3953697681427
Epoch 99, Batch 2000/3125, Loss: 1.6902281045913696, Uncertainty: 2.617299795150757
Epoch 99, Batch 2100/3125, Loss: 1.672332525253296, Uncertainty: 1.9530060291290283
Epoch 99, Batch 2200/3125, Loss: 2.020317554473877, Uncertainty: 3.2298622131347656
Epoch 99, Batch 2300/3125, Loss: 1.9624985456466675, Uncertainty: 2.7059898376464844
Epoch 99, Batch 2400/3125, Loss: 1.898271083831787, Uncertainty: 2.0218992233276367
Epoch 99, Batch 2500/3125, Loss: 1.5310404300689697, Uncertainty: 1.7854610681533813
Epoch 99, Batch 2600/3125, Loss: 1.6818757057189941, Uncertainty: 1.9434483051300049
Epoch 99, Batch 2700/3125, Loss: 1.7973270416259766, Uncertainty: 2.4831719398498535
Epoch 99, Batch 2800/3125, Loss: 1.5193805694580078, Uncertainty: 1.8693408966064453
Epoch 99, Batch 2900/3125, Loss: 1.4612120389938354, Uncertainty: 1.9450268745422363
Epoch 99, Batch 3000/3125, Loss: 1.5102839469909668, Uncertainty: 1.7659049034118652
Epoch 99, Batch 3100/3125, Loss: 1.5061428546905518, Uncertainty: 1.9595588445663452

Training and Validation Results of Epoch 99:
================================
Training Loss: 1.2351618043518067, Training Uncertainty: 2.1197879887771607, time: 197.54899191856384
Validation Loss: 0.9562896797266762, Validation Uncertainty: 4.2424689964260285, time: 46.21928429603577
Number of predictions within uncertainty interval: 163027/200000 (81.51%)

Epoch 100, Batch 100/3125, Loss: 1.3157932758331299, Uncertainty: 1.6297919750213623
Epoch 100, Batch 200/3125, Loss: 1.4002647399902344, Uncertainty: 1.8081730604171753
Epoch 100, Batch 300/3125, Loss: 1.4182342290878296, Uncertainty: 1.9316635131835938
Epoch 100, Batch 400/3125, Loss: 1.465157151222229, Uncertainty: 1.8355159759521484
Epoch 100, Batch 500/3125, Loss: 1.778428554534912, Uncertainty: 2.1137092113494873
Epoch 100, Batch 600/3125, Loss: 1.7051093578338623, Uncertainty: 1.809623122215271
Epoch 100, Batch 700/3125, Loss: 1.5356574058532715, Uncertainty: 2.2218382358551025
Epoch 100, Batch 800/3125, Loss: 1.3803465366363525, Uncertainty: 1.7598611116409302
Epoch 100, Batch 900/3125, Loss: 1.935213565826416, Uncertainty: 3.1468100547790527
Epoch 100, Batch 1000/3125, Loss: 1.5310070514678955, Uncertainty: 1.925370216369629
Epoch 100, Batch 1100/3125, Loss: 1.5366289615631104, Uncertainty: 1.8176637887954712
Epoch 100, Batch 1200/3125, Loss: 1.5695064067840576, Uncertainty: 1.9972145557403564
Epoch 100, Batch 1300/3125, Loss: 1.2935492992401123, Uncertainty: 1.656952142715454
Epoch 100, Batch 1400/3125, Loss: 1.475305199623108, Uncertainty: 1.656128168106079
Epoch 100, Batch 1500/3125, Loss: 1.7019881010055542, Uncertainty: 1.8508422374725342
Epoch 100, Batch 1600/3125, Loss: 1.4533956050872803, Uncertainty: 1.8884472846984863
Epoch 100, Batch 1700/3125, Loss: 1.397907018661499, Uncertainty: 1.8981009721755981
Epoch 100, Batch 1800/3125, Loss: 1.604250192642212, Uncertainty: 1.6327221393585205
Epoch 100, Batch 1900/3125, Loss: 1.6876024007797241, Uncertainty: 2.246180772781372
Epoch 100, Batch 2000/3125, Loss: 1.5293986797332764, Uncertainty: 1.9773722887039185
Epoch 100, Batch 2100/3125, Loss: 1.5214903354644775, Uncertainty: 1.9406955242156982
Epoch 100, Batch 2200/3125, Loss: 1.5037411451339722, Uncertainty: 2.272284984588623
Epoch 100, Batch 2300/3125, Loss: 1.9706063270568848, Uncertainty: 2.9469027519226074
Epoch 100, Batch 2400/3125, Loss: 1.5605491399765015, Uncertainty: 2.0675129890441895
Epoch 100, Batch 2500/3125, Loss: 1.4229408502578735, Uncertainty: 1.8133176565170288
Epoch 100, Batch 2600/3125, Loss: 1.5376296043395996, Uncertainty: 2.069253921508789
Epoch 100, Batch 2700/3125, Loss: 1.6571896076202393, Uncertainty: 1.9436993598937988
Epoch 100, Batch 2800/3125, Loss: 1.6493573188781738, Uncertainty: 1.9470813274383545
Epoch 100, Batch 2900/3125, Loss: 2.139223098754883, Uncertainty: 3.915205717086792
Epoch 100, Batch 3000/3125, Loss: 1.73455011844635, Uncertainty: 2.6522250175476074
Epoch 100, Batch 3100/3125, Loss: 1.5059043169021606, Uncertainty: 2.0992448329925537

Training and Validation Results of Epoch 100:
================================
Training Loss: 1.2360957582855225, Training Uncertainty: 2.122813219528198, time: 209.9068901538849
Validation Loss: 0.97128761332968, Validation Uncertainty: 2.9780213299309812, time: 46.16766285896301
Number of predictions within uncertainty interval: 144232/200000 (72.12%)

Epoch 101, Batch 100/3125, Loss: 1.5123088359832764, Uncertainty: 2.01495361328125
Epoch 101, Batch 200/3125, Loss: 1.588664174079895, Uncertainty: 1.99546217918396
Epoch 101, Batch 300/3125, Loss: 1.6004564762115479, Uncertainty: 2.2052981853485107
Epoch 101, Batch 400/3125, Loss: 1.3813703060150146, Uncertainty: 1.6647177934646606
Epoch 101, Batch 500/3125, Loss: 1.6038891077041626, Uncertainty: 2.249980926513672
Epoch 101, Batch 600/3125, Loss: 1.486208438873291, Uncertainty: 1.8137869834899902
Epoch 101, Batch 700/3125, Loss: 1.7874257564544678, Uncertainty: 2.2999913692474365
Epoch 101, Batch 800/3125, Loss: 1.6493401527404785, Uncertainty: 1.898242712020874
Epoch 101, Batch 900/3125, Loss: 1.766558289527893, Uncertainty: 2.6276373863220215
Epoch 101, Batch 1000/3125, Loss: 1.3919024467468262, Uncertainty: 1.796086311340332
Epoch 101, Batch 1100/3125, Loss: 1.5039652585983276, Uncertainty: 1.8807833194732666
Epoch 101, Batch 1200/3125, Loss: 1.6722073554992676, Uncertainty: 2.3879714012145996
Epoch 101, Batch 1300/3125, Loss: 1.4813728332519531, Uncertainty: 2.0904359817504883
Epoch 101, Batch 1400/3125, Loss: 1.480195164680481, Uncertainty: 1.9091079235076904
Epoch 101, Batch 1500/3125, Loss: 1.6566836833953857, Uncertainty: 1.6128060817718506
Epoch 101, Batch 1600/3125, Loss: 1.5357701778411865, Uncertainty: 1.8324869871139526
Epoch 101, Batch 1700/3125, Loss: 1.3334465026855469, Uncertainty: 1.8703449964523315
Epoch 101, Batch 1800/3125, Loss: 1.6721398830413818, Uncertainty: 1.683476448059082
Epoch 101, Batch 1900/3125, Loss: 1.6644854545593262, Uncertainty: 2.0570998191833496
Epoch 101, Batch 2000/3125, Loss: 1.8104701042175293, Uncertainty: 1.9411883354187012
Epoch 101, Batch 2100/3125, Loss: 1.665478229522705, Uncertainty: 2.037550449371338
Epoch 101, Batch 2200/3125, Loss: 1.507124423980713, Uncertainty: 1.7234684228897095
Epoch 101, Batch 2300/3125, Loss: 1.7419896125793457, Uncertainty: 2.975572109222412
Epoch 101, Batch 2400/3125, Loss: 1.6110773086547852, Uncertainty: 2.4634132385253906
Epoch 101, Batch 2500/3125, Loss: 1.813408613204956, Uncertainty: 1.9485759735107422
Epoch 101, Batch 2600/3125, Loss: 1.446846604347229, Uncertainty: 1.9822168350219727
Epoch 101, Batch 2700/3125, Loss: 1.6967480182647705, Uncertainty: 2.2279138565063477
Epoch 101, Batch 2800/3125, Loss: 1.5777876377105713, Uncertainty: 2.328125476837158
Epoch 101, Batch 2900/3125, Loss: 2.4095077514648438, Uncertainty: 1.8438113927841187
Epoch 101, Batch 3000/3125, Loss: 1.8567495346069336, Uncertainty: 2.96090030670166
Epoch 101, Batch 3100/3125, Loss: 1.6553034782409668, Uncertainty: 1.9161362648010254

Training and Validation Results of Epoch 101:
================================
Training Loss: 1.2329492905044557, Training Uncertainty: 2.1096300399780272, time: 199.3841278553009
Validation Loss: 0.9202943753708354, Validation Uncertainty: 3.1357906806804334, time: 45.81264638900757
Number of predictions within uncertainty interval: 150791/200000 (75.40%)

Epoch 102, Batch 100/3125, Loss: 1.297156572341919, Uncertainty: 1.7721483707427979
Epoch 102, Batch 200/3125, Loss: 1.4284517765045166, Uncertainty: 1.8466094732284546
Epoch 102, Batch 300/3125, Loss: 1.6394222974777222, Uncertainty: 1.8232486248016357
Epoch 102, Batch 400/3125, Loss: 1.6568856239318848, Uncertainty: 2.1567773818969727
Epoch 102, Batch 500/3125, Loss: 1.5530716180801392, Uncertainty: 1.7182902097702026
Epoch 102, Batch 600/3125, Loss: 1.6901659965515137, Uncertainty: 2.0351033210754395
Epoch 102, Batch 700/3125, Loss: 1.6345305442810059, Uncertainty: 2.2860445976257324
Epoch 102, Batch 800/3125, Loss: 2.027419090270996, Uncertainty: 3.4032769203186035
Epoch 102, Batch 900/3125, Loss: 1.5901737213134766, Uncertainty: 1.9969487190246582
Epoch 102, Batch 1000/3125, Loss: 1.5674400329589844, Uncertainty: 1.9188085794448853
Epoch 102, Batch 1100/3125, Loss: 1.5758095979690552, Uncertainty: 1.8947035074234009
Epoch 102, Batch 1200/3125, Loss: 1.5692498683929443, Uncertainty: 2.0529861450195312
Epoch 102, Batch 1300/3125, Loss: 1.605975866317749, Uncertainty: 2.419523000717163
Epoch 102, Batch 1400/3125, Loss: 1.547497034072876, Uncertainty: 2.247347354888916
Epoch 102, Batch 1500/3125, Loss: 1.3345510959625244, Uncertainty: 1.6051886081695557
Epoch 102, Batch 1600/3125, Loss: 1.3072012662887573, Uncertainty: 1.4851033687591553
Epoch 102, Batch 1700/3125, Loss: 1.339111089706421, Uncertainty: 1.8534197807312012
Epoch 102, Batch 1800/3125, Loss: 1.7657885551452637, Uncertainty: 1.8905274868011475
Epoch 102, Batch 1900/3125, Loss: 1.7894221544265747, Uncertainty: 2.3767991065979004
Epoch 102, Batch 2000/3125, Loss: 1.5463359355926514, Uncertainty: 2.265504837036133
Epoch 102, Batch 2100/3125, Loss: 1.539311408996582, Uncertainty: 1.8233245611190796
Epoch 102, Batch 2200/3125, Loss: 1.7090274095535278, Uncertainty: 1.7221393585205078
Epoch 102, Batch 2300/3125, Loss: 1.6006758213043213, Uncertainty: 2.352933406829834
Epoch 102, Batch 2400/3125, Loss: 1.8911381959915161, Uncertainty: 1.6473171710968018
Epoch 102, Batch 2500/3125, Loss: 1.298316240310669, Uncertainty: 1.739423394203186
Epoch 102, Batch 2600/3125, Loss: 1.9735223054885864, Uncertainty: 2.107936382293701
Epoch 102, Batch 2700/3125, Loss: 1.4598138332366943, Uncertainty: 1.741387128829956
Epoch 102, Batch 2800/3125, Loss: 1.5079456567764282, Uncertainty: 2.055743455886841
Epoch 102, Batch 2900/3125, Loss: 1.750411033630371, Uncertainty: 2.3892250061035156
Epoch 102, Batch 3000/3125, Loss: 1.5509707927703857, Uncertainty: 1.711937665939331
Epoch 102, Batch 3100/3125, Loss: 1.566199779510498, Uncertainty: 1.755489706993103

Training and Validation Results of Epoch 102:
================================
Training Loss: 1.231665306148529, Training Uncertainty: 2.0891360161590575, time: 204.20573925971985
Validation Loss: 1.3419592061920849, Validation Uncertainty: 2.477146375209779, time: 46.16949510574341
Number of predictions within uncertainty interval: 98743/200000 (49.37%)

Epoch 103, Batch 100/3125, Loss: 1.2393665313720703, Uncertainty: 1.6743686199188232
Epoch 103, Batch 200/3125, Loss: 1.7473130226135254, Uncertainty: 2.816922187805176
Epoch 103, Batch 300/3125, Loss: 1.592919945716858, Uncertainty: 2.234172821044922
Epoch 103, Batch 400/3125, Loss: 2.0755982398986816, Uncertainty: 3.6584630012512207
Epoch 103, Batch 500/3125, Loss: 1.538880705833435, Uncertainty: 2.1834635734558105
Epoch 103, Batch 600/3125, Loss: 2.0686168670654297, Uncertainty: 3.0440797805786133
Epoch 103, Batch 700/3125, Loss: 1.6925020217895508, Uncertainty: 2.196479320526123
Epoch 103, Batch 800/3125, Loss: 1.591653823852539, Uncertainty: 1.8136358261108398
Epoch 103, Batch 900/3125, Loss: 1.6524133682250977, Uncertainty: 2.2420294284820557
Epoch 103, Batch 1000/3125, Loss: 1.5391466617584229, Uncertainty: 1.7116326093673706
Epoch 103, Batch 1100/3125, Loss: 1.6787906885147095, Uncertainty: 2.3886096477508545
Epoch 103, Batch 1200/3125, Loss: 2.074199676513672, Uncertainty: 3.493129014968872
Epoch 103, Batch 1300/3125, Loss: 1.4942903518676758, Uncertainty: 1.896277904510498
Epoch 103, Batch 1400/3125, Loss: 1.8114447593688965, Uncertainty: 2.893907308578491
Epoch 103, Batch 1500/3125, Loss: 1.6586828231811523, Uncertainty: 2.0967326164245605
Epoch 103, Batch 1600/3125, Loss: 1.695356011390686, Uncertainty: 1.8621165752410889
Epoch 103, Batch 1700/3125, Loss: 1.59882652759552, Uncertainty: 2.186095714569092
Epoch 103, Batch 1800/3125, Loss: 1.345082402229309, Uncertainty: 1.7568637132644653
Epoch 103, Batch 1900/3125, Loss: 1.4458516836166382, Uncertainty: 1.836233377456665
Epoch 103, Batch 2000/3125, Loss: 1.5244826078414917, Uncertainty: 2.0653762817382812
Epoch 103, Batch 2100/3125, Loss: 1.614889144897461, Uncertainty: 1.9233336448669434
Epoch 103, Batch 2200/3125, Loss: 1.5102616548538208, Uncertainty: 2.107607841491699
Epoch 103, Batch 2300/3125, Loss: 1.8260209560394287, Uncertainty: 3.11386775970459
Epoch 103, Batch 2400/3125, Loss: 1.7480061054229736, Uncertainty: 2.52510929107666
Epoch 103, Batch 2500/3125, Loss: 1.3344907760620117, Uncertainty: 1.633130669593811
Epoch 103, Batch 2600/3125, Loss: 1.4774620532989502, Uncertainty: 1.8424403667449951
Epoch 103, Batch 2700/3125, Loss: 1.3496387004852295, Uncertainty: 1.6215133666992188
Epoch 103, Batch 2800/3125, Loss: 1.7096632719039917, Uncertainty: 1.909263014793396
Epoch 103, Batch 2900/3125, Loss: 1.5013395547866821, Uncertainty: 1.7544561624526978
Epoch 103, Batch 3000/3125, Loss: 1.6740344762802124, Uncertainty: 2.4212992191314697
Epoch 103, Batch 3100/3125, Loss: 1.5349757671356201, Uncertainty: 2.2687227725982666

Training and Validation Results of Epoch 103:
================================
Training Loss: 1.2115704956245423, Training Uncertainty: 2.0827619482421875, time: 198.77154350280762
Validation Loss: 0.9868873529269567, Validation Uncertainty: 2.655194999616774, time: 46.51607584953308
Number of predictions within uncertainty interval: 132595/200000 (66.30%)

Epoch 104, Batch 100/3125, Loss: 1.275071620941162, Uncertainty: 1.8224515914916992
Epoch 104, Batch 200/3125, Loss: 1.3477106094360352, Uncertainty: 1.8374450206756592
Epoch 104, Batch 300/3125, Loss: 1.591974139213562, Uncertainty: 1.8857555389404297
Epoch 104, Batch 400/3125, Loss: 1.3496105670928955, Uncertainty: 1.7651653289794922
Epoch 104, Batch 500/3125, Loss: 1.457460641860962, Uncertainty: 1.9262099266052246
Epoch 104, Batch 600/3125, Loss: 1.3892648220062256, Uncertainty: 1.7210631370544434
Epoch 104, Batch 700/3125, Loss: 1.3803012371063232, Uncertainty: 1.7267627716064453
Epoch 104, Batch 800/3125, Loss: 1.615062952041626, Uncertainty: 1.881601095199585
Epoch 104, Batch 900/3125, Loss: 1.7912182807922363, Uncertainty: 2.789569854736328
Epoch 104, Batch 1000/3125, Loss: 1.7622578144073486, Uncertainty: 2.6777257919311523
Epoch 104, Batch 1100/3125, Loss: 1.8736200332641602, Uncertainty: 2.3514389991760254
Epoch 104, Batch 1200/3125, Loss: 1.895920991897583, Uncertainty: 2.662238836288452
Epoch 104, Batch 1300/3125, Loss: 1.6485177278518677, Uncertainty: 1.8250632286071777
Epoch 104, Batch 1400/3125, Loss: 1.672440767288208, Uncertainty: 2.0967960357666016
Epoch 104, Batch 1500/3125, Loss: 1.7620892524719238, Uncertainty: 1.5941081047058105
Epoch 104, Batch 1600/3125, Loss: 1.308632731437683, Uncertainty: 1.5977983474731445
Epoch 104, Batch 1700/3125, Loss: 1.4651575088500977, Uncertainty: 1.9460525512695312
Epoch 104, Batch 1800/3125, Loss: 1.6416523456573486, Uncertainty: 1.6866146326065063
Epoch 104, Batch 1900/3125, Loss: 1.58345365524292, Uncertainty: 2.2565653324127197
Epoch 104, Batch 2000/3125, Loss: 1.4713170528411865, Uncertainty: 1.7832151651382446
Epoch 104, Batch 2100/3125, Loss: 1.616783618927002, Uncertainty: 1.809666395187378
Epoch 104, Batch 2200/3125, Loss: 1.5787253379821777, Uncertainty: 1.883772850036621
Epoch 104, Batch 2300/3125, Loss: 1.4338014125823975, Uncertainty: 1.862161636352539
Epoch 104, Batch 2400/3125, Loss: 1.3883423805236816, Uncertainty: 1.4912831783294678
Epoch 104, Batch 2500/3125, Loss: 1.42502760887146, Uncertainty: 1.6797808408737183
Epoch 104, Batch 2600/3125, Loss: 1.5777814388275146, Uncertainty: 2.1136927604675293
Epoch 104, Batch 2700/3125, Loss: 1.5304443836212158, Uncertainty: 1.9118430614471436
Epoch 104, Batch 2800/3125, Loss: 1.6674103736877441, Uncertainty: 2.031212091445923
Epoch 104, Batch 2900/3125, Loss: 1.5081982612609863, Uncertainty: 2.195115566253662
Epoch 104, Batch 3000/3125, Loss: 1.552647590637207, Uncertainty: 1.822507381439209
Epoch 104, Batch 3100/3125, Loss: 1.5228943824768066, Uncertainty: 1.9549660682678223

Training and Validation Results of Epoch 104:
================================
Training Loss: 1.2136030369377135, Training Uncertainty: 2.067153176307678, time: 196.59138679504395
Validation Loss: 0.9334045607415612, Validation Uncertainty: 3.899244263958748, time: 43.945659160614014
Number of predictions within uncertainty interval: 166196/200000 (83.10%)

Epoch 105, Batch 100/3125, Loss: 1.5122690200805664, Uncertainty: 1.5194967985153198
Epoch 105, Batch 200/3125, Loss: 1.981720209121704, Uncertainty: 3.0179078578948975
Epoch 105, Batch 300/3125, Loss: 1.4000519514083862, Uncertainty: 1.7802457809448242
Epoch 105, Batch 400/3125, Loss: 1.6158056259155273, Uncertainty: 2.3775839805603027
Epoch 105, Batch 500/3125, Loss: 1.4357025623321533, Uncertainty: 1.6518970727920532
Epoch 105, Batch 600/3125, Loss: 1.4102404117584229, Uncertainty: 1.869940161705017
Epoch 105, Batch 700/3125, Loss: 1.348531723022461, Uncertainty: 1.7414681911468506
Epoch 105, Batch 800/3125, Loss: 1.4475741386413574, Uncertainty: 1.904100775718689
Epoch 105, Batch 900/3125, Loss: 1.6483159065246582, Uncertainty: 2.3685154914855957
Epoch 105, Batch 1000/3125, Loss: 1.8462517261505127, Uncertainty: 2.883676528930664
Epoch 105, Batch 1100/3125, Loss: 1.8919624090194702, Uncertainty: 2.4882736206054688
Epoch 105, Batch 1200/3125, Loss: 1.6891828775405884, Uncertainty: 2.5750584602355957
Epoch 105, Batch 1300/3125, Loss: 1.4603538513183594, Uncertainty: 1.994896411895752
Epoch 105, Batch 1400/3125, Loss: 1.7651805877685547, Uncertainty: 1.9769315719604492
Epoch 105, Batch 1500/3125, Loss: 1.6912994384765625, Uncertainty: 2.552921772003174
Epoch 105, Batch 1600/3125, Loss: 1.3476650714874268, Uncertainty: 1.5296231508255005
Epoch 105, Batch 1700/3125, Loss: 1.4231125116348267, Uncertainty: 1.7908382415771484
Epoch 105, Batch 1800/3125, Loss: 1.3449974060058594, Uncertainty: 1.6032962799072266
Epoch 105, Batch 1900/3125, Loss: 1.5745238065719604, Uncertainty: 2.4819350242614746
Epoch 105, Batch 2000/3125, Loss: 1.428842544555664, Uncertainty: 2.1781060695648193
Epoch 105, Batch 2100/3125, Loss: 1.8747673034667969, Uncertainty: 1.7650033235549927
Epoch 105, Batch 2200/3125, Loss: 1.3982045650482178, Uncertainty: 1.7655223608016968
Epoch 105, Batch 2300/3125, Loss: 1.4476957321166992, Uncertainty: 1.783064365386963
Epoch 105, Batch 2400/3125, Loss: 1.414457082748413, Uncertainty: 1.638676404953003
Epoch 105, Batch 2500/3125, Loss: 1.5108901262283325, Uncertainty: 2.2920641899108887
Epoch 105, Batch 2600/3125, Loss: 1.3746893405914307, Uncertainty: 1.8005328178405762
Epoch 105, Batch 2700/3125, Loss: 1.5457477569580078, Uncertainty: 2.172727108001709
Epoch 105, Batch 2800/3125, Loss: 1.6806012392044067, Uncertainty: 2.4960036277770996
Epoch 105, Batch 2900/3125, Loss: 1.5680437088012695, Uncertainty: 2.0522656440734863
Epoch 105, Batch 3000/3125, Loss: 1.935224175453186, Uncertainty: 3.166168689727783
Epoch 105, Batch 3100/3125, Loss: 1.3866361379623413, Uncertainty: 1.9475947618484497

Training and Validation Results of Epoch 105:
================================
Training Loss: 1.2105758280563355, Training Uncertainty: 2.0689739222335817, time: 194.67285799980164
Validation Loss: 1.1845309452327621, Validation Uncertainty: 3.202031987097562, time: 45.910945892333984
Number of predictions within uncertainty interval: 134256/200000 (67.13%)

Epoch 106, Batch 100/3125, Loss: 1.7378957271575928, Uncertainty: 2.2105040550231934
Epoch 106, Batch 200/3125, Loss: 1.394605278968811, Uncertainty: 1.7710850238800049
Epoch 106, Batch 300/3125, Loss: 1.6718589067459106, Uncertainty: 2.4563827514648438
Epoch 106, Batch 400/3125, Loss: 1.46954345703125, Uncertainty: 2.038054943084717
Epoch 106, Batch 500/3125, Loss: 1.8749465942382812, Uncertainty: 2.683236598968506
Epoch 106, Batch 600/3125, Loss: 1.306686520576477, Uncertainty: 1.7915157079696655
Epoch 106, Batch 700/3125, Loss: 1.4155887365341187, Uncertainty: 1.67281174659729
Epoch 106, Batch 800/3125, Loss: 1.6481362581253052, Uncertainty: 1.7883262634277344
Epoch 106, Batch 900/3125, Loss: 1.8426361083984375, Uncertainty: 2.7336244583129883
Epoch 106, Batch 1000/3125, Loss: 1.7873506546020508, Uncertainty: 2.652331829071045
Epoch 106, Batch 1100/3125, Loss: 1.4861230850219727, Uncertainty: 1.8111395835876465
Epoch 106, Batch 1200/3125, Loss: 1.6684935092926025, Uncertainty: 2.080660104751587
Epoch 106, Batch 1300/3125, Loss: 1.6073939800262451, Uncertainty: 2.396531820297241
Epoch 106, Batch 1400/3125, Loss: 1.466767430305481, Uncertainty: 2.0891566276550293
Epoch 106, Batch 1500/3125, Loss: 1.7494957447052002, Uncertainty: 2.257483720779419
Epoch 106, Batch 1600/3125, Loss: 1.663364052772522, Uncertainty: 2.367175817489624
Epoch 106, Batch 1700/3125, Loss: 1.6064053773880005, Uncertainty: 2.2543649673461914
Epoch 106, Batch 1800/3125, Loss: 1.6948274374008179, Uncertainty: 1.79325270652771
Epoch 106, Batch 1900/3125, Loss: 1.6129817962646484, Uncertainty: 2.2177929878234863
Epoch 106, Batch 2000/3125, Loss: 1.4198777675628662, Uncertainty: 1.977647066116333
Epoch 106, Batch 2100/3125, Loss: 1.5446091890335083, Uncertainty: 1.800539493560791
Epoch 106, Batch 2200/3125, Loss: 1.7968695163726807, Uncertainty: 2.898705005645752
Epoch 106, Batch 2300/3125, Loss: 1.7092657089233398, Uncertainty: 2.512901782989502
Epoch 106, Batch 2400/3125, Loss: 1.3514376878738403, Uncertainty: 1.8542563915252686
Epoch 106, Batch 2500/3125, Loss: 1.535046100616455, Uncertainty: 1.9891211986541748
Epoch 106, Batch 2600/3125, Loss: 1.4333487749099731, Uncertainty: 1.6794060468673706
Epoch 106, Batch 2700/3125, Loss: 1.639963150024414, Uncertainty: 2.629615306854248
Epoch 106, Batch 2800/3125, Loss: 1.4995702505111694, Uncertainty: 1.9858194589614868
Epoch 106, Batch 2900/3125, Loss: 1.6680665016174316, Uncertainty: 2.520599842071533
Epoch 106, Batch 3000/3125, Loss: 2.096571445465088, Uncertainty: 1.6763017177581787
Epoch 106, Batch 3100/3125, Loss: 1.8690907955169678, Uncertainty: 2.2820563316345215

Training and Validation Results of Epoch 106:
================================
Training Loss: 1.201923091621399, Training Uncertainty: 2.0609781925201416, time: 193.970938205719
Validation Loss: 1.2429449951557248, Validation Uncertainty: 2.700348699794096, time: 44.92601227760315
Number of predictions within uncertainty interval: 115963/200000 (57.98%)

Epoch 107, Batch 100/3125, Loss: 1.5042295455932617, Uncertainty: 2.1257290840148926
Epoch 107, Batch 200/3125, Loss: 1.4033071994781494, Uncertainty: 1.7322919368743896
Epoch 107, Batch 300/3125, Loss: 1.8124750852584839, Uncertainty: 2.0861330032348633
Epoch 107, Batch 400/3125, Loss: 1.362518072128296, Uncertainty: 1.7405028343200684
Epoch 107, Batch 500/3125, Loss: 1.484081506729126, Uncertainty: 1.8628532886505127
Epoch 107, Batch 600/3125, Loss: 1.805732011795044, Uncertainty: 1.6895456314086914
Epoch 107, Batch 700/3125, Loss: 1.3509471416473389, Uncertainty: 1.8893753290176392
Epoch 107, Batch 800/3125, Loss: 1.4001250267028809, Uncertainty: 1.697230577468872
Epoch 107, Batch 900/3125, Loss: 1.4902904033660889, Uncertainty: 1.8011507987976074
Epoch 107, Batch 1000/3125, Loss: 2.238738536834717, Uncertainty: 2.3953094482421875
Epoch 107, Batch 1100/3125, Loss: 1.5134475231170654, Uncertainty: 1.6604434251785278
Epoch 107, Batch 1200/3125, Loss: 1.407975196838379, Uncertainty: 1.6520850658416748
Epoch 107, Batch 1300/3125, Loss: 1.2925455570220947, Uncertainty: 1.7799363136291504
Epoch 107, Batch 1400/3125, Loss: 2.010523796081543, Uncertainty: 3.4724082946777344
Epoch 107, Batch 1500/3125, Loss: 1.386439561843872, Uncertainty: 1.62571382522583
Epoch 107, Batch 1600/3125, Loss: 1.474334955215454, Uncertainty: 2.0128867626190186
Epoch 107, Batch 1700/3125, Loss: 1.4844729900360107, Uncertainty: 1.8467650413513184
Epoch 107, Batch 1800/3125, Loss: 1.4204715490341187, Uncertainty: 1.6941584348678589
Epoch 107, Batch 1900/3125, Loss: 1.9173436164855957, Uncertainty: 2.3404977321624756
Epoch 107, Batch 2000/3125, Loss: 1.4395002126693726, Uncertainty: 2.145909309387207
Epoch 107, Batch 2100/3125, Loss: 1.5609090328216553, Uncertainty: 2.067627191543579
Epoch 107, Batch 2200/3125, Loss: 1.7076923847198486, Uncertainty: 1.9980332851409912
Epoch 107, Batch 2300/3125, Loss: 1.627684473991394, Uncertainty: 1.9236092567443848
Epoch 107, Batch 2400/3125, Loss: 1.5741515159606934, Uncertainty: 2.0807077884674072
Epoch 107, Batch 2500/3125, Loss: 1.8969106674194336, Uncertainty: 1.9212743043899536
Epoch 107, Batch 2600/3125, Loss: 1.7394731044769287, Uncertainty: 2.121209144592285
Epoch 107, Batch 2700/3125, Loss: 1.5726358890533447, Uncertainty: 2.274099826812744
Epoch 107, Batch 2800/3125, Loss: 1.4741219282150269, Uncertainty: 1.7973655462265015
Epoch 107, Batch 2900/3125, Loss: 1.5161432027816772, Uncertainty: 1.7936373949050903
Epoch 107, Batch 3000/3125, Loss: 1.7367489337921143, Uncertainty: 2.096228837966919
Epoch 107, Batch 3100/3125, Loss: 1.2936620712280273, Uncertainty: 1.5811049938201904

Training and Validation Results of Epoch 107:
================================
Training Loss: 1.2042210540771485, Training Uncertainty: 2.058276270751953, time: 193.0353066921234
Validation Loss: 0.9501759740702637, Validation Uncertainty: 2.946704612668518, time: 44.75210952758789
Number of predictions within uncertainty interval: 143736/200000 (71.87%)

Epoch 108, Batch 100/3125, Loss: 1.2940469980239868, Uncertainty: 1.527029275894165
Epoch 108, Batch 200/3125, Loss: 1.4191601276397705, Uncertainty: 1.9428415298461914
Epoch 108, Batch 300/3125, Loss: 1.747010588645935, Uncertainty: 2.318305492401123
Epoch 108, Batch 400/3125, Loss: 1.4129292964935303, Uncertainty: 1.7322380542755127
Epoch 108, Batch 500/3125, Loss: 1.4657843112945557, Uncertainty: 1.945097804069519
Epoch 108, Batch 600/3125, Loss: 1.7994781732559204, Uncertainty: 1.8907047510147095
Epoch 108, Batch 700/3125, Loss: 1.483699083328247, Uncertainty: 1.761987328529358
Epoch 108, Batch 800/3125, Loss: 1.5114126205444336, Uncertainty: 1.7434650659561157
Epoch 108, Batch 900/3125, Loss: 1.772062063217163, Uncertainty: 2.360164165496826
Epoch 108, Batch 1000/3125, Loss: 1.6685407161712646, Uncertainty: 2.5298550128936768
Epoch 108, Batch 1100/3125, Loss: 1.4620211124420166, Uncertainty: 1.784528374671936
Epoch 108, Batch 1200/3125, Loss: 1.624769687652588, Uncertainty: 2.0393569469451904
Epoch 108, Batch 1300/3125, Loss: 1.6004011631011963, Uncertainty: 1.8707811832427979
Epoch 108, Batch 1400/3125, Loss: 1.6951007843017578, Uncertainty: 2.306077003479004
Epoch 108, Batch 1500/3125, Loss: 1.5172836780548096, Uncertainty: 2.0273518562316895
Epoch 108, Batch 1600/3125, Loss: 1.6712713241577148, Uncertainty: 2.3134899139404297
Epoch 108, Batch 1700/3125, Loss: 1.3473488092422485, Uncertainty: 1.837624430656433
Epoch 108, Batch 1800/3125, Loss: 1.4121054410934448, Uncertainty: 1.804142713546753
Epoch 108, Batch 1900/3125, Loss: 1.519012451171875, Uncertainty: 1.9243218898773193
Epoch 108, Batch 2000/3125, Loss: 1.2586251497268677, Uncertainty: 1.7676472663879395
Epoch 108, Batch 2100/3125, Loss: 1.9088093042373657, Uncertainty: 2.2216033935546875
Epoch 108, Batch 2200/3125, Loss: 1.553371787071228, Uncertainty: 2.2329139709472656
Epoch 108, Batch 2300/3125, Loss: 1.716010332107544, Uncertainty: 2.0317904949188232
Epoch 108, Batch 2400/3125, Loss: 1.812791347503662, Uncertainty: 1.614071249961853
Epoch 108, Batch 2500/3125, Loss: 1.383467435836792, Uncertainty: 1.9418658018112183
Epoch 108, Batch 2600/3125, Loss: 1.4248547554016113, Uncertainty: 1.9893897771835327
Epoch 108, Batch 2700/3125, Loss: 2.0104713439941406, Uncertainty: 3.2268693447113037
Epoch 108, Batch 2800/3125, Loss: 1.5158264636993408, Uncertainty: 1.7333168983459473
Epoch 108, Batch 2900/3125, Loss: 1.5504578351974487, Uncertainty: 1.970078468322754
Epoch 108, Batch 3000/3125, Loss: 1.532787799835205, Uncertainty: 1.7263996601104736
Epoch 108, Batch 3100/3125, Loss: 1.4051940441131592, Uncertainty: 1.8507486581802368

Training and Validation Results of Epoch 108:
================================
Training Loss: 1.1834225449562072, Training Uncertainty: 2.021584754524231, time: 193.81445932388306
Validation Loss: 0.9581052828627779, Validation Uncertainty: 3.924643091228612, time: 45.461403131484985
Number of predictions within uncertainty interval: 166948/200000 (83.47%)

Epoch 109, Batch 100/3125, Loss: 1.4624810218811035, Uncertainty: 1.891817331314087
Epoch 109, Batch 200/3125, Loss: 1.5691590309143066, Uncertainty: 2.365260601043701
Epoch 109, Batch 300/3125, Loss: 1.7037640810012817, Uncertainty: 2.3241591453552246
Epoch 109, Batch 400/3125, Loss: 1.5884877443313599, Uncertainty: 2.457679271697998
Epoch 109, Batch 500/3125, Loss: 1.5017377138137817, Uncertainty: 1.632223129272461
Epoch 109, Batch 600/3125, Loss: 1.7786712646484375, Uncertainty: 1.645837664604187
Epoch 109, Batch 700/3125, Loss: 1.661211609840393, Uncertainty: 2.584197759628296
Epoch 109, Batch 800/3125, Loss: 1.8803833723068237, Uncertainty: 3.120448112487793
Epoch 109, Batch 900/3125, Loss: 1.2961015701293945, Uncertainty: 1.774678349494934
Epoch 109, Batch 1000/3125, Loss: 1.7745927572250366, Uncertainty: 2.427844524383545
Epoch 109, Batch 1100/3125, Loss: 1.6701369285583496, Uncertainty: 2.4154562950134277
Epoch 109, Batch 1200/3125, Loss: 1.6260688304901123, Uncertainty: 2.161681652069092
Epoch 109, Batch 1300/3125, Loss: 1.3973448276519775, Uncertainty: 1.9899957180023193
Epoch 109, Batch 1400/3125, Loss: 1.6500170230865479, Uncertainty: 2.0973286628723145
Epoch 109, Batch 1500/3125, Loss: 1.6783344745635986, Uncertainty: 1.454345464706421
Epoch 109, Batch 1600/3125, Loss: 1.4783146381378174, Uncertainty: 2.0239155292510986
Epoch 109, Batch 1700/3125, Loss: 1.4792659282684326, Uncertainty: 1.9822325706481934
Epoch 109, Batch 1800/3125, Loss: 1.5018987655639648, Uncertainty: 1.8351539373397827
Epoch 109, Batch 1900/3125, Loss: 1.6655566692352295, Uncertainty: 2.4612889289855957
Epoch 109, Batch 2000/3125, Loss: 1.358180046081543, Uncertainty: 1.849992275238037
Epoch 109, Batch 2100/3125, Loss: 1.5756418704986572, Uncertainty: 2.315434694290161
Epoch 109, Batch 2200/3125, Loss: 1.404146432876587, Uncertainty: 1.6426780223846436
Epoch 109, Batch 2300/3125, Loss: 1.6068449020385742, Uncertainty: 2.423146963119507
Epoch 109, Batch 2400/3125, Loss: 1.739386796951294, Uncertainty: 2.201282501220703
Epoch 109, Batch 2500/3125, Loss: 1.7611851692199707, Uncertainty: 2.285655975341797
Epoch 109, Batch 2600/3125, Loss: 1.4212874174118042, Uncertainty: 1.838949203491211
Epoch 109, Batch 2700/3125, Loss: 1.5223109722137451, Uncertainty: 1.8594541549682617
Epoch 109, Batch 2800/3125, Loss: 1.512640357017517, Uncertainty: 1.493621587753296
Epoch 109, Batch 2900/3125, Loss: 1.6148203611373901, Uncertainty: 1.838942289352417
Epoch 109, Batch 3000/3125, Loss: 1.3839316368103027, Uncertainty: 1.948288917541504
Epoch 109, Batch 3100/3125, Loss: 1.5735719203948975, Uncertainty: 2.146287441253662

Training and Validation Results of Epoch 109:
================================
Training Loss: 1.1863254182434082, Training Uncertainty: 2.0206678242874148, time: 195.61742091178894
Validation Loss: 0.9102749998307289, Validation Uncertainty: 2.8024195039363775, time: 45.91722393035889
Number of predictions within uncertainty interval: 143015/200000 (71.51%)

Epoch 110, Batch 100/3125, Loss: 1.5840742588043213, Uncertainty: 1.6190744638442993
Epoch 110, Batch 200/3125, Loss: 1.4407355785369873, Uncertainty: 2.0128018856048584
Epoch 110, Batch 300/3125, Loss: 1.612096905708313, Uncertainty: 2.0665740966796875
Epoch 110, Batch 400/3125, Loss: 1.641383409500122, Uncertainty: 2.2100448608398438
Epoch 110, Batch 500/3125, Loss: 1.5577447414398193, Uncertainty: 2.2287960052490234
Epoch 110, Batch 600/3125, Loss: 1.6568727493286133, Uncertainty: 1.9056881666183472
Epoch 110, Batch 700/3125, Loss: 1.6862716674804688, Uncertainty: 2.790083885192871
Epoch 110, Batch 800/3125, Loss: 1.8983938694000244, Uncertainty: 2.2259738445281982
Epoch 110, Batch 900/3125, Loss: 1.7179911136627197, Uncertainty: 1.6589809656143188
Epoch 110, Batch 1000/3125, Loss: 1.9355762004852295, Uncertainty: 3.122438430786133
Epoch 110, Batch 1100/3125, Loss: 1.487375020980835, Uncertainty: 1.9097241163253784
Epoch 110, Batch 1200/3125, Loss: 1.6643733978271484, Uncertainty: 1.5260449647903442
Epoch 110, Batch 1300/3125, Loss: 1.33583402633667, Uncertainty: 1.7360475063323975
Epoch 110, Batch 1400/3125, Loss: 1.3614773750305176, Uncertainty: 1.740285873413086
Epoch 110, Batch 1500/3125, Loss: 1.9076439142227173, Uncertainty: 1.5994493961334229
Epoch 110, Batch 1600/3125, Loss: 1.4312233924865723, Uncertainty: 1.841127872467041
Epoch 110, Batch 1700/3125, Loss: 1.590059518814087, Uncertainty: 2.230961799621582
Epoch 110, Batch 1800/3125, Loss: 1.433567762374878, Uncertainty: 1.7931177616119385
Epoch 110, Batch 1900/3125, Loss: 1.3423287868499756, Uncertainty: 1.7216155529022217
Epoch 110, Batch 2000/3125, Loss: 1.51172935962677, Uncertainty: 2.033353805541992
Epoch 110, Batch 2100/3125, Loss: 1.5414212942123413, Uncertainty: 2.1341614723205566
Epoch 110, Batch 2200/3125, Loss: 1.3092619180679321, Uncertainty: 1.4861652851104736
Epoch 110, Batch 2300/3125, Loss: 1.5190017223358154, Uncertainty: 1.99458646774292
Epoch 110, Batch 2400/3125, Loss: 1.499739408493042, Uncertainty: 2.2232825756073
Epoch 110, Batch 2500/3125, Loss: 1.503212332725525, Uncertainty: 1.9737653732299805
Epoch 110, Batch 2600/3125, Loss: 1.5248620510101318, Uncertainty: 1.581055998802185
Epoch 110, Batch 2700/3125, Loss: 1.7177135944366455, Uncertainty: 2.7240591049194336
Epoch 110, Batch 2800/3125, Loss: 1.6479263305664062, Uncertainty: 2.2693071365356445
Epoch 110, Batch 2900/3125, Loss: 2.2035398483276367, Uncertainty: 1.968654751777649
Epoch 110, Batch 3000/3125, Loss: 1.511307716369629, Uncertainty: 1.7996549606323242
Epoch 110, Batch 3100/3125, Loss: 1.6767618656158447, Uncertainty: 1.9566470384597778

Training and Validation Results of Epoch 110:
================================
Training Loss: 1.1912601155471803, Training Uncertainty: 2.022756192855835, time: 197.44583249092102
Validation Loss: 0.9981656428188315, Validation Uncertainty: 2.804562165913984, time: 45.79344916343689
Number of predictions within uncertainty interval: 135662/200000 (67.83%)

Epoch 111, Batch 100/3125, Loss: 1.341890573501587, Uncertainty: 1.6413469314575195
Epoch 111, Batch 200/3125, Loss: 1.7484959363937378, Uncertainty: 2.0307016372680664
Epoch 111, Batch 300/3125, Loss: 1.756596326828003, Uncertainty: 2.4221882820129395
Epoch 111, Batch 400/3125, Loss: 1.2514245510101318, Uncertainty: 1.622072458267212
Epoch 111, Batch 500/3125, Loss: 1.5942332744598389, Uncertainty: 1.6556262969970703
Epoch 111, Batch 600/3125, Loss: 1.7493603229522705, Uncertainty: 2.3561244010925293
Epoch 111, Batch 700/3125, Loss: 1.6150085926055908, Uncertainty: 1.7291061878204346
Epoch 111, Batch 800/3125, Loss: 1.4327456951141357, Uncertainty: 1.8231889009475708
Epoch 111, Batch 900/3125, Loss: 1.7964787483215332, Uncertainty: 2.5544021129608154
Epoch 111, Batch 1000/3125, Loss: 1.7591865062713623, Uncertainty: 1.811828851699829
Epoch 111, Batch 1100/3125, Loss: 1.4562294483184814, Uncertainty: 1.9703118801116943
Epoch 111, Batch 1200/3125, Loss: 1.4244813919067383, Uncertainty: 1.5217992067337036
Epoch 111, Batch 1300/3125, Loss: 1.2596648931503296, Uncertainty: 1.608596920967102
Epoch 111, Batch 1400/3125, Loss: 1.5512516498565674, Uncertainty: 1.9297858476638794
Epoch 111, Batch 1500/3125, Loss: 1.5433118343353271, Uncertainty: 1.9529690742492676
Epoch 111, Batch 1600/3125, Loss: 1.4842994213104248, Uncertainty: 1.9975461959838867
Epoch 111, Batch 1700/3125, Loss: 1.5310585498809814, Uncertainty: 2.0988802909851074
Epoch 111, Batch 1800/3125, Loss: 1.347456455230713, Uncertainty: 1.709341287612915
Epoch 111, Batch 1900/3125, Loss: 1.4303988218307495, Uncertainty: 2.0717198848724365
Epoch 111, Batch 2000/3125, Loss: 1.5854452848434448, Uncertainty: 2.40759015083313
Epoch 111, Batch 2100/3125, Loss: 1.5450025796890259, Uncertainty: 1.6877689361572266
Epoch 111, Batch 2200/3125, Loss: 1.7407313585281372, Uncertainty: 2.509341239929199
Epoch 111, Batch 2300/3125, Loss: 1.4849417209625244, Uncertainty: 1.9162038564682007
Epoch 111, Batch 2400/3125, Loss: 1.7611045837402344, Uncertainty: 2.6213417053222656
Epoch 111, Batch 2500/3125, Loss: 1.7675162553787231, Uncertainty: 2.811187744140625
Epoch 111, Batch 2600/3125, Loss: 1.5041921138763428, Uncertainty: 1.8691520690917969
Epoch 111, Batch 2700/3125, Loss: 1.51808762550354, Uncertainty: 2.1052169799804688
Epoch 111, Batch 2800/3125, Loss: 1.5169224739074707, Uncertainty: 1.785409688949585
Epoch 111, Batch 2900/3125, Loss: 1.4861799478530884, Uncertainty: 1.8203680515289307
Epoch 111, Batch 3000/3125, Loss: 1.4358705282211304, Uncertainty: 1.656977891921997
Epoch 111, Batch 3100/3125, Loss: 1.4115971326828003, Uncertainty: 1.7365479469299316

Training and Validation Results of Epoch 111:
================================
Training Loss: 1.1698208150672913, Training Uncertainty: 2.0221759448242187, time: 198.1542444229126
Validation Loss: 0.99100080582187, Validation Uncertainty: 2.535250633269015, time: 45.73327922821045
Number of predictions within uncertainty interval: 130764/200000 (65.38%)

Epoch 112, Batch 100/3125, Loss: 1.4841625690460205, Uncertainty: 2.216090679168701
Epoch 112, Batch 200/3125, Loss: 1.377575397491455, Uncertainty: 2.047445297241211
Epoch 112, Batch 300/3125, Loss: 1.3749046325683594, Uncertainty: 1.7198262214660645
Epoch 112, Batch 400/3125, Loss: 1.2369979619979858, Uncertainty: 1.7988700866699219
Epoch 112, Batch 500/3125, Loss: 1.524707555770874, Uncertainty: 1.8130908012390137
Epoch 112, Batch 600/3125, Loss: 1.4217132329940796, Uncertainty: 1.90802001953125
Epoch 112, Batch 700/3125, Loss: 1.2756338119506836, Uncertainty: 1.5535622835159302
Epoch 112, Batch 800/3125, Loss: 1.2527318000793457, Uncertainty: 1.6970270872116089
Epoch 112, Batch 900/3125, Loss: 1.7139930725097656, Uncertainty: 2.8171119689941406
Epoch 112, Batch 1000/3125, Loss: 1.5351104736328125, Uncertainty: 2.020935297012329
Epoch 112, Batch 1100/3125, Loss: 1.6325491666793823, Uncertainty: 2.2362594604492188
Epoch 112, Batch 1200/3125, Loss: 1.981001377105713, Uncertainty: 1.8503631353378296
Epoch 112, Batch 1300/3125, Loss: 1.5919990539550781, Uncertainty: 1.51620614528656
Epoch 112, Batch 1400/3125, Loss: 1.514162540435791, Uncertainty: 2.309699535369873
Epoch 112, Batch 1500/3125, Loss: 1.5477262735366821, Uncertainty: 1.9217829704284668
Epoch 112, Batch 1600/3125, Loss: 1.530482292175293, Uncertainty: 1.7130614519119263
Epoch 112, Batch 1700/3125, Loss: 1.4056906700134277, Uncertainty: 1.919142246246338
Epoch 112, Batch 1800/3125, Loss: 1.7305455207824707, Uncertainty: 2.6607301235198975
Epoch 112, Batch 1900/3125, Loss: 1.5216844081878662, Uncertainty: 2.074923276901245
Epoch 112, Batch 2000/3125, Loss: 1.398339033126831, Uncertainty: 1.7506849765777588
Epoch 112, Batch 2100/3125, Loss: 1.4031364917755127, Uncertainty: 1.9085655212402344
Epoch 112, Batch 2200/3125, Loss: 1.4215707778930664, Uncertainty: 1.925959825515747
Epoch 112, Batch 2300/3125, Loss: 1.5646675825119019, Uncertainty: 2.0726161003112793
Epoch 112, Batch 2400/3125, Loss: 1.604982614517212, Uncertainty: 1.7470500469207764
Epoch 112, Batch 2500/3125, Loss: 1.6378161907196045, Uncertainty: 2.6533279418945312
Epoch 112, Batch 2600/3125, Loss: 1.3535680770874023, Uncertainty: 1.6542062759399414
Epoch 112, Batch 2700/3125, Loss: 1.4052866697311401, Uncertainty: 1.8390365839004517
Epoch 112, Batch 2800/3125, Loss: 1.5879507064819336, Uncertainty: 2.2158682346343994
Epoch 112, Batch 2900/3125, Loss: 1.541688323020935, Uncertainty: 2.4242634773254395
Epoch 112, Batch 3000/3125, Loss: 1.8346819877624512, Uncertainty: 2.6399805545806885
Epoch 112, Batch 3100/3125, Loss: 1.5304627418518066, Uncertainty: 1.7297041416168213

Training and Validation Results of Epoch 112:
================================
Training Loss: 1.1675581928253174, Training Uncertainty: 2.0253746252441407, time: 203.89222645759583
Validation Loss: 0.960297961369195, Validation Uncertainty: 3.018990695019207, time: 47.50691080093384
Number of predictions within uncertainty interval: 141674/200000 (70.84%)

Epoch 113, Batch 100/3125, Loss: 1.7603321075439453, Uncertainty: 2.9456443786621094
Epoch 113, Batch 200/3125, Loss: 1.4290488958358765, Uncertainty: 2.1300036907196045
Epoch 113, Batch 300/3125, Loss: 1.4310094118118286, Uncertainty: 1.989749789237976
Epoch 113, Batch 400/3125, Loss: 1.2741971015930176, Uncertainty: 1.7324057817459106
Epoch 113, Batch 500/3125, Loss: 1.3971319198608398, Uncertainty: 1.8187509775161743
Epoch 113, Batch 600/3125, Loss: 1.4378108978271484, Uncertainty: 1.783551573753357
Epoch 113, Batch 700/3125, Loss: 1.1915383338928223, Uncertainty: 1.3906123638153076
Epoch 113, Batch 800/3125, Loss: 1.477376103401184, Uncertainty: 1.5585095882415771
Epoch 113, Batch 900/3125, Loss: 1.4431734085083008, Uncertainty: 2.125685691833496
Epoch 113, Batch 1000/3125, Loss: 1.5697941780090332, Uncertainty: 2.0888724327087402
Epoch 113, Batch 1100/3125, Loss: 1.4027135372161865, Uncertainty: 1.7693865299224854
Epoch 113, Batch 1200/3125, Loss: 1.5601447820663452, Uncertainty: 2.104748249053955
Epoch 113, Batch 1300/3125, Loss: 1.4679973125457764, Uncertainty: 2.291290760040283
Epoch 113, Batch 1400/3125, Loss: 1.6894696950912476, Uncertainty: 2.525615692138672
Epoch 113, Batch 1500/3125, Loss: 1.8579795360565186, Uncertainty: 1.562308430671692
Epoch 113, Batch 1600/3125, Loss: 1.5415050983428955, Uncertainty: 1.9627246856689453
Epoch 113, Batch 1700/3125, Loss: 1.728919506072998, Uncertainty: 2.3018734455108643
Epoch 113, Batch 1800/3125, Loss: 1.3916269540786743, Uncertainty: 1.8159761428833008
Epoch 113, Batch 1900/3125, Loss: 1.583159327507019, Uncertainty: 1.707698106765747
Epoch 113, Batch 2000/3125, Loss: 1.2033411264419556, Uncertainty: 1.5542231798171997
Epoch 113, Batch 2100/3125, Loss: 1.9237408638000488, Uncertainty: 1.8381626605987549
Epoch 113, Batch 2200/3125, Loss: 1.3546680212020874, Uncertainty: 1.496904969215393
Epoch 113, Batch 2300/3125, Loss: 1.5771431922912598, Uncertainty: 2.078205108642578
Epoch 113, Batch 2400/3125, Loss: 1.3370658159255981, Uncertainty: 1.6018702983856201
Epoch 113, Batch 2500/3125, Loss: 1.429897665977478, Uncertainty: 2.023106336593628
Epoch 113, Batch 2600/3125, Loss: 1.4811124801635742, Uncertainty: 1.857450008392334
Epoch 113, Batch 2700/3125, Loss: 2.015134572982788, Uncertainty: 3.420919895172119
Epoch 113, Batch 2800/3125, Loss: 1.8409979343414307, Uncertainty: 2.746096134185791
Epoch 113, Batch 2900/3125, Loss: 1.57625150680542, Uncertainty: 2.1852664947509766
Epoch 113, Batch 3000/3125, Loss: 1.468766450881958, Uncertainty: 1.8092584609985352
Epoch 113, Batch 3100/3125, Loss: 1.4465148448944092, Uncertainty: 1.7740281820297241

Training and Validation Results of Epoch 113:
================================
Training Loss: 1.164896321926117, Training Uncertainty: 2.01167621837616, time: 197.25741958618164
Validation Loss: 1.053968799388622, Validation Uncertainty: 2.950186559306386, time: 46.387197971343994
Number of predictions within uncertainty interval: 130826/200000 (65.41%)

Epoch 114, Batch 100/3125, Loss: 1.2086297273635864, Uncertainty: 1.540574550628662
Epoch 114, Batch 200/3125, Loss: 1.5953950881958008, Uncertainty: 1.9411895275115967
Epoch 114, Batch 300/3125, Loss: 1.608386516571045, Uncertainty: 2.2127139568328857
Epoch 114, Batch 400/3125, Loss: 1.370158314704895, Uncertainty: 1.673518419265747
Epoch 114, Batch 500/3125, Loss: 1.588639497756958, Uncertainty: 2.003373622894287
Epoch 114, Batch 600/3125, Loss: 1.459079623222351, Uncertainty: 1.8457510471343994
Epoch 114, Batch 700/3125, Loss: 1.2812459468841553, Uncertainty: 1.5657553672790527
Epoch 114, Batch 800/3125, Loss: 1.5453674793243408, Uncertainty: 1.7823643684387207
Epoch 114, Batch 900/3125, Loss: 1.4112874269485474, Uncertainty: 1.8292603492736816
Epoch 114, Batch 1000/3125, Loss: 1.398949384689331, Uncertainty: 1.7016894817352295
Epoch 114, Batch 1100/3125, Loss: 1.465601921081543, Uncertainty: 1.9686379432678223
Epoch 114, Batch 1200/3125, Loss: 1.2989751100540161, Uncertainty: 1.7374317646026611
Epoch 114, Batch 1300/3125, Loss: 1.2142024040222168, Uncertainty: 1.5575666427612305
Epoch 114, Batch 1400/3125, Loss: 1.560166835784912, Uncertainty: 1.959226131439209
Epoch 114, Batch 1500/3125, Loss: 1.4948136806488037, Uncertainty: 2.098720073699951
Epoch 114, Batch 1600/3125, Loss: 1.5786330699920654, Uncertainty: 1.6089129447937012
Epoch 114, Batch 1700/3125, Loss: 1.54759681224823, Uncertainty: 1.8158398866653442
Epoch 114, Batch 1800/3125, Loss: 1.429532527923584, Uncertainty: 1.8458462953567505
Epoch 114, Batch 1900/3125, Loss: 1.7385739088058472, Uncertainty: 2.2544021606445312
Epoch 114, Batch 2000/3125, Loss: 1.4666485786437988, Uncertainty: 2.230494499206543
Epoch 114, Batch 2100/3125, Loss: 1.869432806968689, Uncertainty: 2.440002918243408
Epoch 114, Batch 2200/3125, Loss: 1.2971043586730957, Uncertainty: 1.4525995254516602
Epoch 114, Batch 2300/3125, Loss: 1.4606914520263672, Uncertainty: 1.7085614204406738
Epoch 114, Batch 2400/3125, Loss: 1.3298797607421875, Uncertainty: 1.624419927597046
Epoch 114, Batch 2500/3125, Loss: 1.435828685760498, Uncertainty: 1.583953857421875
Epoch 114, Batch 2600/3125, Loss: 1.4799296855926514, Uncertainty: 1.939549207687378
Epoch 114, Batch 2700/3125, Loss: 1.467374324798584, Uncertainty: 1.8723320960998535
Epoch 114, Batch 2800/3125, Loss: 1.9172172546386719, Uncertainty: 2.7701659202575684
Epoch 114, Batch 2900/3125, Loss: 1.4536687135696411, Uncertainty: 1.664097785949707
Epoch 114, Batch 3000/3125, Loss: 1.3282005786895752, Uncertainty: 1.6388075351715088
Epoch 114, Batch 3100/3125, Loss: 1.3669497966766357, Uncertainty: 1.7630970478057861

Training and Validation Results of Epoch 114:
================================
Training Loss: 1.1532281127929687, Training Uncertainty: 1.9907555504226684, time: 195.97795486450195
Validation Loss: 1.179733882932102, Validation Uncertainty: 2.641420797923642, time: 45.000508069992065
Number of predictions within uncertainty interval: 112983/200000 (56.49%)

Epoch 115, Batch 100/3125, Loss: 1.4659407138824463, Uncertainty: 1.8196091651916504
Epoch 115, Batch 200/3125, Loss: 1.4863641262054443, Uncertainty: 1.7779085636138916
Epoch 115, Batch 300/3125, Loss: 1.5107160806655884, Uncertainty: 1.8940446376800537
Epoch 115, Batch 400/3125, Loss: 1.6127952337265015, Uncertainty: 2.2604377269744873
Epoch 115, Batch 500/3125, Loss: 1.6003472805023193, Uncertainty: 2.309553384780884
Epoch 115, Batch 600/3125, Loss: 1.4270851612091064, Uncertainty: 1.8464308977127075
Epoch 115, Batch 700/3125, Loss: 1.6628999710083008, Uncertainty: 1.8498432636260986
Epoch 115, Batch 800/3125, Loss: 1.53652024269104, Uncertainty: 2.3735973834991455
Epoch 115, Batch 900/3125, Loss: 1.3333784341812134, Uncertainty: 1.7602076530456543
Epoch 115, Batch 1000/3125, Loss: 1.3583413362503052, Uncertainty: 1.6332876682281494
Epoch 115, Batch 1100/3125, Loss: 1.4684407711029053, Uncertainty: 1.9714024066925049
Epoch 115, Batch 1200/3125, Loss: 1.3932723999023438, Uncertainty: 1.7486262321472168
Epoch 115, Batch 1300/3125, Loss: 1.5139155387878418, Uncertainty: 1.7408628463745117
Epoch 115, Batch 1400/3125, Loss: 1.3554344177246094, Uncertainty: 1.751814842224121
Epoch 115, Batch 1500/3125, Loss: 1.2925856113433838, Uncertainty: 1.7225842475891113
Epoch 115, Batch 1600/3125, Loss: 1.6701005697250366, Uncertainty: 1.9814763069152832
Epoch 115, Batch 1700/3125, Loss: 1.23650062084198, Uncertainty: 1.5608534812927246
Epoch 115, Batch 1800/3125, Loss: 1.251046061515808, Uncertainty: 1.5603126287460327
Epoch 115, Batch 1900/3125, Loss: 1.437913417816162, Uncertainty: 1.5951805114746094
Epoch 115, Batch 2000/3125, Loss: 1.3936591148376465, Uncertainty: 1.6681122779846191
Epoch 115, Batch 2100/3125, Loss: 1.6429736614227295, Uncertainty: 2.263248920440674
Epoch 115, Batch 2200/3125, Loss: 1.43086576461792, Uncertainty: 1.6027300357818604
Epoch 115, Batch 2300/3125, Loss: 1.5025200843811035, Uncertainty: 2.098785877227783
Epoch 115, Batch 2400/3125, Loss: 1.7177369594573975, Uncertainty: 1.6053826808929443
Epoch 115, Batch 2500/3125, Loss: 1.4772212505340576, Uncertainty: 1.8863235712051392
Epoch 115, Batch 2600/3125, Loss: 1.555736780166626, Uncertainty: 1.6731846332550049
Epoch 115, Batch 2700/3125, Loss: 1.550145149230957, Uncertainty: 2.5567750930786133
Epoch 115, Batch 2800/3125, Loss: 2.3791754245758057, Uncertainty: 1.8898932933807373
Epoch 115, Batch 2900/3125, Loss: 1.4844032526016235, Uncertainty: 2.1067326068878174
Epoch 115, Batch 3000/3125, Loss: 1.581559181213379, Uncertainty: 2.1342201232910156
Epoch 115, Batch 3100/3125, Loss: 1.4022929668426514, Uncertainty: 1.756234884262085

Training and Validation Results of Epoch 115:
================================
Training Loss: 1.155084215106964, Training Uncertainty: 1.9811191557693482, time: 197.77619552612305
Validation Loss: 0.9873826560919242, Validation Uncertainty: 2.570091193594286, time: 45.935667753219604
Number of predictions within uncertainty interval: 130527/200000 (65.26%)

Epoch 116, Batch 100/3125, Loss: 1.3640010356903076, Uncertainty: 1.7797331809997559
Epoch 116, Batch 200/3125, Loss: 1.5423848628997803, Uncertainty: 2.097930908203125
Epoch 116, Batch 300/3125, Loss: 1.4435909986495972, Uncertainty: 1.741844654083252
Epoch 116, Batch 400/3125, Loss: 1.5670605897903442, Uncertainty: 2.1023941040039062
Epoch 116, Batch 500/3125, Loss: 1.4639732837677002, Uncertainty: 1.884432315826416
Epoch 116, Batch 600/3125, Loss: 1.6053447723388672, Uncertainty: 2.457827568054199
Epoch 116, Batch 700/3125, Loss: 1.3088899850845337, Uncertainty: 1.6250351667404175
Epoch 116, Batch 800/3125, Loss: 1.5299034118652344, Uncertainty: 1.8594675064086914
Epoch 116, Batch 900/3125, Loss: 1.4401259422302246, Uncertainty: 1.9447202682495117
Epoch 116, Batch 1000/3125, Loss: 1.4252667427062988, Uncertainty: 1.7006498575210571
Epoch 116, Batch 1100/3125, Loss: 1.4555953741073608, Uncertainty: 1.9336289167404175
Epoch 116, Batch 1200/3125, Loss: 1.3641259670257568, Uncertainty: 1.6551387310028076
Epoch 116, Batch 1300/3125, Loss: 1.2654685974121094, Uncertainty: 1.5902408361434937
Epoch 116, Batch 1400/3125, Loss: 1.667933702468872, Uncertainty: 2.4663376808166504
Epoch 116, Batch 1500/3125, Loss: 1.7211599349975586, Uncertainty: 2.5556938648223877
Epoch 116, Batch 1600/3125, Loss: 2.0978074073791504, Uncertainty: 2.739603281021118
Epoch 116, Batch 1700/3125, Loss: 1.6656043529510498, Uncertainty: 2.1030163764953613
Epoch 116, Batch 1800/3125, Loss: 1.7204140424728394, Uncertainty: 1.8040251731872559
Epoch 116, Batch 1900/3125, Loss: 1.3873813152313232, Uncertainty: 1.7338144779205322
Epoch 116, Batch 2000/3125, Loss: 1.3095301389694214, Uncertainty: 1.8328429460525513
Epoch 116, Batch 2100/3125, Loss: 1.5564478635787964, Uncertainty: 2.2608160972595215
Epoch 116, Batch 2200/3125, Loss: 1.3033119440078735, Uncertainty: 1.6936240196228027
Epoch 116, Batch 2300/3125, Loss: 1.4697682857513428, Uncertainty: 1.9201834201812744
Epoch 116, Batch 2400/3125, Loss: 1.6897261142730713, Uncertainty: 2.428575038909912
Epoch 116, Batch 2500/3125, Loss: 1.7492361068725586, Uncertainty: 2.847280740737915
Epoch 116, Batch 2600/3125, Loss: 1.415888786315918, Uncertainty: 1.9896678924560547
Epoch 116, Batch 2700/3125, Loss: 1.6082425117492676, Uncertainty: 2.3310670852661133
Epoch 116, Batch 2800/3125, Loss: 1.5032286643981934, Uncertainty: 1.8271968364715576
Epoch 116, Batch 2900/3125, Loss: 1.962146520614624, Uncertainty: 2.5235376358032227
Epoch 116, Batch 3000/3125, Loss: 1.3020682334899902, Uncertainty: 1.4689909219741821
Epoch 116, Batch 3100/3125, Loss: 1.4447412490844727, Uncertainty: 1.7331879138946533

Training and Validation Results of Epoch 116:
================================
Training Loss: 1.1457340753173828, Training Uncertainty: 1.971048042831421, time: 199.48706936836243
Validation Loss: 0.953290915016628, Validation Uncertainty: 3.782146865449598, time: 49.61648988723755
Number of predictions within uncertainty interval: 164056/200000 (82.03%)

Epoch 117, Batch 100/3125, Loss: 1.4228041172027588, Uncertainty: 1.912047028541565
Epoch 117, Batch 200/3125, Loss: 1.472578525543213, Uncertainty: 2.111304759979248
Epoch 117, Batch 300/3125, Loss: 1.6681993007659912, Uncertainty: 1.937522053718567
Epoch 117, Batch 400/3125, Loss: 1.2602962255477905, Uncertainty: 1.7359744310379028
Epoch 117, Batch 500/3125, Loss: 1.56596839427948, Uncertainty: 1.7547791004180908
Epoch 117, Batch 600/3125, Loss: 1.4202768802642822, Uncertainty: 1.924046277999878
Epoch 117, Batch 700/3125, Loss: 1.6200127601623535, Uncertainty: 1.6741153001785278
Epoch 117, Batch 800/3125, Loss: 1.8340007066726685, Uncertainty: 2.7939600944519043
Epoch 117, Batch 900/3125, Loss: 1.4729846715927124, Uncertainty: 1.849665880203247
Epoch 117, Batch 1000/3125, Loss: 1.6919074058532715, Uncertainty: 2.1809072494506836
Epoch 117, Batch 1100/3125, Loss: 1.4050971269607544, Uncertainty: 1.8570044040679932
Epoch 117, Batch 1200/3125, Loss: 1.2413084506988525, Uncertainty: 1.5013631582260132
Epoch 117, Batch 1300/3125, Loss: 1.869691252708435, Uncertainty: 2.5101284980773926
Epoch 117, Batch 1400/3125, Loss: 1.771780252456665, Uncertainty: 1.93185555934906
Epoch 117, Batch 1500/3125, Loss: 1.2306840419769287, Uncertainty: 1.532323956489563
Epoch 117, Batch 1600/3125, Loss: 1.4904861450195312, Uncertainty: 1.9433377981185913
Epoch 117, Batch 1700/3125, Loss: 1.5942964553833008, Uncertainty: 1.9903032779693604
Epoch 117, Batch 1800/3125, Loss: 2.2493245601654053, Uncertainty: 2.3619961738586426
Epoch 117, Batch 1900/3125, Loss: 1.6410245895385742, Uncertainty: 1.8602294921875
Epoch 117, Batch 2000/3125, Loss: 1.4569672346115112, Uncertainty: 2.2432847023010254
Epoch 117, Batch 2100/3125, Loss: 1.6269433498382568, Uncertainty: 2.1164698600769043
Epoch 117, Batch 2200/3125, Loss: 1.1747957468032837, Uncertainty: 1.4607540369033813
Epoch 117, Batch 2300/3125, Loss: 1.4282491207122803, Uncertainty: 1.8514736890792847
Epoch 117, Batch 2400/3125, Loss: 1.4447853565216064, Uncertainty: 1.8289813995361328
Epoch 117, Batch 2500/3125, Loss: 1.3281253576278687, Uncertainty: 1.841841459274292
Epoch 117, Batch 2600/3125, Loss: 1.6193194389343262, Uncertainty: 1.5639979839324951
Epoch 117, Batch 2700/3125, Loss: 1.8456275463104248, Uncertainty: 2.929459571838379
Epoch 117, Batch 2800/3125, Loss: 1.3563804626464844, Uncertainty: 1.430162787437439
Epoch 117, Batch 2900/3125, Loss: 1.660220742225647, Uncertainty: 2.329720973968506
Epoch 117, Batch 3000/3125, Loss: 1.3677127361297607, Uncertainty: 1.6905571222305298
Epoch 117, Batch 3100/3125, Loss: 1.6428487300872803, Uncertainty: 2.0187630653381348

Training and Validation Results of Epoch 117:
================================
Training Loss: 1.1464902927207947, Training Uncertainty: 1.9900418729400635, time: 199.44273471832275
Validation Loss: 0.9982666885456466, Validation Uncertainty: 2.5457244785240545, time: 45.5125048160553
Number of predictions within uncertainty interval: 124496/200000 (62.25%)

Epoch 118, Batch 100/3125, Loss: 1.5445157289505005, Uncertainty: 2.363154649734497
Epoch 118, Batch 200/3125, Loss: 1.4792993068695068, Uncertainty: 2.154334306716919
Epoch 118, Batch 300/3125, Loss: 1.5313358306884766, Uncertainty: 2.216291904449463
Epoch 118, Batch 400/3125, Loss: 1.7255594730377197, Uncertainty: 2.0299792289733887
Epoch 118, Batch 500/3125, Loss: 1.7236462831497192, Uncertainty: 2.1915602684020996
Epoch 118, Batch 600/3125, Loss: 1.9912748336791992, Uncertainty: 2.441588878631592
Epoch 118, Batch 700/3125, Loss: 1.8341931104660034, Uncertainty: 2.9183077812194824
Epoch 118, Batch 800/3125, Loss: 1.1820155382156372, Uncertainty: 1.5483874082565308
Epoch 118, Batch 900/3125, Loss: 1.6590301990509033, Uncertainty: 2.6173787117004395
Epoch 118, Batch 1000/3125, Loss: 1.6016770601272583, Uncertainty: 2.527174949645996
Epoch 118, Batch 1100/3125, Loss: 1.4765169620513916, Uncertainty: 1.589537262916565
Epoch 118, Batch 1200/3125, Loss: 1.3024961948394775, Uncertainty: 1.6543035507202148
Epoch 118, Batch 1300/3125, Loss: 1.583860158920288, Uncertainty: 1.943458080291748
Epoch 118, Batch 1400/3125, Loss: 1.662535309791565, Uncertainty: 2.344539165496826
Epoch 118, Batch 1500/3125, Loss: 1.452679991722107, Uncertainty: 1.6227957010269165
Epoch 118, Batch 1600/3125, Loss: 1.6050463914871216, Uncertainty: 1.5543556213378906
Epoch 118, Batch 1700/3125, Loss: 1.720839023590088, Uncertainty: 1.8222168684005737
Epoch 118, Batch 1800/3125, Loss: 1.5376358032226562, Uncertainty: 2.1685595512390137
Epoch 118, Batch 1900/3125, Loss: 1.4180808067321777, Uncertainty: 1.707973837852478
Epoch 118, Batch 2000/3125, Loss: 1.5871756076812744, Uncertainty: 1.976144552230835
Epoch 118, Batch 2100/3125, Loss: 1.4688411951065063, Uncertainty: 1.8489644527435303
Epoch 118, Batch 2200/3125, Loss: 1.3631634712219238, Uncertainty: 1.4984261989593506
Epoch 118, Batch 2300/3125, Loss: 1.4239435195922852, Uncertainty: 1.965613842010498
Epoch 118, Batch 2400/3125, Loss: 1.2545204162597656, Uncertainty: 1.6000022888183594
Epoch 118, Batch 2500/3125, Loss: 1.5552053451538086, Uncertainty: 1.5980359315872192
Epoch 118, Batch 2600/3125, Loss: 1.4857008457183838, Uncertainty: 1.7687244415283203
Epoch 118, Batch 2700/3125, Loss: 1.374847650527954, Uncertainty: 1.8975510597229004
Epoch 118, Batch 2800/3125, Loss: 1.8065431118011475, Uncertainty: 2.3056998252868652
Epoch 118, Batch 2900/3125, Loss: 1.628974437713623, Uncertainty: 1.8108384609222412
Epoch 118, Batch 3000/3125, Loss: 1.4685347080230713, Uncertainty: 1.712175726890564
Epoch 118, Batch 3100/3125, Loss: 1.2754838466644287, Uncertainty: 1.5547065734863281

Training and Validation Results of Epoch 118:
================================
Training Loss: 1.1417037434768678, Training Uncertainty: 1.97371873462677, time: 198.31421995162964
Validation Loss: 0.8379861274186302, Validation Uncertainty: 2.8671579010346355, time: 46.17441964149475
Number of predictions within uncertainty interval: 149869/200000 (74.93%)

Epoch 119, Batch 100/3125, Loss: 1.191408395767212, Uncertainty: 1.529921293258667
Epoch 119, Batch 200/3125, Loss: 1.493868350982666, Uncertainty: 2.142731189727783
Epoch 119, Batch 300/3125, Loss: 1.3600492477416992, Uncertainty: 1.892698049545288
Epoch 119, Batch 400/3125, Loss: 1.6359291076660156, Uncertainty: 2.0838325023651123
Epoch 119, Batch 500/3125, Loss: 1.3377680778503418, Uncertainty: 1.9900782108306885
Epoch 119, Batch 600/3125, Loss: 1.9265965223312378, Uncertainty: 2.065124034881592
Epoch 119, Batch 700/3125, Loss: 1.274825096130371, Uncertainty: 1.6495778560638428
Epoch 119, Batch 800/3125, Loss: 1.899827241897583, Uncertainty: 1.5168648958206177
Epoch 119, Batch 900/3125, Loss: 2.3740344047546387, Uncertainty: 4.019726753234863
Epoch 119, Batch 1000/3125, Loss: 1.3274807929992676, Uncertainty: 1.743880033493042
Epoch 119, Batch 1100/3125, Loss: 1.6367928981781006, Uncertainty: 1.828521490097046
Epoch 119, Batch 1200/3125, Loss: 1.6791373491287231, Uncertainty: 2.1237573623657227
Epoch 119, Batch 1300/3125, Loss: 1.3300647735595703, Uncertainty: 1.7689400911331177
Epoch 119, Batch 1400/3125, Loss: 1.6211011409759521, Uncertainty: 2.3369832038879395
Epoch 119, Batch 1500/3125, Loss: 1.352907657623291, Uncertainty: 1.7641208171844482
Epoch 119, Batch 1600/3125, Loss: 1.2003209590911865, Uncertainty: 1.606877088546753
Epoch 119, Batch 1700/3125, Loss: 1.5390582084655762, Uncertainty: 2.336238384246826
Epoch 119, Batch 1800/3125, Loss: 1.59120774269104, Uncertainty: 1.6368200778961182
Epoch 119, Batch 1900/3125, Loss: 1.3979592323303223, Uncertainty: 1.7987253665924072
Epoch 119, Batch 2000/3125, Loss: 1.3001105785369873, Uncertainty: 1.8401100635528564
Epoch 119, Batch 2100/3125, Loss: 1.4218720197677612, Uncertainty: 1.6448965072631836
Epoch 119, Batch 2200/3125, Loss: 1.4802273511886597, Uncertainty: 1.731826901435852
Epoch 119, Batch 2300/3125, Loss: 1.4455616474151611, Uncertainty: 1.950162410736084
Epoch 119, Batch 2400/3125, Loss: 1.624572515487671, Uncertainty: 2.032822370529175
Epoch 119, Batch 2500/3125, Loss: 1.6089301109313965, Uncertainty: 2.4506092071533203
Epoch 119, Batch 2600/3125, Loss: 1.5490429401397705, Uncertainty: 1.7971222400665283
Epoch 119, Batch 2700/3125, Loss: 1.7213375568389893, Uncertainty: 2.31428599357605
Epoch 119, Batch 2800/3125, Loss: 1.667492151260376, Uncertainty: 2.607883930206299
Epoch 119, Batch 2900/3125, Loss: 1.7873730659484863, Uncertainty: 3.0283217430114746
Epoch 119, Batch 3000/3125, Loss: 1.472287893295288, Uncertainty: 1.654463768005371
Epoch 119, Batch 3100/3125, Loss: 1.4199564456939697, Uncertainty: 1.7936372756958008

Training and Validation Results of Epoch 119:
================================
Training Loss: 1.1400270962905883, Training Uncertainty: 1.951813900680542, time: 196.17561197280884
Validation Loss: 0.8968926553835954, Validation Uncertainty: 2.616639858011699, time: 44.972917556762695
Number of predictions within uncertainty interval: 136689/200000 (68.34%)

Epoch 120, Batch 100/3125, Loss: 1.4666101932525635, Uncertainty: 2.304683208465576
Epoch 120, Batch 200/3125, Loss: 1.2947862148284912, Uncertainty: 1.6358957290649414
Epoch 120, Batch 300/3125, Loss: 1.5369070768356323, Uncertainty: 2.1570849418640137
Epoch 120, Batch 400/3125, Loss: 1.4775056838989258, Uncertainty: 1.944026231765747
Epoch 120, Batch 500/3125, Loss: 1.395829200744629, Uncertainty: 1.9272996187210083
Epoch 120, Batch 600/3125, Loss: 1.4032845497131348, Uncertainty: 1.7437148094177246
Epoch 120, Batch 700/3125, Loss: 1.7566437721252441, Uncertainty: 2.3841238021850586
Epoch 120, Batch 800/3125, Loss: 1.4519579410552979, Uncertainty: 1.7405530214309692
Epoch 120, Batch 900/3125, Loss: 1.6086926460266113, Uncertainty: 1.832434892654419
Epoch 120, Batch 1000/3125, Loss: 1.9517018795013428, Uncertainty: 2.695937156677246
Epoch 120, Batch 1100/3125, Loss: 1.7133628129959106, Uncertainty: 1.606100082397461
Epoch 120, Batch 1200/3125, Loss: 1.3818488121032715, Uncertainty: 1.9542477130889893
Epoch 120, Batch 1300/3125, Loss: 1.4710240364074707, Uncertainty: 2.1265695095062256
Epoch 120, Batch 1400/3125, Loss: 1.6353981494903564, Uncertainty: 2.5526702404022217
Epoch 120, Batch 1500/3125, Loss: 1.2784844636917114, Uncertainty: 1.6628203392028809
Epoch 120, Batch 1600/3125, Loss: 1.356798768043518, Uncertainty: 1.7149953842163086
Epoch 120, Batch 1700/3125, Loss: 1.3603975772857666, Uncertainty: 1.9224435091018677
Epoch 120, Batch 1800/3125, Loss: 1.2962782382965088, Uncertainty: 1.5952149629592896
Epoch 120, Batch 1900/3125, Loss: 1.3613860607147217, Uncertainty: 1.6200110912322998
Epoch 120, Batch 2000/3125, Loss: 1.4882400035858154, Uncertainty: 2.1342265605926514
Epoch 120, Batch 2100/3125, Loss: 1.4977891445159912, Uncertainty: 1.7112114429473877
Epoch 120, Batch 2200/3125, Loss: 1.5286667346954346, Uncertainty: 2.562534809112549
Epoch 120, Batch 2300/3125, Loss: 1.442276954650879, Uncertainty: 2.0195810794830322
Epoch 120, Batch 2400/3125, Loss: 1.434768795967102, Uncertainty: 1.5900053977966309
Epoch 120, Batch 2500/3125, Loss: 1.2914687395095825, Uncertainty: 1.4864544868469238
Epoch 120, Batch 2600/3125, Loss: 1.8924267292022705, Uncertainty: 2.6970579624176025
Epoch 120, Batch 2700/3125, Loss: 1.5600955486297607, Uncertainty: 2.4192428588867188
Epoch 120, Batch 2800/3125, Loss: 1.4683690071105957, Uncertainty: 1.7831649780273438
Epoch 120, Batch 2900/3125, Loss: 1.4188674688339233, Uncertainty: 1.9627844095230103
Epoch 120, Batch 3000/3125, Loss: 1.6987926959991455, Uncertainty: 2.3572604656219482
Epoch 120, Batch 3100/3125, Loss: 1.6078169345855713, Uncertainty: 2.1730246543884277

Training and Validation Results of Epoch 120:
================================
Training Loss: 1.14184559841156, Training Uncertainty: 1.968596720428467, time: 196.98388123512268
Validation Loss: 0.8732249798524715, Validation Uncertainty: 3.065891708559392, time: 46.06603527069092
Number of predictions within uncertainty interval: 153493/200000 (76.75%)

Epoch 121, Batch 100/3125, Loss: 1.196805477142334, Uncertainty: 1.535361886024475
Epoch 121, Batch 200/3125, Loss: 1.6670154333114624, Uncertainty: 2.5411555767059326
Epoch 121, Batch 300/3125, Loss: 1.395138144493103, Uncertainty: 1.6940357685089111
Epoch 121, Batch 400/3125, Loss: 1.3510651588439941, Uncertainty: 1.7912042140960693
Epoch 121, Batch 500/3125, Loss: 1.3222736120224, Uncertainty: 1.654301404953003
Epoch 121, Batch 600/3125, Loss: 1.5981719493865967, Uncertainty: 2.4051616191864014
Epoch 121, Batch 700/3125, Loss: 1.3711199760437012, Uncertainty: 1.7995643615722656
Epoch 121, Batch 800/3125, Loss: 1.596051812171936, Uncertainty: 2.575439453125
Epoch 121, Batch 900/3125, Loss: 1.395381212234497, Uncertainty: 1.8149514198303223
Epoch 121, Batch 1000/3125, Loss: 1.5039350986480713, Uncertainty: 1.6303919553756714
Epoch 121, Batch 1100/3125, Loss: 1.8193402290344238, Uncertainty: 1.9323543310165405
Epoch 121, Batch 1200/3125, Loss: 1.3876795768737793, Uncertainty: 1.8675308227539062
Epoch 121, Batch 1300/3125, Loss: 1.600691318511963, Uncertainty: 1.8061039447784424
Epoch 121, Batch 1400/3125, Loss: 1.4494431018829346, Uncertainty: 1.901465654373169
Epoch 121, Batch 1500/3125, Loss: 1.6548514366149902, Uncertainty: 2.0757651329040527
Epoch 121, Batch 1600/3125, Loss: 1.185685396194458, Uncertainty: 1.4779788255691528
Epoch 121, Batch 1700/3125, Loss: 1.443038821220398, Uncertainty: 1.8693662881851196
Epoch 121, Batch 1800/3125, Loss: 1.872733235359192, Uncertainty: 2.78662371635437
Epoch 121, Batch 1900/3125, Loss: 1.6797046661376953, Uncertainty: 1.8829352855682373
Epoch 121, Batch 2000/3125, Loss: 1.4955151081085205, Uncertainty: 1.803406000137329
Epoch 121, Batch 2100/3125, Loss: 1.4926528930664062, Uncertainty: 1.7813191413879395
Epoch 121, Batch 2200/3125, Loss: 1.541776418685913, Uncertainty: 1.5728881359100342
Epoch 121, Batch 2300/3125, Loss: 1.7216166257858276, Uncertainty: 2.6535770893096924
Epoch 121, Batch 2400/3125, Loss: 1.4111108779907227, Uncertainty: 1.8282599449157715
Epoch 121, Batch 2500/3125, Loss: 1.5237839221954346, Uncertainty: 2.3581418991088867
Epoch 121, Batch 2600/3125, Loss: 1.4432718753814697, Uncertainty: 2.015132427215576
Epoch 121, Batch 2700/3125, Loss: 1.6482083797454834, Uncertainty: 2.214418411254883
Epoch 121, Batch 2800/3125, Loss: 1.3212714195251465, Uncertainty: 1.482263207435608
Epoch 121, Batch 2900/3125, Loss: 1.4119865894317627, Uncertainty: 1.9590952396392822
Epoch 121, Batch 3000/3125, Loss: 1.6122410297393799, Uncertainty: 1.6881481409072876
Epoch 121, Batch 3100/3125, Loss: 1.3242803812026978, Uncertainty: 1.5717928409576416

Training and Validation Results of Epoch 121:
================================
Training Loss: 1.11721380695343, Training Uncertainty: 1.9334587482452392, time: 202.7460515499115
Validation Loss: 0.9634912553650644, Validation Uncertainty: 3.4601808002842662, time: 46.24808430671692
Number of predictions within uncertainty interval: 151539/200000 (75.77%)

Epoch 122, Batch 100/3125, Loss: 1.527052879333496, Uncertainty: 1.9851603507995605
Epoch 122, Batch 200/3125, Loss: 1.5051826238632202, Uncertainty: 1.6450161933898926
Epoch 122, Batch 300/3125, Loss: 1.5683581829071045, Uncertainty: 2.275341033935547
Epoch 122, Batch 400/3125, Loss: 1.3822436332702637, Uncertainty: 1.7837148904800415
Epoch 122, Batch 500/3125, Loss: 1.4189214706420898, Uncertainty: 1.4822912216186523
Epoch 122, Batch 600/3125, Loss: 1.4630159139633179, Uncertainty: 2.195046901702881
Epoch 122, Batch 700/3125, Loss: 1.682845115661621, Uncertainty: 2.691283702850342
Epoch 122, Batch 800/3125, Loss: 1.4487017393112183, Uncertainty: 1.9235830307006836
Epoch 122, Batch 900/3125, Loss: 1.3328588008880615, Uncertainty: 1.9158146381378174
Epoch 122, Batch 1000/3125, Loss: 1.7019870281219482, Uncertainty: 1.9405955076217651
Epoch 122, Batch 1100/3125, Loss: 1.472280740737915, Uncertainty: 2.03446102142334
Epoch 122, Batch 1200/3125, Loss: 1.2958316802978516, Uncertainty: 1.4091020822525024
Epoch 122, Batch 1300/3125, Loss: 1.660635232925415, Uncertainty: 1.9056289196014404
Epoch 122, Batch 1400/3125, Loss: 1.3558661937713623, Uncertainty: 1.7343978881835938
Epoch 122, Batch 1500/3125, Loss: 1.2700103521347046, Uncertainty: 1.686390995979309
Epoch 122, Batch 1600/3125, Loss: 1.3869593143463135, Uncertainty: 1.5085341930389404
Epoch 122, Batch 1700/3125, Loss: 1.3491166830062866, Uncertainty: 1.7818602323532104
Epoch 122, Batch 1800/3125, Loss: 1.4568603038787842, Uncertainty: 1.9239881038665771
Epoch 122, Batch 1900/3125, Loss: 1.3816938400268555, Uncertainty: 1.8896207809448242
Epoch 122, Batch 2000/3125, Loss: 1.3860310316085815, Uncertainty: 1.7176685333251953
Epoch 122, Batch 2100/3125, Loss: 2.1439414024353027, Uncertainty: 2.098522663116455
Epoch 122, Batch 2200/3125, Loss: 1.410987377166748, Uncertainty: 1.6387708187103271
Epoch 122, Batch 2300/3125, Loss: 1.34872305393219, Uncertainty: 1.7165277004241943
Epoch 122, Batch 2400/3125, Loss: 1.4000636339187622, Uncertainty: 1.716768741607666
Epoch 122, Batch 2500/3125, Loss: 1.2142419815063477, Uncertainty: 1.5662647485733032
Epoch 122, Batch 2600/3125, Loss: 1.3441030979156494, Uncertainty: 1.6367872953414917
Epoch 122, Batch 2700/3125, Loss: 1.7052497863769531, Uncertainty: 2.639033555984497
Epoch 122, Batch 2800/3125, Loss: 1.4714964628219604, Uncertainty: 1.940312385559082
Epoch 122, Batch 2900/3125, Loss: 1.4362051486968994, Uncertainty: 1.8163328170776367
Epoch 122, Batch 3000/3125, Loss: 1.4112770557403564, Uncertainty: 1.9298934936523438
Epoch 122, Batch 3100/3125, Loss: 1.2527599334716797, Uncertainty: 1.5891103744506836

Training and Validation Results of Epoch 122:
================================
Training Loss: 1.1126494626426697, Training Uncertainty: 1.9397448075485229, time: 199.63242268562317
Validation Loss: 0.8848735121509913, Validation Uncertainty: 3.3247268581024523, time: 45.966373443603516
Number of predictions within uncertainty interval: 157174/200000 (78.59%)

Epoch 123, Batch 100/3125, Loss: 1.2096502780914307, Uncertainty: 1.701408863067627
Epoch 123, Batch 200/3125, Loss: 2.0982861518859863, Uncertainty: 2.5004894733428955
Epoch 123, Batch 300/3125, Loss: 1.331545352935791, Uncertainty: 1.8202202320098877
Epoch 123, Batch 400/3125, Loss: 1.4348094463348389, Uncertainty: 1.9152333736419678
Epoch 123, Batch 500/3125, Loss: 1.6165329217910767, Uncertainty: 2.272867202758789
Epoch 123, Batch 600/3125, Loss: 1.3929873704910278, Uncertainty: 1.7712559700012207
Epoch 123, Batch 700/3125, Loss: 1.3370028734207153, Uncertainty: 1.9095442295074463
Epoch 123, Batch 800/3125, Loss: 1.446864128112793, Uncertainty: 1.617833137512207
Epoch 123, Batch 900/3125, Loss: 1.3858790397644043, Uncertainty: 1.5677627325057983
Epoch 123, Batch 1000/3125, Loss: 1.5923936367034912, Uncertainty: 2.0966005325317383
Epoch 123, Batch 1100/3125, Loss: 1.4729588031768799, Uncertainty: 2.0398106575012207
Epoch 123, Batch 1200/3125, Loss: 1.3345918655395508, Uncertainty: 1.4163825511932373
Epoch 123, Batch 1300/3125, Loss: 1.4776878356933594, Uncertainty: 2.1304683685302734
Epoch 123, Batch 1400/3125, Loss: 1.6580291986465454, Uncertainty: 2.192152500152588
Epoch 123, Batch 1500/3125, Loss: 1.5200592279434204, Uncertainty: 2.382841110229492
Epoch 123, Batch 1600/3125, Loss: 1.5459378957748413, Uncertainty: 2.4124550819396973
Epoch 123, Batch 1700/3125, Loss: 1.3393399715423584, Uncertainty: 1.9732675552368164
Epoch 123, Batch 1800/3125, Loss: 1.340622901916504, Uncertainty: 1.5879299640655518
Epoch 123, Batch 1900/3125, Loss: 1.3963954448699951, Uncertainty: 1.6934685707092285
Epoch 123, Batch 2000/3125, Loss: 1.2686280012130737, Uncertainty: 1.6648122072219849
Epoch 123, Batch 2100/3125, Loss: 1.4734413623809814, Uncertainty: 2.026691198348999
Epoch 123, Batch 2200/3125, Loss: 1.3341381549835205, Uncertainty: 1.702606201171875
Epoch 123, Batch 2300/3125, Loss: 1.4770288467407227, Uncertainty: 1.7830535173416138
Epoch 123, Batch 2400/3125, Loss: 1.6466944217681885, Uncertainty: 2.414259910583496
Epoch 123, Batch 2500/3125, Loss: 1.6268458366394043, Uncertainty: 1.8120431900024414
Epoch 123, Batch 2600/3125, Loss: 1.372218132019043, Uncertainty: 1.7979077100753784
Epoch 123, Batch 2700/3125, Loss: 1.8367087841033936, Uncertainty: 2.2772421836853027
Epoch 123, Batch 2800/3125, Loss: 1.2610960006713867, Uncertainty: 1.6149569749832153
Epoch 123, Batch 2900/3125, Loss: 1.750364065170288, Uncertainty: 1.826258897781372
Epoch 123, Batch 3000/3125, Loss: 1.4165830612182617, Uncertainty: 2.0335805416107178
Epoch 123, Batch 3100/3125, Loss: 1.3614532947540283, Uncertainty: 1.713795781135559

Training and Validation Results of Epoch 123:
================================
Training Loss: 1.1146395243072509, Training Uncertainty: 1.9484739825439452, time: 197.11210918426514
Validation Loss: 0.9303029631562245, Validation Uncertainty: 3.1646743140866995, time: 45.49215245246887
Number of predictions within uncertainty interval: 152635/200000 (76.32%)

Epoch 124, Batch 100/3125, Loss: 1.1885626316070557, Uncertainty: 1.7313907146453857
Epoch 124, Batch 200/3125, Loss: 1.238162875175476, Uncertainty: 1.454892635345459
Epoch 124, Batch 300/3125, Loss: 1.4099314212799072, Uncertainty: 1.7986106872558594
Epoch 124, Batch 400/3125, Loss: 1.4054770469665527, Uncertainty: 2.007733106613159
Epoch 124, Batch 500/3125, Loss: 1.4773638248443604, Uncertainty: 1.739173412322998
Epoch 124, Batch 600/3125, Loss: 1.8380842208862305, Uncertainty: 2.498344898223877
Epoch 124, Batch 700/3125, Loss: 1.585268497467041, Uncertainty: 1.689015507698059
Epoch 124, Batch 800/3125, Loss: 1.443648338317871, Uncertainty: 2.1031179428100586
Epoch 124, Batch 900/3125, Loss: 1.4891667366027832, Uncertainty: 2.0332932472229004
Epoch 124, Batch 1000/3125, Loss: 1.3744053840637207, Uncertainty: 1.566076397895813
Epoch 124, Batch 1100/3125, Loss: 1.2991116046905518, Uncertainty: 1.7368308305740356
Epoch 124, Batch 1200/3125, Loss: 1.4085853099822998, Uncertainty: 1.8284159898757935
Epoch 124, Batch 1300/3125, Loss: 1.2991769313812256, Uncertainty: 1.8569657802581787
Epoch 124, Batch 1400/3125, Loss: 1.4350051879882812, Uncertainty: 2.0478410720825195
Epoch 124, Batch 1500/3125, Loss: 1.4431995153427124, Uncertainty: 2.211057186126709
Epoch 124, Batch 1600/3125, Loss: 1.2616273164749146, Uncertainty: 1.546843409538269
Epoch 124, Batch 1700/3125, Loss: 1.5002522468566895, Uncertainty: 1.849410057067871
Epoch 124, Batch 1800/3125, Loss: 1.3429511785507202, Uncertainty: 1.5110962390899658
Epoch 124, Batch 1900/3125, Loss: 1.3922650814056396, Uncertainty: 1.762044072151184
Epoch 124, Batch 2000/3125, Loss: 1.2674345970153809, Uncertainty: 1.8123035430908203
Epoch 124, Batch 2100/3125, Loss: 1.335353136062622, Uncertainty: 1.6623539924621582
Epoch 124, Batch 2200/3125, Loss: 1.3538775444030762, Uncertainty: 1.7606558799743652
Epoch 124, Batch 2300/3125, Loss: 1.5858685970306396, Uncertainty: 1.78067946434021
Epoch 124, Batch 2400/3125, Loss: 1.2741694450378418, Uncertainty: 1.6671271324157715
Epoch 124, Batch 2500/3125, Loss: 1.3914613723754883, Uncertainty: 1.9804655313491821
Epoch 124, Batch 2600/3125, Loss: 1.3992009162902832, Uncertainty: 2.016063928604126
Epoch 124, Batch 2700/3125, Loss: 1.3407255411148071, Uncertainty: 1.8220244646072388
Epoch 124, Batch 2800/3125, Loss: 1.4615864753723145, Uncertainty: 1.7922509908676147
Epoch 124, Batch 2900/3125, Loss: 1.7736363410949707, Uncertainty: 2.9774374961853027
Epoch 124, Batch 3000/3125, Loss: 1.379554033279419, Uncertainty: 1.7972967624664307
Epoch 124, Batch 3100/3125, Loss: 1.5574595928192139, Uncertainty: 2.130082607269287

Training and Validation Results of Epoch 124:
================================
Training Loss: 1.106818932094574, Training Uncertainty: 1.9380657950592042, time: 196.45430517196655
Validation Loss: 0.9687945014985321, Validation Uncertainty: 3.0001463280309495, time: 44.91052985191345
Number of predictions within uncertainty interval: 141423/200000 (70.71%)

Epoch 125, Batch 100/3125, Loss: 1.2924633026123047, Uncertainty: 1.880285382270813
Epoch 125, Batch 200/3125, Loss: 1.4889776706695557, Uncertainty: 2.069624185562134
Epoch 125, Batch 300/3125, Loss: 1.1985864639282227, Uncertainty: 1.5488349199295044
Epoch 125, Batch 400/3125, Loss: 1.2853904962539673, Uncertainty: 1.7689659595489502
Epoch 125, Batch 500/3125, Loss: 1.311632513999939, Uncertainty: 1.7630947828292847
Epoch 125, Batch 600/3125, Loss: 1.9087846279144287, Uncertainty: 2.8264994621276855
Epoch 125, Batch 700/3125, Loss: 1.2767510414123535, Uncertainty: 1.67363440990448
Epoch 125, Batch 800/3125, Loss: 1.2363097667694092, Uncertainty: 1.8036322593688965
Epoch 125, Batch 900/3125, Loss: 1.2079527378082275, Uncertainty: 1.6155352592468262
Epoch 125, Batch 1000/3125, Loss: 1.5805604457855225, Uncertainty: 1.9937294721603394
Epoch 125, Batch 1100/3125, Loss: 1.7203564643859863, Uncertainty: 1.7740081548690796
Epoch 125, Batch 1200/3125, Loss: 1.663905143737793, Uncertainty: 1.645510196685791
Epoch 125, Batch 1300/3125, Loss: 1.6544303894042969, Uncertainty: 2.564445972442627
Epoch 125, Batch 1400/3125, Loss: 1.3101606369018555, Uncertainty: 1.821348786354065
Epoch 125, Batch 1500/3125, Loss: 1.8384485244750977, Uncertainty: 2.650881767272949
Epoch 125, Batch 1600/3125, Loss: 1.2673039436340332, Uncertainty: 1.595892310142517
Epoch 125, Batch 1700/3125, Loss: 1.2911851406097412, Uncertainty: 1.760643720626831
Epoch 125, Batch 1800/3125, Loss: 1.5965352058410645, Uncertainty: 1.6594476699829102
Epoch 125, Batch 1900/3125, Loss: 1.4767953157424927, Uncertainty: 1.7883647680282593
Epoch 125, Batch 2000/3125, Loss: 1.2749725580215454, Uncertainty: 1.5583792924880981
Epoch 125, Batch 2100/3125, Loss: 1.4731310606002808, Uncertainty: 1.5516047477722168
Epoch 125, Batch 2200/3125, Loss: 1.3511720895767212, Uncertainty: 1.9121522903442383
Epoch 125, Batch 2300/3125, Loss: 1.3023306131362915, Uncertainty: 1.5284771919250488
Epoch 125, Batch 2400/3125, Loss: 1.5854939222335815, Uncertainty: 2.3524632453918457
Epoch 125, Batch 2500/3125, Loss: 1.2812845706939697, Uncertainty: 1.7629027366638184
Epoch 125, Batch 2600/3125, Loss: 1.5661778450012207, Uncertainty: 1.9608168601989746
Epoch 125, Batch 2700/3125, Loss: 1.5284028053283691, Uncertainty: 2.5114798545837402
Epoch 125, Batch 2800/3125, Loss: 1.4458953142166138, Uncertainty: 1.6547579765319824
Epoch 125, Batch 2900/3125, Loss: 1.169662356376648, Uncertainty: 1.491018533706665
Epoch 125, Batch 3000/3125, Loss: 1.6309666633605957, Uncertainty: 1.7326934337615967
Epoch 125, Batch 3100/3125, Loss: 1.569913625717163, Uncertainty: 2.2809576988220215

Training and Validation Results of Epoch 125:
================================
Training Loss: 1.1129470514678954, Training Uncertainty: 1.913575689239502, time: 198.40314197540283
Validation Loss: 0.9960543030820539, Validation Uncertainty: 3.066321191275516, time: 45.708497047424316
Number of predictions within uncertainty interval: 142852/200000 (71.43%)

Epoch 126, Batch 100/3125, Loss: 1.2606806755065918, Uncertainty: 1.7897162437438965
Epoch 126, Batch 200/3125, Loss: 1.3565125465393066, Uncertainty: 1.8597743511199951
Epoch 126, Batch 300/3125, Loss: 1.4608863592147827, Uncertainty: 2.179835796356201
Epoch 126, Batch 400/3125, Loss: 1.3914775848388672, Uncertainty: 1.5585509538650513
Epoch 126, Batch 500/3125, Loss: 1.1778459548950195, Uncertainty: 1.5487329959869385
Epoch 126, Batch 600/3125, Loss: 1.7304445505142212, Uncertainty: 2.606844425201416
Epoch 126, Batch 700/3125, Loss: 1.2848302125930786, Uncertainty: 1.6334723234176636
Epoch 126, Batch 800/3125, Loss: 1.9202606678009033, Uncertainty: 3.4891223907470703
Epoch 126, Batch 900/3125, Loss: 1.6753370761871338, Uncertainty: 2.7114343643188477
Epoch 126, Batch 1000/3125, Loss: 1.4443162679672241, Uncertainty: 1.9485809803009033
Epoch 126, Batch 1100/3125, Loss: 1.66231107711792, Uncertainty: 2.419283390045166
Epoch 126, Batch 1200/3125, Loss: 1.3537116050720215, Uncertainty: 1.6392974853515625
Epoch 126, Batch 1300/3125, Loss: 1.4826000928878784, Uncertainty: 1.799298644065857
Epoch 126, Batch 1400/3125, Loss: 1.6145026683807373, Uncertainty: 2.142700672149658
Epoch 126, Batch 1500/3125, Loss: 1.1878302097320557, Uncertainty: 1.5266746282577515
Epoch 126, Batch 1600/3125, Loss: 1.3110188245773315, Uncertainty: 1.9147216081619263
Epoch 126, Batch 1700/3125, Loss: 1.361832618713379, Uncertainty: 1.9948285818099976
Epoch 126, Batch 1800/3125, Loss: 1.6335227489471436, Uncertainty: 2.5008912086486816
Epoch 126, Batch 1900/3125, Loss: 1.2347512245178223, Uncertainty: 1.6938508749008179
Epoch 126, Batch 2000/3125, Loss: 1.3889484405517578, Uncertainty: 1.7172714471817017
Epoch 126, Batch 2100/3125, Loss: 1.6532723903656006, Uncertainty: 2.3720321655273438
Epoch 126, Batch 2200/3125, Loss: 1.3986430168151855, Uncertainty: 1.9410858154296875
Epoch 126, Batch 2300/3125, Loss: 1.6991021633148193, Uncertainty: 2.163529396057129
Epoch 126, Batch 2400/3125, Loss: 1.8848488330841064, Uncertainty: 1.9874529838562012
Epoch 126, Batch 2500/3125, Loss: 1.2898120880126953, Uncertainty: 1.7327991724014282
Epoch 126, Batch 2600/3125, Loss: 1.6083521842956543, Uncertainty: 2.270944118499756
Epoch 126, Batch 2700/3125, Loss: 1.5463097095489502, Uncertainty: 2.1242547035217285
Epoch 126, Batch 2800/3125, Loss: 1.7837530374526978, Uncertainty: 2.605410575866699
Epoch 126, Batch 2900/3125, Loss: 1.3844324350357056, Uncertainty: 2.0448930263519287
Epoch 126, Batch 3000/3125, Loss: 1.394690990447998, Uncertainty: 1.8447039127349854
Epoch 126, Batch 3100/3125, Loss: 1.2807552814483643, Uncertainty: 1.8155235052108765

Training and Validation Results of Epoch 126:
================================
Training Loss: 1.0905934486007691, Training Uncertainty: 1.9189052703094482, time: 197.22450041770935
Validation Loss: 0.8845319217428222, Validation Uncertainty: 2.6469189773130295, time: 45.928165674209595
Number of predictions within uncertainty interval: 139387/200000 (69.69%)

Epoch 127, Batch 100/3125, Loss: 1.4218021631240845, Uncertainty: 1.8915185928344727
Epoch 127, Batch 200/3125, Loss: 1.7125530242919922, Uncertainty: 2.859104633331299
Epoch 127, Batch 300/3125, Loss: 1.5881983041763306, Uncertainty: 2.237931728363037
Epoch 127, Batch 400/3125, Loss: 1.569833755493164, Uncertainty: 1.6646692752838135
Epoch 127, Batch 500/3125, Loss: 1.467334270477295, Uncertainty: 1.8413095474243164
Epoch 127, Batch 600/3125, Loss: 1.452660322189331, Uncertainty: 1.8276097774505615
Epoch 127, Batch 700/3125, Loss: 1.323239803314209, Uncertainty: 1.9696056842803955
Epoch 127, Batch 800/3125, Loss: 1.4310574531555176, Uncertainty: 1.5755653381347656
Epoch 127, Batch 900/3125, Loss: 1.3677486181259155, Uncertainty: 1.7362241744995117
Epoch 127, Batch 1000/3125, Loss: 1.7048628330230713, Uncertainty: 2.3289542198181152
Epoch 127, Batch 1100/3125, Loss: 1.3565884828567505, Uncertainty: 1.5544253587722778
Epoch 127, Batch 1200/3125, Loss: 1.5155320167541504, Uncertainty: 1.9587607383728027
Epoch 127, Batch 1300/3125, Loss: 1.3383190631866455, Uncertainty: 1.7387235164642334
Epoch 127, Batch 1400/3125, Loss: 1.3223991394042969, Uncertainty: 1.7875066995620728
Epoch 127, Batch 1500/3125, Loss: 1.4542325735092163, Uncertainty: 1.4817636013031006
Epoch 127, Batch 1600/3125, Loss: 1.735610842704773, Uncertainty: 1.629988670349121
Epoch 127, Batch 1700/3125, Loss: 1.400663137435913, Uncertainty: 1.9602599143981934
Epoch 127, Batch 1800/3125, Loss: 1.5127984285354614, Uncertainty: 1.6807746887207031
Epoch 127, Batch 1900/3125, Loss: 1.2737782001495361, Uncertainty: 1.7745106220245361
Epoch 127, Batch 2000/3125, Loss: 1.4666635990142822, Uncertainty: 1.9153517484664917
Epoch 127, Batch 2100/3125, Loss: 1.4509913921356201, Uncertainty: 1.884934902191162
Epoch 127, Batch 2200/3125, Loss: 1.6376047134399414, Uncertainty: 1.854849100112915
Epoch 127, Batch 2300/3125, Loss: 1.5021175146102905, Uncertainty: 2.015258550643921
Epoch 127, Batch 2400/3125, Loss: 1.5819668769836426, Uncertainty: 2.2155091762542725
Epoch 127, Batch 2500/3125, Loss: 1.3155403137207031, Uncertainty: 1.7274019718170166
Epoch 127, Batch 2600/3125, Loss: 1.4617609977722168, Uncertainty: 2.0138745307922363
Epoch 127, Batch 2700/3125, Loss: 1.4052186012268066, Uncertainty: 2.070194721221924
Epoch 127, Batch 2800/3125, Loss: 1.6579328775405884, Uncertainty: 2.4571726322174072
Epoch 127, Batch 2900/3125, Loss: 1.3325598239898682, Uncertainty: 1.6465513706207275
Epoch 127, Batch 3000/3125, Loss: 1.3318026065826416, Uncertainty: 1.734910488128662
Epoch 127, Batch 3100/3125, Loss: 1.630525827407837, Uncertainty: 1.7179405689239502

Training and Validation Results of Epoch 127:
================================
Training Loss: 1.0991059427833556, Training Uncertainty: 1.915151805419922, time: 198.15676498413086
Validation Loss: 0.8777853881611544, Validation Uncertainty: 2.850610568395356, time: 45.81502676010132
Number of predictions within uncertainty interval: 148519/200000 (74.26%)

Epoch 128, Batch 100/3125, Loss: 1.330085039138794, Uncertainty: 1.9297285079956055
Epoch 128, Batch 200/3125, Loss: 1.6325383186340332, Uncertainty: 2.823326587677002
Epoch 128, Batch 300/3125, Loss: 1.3979473114013672, Uncertainty: 1.732179045677185
Epoch 128, Batch 400/3125, Loss: 1.2777518033981323, Uncertainty: 1.7865248918533325
Epoch 128, Batch 500/3125, Loss: 1.6059569120407104, Uncertainty: 2.3120930194854736
Epoch 128, Batch 600/3125, Loss: 1.6909246444702148, Uncertainty: 1.737746238708496
Epoch 128, Batch 700/3125, Loss: 1.4088716506958008, Uncertainty: 1.6627027988433838
Epoch 128, Batch 800/3125, Loss: 1.3288700580596924, Uncertainty: 1.671905517578125
Epoch 128, Batch 900/3125, Loss: 1.4214107990264893, Uncertainty: 1.8120553493499756
Epoch 128, Batch 1000/3125, Loss: 1.4932913780212402, Uncertainty: 1.802969217300415
Epoch 128, Batch 1100/3125, Loss: 1.364528775215149, Uncertainty: 1.8438425064086914
Epoch 128, Batch 1200/3125, Loss: 1.738185167312622, Uncertainty: 1.774745225906372
Epoch 128, Batch 1300/3125, Loss: 1.3274351358413696, Uncertainty: 1.6071739196777344
Epoch 128, Batch 1400/3125, Loss: 1.4403269290924072, Uncertainty: 2.0429348945617676
Epoch 128, Batch 1500/3125, Loss: 2.001042366027832, Uncertainty: 1.745465874671936
Epoch 128, Batch 1600/3125, Loss: 1.485907793045044, Uncertainty: 2.2614996433258057
Epoch 128, Batch 1700/3125, Loss: 1.2838457822799683, Uncertainty: 1.4698708057403564
Epoch 128, Batch 1800/3125, Loss: 1.4883472919464111, Uncertainty: 2.114926815032959
Epoch 128, Batch 1900/3125, Loss: 1.4443316459655762, Uncertainty: 1.7113534212112427
Epoch 128, Batch 2000/3125, Loss: 1.2703983783721924, Uncertainty: 1.6092586517333984
Epoch 128, Batch 2100/3125, Loss: 1.398168683052063, Uncertainty: 1.5699772834777832
Epoch 128, Batch 2200/3125, Loss: 1.3467518091201782, Uncertainty: 1.593785047531128
Epoch 128, Batch 2300/3125, Loss: 1.5640313625335693, Uncertainty: 2.129598617553711
Epoch 128, Batch 2400/3125, Loss: 1.6290068626403809, Uncertainty: 2.7370543479919434
Epoch 128, Batch 2500/3125, Loss: 1.5542535781860352, Uncertainty: 2.0496530532836914
Epoch 128, Batch 2600/3125, Loss: 1.3794070482254028, Uncertainty: 2.023798942565918
Epoch 128, Batch 2700/3125, Loss: 1.7258903980255127, Uncertainty: 2.6703951358795166
Epoch 128, Batch 2800/3125, Loss: 1.8309811353683472, Uncertainty: 2.011765241622925
Epoch 128, Batch 2900/3125, Loss: 1.2130110263824463, Uncertainty: 1.5683716535568237
Epoch 128, Batch 3000/3125, Loss: 1.7098939418792725, Uncertainty: 2.2258477210998535
Epoch 128, Batch 3100/3125, Loss: 3.9263720512390137, Uncertainty: 6.061825752258301

Training and Validation Results of Epoch 128:
================================
Training Loss: 1.1539807634162902, Training Uncertainty: 2.035432657546997, time: 198.02348351478577
Validation Loss: 1.8979556414172472, Validation Uncertainty: 6.230410161225692, time: 45.78591847419739
Number of predictions within uncertainty interval: 164888/200000 (82.44%)

Epoch 129, Batch 100/3125, Loss: 1.7334537506103516, Uncertainty: 2.3571743965148926
Epoch 129, Batch 200/3125, Loss: 2.1452584266662598, Uncertainty: 2.327587366104126
Epoch 129, Batch 300/3125, Loss: 1.403792142868042, Uncertainty: 2.058593273162842
Epoch 129, Batch 400/3125, Loss: 1.4900119304656982, Uncertainty: 2.1917319297790527
Epoch 129, Batch 500/3125, Loss: 1.3850287199020386, Uncertainty: 1.8370615243911743
Epoch 129, Batch 600/3125, Loss: 1.3748846054077148, Uncertainty: 1.619268774986267
Epoch 129, Batch 700/3125, Loss: 1.2483465671539307, Uncertainty: 1.5620824098587036
Epoch 129, Batch 800/3125, Loss: 1.4780486822128296, Uncertainty: 2.1744353771209717
Epoch 129, Batch 900/3125, Loss: 1.5314536094665527, Uncertainty: 2.2430992126464844
Epoch 129, Batch 1000/3125, Loss: 1.415863037109375, Uncertainty: 1.5384724140167236
Epoch 129, Batch 1100/3125, Loss: 1.2905850410461426, Uncertainty: 1.6384608745574951
Epoch 129, Batch 1200/3125, Loss: 1.3170819282531738, Uncertainty: 1.5780010223388672
Epoch 129, Batch 1300/3125, Loss: 1.3255980014801025, Uncertainty: 1.7948870658874512
Epoch 129, Batch 1400/3125, Loss: 1.2729225158691406, Uncertainty: 1.6367173194885254
Epoch 129, Batch 1500/3125, Loss: 1.7668678760528564, Uncertainty: 2.6617398262023926
Epoch 129, Batch 1600/3125, Loss: 1.163596749305725, Uncertainty: 1.4786810874938965
Epoch 129, Batch 1700/3125, Loss: 1.5007201433181763, Uncertainty: 2.3763325214385986
Epoch 129, Batch 1800/3125, Loss: 1.3685994148254395, Uncertainty: 1.4263346195220947
Epoch 129, Batch 1900/3125, Loss: 2.0190091133117676, Uncertainty: 3.3392810821533203
Epoch 129, Batch 2000/3125, Loss: 1.2222604751586914, Uncertainty: 1.6453399658203125
Epoch 129, Batch 2100/3125, Loss: 1.4071635007858276, Uncertainty: 1.7246394157409668
Epoch 129, Batch 2200/3125, Loss: 1.1546761989593506, Uncertainty: 1.4944747686386108
Epoch 129, Batch 2300/3125, Loss: 1.5802760124206543, Uncertainty: 2.514721632003784
Epoch 129, Batch 2400/3125, Loss: 1.6924872398376465, Uncertainty: 2.2253987789154053
Epoch 129, Batch 2500/3125, Loss: 1.377288818359375, Uncertainty: 1.6751837730407715
Epoch 129, Batch 2600/3125, Loss: 1.5959885120391846, Uncertainty: 1.7516967058181763
Epoch 129, Batch 2700/3125, Loss: 1.3921029567718506, Uncertainty: 1.866089105606079
Epoch 129, Batch 2800/3125, Loss: 1.3224867582321167, Uncertainty: 1.6327775716781616
Epoch 129, Batch 2900/3125, Loss: 1.2003015279769897, Uncertainty: 1.443566918373108
Epoch 129, Batch 3000/3125, Loss: 1.9410202503204346, Uncertainty: 1.5755844116210938
Epoch 129, Batch 3100/3125, Loss: 1.3208211660385132, Uncertainty: 1.7534821033477783

Training and Validation Results of Epoch 129:
================================
Training Loss: 1.1125806088447572, Training Uncertainty: 1.9461535446929932, time: 196.36647534370422
Validation Loss: 0.857995547220835, Validation Uncertainty: 2.673767585278777, time: 44.94158172607422
Number of predictions within uncertainty interval: 144145/200000 (72.07%)

Epoch 130, Batch 100/3125, Loss: 1.2120733261108398, Uncertainty: 1.7332580089569092
Epoch 130, Batch 200/3125, Loss: 1.2045966386795044, Uncertainty: 1.6345280408859253
Epoch 130, Batch 300/3125, Loss: 1.2832456827163696, Uncertainty: 1.4954737424850464
Epoch 130, Batch 400/3125, Loss: 1.284195899963379, Uncertainty: 1.7809648513793945
Epoch 130, Batch 500/3125, Loss: 1.560049295425415, Uncertainty: 1.939112663269043
Epoch 130, Batch 600/3125, Loss: 1.527510404586792, Uncertainty: 2.2983627319335938
Epoch 130, Batch 700/3125, Loss: 1.3031611442565918, Uncertainty: 1.7044098377227783
Epoch 130, Batch 800/3125, Loss: 1.1913578510284424, Uncertainty: 1.6076856851577759
Epoch 130, Batch 900/3125, Loss: 1.2894843816757202, Uncertainty: 1.7265357971191406
Epoch 130, Batch 1000/3125, Loss: 1.6697537899017334, Uncertainty: 2.417940616607666
Epoch 130, Batch 1100/3125, Loss: 1.474759578704834, Uncertainty: 1.7010724544525146
Epoch 130, Batch 1200/3125, Loss: 1.546301245689392, Uncertainty: 2.2592971324920654
Epoch 130, Batch 1300/3125, Loss: 1.3370263576507568, Uncertainty: 2.0780177116394043
Epoch 130, Batch 1400/3125, Loss: 1.4200942516326904, Uncertainty: 1.7511801719665527
Epoch 130, Batch 1500/3125, Loss: 1.2093851566314697, Uncertainty: 1.567918300628662
Epoch 130, Batch 1600/3125, Loss: 1.3801008462905884, Uncertainty: 1.7284681797027588
Epoch 130, Batch 1700/3125, Loss: 1.4037847518920898, Uncertainty: 2.1146187782287598
Epoch 130, Batch 1800/3125, Loss: 1.5695414543151855, Uncertainty: 1.587868332862854
Epoch 130, Batch 1900/3125, Loss: 1.1997122764587402, Uncertainty: 1.5657033920288086
Epoch 130, Batch 2000/3125, Loss: 1.30537748336792, Uncertainty: 1.7569499015808105
Epoch 130, Batch 2100/3125, Loss: 1.2591679096221924, Uncertainty: 1.6314088106155396
Epoch 130, Batch 2200/3125, Loss: 1.5094339847564697, Uncertainty: 2.431673765182495
Epoch 130, Batch 2300/3125, Loss: 1.340494155883789, Uncertainty: 1.6840436458587646
Epoch 130, Batch 2400/3125, Loss: 1.8809473514556885, Uncertainty: 3.293757915496826
Epoch 130, Batch 2500/3125, Loss: 1.5548386573791504, Uncertainty: 2.221705913543701
Epoch 130, Batch 2600/3125, Loss: 1.631636381149292, Uncertainty: 2.4835681915283203
Epoch 130, Batch 2700/3125, Loss: 1.5234665870666504, Uncertainty: 2.3017027378082275
Epoch 130, Batch 2800/3125, Loss: 1.3393819332122803, Uncertainty: 1.630086898803711
Epoch 130, Batch 2900/3125, Loss: 1.3022823333740234, Uncertainty: 1.89199960231781
Epoch 130, Batch 3000/3125, Loss: 1.3864784240722656, Uncertainty: 1.8775575160980225
Epoch 130, Batch 3100/3125, Loss: 1.3621678352355957, Uncertainty: 2.010328769683838

Training and Validation Results of Epoch 130:
================================
Training Loss: 1.0685092985153197, Training Uncertainty: 1.8651067620849608, time: 196.8029260635376
Validation Loss: 0.8436472454034459, Validation Uncertainty: 2.6435967842331323, time: 45.663315296173096
Number of predictions within uncertainty interval: 143039/200000 (71.52%)

Epoch 131, Batch 100/3125, Loss: 1.4212875366210938, Uncertainty: 1.9601680040359497
Epoch 131, Batch 200/3125, Loss: 1.305530071258545, Uncertainty: 1.5428779125213623
Epoch 131, Batch 300/3125, Loss: 1.3839945793151855, Uncertainty: 1.9044389724731445
Epoch 131, Batch 400/3125, Loss: 1.2192420959472656, Uncertainty: 1.461071491241455
Epoch 131, Batch 500/3125, Loss: 1.4622259140014648, Uncertainty: 1.6855981349945068
Epoch 131, Batch 600/3125, Loss: 1.522993564605713, Uncertainty: 2.1491928100585938
Epoch 131, Batch 700/3125, Loss: 1.4756731986999512, Uncertainty: 1.462432861328125
Epoch 131, Batch 800/3125, Loss: 1.2543103694915771, Uncertainty: 1.7518255710601807
Epoch 131, Batch 900/3125, Loss: 1.7073602676391602, Uncertainty: 2.1314401626586914
Epoch 131, Batch 1000/3125, Loss: 1.2334184646606445, Uncertainty: 1.599825382232666
Epoch 131, Batch 1100/3125, Loss: 1.8477652072906494, Uncertainty: 2.7815332412719727
Epoch 131, Batch 1200/3125, Loss: 1.585973858833313, Uncertainty: 1.4995895624160767
Epoch 131, Batch 1300/3125, Loss: 1.2502717971801758, Uncertainty: 1.674340009689331
Epoch 131, Batch 1400/3125, Loss: 1.224586009979248, Uncertainty: 1.5457255840301514
Epoch 131, Batch 1500/3125, Loss: 1.2704761028289795, Uncertainty: 1.4146058559417725
Epoch 131, Batch 1600/3125, Loss: 1.336167812347412, Uncertainty: 1.7434818744659424
Epoch 131, Batch 1700/3125, Loss: 1.3488627672195435, Uncertainty: 1.7863969802856445
Epoch 131, Batch 1800/3125, Loss: 1.452000617980957, Uncertainty: 2.2379605770111084
Epoch 131, Batch 1900/3125, Loss: 1.6763721704483032, Uncertainty: 2.5979888439178467
Epoch 131, Batch 2000/3125, Loss: 1.3611255884170532, Uncertainty: 1.68951416015625
Epoch 131, Batch 2100/3125, Loss: 1.6083064079284668, Uncertainty: 2.228595733642578
Epoch 131, Batch 2200/3125, Loss: 1.2988805770874023, Uncertainty: 1.5376269817352295
Epoch 131, Batch 2300/3125, Loss: 1.2774027585983276, Uncertainty: 1.633523941040039
Epoch 131, Batch 2400/3125, Loss: 1.2959098815917969, Uncertainty: 1.74274742603302
Epoch 131, Batch 2500/3125, Loss: 1.8045750856399536, Uncertainty: 1.5484728813171387
Epoch 131, Batch 2600/3125, Loss: 1.4567885398864746, Uncertainty: 2.2442755699157715
Epoch 131, Batch 2700/3125, Loss: 1.4034433364868164, Uncertainty: 1.6875771284103394
Epoch 131, Batch 2800/3125, Loss: 1.3177516460418701, Uncertainty: 1.7561699151992798
Epoch 131, Batch 2900/3125, Loss: 1.3385764360427856, Uncertainty: 1.708709955215454
Epoch 131, Batch 3000/3125, Loss: 1.8223817348480225, Uncertainty: 2.7838754653930664
Epoch 131, Batch 3100/3125, Loss: 1.6173043251037598, Uncertainty: 2.19702410697937

Training and Validation Results of Epoch 131:
================================
Training Loss: 1.0827388225746155, Training Uncertainty: 1.8751012587738036, time: 202.21644115447998
Validation Loss: 0.918933575491771, Validation Uncertainty: 2.80145515779705, time: 48.08370113372803
Number of predictions within uncertainty interval: 141641/200000 (70.82%)

Epoch 132, Batch 100/3125, Loss: 1.3204562664031982, Uncertainty: 1.723371148109436
Epoch 132, Batch 200/3125, Loss: 1.2876381874084473, Uncertainty: 1.8849265575408936
Epoch 132, Batch 300/3125, Loss: 1.55410897731781, Uncertainty: 1.9155683517456055
Epoch 132, Batch 400/3125, Loss: 1.208510160446167, Uncertainty: 1.558334231376648
Epoch 132, Batch 500/3125, Loss: 1.3318781852722168, Uncertainty: 1.7377452850341797
Epoch 132, Batch 600/3125, Loss: 1.435730218887329, Uncertainty: 1.6282222270965576
Epoch 132, Batch 700/3125, Loss: 1.252471923828125, Uncertainty: 1.6522283554077148
Epoch 132, Batch 800/3125, Loss: 1.37000572681427, Uncertainty: 1.4034323692321777
Epoch 132, Batch 900/3125, Loss: 1.3305985927581787, Uncertainty: 1.8792797327041626
Epoch 132, Batch 1000/3125, Loss: 1.4095182418823242, Uncertainty: 1.6206517219543457
Epoch 132, Batch 1100/3125, Loss: 1.324509859085083, Uncertainty: 1.5245845317840576
Epoch 132, Batch 1200/3125, Loss: 1.662757396697998, Uncertainty: 1.409670352935791
Epoch 132, Batch 1300/3125, Loss: 1.4585515260696411, Uncertainty: 1.449832797050476
Epoch 132, Batch 1400/3125, Loss: 1.6213116645812988, Uncertainty: 1.7340805530548096
Epoch 132, Batch 1500/3125, Loss: 1.343174695968628, Uncertainty: 1.8210450410842896
Epoch 132, Batch 1600/3125, Loss: 1.3730236291885376, Uncertainty: 1.6763910055160522
Epoch 132, Batch 1700/3125, Loss: 1.4655821323394775, Uncertainty: 1.9049568176269531
Epoch 132, Batch 1800/3125, Loss: 1.7087628841400146, Uncertainty: 2.206757068634033
Epoch 132, Batch 1900/3125, Loss: 1.244713306427002, Uncertainty: 1.5270707607269287
Epoch 132, Batch 2000/3125, Loss: 1.3543356657028198, Uncertainty: 1.7837889194488525
Epoch 132, Batch 2100/3125, Loss: 1.3026028871536255, Uncertainty: 1.50382661819458
Epoch 132, Batch 2200/3125, Loss: 1.1302409172058105, Uncertainty: 1.3636925220489502
Epoch 132, Batch 2300/3125, Loss: 1.1906352043151855, Uncertainty: 1.4928929805755615
Epoch 132, Batch 2400/3125, Loss: 1.3504297733306885, Uncertainty: 1.7978897094726562
Epoch 132, Batch 2500/3125, Loss: 1.4114147424697876, Uncertainty: 2.152836322784424
Epoch 132, Batch 2600/3125, Loss: 1.2514302730560303, Uncertainty: 1.5944188833236694
Epoch 132, Batch 2700/3125, Loss: 1.6027566194534302, Uncertainty: 1.6342389583587646
Epoch 132, Batch 2800/3125, Loss: 1.3451017141342163, Uncertainty: 1.7829959392547607
Epoch 132, Batch 2900/3125, Loss: 1.3238084316253662, Uncertainty: 1.6719186305999756
Epoch 132, Batch 3000/3125, Loss: 1.285884141921997, Uncertainty: 1.6051647663116455
Epoch 132, Batch 3100/3125, Loss: 1.2930221557617188, Uncertainty: 1.6333441734313965

Training and Validation Results of Epoch 132:
================================
Training Loss: 1.075415999355316, Training Uncertainty: 1.8684356719207764, time: 197.73040771484375
Validation Loss: 0.8934934447183633, Validation Uncertainty: 2.6571965205395007, time: 52.284783363342285
Number of predictions within uncertainty interval: 139546/200000 (69.77%)

Epoch 133, Batch 100/3125, Loss: 1.3410634994506836, Uncertainty: 1.9592177867889404
Epoch 133, Batch 200/3125, Loss: 1.37760329246521, Uncertainty: 1.8599708080291748
Epoch 133, Batch 300/3125, Loss: 1.3386625051498413, Uncertainty: 1.6751620769500732
Epoch 133, Batch 400/3125, Loss: 1.3447390794754028, Uncertainty: 1.6016558408737183
Epoch 133, Batch 500/3125, Loss: 1.5498485565185547, Uncertainty: 2.1023647785186768
Epoch 133, Batch 600/3125, Loss: 1.489649772644043, Uncertainty: 1.9595973491668701
Epoch 133, Batch 700/3125, Loss: 1.364060401916504, Uncertainty: 1.7112526893615723
Epoch 133, Batch 800/3125, Loss: 1.304309606552124, Uncertainty: 1.8894362449645996
Epoch 133, Batch 900/3125, Loss: 1.933985710144043, Uncertainty: 2.234002113342285
Epoch 133, Batch 1000/3125, Loss: 1.1836469173431396, Uncertainty: 1.4745384454727173
Epoch 133, Batch 1100/3125, Loss: 1.6602247953414917, Uncertainty: 1.5084812641143799
Epoch 133, Batch 1200/3125, Loss: 1.424267053604126, Uncertainty: 1.9781969785690308
Epoch 133, Batch 1300/3125, Loss: 1.3136218786239624, Uncertainty: 1.5251219272613525
Epoch 133, Batch 1400/3125, Loss: 1.3944355249404907, Uncertainty: 1.7905817031860352
Epoch 133, Batch 1500/3125, Loss: 1.4281517267227173, Uncertainty: 2.1645455360412598
Epoch 133, Batch 1600/3125, Loss: 1.296682596206665, Uncertainty: 1.8007006645202637
Epoch 133, Batch 1700/3125, Loss: 1.386336088180542, Uncertainty: 1.8808801174163818
Epoch 133, Batch 1800/3125, Loss: 1.46494722366333, Uncertainty: 2.012911081314087
Epoch 133, Batch 1900/3125, Loss: 1.4688488245010376, Uncertainty: 1.822972297668457
Epoch 133, Batch 2000/3125, Loss: 1.2345609664916992, Uncertainty: 1.5220320224761963
Epoch 133, Batch 2100/3125, Loss: 1.3702392578125, Uncertainty: 1.7449772357940674
Epoch 133, Batch 2200/3125, Loss: 1.6182849407196045, Uncertainty: 1.9335711002349854
Epoch 133, Batch 2300/3125, Loss: 1.3389294147491455, Uncertainty: 1.4828994274139404
Epoch 133, Batch 2400/3125, Loss: 1.2548857927322388, Uncertainty: 1.7104425430297852
Epoch 133, Batch 2500/3125, Loss: 1.3927481174468994, Uncertainty: 2.0977625846862793
Epoch 133, Batch 2600/3125, Loss: 1.3057072162628174, Uncertainty: 1.747211217880249
Epoch 133, Batch 2700/3125, Loss: 1.4236572980880737, Uncertainty: 1.899994969367981
Epoch 133, Batch 2800/3125, Loss: 1.2601487636566162, Uncertainty: 1.5659974813461304
Epoch 133, Batch 2900/3125, Loss: 1.2470550537109375, Uncertainty: 1.537994146347046
Epoch 133, Batch 3000/3125, Loss: 1.2233424186706543, Uncertainty: 1.551429271697998
Epoch 133, Batch 3100/3125, Loss: 1.3688957691192627, Uncertainty: 1.977212905883789

Training and Validation Results of Epoch 133:
================================
Training Loss: 1.0673949176979065, Training Uncertainty: 1.8574333359527588, time: 197.2021415233612
Validation Loss: 0.9061327198582232, Validation Uncertainty: 3.142119634791713, time: 45.89480924606323
Number of predictions within uncertainty interval: 153526/200000 (76.76%)

Epoch 134, Batch 100/3125, Loss: 1.1200876235961914, Uncertainty: 1.507913589477539
Epoch 134, Batch 200/3125, Loss: 1.5503777265548706, Uncertainty: 2.4232192039489746
Epoch 134, Batch 300/3125, Loss: 1.46796452999115, Uncertainty: 1.9104689359664917
Epoch 134, Batch 400/3125, Loss: 1.4517474174499512, Uncertainty: 1.6647971868515015
Epoch 134, Batch 500/3125, Loss: 1.2712314128875732, Uncertainty: 1.5735642910003662
Epoch 134, Batch 600/3125, Loss: 1.3621442317962646, Uncertainty: 1.9051647186279297
Epoch 134, Batch 700/3125, Loss: 1.2827571630477905, Uncertainty: 1.7251276969909668
Epoch 134, Batch 800/3125, Loss: 1.4866948127746582, Uncertainty: 1.7740668058395386
Epoch 134, Batch 900/3125, Loss: 1.3861802816390991, Uncertainty: 1.8748581409454346
Epoch 134, Batch 1000/3125, Loss: 1.4876550436019897, Uncertainty: 1.7127878665924072
Epoch 134, Batch 1100/3125, Loss: 1.3376544713974, Uncertainty: 1.8327767848968506
Epoch 134, Batch 1200/3125, Loss: 1.5011091232299805, Uncertainty: 1.716630220413208
Epoch 134, Batch 1300/3125, Loss: 1.2507445812225342, Uncertainty: 1.4041736125946045
Epoch 134, Batch 1400/3125, Loss: 1.4121065139770508, Uncertainty: 2.066678047180176
Epoch 134, Batch 1500/3125, Loss: 1.32488214969635, Uncertainty: 1.856294870376587
Epoch 134, Batch 1600/3125, Loss: 1.4225044250488281, Uncertainty: 1.8398061990737915
Epoch 134, Batch 1700/3125, Loss: 1.2948949337005615, Uncertainty: 1.7104601860046387
Epoch 134, Batch 1800/3125, Loss: 1.5133635997772217, Uncertainty: 1.9204403162002563
Epoch 134, Batch 1900/3125, Loss: 1.4272072315216064, Uncertainty: 1.754754900932312
Epoch 134, Batch 2000/3125, Loss: 1.2281081676483154, Uncertainty: 1.6975462436676025
Epoch 134, Batch 2100/3125, Loss: 1.5819587707519531, Uncertainty: 2.4778451919555664
Epoch 134, Batch 2200/3125, Loss: 1.5111035108566284, Uncertainty: 2.2020890712738037
Epoch 134, Batch 2300/3125, Loss: 1.2894530296325684, Uncertainty: 1.7767279148101807
Epoch 134, Batch 2400/3125, Loss: 1.4822742938995361, Uncertainty: 2.117764711380005
Epoch 134, Batch 2500/3125, Loss: 1.239781379699707, Uncertainty: 1.8744158744812012
Epoch 134, Batch 2600/3125, Loss: 1.5811618566513062, Uncertainty: 2.1322665214538574
Epoch 134, Batch 2700/3125, Loss: 1.161163091659546, Uncertainty: 1.4560730457305908
Epoch 134, Batch 2800/3125, Loss: 1.338582992553711, Uncertainty: 1.602879285812378
Epoch 134, Batch 2900/3125, Loss: 1.8453031778335571, Uncertainty: 3.0101184844970703
Epoch 134, Batch 3000/3125, Loss: 1.5783566236495972, Uncertainty: 1.954010248184204
Epoch 134, Batch 3100/3125, Loss: 1.2336711883544922, Uncertainty: 1.7339917421340942

Training and Validation Results of Epoch 134:
================================
Training Loss: 1.0640923488807679, Training Uncertainty: 1.8540900520324708, time: 196.3388922214508
Validation Loss: 0.9984718817274284, Validation Uncertainty: 2.6549611832479685, time: 45.00378227233887
Number of predictions within uncertainty interval: 131897/200000 (65.95%)

Epoch 135, Batch 100/3125, Loss: 1.2188174724578857, Uncertainty: 1.7489267587661743
Epoch 135, Batch 200/3125, Loss: 1.4119192361831665, Uncertainty: 1.915849208831787
Epoch 135, Batch 300/3125, Loss: 1.3752638101577759, Uncertainty: 1.795562744140625
Epoch 135, Batch 400/3125, Loss: 1.20856773853302, Uncertainty: 1.8018840551376343
Epoch 135, Batch 500/3125, Loss: 1.443956732749939, Uncertainty: 2.023571252822876
Epoch 135, Batch 600/3125, Loss: 1.6066243648529053, Uncertainty: 2.285390853881836
Epoch 135, Batch 700/3125, Loss: 1.3105332851409912, Uncertainty: 2.00652813911438
Epoch 135, Batch 800/3125, Loss: 1.4830584526062012, Uncertainty: 2.0858089923858643
Epoch 135, Batch 900/3125, Loss: 1.4744110107421875, Uncertainty: 2.135786533355713
Epoch 135, Batch 1000/3125, Loss: 1.485397219657898, Uncertainty: 1.8808343410491943
Epoch 135, Batch 1100/3125, Loss: 1.467094898223877, Uncertainty: 1.8698571920394897
Epoch 135, Batch 1200/3125, Loss: 1.5302941799163818, Uncertainty: 2.1511945724487305
Epoch 135, Batch 1300/3125, Loss: 1.2397568225860596, Uncertainty: 1.7447932958602905
Epoch 135, Batch 1400/3125, Loss: 1.4991991519927979, Uncertainty: 1.806897521018982
Epoch 135, Batch 1500/3125, Loss: 1.6238257884979248, Uncertainty: 2.3068008422851562
Epoch 135, Batch 1600/3125, Loss: 1.4528801441192627, Uncertainty: 1.5049314498901367
Epoch 135, Batch 1700/3125, Loss: 1.2587023973464966, Uncertainty: 1.6479151248931885
Epoch 135, Batch 1800/3125, Loss: 1.5873651504516602, Uncertainty: 2.2277050018310547
Epoch 135, Batch 1900/3125, Loss: 1.3253387212753296, Uncertainty: 1.7616658210754395
Epoch 135, Batch 2000/3125, Loss: 1.3037760257720947, Uncertainty: 1.7999515533447266
Epoch 135, Batch 2100/3125, Loss: 1.4909324645996094, Uncertainty: 1.7634608745574951
Epoch 135, Batch 2200/3125, Loss: 1.1974477767944336, Uncertainty: 1.4465489387512207
Epoch 135, Batch 2300/3125, Loss: 1.3415498733520508, Uncertainty: 1.7674658298492432
Epoch 135, Batch 2400/3125, Loss: 1.4246944189071655, Uncertainty: 2.1453351974487305
Epoch 135, Batch 2500/3125, Loss: 1.1446740627288818, Uncertainty: 1.3463659286499023
Epoch 135, Batch 2600/3125, Loss: 1.8356479406356812, Uncertainty: 2.7604198455810547
Epoch 135, Batch 2700/3125, Loss: 1.3790514469146729, Uncertainty: 2.0056135654449463
Epoch 135, Batch 2800/3125, Loss: 1.5319615602493286, Uncertainty: 1.4762818813323975
Epoch 135, Batch 2900/3125, Loss: 1.442814588546753, Uncertainty: 2.170504331588745
Epoch 135, Batch 3000/3125, Loss: 1.5288841724395752, Uncertainty: 1.7481828927993774
Epoch 135, Batch 3100/3125, Loss: 1.3462693691253662, Uncertainty: 1.7282629013061523

Training and Validation Results of Epoch 135:
================================
Training Loss: 1.0646472367286681, Training Uncertainty: 1.854934447631836, time: 196.87320852279663
Validation Loss: 0.8704761526621211, Validation Uncertainty: 2.9034213474034654, time: 45.859649419784546
Number of predictions within uncertainty interval: 146012/200000 (73.01%)

Epoch 136, Batch 100/3125, Loss: 1.1077494621276855, Uncertainty: 1.5927913188934326
Epoch 136, Batch 200/3125, Loss: 1.3023850917816162, Uncertainty: 1.7838170528411865
Epoch 136, Batch 300/3125, Loss: 1.419593334197998, Uncertainty: 1.7023205757141113
Epoch 136, Batch 400/3125, Loss: 1.2910728454589844, Uncertainty: 1.4795199632644653
Epoch 136, Batch 500/3125, Loss: 1.2852026224136353, Uncertainty: 1.666110873222351
Epoch 136, Batch 600/3125, Loss: 1.4733175039291382, Uncertainty: 2.0836234092712402
Epoch 136, Batch 700/3125, Loss: 1.5116034746170044, Uncertainty: 2.265047550201416
Epoch 136, Batch 800/3125, Loss: 1.3904989957809448, Uncertainty: 1.8245186805725098
Epoch 136, Batch 900/3125, Loss: 1.620080590248108, Uncertainty: 2.5704870223999023
Epoch 136, Batch 1000/3125, Loss: 1.6348965167999268, Uncertainty: 1.8371946811676025
Epoch 136, Batch 1100/3125, Loss: 1.3147342205047607, Uncertainty: 1.6230956315994263
Epoch 136, Batch 1200/3125, Loss: 1.418170690536499, Uncertainty: 1.9692814350128174
Epoch 136, Batch 1300/3125, Loss: 1.362382411956787, Uncertainty: 1.4720816612243652
Epoch 136, Batch 1400/3125, Loss: 1.3150832653045654, Uncertainty: 1.7317579984664917
Epoch 136, Batch 1500/3125, Loss: 2.5974998474121094, Uncertainty: 3.404332160949707
Epoch 136, Batch 1600/3125, Loss: 1.879366397857666, Uncertainty: 2.617274761199951
Epoch 136, Batch 1700/3125, Loss: 1.428818702697754, Uncertainty: 2.165614128112793
Epoch 136, Batch 1800/3125, Loss: 1.5508977174758911, Uncertainty: 1.7781915664672852
Epoch 136, Batch 1900/3125, Loss: 1.491010308265686, Uncertainty: 2.006673812866211
Epoch 136, Batch 2000/3125, Loss: 2.014024257659912, Uncertainty: 1.7977354526519775
Epoch 136, Batch 2100/3125, Loss: 1.3616201877593994, Uncertainty: 1.771646499633789
Epoch 136, Batch 2200/3125, Loss: 1.2197389602661133, Uncertainty: 1.5895400047302246
Epoch 136, Batch 2300/3125, Loss: 1.2599811553955078, Uncertainty: 1.6906124353408813
Epoch 136, Batch 2400/3125, Loss: 1.185394525527954, Uncertainty: 1.4332306385040283
Epoch 136, Batch 2500/3125, Loss: 1.2764112949371338, Uncertainty: 1.7597603797912598
Epoch 136, Batch 2600/3125, Loss: 1.3779926300048828, Uncertainty: 1.759585976600647
Epoch 136, Batch 2700/3125, Loss: 1.3855071067810059, Uncertainty: 1.922415852546692
Epoch 136, Batch 2800/3125, Loss: 1.6493805646896362, Uncertainty: 2.114359140396118
Epoch 136, Batch 2900/3125, Loss: 1.2496919631958008, Uncertainty: 1.490989089012146
Epoch 136, Batch 3000/3125, Loss: 1.711470603942871, Uncertainty: 2.7044677734375
Epoch 136, Batch 3100/3125, Loss: 1.5440866947174072, Uncertainty: 2.004512310028076

Training and Validation Results of Epoch 136:
================================
Training Loss: 1.1981555955505372, Training Uncertainty: 2.118498507385254, time: 196.84194779396057
Validation Loss: 0.8392681530521958, Validation Uncertainty: 2.5308589447489784, time: 45.52009463310242
Number of predictions within uncertainty interval: 139439/200000 (69.72%)

Epoch 137, Batch 100/3125, Loss: 1.4995670318603516, Uncertainty: 1.7439615726470947
Epoch 137, Batch 200/3125, Loss: 1.3696081638336182, Uncertainty: 1.7275974750518799
Epoch 137, Batch 300/3125, Loss: 1.3821611404418945, Uncertainty: 1.748002529144287
Epoch 137, Batch 400/3125, Loss: 1.2478148937225342, Uncertainty: 1.7933021783828735
Epoch 137, Batch 500/3125, Loss: 1.8345975875854492, Uncertainty: 1.3947422504425049
Epoch 137, Batch 600/3125, Loss: 1.4782265424728394, Uncertainty: 2.036421298980713
Epoch 137, Batch 700/3125, Loss: 1.7814140319824219, Uncertainty: 2.4299211502075195
Epoch 137, Batch 800/3125, Loss: 1.3700637817382812, Uncertainty: 2.101698160171509
Epoch 137, Batch 900/3125, Loss: 1.4681906700134277, Uncertainty: 1.9466266632080078
Epoch 137, Batch 1000/3125, Loss: 1.4047706127166748, Uncertainty: 1.7782742977142334
Epoch 137, Batch 1100/3125, Loss: 1.7524086236953735, Uncertainty: 2.5163888931274414
Epoch 137, Batch 1200/3125, Loss: 1.4078078269958496, Uncertainty: 1.7955286502838135
Epoch 137, Batch 1300/3125, Loss: 1.303202748298645, Uncertainty: 1.777146339416504
Epoch 137, Batch 1400/3125, Loss: 1.414278507232666, Uncertainty: 1.3726274967193604
Epoch 137, Batch 1500/3125, Loss: 1.3596749305725098, Uncertainty: 1.8009403944015503
Epoch 137, Batch 1600/3125, Loss: 1.172145962715149, Uncertainty: 1.419463038444519
Epoch 137, Batch 1700/3125, Loss: 1.2243711948394775, Uncertainty: 1.587064504623413
Epoch 137, Batch 1800/3125, Loss: 1.8182179927825928, Uncertainty: 3.1078314781188965
Epoch 137, Batch 1900/3125, Loss: 1.5324015617370605, Uncertainty: 2.231144905090332
Epoch 137, Batch 2000/3125, Loss: 1.5373204946517944, Uncertainty: 2.091912269592285
Epoch 137, Batch 2100/3125, Loss: 1.3092639446258545, Uncertainty: 1.5798392295837402
Epoch 137, Batch 2200/3125, Loss: 1.1764247417449951, Uncertainty: 1.5040862560272217
Epoch 137, Batch 2300/3125, Loss: 1.3520481586456299, Uncertainty: 1.6548287868499756
Epoch 137, Batch 2400/3125, Loss: 1.451589584350586, Uncertainty: 2.254805088043213
Epoch 137, Batch 2500/3125, Loss: 1.3515253067016602, Uncertainty: 1.693462610244751
Epoch 137, Batch 2600/3125, Loss: 1.2802863121032715, Uncertainty: 1.7818461656570435
Epoch 137, Batch 2700/3125, Loss: 1.4501385688781738, Uncertainty: 1.794205665588379
Epoch 137, Batch 2800/3125, Loss: 1.2845346927642822, Uncertainty: 1.5121866464614868
Epoch 137, Batch 2900/3125, Loss: 1.6014885902404785, Uncertainty: 1.8647058010101318
Epoch 137, Batch 3000/3125, Loss: 1.4961249828338623, Uncertainty: 1.7237647771835327
Epoch 137, Batch 3100/3125, Loss: 1.5082571506500244, Uncertainty: 2.328348159790039

Training and Validation Results of Epoch 137:
================================
Training Loss: 1.0597817992401124, Training Uncertainty: 1.8659021437835694, time: 196.86809277534485
Validation Loss: 0.8063264647713098, Validation Uncertainty: 3.3073288406557437, time: 46.8453094959259
Number of predictions within uncertainty interval: 163569/200000 (81.78%)

Epoch 138, Batch 100/3125, Loss: 1.20952308177948, Uncertainty: 1.7463359832763672
Epoch 138, Batch 200/3125, Loss: 1.363910436630249, Uncertainty: 1.7041678428649902
Epoch 138, Batch 300/3125, Loss: 1.231597900390625, Uncertainty: 1.683591365814209
Epoch 138, Batch 400/3125, Loss: 1.1567548513412476, Uncertainty: 1.5599056482315063
Epoch 138, Batch 500/3125, Loss: 1.255814552307129, Uncertainty: 1.6628838777542114
Epoch 138, Batch 600/3125, Loss: 1.375594973564148, Uncertainty: 1.8456153869628906
Epoch 138, Batch 700/3125, Loss: 1.4018092155456543, Uncertainty: 1.6884057521820068
Epoch 138, Batch 800/3125, Loss: 1.4514217376708984, Uncertainty: 2.202059745788574
Epoch 138, Batch 900/3125, Loss: 1.7140839099884033, Uncertainty: 1.9849817752838135
Epoch 138, Batch 1000/3125, Loss: 1.409140944480896, Uncertainty: 1.7720348834991455
Epoch 138, Batch 1100/3125, Loss: 1.3951804637908936, Uncertainty: 1.7895655632019043
Epoch 138, Batch 1200/3125, Loss: 1.2653276920318604, Uncertainty: 1.488166093826294
Epoch 138, Batch 1300/3125, Loss: 1.1978288888931274, Uncertainty: 1.559671401977539
Epoch 138, Batch 1400/3125, Loss: 1.3172178268432617, Uncertainty: 1.5981192588806152
Epoch 138, Batch 1500/3125, Loss: 1.3506109714508057, Uncertainty: 1.6401731967926025
Epoch 138, Batch 1600/3125, Loss: 1.265254020690918, Uncertainty: 1.5135570764541626
Epoch 138, Batch 1700/3125, Loss: 1.25767183303833, Uncertainty: 1.4844584465026855
Epoch 138, Batch 1800/3125, Loss: 2.055208444595337, Uncertainty: 3.5334837436676025
Epoch 138, Batch 1900/3125, Loss: 1.4435052871704102, Uncertainty: 1.799971342086792
Epoch 138, Batch 2000/3125, Loss: 1.234981894493103, Uncertainty: 1.6535876989364624
Epoch 138, Batch 2100/3125, Loss: 1.3777501583099365, Uncertainty: 1.6049522161483765
Epoch 138, Batch 2200/3125, Loss: 1.2331987619400024, Uncertainty: 1.3716340065002441
Epoch 138, Batch 2300/3125, Loss: 1.2939136028289795, Uncertainty: 1.8777676820755005
Epoch 138, Batch 2400/3125, Loss: 1.5056006908416748, Uncertainty: 1.9549660682678223
Epoch 138, Batch 2500/3125, Loss: 1.1527385711669922, Uncertainty: 1.5431828498840332
Epoch 138, Batch 2600/3125, Loss: 1.587874412536621, Uncertainty: 1.707341194152832
Epoch 138, Batch 2700/3125, Loss: 1.2841159105300903, Uncertainty: 1.4989691972732544
Epoch 138, Batch 2800/3125, Loss: 1.7077744007110596, Uncertainty: 2.4842233657836914
Epoch 138, Batch 2900/3125, Loss: 1.5744657516479492, Uncertainty: 2.098374843597412
Epoch 138, Batch 3000/3125, Loss: 1.5916364192962646, Uncertainty: 2.1855947971343994
Epoch 138, Batch 3100/3125, Loss: 1.39681077003479, Uncertainty: 1.8063029050827026

Training and Validation Results of Epoch 138:
================================
Training Loss: 1.0623670725250245, Training Uncertainty: 1.8610850423431395, time: 196.79914379119873
Validation Loss: 0.8297931283636166, Validation Uncertainty: 2.668014816006126, time: 45.44460701942444
Number of predictions within uncertainty interval: 145125/200000 (72.56%)

Epoch 139, Batch 100/3125, Loss: 1.172248363494873, Uncertainty: 1.6791565418243408
Epoch 139, Batch 200/3125, Loss: 1.6564373970031738, Uncertainty: 1.9642536640167236
Epoch 139, Batch 300/3125, Loss: 1.171776294708252, Uncertainty: 1.6088935136795044
Epoch 139, Batch 400/3125, Loss: 1.2378517389297485, Uncertainty: 1.6929168701171875
Epoch 139, Batch 500/3125, Loss: 1.597550392150879, Uncertainty: 1.678966760635376
Epoch 139, Batch 600/3125, Loss: 1.3559746742248535, Uncertainty: 1.9718778133392334
Epoch 139, Batch 700/3125, Loss: 1.423283338546753, Uncertainty: 2.009796142578125
Epoch 139, Batch 800/3125, Loss: 1.2211453914642334, Uncertainty: 1.6590626239776611
Epoch 139, Batch 900/3125, Loss: 1.3393878936767578, Uncertainty: 1.890604019165039
Epoch 139, Batch 1000/3125, Loss: 1.368124008178711, Uncertainty: 1.7285470962524414
Epoch 139, Batch 1100/3125, Loss: 1.307760238647461, Uncertainty: 1.7067489624023438
Epoch 139, Batch 1200/3125, Loss: 1.2194552421569824, Uncertainty: 1.5293117761611938
Epoch 139, Batch 1300/3125, Loss: 1.1893792152404785, Uncertainty: 1.593049168586731
Epoch 139, Batch 1400/3125, Loss: 1.4480606317520142, Uncertainty: 2.0331244468688965
Epoch 139, Batch 1500/3125, Loss: 1.3497905731201172, Uncertainty: 1.6060621738433838
Epoch 139, Batch 1600/3125, Loss: 1.2657965421676636, Uncertainty: 1.686889410018921
Epoch 139, Batch 1700/3125, Loss: 1.4931743144989014, Uncertainty: 2.0984363555908203
Epoch 139, Batch 1800/3125, Loss: 1.629228115081787, Uncertainty: 1.784081220626831
Epoch 139, Batch 1900/3125, Loss: 1.2920750379562378, Uncertainty: 1.4284422397613525
Epoch 139, Batch 2000/3125, Loss: 1.1478281021118164, Uncertainty: 1.5558563470840454
Epoch 139, Batch 2100/3125, Loss: 1.3790562152862549, Uncertainty: 1.9219435453414917
Epoch 139, Batch 2200/3125, Loss: 1.4364105463027954, Uncertainty: 1.8041504621505737
Epoch 139, Batch 2300/3125, Loss: 1.3420255184173584, Uncertainty: 1.7323765754699707
Epoch 139, Batch 2400/3125, Loss: 1.293866515159607, Uncertainty: 1.660638689994812
Epoch 139, Batch 2500/3125, Loss: 1.5252305269241333, Uncertainty: 1.940581202507019
Epoch 139, Batch 2600/3125, Loss: 1.221968650817871, Uncertainty: 1.6655088663101196
Epoch 139, Batch 2700/3125, Loss: 1.3152422904968262, Uncertainty: 1.7288646697998047
Epoch 139, Batch 2800/3125, Loss: 1.2975313663482666, Uncertainty: 1.6345338821411133
Epoch 139, Batch 2900/3125, Loss: 1.498642921447754, Uncertainty: 1.5095946788787842
Epoch 139, Batch 3000/3125, Loss: 1.7025730609893799, Uncertainty: 2.7610647678375244
Epoch 139, Batch 3100/3125, Loss: 1.4214144945144653, Uncertainty: 1.5554953813552856

Training and Validation Results of Epoch 139:
================================
Training Loss: 1.0447508182907104, Training Uncertainty: 1.8337764303207398, time: 200.8914020061493
Validation Loss: 0.8604178042972789, Validation Uncertainty: 2.6376695812815596, time: 44.96324968338013
Number of predictions within uncertainty interval: 142221/200000 (71.11%)

Epoch 140, Batch 100/3125, Loss: 1.4377570152282715, Uncertainty: 1.9622595310211182
Epoch 140, Batch 200/3125, Loss: 1.3363752365112305, Uncertainty: 2.0359044075012207
Epoch 140, Batch 300/3125, Loss: 1.3944134712219238, Uncertainty: 2.0236141681671143
Epoch 140, Batch 400/3125, Loss: 1.2600643634796143, Uncertainty: 1.5805368423461914
Epoch 140, Batch 500/3125, Loss: 1.4359878301620483, Uncertainty: 1.8421980142593384
Epoch 140, Batch 600/3125, Loss: 1.5308834314346313, Uncertainty: 2.5004546642303467
Epoch 140, Batch 700/3125, Loss: 1.498976707458496, Uncertainty: 2.2637782096862793
Epoch 140, Batch 800/3125, Loss: 1.8747279644012451, Uncertainty: 2.0625436305999756
Epoch 140, Batch 900/3125, Loss: 1.301753282546997, Uncertainty: 1.6761386394500732
Epoch 140, Batch 1000/3125, Loss: 1.3203434944152832, Uncertainty: 1.73707115650177
Epoch 140, Batch 1100/3125, Loss: 1.2102328538894653, Uncertainty: 1.4301300048828125
Epoch 140, Batch 1200/3125, Loss: 1.1755931377410889, Uncertainty: 1.4543050527572632
Epoch 140, Batch 1300/3125, Loss: 1.2817039489746094, Uncertainty: 1.982377290725708
Epoch 140, Batch 1400/3125, Loss: 1.3796056509017944, Uncertainty: 1.6704524755477905
Epoch 140, Batch 1500/3125, Loss: 1.2412879467010498, Uncertainty: 1.8429920673370361
Epoch 140, Batch 1600/3125, Loss: 1.3425922393798828, Uncertainty: 1.8865928649902344
Epoch 140, Batch 1700/3125, Loss: 1.3208684921264648, Uncertainty: 1.7720094919204712
Epoch 140, Batch 1800/3125, Loss: 1.66864013671875, Uncertainty: 1.833404541015625
Epoch 140, Batch 1900/3125, Loss: 1.3412116765975952, Uncertainty: 1.779423475265503
Epoch 140, Batch 2000/3125, Loss: 1.5571856498718262, Uncertainty: 2.237921714782715
Epoch 140, Batch 2100/3125, Loss: 1.4982490539550781, Uncertainty: 1.8951659202575684
Epoch 140, Batch 2200/3125, Loss: 1.1935126781463623, Uncertainty: 1.5399597883224487
Epoch 140, Batch 2300/3125, Loss: 1.4688074588775635, Uncertainty: 1.829906940460205
Epoch 140, Batch 2400/3125, Loss: 1.5728023052215576, Uncertainty: 2.288374423980713
Epoch 140, Batch 2500/3125, Loss: 1.1852617263793945, Uncertainty: 1.6225841045379639
Epoch 140, Batch 2600/3125, Loss: 1.2536280155181885, Uncertainty: 1.7781085968017578
Epoch 140, Batch 2700/3125, Loss: 1.531429409980774, Uncertainty: 2.443605899810791
Epoch 140, Batch 2800/3125, Loss: 1.3128280639648438, Uncertainty: 1.5735951662063599
Epoch 140, Batch 2900/3125, Loss: 1.7301759719848633, Uncertainty: 2.123656749725342
Epoch 140, Batch 3000/3125, Loss: 1.3200602531433105, Uncertainty: 1.6879910230636597
Epoch 140, Batch 3100/3125, Loss: 1.2677944898605347, Uncertainty: 1.7368593215942383

Training and Validation Results of Epoch 140:
================================
Training Loss: 1.0383048461914062, Training Uncertainty: 1.8303909030151366, time: 196.61396265029907
Validation Loss: 0.9274647254163347, Validation Uncertainty: 3.6924047561557702, time: 45.669612884521484
Number of predictions within uncertainty interval: 162355/200000 (81.18%)

Epoch 141, Batch 100/3125, Loss: 1.2880960702896118, Uncertainty: 1.720426321029663
Epoch 141, Batch 200/3125, Loss: 1.476947546005249, Uncertainty: 2.1339545249938965
Epoch 141, Batch 300/3125, Loss: 1.203279972076416, Uncertainty: 1.6371939182281494
Epoch 141, Batch 400/3125, Loss: 1.2591677904129028, Uncertainty: 1.788259744644165
Epoch 141, Batch 500/3125, Loss: 1.405116081237793, Uncertainty: 1.5512789487838745
Epoch 141, Batch 600/3125, Loss: 1.4573030471801758, Uncertainty: 1.635493278503418
Epoch 141, Batch 700/3125, Loss: 1.2206801176071167, Uncertainty: 1.5415019989013672
Epoch 141, Batch 800/3125, Loss: 1.2814987897872925, Uncertainty: 1.8293408155441284
Epoch 141, Batch 900/3125, Loss: 1.3442111015319824, Uncertainty: 1.8730478286743164
Epoch 141, Batch 1000/3125, Loss: 1.5867412090301514, Uncertainty: 2.0215892791748047
Epoch 141, Batch 1100/3125, Loss: 1.3581223487854004, Uncertainty: 1.9590779542922974
Epoch 141, Batch 1200/3125, Loss: 1.2593988180160522, Uncertainty: 1.6934794187545776
Epoch 141, Batch 1300/3125, Loss: 1.2481329441070557, Uncertainty: 1.5582647323608398
Epoch 141, Batch 1400/3125, Loss: 1.3534740209579468, Uncertainty: 1.9686715602874756
Epoch 141, Batch 1500/3125, Loss: 1.4777016639709473, Uncertainty: 2.3932647705078125
Epoch 141, Batch 1600/3125, Loss: 1.418691635131836, Uncertainty: 2.1296472549438477
Epoch 141, Batch 1700/3125, Loss: 1.1464024782180786, Uncertainty: 1.5497806072235107
Epoch 141, Batch 1800/3125, Loss: 1.4881434440612793, Uncertainty: 2.0647835731506348
Epoch 141, Batch 1900/3125, Loss: 1.6447608470916748, Uncertainty: 1.8277554512023926
Epoch 141, Batch 2000/3125, Loss: 1.6660308837890625, Uncertainty: 2.9008500576019287
Epoch 141, Batch 2100/3125, Loss: 1.3799726963043213, Uncertainty: 1.7200170755386353
Epoch 141, Batch 2200/3125, Loss: 1.3102749586105347, Uncertainty: 1.7434325218200684
Epoch 141, Batch 2300/3125, Loss: 1.353737235069275, Uncertainty: 1.7121989727020264
Epoch 141, Batch 2400/3125, Loss: 1.2333662509918213, Uncertainty: 1.6250720024108887
Epoch 141, Batch 2500/3125, Loss: 1.382989525794983, Uncertainty: 1.9451426267623901
Epoch 141, Batch 2600/3125, Loss: 1.5207046270370483, Uncertainty: 1.7600703239440918
Epoch 141, Batch 2700/3125, Loss: 1.2064845561981201, Uncertainty: 1.6641523838043213
Epoch 141, Batch 2800/3125, Loss: 1.294925570487976, Uncertainty: 1.5973224639892578
Epoch 141, Batch 2900/3125, Loss: 1.3634514808654785, Uncertainty: 1.8735965490341187
Epoch 141, Batch 3000/3125, Loss: 1.4245960712432861, Uncertainty: 1.5810999870300293
Epoch 141, Batch 3100/3125, Loss: 1.6119225025177002, Uncertainty: 2.7242190837860107

Training and Validation Results of Epoch 141:
================================
Training Loss: 1.0318145283699036, Training Uncertainty: 1.8239661726379395, time: 197.7002010345459
Validation Loss: 0.8622385566039463, Validation Uncertainty: 2.4647961089678128, time: 45.39287328720093
Number of predictions within uncertainty interval: 137279/200000 (68.64%)

Epoch 142, Batch 100/3125, Loss: 1.2718749046325684, Uncertainty: 1.8399226665496826
Epoch 142, Batch 200/3125, Loss: 1.2957799434661865, Uncertainty: 1.9798239469528198
Epoch 142, Batch 300/3125, Loss: 1.2904484272003174, Uncertainty: 1.5725888013839722
Epoch 142, Batch 400/3125, Loss: 1.2833737134933472, Uncertainty: 1.8101203441619873
Epoch 142, Batch 500/3125, Loss: 1.8693158626556396, Uncertainty: 3.264697551727295
Epoch 142, Batch 600/3125, Loss: 1.6799405813217163, Uncertainty: 2.118302822113037
Epoch 142, Batch 700/3125, Loss: 1.3270454406738281, Uncertainty: 1.500892162322998
Epoch 142, Batch 800/3125, Loss: 1.3647518157958984, Uncertainty: 1.9272863864898682
Epoch 142, Batch 900/3125, Loss: 1.6427743434906006, Uncertainty: 1.5850361585617065
Epoch 142, Batch 1000/3125, Loss: 1.3322081565856934, Uncertainty: 1.7334874868392944
Epoch 142, Batch 1100/3125, Loss: 1.35938560962677, Uncertainty: 1.8635624647140503
Epoch 142, Batch 1200/3125, Loss: 1.3052409887313843, Uncertainty: 1.2903060913085938
Epoch 142, Batch 1300/3125, Loss: 1.1706640720367432, Uncertainty: 1.603853464126587
Epoch 142, Batch 1400/3125, Loss: 1.3081077337265015, Uncertainty: 1.6443524360656738
Epoch 142, Batch 1500/3125, Loss: 1.3350622653961182, Uncertainty: 1.8077553510665894
Epoch 142, Batch 1600/3125, Loss: 1.0993127822875977, Uncertainty: 1.4851744174957275
Epoch 142, Batch 1700/3125, Loss: 1.381954312324524, Uncertainty: 1.7992489337921143
Epoch 142, Batch 1800/3125, Loss: 1.4346493482589722, Uncertainty: 1.8110382556915283
Epoch 142, Batch 1900/3125, Loss: 1.2311232089996338, Uncertainty: 1.5764731168746948
Epoch 142, Batch 2000/3125, Loss: 1.3342530727386475, Uncertainty: 1.946183204650879
Epoch 142, Batch 2100/3125, Loss: 1.7644752264022827, Uncertainty: 2.7894697189331055
Epoch 142, Batch 2200/3125, Loss: 1.2505388259887695, Uncertainty: 1.599379539489746
Epoch 142, Batch 2300/3125, Loss: 1.8818185329437256, Uncertainty: 1.8654118776321411
Epoch 142, Batch 2400/3125, Loss: 1.1912591457366943, Uncertainty: 1.5367815494537354
Epoch 142, Batch 2500/3125, Loss: 1.2204885482788086, Uncertainty: 1.492796778678894
Epoch 142, Batch 2600/3125, Loss: 1.7000478506088257, Uncertainty: 2.6950743198394775
Epoch 142, Batch 2700/3125, Loss: 1.4031436443328857, Uncertainty: 1.7544995546340942
Epoch 142, Batch 2800/3125, Loss: 1.402375340461731, Uncertainty: 1.3759286403656006
Epoch 142, Batch 2900/3125, Loss: 1.6192399263381958, Uncertainty: 2.4412026405334473
Epoch 142, Batch 3000/3125, Loss: 1.3726741075515747, Uncertainty: 1.752117395401001
Epoch 142, Batch 3100/3125, Loss: 1.5052218437194824, Uncertainty: 1.8735682964324951

Training and Validation Results of Epoch 142:
================================
Training Loss: 1.0300826181983949, Training Uncertainty: 1.8333588656997681, time: 196.7425458431244
Validation Loss: 0.8573037994182323, Validation Uncertainty: 2.9183134794844996, time: 46.05729365348816
Number of predictions within uncertainty interval: 149527/200000 (74.76%)

Epoch 143, Batch 100/3125, Loss: 1.191499948501587, Uncertainty: 1.7669425010681152
Epoch 143, Batch 200/3125, Loss: 1.3437944650650024, Uncertainty: 2.0734007358551025
Epoch 143, Batch 300/3125, Loss: 1.5344786643981934, Uncertainty: 2.1683359146118164
Epoch 143, Batch 400/3125, Loss: 1.2173386812210083, Uncertainty: 1.8819434642791748
Epoch 143, Batch 500/3125, Loss: 1.2841949462890625, Uncertainty: 1.9215483665466309
Epoch 143, Batch 600/3125, Loss: 1.5996853113174438, Uncertainty: 2.2102200984954834
Epoch 143, Batch 700/3125, Loss: 1.3375437259674072, Uncertainty: 1.9260778427124023
Epoch 143, Batch 800/3125, Loss: 1.227518081665039, Uncertainty: 1.5306710004806519
Epoch 143, Batch 900/3125, Loss: 1.3633930683135986, Uncertainty: 1.6167348623275757
Epoch 143, Batch 1000/3125, Loss: 1.215343713760376, Uncertainty: 1.4677348136901855
Epoch 143, Batch 1100/3125, Loss: 1.231885313987732, Uncertainty: 1.5931237936019897
Epoch 143, Batch 1200/3125, Loss: 1.2737969160079956, Uncertainty: 1.5977946519851685
Epoch 143, Batch 1300/3125, Loss: 1.1373575925827026, Uncertainty: 1.442939281463623
Epoch 143, Batch 1400/3125, Loss: 1.1254963874816895, Uncertainty: 1.449198842048645
Epoch 143, Batch 1500/3125, Loss: 1.1951744556427002, Uncertainty: 1.513262152671814
Epoch 143, Batch 1600/3125, Loss: 1.3621776103973389, Uncertainty: 1.336299180984497
Epoch 143, Batch 1700/3125, Loss: 1.1538431644439697, Uncertainty: 1.5409767627716064
Epoch 143, Batch 1800/3125, Loss: 1.5058317184448242, Uncertainty: 1.6272928714752197
Epoch 143, Batch 1900/3125, Loss: 1.122459053993225, Uncertainty: 1.4501445293426514
Epoch 143, Batch 2000/3125, Loss: 1.4814841747283936, Uncertainty: 2.1528682708740234
Epoch 143, Batch 2100/3125, Loss: 1.509758710861206, Uncertainty: 1.835658073425293
Epoch 143, Batch 2200/3125, Loss: 1.387496829032898, Uncertainty: 1.7688734531402588
Epoch 143, Batch 2300/3125, Loss: 1.9057564735412598, Uncertainty: 2.736800193786621
Epoch 143, Batch 2400/3125, Loss: 1.4626655578613281, Uncertainty: 2.151599884033203
Epoch 143, Batch 2500/3125, Loss: 1.3318427801132202, Uncertainty: 1.4914796352386475
Epoch 143, Batch 2600/3125, Loss: 1.4448418617248535, Uncertainty: 1.6377816200256348
Epoch 143, Batch 2700/3125, Loss: 1.2792816162109375, Uncertainty: 1.5851794481277466
Epoch 143, Batch 2800/3125, Loss: 1.297059178352356, Uncertainty: 1.3755383491516113
Epoch 143, Batch 2900/3125, Loss: 1.5651576519012451, Uncertainty: 1.8468760251998901
Epoch 143, Batch 3000/3125, Loss: 1.2548657655715942, Uncertainty: 1.386500358581543
Epoch 143, Batch 3100/3125, Loss: 1.6751388311386108, Uncertainty: 1.6538095474243164

Training and Validation Results of Epoch 143:
================================
Training Loss: 1.029125636768341, Training Uncertainty: 1.8333276482009888, time: 199.74873852729797
Validation Loss: 0.9837609548550432, Validation Uncertainty: 2.499313738035119, time: 46.33176326751709
Number of predictions within uncertainty interval: 127667/200000 (63.83%)

Epoch 144, Batch 100/3125, Loss: 1.2336452007293701, Uncertainty: 1.8305399417877197
Epoch 144, Batch 200/3125, Loss: 1.2403138875961304, Uncertainty: 1.5889140367507935
Epoch 144, Batch 300/3125, Loss: 1.238572120666504, Uncertainty: 1.5509610176086426
Epoch 144, Batch 400/3125, Loss: 1.159785270690918, Uncertainty: 1.5894896984100342
Epoch 144, Batch 500/3125, Loss: 1.5910950899124146, Uncertainty: 2.2605204582214355
Epoch 144, Batch 600/3125, Loss: 1.3911446332931519, Uncertainty: 1.810084342956543
Epoch 144, Batch 700/3125, Loss: 1.2088897228240967, Uncertainty: 1.4947831630706787
Epoch 144, Batch 800/3125, Loss: 1.1909027099609375, Uncertainty: 1.7706660032272339
Epoch 144, Batch 900/3125, Loss: 1.3001735210418701, Uncertainty: 1.9000540971755981
Epoch 144, Batch 1000/3125, Loss: 1.3801072835922241, Uncertainty: 1.7440919876098633
Epoch 144, Batch 1100/3125, Loss: 1.2429685592651367, Uncertainty: 1.6023199558258057
Epoch 144, Batch 1200/3125, Loss: 1.2583332061767578, Uncertainty: 1.4459947347640991
Epoch 144, Batch 1300/3125, Loss: 1.4030033349990845, Uncertainty: 1.6906818151474
Epoch 144, Batch 1400/3125, Loss: 1.6204123497009277, Uncertainty: 2.6510393619537354
Epoch 144, Batch 1500/3125, Loss: 1.2570399045944214, Uncertainty: 1.6564747095108032
Epoch 144, Batch 1600/3125, Loss: 1.7049715518951416, Uncertainty: 1.9180521965026855
Epoch 144, Batch 1700/3125, Loss: 1.2656798362731934, Uncertainty: 1.5154274702072144
Epoch 144, Batch 1800/3125, Loss: 1.4674556255340576, Uncertainty: 2.0933709144592285
Epoch 144, Batch 1900/3125, Loss: 1.3819040060043335, Uncertainty: 1.9761760234832764
Epoch 144, Batch 2000/3125, Loss: 1.6010587215423584, Uncertainty: 2.2276222705841064
Epoch 144, Batch 2100/3125, Loss: 1.424257755279541, Uncertainty: 2.040365219116211
Epoch 144, Batch 2200/3125, Loss: 1.3205180168151855, Uncertainty: 1.7924458980560303
Epoch 144, Batch 2300/3125, Loss: 1.3205442428588867, Uncertainty: 1.6797538995742798
Epoch 144, Batch 2400/3125, Loss: 1.2895092964172363, Uncertainty: 1.5818760395050049
Epoch 144, Batch 2500/3125, Loss: 1.2443280220031738, Uncertainty: 1.8806536197662354
Epoch 144, Batch 2600/3125, Loss: 1.3258557319641113, Uncertainty: 1.8820526599884033
Epoch 144, Batch 2700/3125, Loss: 1.2637771368026733, Uncertainty: 1.5878748893737793
Epoch 144, Batch 2800/3125, Loss: 1.1984853744506836, Uncertainty: 1.5333434343338013
Epoch 144, Batch 2900/3125, Loss: 1.51155424118042, Uncertainty: 2.275728702545166
Epoch 144, Batch 3000/3125, Loss: 1.5882439613342285, Uncertainty: 1.9397598505020142
Epoch 144, Batch 3100/3125, Loss: 1.1525914669036865, Uncertainty: 1.5454678535461426

Training and Validation Results of Epoch 144:
================================
Training Loss: 1.0240892243385316, Training Uncertainty: 1.8215081127929686, time: 200.37658715248108
Validation Loss: 0.7861727030990678, Validation Uncertainty: 2.845851639652496, time: 45.73910474777222
Number of predictions within uncertainty interval: 155130/200000 (77.56%)

Epoch 145, Batch 100/3125, Loss: 1.1696292161941528, Uncertainty: 1.6727933883666992
Epoch 145, Batch 200/3125, Loss: 1.4949049949645996, Uncertainty: 2.3967628479003906
Epoch 145, Batch 300/3125, Loss: 1.3042829036712646, Uncertainty: 1.6522916555404663
Epoch 145, Batch 400/3125, Loss: 1.3962693214416504, Uncertainty: 1.9839468002319336
Epoch 145, Batch 500/3125, Loss: 1.4007115364074707, Uncertainty: 1.912688970565796
Epoch 145, Batch 600/3125, Loss: 1.4527876377105713, Uncertainty: 1.8150813579559326
Epoch 145, Batch 700/3125, Loss: 1.1784648895263672, Uncertainty: 1.627474069595337
Epoch 145, Batch 800/3125, Loss: 1.5334510803222656, Uncertainty: 1.9843418598175049
Epoch 145, Batch 900/3125, Loss: 1.2946193218231201, Uncertainty: 1.9572075605392456
Epoch 145, Batch 1000/3125, Loss: 1.2695798873901367, Uncertainty: 1.656959056854248
Epoch 145, Batch 1100/3125, Loss: 1.287399172782898, Uncertainty: 1.589015245437622
Epoch 145, Batch 1200/3125, Loss: 1.6101114749908447, Uncertainty: 2.499606132507324
Epoch 145, Batch 1300/3125, Loss: 1.1605827808380127, Uncertainty: 1.455324649810791
Epoch 145, Batch 1400/3125, Loss: 1.3283954858779907, Uncertainty: 1.5058479309082031
Epoch 145, Batch 1500/3125, Loss: 1.270861029624939, Uncertainty: 1.709767460823059
Epoch 145, Batch 1600/3125, Loss: 1.1759581565856934, Uncertainty: 1.5251922607421875
Epoch 145, Batch 1700/3125, Loss: 1.158581018447876, Uncertainty: 1.5839643478393555
Epoch 145, Batch 1800/3125, Loss: 1.6328129768371582, Uncertainty: 1.8321340084075928
Epoch 145, Batch 1900/3125, Loss: 1.4747788906097412, Uncertainty: 1.852698564529419
Epoch 145, Batch 2000/3125, Loss: 1.2336068153381348, Uncertainty: 1.9003164768218994
Epoch 145, Batch 2100/3125, Loss: 1.506140112876892, Uncertainty: 2.331822633743286
Epoch 145, Batch 2200/3125, Loss: 1.4532437324523926, Uncertainty: 1.6923526525497437
Epoch 145, Batch 2300/3125, Loss: 1.3789174556732178, Uncertainty: 2.045124053955078
Epoch 145, Batch 2400/3125, Loss: 1.2735929489135742, Uncertainty: 1.7579535245895386
Epoch 145, Batch 2500/3125, Loss: 1.3852399587631226, Uncertainty: 2.0697333812713623
Epoch 145, Batch 2600/3125, Loss: 1.2582857608795166, Uncertainty: 1.765005111694336
Epoch 145, Batch 2700/3125, Loss: 1.5487263202667236, Uncertainty: 2.3291079998016357
Epoch 145, Batch 2800/3125, Loss: 1.4782326221466064, Uncertainty: 1.5996003150939941
Epoch 145, Batch 2900/3125, Loss: 1.1677712202072144, Uncertainty: 1.4018325805664062
Epoch 145, Batch 3000/3125, Loss: 1.586449384689331, Uncertainty: 1.6139758825302124
Epoch 145, Batch 3100/3125, Loss: 1.3170650005340576, Uncertainty: 1.7964907884597778

Training and Validation Results of Epoch 145:
================================
Training Loss: 1.0249385222625733, Training Uncertainty: 1.793309140701294, time: 199.08128452301025
Validation Loss: 0.8256599747616312, Validation Uncertainty: 2.315058971609911, time: 45.98195266723633
Number of predictions within uncertainty interval: 135317/200000 (67.66%)

Epoch 146, Batch 100/3125, Loss: 1.4676384925842285, Uncertainty: 2.501333236694336
Epoch 146, Batch 200/3125, Loss: 1.3699345588684082, Uncertainty: 1.801897644996643
Epoch 146, Batch 300/3125, Loss: 1.1689069271087646, Uncertainty: 1.5427525043487549
Epoch 146, Batch 400/3125, Loss: 1.243705153465271, Uncertainty: 1.7637813091278076
Epoch 146, Batch 500/3125, Loss: 1.5356961488723755, Uncertainty: 1.996009349822998
Epoch 146, Batch 600/3125, Loss: 1.4506478309631348, Uncertainty: 1.7759144306182861
Epoch 146, Batch 700/3125, Loss: 1.1786346435546875, Uncertainty: 1.567232608795166
Epoch 146, Batch 800/3125, Loss: 1.3626174926757812, Uncertainty: 1.7003984451293945
Epoch 146, Batch 900/3125, Loss: 1.2970478534698486, Uncertainty: 1.614502191543579
Epoch 146, Batch 1000/3125, Loss: 1.2277722358703613, Uncertainty: 1.680938720703125
Epoch 146, Batch 1100/3125, Loss: 1.3357993364334106, Uncertainty: 1.5264461040496826
Epoch 146, Batch 1200/3125, Loss: 1.4714219570159912, Uncertainty: 2.396998882293701
Epoch 146, Batch 1300/3125, Loss: 1.3451398611068726, Uncertainty: 1.8638972043991089
Epoch 146, Batch 1400/3125, Loss: 1.2359082698822021, Uncertainty: 1.6084306240081787
Epoch 146, Batch 1500/3125, Loss: 1.2036197185516357, Uncertainty: 1.4976840019226074
Epoch 146, Batch 1600/3125, Loss: 1.3283759355545044, Uncertainty: 1.7516837120056152
Epoch 146, Batch 1700/3125, Loss: 1.3783283233642578, Uncertainty: 2.0198512077331543
Epoch 146, Batch 1800/3125, Loss: 1.3869459629058838, Uncertainty: 1.6677048206329346
Epoch 146, Batch 1900/3125, Loss: 1.4039241075515747, Uncertainty: 1.5938115119934082
Epoch 146, Batch 2000/3125, Loss: 1.2080965042114258, Uncertainty: 1.6845142841339111
Epoch 146, Batch 2100/3125, Loss: 1.3331537246704102, Uncertainty: 1.726885199546814
Epoch 146, Batch 2200/3125, Loss: 1.1958117485046387, Uncertainty: 1.6512072086334229
Epoch 146, Batch 2300/3125, Loss: 1.5479917526245117, Uncertainty: 2.2207655906677246
Epoch 146, Batch 2400/3125, Loss: 1.2523877620697021, Uncertainty: 1.7313735485076904
Epoch 146, Batch 2500/3125, Loss: 1.645503044128418, Uncertainty: 2.742105722427368
Epoch 146, Batch 2600/3125, Loss: 1.333786964416504, Uncertainty: 1.9489896297454834
Epoch 146, Batch 2700/3125, Loss: 1.4736981391906738, Uncertainty: 1.9955551624298096
Epoch 146, Batch 2800/3125, Loss: 1.3483154773712158, Uncertainty: 1.5623250007629395
Epoch 146, Batch 2900/3125, Loss: 1.2571089267730713, Uncertainty: 1.3748583793640137
Epoch 146, Batch 3000/3125, Loss: 1.635658621788025, Uncertainty: 1.6916056871414185
Epoch 146, Batch 3100/3125, Loss: 1.341684341430664, Uncertainty: 1.5982820987701416

Training and Validation Results of Epoch 146:
================================
Training Loss: 1.0176423135375976, Training Uncertainty: 1.7952071731185912, time: 204.27259135246277
Validation Loss: 0.8345022100164458, Validation Uncertainty: 2.708384180617759, time: 46.35087704658508
Number of predictions within uncertainty interval: 145729/200000 (72.86%)

Epoch 147, Batch 100/3125, Loss: 1.2199313640594482, Uncertainty: 1.845908522605896
Epoch 147, Batch 200/3125, Loss: 1.3342761993408203, Uncertainty: 2.1096205711364746
Epoch 147, Batch 300/3125, Loss: 1.2616980075836182, Uncertainty: 1.372258186340332
Epoch 147, Batch 400/3125, Loss: 1.1979858875274658, Uncertainty: 1.5979669094085693
Epoch 147, Batch 500/3125, Loss: 1.193080186843872, Uncertainty: 1.5250179767608643
Epoch 147, Batch 600/3125, Loss: 1.5648188591003418, Uncertainty: 1.9760346412658691
Epoch 147, Batch 700/3125, Loss: 1.424454927444458, Uncertainty: 1.6367278099060059
Epoch 147, Batch 800/3125, Loss: 1.5123357772827148, Uncertainty: 1.560474157333374
Epoch 147, Batch 900/3125, Loss: 1.4756834506988525, Uncertainty: 2.0477406978607178
Epoch 147, Batch 1000/3125, Loss: 1.4032783508300781, Uncertainty: 1.565408706665039
Epoch 147, Batch 1100/3125, Loss: 1.431179404258728, Uncertainty: 1.651222825050354
Epoch 147, Batch 1200/3125, Loss: 1.2426557540893555, Uncertainty: 1.4232628345489502
Epoch 147, Batch 1300/3125, Loss: 1.1263549327850342, Uncertainty: 1.4938585758209229
Epoch 147, Batch 1400/3125, Loss: 1.3363707065582275, Uncertainty: 1.819071650505066
Epoch 147, Batch 1500/3125, Loss: 1.38204824924469, Uncertainty: 1.9564244747161865
Epoch 147, Batch 1600/3125, Loss: 1.0954337120056152, Uncertainty: 1.3248789310455322
Epoch 147, Batch 1700/3125, Loss: 1.0972099304199219, Uncertainty: 1.3338022232055664
Epoch 147, Batch 1800/3125, Loss: 1.3295776844024658, Uncertainty: 1.7598317861557007
Epoch 147, Batch 1900/3125, Loss: 1.2098628282546997, Uncertainty: 1.4493095874786377
Epoch 147, Batch 2000/3125, Loss: 1.3314712047576904, Uncertainty: 1.983790397644043
Epoch 147, Batch 2100/3125, Loss: 1.6009278297424316, Uncertainty: 2.456998109817505
Epoch 147, Batch 2200/3125, Loss: 1.2304670810699463, Uncertainty: 1.5777077674865723
Epoch 147, Batch 2300/3125, Loss: 1.2477881908416748, Uncertainty: 1.4576849937438965
Epoch 147, Batch 2400/3125, Loss: 1.3687949180603027, Uncertainty: 1.9637703895568848
Epoch 147, Batch 2500/3125, Loss: 1.2741599082946777, Uncertainty: 1.653308391571045
Epoch 147, Batch 2600/3125, Loss: 1.205398678779602, Uncertainty: 1.5615124702453613
Epoch 147, Batch 2700/3125, Loss: 1.299790620803833, Uncertainty: 1.85490083694458
Epoch 147, Batch 2800/3125, Loss: 1.29897940158844, Uncertainty: 1.623574137687683
Epoch 147, Batch 2900/3125, Loss: 1.346872091293335, Uncertainty: 1.8684602975845337
Epoch 147, Batch 3000/3125, Loss: 1.2526304721832275, Uncertainty: 1.5894513130187988
Epoch 147, Batch 3100/3125, Loss: 1.2603923082351685, Uncertainty: 1.7759909629821777

Training and Validation Results of Epoch 147:
================================
Training Loss: 1.0186517999839784, Training Uncertainty: 1.7865228085708618, time: 199.9697606563568
Validation Loss: 0.910352490899508, Validation Uncertainty: 2.525703216757616, time: 45.738120317459106
Number of predictions within uncertainty interval: 135571/200000 (67.79%)

Epoch 148, Batch 100/3125, Loss: 1.0834124088287354, Uncertainty: 1.4972541332244873
Epoch 148, Batch 200/3125, Loss: 1.2102537155151367, Uncertainty: 1.7047902345657349
Epoch 148, Batch 300/3125, Loss: 1.1208045482635498, Uncertainty: 1.3851747512817383
Epoch 148, Batch 400/3125, Loss: 1.2712382078170776, Uncertainty: 1.7125740051269531
Epoch 148, Batch 500/3125, Loss: 1.2365326881408691, Uncertainty: 1.7048066854476929
Epoch 148, Batch 600/3125, Loss: 1.3549580574035645, Uncertainty: 1.9586982727050781
Epoch 148, Batch 700/3125, Loss: 1.4853061437606812, Uncertainty: 2.288703441619873
Epoch 148, Batch 800/3125, Loss: 1.238369107246399, Uncertainty: 1.4625108242034912
Epoch 148, Batch 900/3125, Loss: 1.246285319328308, Uncertainty: 1.6684876680374146
Epoch 148, Batch 1000/3125, Loss: 1.5382931232452393, Uncertainty: 2.225889205932617
Epoch 148, Batch 1100/3125, Loss: 1.3126089572906494, Uncertainty: 1.685699701309204
Epoch 148, Batch 1200/3125, Loss: 1.7145329713821411, Uncertainty: 1.5021142959594727
Epoch 148, Batch 1300/3125, Loss: 1.3197896480560303, Uncertainty: 1.843357801437378
Epoch 148, Batch 1400/3125, Loss: 1.2998491525650024, Uncertainty: 1.6291718482971191
Epoch 148, Batch 1500/3125, Loss: 1.2670562267303467, Uncertainty: 1.961090326309204
Epoch 148, Batch 1600/3125, Loss: 1.5787487030029297, Uncertainty: 2.2239537239074707
Epoch 148, Batch 1700/3125, Loss: 1.4769039154052734, Uncertainty: 1.690337896347046
Epoch 148, Batch 1800/3125, Loss: 1.3606388568878174, Uncertainty: 1.6495639085769653
Epoch 148, Batch 1900/3125, Loss: 1.8929803371429443, Uncertainty: 2.5471818447113037
Epoch 148, Batch 2000/3125, Loss: 1.33888840675354, Uncertainty: 1.7321652173995972
Epoch 148, Batch 2100/3125, Loss: 1.7984263896942139, Uncertainty: 1.7608320713043213
Epoch 148, Batch 2200/3125, Loss: 1.0513893365859985, Uncertainty: 1.5637001991271973
Epoch 148, Batch 2300/3125, Loss: 1.4702332019805908, Uncertainty: 1.6578052043914795
Epoch 148, Batch 2400/3125, Loss: 1.4025564193725586, Uncertainty: 2.1112747192382812
Epoch 148, Batch 2500/3125, Loss: 1.1514239311218262, Uncertainty: 1.5113680362701416
Epoch 148, Batch 2600/3125, Loss: 1.2145535945892334, Uncertainty: 1.4665627479553223
Epoch 148, Batch 2700/3125, Loss: 1.402986764907837, Uncertainty: 2.0947201251983643
Epoch 148, Batch 2800/3125, Loss: 1.2172218561172485, Uncertainty: 1.556485652923584
Epoch 148, Batch 2900/3125, Loss: 1.533703327178955, Uncertainty: 2.480811357498169
Epoch 148, Batch 3000/3125, Loss: 1.2410120964050293, Uncertainty: 1.641174077987671
Epoch 148, Batch 3100/3125, Loss: 1.1776916980743408, Uncertainty: 1.6111866235733032

Training and Validation Results of Epoch 148:
================================
Training Loss: 1.0042932123184205, Training Uncertainty: 1.779292236366272, time: 196.99753856658936
Validation Loss: 0.8927637042901705, Validation Uncertainty: 3.019151739147313, time: 45.684871673583984
Number of predictions within uncertainty interval: 148336/200000 (74.17%)

Epoch 149, Batch 100/3125, Loss: 1.3734185695648193, Uncertainty: 2.2630739212036133
Epoch 149, Batch 200/3125, Loss: 1.0451533794403076, Uncertainty: 1.467759609222412
Epoch 149, Batch 300/3125, Loss: 1.212664246559143, Uncertainty: 1.653536319732666
Epoch 149, Batch 400/3125, Loss: 1.1941628456115723, Uncertainty: 1.474013090133667
Epoch 149, Batch 500/3125, Loss: 1.3059937953948975, Uncertainty: 1.7822589874267578
Epoch 149, Batch 600/3125, Loss: 1.3977333307266235, Uncertainty: 1.3968875408172607
Epoch 149, Batch 700/3125, Loss: 1.3269896507263184, Uncertainty: 1.6294019222259521
Epoch 149, Batch 800/3125, Loss: 1.2040220499038696, Uncertainty: 1.7617372274398804
Epoch 149, Batch 900/3125, Loss: 1.207270622253418, Uncertainty: 1.5648280382156372
Epoch 149, Batch 1000/3125, Loss: 1.4727345705032349, Uncertainty: 2.3950035572052
Epoch 149, Batch 1100/3125, Loss: 1.3383548259735107, Uncertainty: 1.964088797569275
Epoch 149, Batch 1200/3125, Loss: 1.4437001943588257, Uncertainty: 1.8474657535552979
Epoch 149, Batch 1300/3125, Loss: 1.1366784572601318, Uncertainty: 1.5180227756500244
Epoch 149, Batch 1400/3125, Loss: 1.1239615678787231, Uncertainty: 1.4761230945587158
Epoch 149, Batch 1500/3125, Loss: 1.3752647638320923, Uncertainty: 1.8406256437301636
Epoch 149, Batch 1600/3125, Loss: 1.3486112356185913, Uncertainty: 1.8130264282226562
Epoch 149, Batch 1700/3125, Loss: 1.2816743850708008, Uncertainty: 1.860476016998291
Epoch 149, Batch 1800/3125, Loss: 1.6333223581314087, Uncertainty: 1.824986457824707
Epoch 149, Batch 1900/3125, Loss: 1.335193395614624, Uncertainty: 1.8166313171386719
Epoch 149, Batch 2000/3125, Loss: 1.186361312866211, Uncertainty: 1.6590697765350342
Epoch 149, Batch 2100/3125, Loss: 1.295998215675354, Uncertainty: 1.440791368484497
Epoch 149, Batch 2200/3125, Loss: 1.1628873348236084, Uncertainty: 1.4161748886108398
Epoch 149, Batch 2300/3125, Loss: 1.2564630508422852, Uncertainty: 1.634699821472168
Epoch 149, Batch 2400/3125, Loss: 1.247697353363037, Uncertainty: 1.8410885334014893
Epoch 149, Batch 2500/3125, Loss: 1.0674904584884644, Uncertainty: 1.4352364540100098
Epoch 149, Batch 2600/3125, Loss: 1.4184749126434326, Uncertainty: 1.9571690559387207
Epoch 149, Batch 2700/3125, Loss: 1.193885326385498, Uncertainty: 1.3706761598587036
Epoch 149, Batch 2800/3125, Loss: 1.2623562812805176, Uncertainty: 1.7199832201004028
Epoch 149, Batch 2900/3125, Loss: 1.3198497295379639, Uncertainty: 1.4465677738189697
Epoch 149, Batch 3000/3125, Loss: 1.3760257959365845, Uncertainty: 1.869983434677124
Epoch 149, Batch 3100/3125, Loss: 1.225954532623291, Uncertainty: 1.5906952619552612

Training and Validation Results of Epoch 149:
================================
Training Loss: 1.018830781173706, Training Uncertainty: 1.782831043624878, time: 196.0888204574585
Validation Loss: 0.8031901333033277, Validation Uncertainty: 3.7317470970666013, time: 44.73924398422241
Number of predictions within uncertainty interval: 171416/200000 (85.71%)


============================= JOB FEEDBACK =============================

NodeName=uc2n508
Job ID: 23975788
Cluster: uc2
User/Group: fq0795/iti
State: COMPLETED (exit code 0)
Nodes: 1
Cores per node: 10
CPU Utilized: 10:07:07
CPU Efficiency: 10.00% of 4-05:12:20 core-walltime
Job Wall-clock time: 10:07:14
Memory Utilized: 8.88 GB
Memory Efficiency: 9.67% of 91.80 GB
