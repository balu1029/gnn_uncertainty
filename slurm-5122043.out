/home/ws/fq0795/git/gnn_uncertainty/active_learning.py:173: DeprecationWarning: Please use atoms.calc = calc
  self.atoms.set_calculator(self.calc)
wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_180127-wz6t76ga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-salad-48
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/wz6t76ga
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
Uncertainty Slope: 0.08370574563741684, Uncertainty Bias: 0.13280528783798218

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.157685723684798, Test Loss Force: 11.220072982747515, time: 6.1351213455200195

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.047 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ
wandb:  test_error_energy ‚ñÅ
wandb:   test_error_force ‚ñÅ
wandb:   test_error_total ‚ñÅ
wandb: train_error_energy ‚ñÅ
wandb:  train_error_force ‚ñÅ
wandb:  train_error_total ‚ñÅ
wandb: valid_error_energy ‚ñÅ
wandb:  valid_error_force ‚ñÅ
wandb:  valid_error_total ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:  test_error_energy 10.15769
wandb:   test_error_force 11.22007
wandb:   test_error_total 2.59083
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:  train_error_total 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:  valid_error_total 0.0
wandb: 
wandb: üöÄ View run curious-salad-48 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/wz6t76ga
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241120_180127-wz6t76ga/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample after 1910 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 22 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 85 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 25 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 34 steps.
Found uncertainty sample after 81 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 33 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 50 steps.
Found uncertainty sample after 67 steps.
Found uncertainty sample after 24 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 48 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 26 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 47 steps.
Found uncertainty sample after 87 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 42 steps.
Found uncertainty sample after 65 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 92 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 62 steps.
Found uncertainty sample after 49 steps.
Found uncertainty sample after 22 steps.
Found uncertainty sample after 29 steps.
Found uncertainty sample after 47 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 37 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 102 steps.
Found uncertainty sample after 63 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 216 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 91 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 21 steps.
Found uncertainty sample after 34 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 21 steps.
Found uncertainty sample after 47 steps.
Found uncertainty sample after 25 steps.
Found uncertainty sample after 49 steps.
Found uncertainty sample after 26 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 96 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 30 steps.
Found uncertainty sample after 144 steps.
Found uncertainty sample after 98 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241120_180323-no7p9tpr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_38_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/no7p9tpr
Training model 0. Added 97 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 7656920.249081075, Training Loss Force: 46950.83995345483, time: 0.5768752098083496
Validation Loss Energy: 51309.38842541594, Validation Loss Force: 41011.28327261177, time: 0.030089139938354492
Test Loss Energy: 32.80073587300754, Test Loss Force: 129.9129590434504, time: 6.458145380020142


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 7656879.878315977, Training Loss Force: 46937.995837772825, time: 0.45966005325317383
Validation Loss Energy: 51383.056755931924, Validation Loss Force: 40845.47571783432, time: 0.03296971321105957
Test Loss Energy: 90.27799812786829, Test Loss Force: 65.81327551430849, time: 6.575808048248291


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7656854.111057551, Training Loss Force: 46891.5943515309, time: 0.44408655166625977
Validation Loss Energy: 51357.58129651564, Validation Loss Force: 40840.29525780695, time: 0.030658960342407227
Test Loss Energy: 49.618750168967296, Test Loss Force: 61.2597619694425, time: 6.558073997497559


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7656883.204397663, Training Loss Force: 46923.115235761135, time: 0.43793582916259766
Validation Loss Energy: 51395.23448520753, Validation Loss Force: 40830.62384968543, time: 0.03662514686584473
Test Loss Energy: 85.95172305835428, Test Loss Force: 63.8611792540776, time: 6.728752374649048


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 7656971.068362107, Training Loss Force: 46915.99421132773, time: 0.4424431324005127
Validation Loss Energy: 51338.424539048225, Validation Loss Force: 40856.4094070611, time: 0.029787063598632812
Test Loss Energy: 34.39321515788055, Test Loss Force: 87.81436226200755, time: 6.665512323379517


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7656948.504811623, Training Loss Force: 46973.00670344968, time: 0.44867634773254395
Validation Loss Energy: 51373.21388187992, Validation Loss Force: 40846.872982757195, time: 0.032311439514160156
Test Loss Energy: 74.02300207256593, Test Loss Force: 67.97316742359445, time: 6.601439714431763


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7656894.703602136, Training Loss Force: 46932.37795744119, time: 0.4410264492034912
Validation Loss Energy: 51341.95965578521, Validation Loss Force: 40832.258248341954, time: 0.03330850601196289
Test Loss Energy: 49.666796658722795, Test Loss Force: 64.44438655878578, time: 6.626849412918091


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7656876.455597341, Training Loss Force: 46924.23233989148, time: 0.4513716697692871
Validation Loss Energy: 51369.904954242724, Validation Loss Force: 40863.2789889143, time: 0.03231072425842285
Test Loss Energy: 78.61776448215346, Test Loss Force: 57.1210065157271, time: 6.686192989349365


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7656858.549652566, Training Loss Force: 46975.90022041891, time: 0.6198127269744873
Validation Loss Energy: 51353.830935312726, Validation Loss Force: 40961.791638293944, time: 0.05203104019165039
Test Loss Energy: 21.356749762928168, Test Loss Force: 76.35355794900462, time: 6.740901947021484

slurmstepd: error: *** JOB 5122043 ON aimat01 CANCELLED AT 2024-11-20T18:04:35 ***
