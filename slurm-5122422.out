/home/ws/fq0795/git/gnn_uncertainty/active_learning.py:175: DeprecationWarning: Please use atoms.calc = calc
  self.atoms.set_calculator(self.calc)
wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_103223-fchhmgj0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-plant-55
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/fchhmgj0
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
Uncertainty Slope: 0.6569411158561707, Uncertainty Bias: 0.026700079441070557

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 12.42631914328964, Test Loss Force: 10.720071514019354, time: 15.220008373260498

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.039 MB of 0.047 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ
wandb:  test_error_energy ‚ñÅ
wandb:   test_error_force ‚ñÅ
wandb:   test_error_total ‚ñÅ
wandb: train_error_energy ‚ñÅ
wandb:  train_error_force ‚ñÅ
wandb:  train_error_total ‚ñÅ
wandb: valid_error_energy ‚ñÅ
wandb:  valid_error_force ‚ñÅ
wandb:  valid_error_total ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:  test_error_energy 12.42632
wandb:   test_error_force 10.72007
wandb:   test_error_total 6.04292
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:  train_error_total 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:  valid_error_total 0.0
wandb: 
wandb: üöÄ View run honest-plant-55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/fchhmgj0
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_103223-fchhmgj0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample after 3218 steps.
Found uncertainty sample after 2051 steps.
Found uncertainty sample after 384 steps.
Found uncertainty sample after 2887 steps.
Found uncertainty sample after 191 steps.
Found uncertainty sample after 249 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 75 steps.
Found uncertainty sample after 2869 steps.
Found uncertainty sample after 2356 steps.
Found uncertainty sample after 1401 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 1702 steps.
Found uncertainty sample after 809 steps.
Found uncertainty sample after 2419 steps.
Found uncertainty sample after 597 steps.
Found uncertainty sample after 3096 steps.
Found uncertainty sample after 1475 steps.
Found uncertainty sample after 1773 steps.
Found uncertainty sample after 619 steps.
Found uncertainty sample after 1603 steps.
Found uncertainty sample after 626 steps.
Found uncertainty sample after 2023 steps.
Found uncertainty sample after 426 steps.
Found uncertainty sample after 395 steps.
Found uncertainty sample after 954 steps.
Found uncertainty sample after 1983 steps.
Found uncertainty sample after 328 steps.
Found uncertainty sample after 1368 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 617 steps.
Found uncertainty sample after 1003 steps.
Found uncertainty sample after 217 steps.
Found uncertainty sample after 653 steps.
Found uncertainty sample after 1268 steps.
Found uncertainty sample after 810 steps.
Found uncertainty sample after 3133 steps.
Found uncertainty sample after 2748 steps.
Found uncertainty sample after 247 steps.
Found uncertainty sample after 1170 steps.
Found uncertainty sample after 1557 steps.
Found uncertainty sample after 2338 steps.
Found uncertainty sample after 3195 steps.
Found uncertainty sample after 3057 steps.
Found uncertainty sample after 3288 steps.
Found uncertainty sample after 1279 steps.
Found uncertainty sample after 718 steps.
Found uncertainty sample after 534 steps.
Found uncertainty sample after 1306 steps.
Found uncertainty sample after 3688 steps.
Found uncertainty sample after 627 steps.
Found uncertainty sample after 1012 steps.
Found uncertainty sample after 1049 steps.
Found uncertainty sample after 1004 steps.
Found uncertainty sample after 1455 steps.
Found uncertainty sample after 1096 steps.
Found uncertainty sample after 700 steps.
Found uncertainty sample after 204 steps.
Found uncertainty sample after 1634 steps.
Found uncertainty sample after 1856 steps.
Found uncertainty sample after 219 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 1230 steps.
Found uncertainty sample after 315 steps.
Found uncertainty sample after 2305 steps.
Found uncertainty sample after 423 steps.
Found uncertainty sample after 370 steps.
Found uncertainty sample after 3445 steps.
Found uncertainty sample after 1366 steps.
Found uncertainty sample after 1199 steps.
Found uncertainty sample after 1746 steps.
Found uncertainty sample after 1629 steps.
Found uncertainty sample after 1133 steps.
Found uncertainty sample after 287 steps.
Found uncertainty sample after 380 steps.
Found uncertainty sample after 638 steps.
Found uncertainty sample after 449 steps.
Found uncertainty sample after 1496 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_115849-ramylauz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_0
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ramylauz
Training model 0. Added 78 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 30.617328542644685, Training Loss Force: 24.078241405031346, time: 1.0684645175933838
Validation Loss Energy: 17.527113242492696, Validation Loss Force: 12.024678974169774, time: 0.07113981246948242
Test Loss Energy: 17.139487995324693, Test Loss Force: 19.081409399424686, time: 15.471923351287842


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.769412521576632, Training Loss Force: 11.710884182099509, time: 1.0157206058502197
Validation Loss Energy: 9.542177183960801, Validation Loss Force: 8.576888622832165, time: 0.06726264953613281
Test Loss Energy: 20.231820751675468, Test Loss Force: 13.908219410082522, time: 15.688542127609253


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.75827665069576, Training Loss Force: 7.714530083184014, time: 1.0087223052978516
Validation Loss Energy: 2.396808905413541, Validation Loss Force: 5.85998569473476, time: 0.06902933120727539
Test Loss Energy: 13.730641666208149, Test Loss Force: 12.49729695040031, time: 15.5662362575531


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 8.888884693541623, Training Loss Force: 6.458200272091383, time: 1.0121452808380127
Validation Loss Energy: 1.859400039084868, Validation Loss Force: 5.224328075810077, time: 0.06628012657165527
Test Loss Energy: 13.251780979771437, Test Loss Force: 11.298660912455317, time: 15.875242471694946


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 5.419763862704435, Training Loss Force: 5.2864450059137, time: 1.0065417289733887
Validation Loss Energy: 12.719024609210061, Validation Loss Force: 4.298966764576046, time: 0.06553936004638672
Test Loss Energy: 14.433460997747051, Test Loss Force: 10.901523001548641, time: 15.821479320526123


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 5.934383834223693, Training Loss Force: 5.154699338448824, time: 1.0261015892028809
Validation Loss Energy: 2.70105801434233, Validation Loss Force: 4.229016588397707, time: 0.07016944885253906
Test Loss Energy: 13.577071517417734, Test Loss Force: 10.889509243351256, time: 16.00311040878296


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 9.206290781535358, Training Loss Force: 4.507175267209236, time: 1.0186476707458496
Validation Loss Energy: 15.46681620123057, Validation Loss Force: 4.331460873041288, time: 0.07369303703308105
Test Loss Energy: 14.499371316756, Test Loss Force: 11.072626557232859, time: 16.137296199798584


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.824413014358962, Training Loss Force: 4.891803500339976, time: 1.257775068283081
Validation Loss Energy: 7.321511597110019, Validation Loss Force: 4.060706325050395, time: 0.0691683292388916
Test Loss Energy: 16.28516044061312, Test Loss Force: 10.59714666459942, time: 15.895736694335938


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.123044702609313, Training Loss Force: 4.626833491184343, time: 1.0132555961608887
Validation Loss Energy: 4.454124852149988, Validation Loss Force: 3.8942268474209008, time: 0.06709027290344238
Test Loss Energy: 11.383082619899895, Test Loss Force: 10.481451110583494, time: 16.07330870628357


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.075640913672732, Training Loss Force: 4.618251003195928, time: 1.0243709087371826
Validation Loss Energy: 14.934010796824808, Validation Loss Force: 4.260087395682179, time: 0.06589174270629883
Test Loss Energy: 14.001259518659584, Test Loss Force: 10.415391605578387, time: 15.955727100372314


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.248577094733694, Training Loss Force: 4.454659623913811, time: 1.0534982681274414
Validation Loss Energy: 8.272694067844128, Validation Loss Force: 4.46719330432449, time: 0.06732559204101562
Test Loss Energy: 11.434034869729718, Test Loss Force: 10.946046049350628, time: 16.166172742843628


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.18695917015234, Training Loss Force: 4.376320149088558, time: 0.9766323566436768
Validation Loss Energy: 4.692625774353242, Validation Loss Force: 4.269384723201248, time: 0.07117843627929688
Test Loss Energy: 11.460944610886147, Test Loss Force: 10.845989698938961, time: 16.06758737564087


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.4736033307362435, Training Loss Force: 4.506585973314538, time: 1.0282416343688965
Validation Loss Energy: 2.8192180646363485, Validation Loss Force: 4.195493748478279, time: 0.06914687156677246
Test Loss Energy: 11.41300739455675, Test Loss Force: 10.456969908718413, time: 16.146296501159668


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.320335590903522, Training Loss Force: 4.457380569304823, time: 1.007704257965088
Validation Loss Energy: 2.2348591862196554, Validation Loss Force: 3.932945449191408, time: 0.07485461235046387
Test Loss Energy: 13.306968457378769, Test Loss Force: 10.478392471236292, time: 16.06636691093445


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 13.758565612633964, Training Loss Force: 4.635857118560719, time: 1.0592820644378662
Validation Loss Energy: 3.970591231016835, Validation Loss Force: 4.878493054518668, time: 0.06755805015563965
Test Loss Energy: 11.434638212182232, Test Loss Force: 10.42637098981548, time: 16.222015857696533


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.156030665353612, Training Loss Force: 4.815356490585964, time: 1.023082971572876
Validation Loss Energy: 2.4268810415785262, Validation Loss Force: 3.7090204492805876, time: 0.06813263893127441
Test Loss Energy: 12.89399134633735, Test Loss Force: 10.158666106789143, time: 16.48403310775757


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.236446314251408, Training Loss Force: 5.098356919116424, time: 1.067491054534912
Validation Loss Energy: 6.808574515257102, Validation Loss Force: 4.31539084077968, time: 0.0678102970123291
Test Loss Energy: 11.449355514226836, Test Loss Force: 10.362060167401122, time: 16.05448579788208


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.422246109760682, Training Loss Force: 5.215524119498626, time: 1.0294263362884521
Validation Loss Energy: 4.160396192358849, Validation Loss Force: 5.610613174150728, time: 0.07026791572570801
Test Loss Energy: 10.899256220316639, Test Loss Force: 11.175376626069957, time: 16.214974641799927


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.839922748426217, Training Loss Force: 5.04810496216838, time: 1.0163421630859375
Validation Loss Energy: 7.082077245847037, Validation Loss Force: 4.143100589118054, time: 0.07122039794921875
Test Loss Energy: 15.428428180369464, Test Loss Force: 10.233480911316619, time: 16.01024079322815


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.929780993599945, Training Loss Force: 4.806144095441128, time: 1.0179595947265625
Validation Loss Energy: 8.145627474382145, Validation Loss Force: 3.9526850689779063, time: 0.07230973243713379
Test Loss Energy: 11.899590983764295, Test Loss Force: 10.294662595700046, time: 16.17575192451477

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.045 MB of 0.061 MB uploaded (0.003 MB deduped)wandb: / 0.045 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: - 0.045 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: \ 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÜ‚ñà‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÑ‚ñÖ‚ñÅ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÑ‚ñÇ
wandb:   test_error_force ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ
wandb:  train_error_force ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñà‚ñÑ‚ñÅ‚ñÅ‚ñÜ‚ñÅ‚ñá‚ñÉ‚ñÇ‚ñá‚ñÑ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÑ
wandb:  valid_error_force ‚ñà‚ñÖ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÖ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 870
wandb:                 lr 0.001
wandb:  test_error_energy 11.89959
wandb:   test_error_force 10.29466
wandb:   test_error_total 5.60062
wandb: train_error_energy 10.92978
wandb:  train_error_force 4.80614
wandb:  train_error_total 2.89685
wandb: valid_error_energy 8.14563
wandb:  valid_error_force 3.95269
wandb:  valid_error_total 2.4179
wandb: 
wandb: üöÄ View run al_43_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/ramylauz
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_115849-ramylauz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.0179461240768433, Uncertainty Bias: 0.0032496750354766846
Found uncertainty sample after 12 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 74 steps.
Found uncertainty sample after 21 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 19 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 42 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 24 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 19 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 31 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 39 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 24 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 48 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 22 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 29 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 30 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 24 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 49 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 11 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_120521-o5chipj8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_1
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/o5chipj8
Training model 1. Added 140 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 28.476708519627135, Training Loss Force: 27.64608915852672, time: 1.2296605110168457
Validation Loss Energy: 13.24857993476186, Validation Loss Force: 10.978256901677724, time: 0.07711100578308105
Test Loss Energy: 17.710148595475687, Test Loss Force: 16.07131752190843, time: 16.938054084777832


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 5.97044803090359, Training Loss Force: 9.673589165805565, time: 1.2245795726776123
Validation Loss Energy: 6.303067902803796, Validation Loss Force: 6.527129176231924, time: 0.08027005195617676
Test Loss Energy: 15.024022012787274, Test Loss Force: 12.755598881457528, time: 17.128467321395874


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.722943091127174, Training Loss Force: 6.6965814539614135, time: 1.2523326873779297
Validation Loss Energy: 6.999664277571119, Validation Loss Force: 4.999327583924425, time: 0.07666826248168945
Test Loss Energy: 14.659576110755252, Test Loss Force: 10.987248281790288, time: 17.19888710975647


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 11.532273309669453, Training Loss Force: 5.6941219251274, time: 1.2900242805480957
Validation Loss Energy: 2.106082716386092, Validation Loss Force: 5.289931750259906, time: 0.07699346542358398
Test Loss Energy: 11.863758505214209, Test Loss Force: 11.29268826378313, time: 17.279878616333008


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 5.854443438817385, Training Loss Force: 5.1283006566970215, time: 1.2718658447265625
Validation Loss Energy: 5.400867745452589, Validation Loss Force: 4.3167829682800205, time: 0.08048033714294434
Test Loss Energy: 11.076522768321178, Test Loss Force: 10.519992267195029, time: 17.21569561958313


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.177547363847685, Training Loss Force: 5.139497769535503, time: 1.2731776237487793
Validation Loss Energy: 12.494569656731931, Validation Loss Force: 3.9927886728360846, time: 0.08001208305358887
Test Loss Energy: 13.683644225592047, Test Loss Force: 10.276044004311625, time: 17.1628201007843


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.242024757886227, Training Loss Force: 4.5874329731069015, time: 1.2925667762756348
Validation Loss Energy: 3.671846948713673, Validation Loss Force: 4.399531276289705, time: 0.08117008209228516
Test Loss Energy: 11.30036613375936, Test Loss Force: 9.97499998690867, time: 17.677795886993408


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.24065089720083, Training Loss Force: 4.842311628497792, time: 1.2773115634918213
Validation Loss Energy: 11.383937818643561, Validation Loss Force: 4.4789613686867735, time: 0.0786442756652832
Test Loss Energy: 13.184840227230016, Test Loss Force: 10.34405104594705, time: 17.198148250579834


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.289034525327079, Training Loss Force: 4.420145206477688, time: 1.3966591358184814
Validation Loss Energy: 17.185536991286302, Validation Loss Force: 4.710616550667623, time: 0.10027623176574707
Test Loss Energy: 22.265949043403303, Test Loss Force: 10.032045812244023, time: 17.286680221557617


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.320752633307354, Training Loss Force: 4.83454131031421, time: 1.2677485942840576
Validation Loss Energy: 9.633798412097414, Validation Loss Force: 3.681532388554094, time: 0.0751652717590332
Test Loss Energy: 12.815859900036774, Test Loss Force: 9.822433784514628, time: 16.9280047416687


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.007166306280936, Training Loss Force: 4.427103116282354, time: 1.2110371589660645
Validation Loss Energy: 2.8811612809962703, Validation Loss Force: 4.009581043807083, time: 0.08117198944091797
Test Loss Energy: 10.918805717958339, Test Loss Force: 10.113372749649404, time: 16.91351294517517


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.827426443618127, Training Loss Force: 3.983155281908524, time: 1.2524850368499756
Validation Loss Energy: 6.061810336573956, Validation Loss Force: 3.4770417290307045, time: 0.0796365737915039
Test Loss Energy: 10.856657915285595, Test Loss Force: 9.787532986313705, time: 17.070277214050293


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.1159679560707705, Training Loss Force: 3.910826032032574, time: 1.202690601348877
Validation Loss Energy: 5.536029253045632, Validation Loss Force: 3.6352777722088065, time: 0.07238268852233887
Test Loss Energy: 14.839451483116079, Test Loss Force: 9.992862902169394, time: 16.03200626373291


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.848429204834391, Training Loss Force: 4.352983147218031, time: 1.1529145240783691
Validation Loss Energy: 5.201952944012378, Validation Loss Force: 4.5473452900926565, time: 0.07371711730957031
Test Loss Energy: 11.202070683596284, Test Loss Force: 10.068049715725484, time: 16.255709886550903


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 8.422031103813172, Training Loss Force: 4.701682034688201, time: 1.1479911804199219
Validation Loss Energy: 6.7681516038436635, Validation Loss Force: 4.234146885519884, time: 0.07181906700134277
Test Loss Energy: 15.335407153722143, Test Loss Force: 10.246780204944445, time: 16.497251749038696


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.871102780881128, Training Loss Force: 4.6771307016600625, time: 1.1580097675323486
Validation Loss Energy: 8.234084128616834, Validation Loss Force: 4.23659179274217, time: 0.07336568832397461
Test Loss Energy: 11.810080150839203, Test Loss Force: 10.208906617427242, time: 16.137271404266357


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.071261154709292, Training Loss Force: 4.150669336057286, time: 1.168809413909912
Validation Loss Energy: 2.0327020993455895, Validation Loss Force: 3.633487512275547, time: 0.07547664642333984
Test Loss Energy: 11.293281412418832, Test Loss Force: 9.686299058867348, time: 16.19999051094055


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.25301264870767, Training Loss Force: 4.411768421041529, time: 1.1885387897491455
Validation Loss Energy: 4.298466204336001, Validation Loss Force: 4.738569544570814, time: 0.0758371353149414
Test Loss Energy: 14.008932496909443, Test Loss Force: 10.39284624496734, time: 15.985551834106445


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.437205153200803, Training Loss Force: 4.495592819449374, time: 1.145277738571167
Validation Loss Energy: 8.520531061997843, Validation Loss Force: 3.4729285845671267, time: 0.07352089881896973
Test Loss Energy: 11.878944904698283, Test Loss Force: 9.579978733928971, time: 16.178273677825928


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.661174995101499, Training Loss Force: 4.080553069571317, time: 1.161649227142334
Validation Loss Energy: 3.7626765880365145, Validation Loss Force: 4.855118583594045, time: 0.0823979377746582
Test Loss Energy: 13.847260296917229, Test Loss Force: 10.578957407303713, time: 16.033260345458984

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÉ‚ñÅ‚ñÇ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÉ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ
wandb:   test_error_force ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:   test_error_total ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÜ‚ñÉ‚ñÉ‚ñÅ‚ñÉ‚ñÜ‚ñÇ‚ñÖ‚ñà‚ñÖ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÑ‚ñÇ
wandb:  valid_error_force ‚ñà‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÑ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 996
wandb:                 lr 0.001
wandb:  test_error_energy 13.84726
wandb:   test_error_force 10.57896
wandb:   test_error_total 5.80521
wandb: train_error_energy 7.66117
wandb:  train_error_force 4.08055
wandb:  train_error_total 2.43619
wandb: valid_error_energy 3.76268
wandb:  valid_error_force 4.85512
wandb:  valid_error_total 2.76962
wandb: 
wandb: üöÄ View run al_43_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/o5chipj8
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_120521-o5chipj8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.5309793949127197, Uncertainty Bias: 0.15604731440544128
Found uncertainty sample after 0 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 364 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 133 steps.
Found uncertainty sample after 42 steps.
Found uncertainty sample after 1150 steps.
Found uncertainty sample after 65 steps.
Found uncertainty sample after 43 steps.
Found uncertainty sample after 569 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 515 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 88 steps.
Found uncertainty sample after 21 steps.
Found uncertainty sample after 171 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 169 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 83 steps.
Found uncertainty sample after 32 steps.
Found uncertainty sample after 45 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 129 steps.
Found uncertainty sample after 38 steps.
Found uncertainty sample after 87 steps.
Found uncertainty sample after 64 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 91 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 74 steps.
Found uncertainty sample after 105 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 124 steps.
Found uncertainty sample after 35 steps.
Found uncertainty sample after 93 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 71 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 35 steps.
Found uncertainty sample after 56 steps.
Found uncertainty sample after 29 steps.
Found uncertainty sample after 117 steps.
Found uncertainty sample after 364 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 25 steps.
Found uncertainty sample after 88 steps.
Found uncertainty sample after 93 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 29 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 29 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 90 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 54 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 41 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 52 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 21 steps.
Found uncertainty sample after 35 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 42 steps.
Found uncertainty sample after 29 steps.
Found uncertainty sample after 50 steps.
Found uncertainty sample after 25 steps.
Found uncertainty sample after 68 steps.
Found uncertainty sample after 119 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 83 steps.
Found uncertainty sample after 63 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 31 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 50 steps.
Found uncertainty sample after 189 steps.
Found uncertainty sample after 87 steps.
Found uncertainty sample after 71 steps.
Found uncertainty sample after 32 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_121450-3itq9vlu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_2
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3itq9vlu
Training model 2. Added 111 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.361134500862818, Training Loss Force: 27.864506838712728, time: 1.2621986865997314
Validation Loss Energy: 7.091803879479454, Validation Loss Force: 15.637003120139761, time: 0.08626770973205566
Test Loss Energy: 18.250689311502484, Test Loss Force: 21.239122583216492, time: 16.026596069335938


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.17966671726003, Training Loss Force: 14.119447273225571, time: 1.2676937580108643
Validation Loss Energy: 10.067567705807166, Validation Loss Force: 10.1401756609113, time: 0.08034610748291016
Test Loss Energy: 19.375951221288993, Test Loss Force: 16.0852293119057, time: 16.226577520370483


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.291482624573714, Training Loss Force: 9.692609532440839, time: 1.2646605968475342
Validation Loss Energy: 4.225419145676098, Validation Loss Force: 7.904796542235903, time: 0.08026504516601562
Test Loss Energy: 16.080007419655477, Test Loss Force: 14.244230662698376, time: 16.14458990097046


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.032819953966964, Training Loss Force: 8.311722625065768, time: 1.2902092933654785
Validation Loss Energy: 7.7953038884471235, Validation Loss Force: 6.566012107832126, time: 0.07998251914978027
Test Loss Energy: 14.053836595739503, Test Loss Force: 12.592588554147378, time: 16.252595901489258


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 12.355928911923888, Training Loss Force: 7.465787067361448, time: 1.2574617862701416
Validation Loss Energy: 6.420484460819561, Validation Loss Force: 6.089334915040381, time: 0.0810232162475586
Test Loss Energy: 13.734281665550196, Test Loss Force: 12.201890449449426, time: 16.013222694396973


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 14.61884268643506, Training Loss Force: 6.589309560680162, time: 1.520768404006958
Validation Loss Energy: 4.160255465458623, Validation Loss Force: 5.967998489379704, time: 0.08218502998352051
Test Loss Energy: 14.891285521416686, Test Loss Force: 12.217704412193218, time: 16.40617275238037


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.709172701916142, Training Loss Force: 6.058845274226781, time: 1.3198587894439697
Validation Loss Energy: 9.471853814293887, Validation Loss Force: 5.256278871559256, time: 0.08416986465454102
Test Loss Energy: 17.402356877559733, Test Loss Force: 11.027587406651277, time: 16.266177892684937


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.549408617554655, Training Loss Force: 5.837155694405759, time: 1.2627949714660645
Validation Loss Energy: 3.361947832876112, Validation Loss Force: 4.921523866969213, time: 0.07828593254089355
Test Loss Energy: 12.672280517118129, Test Loss Force: 10.775835842279871, time: 16.137726068496704


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.43779977248418, Training Loss Force: 5.409643429144481, time: 1.2637650966644287
Validation Loss Energy: 14.946235332936242, Validation Loss Force: 4.636822214353987, time: 0.08144283294677734
Test Loss Energy: 15.493046771180937, Test Loss Force: 10.401443558981962, time: 16.330390214920044


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 8.206180484558358, Training Loss Force: 5.49007868823812, time: 1.245534896850586
Validation Loss Energy: 11.329496993817385, Validation Loss Force: 4.926431494945462, time: 0.0801687240600586
Test Loss Energy: 14.316674975798971, Test Loss Force: 10.51282305748621, time: 16.193232774734497


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.025013251453618, Training Loss Force: 5.157664203574755, time: 1.2721772193908691
Validation Loss Energy: 12.701594959143417, Validation Loss Force: 4.482584641029311, time: 0.08298730850219727
Test Loss Energy: 19.934499216794727, Test Loss Force: 10.332027219840011, time: 16.33348059654236


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.582178113676617, Training Loss Force: 4.710822506903655, time: 1.2949445247650146
Validation Loss Energy: 2.688843721011607, Validation Loss Force: 4.6137363226424855, time: 0.07932281494140625
Test Loss Energy: 13.451075195446624, Test Loss Force: 10.72338575422994, time: 16.330079793930054


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 5.75476148759588, Training Loss Force: 4.464801417806837, time: 1.237701416015625
Validation Loss Energy: 5.580926923615635, Validation Loss Force: 4.536863808055544, time: 0.07900547981262207
Test Loss Energy: 12.893668548355794, Test Loss Force: 10.163640824629317, time: 16.091469287872314


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.394947531528346, Training Loss Force: 4.7517662414494195, time: 1.2497038841247559
Validation Loss Energy: 3.946939314336386, Validation Loss Force: 4.384214311079624, time: 0.0814363956451416
Test Loss Energy: 12.328940567726226, Test Loss Force: 10.22661072645206, time: 16.372161388397217


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.063436616797478, Training Loss Force: 4.947945660585492, time: 1.282151460647583
Validation Loss Energy: 5.562109154093278, Validation Loss Force: 4.24623470277572, time: 0.07553601264953613
Test Loss Energy: 14.296283182565999, Test Loss Force: 10.049431446099808, time: 16.413652181625366


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.959621115662111, Training Loss Force: 4.654802455236778, time: 1.3171148300170898
Validation Loss Energy: 10.540378916887313, Validation Loss Force: 4.190129648752879, time: 0.08507609367370605
Test Loss Energy: 17.430845168089736, Test Loss Force: 10.021461086334849, time: 16.283367156982422


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.381412477557726, Training Loss Force: 4.564938302968703, time: 1.2517991065979004
Validation Loss Energy: 2.64042320188388, Validation Loss Force: 3.9456816790001854, time: 0.07991266250610352
Test Loss Energy: 12.245372869902123, Test Loss Force: 9.899075357388838, time: 16.201616525650024


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.3999760153679786, Training Loss Force: 4.422457068885284, time: 1.2894017696380615
Validation Loss Energy: 8.351950032969082, Validation Loss Force: 3.897187901723448, time: 0.0791478157043457
Test Loss Energy: 13.413303340915549, Test Loss Force: 9.887661141112996, time: 16.282124996185303


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 9.088946912271789, Training Loss Force: 4.231557917722157, time: 1.2302839756011963
Validation Loss Energy: 5.049279398768698, Validation Loss Force: 3.9662576440987887, time: 0.07791709899902344
Test Loss Energy: 12.231932089267879, Test Loss Force: 9.585278222296227, time: 16.23035764694214


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.297601480455162, Training Loss Force: 4.589811388141227, time: 1.2771039009094238
Validation Loss Energy: 11.616145220106311, Validation Loss Force: 4.611598698841579, time: 0.07630515098571777
Test Loss Energy: 18.462735735537834, Test Loss Force: 10.205986858341905, time: 16.17189860343933

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÜ‚ñá‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÜ‚ñÅ‚ñÑ‚ñÉ‚ñà‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÜ‚ñÅ‚ñÇ‚ñÅ‚ñá
wandb:   test_error_force ‚ñà‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÖ‚ñÑ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ
wandb:  train_error_force ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÑ‚ñÖ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÖ‚ñÅ‚ñà‚ñÜ‚ñá‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÖ‚ñÅ‚ñÑ‚ñÇ‚ñÜ
wandb:  valid_error_force ‚ñà‚ñÖ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1095
wandb:                 lr 0.001
wandb:  test_error_energy 18.46274
wandb:   test_error_force 10.20599
wandb:   test_error_total 6.07926
wandb: train_error_energy 11.2976
wandb:  train_error_force 4.58981
wandb:  train_error_total 2.97273
wandb: valid_error_energy 11.61615
wandb:  valid_error_force 4.6116
wandb:  valid_error_total 2.99905
wandb: 
wandb: üöÄ View run al_43_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/3itq9vlu
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_121450-3itq9vlu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.1386361122131348, Uncertainty Bias: -0.1253626048564911
Found uncertainty sample after 0 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 19 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 24 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 39 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 54 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 98 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 25 steps.
Found uncertainty sample after 35 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 46 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 121 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 41 steps.
Found uncertainty sample after 14 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_122124-eohtzr4h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_3
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eohtzr4h
Training model 3. Added 150 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 32.1665463820392, Training Loss Force: 16.521169577416607, time: 1.3945386409759521
Validation Loss Energy: 8.115470946610852, Validation Loss Force: 8.386109261307572, time: 0.0889592170715332
Test Loss Energy: 18.429402644704943, Test Loss Force: 13.78649828908094, time: 16.481392860412598


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.770683591830404, Training Loss Force: 6.814577652593453, time: 1.3856489658355713
Validation Loss Energy: 7.770129805485111, Validation Loss Force: 4.5252159850320615, time: 0.08539223670959473
Test Loss Energy: 13.37077032107912, Test Loss Force: 10.30802509472272, time: 16.615044116973877


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 15.178997032126262, Training Loss Force: 5.124650392500532, time: 1.4314446449279785
Validation Loss Energy: 3.9716480187834087, Validation Loss Force: 4.604444339182919, time: 0.08273077011108398
Test Loss Energy: 12.383207370202923, Test Loss Force: 10.1874287210437, time: 16.487687587738037


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 17.614087057242674, Training Loss Force: 5.336735080475412, time: 1.4471650123596191
Validation Loss Energy: 14.839484181672127, Validation Loss Force: 4.451421648718425, time: 0.08732795715332031
Test Loss Energy: 16.087216919655834, Test Loss Force: 10.206653173027856, time: 16.908581972122192


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 7.62604108931452, Training Loss Force: 4.902254147594206, time: 1.4094464778900146
Validation Loss Energy: 7.501056409545972, Validation Loss Force: 4.331784188641175, time: 0.0880889892578125
Test Loss Energy: 15.683857329702102, Test Loss Force: 10.001017699145216, time: 16.624562740325928


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.239898679075418, Training Loss Force: 4.64051536484209, time: 1.4195375442504883
Validation Loss Energy: 7.4099081306753085, Validation Loss Force: 3.9520745101797723, time: 0.0879511833190918
Test Loss Energy: 12.426211958989756, Test Loss Force: 9.819045762707665, time: 16.517840147018433


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.200454661193738, Training Loss Force: 4.261919511705407, time: 1.4914674758911133
Validation Loss Energy: 5.109437031247425, Validation Loss Force: 4.068583914095028, time: 0.09179830551147461
Test Loss Energy: 12.315445204006055, Test Loss Force: 10.05987564096434, time: 16.65210771560669


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.612160840443545, Training Loss Force: 4.304591878216195, time: 1.4323310852050781
Validation Loss Energy: 16.82331841957582, Validation Loss Force: 4.770819607652119, time: 0.08606791496276855
Test Loss Energy: 22.34517446438363, Test Loss Force: 10.073946628908686, time: 16.531764030456543


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 13.329135779556623, Training Loss Force: 5.036989569212318, time: 1.4227375984191895
Validation Loss Energy: 6.372480555663865, Validation Loss Force: 4.926916468345293, time: 0.08583831787109375
Test Loss Energy: 12.700813434741878, Test Loss Force: 10.138552265272255, time: 16.658605813980103


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.061615881905194, Training Loss Force: 4.557693193480074, time: 1.4294114112854004
Validation Loss Energy: 3.461498977306653, Validation Loss Force: 4.240074783522773, time: 0.08437585830688477
Test Loss Energy: 11.710046654908878, Test Loss Force: 10.003301547792383, time: 16.686837434768677


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.69538977332559, Training Loss Force: 4.603714189925026, time: 1.4126255512237549
Validation Loss Energy: 5.433961279258669, Validation Loss Force: 3.732613358637366, time: 0.08918094635009766
Test Loss Energy: 12.068651784361844, Test Loss Force: 9.632879793450408, time: 16.5517418384552


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.246867375872194, Training Loss Force: 4.571012759356529, time: 1.4217493534088135
Validation Loss Energy: 7.723013904883375, Validation Loss Force: 3.666062226971615, time: 0.08707356452941895
Test Loss Energy: 13.184980576408758, Test Loss Force: 9.680251304241985, time: 16.679272651672363


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.545077589083581, Training Loss Force: 3.900034726754135, time: 1.4372100830078125
Validation Loss Energy: 8.894027380611277, Validation Loss Force: 3.9087043499508334, time: 0.08628225326538086
Test Loss Energy: 16.01496350512753, Test Loss Force: 9.619798272578912, time: 16.818214178085327


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.907597680510243, Training Loss Force: 4.046872210743956, time: 1.4164466857910156
Validation Loss Energy: 4.519107279682678, Validation Loss Force: 3.857246846341797, time: 0.08753013610839844
Test Loss Energy: 13.695922682611007, Test Loss Force: 9.5726806559092, time: 16.720504999160767


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.819384603098511, Training Loss Force: 4.3034476671172515, time: 1.4531688690185547
Validation Loss Energy: 8.021262302998556, Validation Loss Force: 4.190346973839304, time: 0.08514237403869629
Test Loss Energy: 15.551837100854579, Test Loss Force: 9.961759184151992, time: 16.681694984436035


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 7.473294517155175, Training Loss Force: 4.017180975845674, time: 1.4151992797851562
Validation Loss Energy: 4.105537640214912, Validation Loss Force: 4.542227907780944, time: 0.08297252655029297
Test Loss Energy: 11.673445569099334, Test Loss Force: 10.152263014175933, time: 16.55666756629944


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.10374546953492, Training Loss Force: 4.060325246790266, time: 1.4036295413970947
Validation Loss Energy: 8.955772644100469, Validation Loss Force: 3.665417377125008, time: 0.08252859115600586
Test Loss Energy: 16.54041332458352, Test Loss Force: 9.635833146431606, time: 16.72828722000122


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.620133218800412, Training Loss Force: 3.9389624947851827, time: 1.430271863937378
Validation Loss Energy: 2.0960327671537873, Validation Loss Force: 4.073479963275688, time: 0.08579874038696289
Test Loss Energy: 12.231788886193485, Test Loss Force: 9.773270017928127, time: 16.550830364227295


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.088853479039121, Training Loss Force: 4.228000726078263, time: 1.3965177536010742
Validation Loss Energy: 14.215715759125112, Validation Loss Force: 3.5466864031408307, time: 0.08850646018981934
Test Loss Energy: 15.668625183949512, Test Loss Force: 9.443761623029316, time: 16.643871068954468


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 9.68278136494043, Training Loss Force: 4.31339315597279, time: 1.4621615409851074
Validation Loss Energy: 12.010960773427456, Validation Loss Force: 5.252013421399863, time: 0.08628058433532715
Test Loss Energy: 18.147303518756342, Test Loss Force: 10.569151165371304, time: 16.599149465560913

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.057 MB of 0.058 MB uploadedwandb: | 0.057 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÖ‚ñÇ‚ñÅ‚ñÑ‚ñÑ‚ñÅ‚ñÅ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñÑ‚ñÅ‚ñÑ‚ñÖ
wandb:   test_error_force ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ
wandb:   test_error_total ‚ñà‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÉ
wandb: train_error_energy ‚ñà‚ñÅ‚ñÉ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÑ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñà‚ñÉ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÇ‚ñÑ‚ñÅ‚ñá‚ñÜ
wandb:  valid_error_force ‚ñà‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÉ
wandb:  valid_error_total ‚ñà‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÉ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1230
wandb:                 lr 0.001
wandb:  test_error_energy 18.1473
wandb:   test_error_force 10.56915
wandb:   test_error_total 5.86872
wandb: train_error_energy 9.68278
wandb:  train_error_force 4.31339
wandb:  train_error_total 2.67445
wandb: valid_error_energy 12.01096
wandb:  valid_error_force 5.25201
wandb:  valid_error_total 3.02302
wandb: 
wandb: üöÄ View run al_43_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/eohtzr4h
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_122124-eohtzr4h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.5699040293693542, Uncertainty Bias: 0.1825333684682846
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_122748-qj6jp6p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_4
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qj6jp6p3
Training model 4. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 20.71979388394457, Training Loss Force: 18.175362880790853, time: 1.5958397388458252
Validation Loss Energy: 12.081701870412129, Validation Loss Force: 10.05470945330642, time: 0.12875008583068848
Test Loss Energy: 14.483064963747944, Test Loss Force: 14.086080561649954, time: 16.47744655609131


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 10.111749806809817, Training Loss Force: 9.213198474322695, time: 1.6577682495117188
Validation Loss Energy: 5.123689192601679, Validation Loss Force: 6.175664633593168, time: 0.12193560600280762
Test Loss Energy: 12.712226872258613, Test Loss Force: 11.513472794018524, time: 16.66006875038147


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.193918672797459, Training Loss Force: 6.315210189880928, time: 1.6401050090789795
Validation Loss Energy: 11.036424762668439, Validation Loss Force: 4.9571910107639265, time: 0.12319779396057129
Test Loss Energy: 13.99658020233537, Test Loss Force: 10.322493580900952, time: 16.916430711746216


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.473126543544738, Training Loss Force: 5.268952848023035, time: 1.6450998783111572
Validation Loss Energy: 7.1476150102296705, Validation Loss Force: 4.903057692028276, time: 0.12448883056640625
Test Loss Energy: 16.915987614982892, Test Loss Force: 10.283517335773116, time: 16.671822547912598


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.775568706251553, Training Loss Force: 5.025817933482862, time: 1.6419484615325928
Validation Loss Energy: 2.639346151225028, Validation Loss Force: 4.692490168843372, time: 0.12811756134033203
Test Loss Energy: 12.2075711287416, Test Loss Force: 10.127798035681714, time: 16.77139449119568


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 9.156261325494333, Training Loss Force: 4.691819994092569, time: 1.6656718254089355
Validation Loss Energy: 10.323227512395615, Validation Loss Force: 4.397890650022509, time: 0.12347674369812012
Test Loss Energy: 17.70080073488437, Test Loss Force: 10.082021703335423, time: 16.566219091415405


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.909438874769388, Training Loss Force: 4.505848435492002, time: 1.6620759963989258
Validation Loss Energy: 2.329991350114687, Validation Loss Force: 4.196893001391289, time: 0.1307849884033203
Test Loss Energy: 11.54186906972994, Test Loss Force: 9.933478980853378, time: 16.752935886383057


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.238314528757895, Training Loss Force: 4.611785196621802, time: 1.6347806453704834
Validation Loss Energy: 3.301620749177334, Validation Loss Force: 5.457202371364882, time: 0.12771844863891602
Test Loss Energy: 13.272308976573296, Test Loss Force: 10.743487452700629, time: 16.59311866760254


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 8.49674278768063, Training Loss Force: 4.7505835940127055, time: 1.6981823444366455
Validation Loss Energy: 10.628652982422341, Validation Loss Force: 4.259897236231557, time: 0.16040372848510742
Test Loss Energy: 13.074798203191758, Test Loss Force: 10.163518447532006, time: 16.67706823348999


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.787655693156623, Training Loss Force: 4.669639193080823, time: 1.631194829940796
Validation Loss Energy: 4.611027997820566, Validation Loss Force: 4.312122948394044, time: 0.12031745910644531
Test Loss Energy: 13.670395458041625, Test Loss Force: 9.792506258553141, time: 16.788185834884644


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.519764233993094, Training Loss Force: 4.332693505106502, time: 1.6198556423187256
Validation Loss Energy: 2.230084825727245, Validation Loss Force: 4.431268532327939, time: 0.12522411346435547
Test Loss Energy: 11.231218555110738, Test Loss Force: 9.919131323580697, time: 16.907101154327393


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 9.035026907043505, Training Loss Force: 4.639493066432748, time: 1.665600299835205
Validation Loss Energy: 3.374630288086148, Validation Loss Force: 4.176421690791273, time: 0.1176605224609375
Test Loss Energy: 12.570812672819457, Test Loss Force: 9.953421896404302, time: 16.813278436660767


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.743636667614148, Training Loss Force: 4.188212754402228, time: 1.64609956741333
Validation Loss Energy: 1.466283618349012, Validation Loss Force: 3.7001468611462194, time: 0.12369298934936523
Test Loss Energy: 11.580735038837611, Test Loss Force: 9.478115583113665, time: 16.610364198684692


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.958492100852966, Training Loss Force: 4.0508993325973135, time: 1.8590266704559326
Validation Loss Energy: 6.004925717871222, Validation Loss Force: 3.770421800273894, time: 0.1170957088470459
Test Loss Energy: 14.164137247076235, Test Loss Force: 9.597238833681965, time: 16.64720845222473


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.253664224226368, Training Loss Force: 4.315811675569077, time: 1.585860013961792
Validation Loss Energy: 3.286474905205899, Validation Loss Force: 4.248757544199082, time: 0.12182044982910156
Test Loss Energy: 12.316389367817067, Test Loss Force: 9.784555682992538, time: 16.807554721832275


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.258479263529598, Training Loss Force: 4.223023621522175, time: 1.6578583717346191
Validation Loss Energy: 2.068705974556232, Validation Loss Force: 3.556504219788506, time: 0.1187584400177002
Test Loss Energy: 11.273553630237084, Test Loss Force: 9.67284972120938, time: 16.643276691436768


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.228167224574168, Training Loss Force: 4.020538829991946, time: 1.6596710681915283
Validation Loss Energy: 8.068832893996277, Validation Loss Force: 4.105614683739403, time: 0.11564922332763672
Test Loss Energy: 11.966487743411001, Test Loss Force: 9.991109882776435, time: 16.75016951560974


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.924969731592185, Training Loss Force: 4.110288474475004, time: 1.634547233581543
Validation Loss Energy: 14.280632276590609, Validation Loss Force: 3.9427892067945836, time: 0.1221916675567627
Test Loss Energy: 14.263917534379237, Test Loss Force: 9.886959595738091, time: 16.78067636489868


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.056059812075807, Training Loss Force: 4.238027914717543, time: 1.622039556503296
Validation Loss Energy: 3.903551117906627, Validation Loss Force: 3.597295759973028, time: 0.1246793270111084
Test Loss Energy: 12.945054809496202, Test Loss Force: 9.70326376176761, time: 16.64061450958252


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.692050153502786, Training Loss Force: 4.066961942554058, time: 1.6271851062774658
Validation Loss Energy: 3.3004703290348982, Validation Loss Force: 3.5997226309944947, time: 0.11861729621887207
Test Loss Energy: 11.19908777507484, Test Loss Force: 9.489267240989667, time: 16.78217339515686

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÖ‚ñÉ‚ñÑ‚ñá‚ñÇ‚ñà‚ñÅ‚ñÉ‚ñÉ‚ñÑ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÉ‚ñÅ
wandb:   test_error_force ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ
wandb:   test_error_total ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ
wandb: train_error_energy ‚ñà‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÉ‚ñÇ
wandb:  train_error_force ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñá‚ñÉ‚ñÜ‚ñÑ‚ñÇ‚ñÜ‚ñÅ‚ñÇ‚ñÜ‚ñÉ‚ñÅ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÖ‚ñà‚ñÇ‚ñÇ
wandb:  valid_error_force ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ
wandb:  valid_error_total ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1410
wandb:                 lr 0.001
wandb:  test_error_energy 11.19909
wandb:   test_error_force 9.48927
wandb:   test_error_total 5.15448
wandb: train_error_energy 8.69205
wandb:  train_error_force 4.06696
wandb:  train_error_total 2.3395
wandb: valid_error_energy 3.30047
wandb:  valid_error_force 3.59972
wandb:  valid_error_total 2.26496
wandb: 
wandb: üöÄ View run al_43_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/qj6jp6p3
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_122748-qj6jp6p3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.2523847818374634, Uncertainty Bias: -0.23131097853183746
Found uncertainty sample after 15 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 151 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 850 steps.
Found uncertainty sample after 1273 steps.
Found uncertainty sample after 2041 steps.
Found uncertainty sample after 429 steps.
Found uncertainty sample after 112 steps.
Found uncertainty sample after 99 steps.
Found uncertainty sample after 2169 steps.
Found uncertainty sample after 648 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 2683 steps.
Found uncertainty sample after 3310 steps.
Found uncertainty sample after 1850 steps.
Found uncertainty sample after 140 steps.
Found uncertainty sample after 1246 steps.
Found uncertainty sample after 943 steps.
Found uncertainty sample after 1385 steps.
Found uncertainty sample after 3556 steps.
Found uncertainty sample after 2462 steps.
Found uncertainty sample after 2506 steps.
Found uncertainty sample after 366 steps.
Found uncertainty sample after 828 steps.
Found uncertainty sample after 724 steps.
Found uncertainty sample after 242 steps.
Found uncertainty sample after 565 steps.
Found uncertainty sample after 3135 steps.
Found uncertainty sample after 145 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 115 steps.
Found uncertainty sample after 2191 steps.
Found uncertainty sample after 574 steps.
Found uncertainty sample after 2556 steps.
Found uncertainty sample after 587 steps.
Found uncertainty sample after 227 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1266 steps.
Found uncertainty sample after 3322 steps.
Found uncertainty sample after 146 steps.
Found uncertainty sample after 229 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 317 steps.
Found uncertainty sample after 216 steps.
Found uncertainty sample after 436 steps.
Found uncertainty sample after 757 steps.
Found uncertainty sample after 775 steps.
Found uncertainty sample after 1128 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 134 steps.
Found uncertainty sample after 2431 steps.
Found uncertainty sample after 219 steps.
Found uncertainty sample after 84 steps.
Found uncertainty sample after 323 steps.
Found uncertainty sample after 445 steps.
Found uncertainty sample after 1161 steps.
Found uncertainty sample after 54 steps.
Found uncertainty sample after 130 steps.
Found uncertainty sample after 592 steps.
Found uncertainty sample after 295 steps.
Found uncertainty sample after 1543 steps.
Found uncertainty sample after 1200 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 99 steps.
Found uncertainty sample after 279 steps.
Found uncertainty sample after 1634 steps.
Found uncertainty sample after 260 steps.
Found uncertainty sample after 641 steps.
Found uncertainty sample after 407 steps.
Found uncertainty sample after 128 steps.
Found uncertainty sample after 152 steps.
Found uncertainty sample after 102 steps.
Found uncertainty sample after 57 steps.
Found uncertainty sample after 374 steps.
Found uncertainty sample after 639 steps.
Found uncertainty sample after 520 steps.
Found uncertainty sample after 319 steps.
Found uncertainty sample after 2174 steps.
Found uncertainty sample after 745 steps.
Found uncertainty sample after 263 steps.
Found uncertainty sample after 425 steps.
Found uncertainty sample after 32 steps.
Found uncertainty sample after 642 steps.
Found uncertainty sample after 218 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 816 steps.
Found uncertainty sample after 1720 steps.
Found uncertainty sample after 799 steps.
Found uncertainty sample after 131 steps.
Found uncertainty sample after 788 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 2057 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_131745-nlvruww9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_5
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nlvruww9
Training model 5. Added 95 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 19.470665419061852, Training Loss Force: 16.335578042922613, time: 1.7165346145629883
Validation Loss Energy: 6.921009964478463, Validation Loss Force: 7.735901104373092, time: 0.12667226791381836
Test Loss Energy: 12.372620163456356, Test Loss Force: 12.412888076159701, time: 16.910764694213867


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.50378842389121, Training Loss Force: 6.538796347782894, time: 1.7172093391418457
Validation Loss Energy: 5.243104428871292, Validation Loss Force: 4.685869547127501, time: 0.12821125984191895
Test Loss Energy: 13.481096671466393, Test Loss Force: 10.294742695970614, time: 17.069357872009277


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.981874731259013, Training Loss Force: 4.746796672060499, time: 1.70511794090271
Validation Loss Energy: 1.956315671504208, Validation Loss Force: 4.1228893560804805, time: 0.12036466598510742
Test Loss Energy: 11.632329527106258, Test Loss Force: 9.937664894992814, time: 16.85900616645813


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.6110918478038, Training Loss Force: 4.502641180599803, time: 1.9261760711669922
Validation Loss Energy: 7.228570386276345, Validation Loss Force: 4.169762547313155, time: 0.1247713565826416
Test Loss Energy: 15.4144260123467, Test Loss Force: 9.648674110013847, time: 16.881983280181885


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 9.545658019114565, Training Loss Force: 4.597326089827032, time: 1.6890499591827393
Validation Loss Energy: 4.53325077849372, Validation Loss Force: 3.9355402127489043, time: 0.12381958961486816
Test Loss Energy: 11.319223263259229, Test Loss Force: 9.401331189549772, time: 17.325254201889038


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.547052644930695, Training Loss Force: 4.341574624090365, time: 1.7013580799102783
Validation Loss Energy: 5.199590424374084, Validation Loss Force: 3.9817140001942204, time: 0.13727712631225586
Test Loss Energy: 13.948375316708043, Test Loss Force: 9.630221086542203, time: 16.854744911193848


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.070891476040535, Training Loss Force: 4.3824521027211105, time: 1.687682867050171
Validation Loss Energy: 5.277737942490608, Validation Loss Force: 4.0071085256107, time: 0.12266683578491211
Test Loss Energy: 13.965257471142937, Test Loss Force: 9.25638592844225, time: 17.03292226791382


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.970686870573879, Training Loss Force: 3.9777719272240533, time: 1.6736905574798584
Validation Loss Energy: 8.475906383800746, Validation Loss Force: 3.8734486987377954, time: 0.13262701034545898
Test Loss Energy: 16.324357969908114, Test Loss Force: 9.508149486636553, time: 17.070589542388916


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.370563280617113, Training Loss Force: 3.9755530007590343, time: 1.7133572101593018
Validation Loss Energy: 2.019949336352727, Validation Loss Force: 3.3082839007000775, time: 0.1244804859161377
Test Loss Energy: 11.089846688457062, Test Loss Force: 9.282462705127012, time: 16.961551904678345


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.8316489839889245, Training Loss Force: 3.8559043219469435, time: 1.7335915565490723
Validation Loss Energy: 11.672395899750589, Validation Loss Force: 3.7938460377526324, time: 0.11918354034423828
Test Loss Energy: 14.008504706345256, Test Loss Force: 9.63858187229673, time: 17.083329439163208


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.062864310181534, Training Loss Force: 3.842880735236525, time: 1.7255210876464844
Validation Loss Energy: 7.325933806348146, Validation Loss Force: 3.55051898448054, time: 0.1256084442138672
Test Loss Energy: 15.016102447694117, Test Loss Force: 9.440727712781188, time: 16.91556739807129


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.650329962748785, Training Loss Force: 3.8561532944779398, time: 1.6995570659637451
Validation Loss Energy: 12.17663641544015, Validation Loss Force: 3.644404535162095, time: 0.1317310333251953
Test Loss Energy: 17.679263177159402, Test Loss Force: 9.407645307769178, time: 17.07903027534485


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.087876345804494, Training Loss Force: 3.9280149620953915, time: 1.715681791305542
Validation Loss Energy: 2.807924174220318, Validation Loss Force: 3.9414983937556403, time: 0.12366724014282227
Test Loss Energy: 10.713992898149849, Test Loss Force: 9.623339863816526, time: 17.095077991485596


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.308419473574041, Training Loss Force: 4.106423247522321, time: 1.717977523803711
Validation Loss Energy: 4.835680235161987, Validation Loss Force: 3.5429251872623917, time: 0.1317300796508789
Test Loss Energy: 10.57227394275899, Test Loss Force: 9.525506292415686, time: 16.916467666625977


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.939403636397937, Training Loss Force: 3.8022637416053824, time: 1.671367883682251
Validation Loss Energy: 6.052189248116708, Validation Loss Force: 3.543821430574751, time: 0.1256415843963623
Test Loss Energy: 14.893420888215154, Test Loss Force: 9.361241934444724, time: 16.994952917099


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.23085873076955, Training Loss Force: 4.129702581869938, time: 1.7595229148864746
Validation Loss Energy: 9.330966592282458, Validation Loss Force: 4.222328052592328, time: 0.12233304977416992
Test Loss Energy: 17.009079401454727, Test Loss Force: 9.626836496871189, time: 17.28889012336731


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.405321184170328, Training Loss Force: 4.270294089780293, time: 1.916799783706665
Validation Loss Energy: 2.4971058801483674, Validation Loss Force: 4.687400397505755, time: 0.11982941627502441
Test Loss Energy: 11.208231843267928, Test Loss Force: 9.883211824529418, time: 16.933372259140015


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.652533804563576, Training Loss Force: 4.183679155739779, time: 1.667855978012085
Validation Loss Energy: 2.043195549849296, Validation Loss Force: 3.7633214378831212, time: 0.13236641883850098
Test Loss Energy: 11.021069430748453, Test Loss Force: 9.41270089531257, time: 17.10019826889038


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.387939652748639, Training Loss Force: 3.8988660927493264, time: 1.6884527206420898
Validation Loss Energy: 2.7754965324951355, Validation Loss Force: 3.6296234232516893, time: 0.12378931045532227
Test Loss Energy: 11.08022155231775, Test Loss Force: 9.307690489824823, time: 16.984123945236206


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 8.05273662467658, Training Loss Force: 3.905996124619384, time: 1.7068731784820557
Validation Loss Energy: 6.109247771422412, Validation Loss Force: 3.793249618445265, time: 0.12367105484008789
Test Loss Energy: 11.035062384232319, Test Loss Force: 9.552282488043298, time: 17.1102397441864

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:                 lr ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  test_error_energy ‚ñÉ‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÑ‚ñÑ‚ñá‚ñÇ‚ñÑ‚ñÖ‚ñà‚ñÅ‚ñÅ‚ñÖ‚ñá‚ñÇ‚ñÅ‚ñÇ‚ñÅ
wandb:   test_error_force ‚ñà‚ñÉ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ
wandb:   test_error_total ‚ñà‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÅ‚ñÉ‚ñÇ
wandb: train_error_energy ‚ñà‚ñÉ‚ñÅ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÉ
wandb:  train_error_force ‚ñà‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:  train_error_total ‚ñà‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: valid_error_energy ‚ñÑ‚ñÉ‚ñÅ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñÅ‚ñà‚ñÖ‚ñà‚ñÇ‚ñÉ‚ñÑ‚ñÜ‚ñÅ‚ñÅ‚ñÇ‚ñÑ
wandb:  valid_error_force ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ
wandb:  valid_error_total ‚ñà‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÑ‚ñÇ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1495
wandb:                 lr 0.001
wandb:  test_error_energy 11.03506
wandb:   test_error_force 9.55228
wandb:   test_error_total 5.27324
wandb: train_error_energy 8.05274
wandb:  train_error_force 3.906
wandb:  train_error_total 2.47752
wandb: valid_error_energy 6.10925
wandb:  valid_error_force 3.79325
wandb:  valid_error_total 2.53385
wandb: 
wandb: üöÄ View run al_43_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/nlvruww9
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241121_131745-nlvruww9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.5710523128509521, Uncertainty Bias: 0.14172819256782532
Found uncertainty sample after 33 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 290 steps.
Found uncertainty sample after 47 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 51 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 35 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 2 steps.
Found uncertainty sample after 68 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 16 steps.
Found uncertainty sample after 50 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 65 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 414 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 13 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 53 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 22 steps.
Found uncertainty sample after 114 steps.
Found uncertainty sample after 4 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 23 steps.
Found uncertainty sample after 7 steps.
Found uncertainty sample after 28 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 88 steps.
Found uncertainty sample after 10 steps.
Found uncertainty sample after 31 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 72 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 40 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 5 steps.
Found uncertainty sample after 63 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 20 steps.
Found uncertainty sample after 64 steps.
Found uncertainty sample after 15 steps.
Found uncertainty sample after 32 steps.
Found uncertainty sample after 62 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 70 steps.
Found uncertainty sample after 87 steps.
Found uncertainty sample after 60 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 12 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 90 steps.
Found uncertainty sample after 1 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 8 steps.
Found uncertainty sample after 61 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 26 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 27 steps.
Found uncertainty sample after 6 steps.
Found uncertainty sample after 9 steps.
Found uncertainty sample after 3 steps.
Found uncertainty sample after 0 steps.
Found uncertainty sample after 18 steps.
Found uncertainty sample after 11 steps.
Found uncertainty sample after 30 steps.
Found uncertainty sample after 17 steps.
Found uncertainty sample after 149 steps.
Found uncertainty sample after 67 steps.
Found uncertainty sample after 158 steps.
Found uncertainty sample after 14 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241121_132545-s2261w6g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_43_6
wandb: ‚≠êÔ∏è View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble
wandb: üöÄ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Ensemble/runs/s2261w6g
Training model 6. Added 117 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 23.785487297155907, Training Loss Force: 12.621751138566449, time: 1.835618257522583
Validation Loss Energy: 3.0396009551083227, Validation Loss Force: 5.576517629187974, time: 0.13121509552001953
Test Loss Energy: 12.594457324190392, Test Loss Force: 10.613495140547686, time: 16.947415113449097


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.4227399166791095, Training Loss Force: 5.236226811333958, time: 1.8022944927215576
Validation Loss Energy: 3.867820958743616, Validation Loss Force: 3.7907828896466764, time: 0.1230623722076416
Test Loss Energy: 10.87857868311328, Test Loss Force: 9.578472338685136, time: 17.11522078514099


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.049375627593582, Training Loss Force: 4.246507610534351, time: 1.8119785785675049
Validation Loss Energy: 2.9717282820614903, Validation Loss Force: 4.755195136351512, time: 0.12627029418945312
Test Loss Energy: 11.225431363023548, Test Loss Force: 9.936103105261346, time: 17.026738166809082


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 8.0701143527044, Training Loss Force: 4.3016267301128535, time: 2.033249855041504
Validation Loss Energy: 5.199610687266363, Validation Loss Force: 3.881811706520551, time: 0.1222071647644043
Test Loss Energy: 13.700903425341998, Test Loss Force: 9.43309073931616, time: 16.97084140777588


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 9.547358632639178, Training Loss Force: 4.0511020659271955, time: 1.8628392219543457
Validation Loss Energy: 3.924135989771067, Validation Loss Force: 4.193546952135432, time: 0.1314694881439209
Test Loss Energy: 11.053598161351365, Test Loss Force: 9.625399066109011, time: 17.122359037399292


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 7.940309460926764, Training Loss Force: 3.89125608474359, time: 1.7968227863311768
Validation Loss Energy: 5.812724613849879, Validation Loss Force: 3.913330969464921, time: 0.1216592788696289
Test Loss Energy: 11.548542144602267, Test Loss Force: 9.353701074775856, time: 16.991749048233032


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.854644269535267, Training Loss Force: 4.187537744267216, time: 1.8099775314331055
Validation Loss Energy: 21.6563771708828, Validation Loss Force: 3.7133255345479554, time: 0.12897014617919922
Test Loss Energy: 27.212619160857095, Test Loss Force: 9.362076479750748, time: 17.119569301605225


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.610951945342812, Training Loss Force: 4.200321215561994, time: 1.8424267768859863
Validation Loss Energy: 5.2132115413687785, Validation Loss Force: 4.620743497995687, time: 0.1272275447845459
Test Loss Energy: 14.065168748525712, Test Loss Force: 9.634630122160704, time: 17.19755506515503

slurmstepd: error: *** JOB 5122422 ON aimat01 CANCELLED AT 2024-11-21T13:28:31 ***
