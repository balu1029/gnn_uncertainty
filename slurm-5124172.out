wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_101105-4olmz3dp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/4olmz3dp
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
72
Uncertainty Slope: 0.044184185564517975, Uncertainty Bias: 0.2551637291908264
0.0014572144 0.0016615391
3.8687816 7.0848565
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 11.451026320906859, Test Loss Force: 12.623542414663762, time: 6.9197447299957275

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.050 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.45103
wandb:   test_error_force 12.62354
wandb:          test_loss 10.20482
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_73 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/4olmz3dp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_101105-4olmz3dp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 801 steps.
Found uncertainty sample 1 after 502 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 667 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1228 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1114 steps.
Found uncertainty sample 9 after 866 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 929 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2936 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1742 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3095 steps.
Found uncertainty sample 21 after 759 steps.
Found uncertainty sample 22 after 2021 steps.
Found uncertainty sample 23 after 644 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2126 steps.
Found uncertainty sample 26 after 2650 steps.
Found uncertainty sample 27 after 3016 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2061 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1713 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1756 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 388 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2012 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1307 steps.
Found uncertainty sample 54 after 508 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2396 steps.
Found uncertainty sample 58 after 1683 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 984 steps.
Found uncertainty sample 61 after 888 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 553 steps.
Found uncertainty sample 64 after 978 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1590 steps.
Found uncertainty sample 69 after 629 steps.
Found uncertainty sample 70 after 730 steps.
Found uncertainty sample 71 after 1782 steps.
Found uncertainty sample 72 after 3654 steps.
Found uncertainty sample 73 after 1531 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1419 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1276 steps.
Found uncertainty sample 78 after 1560 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3003 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1347 steps.
Found uncertainty sample 85 after 3915 steps.
Found uncertainty sample 86 after 1161 steps.
Found uncertainty sample 87 after 1728 steps.
Found uncertainty sample 88 after 340 steps.
Found uncertainty sample 89 after 2677 steps.
Found uncertainty sample 90 after 2681 steps.
Found uncertainty sample 91 after 1165 steps.
Found uncertainty sample 92 after 2172 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1954 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3975 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_104008-sgn1qt1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/sgn1qt1r
Training model 0. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.984426568802441, Training Loss Force: 4.152210816825505, time: 0.6339781284332275
Validation Loss Energy: 1.6669938567801257, Validation Loss Force: 4.307779564033576, time: 0.050642967224121094
Test Loss Energy: 10.595034035701595, Test Loss Force: 12.210026295065898, time: 8.53928804397583


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3835221062259637, Training Loss Force: 3.9774389257795204, time: 0.4616246223449707
Validation Loss Energy: 3.072388652842471, Validation Loss Force: 4.485175619211327, time: 0.03653669357299805
Test Loss Energy: 11.85208693470119, Test Loss Force: 12.38994661628322, time: 8.25227952003479


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.620067143184394, Training Loss Force: 3.9839252780003966, time: 0.4408407211303711
Validation Loss Energy: 2.5770865220087424, Validation Loss Force: 4.3552521806070885, time: 0.04076337814331055
Test Loss Energy: 11.460395291932176, Test Loss Force: 11.814083532237714, time: 8.43004059791565


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.746065073894042, Training Loss Force: 4.416891519558863, time: 0.4375576972961426
Validation Loss Energy: 2.3331573713660614, Validation Loss Force: 4.404005590107978, time: 0.0369870662689209
Test Loss Energy: 11.010072004481508, Test Loss Force: 11.842886152326885, time: 8.64626693725586


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.3786320340624707, Training Loss Force: 3.8891051849133835, time: 0.45798420906066895
Validation Loss Energy: 4.769934275127911, Validation Loss Force: 5.178055200594824, time: 0.04093289375305176
Test Loss Energy: 9.809951889502779, Test Loss Force: 12.154067053193621, time: 8.293073177337646


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 5.324839109817189, Training Loss Force: 4.240701259041338, time: 0.4499642848968506
Validation Loss Energy: 10.898606366826186, Validation Loss Force: 4.663035271550898, time: 0.03955388069152832
Test Loss Energy: 11.229585590527451, Test Loss Force: 12.204354363989806, time: 8.44908094406128


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.8326697228660067, Training Loss Force: 4.2220273915162885, time: 0.44342517852783203
Validation Loss Energy: 1.9197429322930066, Validation Loss Force: 4.99296637176356, time: 0.04885125160217285
Test Loss Energy: 9.89247723924639, Test Loss Force: 11.822325676140709, time: 8.665773868560791


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.4362677955007013, Training Loss Force: 4.267420740099138, time: 0.48285341262817383
Validation Loss Energy: 1.9090100567901414, Validation Loss Force: 4.312502821956997, time: 0.040474653244018555
Test Loss Energy: 10.344937082618717, Test Loss Force: 11.601511427152076, time: 8.468175411224365


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.486353096374455, Training Loss Force: 3.948067446946715, time: 0.42675352096557617
Validation Loss Energy: 2.686392356384088, Validation Loss Force: 4.413016119767092, time: 0.039575815200805664
Test Loss Energy: 9.689906466907592, Test Loss Force: 11.690781222475415, time: 8.361344337463379


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0039127732028224, Training Loss Force: 3.908736851399133, time: 0.504169225692749
Validation Loss Energy: 3.483322112291598, Validation Loss Force: 4.159369242257831, time: 0.04073905944824219
Test Loss Energy: 11.284414978842305, Test Loss Force: 11.627488494691743, time: 8.712056636810303


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.01724769849246, Training Loss Force: 3.769308986476103, time: 0.47263312339782715
Validation Loss Energy: 2.7159781831343675, Validation Loss Force: 4.11718190053206, time: 0.04080700874328613
Test Loss Energy: 9.753131032284854, Test Loss Force: 11.64881110557666, time: 8.838737487792969


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9189303802935145, Training Loss Force: 3.665221370547554, time: 0.4321784973144531
Validation Loss Energy: 2.4859551659931687, Validation Loss Force: 4.056047641179294, time: 0.037442922592163086
Test Loss Energy: 10.644245614366694, Test Loss Force: 11.477562630750077, time: 8.496470928192139


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.894665517306866, Training Loss Force: 3.631140793899609, time: 0.4745044708251953
Validation Loss Energy: 2.8649287002581345, Validation Loss Force: 4.0525726664879445, time: 0.04319357872009277
Test Loss Energy: 9.58858148993089, Test Loss Force: 11.476140299520768, time: 8.229812860488892


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9693098147385304, Training Loss Force: 3.6190443915111468, time: 0.4479787349700928
Validation Loss Energy: 2.272325274044319, Validation Loss Force: 4.075473297470034, time: 0.042687177658081055
Test Loss Energy: 10.580753682801335, Test Loss Force: 11.482758791307164, time: 8.787230014801025


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9222628838429934, Training Loss Force: 3.629844867717314, time: 0.45330333709716797
Validation Loss Energy: 3.026776659652331, Validation Loss Force: 4.073839351277216, time: 0.035578012466430664
Test Loss Energy: 9.535134002656958, Test Loss Force: 11.513548039868551, time: 8.345810413360596


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9639726332387712, Training Loss Force: 3.6789036143463085, time: 0.5001363754272461
Validation Loss Energy: 2.372628372180659, Validation Loss Force: 4.063641995070307, time: 0.04185795783996582
Test Loss Energy: 10.480328652905976, Test Loss Force: 11.461614665481104, time: 8.372413158416748


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.885209175153087, Training Loss Force: 3.65620066408377, time: 0.45662450790405273
Validation Loss Energy: 2.8998875334996512, Validation Loss Force: 4.06547634349446, time: 0.04090714454650879
Test Loss Energy: 9.495255600077614, Test Loss Force: 11.384341719489747, time: 8.50486135482788


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.958201387103545, Training Loss Force: 3.614909301766186, time: 0.4532647132873535
Validation Loss Energy: 2.3082656328810858, Validation Loss Force: 4.038600177580976, time: 0.03710460662841797
Test Loss Energy: 10.369933790370178, Test Loss Force: 11.408469849695878, time: 7.9564409255981445


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.87082952334228, Training Loss Force: 3.5957155430204213, time: 0.4255256652832031
Validation Loss Energy: 2.9288968698311235, Validation Loss Force: 4.051172968236642, time: 0.032788991928100586
Test Loss Energy: 9.466455008492705, Test Loss Force: 11.431493769436388, time: 8.114354372024536


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9227174629044055, Training Loss Force: 3.6254053232738275, time: 0.44121384620666504
Validation Loss Energy: 2.2677707993335123, Validation Loss Force: 4.081274274059744, time: 0.04333066940307617
Test Loss Energy: 10.378200980471766, Test Loss Force: 11.49988127453313, time: 9.150200843811035

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–‡â–†â–‚â–†â–‚â–„â–‚â–†â–‚â–„â–â–„â–â–„â–â–„â–â–„
wandb:   test_error_force â–‡â–ˆâ–„â–„â–†â–‡â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚
wandb:          test_loss â–â–‚â–…â–„â–„â–ˆâ–…â–†â–…â–‡â–ƒâ–…â–„â–…â–‚â–„â–ƒâ–ƒâ–‚â–‚
wandb: train_error_energy â–‡â–ƒâ–â–„â–ƒâ–ˆâ–„â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–†â–„â–„â–ˆâ–„â–†â–†â–‡â–„â–„â–‚â–‚â–â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–‡â–‚â–â–„â–ƒâ–ˆâ–„â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–‚â–‚â–ƒâ–ˆâ–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–
wandb:  valid_error_force â–ƒâ–„â–ƒâ–ƒâ–ˆâ–…â–‡â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–‚â–â–â–ƒâ–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 845
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.3782
wandb:   test_error_force 11.49988
wandb:          test_loss 10.53395
wandb: train_error_energy 2.92272
wandb:  train_error_force 3.62541
wandb:         train_loss 1.06695
wandb: valid_error_energy 2.26777
wandb:  valid_error_force 4.08127
wandb:         valid_loss 1.03877
wandb: 
wandb: ğŸš€ View run al_73_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/sgn1qt1r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_104008-sgn1qt1r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.16490259766578674, Uncertainty Bias: 0.24581125378608704
1.335144e-05 0.0016336441
3.858809 11.501208
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1181 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2608 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 945 steps.
Found uncertainty sample 9 after 1356 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1320 steps.
Found uncertainty sample 14 after 421 steps.
Found uncertainty sample 15 after 1180 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 203 steps.
Found uncertainty sample 19 after 1160 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 855 steps.
Found uncertainty sample 22 after 518 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 967 steps.
Found uncertainty sample 25 after 870 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 432 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2436 steps.
Found uncertainty sample 31 after 1019 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1574 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 690 steps.
Found uncertainty sample 40 after 3066 steps.
Found uncertainty sample 41 after 481 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1557 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2994 steps.
Found uncertainty sample 47 after 2250 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2106 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2082 steps.
Found uncertainty sample 52 after 1122 steps.
Found uncertainty sample 53 after 1556 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1764 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 311 steps.
Found uncertainty sample 61 after 2108 steps.
Found uncertainty sample 62 after 2839 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1059 steps.
Found uncertainty sample 66 after 634 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2902 steps.
Found uncertainty sample 71 after 1545 steps.
Found uncertainty sample 72 after 1303 steps.
Found uncertainty sample 73 after 3577 steps.
Found uncertainty sample 74 after 2625 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1226 steps.
Found uncertainty sample 79 after 680 steps.
Found uncertainty sample 80 after 1246 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 798 steps.
Found uncertainty sample 83 after 2801 steps.
Found uncertainty sample 84 after 3028 steps.
Found uncertainty sample 85 after 1556 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 827 steps.
Found uncertainty sample 88 after 1683 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2609 steps.
Found uncertainty sample 91 after 915 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2054 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2872 steps.
Found uncertainty sample 96 after 2858 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1568 steps.
Found uncertainty sample 99 after 1095 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_111043-uev4o3gv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uev4o3gv
Training model 1. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.15559590880899, Training Loss Force: 4.420833174613911, time: 0.5014481544494629
Validation Loss Energy: 2.1072040782049846, Validation Loss Force: 4.382687246076852, time: 0.04241371154785156
Test Loss Energy: 10.300021899295256, Test Loss Force: 11.504346208267908, time: 8.588073968887329


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.909278645488059, Training Loss Force: 4.309576623328256, time: 0.5141720771789551
Validation Loss Energy: 2.419654982454878, Validation Loss Force: 4.897627459566535, time: 0.04342246055603027
Test Loss Energy: 10.177371168417835, Test Loss Force: 12.057062897547802, time: 8.29610800743103


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.344357674141367, Training Loss Force: 4.196230687921666, time: 0.4799172878265381
Validation Loss Energy: 4.003621972123764, Validation Loss Force: 4.265849627840498, time: 0.04314708709716797
Test Loss Energy: 9.54468455978788, Test Loss Force: 11.192257684646231, time: 8.480543375015259


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.3689249160847345, Training Loss Force: 3.971600598207796, time: 0.6382772922515869
Validation Loss Energy: 2.32113435083169, Validation Loss Force: 4.232728928398616, time: 0.04279685020446777
Test Loss Energy: 10.003736445116326, Test Loss Force: 11.141638044230074, time: 8.189374446868896


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.33197943667572, Training Loss Force: 3.950076937319185, time: 0.49266719818115234
Validation Loss Energy: 2.948425399267282, Validation Loss Force: 4.256905008248579, time: 0.0472254753112793
Test Loss Energy: 10.394175498162033, Test Loss Force: 11.203770019906356, time: 8.343416929244995


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.32087850100334, Training Loss Force: 3.969242508095012, time: 0.4598703384399414
Validation Loss Energy: 4.083533029876036, Validation Loss Force: 4.252972671131494, time: 0.047846317291259766
Test Loss Energy: 9.493371007701361, Test Loss Force: 11.1950382976657, time: 9.740389108657837


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.378729137985805, Training Loss Force: 3.9477253443739793, time: 0.5017590522766113
Validation Loss Energy: 2.265868982158143, Validation Loss Force: 4.225436959207772, time: 0.05170392990112305
Test Loss Energy: 10.023169124228716, Test Loss Force: 11.18991130210908, time: 9.733780145645142


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.236177444227391, Training Loss Force: 3.9480244049419007, time: 0.5090532302856445
Validation Loss Energy: 2.7541452334304117, Validation Loss Force: 4.242965474375207, time: 0.045287132263183594
Test Loss Energy: 10.024773899597609, Test Loss Force: 11.106810155601858, time: 8.570896625518799


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2671862938220078, Training Loss Force: 3.9571854430387225, time: 0.47565555572509766
Validation Loss Energy: 3.879972904713479, Validation Loss Force: 4.248874222831548, time: 0.03496241569519043
Test Loss Energy: 9.572030620552852, Test Loss Force: 11.102630886562586, time: 8.422610521316528


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.237688914437478, Training Loss Force: 3.9501415193239735, time: 0.5201220512390137
Validation Loss Energy: 2.4547006566633063, Validation Loss Force: 4.244423511942743, time: 0.04757285118103027
Test Loss Energy: 9.966989437570357, Test Loss Force: 11.164405864141782, time: 8.874531984329224


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.159766586399712, Training Loss Force: 3.936636937817294, time: 0.4853665828704834
Validation Loss Energy: 2.521605164263645, Validation Loss Force: 4.22677564611309, time: 0.047162771224975586
Test Loss Energy: 9.954112403918087, Test Loss Force: 11.139695399326119, time: 7.996690988540649


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.135340401384055, Training Loss Force: 3.946355324738842, time: 0.43960142135620117
Validation Loss Energy: 3.7310402011213863, Validation Loss Force: 4.246788258272496, time: 0.035657644271850586
Test Loss Energy: 9.414971225261223, Test Loss Force: 11.06237426353468, time: 7.9195239543914795


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.160015582195912, Training Loss Force: 3.95303107297327, time: 0.4946708679199219
Validation Loss Energy: 2.1453475255715606, Validation Loss Force: 4.283968661582934, time: 0.03961515426635742
Test Loss Energy: 9.849772402767412, Test Loss Force: 11.144603372381253, time: 8.323221683502197


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.2023198411282334, Training Loss Force: 3.9442518249845486, time: 0.6293931007385254
Validation Loss Energy: 2.570251915243635, Validation Loss Force: 4.2505339986452935, time: 0.03945159912109375
Test Loss Energy: 10.069784287387735, Test Loss Force: 11.1857512222538, time: 8.463074207305908


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1021732356628995, Training Loss Force: 3.9510079011133703, time: 0.47729969024658203
Validation Loss Energy: 3.8436194946110165, Validation Loss Force: 4.26655326234163, time: 0.04201626777648926
Test Loss Energy: 9.672392598939894, Test Loss Force: 11.225378178906075, time: 8.514312028884888


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.2736941336154666, Training Loss Force: 3.9486012134594866, time: 0.48128747940063477
Validation Loss Energy: 2.3135934375356997, Validation Loss Force: 4.23807254256259, time: 0.038735151290893555
Test Loss Energy: 9.85768119114023, Test Loss Force: 11.090848998060343, time: 8.40805697441101


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.049815747104605, Training Loss Force: 3.945384304355799, time: 0.5232288837432861
Validation Loss Energy: 2.3537353404869776, Validation Loss Force: 4.260544312769623, time: 0.04137611389160156
Test Loss Energy: 9.849128951889263, Test Loss Force: 11.12181884878618, time: 8.571433782577515


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.069184129710025, Training Loss Force: 3.9441307565889203, time: 0.4511086940765381
Validation Loss Energy: 4.006218739703574, Validation Loss Force: 4.284132991412629, time: 0.0452275276184082
Test Loss Energy: 9.423887224290143, Test Loss Force: 11.082588560313173, time: 8.815617084503174


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0979233802961907, Training Loss Force: 3.970296393210218, time: 0.5074646472930908
Validation Loss Energy: 2.154890011820296, Validation Loss Force: 4.258572354813286, time: 0.044030189514160156
Test Loss Energy: 9.752750261050474, Test Loss Force: 11.065214057583068, time: 8.331180334091187


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1305162822899995, Training Loss Force: 3.9585127499601893, time: 0.5008265972137451
Validation Loss Energy: 2.660384154801431, Validation Loss Force: 4.25959084348676, time: 0.04265284538269043
Test Loss Energy: 9.953935625600748, Test Loss Force: 11.111682380349707, time: 8.715696573257446

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–‚â–…â–ˆâ–‚â–…â–…â–‚â–…â–…â–â–„â–†â–ƒâ–„â–„â–â–ƒâ–…
wandb:   test_error_force â–„â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:          test_loss â–„â–â–…â–‡â–‡â–…â–‡â–ˆâ–†â–‡â–†â–…â–‡â–‡â–…â–‡â–†â–„â–ˆâ–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–ˆâ–‚â–„â–ˆâ–‚â–ƒâ–‡â–‚â–‚â–‡â–â–ƒâ–‡â–‚â–‚â–ˆâ–â–ƒ
wandb:  valid_error_force â–ƒâ–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–
wandb:         valid_loss â–‚â–„â–ˆâ–â–ƒâ–ˆâ–â–ƒâ–‡â–‚â–‚â–‡â–â–‚â–‡â–â–‚â–ˆâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 893
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.95394
wandb:   test_error_force 11.11168
wandb:          test_loss 10.96439
wandb: train_error_energy 3.13052
wandb:  train_error_force 3.95851
wandb:         train_loss 1.21258
wandb: valid_error_energy 2.66038
wandb:  valid_error_force 4.25959
wandb:         valid_loss 1.20746
wandb: 
wandb: ğŸš€ View run al_73_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uev4o3gv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_111043-uev4o3gv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.349067360162735, Uncertainty Bias: 0.2268189787864685
6.1035156e-05 0.055938244
3.8525083 14.577389
(48745, 22, 3)
Found uncertainty sample 0 after 3387 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1798 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3508 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3661 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3091 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2018 steps.
Found uncertainty sample 25 after 1951 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1979 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1086 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1849 steps.
Found uncertainty sample 34 after 427 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1887 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1499 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 772 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 610 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1444 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1368 steps.
Found uncertainty sample 58 after 2585 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2438 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3693 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 529 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2027 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2872 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1083 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1022 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3447 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_114835-s3iwgnqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/s3iwgnqx
Training model 2. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.207906034341742, Training Loss Force: 4.577203548703855, time: 0.4884912967681885
Validation Loss Energy: 2.8862042918132427, Validation Loss Force: 4.384589731259658, time: 0.05273580551147461
Test Loss Energy: 9.950133621048261, Test Loss Force: 11.004788156581586, time: 9.597780227661133


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2235088235720495, Training Loss Force: 4.593958296267438, time: 0.5478277206420898
Validation Loss Energy: 3.8964597736162645, Validation Loss Force: 4.515777039936182, time: 0.046485185623168945
Test Loss Energy: 10.459554675480486, Test Loss Force: 10.928275032327788, time: 9.421550989151001


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.52568943211325, Training Loss Force: 4.76932803150426, time: 0.5227696895599365
Validation Loss Energy: 5.239704271012974, Validation Loss Force: 4.862681318466336, time: 0.044692277908325195
Test Loss Energy: 10.649118538598774, Test Loss Force: 10.86592406679262, time: 9.517577409744263


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.467916322558687, Training Loss Force: 4.946563565262535, time: 0.48267054557800293
Validation Loss Energy: 5.223785653770597, Validation Loss Force: 4.766852979486561, time: 0.04164743423461914
Test Loss Energy: 11.71738199678509, Test Loss Force: 11.391635656562883, time: 9.838995218276978


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.040667553105465, Training Loss Force: 4.731303512496348, time: 0.5503673553466797
Validation Loss Energy: 2.3991892385835087, Validation Loss Force: 4.496159442841653, time: 0.04482460021972656
Test Loss Energy: 9.562806960381065, Test Loss Force: 11.080480039719378, time: 9.456178426742554


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.164994021017238, Training Loss Force: 4.58916962736284, time: 0.54154372215271
Validation Loss Energy: 6.231095890780432, Validation Loss Force: 4.649887994498738, time: 0.044567108154296875
Test Loss Energy: 11.992336968549921, Test Loss Force: 11.02829736448983, time: 9.648821115493774


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.3660019252173194, Training Loss Force: 4.5821590121552465, time: 0.5033748149871826
Validation Loss Energy: 5.5495439341885735, Validation Loss Force: 4.44909252945202, time: 0.047582387924194336
Test Loss Energy: 10.453262064069477, Test Loss Force: 10.747590804385014, time: 9.473264932632446


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.41719449861218, Training Loss Force: 4.283495727673476, time: 0.5062739849090576
Validation Loss Energy: 2.3592798022205796, Validation Loss Force: 4.410552953674839, time: 0.044801950454711914
Test Loss Energy: 9.99138942931656, Test Loss Force: 10.808472890347115, time: 9.483973026275635


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.330600041801378, Training Loss Force: 4.260450469241984, time: 0.5165097713470459
Validation Loss Energy: 3.402903814224902, Validation Loss Force: 4.380465008000492, time: 0.05031991004943848
Test Loss Energy: 10.29944909166091, Test Loss Force: 10.872862763805703, time: 9.503478288650513


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.31094831490155, Training Loss Force: 4.242647856034157, time: 0.49990391731262207
Validation Loss Energy: 5.632530052846109, Validation Loss Force: 4.401513031688462, time: 0.04618477821350098
Test Loss Energy: 10.593252985644003, Test Loss Force: 10.739051808702097, time: 9.443115472793579


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.371985152663849, Training Loss Force: 4.213386588759684, time: 0.5238630771636963
Validation Loss Energy: 5.058954373159261, Validation Loss Force: 4.40941555967744, time: 0.045316457748413086
Test Loss Energy: 10.892268792569004, Test Loss Force: 10.944454517549785, time: 9.392678499221802


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.318156944405845, Training Loss Force: 4.199856213281079, time: 0.49889087677001953
Validation Loss Energy: 2.3592864822949573, Validation Loss Force: 4.3593577543197055, time: 0.04642128944396973
Test Loss Energy: 9.66165458339376, Test Loss Force: 10.783621437490444, time: 9.514085054397583


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.178827792156197, Training Loss Force: 4.214252979049997, time: 0.48880863189697266
Validation Loss Energy: 3.6211164598660908, Validation Loss Force: 4.359983454619763, time: 0.04655599594116211
Test Loss Energy: 9.850035101064096, Test Loss Force: 10.839884665881774, time: 9.653175830841064


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.2400316394561886, Training Loss Force: 4.194833833912212, time: 0.5228128433227539
Validation Loss Energy: 5.851741592275929, Validation Loss Force: 4.361489143384526, time: 0.047289133071899414
Test Loss Energy: 11.459252330040323, Test Loss Force: 10.877401311260636, time: 9.516597509384155


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.37749328861368, Training Loss Force: 4.186568677701723, time: 0.5257208347320557
Validation Loss Energy: 4.58641570911373, Validation Loss Force: 4.440203577146583, time: 0.04638314247131348
Test Loss Energy: 10.052479933599248, Test Loss Force: 10.825079536597498, time: 9.783217191696167


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.358050920619625, Training Loss Force: 4.197025067229563, time: 0.48200201988220215
Validation Loss Energy: 3.0808418416293275, Validation Loss Force: 4.406785391725741, time: 0.045285940170288086
Test Loss Energy: 10.43657547143506, Test Loss Force: 10.893230774574919, time: 9.346544742584229


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.322457464955721, Training Loss Force: 4.191515595264858, time: 0.5041699409484863
Validation Loss Energy: 3.539128344320604, Validation Loss Force: 4.293615134322818, time: 0.04439878463745117
Test Loss Energy: 10.05094826365864, Test Loss Force: 10.793846623843177, time: 9.487837791442871


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.401151079152633, Training Loss Force: 4.181145816356537, time: 0.5209476947784424
Validation Loss Energy: 5.25260794801949, Validation Loss Force: 4.374684962310499, time: 0.047042131423950195
Test Loss Energy: 10.296840617046737, Test Loss Force: 10.748877225828814, time: 9.341717004776001


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.336677803817723, Training Loss Force: 4.16181990048668, time: 0.4894566535949707
Validation Loss Energy: 5.365566669733782, Validation Loss Force: 4.319805924605136, time: 0.046395301818847656
Test Loss Energy: 10.842301216013457, Test Loss Force: 10.797014951643792, time: 9.932812452316284


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.346837974277262, Training Loss Force: 4.125240381383897, time: 0.5916843414306641
Validation Loss Energy: 2.3512076003424056, Validation Loss Force: 4.288527144338368, time: 0.05167889595031738
Test Loss Energy: 9.359366206865253, Test Loss Force: 10.699834642553208, time: 8.24613904953003

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–„â–‡â–‚â–ˆâ–„â–ƒâ–ƒâ–„â–…â–‚â–‚â–‡â–ƒâ–„â–ƒâ–ƒâ–…â–
wandb:   test_error_force â–„â–ƒâ–ƒâ–ˆâ–…â–„â–â–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–
wandb:          test_loss â–†â–ˆâ–‡â–…â–ƒâ–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–…â–„â–â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–…â–…â–†â–ˆâ–†â–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–„â–†â–†â–â–ˆâ–‡â–â–ƒâ–‡â–†â–â–ƒâ–‡â–…â–‚â–ƒâ–†â–†â–
wandb:  valid_error_force â–‚â–„â–ˆâ–‡â–„â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–
wandb:         valid_loss â–â–„â–ˆâ–…â–â–ˆâ–†â–â–‚â–…â–„â–â–‚â–…â–ƒâ–‚â–‚â–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 916
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.35937
wandb:   test_error_force 10.69983
wandb:          test_loss 7.22273
wandb: train_error_energy 4.34684
wandb:  train_error_force 4.12524
wandb:         train_loss 1.79897
wandb: valid_error_energy 2.35121
wandb:  valid_error_force 4.28853
wandb:         valid_loss 1.32629
wandb: 
wandb: ğŸš€ View run al_73_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/s3iwgnqx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_114835-s3iwgnqx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.767943859100342, Uncertainty Bias: -0.5018616914749146
0.0002708435 0.022019386
1.7532096 6.0994964
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 3.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1128 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_130836-3feiat68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3feiat68
Training model 4. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.437324326881301, Training Loss Force: 4.528101946084707, time: 0.5203120708465576
Validation Loss Energy: 1.7190644798824741, Validation Loss Force: 4.76407095117734, time: 0.046625614166259766
Test Loss Energy: 9.971115009537053, Test Loss Force: 10.805258489852012, time: 8.865105390548706


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.828883944144036, Training Loss Force: 4.461429137248075, time: 0.5189356803894043
Validation Loss Energy: 1.8633947235628125, Validation Loss Force: 4.539131025299381, time: 0.04128146171569824
Test Loss Energy: 8.999853776420093, Test Loss Force: 10.629053469785495, time: 8.831305503845215


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.981859804983668, Training Loss Force: 4.493333863518785, time: 0.46445488929748535
Validation Loss Energy: 2.8003715707941663, Validation Loss Force: 4.334642815136596, time: 0.04334306716918945
Test Loss Energy: 9.34825316051864, Test Loss Force: 10.565581342950244, time: 9.055842161178589


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.094094130218532, Training Loss Force: 4.253544462463497, time: 0.46385955810546875
Validation Loss Energy: 1.5965923302429912, Validation Loss Force: 4.703015516702233, time: 0.0448613166809082
Test Loss Energy: 9.69710146426829, Test Loss Force: 10.691815941892024, time: 8.813380241394043


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.900387233776099, Training Loss Force: 4.377623004908552, time: 0.437603235244751
Validation Loss Energy: 2.7999030749111347, Validation Loss Force: 4.440673854382783, time: 0.041596412658691406
Test Loss Energy: 9.69911086328374, Test Loss Force: 10.561273718555128, time: 8.846216917037964


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9593570799262294, Training Loss Force: 4.1920918553362725, time: 0.5046236515045166
Validation Loss Energy: 3.365179875529254, Validation Loss Force: 4.2600615660612515, time: 0.04566764831542969
Test Loss Energy: 10.258871326097454, Test Loss Force: 10.567824141199681, time: 8.87065601348877


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.938108185633893, Training Loss Force: 4.113481001118305, time: 0.4870424270629883
Validation Loss Energy: 2.4770964966915776, Validation Loss Force: 4.268452184818102, time: 0.0475926399230957
Test Loss Energy: 9.930440295459588, Test Loss Force: 10.570596537611081, time: 9.369144916534424


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9599550348828787, Training Loss Force: 4.114137928846516, time: 0.5059647560119629
Validation Loss Energy: 2.2558092354834174, Validation Loss Force: 4.279779809609741, time: 0.04317164421081543
Test Loss Energy: 9.379848634601268, Test Loss Force: 10.524522817213624, time: 8.856382131576538


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9475774828378354, Training Loss Force: 4.096110366053578, time: 0.4686150550842285
Validation Loss Energy: 3.4578837210533697, Validation Loss Force: 4.2532959867313815, time: 0.04092979431152344
Test Loss Energy: 9.60050992037891, Test Loss Force: 10.489652763676137, time: 8.876367568969727


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.988142541627087, Training Loss Force: 4.094182366057946, time: 0.49603796005249023
Validation Loss Energy: 2.5178908202404235, Validation Loss Force: 4.256721974210627, time: 0.04228854179382324
Test Loss Energy: 9.428429945334303, Test Loss Force: 10.504071087508764, time: 8.946042776107788


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9784843211701935, Training Loss Force: 4.100753823962046, time: 0.48046088218688965
Validation Loss Energy: 2.278034288276762, Validation Loss Force: 4.27624204221924, time: 0.0392298698425293
Test Loss Energy: 10.160977053455303, Test Loss Force: 10.519253751747062, time: 8.743651628494263


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0091451561657805, Training Loss Force: 4.097336996630769, time: 0.47885918617248535
Validation Loss Energy: 3.808358054000184, Validation Loss Force: 4.2494509359195005, time: 0.04453253746032715
Test Loss Energy: 10.685656591552917, Test Loss Force: 10.490771201650958, time: 8.821863889694214


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.955635019265364, Training Loss Force: 4.076386801480326, time: 0.4534897804260254
Validation Loss Energy: 2.8747898260546925, Validation Loss Force: 4.244021816803489, time: 0.042101383209228516
Test Loss Energy: 10.0774738107712, Test Loss Force: 10.48196406568406, time: 9.029300928115845


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.983186022416815, Training Loss Force: 4.081636779429315, time: 0.4795536994934082
Validation Loss Energy: 1.9220292990833932, Validation Loss Force: 4.295449482746971, time: 0.04499101638793945
Test Loss Energy: 9.325330866510008, Test Loss Force: 10.391289076495005, time: 8.813232421875


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9114827067874915, Training Loss Force: 4.097289552746194, time: 0.49100780487060547
Validation Loss Energy: 3.41231492567754, Validation Loss Force: 4.305574248812308, time: 0.04529595375061035
Test Loss Energy: 9.557223723905091, Test Loss Force: 10.446862515509688, time: 8.852225303649902


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0196437453358977, Training Loss Force: 4.082268852673894, time: 0.5932071208953857
Validation Loss Energy: 2.4091993300386925, Validation Loss Force: 4.245138725239463, time: 0.042949676513671875
Test Loss Energy: 9.37709050300489, Test Loss Force: 10.36657948370301, time: 9.050102233886719


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9302337216355485, Training Loss Force: 4.091649711835671, time: 0.47530698776245117
Validation Loss Energy: 2.5560759067372882, Validation Loss Force: 4.27970053939379, time: 0.04173469543457031
Test Loss Energy: 10.120377417351648, Test Loss Force: 10.38187899444999, time: 8.845425128936768


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.990521488873578, Training Loss Force: 4.076759772299754, time: 0.4832179546356201
Validation Loss Energy: 3.5881275805585973, Validation Loss Force: 4.256507321153952, time: 0.044156789779663086
Test Loss Energy: 10.674042458021471, Test Loss Force: 10.398262267406984, time: 9.212309837341309


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.980253304682648, Training Loss Force: 4.067418870732302, time: 0.4875516891479492
Validation Loss Energy: 2.580905075192258, Validation Loss Force: 4.272587150857981, time: 0.05017828941345215
Test Loss Energy: 9.996595611151022, Test Loss Force: 10.373511904010956, time: 8.902491807937622


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9945142576290427, Training Loss Force: 4.071420841866091, time: 0.5552186965942383
Validation Loss Energy: 2.013703522476739, Validation Loss Force: 4.247378776847497, time: 0.06742095947265625
Test Loss Energy: 9.365690947918468, Test Loss Force: 10.349231468109009, time: 8.923109292984009

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‚â–„â–„â–†â–…â–ƒâ–ƒâ–ƒâ–†â–ˆâ–…â–‚â–ƒâ–ƒâ–†â–ˆâ–…â–ƒ
wandb:   test_error_force â–ˆâ–…â–„â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–
wandb:          test_loss â–„â–…â–†â–ˆâ–…â–†â–„â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–â–ƒâ–…â–‚â–‚
wandb: train_error_energy â–ˆâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‡â–‡â–„â–†â–ƒâ–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–…â–â–…â–‡â–„â–ƒâ–‡â–„â–ƒâ–ˆâ–…â–‚â–‡â–„â–„â–‡â–„â–‚
wandb:  valid_error_force â–ˆâ–…â–‚â–‡â–„â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–
wandb:         valid_loss â–„â–‚â–„â–‚â–…â–†â–ƒâ–‚â–‡â–ƒâ–‚â–ˆâ–„â–â–†â–‚â–ƒâ–‡â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 917
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.36569
wandb:   test_error_force 10.34923
wandb:          test_loss 8.14535
wandb: train_error_energy 2.99451
wandb:  train_error_force 4.07142
wandb:         train_loss 1.38048
wandb: valid_error_energy 2.0137
wandb:  valid_error_force 4.24738
wandb:         valid_loss 1.05633
wandb: 
wandb: ğŸš€ View run al_73_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3feiat68
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_130836-3feiat68/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.590474009513855, Uncertainty Bias: 0.07543489336967468
7.6293945e-05 0.009707451
3.4549375 13.540712
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3582 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2994 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2747 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_135107-u4mnl2ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/u4mnl2ne
Training model 5. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.935993597816213, Training Loss Force: 4.609943192132837, time: 0.505396842956543
Validation Loss Energy: 5.344806779920642, Validation Loss Force: 5.1104163301512155, time: 0.03983640670776367
Test Loss Energy: 12.527487654970987, Test Loss Force: 11.014537068786668, time: 7.747786283493042


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2375579068260936, Training Loss Force: 4.326800438530006, time: 0.48043298721313477
Validation Loss Energy: 1.953903941984664, Validation Loss Force: 4.298551263949745, time: 0.03884387016296387
Test Loss Energy: 9.145843041054112, Test Loss Force: 10.355230375419115, time: 7.7045204639434814


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9682616075545116, Training Loss Force: 4.093567522798315, time: 0.47272419929504395
Validation Loss Energy: 3.240320378641706, Validation Loss Force: 4.286153491242778, time: 0.03567767143249512
Test Loss Energy: 9.475878683847887, Test Loss Force: 10.35784877338287, time: 7.649429559707642


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.01966453802718, Training Loss Force: 4.080603847974342, time: 0.47389984130859375
Validation Loss Energy: 2.671990338694625, Validation Loss Force: 4.2610649132328025, time: 0.03652620315551758
Test Loss Energy: 9.215115048620449, Test Loss Force: 10.306720220884987, time: 7.8910181522369385


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.982979354736408, Training Loss Force: 4.096149294762884, time: 0.4680216312408447
Validation Loss Energy: 2.267016841605401, Validation Loss Force: 4.325304516494677, time: 0.03625297546386719
Test Loss Energy: 9.781470551846006, Test Loss Force: 10.45858249965775, time: 7.987722873687744


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9345282493141016, Training Loss Force: 4.082750248010897, time: 0.48918581008911133
Validation Loss Energy: 3.7963152159118256, Validation Loss Force: 4.32630830900452, time: 0.03673100471496582
Test Loss Energy: 10.447869222537147, Test Loss Force: 10.458011617936645, time: 7.733996391296387


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9693584143413814, Training Loss Force: 4.0790749785836615, time: 0.4520702362060547
Validation Loss Energy: 2.7715641953780508, Validation Loss Force: 4.267056939949719, time: 0.03899669647216797
Test Loss Energy: 10.421031402349044, Test Loss Force: 10.362523748241642, time: 7.921738862991333


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.110410557407479, Training Loss Force: 4.0643660460286455, time: 0.45676112174987793
Validation Loss Energy: 2.403530396252517, Validation Loss Force: 4.232352617541998, time: 0.04183626174926758
Test Loss Energy: 9.380981617184803, Test Loss Force: 10.377189572910293, time: 7.760090351104736


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0121788620358716, Training Loss Force: 4.052604922801118, time: 0.4586293697357178
Validation Loss Energy: 3.6901209601816745, Validation Loss Force: 4.267747659640387, time: 0.037352561950683594
Test Loss Energy: 9.519911024810987, Test Loss Force: 10.297988992946516, time: 7.699939966201782


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.993875634840275, Training Loss Force: 4.051615288977659, time: 0.45905613899230957
Validation Loss Energy: 2.582541916083973, Validation Loss Force: 4.232471522865923, time: 0.037989139556884766
Test Loss Energy: 9.288900753298712, Test Loss Force: 10.306956833083193, time: 8.62916111946106


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.991591602236798, Training Loss Force: 4.061192795708276, time: 0.4795410633087158
Validation Loss Energy: 2.1918766929737767, Validation Loss Force: 4.266130636302659, time: 0.04136490821838379
Test Loss Energy: 9.905547834174245, Test Loss Force: 10.390742769986444, time: 9.998024702072144


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9241951186759008, Training Loss Force: 4.040351892717251, time: 0.4740121364593506
Validation Loss Energy: 3.699706198906428, Validation Loss Force: 4.230806848330967, time: 0.04762554168701172
Test Loss Energy: 10.687453510576026, Test Loss Force: 10.392756892852047, time: 9.004753351211548


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.937519575103125, Training Loss Force: 4.053448224604472, time: 0.5022943019866943
Validation Loss Energy: 2.764940456294137, Validation Loss Force: 4.241588043038498, time: 0.04106307029724121
Test Loss Energy: 9.617362467978047, Test Loss Force: 10.364130430870867, time: 8.43521761894226


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9715899239002823, Training Loss Force: 4.039972694839983, time: 0.4799022674560547
Validation Loss Energy: 2.2371197233891147, Validation Loss Force: 4.247004692682338, time: 0.04053235054016113
Test Loss Energy: 9.252994423203834, Test Loss Force: 10.439992209401195, time: 8.497345924377441


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0342010363634135, Training Loss Force: 4.04115251882705, time: 0.4823465347290039
Validation Loss Energy: 3.519150468547963, Validation Loss Force: 4.254046381753158, time: 0.04812264442443848
Test Loss Energy: 9.461872603376673, Test Loss Force: 10.392828240243306, time: 8.307075023651123


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.020352574170727, Training Loss Force: 4.034741014152191, time: 0.4630911350250244
Validation Loss Energy: 2.491233092759095, Validation Loss Force: 4.226882972641428, time: 0.03772592544555664
Test Loss Energy: 9.11396428984881, Test Loss Force: 10.327141774840248, time: 8.633591175079346


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0449178681704026, Training Loss Force: 4.060922928381658, time: 0.4861929416656494
Validation Loss Energy: 2.3718797585120495, Validation Loss Force: 4.282162369471168, time: 0.03821372985839844
Test Loss Energy: 9.701727288701973, Test Loss Force: 10.33649047014941, time: 8.526253700256348


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0221143017403214, Training Loss Force: 4.073636461294044, time: 0.6179370880126953
Validation Loss Energy: 3.9432461238820276, Validation Loss Force: 4.244461811035842, time: 0.03814053535461426
Test Loss Energy: 10.125752426699393, Test Loss Force: 10.343634517078934, time: 8.379602670669556


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9900318202260667, Training Loss Force: 4.053355509779055, time: 0.4555187225341797
Validation Loss Energy: 2.9217892706931083, Validation Loss Force: 4.28842916991416, time: 0.03920936584472656
Test Loss Energy: 10.442021389830614, Test Loss Force: 10.471655113763408, time: 8.406062602996826


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0608007930843373, Training Loss Force: 4.065293163569826, time: 0.47557640075683594
Validation Loss Energy: 2.10396179277113, Validation Loss Force: 4.2440921802536025, time: 0.04065561294555664
Test Loss Energy: 9.276859407443371, Test Loss Force: 10.321689188028385, time: 8.467475414276123

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–â–‚â–„â–„â–‚â–‚â–â–ƒâ–„â–‚â–â–‚â–â–‚â–ƒâ–„â–
wandb:   test_error_force â–ˆâ–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–ƒâ–
wandb:          test_loss â–ˆâ–â–ƒâ–‚â–ƒâ–…â–…â–‚â–ƒâ–‚â–ƒâ–…â–‚â–â–‚â–â–â–‚â–„â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–â–„â–‚â–‚â–…â–ƒâ–‚â–…â–‚â–â–…â–ƒâ–‚â–„â–‚â–‚â–…â–ƒâ–
wandb:  valid_error_force â–ˆâ–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–ˆâ–â–ƒâ–‚â–‚â–„â–‚â–‚â–„â–‚â–â–„â–‚â–â–„â–‚â–‚â–…â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 919
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.27686
wandb:   test_error_force 10.32169
wandb:          test_loss 7.56679
wandb: train_error_energy 3.0608
wandb:  train_error_force 4.06529
wandb:         train_loss 1.36645
wandb: valid_error_energy 2.10396
wandb:  valid_error_force 4.24409
wandb:         valid_loss 1.07026
wandb: 
wandb: ğŸš€ View run al_73_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/u4mnl2ne
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_135107-u4mnl2ne/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.332857608795166, Uncertainty Bias: -0.028392165899276733
0.0004696846 0.024458885
2.9690912 11.450408
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2746 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_143329-d0rmiei7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/d0rmiei7
Training model 6. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.835177632508397, Training Loss Force: 4.478455003692441, time: 0.5014193058013916
Validation Loss Energy: 1.6110532439215524, Validation Loss Force: 4.4328505966097556, time: 0.05028724670410156
Test Loss Energy: 9.710252052212462, Test Loss Force: 10.402399954440511, time: 9.639745712280273


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.060394905622543, Training Loss Force: 4.385728783758283, time: 0.5188119411468506
Validation Loss Energy: 4.704624078612414, Validation Loss Force: 4.49722691872723, time: 0.044562578201293945
Test Loss Energy: 10.840191473653878, Test Loss Force: 10.449412779046405, time: 9.631990671157837


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.731884534378103, Training Loss Force: 4.577605397408037, time: 0.5867946147918701
Validation Loss Energy: 2.8128771153677627, Validation Loss Force: 4.615512777088698, time: 0.048319339752197266
Test Loss Energy: 9.34436656500684, Test Loss Force: 10.573365963546129, time: 9.993642330169678


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9295445606289023, Training Loss Force: 4.220572605828298, time: 0.5112142562866211
Validation Loss Energy: 2.885338999512167, Validation Loss Force: 4.260825321231784, time: 0.044408321380615234
Test Loss Energy: 9.179770754102805, Test Loss Force: 10.339137103959839, time: 9.572442770004272


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9236637955416094, Training Loss Force: 4.027360929405531, time: 0.4990561008453369
Validation Loss Energy: 2.024675099304039, Validation Loss Force: 4.210073233477047, time: 0.05105781555175781
Test Loss Energy: 9.851525841850908, Test Loss Force: 10.343051557596825, time: 9.997897386550903


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.96645910465735, Training Loss Force: 4.018992539172041, time: 0.5187692642211914
Validation Loss Energy: 3.533130305536747, Validation Loss Force: 4.234431011350088, time: 0.047905921936035156
Test Loss Energy: 10.633160850499035, Test Loss Force: 10.43522037462975, time: 8.850075721740723


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.954929503593861, Training Loss Force: 4.032806295690949, time: 0.5077807903289795
Validation Loss Energy: 2.759081808395631, Validation Loss Force: 4.253168619979911, time: 0.047751665115356445
Test Loss Energy: 10.150122326634106, Test Loss Force: 10.414212969990905, time: 8.63660192489624


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.899104310135343, Training Loss Force: 4.027608391609121, time: 0.49586057662963867
Validation Loss Energy: 2.04052736114093, Validation Loss Force: 4.228437203280003, time: 0.04793357849121094
Test Loss Energy: 9.126474294800166, Test Loss Force: 10.364910206561834, time: 8.846730709075928


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.931739018809746, Training Loss Force: 4.00690169668712, time: 0.5126078128814697
Validation Loss Energy: 3.4670581352038865, Validation Loss Force: 4.236082325736288, time: 0.04121661186218262
Test Loss Energy: 9.304642128232544, Test Loss Force: 10.327744235942633, time: 8.804131031036377


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9159916341405867, Training Loss Force: 4.010727114222927, time: 0.5105886459350586
Validation Loss Energy: 2.4781412603242705, Validation Loss Force: 4.214322651457933, time: 0.04558205604553223
Test Loss Energy: 9.152477690926178, Test Loss Force: 10.312461834579876, time: 8.514094352722168


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.906159121329281, Training Loss Force: 4.014799825040903, time: 0.5114507675170898
Validation Loss Energy: 2.201561687475906, Validation Loss Force: 4.244939659023004, time: 0.04285478591918945
Test Loss Energy: 9.878242138312459, Test Loss Force: 10.40492045259171, time: 8.804730415344238


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.936885017945833, Training Loss Force: 4.01057748823511, time: 0.503131628036499
Validation Loss Energy: 3.7102509189809845, Validation Loss Force: 4.220357430650868, time: 0.04890251159667969
Test Loss Energy: 10.476948190191907, Test Loss Force: 10.399913502518308, time: 8.550784587860107


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.008914547713063, Training Loss Force: 4.018918459450665, time: 0.47957396507263184
Validation Loss Energy: 2.6555845213609572, Validation Loss Force: 4.21354909884498, time: 0.04649019241333008
Test Loss Energy: 10.077536633781337, Test Loss Force: 10.410756659870373, time: 8.789221286773682


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0095309650132087, Training Loss Force: 4.008870299249773, time: 0.5103645324707031
Validation Loss Energy: 1.9196086627980122, Validation Loss Force: 4.230436772210435, time: 0.0438227653503418
Test Loss Energy: 9.08938110318328, Test Loss Force: 10.372942230065949, time: 9.17484998703003


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.8944167906098444, Training Loss Force: 4.012167591640919, time: 0.5154221057891846
Validation Loss Energy: 2.996017589172158, Validation Loss Force: 4.249591662819727, time: 0.046834468841552734
Test Loss Energy: 9.208551037328961, Test Loss Force: 10.337233033279446, time: 8.648228883743286


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.91183936517242, Training Loss Force: 4.01311560936883, time: 0.5243136882781982
Validation Loss Energy: 2.2871033799212546, Validation Loss Force: 4.21144443007767, time: 0.043367624282836914
Test Loss Energy: 9.153984132802293, Test Loss Force: 10.327224966831103, time: 8.894946813583374


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8892682192612096, Training Loss Force: 4.023252491707004, time: 0.4673922061920166
Validation Loss Energy: 2.292914599291678, Validation Loss Force: 4.219004938258502, time: 0.04340028762817383
Test Loss Energy: 10.018462639937084, Test Loss Force: 10.387335717545254, time: 8.570321083068848


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8984460425531324, Training Loss Force: 4.002000050064826, time: 0.5104775428771973
Validation Loss Energy: 3.507423152639384, Validation Loss Force: 4.229753177932436, time: 0.045371055603027344
Test Loss Energy: 10.329546158609592, Test Loss Force: 10.408563529664356, time: 8.482239723205566


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9859079876434835, Training Loss Force: 4.012121376275769, time: 0.5033507347106934
Validation Loss Energy: 2.7046643638297767, Validation Loss Force: 4.231161782949576, time: 0.04697394371032715
Test Loss Energy: 10.181243149372497, Test Loss Force: 10.387784772429972, time: 10.060293197631836


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0625760382067386, Training Loss Force: 4.007795575099585, time: 0.49724459648132324
Validation Loss Energy: 1.978958228946167, Validation Loss Force: 4.208530136295767, time: 0.049010515213012695
Test Loss Energy: 9.074665092852884, Test Loss Force: 10.323800525212004, time: 10.093756675720215

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–‚â–â–„â–‡â–…â–â–‚â–â–„â–‡â–…â–â–‚â–â–…â–†â–…â–
wandb:   test_error_force â–ƒâ–…â–ˆâ–‚â–‚â–„â–„â–‚â–â–â–ƒâ–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–ƒâ–
wandb:          test_loss â–ƒâ–ˆâ–…â–„â–„â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–‡â–†â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–„â–„â–‚â–…â–„â–‚â–…â–ƒâ–‚â–†â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–ƒâ–‚
wandb:  valid_error_force â–…â–†â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–ƒâ–ƒâ–â–„â–‚â–â–„â–‚â–â–„â–‚â–â–ƒâ–â–â–„â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 920
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.07467
wandb:   test_error_force 10.3238
wandb:          test_loss 7.32854
wandb: train_error_energy 3.06258
wandb:  train_error_force 4.0078
wandb:         train_loss 1.33808
wandb: valid_error_energy 1.97896
wandb:  valid_error_force 4.20853
wandb:         valid_loss 1.01825
wandb: 
wandb: ğŸš€ View run al_73_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/d0rmiei7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_143329-d0rmiei7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.696397542953491, Uncertainty Bias: -0.07505148649215698
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:925: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
4.9591064e-05 0.006954193
2.7268949 11.273825
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2703 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2667 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2510 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2743 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2147 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2880 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2725 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1889 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_151502-bznvp3xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bznvp3xx
Training model 7. Added 8 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.622752182275388, Training Loss Force: 4.387237989159902, time: 0.4929773807525635
Validation Loss Energy: 2.005179302232331, Validation Loss Force: 4.329036896718718, time: 0.04907703399658203
Test Loss Energy: 9.017353584754808, Test Loss Force: 10.439025517534807, time: 8.453581809997559


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.5978870738953153, Training Loss Force: 4.5665870830948325, time: 0.48716092109680176
Validation Loss Energy: 4.295140417972423, Validation Loss Force: 4.578312778893418, time: 0.040245771408081055
Test Loss Energy: 10.176827184196911, Test Loss Force: 10.350410336857903, time: 7.9890525341033936


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.8839811553820534, Training Loss Force: 4.137603617338506, time: 0.49558234214782715
Validation Loss Energy: 2.5790526905672846, Validation Loss Force: 4.282369006438589, time: 0.04486417770385742
Test Loss Energy: 10.277791166689981, Test Loss Force: 10.274854475423096, time: 8.334125757217407


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9352734615195493, Training Loss Force: 4.052630391544465, time: 0.605351448059082
Validation Loss Energy: 2.3260707031277637, Validation Loss Force: 4.299978127836851, time: 0.06029248237609863
Test Loss Energy: 9.191596747417242, Test Loss Force: 10.327330332471986, time: 7.9827721118927


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.8309854110825925, Training Loss Force: 4.049542738315087, time: 0.4892153739929199
Validation Loss Energy: 3.460338425718078, Validation Loss Force: 4.270258922268161, time: 0.038818359375
Test Loss Energy: 9.34536030825994, Test Loss Force: 10.276934461723611, time: 7.937709331512451


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.945786570253632, Training Loss Force: 4.036653066430026, time: 0.46767592430114746
Validation Loss Energy: 2.3658140283078306, Validation Loss Force: 4.259112550161307, time: 0.03861498832702637
Test Loss Energy: 9.146384581743465, Test Loss Force: 10.300887245223457, time: 7.911578178405762


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8517643352685855, Training Loss Force: 4.020788051025847, time: 0.4723391532897949
Validation Loss Energy: 2.4422222777255134, Validation Loss Force: 4.234123727928707, time: 0.04158926010131836
Test Loss Energy: 9.834759060344586, Test Loss Force: 10.313137699557156, time: 8.124180316925049


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.914131148965649, Training Loss Force: 4.025606941508319, time: 0.46169614791870117
Validation Loss Energy: 3.740735215735082, Validation Loss Force: 4.262910395114251, time: 0.0392303466796875
Test Loss Energy: 10.562583194999085, Test Loss Force: 10.383908902343006, time: 7.935896635055542


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.850930458512702, Training Loss Force: 4.051290046137922, time: 0.46201038360595703
Validation Loss Energy: 2.8349877162201005, Validation Loss Force: 4.241735895351394, time: 0.03761172294616699
Test Loss Energy: 10.216202037406942, Test Loss Force: 10.363213668188676, time: 7.945054292678833


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9324929803769804, Training Loss Force: 4.025807842825672, time: 0.45177674293518066
Validation Loss Energy: 1.8182063584228, Validation Loss Force: 4.251655360464185, time: 0.04079079627990723
Test Loss Energy: 8.98079679961304, Test Loss Force: 10.316959830602498, time: 7.972645998001099


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.929995861079097, Training Loss Force: 4.022125655298421, time: 0.4491236209869385
Validation Loss Energy: 3.38293306386493, Validation Loss Force: 4.255231872286077, time: 0.04145312309265137
Test Loss Energy: 9.16246829358496, Test Loss Force: 10.31231053614135, time: 8.126400709152222


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9867358830454127, Training Loss Force: 4.02506911873844, time: 0.46939897537231445
Validation Loss Energy: 2.5387386643662047, Validation Loss Force: 4.249523971399364, time: 0.04008817672729492
Test Loss Energy: 9.125884083998226, Test Loss Force: 10.337608581698255, time: 7.992307662963867


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.905991013802351, Training Loss Force: 4.01621001945505, time: 0.4747011661529541
Validation Loss Energy: 2.3188384092680288, Validation Loss Force: 4.254033466942694, time: 0.0403437614440918
Test Loss Energy: 10.165783251555256, Test Loss Force: 10.38572970642089, time: 7.881702184677124


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9465394875793542, Training Loss Force: 4.045445687455987, time: 0.47368335723876953
Validation Loss Energy: 3.860503605270137, Validation Loss Force: 4.273734342297801, time: 0.04036974906921387
Test Loss Energy: 10.582219563918681, Test Loss Force: 10.40468050618535, time: 8.507540702819824


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.8865712275309923, Training Loss Force: 4.02741048480787, time: 0.47644901275634766
Validation Loss Energy: 2.7228735785763134, Validation Loss Force: 4.260543867431331, time: 0.040131330490112305
Test Loss Energy: 10.097720740820547, Test Loss Force: 10.380361477406927, time: 8.849362134933472


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.97909682256467, Training Loss Force: 4.040489494571188, time: 0.5256142616271973
Validation Loss Energy: 2.115509192009799, Validation Loss Force: 4.239860575804391, time: 0.043707847595214844
Test Loss Energy: 9.092045079539336, Test Loss Force: 10.31604563735904, time: 9.943582773208618


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9339600091710634, Training Loss Force: 4.02833779430521, time: 0.4967803955078125
Validation Loss Energy: 3.4458057012399546, Validation Loss Force: 4.229542978258681, time: 0.04262518882751465
Test Loss Energy: 9.071240931027473, Test Loss Force: 10.31109299057787, time: 9.479583978652954


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.985868997508207, Training Loss Force: 4.018263259327896, time: 0.49263882637023926
Validation Loss Energy: 2.3649097689062177, Validation Loss Force: 4.282968877117718, time: 0.04528665542602539
Test Loss Energy: 9.16051331910568, Test Loss Force: 10.365212239188278, time: 8.585115671157837


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9996832147218995, Training Loss Force: 4.025210552037335, time: 0.48130154609680176
Validation Loss Energy: 2.3085314998413233, Validation Loss Force: 4.26704536115413, time: 0.03992462158203125
Test Loss Energy: 9.883235784195842, Test Loss Force: 10.364509574638607, time: 8.44633936882019


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.907239696303236, Training Loss Force: 4.031794947786638, time: 0.48557066917419434
Validation Loss Energy: 3.9223459525069533, Validation Loss Force: 4.253279954552875, time: 0.04319405555725098
Test Loss Energy: 11.000757084934099, Test Loss Force: 10.409612886576813, time: 8.371692657470703

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–…â–‚â–‚â–‚â–„â–†â–…â–â–‚â–‚â–…â–‡â–…â–â–â–‚â–„â–ˆ
wandb:   test_error_force â–ˆâ–„â–â–ƒâ–â–‚â–ƒâ–†â–…â–ƒâ–ƒâ–„â–†â–‡â–…â–ƒâ–ƒâ–…â–…â–‡
wandb:          test_loss â–â–ˆâ–†â–„â–„â–ƒâ–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–†â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–ƒâ–‚â–†â–ƒâ–ƒâ–†â–„â–â–…â–ƒâ–‚â–‡â–„â–‚â–†â–ƒâ–‚â–‡
wandb:  valid_error_force â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–
wandb:         valid_loss â–‚â–ˆâ–‚â–‚â–„â–‚â–‚â–…â–ƒâ–â–„â–‚â–‚â–…â–‚â–â–„â–‚â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 927
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.00076
wandb:   test_error_force 10.40961
wandb:          test_loss 8.03358
wandb: train_error_energy 2.90724
wandb:  train_error_force 4.03179
wandb:         train_loss 1.28207
wandb: valid_error_energy 3.92235
wandb:  valid_error_force 4.25328
wandb:         valid_loss 1.7368
wandb: 
wandb: ğŸš€ View run al_73_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bznvp3xx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_151502-bznvp3xx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.992623805999756, Uncertainty Bias: -0.1358906626701355
3.0517578e-05 0.014289141
2.3793511 9.275897
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1619 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 518 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3803 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2216 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1040 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1114 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 953 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 385 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1286 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3566 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1055 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1622 steps.
Found uncertainty sample 75 after 1728 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_155439-a0zanv9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a0zanv9r
Training model 8. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.840747928196075, Training Loss Force: 4.670457286945267, time: 0.4929802417755127
Validation Loss Energy: 6.019714289198015, Validation Loss Force: 4.556985528096455, time: 0.040441036224365234
Test Loss Energy: 12.57110084633173, Test Loss Force: 10.685649400855054, time: 7.788430452346802


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.31385343279508, Training Loss Force: 4.215232047094512, time: 0.5392570495605469
Validation Loss Energy: 3.9005969663476026, Validation Loss Force: 4.366288108817562, time: 0.03916478157043457
Test Loss Energy: 10.365625834885863, Test Loss Force: 10.400362384863584, time: 7.818220853805542


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.466906643777175, Training Loss Force: 4.161957169872546, time: 0.4773991107940674
Validation Loss Energy: 4.825963621641136, Validation Loss Force: 4.312936581453264, time: 0.03697538375854492
Test Loss Energy: 9.519826788257017, Test Loss Force: 10.274611982894145, time: 8.127736568450928


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.389957185866858, Training Loss Force: 4.11662356507095, time: 0.491619348526001
Validation Loss Energy: 3.2082722764757574, Validation Loss Force: 4.335734339289934, time: 0.03708958625793457
Test Loss Energy: 9.242791317236568, Test Loss Force: 10.291936654367843, time: 7.980025053024292


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.295951044998174, Training Loss Force: 4.128456871492991, time: 0.48775720596313477
Validation Loss Energy: 5.5823675929897885, Validation Loss Force: 4.306710752133123, time: 0.03741168975830078
Test Loss Energy: 11.69301306213861, Test Loss Force: 10.33821469877154, time: 7.850617408752441


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.366580213625495, Training Loss Force: 4.174135168132484, time: 0.4610733985900879
Validation Loss Energy: 3.7941081193373893, Validation Loss Force: 4.290412261327792, time: 0.04043078422546387
Test Loss Energy: 10.915837587207017, Test Loss Force: 10.343321241409333, time: 7.858919620513916


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.247507234677782, Training Loss Force: 4.116374168205207, time: 0.48011136054992676
Validation Loss Energy: 4.681620129146615, Validation Loss Force: 4.385684372781039, time: 0.03951430320739746
Test Loss Energy: 9.445620726200298, Test Loss Force: 10.186234253796522, time: 8.007115364074707


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.29009653503463, Training Loss Force: 4.09839844432509, time: 0.48070836067199707
Validation Loss Energy: 3.5366466966892385, Validation Loss Force: 4.322163100183928, time: 0.039803504943847656
Test Loss Energy: 9.107853674907483, Test Loss Force: 10.25087921050016, time: 7.830728769302368


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.321515934578203, Training Loss Force: 4.213635702298136, time: 0.4748983383178711
Validation Loss Energy: 5.450105237676725, Validation Loss Force: 4.319841997006776, time: 0.0363621711730957
Test Loss Energy: 12.161950468941875, Test Loss Force: 10.39394162327877, time: 7.834020376205444


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.267794349649136, Training Loss Force: 4.1788198894490485, time: 0.5017378330230713
Validation Loss Energy: 3.7842487748939986, Validation Loss Force: 4.301233091143299, time: 0.03850412368774414
Test Loss Energy: 10.898619726974943, Test Loss Force: 10.370987176311791, time: 9.580178260803223


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.260701569142781, Training Loss Force: 4.158822804751418, time: 0.539283037185669
Validation Loss Energy: 4.51507340543505, Validation Loss Force: 4.316573659282849, time: 0.04485130310058594
Test Loss Energy: 9.398311632718004, Test Loss Force: 10.217073091126444, time: 9.718413829803467


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.224404542579221, Training Loss Force: 4.102694741583498, time: 0.46935057640075684
Validation Loss Energy: 3.4527859336264988, Validation Loss Force: 4.285892968342043, time: 0.04699277877807617
Test Loss Energy: 9.17191668871276, Test Loss Force: 10.256460558368723, time: 8.783257484436035


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.449778246509211, Training Loss Force: 4.118786313373823, time: 0.46454286575317383
Validation Loss Energy: 5.050721849496019, Validation Loss Force: 4.310024959701112, time: 0.04241466522216797
Test Loss Energy: 11.353854093190723, Test Loss Force: 10.342345885264976, time: 8.395795822143555


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.305573781207101, Training Loss Force: 4.088583039926495, time: 0.5063719749450684
Validation Loss Energy: 3.917827550197787, Validation Loss Force: 4.272184119703852, time: 0.04065752029418945
Test Loss Energy: 10.725258264181962, Test Loss Force: 10.255773469001197, time: 8.466182231903076


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.378890135932088, Training Loss Force: 4.0602661229935055, time: 0.4586653709411621
Validation Loss Energy: 5.188654697279278, Validation Loss Force: 4.353528276079316, time: 0.0397038459777832
Test Loss Energy: 9.59819629235654, Test Loss Force: 10.270276747524935, time: 8.647841930389404


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.465461981203005, Training Loss Force: 4.115295306503968, time: 0.4737832546234131
Validation Loss Energy: 3.189371228692823, Validation Loss Force: 4.263360186789026, time: 0.04114651679992676
Test Loss Energy: 9.020289264101176, Test Loss Force: 10.199005152375252, time: 8.28100037574768


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.324182137820018, Training Loss Force: 4.073947412613735, time: 0.46941471099853516
Validation Loss Energy: 5.264339939980133, Validation Loss Force: 4.286665630278412, time: 0.03840899467468262
Test Loss Energy: 11.981207857382202, Test Loss Force: 10.332407785892348, time: 8.423481225967407


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.348006571132428, Training Loss Force: 4.09053515806193, time: 0.4655733108520508
Validation Loss Energy: 3.6626596197526924, Validation Loss Force: 4.3774019712291095, time: 0.038687944412231445
Test Loss Energy: 10.11711040631614, Test Loss Force: 10.346928919916813, time: 8.309840202331543


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.350241887309958, Training Loss Force: 4.10438150489773, time: 0.47751808166503906
Validation Loss Energy: 4.763745408885994, Validation Loss Force: 4.349595938962231, time: 0.04117321968078613
Test Loss Energy: 9.387599376844374, Test Loss Force: 10.162563110626257, time: 8.466946601867676


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.295829163329997, Training Loss Force: 4.058847965470005, time: 0.4816770553588867
Validation Loss Energy: 3.422440359750314, Validation Loss Force: 4.276225564702441, time: 0.04280734062194824
Test Loss Energy: 9.116460487917925, Test Loss Force: 10.215934335466416, time: 8.37947964668274

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–‚â–â–†â–…â–‚â–â–‡â–…â–‚â–â–†â–„â–‚â–â–‡â–ƒâ–‚â–
wandb:   test_error_force â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–„â–„â–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–â–‚
wandb:          test_loss â–ˆâ–„â–ƒâ–‚â–†â–…â–ƒâ–‚â–ˆâ–…â–ƒâ–‚â–…â–„â–‚â–â–‡â–„â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–…â–â–‡â–‚â–…â–‚â–‡â–‚â–„â–‚â–†â–ƒâ–†â–â–†â–‚â–…â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–„â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–…â–â–†â–‚â–…â–‚â–†â–‚â–„â–â–…â–‚â–†â–â–…â–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 938
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.11646
wandb:   test_error_force 10.21593
wandb:          test_loss 6.12526
wandb: train_error_energy 4.29583
wandb:  train_error_force 4.05885
wandb:         train_loss 1.69611
wandb: valid_error_energy 3.42244
wandb:  valid_error_force 4.27623
wandb:         valid_loss 1.4824
wandb: 
wandb: ğŸš€ View run al_73_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a0zanv9r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_155439-a0zanv9r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6097054481506348, Uncertainty Bias: -0.17593088746070862
0.00044250488 0.011774063
2.038451 7.355783
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1991 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 761 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 948 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_163615-g7cvhu56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g7cvhu56
Training model 9. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.718399178086114, Training Loss Force: 4.43197825311906, time: 0.499622106552124
Validation Loss Energy: 5.674080115476234, Validation Loss Force: 4.627660715013934, time: 0.04364371299743652
Test Loss Energy: 9.650135845521335, Test Loss Force: 10.329291672257742, time: 8.55851411819458


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.346831820674647, Training Loss Force: 4.155115556451648, time: 0.4632091522216797
Validation Loss Energy: 3.3058042570910255, Validation Loss Force: 4.299998613398276, time: 0.04111051559448242
Test Loss Energy: 9.08296234212336, Test Loss Force: 10.16174723688589, time: 8.472962379455566


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.234496995640331, Training Loss Force: 4.117300731632937, time: 0.4991624355316162
Validation Loss Energy: 5.1680128221134805, Validation Loss Force: 4.325350386338738, time: 0.03990745544433594
Test Loss Energy: 11.04234821195164, Test Loss Force: 10.269895621885214, time: 8.665287494659424


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.24920543576381, Training Loss Force: 4.079441283917381, time: 0.47325825691223145
Validation Loss Energy: 3.8780347924673237, Validation Loss Force: 4.351420935282255, time: 0.038897037506103516
Test Loss Energy: 10.129748370248949, Test Loss Force: 10.19963101821991, time: 8.53162407875061


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.406449235538437, Training Loss Force: 4.155700938791681, time: 0.47219228744506836
Validation Loss Energy: 5.448794161745503, Validation Loss Force: 4.3200757996100005, time: 0.039957523345947266
Test Loss Energy: 9.60333990765842, Test Loss Force: 10.134028989889632, time: 8.993367433547974


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.26038523422062, Training Loss Force: 4.06352208031292, time: 0.4583396911621094
Validation Loss Energy: 3.5891211302877273, Validation Loss Force: 4.322838233034381, time: 0.04071998596191406
Test Loss Energy: 9.060145609611197, Test Loss Force: 10.121721466969381, time: 8.536953449249268


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.352060377979769, Training Loss Force: 4.136115918193201, time: 0.4781148433685303
Validation Loss Energy: 5.2874899604056615, Validation Loss Force: 4.363553286367277, time: 0.04192090034484863
Test Loss Energy: 10.874442544271515, Test Loss Force: 10.190110189168683, time: 8.678010940551758


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.3000666907784915, Training Loss Force: 4.07219404153565, time: 0.48392486572265625
Validation Loss Energy: 3.464133153302979, Validation Loss Force: 4.315702577583979, time: 0.04100942611694336
Test Loss Energy: 10.271811667735587, Test Loss Force: 10.173776407052433, time: 8.5516357421875


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.352025689837986, Training Loss Force: 4.075577640231815, time: 0.47927355766296387
Validation Loss Energy: 4.734724048420641, Validation Loss Force: 4.330177853422453, time: 0.04527783393859863
Test Loss Energy: 9.440651296460889, Test Loss Force: 10.090784422053838, time: 8.54699993133545


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.379355896695778, Training Loss Force: 4.048860022172537, time: 0.49942564964294434
Validation Loss Energy: 3.2166620045560244, Validation Loss Force: 4.304145158233743, time: 0.0455782413482666
Test Loss Energy: 9.057920116601563, Test Loss Force: 10.114006939356376, time: 8.771606922149658


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.333307104575529, Training Loss Force: 4.072437545091332, time: 0.5079410076141357
Validation Loss Energy: 5.362215499087569, Validation Loss Force: 4.373284818720905, time: 0.03923678398132324
Test Loss Energy: 11.749098192519021, Test Loss Force: 10.292293741066258, time: 8.552053451538086


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.3211901696177115, Training Loss Force: 4.048306637388772, time: 0.48978281021118164
Validation Loss Energy: 3.663878510657501, Validation Loss Force: 4.312431122492008, time: 0.042406320571899414
Test Loss Energy: 10.913678708412037, Test Loss Force: 10.207074943364455, time: 8.573424577713013


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.364369799280784, Training Loss Force: 4.057301595052282, time: 0.5126535892486572
Validation Loss Energy: 4.787825295664916, Validation Loss Force: 4.293447241786788, time: 0.04145359992980957
Test Loss Energy: 9.368021433510734, Test Loss Force: 10.143486893339706, time: 8.748159646987915


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.344835666004454, Training Loss Force: 4.0442568719864305, time: 0.4895496368408203
Validation Loss Energy: 3.1460371408655243, Validation Loss Force: 4.421246862077167, time: 0.041889190673828125
Test Loss Energy: 8.864692154577957, Test Loss Force: 10.153193286230179, time: 8.578287363052368


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.30350351853399, Training Loss Force: 4.065933216048075, time: 0.4846611022949219
Validation Loss Energy: 5.261423419506771, Validation Loss Force: 4.304632803663325, time: 0.040329933166503906
Test Loss Energy: 11.349933418807336, Test Loss Force: 10.253790729661292, time: 8.583327293395996


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.341058815040818, Training Loss Force: 4.08585648592383, time: 0.5188412666320801
Validation Loss Energy: 3.8596240621437223, Validation Loss Force: 4.33693808869282, time: 0.03966999053955078
Test Loss Energy: 10.80431385039172, Test Loss Force: 10.254124831307976, time: 8.970451593399048


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.345113794612327, Training Loss Force: 4.034351078759198, time: 0.47269415855407715
Validation Loss Energy: 5.10597274467508, Validation Loss Force: 4.284055947888138, time: 0.040525197982788086
Test Loss Energy: 9.363673439549203, Test Loss Force: 10.144847003115315, time: 8.754140853881836


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.388956373412419, Training Loss Force: 4.041590928525286, time: 0.5201499462127686
Validation Loss Energy: 3.420864752873729, Validation Loss Force: 4.300947183959928, time: 0.04417061805725098
Test Loss Energy: 9.141411262871747, Test Loss Force: 10.14466671338715, time: 8.631162405014038


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.326375684976925, Training Loss Force: 4.054255666693611, time: 0.5179674625396729
Validation Loss Energy: 5.136303399718488, Validation Loss Force: 4.417487316217322, time: 0.04064512252807617
Test Loss Energy: 11.67600027669251, Test Loss Force: 10.317561083928783, time: 8.563898086547852


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.354616883266842, Training Loss Force: 4.045113138764791, time: 0.4972116947174072
Validation Loss Energy: 3.7621537608818763, Validation Loss Force: 4.296987235868748, time: 0.04327821731567383
Test Loss Energy: 10.614173421077163, Test Loss Force: 10.19840702807508, time: 8.813488006591797

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–†â–„â–ƒâ–â–†â–„â–‚â–â–ˆâ–†â–‚â–â–‡â–†â–‚â–‚â–ˆâ–…
wandb:   test_error_force â–ˆâ–ƒâ–†â–„â–‚â–‚â–„â–ƒâ–â–‚â–‡â–„â–ƒâ–ƒâ–†â–†â–ƒâ–ƒâ–ˆâ–„
wandb:          test_loss â–‚â–â–†â–„â–„â–‚â–†â–„â–ƒâ–‚â–ˆâ–†â–‚â–â–†â–†â–‚â–‚â–ˆâ–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–â–‡â–ƒâ–‡â–‚â–‡â–‚â–…â–â–‡â–‚â–†â–â–‡â–ƒâ–†â–‚â–‡â–ƒ
wandb:  valid_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–„â–â–‚â–â–â–„â–
wandb:         valid_loss â–ˆâ–â–†â–ƒâ–ˆâ–‚â–‡â–‚â–…â–â–†â–‚â–…â–â–†â–ƒâ–†â–â–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 940
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.61417
wandb:   test_error_force 10.19841
wandb:          test_loss 6.62172
wandb: train_error_energy 4.35462
wandb:  train_error_force 4.04511
wandb:         train_loss 1.70149
wandb: valid_error_energy 3.76215
wandb:  valid_error_force 4.29699
wandb:         valid_loss 1.59624
wandb: 
wandb: ğŸš€ View run al_73_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g7cvhu56
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_163615-g7cvhu56/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.0527915954589844, Uncertainty Bias: -0.29591104388237
0.00013828278 0.026508331
1.5452895 8.785131
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3385 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1760 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1581 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3260 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1134 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1504 steps.
Found uncertainty sample 53 after 994 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 798 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1258 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3266 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2918 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1534 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_171644-36qmvrc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/36qmvrc5
Training model 10. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.549411822399862, Training Loss Force: 4.642418557998591, time: 0.5620112419128418
Validation Loss Energy: 5.041485087984642, Validation Loss Force: 4.586319961380981, time: 0.05121254920959473
Test Loss Energy: 11.847036523341082, Test Loss Force: 10.325283212603733, time: 9.206095218658447


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.2598776190798, Training Loss Force: 4.188201148391522, time: 0.4920003414154053
Validation Loss Energy: 3.4387261584143265, Validation Loss Force: 4.42911242698792, time: 0.04436945915222168
Test Loss Energy: 10.0904134016296, Test Loss Force: 10.130012737981325, time: 9.255375146865845


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.207604856926779, Training Loss Force: 4.113025261361977, time: 0.5261714458465576
Validation Loss Energy: 5.57600326346088, Validation Loss Force: 4.43460612015625, time: 0.04400038719177246
Test Loss Energy: 9.5566646075087, Test Loss Force: 10.10484904469171, time: 9.35469126701355


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.096292866325434, Training Loss Force: 4.081633817929675, time: 0.5280637741088867
Validation Loss Energy: 3.9025653615976044, Validation Loss Force: 4.394621421621998, time: 0.046730756759643555
Test Loss Energy: 9.206326803390937, Test Loss Force: 10.102992851375117, time: 9.17206883430481


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.273299246786659, Training Loss Force: 4.089512104670964, time: 0.5334925651550293
Validation Loss Energy: 5.502938836607595, Validation Loss Force: 4.42393091596218, time: 0.04236459732055664
Test Loss Energy: 11.407657697211606, Test Loss Force: 10.168670731775084, time: 9.073169469833374


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.288690713381814, Training Loss Force: 4.073456560748451, time: 0.48381853103637695
Validation Loss Energy: 3.6193513615463213, Validation Loss Force: 4.407971327596952, time: 0.04365730285644531
Test Loss Energy: 10.2642163089189, Test Loss Force: 10.165105101596165, time: 9.684560060501099


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.310815932463582, Training Loss Force: 4.105436719135673, time: 0.4869225025177002
Validation Loss Energy: 5.0701711087162264, Validation Loss Force: 4.40280362205826, time: 0.048439979553222656
Test Loss Energy: 9.252050884265392, Test Loss Force: 10.076087540285465, time: 9.183814764022827


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.2848225161122135, Training Loss Force: 4.108776273874773, time: 0.51031494140625
Validation Loss Energy: 3.644648803215177, Validation Loss Force: 4.406035442042255, time: 0.044213056564331055
Test Loss Energy: 8.890732035801303, Test Loss Force: 10.082915145213448, time: 9.158681154251099


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.3901520287918485, Training Loss Force: 4.066100284708264, time: 0.5285398960113525
Validation Loss Energy: 5.355626719059565, Validation Loss Force: 4.40464197852704, time: 0.04259920120239258
Test Loss Energy: 11.504065066903745, Test Loss Force: 10.166497494900515, time: 9.359725952148438


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.212871557456598, Training Loss Force: 4.107543466148344, time: 0.48336029052734375
Validation Loss Energy: 3.935717234719917, Validation Loss Force: 4.414692818435928, time: 0.04279136657714844
Test Loss Energy: 10.647552234862424, Test Loss Force: 10.116973246785477, time: 9.22403883934021


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.408724483716139, Training Loss Force: 4.0925314092220875, time: 0.5451295375823975
Validation Loss Energy: 5.30741929430449, Validation Loss Force: 4.395820717641964, time: 0.041375160217285156
Test Loss Energy: 9.291477569256724, Test Loss Force: 10.054541943155101, time: 9.132348537445068


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.390150536908572, Training Loss Force: 4.076942364582597, time: 0.4808077812194824
Validation Loss Energy: 3.7377991003768782, Validation Loss Force: 4.365257150671916, time: 0.04614686965942383
Test Loss Energy: 8.86313448247698, Test Loss Force: 10.037906254319575, time: 9.168559551239014


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.471051744974346, Training Loss Force: 4.093626889463917, time: 0.4981718063354492
Validation Loss Energy: 5.050630109807896, Validation Loss Force: 4.413916593793224, time: 0.04390883445739746
Test Loss Energy: 11.018644939139163, Test Loss Force: 10.158696716218962, time: 9.379867315292358


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.300581026816364, Training Loss Force: 4.064196611956678, time: 0.48291563987731934
Validation Loss Energy: 3.55100618457183, Validation Loss Force: 4.405289055065106, time: 0.04519033432006836
Test Loss Energy: 10.36379932301668, Test Loss Force: 10.134346238629648, time: 9.254051685333252


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.327529619580714, Training Loss Force: 4.076660072061695, time: 0.5408518314361572
Validation Loss Energy: 4.574467282743245, Validation Loss Force: 4.4023720892534515, time: 0.0429692268371582
Test Loss Energy: 9.265479339987543, Test Loss Force: 9.950819847718568, time: 9.10292673110962


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.331086633007728, Training Loss Force: 4.097615561874922, time: 0.514005184173584
Validation Loss Energy: 3.5845241257700478, Validation Loss Force: 4.369164103506365, time: 0.04200124740600586
Test Loss Energy: 8.994524872409432, Test Loss Force: 10.067365792689898, time: 8.646876573562622


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.364835504377187, Training Loss Force: 4.081214984688489, time: 0.5347871780395508
Validation Loss Energy: 4.9397885263330865, Validation Loss Force: 4.40865492187495, time: 0.05183148384094238
Test Loss Energy: 11.1377984540584, Test Loss Force: 10.173848425948552, time: 10.394093036651611


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.252913263003361, Training Loss Force: 4.125297708451312, time: 0.5172452926635742
Validation Loss Energy: 3.5480910001133434, Validation Loss Force: 4.4547505524500455, time: 0.052988529205322266
Test Loss Energy: 10.414610757344937, Test Loss Force: 10.18157701785777, time: 8.394939422607422


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.21383010730714, Training Loss Force: 4.106325250673278, time: 0.5224659442901611
Validation Loss Energy: 4.6202899209454324, Validation Loss Force: 4.437559158369544, time: 0.03970766067504883
Test Loss Energy: 9.210717787653124, Test Loss Force: 10.082944938578336, time: 8.265375137329102


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.225817597268126, Training Loss Force: 4.065614710101738, time: 0.5080935955047607
Validation Loss Energy: 3.201048221374422, Validation Loss Force: 4.366268959271012, time: 0.04020571708679199
Test Loss Energy: 9.004023625738423, Test Loss Force: 10.01937897360228, time: 8.04873013496399

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–ƒâ–‚â–‡â–„â–‚â–â–‡â–…â–‚â–â–†â–…â–‚â–â–†â–…â–‚â–
wandb:   test_error_force â–ˆâ–„â–„â–„â–…â–…â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–â–ƒâ–…â–…â–ƒâ–‚
wandb:          test_loss â–‡â–„â–„â–ƒâ–ˆâ–…â–ƒâ–â–‡â–†â–ƒâ–â–†â–…â–ƒâ–â–†â–…â–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–‚â–ˆâ–ƒâ–ˆâ–‚â–‡â–‚â–‡â–ƒâ–‡â–ƒâ–†â–‚â–…â–‚â–†â–‚â–…â–
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–â–‚â–„â–ƒâ–
wandb:         valid_loss â–†â–‚â–ˆâ–ƒâ–‡â–‚â–†â–‚â–†â–ƒâ–‡â–‚â–…â–‚â–…â–‚â–…â–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 950
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.00402
wandb:   test_error_force 10.01938
wandb:          test_loss 6.10576
wandb: train_error_energy 4.22582
wandb:  train_error_force 4.06561
wandb:         train_loss 1.68849
wandb: valid_error_energy 3.20105
wandb:  valid_error_force 4.36627
wandb:         valid_loss 1.4581
wandb: 
wandb: ğŸš€ View run al_73_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/36qmvrc5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_171644-36qmvrc5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.0079996585845947, Uncertainty Bias: -0.24891000986099243
3.0517578e-05 0.13466454
1.786866 9.203436
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1860 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3517 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1658 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1960 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1305 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 725 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3424 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2814 steps.
Found uncertainty sample 83 after 1446 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2855 steps.
Found uncertainty sample 94 after 3770 steps.
Found uncertainty sample 95 after 3860 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_175749-zwzhvpf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zwzhvpf5
Training model 11. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.452721453222, Training Loss Force: 4.648049489583861, time: 0.5322864055633545
Validation Loss Energy: 4.474207827759507, Validation Loss Force: 4.690847093215571, time: 0.0468144416809082
Test Loss Energy: 9.181776338597599, Test Loss Force: 10.162913328389555, time: 9.285048007965088


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.3326356457659845, Training Loss Force: 4.1614934316869325, time: 0.47559523582458496
Validation Loss Energy: 3.400218201655867, Validation Loss Force: 4.3640004060123, time: 0.04530501365661621
Test Loss Energy: 8.897564322610387, Test Loss Force: 9.999948080506286, time: 9.47833514213562


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.329722257505275, Training Loss Force: 4.080817564796837, time: 0.5294644832611084
Validation Loss Energy: 4.8915895630055575, Validation Loss Force: 4.402680708689708, time: 0.04690408706665039
Test Loss Energy: 10.757211421856216, Test Loss Force: 10.082402586487278, time: 9.76744818687439


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.2395027167976655, Training Loss Force: 4.088696393366383, time: 0.512993574142456
Validation Loss Energy: 3.3765665076445632, Validation Loss Force: 4.412598392449332, time: 0.04626059532165527
Test Loss Energy: 10.273222238303408, Test Loss Force: 10.161212308654106, time: 9.575356483459473


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.379835344189638, Training Loss Force: 4.107357270208519, time: 0.5129005908966064
Validation Loss Energy: 4.821374410543564, Validation Loss Force: 4.368482735919826, time: 0.04894876480102539
Test Loss Energy: 9.279977339736972, Test Loss Force: 10.019766105479905, time: 9.456023454666138


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.368376040287402, Training Loss Force: 4.083527426035863, time: 0.4910142421722412
Validation Loss Energy: 3.318028125195023, Validation Loss Force: 4.376110490182729, time: 0.049286603927612305
Test Loss Energy: 8.854553084060157, Test Loss Force: 10.070179691832164, time: 9.751628637313843


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.329853409632225, Training Loss Force: 4.081918611767316, time: 0.4983949661254883
Validation Loss Energy: 5.1852086695769, Validation Loss Force: 4.391793078130423, time: 0.04606008529663086
Test Loss Energy: 11.067243853558606, Test Loss Force: 10.043441300995465, time: 9.60874605178833


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.232582493745947, Training Loss Force: 4.0899198415663784, time: 0.5033478736877441
Validation Loss Energy: 3.6855573560358845, Validation Loss Force: 4.42525802407191, time: 0.05214881896972656
Test Loss Energy: 10.16417743162325, Test Loss Force: 10.077553626584852, time: 10.13263726234436


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.2919336853788685, Training Loss Force: 4.0972372618406006, time: 0.5142102241516113
Validation Loss Energy: 4.9034271001413705, Validation Loss Force: 4.367732786236341, time: 0.045728445053100586
Test Loss Energy: 9.269238937142898, Test Loss Force: 10.00876839009281, time: 9.78984522819519


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.285786332088057, Training Loss Force: 4.071758062770229, time: 0.5200765132904053
Validation Loss Energy: 3.456011073536117, Validation Loss Force: 4.373452265918642, time: 0.05097460746765137
Test Loss Energy: 9.158719253978221, Test Loss Force: 10.00274596145973, time: 9.685870170593262


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.409377772723375, Training Loss Force: 4.085953532559929, time: 0.5661072731018066
Validation Loss Energy: 5.13681999213704, Validation Loss Force: 4.400297258151697, time: 0.05464529991149902
Test Loss Energy: 11.186026520593044, Test Loss Force: 10.106836680421214, time: 9.71602725982666


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.224971320912113, Training Loss Force: 4.09139502465815, time: 0.5091307163238525
Validation Loss Energy: 3.7927467201791867, Validation Loss Force: 4.401561128223983, time: 0.0485532283782959
Test Loss Energy: 10.733007211082215, Test Loss Force: 10.063111133240533, time: 9.7007155418396


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.457841200195523, Training Loss Force: 4.087043542563075, time: 0.5364723205566406
Validation Loss Energy: 5.057818760515029, Validation Loss Force: 4.370810964509647, time: 0.04426312446594238
Test Loss Energy: 9.311832784127798, Test Loss Force: 10.033655138923626, time: 9.597436666488647


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.214478742529228, Training Loss Force: 4.107747312329136, time: 0.49138665199279785
Validation Loss Energy: 3.307335107469279, Validation Loss Force: 4.340392132484452, time: 0.04864954948425293
Test Loss Energy: 8.756452594141125, Test Loss Force: 9.933250855730472, time: 9.672790050506592


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.373106765049516, Training Loss Force: 4.084483530236953, time: 0.5739219188690186
Validation Loss Energy: 5.244780682201837, Validation Loss Force: 4.432976627346351, time: 0.049172163009643555
Test Loss Energy: 11.593325344578352, Test Loss Force: 10.055347767638724, time: 9.776015758514404


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.347226880273353, Training Loss Force: 4.091419495997287, time: 0.521327018737793
Validation Loss Energy: 3.853868064721489, Validation Loss Force: 4.34117637321641, time: 0.05042123794555664
Test Loss Energy: 10.25171899261144, Test Loss Force: 10.004362800599944, time: 9.737725973129272


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.347023312428992, Training Loss Force: 4.0955533338468255, time: 0.5362422466278076
Validation Loss Energy: 4.847853334700713, Validation Loss Force: 4.386023275221142, time: 0.04787278175354004
Test Loss Energy: 9.210665946545369, Test Loss Force: 9.963839412940374, time: 9.523028135299683


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.268456166884662, Training Loss Force: 4.104073456978949, time: 0.5083050727844238
Validation Loss Energy: 3.55853017501273, Validation Loss Force: 4.384266415659772, time: 0.04867267608642578
Test Loss Energy: 8.764166436259586, Test Loss Force: 9.99525086671229, time: 9.302136182785034


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.36167216257787, Training Loss Force: 4.074687616810933, time: 0.49584269523620605
Validation Loss Energy: 5.114059197378594, Validation Loss Force: 4.360334381193745, time: 0.04789376258850098
Test Loss Energy: 11.641272829336211, Test Loss Force: 10.047441600000147, time: 10.451698541641235


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.336388845555171, Training Loss Force: 4.07227175306758, time: 0.5578467845916748
Validation Loss Energy: 3.7030631589504353, Validation Loss Force: 4.374896943337422, time: 0.051216840744018555
Test Loss Energy: 10.511167219768666, Test Loss Force: 10.072401225761068, time: 9.108176946640015

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–†â–…â–‚â–â–‡â–„â–‚â–‚â–‡â–†â–‚â–â–ˆâ–…â–‚â–â–ˆâ–…
wandb:   test_error_force â–ˆâ–ƒâ–†â–ˆâ–„â–…â–„â–…â–ƒâ–ƒâ–†â–…â–„â–â–…â–ƒâ–‚â–ƒâ–„â–…
wandb:          test_loss â–â–‚â–†â–…â–ƒâ–ƒâ–‡â–…â–ƒâ–ƒâ–‡â–†â–ƒâ–‚â–‡â–…â–ƒâ–‚â–ˆâ–…
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–â–‡â–â–†â–â–ˆâ–‚â–‡â–‚â–ˆâ–ƒâ–‡â–â–ˆâ–ƒâ–‡â–‚â–ˆâ–‚
wandb:  valid_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–â–‚
wandb:         valid_loss â–†â–â–‡â–‚â–‡â–â–ˆâ–ƒâ–‡â–â–‡â–ƒâ–‡â–â–ˆâ–ƒâ–‡â–‚â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 960
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.51117
wandb:   test_error_force 10.0724
wandb:          test_loss 6.56197
wandb: train_error_energy 4.33639
wandb:  train_error_force 4.07227
wandb:         train_loss 1.71102
wandb: valid_error_energy 3.70306
wandb:  valid_error_force 4.3749
wandb:         valid_loss 1.59617
wandb: 
wandb: ğŸš€ View run al_73_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zwzhvpf5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_175749-zwzhvpf5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.2519052028656006, Uncertainty Bias: -0.3482067883014679
0.0 0.18837166
1.4448338 9.297835
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2816 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1744 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1763 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2455 steps.
Found uncertainty sample 21 after 2093 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1078 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1853 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3702 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1342 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3695 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_183915-jjvv9qcj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jjvv9qcj
Training model 12. Added 10 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.734691454296978, Training Loss Force: 4.501516101107854, time: 0.5148961544036865
Validation Loss Energy: 2.125774684975362, Validation Loss Force: 4.490937406031354, time: 0.04104042053222656
Test Loss Energy: 9.336732044399838, Test Loss Force: 10.02679953131038, time: 8.200975894927979


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.004105501795153, Training Loss Force: 4.446986539035586, time: 0.5067498683929443
Validation Loss Energy: 6.117609443190292, Validation Loss Force: 4.510981637209482, time: 0.04018831253051758
Test Loss Energy: 11.648870659663839, Test Loss Force: 10.006657733740509, time: 8.169223546981812


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.621663053331051, Training Loss Force: 4.851589277631089, time: 0.5114214420318604
Validation Loss Energy: 2.5748820974640574, Validation Loss Force: 5.573058241336839, time: 0.03861808776855469
Test Loss Energy: 9.360633476430888, Test Loss Force: 10.810455051446725, time: 8.122815370559692


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.883680613584865, Training Loss Force: 4.449877668043436, time: 0.5207920074462891
Validation Loss Energy: 1.8487718180805888, Validation Loss Force: 4.351833318540514, time: 0.039539337158203125
Test Loss Energy: 9.135126124283909, Test Loss Force: 9.922788884640093, time: 8.376566410064697


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9076596851122494, Training Loss Force: 4.090792949075617, time: 0.4903683662414551
Validation Loss Energy: 2.6020577533788143, Validation Loss Force: 4.308994446893759, time: 0.0411837100982666
Test Loss Energy: 8.806295748773799, Test Loss Force: 9.896420912671198, time: 8.170899152755737


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.8751477056523282, Training Loss Force: 4.060907481483675, time: 0.4979109764099121
Validation Loss Energy: 3.4665426561310637, Validation Loss Force: 4.30786195161757, time: 0.042009592056274414
Test Loss Energy: 8.714419360448861, Test Loss Force: 9.879475002580527, time: 8.260108709335327


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.914894701281865, Training Loss Force: 4.05013049594129, time: 0.505612850189209
Validation Loss Energy: 2.079832473441811, Validation Loss Force: 4.310134512920909, time: 0.04154777526855469
Test Loss Energy: 8.76025947876191, Test Loss Force: 9.892523535775831, time: 8.484885454177856


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.931712251823543, Training Loss Force: 4.070591427285956, time: 0.5085532665252686
Validation Loss Energy: 2.709167179298728, Validation Loss Force: 4.345831049042884, time: 0.04197955131530762
Test Loss Energy: 9.462824074466257, Test Loss Force: 9.943417210796394, time: 8.223618268966675


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.8659465209241706, Training Loss Force: 4.108085822823656, time: 0.5150303840637207
Validation Loss Energy: 3.5726347067232336, Validation Loss Force: 4.336063889625907, time: 0.04185986518859863
Test Loss Energy: 10.4759862268389, Test Loss Force: 9.948889350524045, time: 8.192345380783081


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1867464119835014, Training Loss Force: 4.097571400118697, time: 0.528095006942749
Validation Loss Energy: 2.227651163296827, Validation Loss Force: 4.321970714041846, time: 0.04096841812133789
Test Loss Energy: 9.402951227664522, Test Loss Force: 9.934564314571297, time: 8.573299169540405


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9718608599892637, Training Loss Force: 4.0750239080362975, time: 0.5899791717529297
Validation Loss Energy: 2.277019807647915, Validation Loss Force: 4.338143619448873, time: 0.04968404769897461
Test Loss Energy: 8.673232162256879, Test Loss Force: 9.895438030076546, time: 10.531468868255615


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.872238554809409, Training Loss Force: 4.066252683063175, time: 0.5576560497283936
Validation Loss Energy: 3.1942748486244446, Validation Loss Force: 4.329595796274997, time: 0.0510706901550293
Test Loss Energy: 8.712122153984556, Test Loss Force: 9.936496616435134, time: 9.860321044921875


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9353929404827883, Training Loss Force: 4.094271931811592, time: 0.5199763774871826
Validation Loss Energy: 2.0407662851345103, Validation Loss Force: 4.333731207653168, time: 0.04796600341796875
Test Loss Energy: 8.702576001272657, Test Loss Force: 9.930582029617103, time: 9.051527261734009


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.882767626989307, Training Loss Force: 4.069332570860891, time: 0.5136623382568359
Validation Loss Energy: 2.6506174407227463, Validation Loss Force: 4.3502394527939625, time: 0.043666839599609375
Test Loss Energy: 9.727850553108528, Test Loss Force: 9.994760892000228, time: 8.672690629959106


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.915617320123406, Training Loss Force: 4.049145407639704, time: 0.5076243877410889
Validation Loss Energy: 3.5547499209223137, Validation Loss Force: 4.34347565481726, time: 0.04224109649658203
Test Loss Energy: 10.224977085700687, Test Loss Force: 9.9852125172601, time: 8.638139724731445


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.962963288233016, Training Loss Force: 4.048460261860561, time: 0.4995608329772949
Validation Loss Energy: 2.484581074693648, Validation Loss Force: 4.353806612511725, time: 0.04296708106994629
Test Loss Energy: 9.831173751342718, Test Loss Force: 9.97249253646994, time: 8.709874629974365


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8477901972826674, Training Loss Force: 4.069386894949622, time: 0.5256330966949463
Validation Loss Energy: 2.464923619821997, Validation Loss Force: 4.315939497555246, time: 0.04277467727661133
Test Loss Energy: 8.533498926008738, Test Loss Force: 9.90960776654098, time: 8.871546983718872


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9103374539810476, Training Loss Force: 4.058313752260277, time: 0.5319035053253174
Validation Loss Energy: 3.3080376286246813, Validation Loss Force: 4.356118363584748, time: 0.04257488250732422
Test Loss Energy: 8.750940523190511, Test Loss Force: 9.943844884779876, time: 8.688217639923096


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9464937372434834, Training Loss Force: 4.048724462393642, time: 0.4772307872772217
Validation Loss Energy: 2.0216118398635103, Validation Loss Force: 4.345470770364773, time: 0.04285836219787598
Test Loss Energy: 8.571434203371625, Test Loss Force: 9.992705098527546, time: 8.700543880462646


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9237414936985275, Training Loss Force: 4.0573483881352965, time: 0.5106306076049805
Validation Loss Energy: 2.6111397598337707, Validation Loss Force: 4.346676746459118, time: 0.04309439659118652
Test Loss Energy: 9.883705128786405, Test Loss Force: 9.975375316155755, time: 8.891380071640015

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–‚â–‚â–â–‚â–ƒâ–…â–ƒâ–â–â–â–„â–…â–„â–â–â–â–„
wandb:   test_error_force â–‚â–‚â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚
wandb:          test_loss â–â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–„â–…â–„â–‚â–ƒâ–ƒâ–„
wandb: train_error_energy â–ˆâ–â–…â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–…â–„â–ˆâ–„â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–†â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–â–‚â–„â–â–‚â–„â–‚â–‚â–ƒâ–â–‚â–„â–‚â–‚â–ƒâ–â–‚
wandb:  valid_error_force â–‚â–‚â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–ˆâ–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 969
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.88371
wandb:   test_error_force 9.97538
wandb:          test_loss 7.55947
wandb: train_error_energy 2.92374
wandb:  train_error_force 4.05735
wandb:         train_loss 1.29638
wandb: valid_error_energy 2.61114
wandb:  valid_error_force 4.34668
wandb:         valid_loss 1.2461
wandb: 
wandb: ğŸš€ View run al_73_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jjvv9qcj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_183915-jjvv9qcj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.047636032104492, Uncertainty Bias: -0.15166980028152466
0.000289917 0.16128683
2.523892 10.600017
(48745, 22, 3)
Found uncertainty sample 0 after 2091 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2622 steps.
Found uncertainty sample 7 after 1570 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3418 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2047 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 928 steps.
Found uncertainty sample 18 after 3804 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 534 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1373 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1291 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3323 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1267 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2477 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1269 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1956 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3592 steps.
Found uncertainty sample 65 after 1852 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 257 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2456 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2126 steps.
Found uncertainty sample 84 after 939 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 412 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 592 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1604 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_191715-uiv433ap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uiv433ap
Training model 13. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.373024073151022, Training Loss Force: 4.442522575741162, time: 0.5039322376251221
Validation Loss Energy: 1.7664441320875617, Validation Loss Force: 5.13960157510797, time: 0.04582524299621582
Test Loss Energy: 9.144397472958751, Test Loss Force: 10.327414228610301, time: 8.674793720245361


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.5830629528772806, Training Loss Force: 4.644589862303538, time: 0.5065157413482666
Validation Loss Energy: 2.9422757227950487, Validation Loss Force: 5.0737039773855175, time: 0.04475116729736328
Test Loss Energy: 9.501903959840549, Test Loss Force: 10.39231996236061, time: 9.076303720474243


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.76598242937963, Training Loss Force: 4.8316719391346385, time: 0.5077264308929443
Validation Loss Energy: 5.320599526390248, Validation Loss Force: 6.333806933060835, time: 0.041078805923461914
Test Loss Energy: 11.394188083837482, Test Loss Force: 10.903044347102043, time: 8.882957935333252


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.1844602193482805, Training Loss Force: 5.092511374835397, time: 0.5277676582336426
Validation Loss Energy: 5.045126619197145, Validation Loss Force: 4.620780238404765, time: 0.05053377151489258
Test Loss Energy: 11.200764560013397, Test Loss Force: 10.135158092667314, time: 8.728879928588867


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.225963420897501, Training Loss Force: 4.236586204464895, time: 0.49561023712158203
Validation Loss Energy: 3.8526358136679244, Validation Loss Force: 4.415927296180952, time: 0.04580354690551758
Test Loss Energy: 10.739618535486889, Test Loss Force: 10.007228671420352, time: 8.68454909324646


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.386201381806382, Training Loss Force: 4.168527609864089, time: 0.5167548656463623
Validation Loss Energy: 2.196094937274233, Validation Loss Force: 4.379430487148512, time: 0.04394268989562988
Test Loss Energy: 8.6884909490321, Test Loss Force: 9.979055172109112, time: 8.667726516723633


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.1666700535686285, Training Loss Force: 4.142828731639503, time: 0.5102050304412842
Validation Loss Energy: 4.6099932542994395, Validation Loss Force: 4.376762910780297, time: 0.04363656044006348
Test Loss Energy: 8.96191035239756, Test Loss Force: 9.915388150315016, time: 8.893954277038574


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.212307811733815, Training Loss Force: 4.127885900874711, time: 0.488436222076416
Validation Loss Energy: 5.3615234433820245, Validation Loss Force: 4.402423303157015, time: 0.0435941219329834
Test Loss Energy: 9.28128174258866, Test Loss Force: 9.936542656487024, time: 8.731069087982178


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.234202344502972, Training Loss Force: 4.1317171749310475, time: 0.4828782081604004
Validation Loss Energy: 3.373640635067072, Validation Loss Force: 4.362939164862808, time: 0.04242706298828125
Test Loss Energy: 8.834804443258731, Test Loss Force: 9.949845974480775, time: 8.6588773727417


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.335739381668658, Training Loss Force: 4.118760560130806, time: 0.48478126525878906
Validation Loss Energy: 2.400077465806615, Validation Loss Force: 4.371573383665304, time: 0.04140353202819824
Test Loss Energy: 9.39129166496408, Test Loss Force: 10.027429733957248, time: 8.882796287536621


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.299541768139589, Training Loss Force: 4.111477820935206, time: 0.4904336929321289
Validation Loss Energy: 5.346426475288121, Validation Loss Force: 4.4231003600478696, time: 0.04383659362792969
Test Loss Energy: 11.362878479632398, Test Loss Force: 10.024480638503388, time: 8.718187093734741


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.187818436395532, Training Loss Force: 4.131504777297335, time: 0.4980947971343994
Validation Loss Energy: 5.889457292213178, Validation Loss Force: 4.436473868952293, time: 0.04554271697998047
Test Loss Energy: 12.054612207922567, Test Loss Force: 10.09079033969041, time: 8.698348999023438


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.351482607452802, Training Loss Force: 4.132926447965327, time: 0.5562083721160889
Validation Loss Energy: 3.7764593628311527, Validation Loss Force: 4.370885336004387, time: 0.053498029708862305
Test Loss Energy: 10.187896260964953, Test Loss Force: 9.97618503909814, time: 8.951932191848755


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.290668840829783, Training Loss Force: 4.118092409035509, time: 0.4877002239227295
Validation Loss Energy: 2.1225971962629724, Validation Loss Force: 4.366887088820108, time: 0.043467044830322266
Test Loss Energy: 8.574370745415209, Test Loss Force: 9.89818456422442, time: 9.13534927368164


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.249772312142955, Training Loss Force: 4.1201127652081455, time: 0.49953794479370117
Validation Loss Energy: 5.008778998492477, Validation Loss Force: 4.360996153895442, time: 0.04506516456604004
Test Loss Energy: 8.997234189333149, Test Loss Force: 9.955737963295011, time: 8.776175498962402


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.23173063797154, Training Loss Force: 4.107048479101535, time: 0.5268359184265137
Validation Loss Energy: 5.256674331962423, Validation Loss Force: 4.378409771783579, time: 0.04275369644165039
Test Loss Energy: 9.103147950722047, Test Loss Force: 9.97092188194169, time: 8.885411262512207


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.3236325154265325, Training Loss Force: 4.111358463090113, time: 0.5131115913391113
Validation Loss Energy: 3.229237689910588, Validation Loss Force: 4.3538872187425515, time: 0.043050289154052734
Test Loss Energy: 8.471677749827888, Test Loss Force: 9.908386830810613, time: 8.71002984046936


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.410342315845667, Training Loss Force: 4.108211444136336, time: 0.49245524406433105
Validation Loss Energy: 2.584238877645089, Validation Loss Force: 4.380219181263388, time: 0.04282712936401367
Test Loss Energy: 9.538135489479503, Test Loss Force: 10.01694762704756, time: 8.695062398910522


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.365231227673604, Training Loss Force: 4.105708879971006, time: 0.5126156806945801
Validation Loss Energy: 5.271698264576463, Validation Loss Force: 4.384915273551005, time: 0.044135332107543945
Test Loss Energy: 11.055313800307179, Test Loss Force: 9.997596372562544, time: 8.67176342010498


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.36824566510817, Training Loss Force: 4.107822951122574, time: 0.5027320384979248
Validation Loss Energy: 6.177645498315342, Validation Loss Force: 4.40026207642664, time: 0.044911861419677734
Test Loss Energy: 11.783739416786146, Test Loss Force: 9.995413921149074, time: 8.891316175460815

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‡â–†â–…â–â–‚â–ƒâ–‚â–ƒâ–‡â–ˆâ–„â–â–‚â–‚â–â–ƒâ–†â–‡
wandb:   test_error_force â–„â–„â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚
wandb:          test_loss â–…â–…â–ˆâ–†â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–‚â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–„â–â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–ƒâ–…â–†â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–‡â–†â–„â–‚â–†â–‡â–„â–‚â–‡â–ˆâ–„â–‚â–†â–‡â–ƒâ–‚â–‡â–ˆ
wandb:  valid_error_force â–„â–„â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–‚â–ˆâ–…â–‚â–â–ƒâ–„â–‚â–â–„â–„â–‚â–â–ƒâ–„â–‚â–â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 990
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.78374
wandb:   test_error_force 9.99541
wandb:          test_loss 7.09642
wandb: train_error_energy 4.36825
wandb:  train_error_force 4.10782
wandb:         train_loss 1.71513
wandb: valid_error_energy 6.17765
wandb:  valid_error_force 4.40026
wandb:         valid_loss 2.35316
wandb: 
wandb: ğŸš€ View run al_73_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uiv433ap
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_191715-uiv433ap/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.001185655593872, Uncertainty Bias: -0.2881906032562256
6.4373016e-05 0.05095482
1.5064405 9.322343
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1215 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1621 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1582 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3382 steps.
Found uncertainty sample 18 after 2566 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 561 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1696 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3686 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 855 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 758 steps.
Found uncertainty sample 38 after 2910 steps.
Found uncertainty sample 39 after 2398 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2392 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 772 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1149 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1193 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2852 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1033 steps.
Found uncertainty sample 71 after 632 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3331 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1127 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 685 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 530 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3599 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_195512-y8wvye2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/y8wvye2x
Training model 14. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.260129358880595, Training Loss Force: 4.63806810389274, time: 0.5359256267547607
Validation Loss Energy: 1.6239133891100388, Validation Loss Force: 4.586270083492293, time: 0.04544687271118164
Test Loss Energy: 8.984724095780457, Test Loss Force: 9.968648656128334, time: 8.762348175048828


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2185067294592864, Training Loss Force: 4.609593305721299, time: 0.48789286613464355
Validation Loss Energy: 2.147501626889266, Validation Loss Force: 4.651274332601284, time: 0.043271780014038086
Test Loss Energy: 8.324128723966664, Test Loss Force: 9.980303872700107, time: 8.808050155639648


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.478595126650598, Training Loss Force: 4.916345640313377, time: 0.5478992462158203
Validation Loss Energy: 1.9060416544057779, Validation Loss Force: 4.905908970441882, time: 0.04296231269836426
Test Loss Energy: 8.573620203501743, Test Loss Force: 10.229756894592333, time: 8.917304754257202


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0053136154684053, Training Loss Force: 4.324486075173587, time: 0.5127396583557129
Validation Loss Energy: 3.5231671972713543, Validation Loss Force: 4.4103218231013654, time: 0.04451727867126465
Test Loss Energy: 10.108020333642227, Test Loss Force: 9.949109678729423, time: 8.803276538848877


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9770275781070152, Training Loss Force: 4.169936785919845, time: 0.5507025718688965
Validation Loss Energy: 2.412362345256597, Validation Loss Force: 4.364603839397764, time: 0.04248404502868652
Test Loss Energy: 8.510258627817125, Test Loss Force: 9.857764695567376, time: 8.765702247619629


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9694042981022637, Training Loss Force: 4.153480610567144, time: 0.53847336769104
Validation Loss Energy: 1.7912140705497148, Validation Loss Force: 4.3615724216451035, time: 0.04448556900024414
Test Loss Energy: 8.606421122070707, Test Loss Force: 9.854815679388391, time: 9.243996858596802


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8785340842859872, Training Loss Force: 4.156725143567689, time: 0.5791571140289307
Validation Loss Energy: 3.5244390834328936, Validation Loss Force: 4.3794420659441, time: 0.06832671165466309
Test Loss Energy: 9.980060484831345, Test Loss Force: 9.913580072186855, time: 8.986047267913818


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.012707664545835, Training Loss Force: 4.1599737820306135, time: 0.5141091346740723
Validation Loss Energy: 2.4706738278464364, Validation Loss Force: 4.358039998314105, time: 0.04446005821228027
Test Loss Energy: 8.485244554203891, Test Loss Force: 9.87382700319149, time: 8.733197212219238


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9217651319660076, Training Loss Force: 4.156167830529075, time: 0.5287580490112305
Validation Loss Energy: 2.031255195235351, Validation Loss Force: 4.373421092238213, time: 0.0427699089050293
Test Loss Energy: 8.540762636036767, Test Loss Force: 9.933418079093258, time: 8.827839136123657


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9006237472801963, Training Loss Force: 4.167225044518217, time: 0.5243091583251953
Validation Loss Energy: 3.7016968610710226, Validation Loss Force: 4.388774575188226, time: 0.04262566566467285
Test Loss Energy: 10.209351909086818, Test Loss Force: 9.954534855086003, time: 9.02121376991272


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9868685349498394, Training Loss Force: 4.156949573191552, time: 0.49607110023498535
Validation Loss Energy: 2.6223181962976376, Validation Loss Force: 4.379088022002075, time: 0.04591774940490723
Test Loss Energy: 8.537070872530235, Test Loss Force: 9.93087517413062, time: 8.76423692703247


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.958510860749157, Training Loss Force: 4.149234351704765, time: 0.5616211891174316
Validation Loss Energy: 1.9348456897847046, Validation Loss Force: 4.349314039823486, time: 0.04270815849304199
Test Loss Energy: 8.489377967388783, Test Loss Force: 9.877254993527243, time: 8.752991676330566


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.93507241767475, Training Loss Force: 4.148373756330987, time: 0.500307559967041
Validation Loss Energy: 3.6016607432406507, Validation Loss Force: 4.395199025386534, time: 0.04828977584838867
Test Loss Energy: 10.167883919272782, Test Loss Force: 9.962069825097668, time: 9.024582386016846


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9889273582275253, Training Loss Force: 4.164504076263855, time: 0.49599123001098633
Validation Loss Energy: 2.258888527102453, Validation Loss Force: 4.376549148400207, time: 0.05170559883117676
Test Loss Energy: 8.696187164148014, Test Loss Force: 9.906723849027488, time: 8.82515811920166


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.007976654952772, Training Loss Force: 4.163583527222535, time: 0.5931808948516846
Validation Loss Energy: 2.0256873532414263, Validation Loss Force: 4.43024759429386, time: 0.044258832931518555
Test Loss Energy: 8.772089620017818, Test Loss Force: 9.952501020754852, time: 8.784497261047363


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.8608692121003143, Training Loss Force: 4.1746190518451805, time: 0.5153489112854004
Validation Loss Energy: 3.821287560627627, Validation Loss Force: 4.418313864087006, time: 0.04260659217834473
Test Loss Energy: 10.102337886986573, Test Loss Force: 9.95867588099091, time: 9.004643440246582


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0066349759308055, Training Loss Force: 4.161258457751222, time: 0.5122237205505371
Validation Loss Energy: 2.48005398828779, Validation Loss Force: 4.373216681962251, time: 0.042611122131347656
Test Loss Energy: 8.42906875667784, Test Loss Force: 9.956164811887106, time: 9.26680064201355


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9371206920016473, Training Loss Force: 4.16830674339549, time: 0.5406298637390137
Validation Loss Energy: 1.9779493150459682, Validation Loss Force: 4.378403982385785, time: 0.04623603820800781
Test Loss Energy: 8.552701638023088, Test Loss Force: 9.922352266584948, time: 8.808194875717163


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.858436120259583, Training Loss Force: 4.176995370012112, time: 0.5150251388549805
Validation Loss Energy: 3.956012636694651, Validation Loss Force: 4.426040038112408, time: 0.04496145248413086
Test Loss Energy: 10.231616818491476, Test Loss Force: 9.972154396467646, time: 8.936466217041016


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0346247937440043, Training Loss Force: 4.1663360657867425, time: 0.5674426555633545
Validation Loss Energy: 2.269266913325001, Validation Loss Force: 4.391472879898578, time: 0.04437375068664551
Test Loss Energy: 8.356223939892791, Test Loss Force: 9.911542451314418, time: 8.828964471817017

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–‚â–ˆâ–‚â–‚â–‡â–‚â–‚â–ˆâ–‚â–‚â–ˆâ–‚â–ƒâ–ˆâ–â–‚â–ˆâ–
wandb:   test_error_force â–ƒâ–ƒâ–ˆâ–ƒâ–â–â–‚â–â–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–â–‡â–†â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–‡â–…â–…â–‡â–…
wandb: train_error_energy â–ˆâ–â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–…â–…â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–‚â–‡â–ƒâ–‚â–‡â–„â–‚â–‡â–„â–‚â–‡â–ƒâ–‚â–ˆâ–„â–‚â–ˆâ–ƒ
wandb:  valid_error_force â–„â–…â–ˆâ–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚
wandb:         valid_loss â–„â–ƒâ–ƒâ–†â–ƒâ–â–†â–ƒâ–‚â–‡â–ƒâ–â–‡â–‚â–‚â–ˆâ–ƒâ–â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1011
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.35622
wandb:   test_error_force 9.91154
wandb:          test_loss 7.01425
wandb: train_error_energy 3.03462
wandb:  train_error_force 4.16634
wandb:         train_loss 1.36133
wandb: valid_error_energy 2.26927
wandb:  valid_error_force 4.39147
wandb:         valid_loss 1.18676
wandb: 
wandb: ğŸš€ View run al_73_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/y8wvye2x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_195512-y8wvye2x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.682526111602783, Uncertainty Bias: -0.07712849974632263
4.5776367e-05 0.015168011
2.858672 9.971728
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 171 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1341 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3315 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3575 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1940 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3318 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 208 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3285 steps.
Found uncertainty sample 32 after 886 steps.
Found uncertainty sample 33 after 995 steps.
Found uncertainty sample 34 after 3834 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2929 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1653 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3766 steps.
Found uncertainty sample 48 after 251 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 576 steps.
Found uncertainty sample 52 after 642 steps.
Found uncertainty sample 53 after 610 steps.
Found uncertainty sample 54 after 3244 steps.
Found uncertainty sample 55 after 612 steps.
Found uncertainty sample 56 after 3926 steps.
Found uncertainty sample 57 after 2873 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3848 steps.
Found uncertainty sample 60 after 1260 steps.
Found uncertainty sample 61 after 1325 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2458 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2083 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 474 steps.
Found uncertainty sample 71 after 1488 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2113 steps.
Found uncertainty sample 81 after 3800 steps.
Found uncertainty sample 82 after 930 steps.
Found uncertainty sample 83 after 1569 steps.
Found uncertainty sample 84 after 539 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 540 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2932 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1366 steps.
Found uncertainty sample 91 after 3059 steps.
Found uncertainty sample 92 after 2587 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3754 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2480 steps.
Found uncertainty sample 98 after 1942 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_203024-vekfffbw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vekfffbw
Training model 15. Added 42 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.575518254121825, Training Loss Force: 4.762582455169662, time: 0.5780620574951172
Validation Loss Energy: 1.8485277726966518, Validation Loss Force: 5.522131135633403, time: 0.046694040298461914
Test Loss Energy: 8.629649461413633, Test Loss Force: 10.409223175934002, time: 8.473106861114502


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.6921397101949296, Training Loss Force: 4.738086932813441, time: 0.507072925567627
Validation Loss Energy: 3.287251241183176, Validation Loss Force: 4.926981933074195, time: 0.047168731689453125
Test Loss Energy: 9.955900472134099, Test Loss Force: 10.101642762876882, time: 8.402979850769043


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.135915930758973, Training Loss Force: 4.684650386320697, time: 0.5267605781555176
Validation Loss Energy: 1.4598574424648225, Validation Loss Force: 4.534438050379807, time: 0.04704403877258301
Test Loss Energy: 8.544173244189452, Test Loss Force: 9.926694991098627, time: 8.51945447921753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.3877191785892267, Training Loss Force: 4.429324704907037, time: 0.6218104362487793
Validation Loss Energy: 5.863448645292229, Validation Loss Force: 4.771435955848047, time: 0.043616294860839844
Test Loss Energy: 9.163618567418611, Test Loss Force: 9.965453197666125, time: 8.772185564041138


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.349302927781139, Training Loss Force: 4.558637321558695, time: 0.5372023582458496
Validation Loss Energy: 1.6147614645432609, Validation Loss Force: 5.068529591772447, time: 0.05315589904785156
Test Loss Energy: 8.691984075339166, Test Loss Force: 10.402451259277026, time: 10.230686902999878


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0271910536804523, Training Loss Force: 4.7070972378260345, time: 0.5659117698669434
Validation Loss Energy: 2.168001216470816, Validation Loss Force: 4.482630956211664, time: 0.05153965950012207
Test Loss Energy: 9.345032921661845, Test Loss Force: 9.996804603048679, time: 9.753509759902954


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.955508525041895, Training Loss Force: 4.26534424984984, time: 0.6135473251342773
Validation Loss Energy: 1.9730837715383, Validation Loss Force: 4.432307283893691, time: 0.049721479415893555
Test Loss Energy: 8.51486586928648, Test Loss Force: 9.995573137749064, time: 9.333489418029785


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.966610886254678, Training Loss Force: 4.253995093626546, time: 0.5343070030212402
Validation Loss Energy: 2.4767571489131837, Validation Loss Force: 4.429931404106642, time: 0.05251193046569824
Test Loss Energy: 9.46849685424988, Test Loss Force: 10.025962831592931, time: 9.001193523406982


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.95039072438209, Training Loss Force: 4.240536693797125, time: 0.5522894859313965
Validation Loss Energy: 1.822280535785841, Validation Loss Force: 4.42486701705166, time: 0.05024218559265137
Test Loss Energy: 8.500980142071544, Test Loss Force: 9.981826593905822, time: 8.959072351455688


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.988667007389312, Training Loss Force: 4.240436452196159, time: 0.5555858612060547
Validation Loss Energy: 2.5755349633999174, Validation Loss Force: 4.434422195441714, time: 0.05059218406677246
Test Loss Energy: 9.483947122500913, Test Loss Force: 9.975776554298648, time: 9.649233341217041


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.97270845477299, Training Loss Force: 4.240283944073848, time: 0.5663259029388428
Validation Loss Energy: 1.7922932365654538, Validation Loss Force: 4.41244920412156, time: 0.04527783393859863
Test Loss Energy: 8.355133161855962, Test Loss Force: 9.986786193560215, time: 8.92923355102539


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0060087739925874, Training Loss Force: 4.237269186021832, time: 0.525212287902832
Validation Loss Energy: 2.3990422769471964, Validation Loss Force: 4.452803533438053, time: 0.04588961601257324
Test Loss Energy: 9.310997026382443, Test Loss Force: 9.967658760038487, time: 8.921439170837402


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9584172520951495, Training Loss Force: 4.245865861456815, time: 0.5528872013092041
Validation Loss Energy: 1.9202238976482107, Validation Loss Force: 4.4167119822512015, time: 0.045296669006347656
Test Loss Energy: 8.464264676601031, Test Loss Force: 10.00159470834816, time: 9.13438606262207


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.995085502874854, Training Loss Force: 4.223847884221634, time: 0.5537123680114746
Validation Loss Energy: 2.3524932919909927, Validation Loss Force: 4.413434292423144, time: 0.05323934555053711
Test Loss Energy: 9.160769314011848, Test Loss Force: 9.955282687663889, time: 8.93109679222107


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9568781224731975, Training Loss Force: 4.222581301634297, time: 0.5389699935913086
Validation Loss Energy: 1.8993375317601842, Validation Loss Force: 4.445369946670399, time: 0.05260920524597168
Test Loss Energy: 8.596578346077063, Test Loss Force: 9.96806863914321, time: 8.92558240890503


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0176390061535416, Training Loss Force: 4.23704840618987, time: 0.5357565879821777
Validation Loss Energy: 2.46256510822833, Validation Loss Force: 4.429514567465465, time: 0.04950976371765137
Test Loss Energy: 9.102856764764368, Test Loss Force: 9.963232195345237, time: 9.109187364578247


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8868675489759124, Training Loss Force: 4.224197002452248, time: 0.5357255935668945
Validation Loss Energy: 1.7483157462409968, Validation Loss Force: 4.431751501705456, time: 0.05253148078918457
Test Loss Energy: 8.464261869337664, Test Loss Force: 9.925644636255338, time: 9.028323411941528


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0785947860645217, Training Loss Force: 4.224647286698163, time: 0.544370174407959
Validation Loss Energy: 2.3186486951556984, Validation Loss Force: 4.427427266891538, time: 0.05492544174194336
Test Loss Energy: 9.304725609343546, Test Loss Force: 9.96000100722866, time: 8.944729328155518


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0509039952019856, Training Loss Force: 4.231474963729548, time: 0.5682599544525146
Validation Loss Energy: 2.146437713710023, Validation Loss Force: 4.424819811192724, time: 0.04550933837890625
Test Loss Energy: 8.590708526249628, Test Loss Force: 9.934178544356303, time: 9.105118989944458


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0071747404899387, Training Loss Force: 4.2273173394171835, time: 0.5397844314575195
Validation Loss Energy: 2.4849930126136144, Validation Loss Force: 4.453101910093596, time: 0.04603457450866699
Test Loss Energy: 9.320695477795315, Test Loss Force: 9.982721103663105, time: 8.921846628189087

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–‚â–…â–‚â–…â–‚â–†â–‚â–†â–â–…â–â–…â–‚â–„â–â–…â–‚â–…
wandb:   test_error_force â–ˆâ–„â–â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚
wandb:          test_loss â–„â–†â–†â–ˆâ–‡â–…â–‚â–ƒâ–‚â–„â–â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–â–ƒ
wandb: train_error_energy â–ˆâ–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ˆâ–‡â–„â–…â–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–„â–„â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–„â–â–ˆâ–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒ
wandb:  valid_error_force â–ˆâ–„â–‚â–ƒâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–ƒâ–â–ˆâ–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1048
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.3207
wandb:   test_error_force 9.98272
wandb:          test_loss 7.4054
wandb: train_error_energy 3.00717
wandb:  train_error_force 4.22732
wandb:         train_loss 1.37371
wandb: valid_error_energy 2.48499
wandb:  valid_error_force 4.4531
wandb:         valid_loss 1.24958
wandb: 
wandb: ğŸš€ View run al_73_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vekfffbw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_203024-vekfffbw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4001522064208984, Uncertainty Bias: -0.04556635022163391
0.00018310547 0.03818512
2.8394935 9.669413
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2441 steps.
Found uncertainty sample 4 after 2293 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1050 steps.
Found uncertainty sample 18 after 2816 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1174 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1095 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 291 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1014 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 995 steps.
Found uncertainty sample 44 after 1319 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1083 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2042 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3968 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3147 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1987 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 364 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3823 steps.
Found uncertainty sample 74 after 148 steps.
Found uncertainty sample 75 after 2615 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1233 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1183 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2919 steps.
Found uncertainty sample 88 after 2453 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3641 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 951 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_210830-hmfctn4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hmfctn4i
Training model 16. Added 25 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.891749111123094, Training Loss Force: 4.789633238147999, time: 0.5795960426330566
Validation Loss Energy: 1.6973360906191217, Validation Loss Force: 5.155623065495766, time: 0.05217409133911133
Test Loss Energy: 8.182614446987387, Test Loss Force: 10.522298597265285, time: 10.117145776748657


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.785515039534217, Training Loss Force: 4.723437604322814, time: 0.609504222869873
Validation Loss Energy: 1.5924512408015992, Validation Loss Force: 5.146694032744063, time: 0.05053234100341797
Test Loss Energy: 8.6453524929537, Test Loss Force: 10.31244173606639, time: 9.825649738311768


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.238143424265627, Training Loss Force: 4.936854198877143, time: 0.6000475883483887
Validation Loss Energy: 2.2881911186991117, Validation Loss Force: 4.5192359824490245, time: 0.05046510696411133
Test Loss Energy: 9.12343986693371, Test Loss Force: 9.938541651840387, time: 10.506789684295654


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.085841743044739, Training Loss Force: 4.602185714348478, time: 0.5650050640106201
Validation Loss Energy: 6.633170903597114, Validation Loss Force: 5.083890645473422, time: 0.04791092872619629
Test Loss Energy: 12.044834397692409, Test Loss Force: 10.355483290263065, time: 10.278838157653809


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.50610401477526, Training Loss Force: 4.681033644812611, time: 0.5557506084442139
Validation Loss Energy: 2.2331695727403553, Validation Loss Force: 4.6644590180699605, time: 0.05555105209350586
Test Loss Energy: 9.163882098101528, Test Loss Force: 9.974162452473378, time: 9.844846487045288


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0056771306261796, Training Loss Force: 5.024656186175527, time: 0.560713529586792
Validation Loss Energy: 1.6206498387727482, Validation Loss Force: 5.135497782748521, time: 0.05308794975280762
Test Loss Energy: 9.119387078632556, Test Loss Force: 10.399831266489231, time: 10.139204740524292


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.550198669239644, Training Loss Force: 4.66696462228179, time: 0.5348126888275146
Validation Loss Energy: 2.086480038124339, Validation Loss Force: 5.071638498387891, time: 0.04937577247619629
Test Loss Energy: 10.098529815574215, Test Loss Force: 10.283460421073094, time: 10.067310333251953


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.2781229490167827, Training Loss Force: 5.114692887571533, time: 0.6275744438171387
Validation Loss Energy: 2.7413375268257916, Validation Loss Force: 5.351329649881451, time: 0.051009178161621094
Test Loss Energy: 10.061575709401232, Test Loss Force: 10.44543563296967, time: 9.795457363128662


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.5845501518637506, Training Loss Force: 5.153927453047712, time: 0.597569465637207
Validation Loss Energy: 3.1452497827655237, Validation Loss Force: 4.772448209785435, time: 0.050768136978149414
Test Loss Energy: 9.714045700260039, Test Loss Force: 10.036389329506493, time: 10.182287216186523


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.861675936276236, Training Loss Force: 4.457038838124542, time: 0.5266134738922119
Validation Loss Energy: 2.727653617131945, Validation Loss Force: 4.478674125488527, time: 0.04771161079406738
Test Loss Energy: 9.723245517346104, Test Loss Force: 9.91869571278284, time: 10.057424545288086


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0294484339888563, Training Loss Force: 4.294466005522147, time: 0.6022007465362549
Validation Loss Energy: 3.247147859994144, Validation Loss Force: 4.44906358246305, time: 0.052486419677734375
Test Loss Energy: 8.57507230711141, Test Loss Force: 9.958557369709768, time: 9.925016164779663


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0018969714976054, Training Loss Force: 4.268607123249113, time: 0.6170105934143066
Validation Loss Energy: 2.3815625263227194, Validation Loss Force: 4.468954617268779, time: 0.0751349925994873
Test Loss Energy: 9.573800828604908, Test Loss Force: 10.022735630536456, time: 10.073511362075806


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9115962368872674, Training Loss Force: 4.270567351780733, time: 0.5788273811340332
Validation Loss Energy: 3.0159026119109473, Validation Loss Force: 4.43454377279539, time: 0.054383277893066406
Test Loss Energy: 9.591295092361309, Test Loss Force: 9.982204427306446, time: 10.217005968093872


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9091128963154835, Training Loss Force: 4.260501665079085, time: 0.5612936019897461
Validation Loss Energy: 2.939814115386817, Validation Loss Force: 4.44164291050586, time: 0.052062273025512695
Test Loss Energy: 8.620883277916676, Test Loss Force: 9.977397385162188, time: 10.020238161087036


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9070397385068696, Training Loss Force: 4.262896982572756, time: 0.5391967296600342
Validation Loss Energy: 2.2853246987835836, Validation Loss Force: 4.425459762318121, time: 0.053969621658325195
Test Loss Energy: 9.000970274491987, Test Loss Force: 9.997149416130506, time: 10.44339394569397


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0205280067447324, Training Loss Force: 4.260396997482314, time: 0.554255485534668
Validation Loss Energy: 2.851507317487337, Validation Loss Force: 4.4528966091410505, time: 0.04817795753479004
Test Loss Energy: 9.635434277208633, Test Loss Force: 10.0181437917098, time: 10.05643367767334


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.944915959976509, Training Loss Force: 4.26857057931281, time: 0.5989902019500732
Validation Loss Energy: 3.195788776147608, Validation Loss Force: 4.421772806599848, time: 0.055529117584228516
Test Loss Energy: 8.55231410044461, Test Loss Force: 9.921318741332184, time: 10.074857950210571


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0328407787797884, Training Loss Force: 4.266499533586536, time: 0.6085891723632812
Validation Loss Energy: 2.3826662972790835, Validation Loss Force: 4.448409380512314, time: 0.05303025245666504
Test Loss Energy: 9.35379178389055, Test Loss Force: 10.026719188551944, time: 9.823933362960815


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0148137270418975, Training Loss Force: 4.2674876606670535, time: 0.5439116954803467
Validation Loss Energy: 3.0289323196540576, Validation Loss Force: 4.458486495380422, time: 0.044879913330078125
Test Loss Energy: 9.927918430982531, Test Loss Force: 10.012490238415992, time: 9.519562482833862


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0212872332177816, Training Loss Force: 4.25611931361808, time: 0.5753438472747803
Validation Loss Energy: 3.4248440731806045, Validation Loss Force: 4.407441375029644, time: 0.0548548698425293
Test Loss Energy: 8.488405462808462, Test Loss Force: 9.878157211600717, time: 10.428043127059937

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–„â–„â–„â–‚â–„â–„â–‚â–‚â–„â–‚â–ƒâ–„â–‚
wandb:   test_error_force â–ˆâ–†â–‚â–†â–‚â–‡â–…â–‡â–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–
wandb:          test_loss â–â–‚â–ƒâ–ˆâ–ƒâ–„â–†â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–…â–…â–†â–„â–„â–‡â–„â–ˆâ–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–â–‚â–ˆâ–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„
wandb:  valid_error_force â–‡â–†â–‚â–†â–ƒâ–†â–†â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–â–â–ˆâ–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1070
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.48841
wandb:   test_error_force 9.87816
wandb:          test_loss 7.07693
wandb: train_error_energy 3.02129
wandb:  train_error_force 4.25612
wandb:         train_loss 1.40254
wandb: valid_error_energy 3.42484
wandb:  valid_error_force 4.40744
wandb:         valid_loss 1.67826
wandb: 
wandb: ğŸš€ View run al_73_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hmfctn4i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_210830-hmfctn4i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.20137619972229, Uncertainty Bias: -0.00459522008895874
0.0001449585 0.27315378
2.9547117 9.21393
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3736 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3175 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3296 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1225 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2091 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2515 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3717 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1537 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3387 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2624 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2397 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1187 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 747 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3560 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2090 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1299 steps.
Found uncertainty sample 96 after 2146 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_214926-mivu2ual
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/mivu2ual
Training model 17. Added 17 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.848994684349998, Training Loss Force: 4.902942126741539, time: 0.5996360778808594
Validation Loss Energy: 3.734978550305411, Validation Loss Force: 5.411089149927259, time: 0.05175280570983887
Test Loss Energy: 10.003715745046403, Test Loss Force: 10.31726610210336, time: 10.031097650527954


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.70300329129571, Training Loss Force: 5.068903649741236, time: 0.5947871208190918
Validation Loss Energy: 3.8049979765881337, Validation Loss Force: 4.716420199287085, time: 0.0529327392578125
Test Loss Energy: 8.547094933851259, Test Loss Force: 9.994178706613997, time: 10.033039331436157


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.307802932070327, Training Loss Force: 4.654803311109614, time: 0.6346025466918945
Validation Loss Energy: 2.1018767188886622, Validation Loss Force: 4.949478642225571, time: 0.05163764953613281
Test Loss Energy: 8.613745057690771, Test Loss Force: 10.116689946346662, time: 10.240459680557251


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.472149989152928, Training Loss Force: 4.54113255895757, time: 0.5965890884399414
Validation Loss Energy: 7.6790875171279085, Validation Loss Force: 4.602707965182974, time: 0.056255340576171875
Test Loss Energy: 12.950655407170721, Test Loss Force: 10.049423402031186, time: 10.139160394668579


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0767873148184144, Training Loss Force: 4.619459535307527, time: 0.5721533298492432
Validation Loss Energy: 6.901389250015891, Validation Loss Force: 5.263106352911693, time: 0.05268669128417969
Test Loss Energy: 9.83751126031471, Test Loss Force: 10.337358525413185, time: 10.160844564437866


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.478269670781386, Training Loss Force: 4.698091489798295, time: 0.56424880027771
Validation Loss Energy: 2.4441606126408146, Validation Loss Force: 5.181601874751162, time: 0.05350756645202637
Test Loss Energy: 9.625129307684853, Test Loss Force: 10.487152406007478, time: 10.276595830917358


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.952330986615939, Training Loss Force: 4.835280609535972, time: 0.5895354747772217
Validation Loss Energy: 2.88531205654551, Validation Loss Force: 4.489228197667212, time: 0.05420827865600586
Test Loss Energy: 9.568235186488883, Test Loss Force: 9.970849825739744, time: 10.390694856643677


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9651134759397837, Training Loss Force: 4.32437892014961, time: 0.6012437343597412
Validation Loss Energy: 3.2697256207146377, Validation Loss Force: 4.489335078857257, time: 0.05052757263183594
Test Loss Energy: 8.560115947005416, Test Loss Force: 10.00206436537501, time: 10.326777219772339


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9749839112713694, Training Loss Force: 4.29629933883696, time: 0.6241166591644287
Validation Loss Energy: 2.3032898681461833, Validation Loss Force: 4.4506739257264, time: 0.057242393493652344
Test Loss Energy: 9.307663354500002, Test Loss Force: 9.97624231752996, time: 10.882116794586182


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9593404345042478, Training Loss Force: 4.290325328673585, time: 0.6285278797149658
Validation Loss Energy: 2.937297954037833, Validation Loss Force: 4.455647463769842, time: 0.0524449348449707
Test Loss Energy: 9.727649866420274, Test Loss Force: 9.965661200959406, time: 10.33313250541687


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.953965695778037, Training Loss Force: 4.28532410761603, time: 0.5834956169128418
Validation Loss Energy: 3.2061344300057044, Validation Loss Force: 4.446458353455695, time: 0.0568239688873291
Test Loss Energy: 8.584946774403813, Test Loss Force: 9.942897937021634, time: 10.444355010986328


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0565811998966517, Training Loss Force: 4.299340468893839, time: 0.6193749904632568
Validation Loss Energy: 2.294000111378076, Validation Loss Force: 4.438451616306423, time: 0.05578041076660156
Test Loss Energy: 9.27431322423132, Test Loss Force: 9.954436824703055, time: 9.306080341339111


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9792887214768506, Training Loss Force: 4.279339533766408, time: 0.6130483150482178
Validation Loss Energy: 2.6929410559658247, Validation Loss Force: 4.428882632429322, time: 0.052376747131347656
Test Loss Energy: 9.45862722971995, Test Loss Force: 9.956650888140404, time: 10.489917039871216


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.995644546312711, Training Loss Force: 4.2870328706418785, time: 0.5904088020324707
Validation Loss Energy: 3.1051918260822604, Validation Loss Force: 4.453336158035112, time: 0.052361488342285156
Test Loss Energy: 8.650274157246791, Test Loss Force: 9.928943706984633, time: 9.331605195999146


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.115365684145181, Training Loss Force: 4.2899433201064685, time: 0.595984697341919
Validation Loss Energy: 2.545410499985639, Validation Loss Force: 4.448665895368422, time: 0.05074167251586914
Test Loss Energy: 9.327607603734187, Test Loss Force: 10.019610129823509, time: 8.74263858795166


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9378206993288147, Training Loss Force: 4.284732338164356, time: 0.5600054264068604
Validation Loss Energy: 2.9306305718013173, Validation Loss Force: 4.426102385473268, time: 0.049773216247558594
Test Loss Energy: 9.397013763049006, Test Loss Force: 9.981218238483008, time: 8.965065479278564


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.960064128875791, Training Loss Force: 4.276372637673328, time: 0.6431674957275391
Validation Loss Energy: 3.3554472298298963, Validation Loss Force: 4.450461499361184, time: 0.0522456169128418
Test Loss Energy: 8.617792979913311, Test Loss Force: 9.90407994320555, time: 8.773076295852661


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9789223324954115, Training Loss Force: 4.286793619193673, time: 0.7702078819274902
Validation Loss Energy: 2.5881226728883613, Validation Loss Force: 4.468161915109276, time: 0.04836630821228027
Test Loss Energy: 9.547231377198965, Test Loss Force: 9.952051522863453, time: 8.983899116516113


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.954607022212864, Training Loss Force: 4.287345629104613, time: 0.5996584892272949
Validation Loss Energy: 2.8088049420270353, Validation Loss Force: 4.438364330001219, time: 0.04902148246765137
Test Loss Energy: 9.544934476176104, Test Loss Force: 9.991901484414086, time: 8.846553325653076


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.966264341420511, Training Loss Force: 4.275332052361666, time: 0.5757253170013428
Validation Loss Energy: 3.1952677303461368, Validation Loss Force: 4.43910849028691, time: 0.05221366882324219
Test Loss Energy: 8.494891738086073, Test Loss Force: 9.947936298600103, time: 8.919240236282349

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–‚â–â–ƒâ–ƒâ–
wandb:   test_error_force â–†â–‚â–„â–ƒâ–†â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb:          test_loss â–‚â–‚â–ƒâ–ˆâ–†â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–
wandb: train_error_energy â–ˆâ–â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–‡â–ˆâ–„â–ƒâ–„â–…â–†â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–„â–„â–ƒâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–ƒâ–â–ˆâ–‡â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–…â–‚â–‡â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–‚â–â–ˆâ–ˆâ–â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1085
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.49489
wandb:   test_error_force 9.94794
wandb:          test_loss 7.28404
wandb: train_error_energy 2.96626
wandb:  train_error_force 4.27533
wandb:         train_loss 1.40003
wandb: valid_error_energy 3.19527
wandb:  valid_error_force 4.43911
wandb:         valid_loss 1.61636
wandb: 
wandb: ğŸš€ View run al_73_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/mivu2ual
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_214926-mivu2ual/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.199585199356079, Uncertainty Bias: 0.0012504160404205322
0.000828743 0.03722
3.0427706 9.211215
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3346 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 894 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2065 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3105 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 222 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3813 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 945 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3284 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3881 steps.
Found uncertainty sample 72 after 3628 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1045 steps.
Found uncertainty sample 76 after 2418 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1690 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_223026-0jx1mmhh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0jx1mmhh
Training model 18. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.869047095344693, Training Loss Force: 4.895922882720629, time: 0.612389087677002
Validation Loss Energy: 2.078901493742687, Validation Loss Force: 4.7637601050496245, time: 0.05704617500305176
Test Loss Energy: 8.394737114803593, Test Loss Force: 9.999338279482732, time: 8.75903868675232


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0021326374112123, Training Loss Force: 4.475365516459064, time: 0.5830886363983154
Validation Loss Energy: 3.3847956912706163, Validation Loss Force: 4.44011406414992, time: 0.04738616943359375
Test Loss Energy: 8.358550541015974, Test Loss Force: 9.93477750803755, time: 8.796577453613281


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0810241631260125, Training Loss Force: 4.3299172923498634, time: 0.5729272365570068
Validation Loss Energy: 2.6047723129368197, Validation Loss Force: 4.495056785231018, time: 0.046590566635131836
Test Loss Energy: 8.325190277552444, Test Loss Force: 9.925610174999035, time: 9.476853609085083


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0951595376942156, Training Loss Force: 4.348144963187609, time: 0.5426528453826904
Validation Loss Energy: 2.425994818377734, Validation Loss Force: 4.44048859365337, time: 0.04694008827209473
Test Loss Energy: 9.1746882970386, Test Loss Force: 9.964449591685412, time: 8.81290054321289


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.026599052379563, Training Loss Force: 4.31899914975561, time: 0.5545039176940918
Validation Loss Energy: 3.703979665155074, Validation Loss Force: 4.443201594527355, time: 0.04697585105895996
Test Loss Energy: 9.90513669599791, Test Loss Force: 9.955237127924502, time: 8.799317598342896


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0893402099858926, Training Loss Force: 4.334676482711461, time: 0.6209323406219482
Validation Loss Energy: 2.703984554927259, Validation Loss Force: 4.4598372064196194, time: 0.046186208724975586
Test Loss Energy: 9.381208361992165, Test Loss Force: 9.977022652808312, time: 8.899784326553345


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0124943934295474, Training Loss Force: 4.3411680962861565, time: 0.7298905849456787
Validation Loss Energy: 2.1601750639988917, Validation Loss Force: 4.431364948068126, time: 0.04783892631530762
Test Loss Energy: 8.256847175714496, Test Loss Force: 9.846810175662975, time: 8.87105417251587


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0738710408716066, Training Loss Force: 4.3093488661923445, time: 0.5760781764984131
Validation Loss Energy: 3.5889966582351533, Validation Loss Force: 4.474230985350684, time: 0.04762601852416992
Test Loss Energy: 8.480676341622846, Test Loss Force: 9.922378940250175, time: 8.869879007339478


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0684068513651117, Training Loss Force: 4.321490321264447, time: 0.5839102268218994
Validation Loss Energy: 2.5960031566318915, Validation Loss Force: 4.446388435343873, time: 0.047676801681518555
Test Loss Energy: 8.267440544917111, Test Loss Force: 9.909075598940284, time: 8.795917510986328


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.061575928183876, Training Loss Force: 4.345079203490672, time: 0.5647940635681152
Validation Loss Energy: 2.360169810796853, Validation Loss Force: 4.446809280029677, time: 0.04650998115539551
Test Loss Energy: 9.285030357841634, Test Loss Force: 9.940224149233472, time: 9.011329412460327


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9545472802681285, Training Loss Force: 4.317825944197572, time: 0.560302734375
Validation Loss Energy: 3.808888006567492, Validation Loss Force: 4.457056959463565, time: 0.0466763973236084
Test Loss Energy: 10.158521360186217, Test Loss Force: 9.94142189473007, time: 8.910570859909058


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.013659563812407, Training Loss Force: 4.322729513233388, time: 0.5627992153167725
Validation Loss Energy: 2.922413189639998, Validation Loss Force: 4.447576152568252, time: 0.04702925682067871
Test Loss Energy: 9.60746014022884, Test Loss Force: 9.975450394129563, time: 8.841978788375854


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0768433399660235, Training Loss Force: 4.3924711247657, time: 0.5600395202636719
Validation Loss Energy: 2.0138961312879666, Validation Loss Force: 4.449056011712088, time: 0.04816126823425293
Test Loss Energy: 8.433857985290421, Test Loss Force: 9.96048817934058, time: 8.970104455947876


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.010657188478351, Training Loss Force: 4.360994709726982, time: 0.5626420974731445
Validation Loss Energy: 3.598569427487735, Validation Loss Force: 4.4548458548445025, time: 0.04710555076599121
Test Loss Energy: 8.392307393383895, Test Loss Force: 9.94873061423656, time: 8.821568250656128


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1627956406784388, Training Loss Force: 4.344215266290398, time: 0.5576646327972412
Validation Loss Energy: 2.7685612792760685, Validation Loss Force: 4.498109133883396, time: 0.047768592834472656
Test Loss Energy: 8.311140516622801, Test Loss Force: 9.937723348558139, time: 8.823665857315063


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0781373339927662, Training Loss Force: 4.346168386436989, time: 0.6000106334686279
Validation Loss Energy: 2.4423084506849873, Validation Loss Force: 4.455772603829854, time: 0.05176663398742676
Test Loss Energy: 9.320723769600724, Test Loss Force: 9.963047363632818, time: 9.487672328948975


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.069519840824117, Training Loss Force: 4.315614419688118, time: 0.6246528625488281
Validation Loss Energy: 3.6449934950530736, Validation Loss Force: 4.469068623871494, time: 0.048493385314941406
Test Loss Energy: 10.002352398990434, Test Loss Force: 9.94741212377252, time: 8.858486890792847


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.060681122678001, Training Loss Force: 4.317436451327514, time: 0.6090424060821533
Validation Loss Energy: 2.978346343082183, Validation Loss Force: 4.494603430849909, time: 0.04943370819091797
Test Loss Energy: 9.375918741015754, Test Loss Force: 9.950365784526777, time: 8.799981355667114


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0546060276457023, Training Loss Force: 4.313173501424531, time: 0.5567913055419922
Validation Loss Energy: 1.9626864584383479, Validation Loss Force: 4.414409583282308, time: 0.046392202377319336
Test Loss Energy: 8.184837759937844, Test Loss Force: 9.917688250312416, time: 8.976434707641602


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9504046353237023, Training Loss Force: 4.33148259282598, time: 0.5507054328918457
Validation Loss Energy: 3.4082122466638203, Validation Loss Force: 4.471622638975286, time: 0.05126190185546875
Test Loss Energy: 8.431013159618818, Test Loss Force: 9.90194924896173, time: 8.840521097183228

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–…â–‡â–…â–â–‚â–â–…â–ˆâ–†â–‚â–‚â–â–…â–‡â–…â–â–‚
wandb:   test_error_force â–ˆâ–…â–…â–†â–†â–‡â–â–„â–„â–…â–…â–‡â–†â–†â–…â–†â–†â–†â–„â–„
wandb:          test_loss â–‚â–„â–‚â–„â–ˆâ–…â–„â–„â–‚â–…â–ˆâ–‡â–„â–ƒâ–‚â–…â–ˆâ–†â–â–„
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–ƒâ–ƒâ–ˆâ–„â–‚â–‡â–ƒâ–ƒâ–ˆâ–…â–â–‡â–„â–ƒâ–‡â–…â–â–†
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚
wandb:         valid_loss â–ƒâ–‡â–ƒâ–‚â–ˆâ–ƒâ–â–ˆâ–ƒâ–‚â–ˆâ–„â–â–ˆâ–„â–‚â–‡â–…â–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1096
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.43101
wandb:   test_error_force 9.90195
wandb:          test_loss 7.12373
wandb: train_error_energy 2.9504
wandb:  train_error_force 4.33148
wandb:         train_loss 1.39729
wandb: valid_error_energy 3.40821
wandb:  valid_error_force 4.47162
wandb:         valid_loss 1.66835
wandb: 
wandb: ğŸš€ View run al_73_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0jx1mmhh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_223026-0jx1mmhh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.085167646408081, Uncertainty Bias: 0.0055130720138549805
0.0002861023 0.02063036
3.1621144 8.962717
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1638 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2348 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2173 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3000 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3916 steps.
Found uncertainty sample 28 after 1095 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1360 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 617 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3323 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2265 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2873 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3252 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 618 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_231111-p4vc6zr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/p4vc6zr7
Training model 19. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.82420349461136, Training Loss Force: 4.8069639505124835, time: 0.567533016204834
Validation Loss Energy: 7.169549702456725, Validation Loss Force: 4.602394001687216, time: 0.0490717887878418
Test Loss Energy: 12.520001406367413, Test Loss Force: 10.068251600863384, time: 8.662310361862183


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.8597614967215756, Training Loss Force: 4.700310061131307, time: 0.5715117454528809
Validation Loss Energy: 3.7972628957968944, Validation Loss Force: 4.648535502106372, time: 0.046448707580566406
Test Loss Energy: 9.781343600121843, Test Loss Force: 10.058932493737066, time: 8.709405660629272


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1453830534303497, Training Loss Force: 4.464565286720543, time: 0.5574643611907959
Validation Loss Energy: 2.5192635755250685, Validation Loss Force: 4.473246342387391, time: 0.04607439041137695
Test Loss Energy: 9.571872952144624, Test Loss Force: 9.94597037952427, time: 8.829957008361816


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.196008601490443, Training Loss Force: 4.324599456911011, time: 0.5655515193939209
Validation Loss Energy: 2.1264487044800853, Validation Loss Force: 4.469395056839424, time: 0.0490717887878418
Test Loss Energy: 8.590581236441421, Test Loss Force: 9.940690817131058, time: 8.662750244140625


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0520990975233113, Training Loss Force: 4.334232041458164, time: 0.5746357440948486
Validation Loss Energy: 3.212762845141683, Validation Loss Force: 4.464083507032463, time: 0.04603385925292969
Test Loss Energy: 8.413638136938774, Test Loss Force: 9.903310393973996, time: 8.68782639503479


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1182008955765315, Training Loss Force: 4.3895196643223535, time: 0.5468981266021729
Validation Loss Energy: 2.435864405601837, Validation Loss Force: 4.454107483956606, time: 0.05327916145324707
Test Loss Energy: 8.154308950339088, Test Loss Force: 9.866609118706855, time: 8.742257595062256


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0941086220311194, Training Loss Force: 4.353865505319836, time: 0.547316312789917
Validation Loss Energy: 2.4351948394800322, Validation Loss Force: 4.511130380198961, time: 0.04727673530578613
Test Loss Energy: 9.029331580655226, Test Loss Force: 9.919832836313004, time: 8.953901767730713


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.140567295562723, Training Loss Force: 4.358649042962047, time: 0.5551245212554932
Validation Loss Energy: 3.415632473282718, Validation Loss Force: 4.477245034909962, time: 0.04774308204650879
Test Loss Energy: 9.871442204980536, Test Loss Force: 9.889469774165311, time: 8.752434492111206


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.118806142125041, Training Loss Force: 4.342974502913483, time: 0.5567069053649902
Validation Loss Energy: 2.7810325328011922, Validation Loss Force: 4.4695348930630665, time: 0.04928421974182129
Test Loss Energy: 9.319622832721292, Test Loss Force: 9.915196211842842, time: 8.812736988067627


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.16303020035676, Training Loss Force: 4.333186991536569, time: 0.5780658721923828
Validation Loss Energy: 2.2152507185601085, Validation Loss Force: 4.461191925503444, time: 0.0521240234375
Test Loss Energy: 8.183292328810856, Test Loss Force: 9.879832079952491, time: 8.930295705795288


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.051824959994796, Training Loss Force: 4.315136730750347, time: 0.603626012802124
Validation Loss Energy: 3.5251456126329224, Validation Loss Force: 4.478173119910189, time: 0.046144962310791016
Test Loss Energy: 8.442344342453564, Test Loss Force: 9.937502805844263, time: 8.727864503860474


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.011864093421133, Training Loss Force: 4.3177164100637, time: 0.6034066677093506
Validation Loss Energy: 2.4544742021418977, Validation Loss Force: 4.4478682944877095, time: 0.04780721664428711
Test Loss Energy: 8.183792674542406, Test Loss Force: 9.906953620269944, time: 9.261610746383667


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.141684703413781, Training Loss Force: 4.328684316031081, time: 0.5625815391540527
Validation Loss Energy: 2.443771386973733, Validation Loss Force: 4.485115943880218, time: 0.04646563529968262
Test Loss Energy: 9.228724530860816, Test Loss Force: 9.903852331037744, time: 8.937203168869019


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0311093877036717, Training Loss Force: 4.320932019733874, time: 0.5591492652893066
Validation Loss Energy: 3.9187253521941674, Validation Loss Force: 4.498672486822593, time: 0.05387401580810547
Test Loss Energy: 10.523818669757391, Test Loss Force: 9.919896470724844, time: 8.782335758209229


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0701676235414745, Training Loss Force: 4.342991094945844, time: 0.5902855396270752
Validation Loss Energy: 2.719513723833409, Validation Loss Force: 4.487590688768059, time: 0.05126810073852539
Test Loss Energy: 9.643292385617515, Test Loss Force: 9.901358012249588, time: 8.768782615661621


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.084373488799303, Training Loss Force: 4.3319661347813, time: 0.5481102466583252
Validation Loss Energy: 2.112259113155837, Validation Loss Force: 4.4496679065250975, time: 0.046741485595703125
Test Loss Energy: 8.280999251597366, Test Loss Force: 9.795975644365507, time: 8.996779680252075


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.091572449087893, Training Loss Force: 4.339237752012206, time: 0.6034853458404541
Validation Loss Energy: 3.226129673971728, Validation Loss Force: 4.549196116033609, time: 0.04934263229370117
Test Loss Energy: 8.388919732977119, Test Loss Force: 9.885986496596175, time: 8.766062498092651


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0633941585428515, Training Loss Force: 4.346826545536547, time: 0.5776901245117188
Validation Loss Energy: 2.315387705513586, Validation Loss Force: 4.4424414020631575, time: 0.0469970703125
Test Loss Energy: 8.107282215323513, Test Loss Force: 9.848819672606217, time: 8.765486717224121


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.03263023069431, Training Loss Force: 4.329925842845067, time: 0.5629947185516357
Validation Loss Energy: 2.4590671986149504, Validation Loss Force: 4.46032930523212, time: 0.048859596252441406
Test Loss Energy: 9.364244461167154, Test Loss Force: 9.915969002017986, time: 8.828710317611694


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.018476740400592, Training Loss Force: 4.318489103809949, time: 0.7222352027893066
Validation Loss Energy: 4.071948444889997, Validation Loss Force: 4.4768691693916365, time: 0.04736495018005371
Test Loss Energy: 10.403144205659153, Test Loss Force: 9.965204708225727, time: 8.718148946762085

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–ƒâ–‚â–â–â–‚â–„â–ƒâ–â–‚â–â–ƒâ–…â–ƒâ–â–â–â–ƒâ–…
wandb:   test_error_force â–ˆâ–ˆâ–…â–…â–„â–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–„â–„â–„â–â–ƒâ–‚â–„â–…
wandb:          test_loss â–‡â–†â–†â–ƒâ–ƒâ–‚â–…â–†â–…â–â–‚â–â–ƒâ–ˆâ–…â–â–‚â–â–„â–‡
wandb: train_error_energy â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–ƒâ–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–â–ƒâ–â–â–ƒâ–‚â–â–ƒâ–â–â–„â–‚â–â–ƒâ–â–â–„
wandb:  valid_error_force â–†â–ˆâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–â–…â–â–‚â–‚
wandb:         valid_loss â–ˆâ–„â–â–â–ƒâ–â–â–ƒâ–‚â–â–ƒâ–â–â–ƒâ–‚â–â–ƒâ–â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1107
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.40314
wandb:   test_error_force 9.9652
wandb:          test_loss 7.96212
wandb: train_error_energy 3.01848
wandb:  train_error_force 4.31849
wandb:         train_loss 1.41597
wandb: valid_error_energy 4.07195
wandb:  valid_error_force 4.47687
wandb:         valid_loss 1.87478
wandb: 
wandb: ğŸš€ View run al_73_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/p4vc6zr7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_231111-p4vc6zr7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.202641487121582, Uncertainty Bias: -0.03620585799217224
0.00042152405 0.019586563
2.8465452 9.282002
(48745, 22, 3)
Found uncertainty sample 0 after 959 steps.
Found uncertainty sample 1 after 580 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2950 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1023 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 836 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1526 steps.
Found uncertainty sample 18 after 511 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2756 steps.
Found uncertainty sample 23 after 1423 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3025 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1701 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2917 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3130 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1721 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1452 steps.
Found uncertainty sample 63 after 912 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 537 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1601 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3734 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1639 steps.
Found uncertainty sample 87 after 1683 steps.
Found uncertainty sample 88 after 3154 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1203 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1681 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_234905-ghy7tfnd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ghy7tfnd
Training model 20. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.9590653712676955, Training Loss Force: 4.812074076991026, time: 0.6419088840484619
Validation Loss Energy: 2.0386473655418618, Validation Loss Force: 5.083329073887391, time: 0.055724382400512695
Test Loss Energy: 8.87204642449738, Test Loss Force: 10.234313460760978, time: 9.448881149291992


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0021788413473534, Training Loss Force: 4.775313541096249, time: 0.6221270561218262
Validation Loss Energy: 1.734146195139882, Validation Loss Force: 4.579988141547378, time: 0.04958224296569824
Test Loss Energy: 8.048923542030229, Test Loss Force: 9.886234762201623, time: 9.55044937133789


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.576705441992393, Training Loss Force: 4.678968782885036, time: 0.6224241256713867
Validation Loss Energy: 4.674251561769572, Validation Loss Force: 4.573936439499353, time: 0.05350136756896973
Test Loss Energy: 8.590824680268925, Test Loss Force: 9.792476339281095, time: 9.55695128440857


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.517022409913595, Training Loss Force: 4.487700773919704, time: 0.6449451446533203
Validation Loss Energy: 3.8207210903203865, Validation Loss Force: 4.511475072036857, time: 0.05453896522521973
Test Loss Energy: 10.015565707353723, Test Loss Force: 9.881340680903257, time: 9.391703605651855


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.393772634671364, Training Loss Force: 4.4117089158049065, time: 0.6156425476074219
Validation Loss Energy: 3.358638746698479, Validation Loss Force: 4.564094908587637, time: 0.05094170570373535
Test Loss Energy: 8.42538455459581, Test Loss Force: 9.94474092873923, time: 9.505329608917236


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.461433639046603, Training Loss Force: 4.461770556020153, time: 0.5738589763641357
Validation Loss Energy: 3.9032992791025825, Validation Loss Force: 4.611021095077042, time: 0.05698370933532715
Test Loss Energy: 9.95070184006607, Test Loss Force: 9.998763951635997, time: 9.653305530548096


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.376166621363264, Training Loss Force: 4.45240653909188, time: 0.585310697555542
Validation Loss Energy: 3.477756496989133, Validation Loss Force: 4.695032382482429, time: 0.05996441841125488
Test Loss Energy: 8.32570338187631, Test Loss Force: 9.875198626477495, time: 9.597211837768555


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.514206665784526, Training Loss Force: 4.456361353422194, time: 0.5619969367980957
Validation Loss Energy: 3.349780745404326, Validation Loss Force: 4.54775188395312, time: 0.0505528450012207
Test Loss Energy: 9.490363845730114, Test Loss Force: 9.829003065253966, time: 9.975690841674805


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.328243143066026, Training Loss Force: 4.4038763430392756, time: 0.608290433883667
Validation Loss Energy: 3.626783166960807, Validation Loss Force: 4.499436241993125, time: 0.05465340614318848
Test Loss Energy: 8.43939704001094, Test Loss Force: 9.80888060142816, time: 9.600317239761353


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.450875985605822, Training Loss Force: 4.421536851528213, time: 0.6125810146331787
Validation Loss Energy: 4.058061906273356, Validation Loss Force: 4.532230508467078, time: 0.05762839317321777
Test Loss Energy: 10.220654837421977, Test Loss Force: 9.88905254114974, time: 9.697633266448975


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.334988484244633, Training Loss Force: 4.397566691156199, time: 0.5934488773345947
Validation Loss Energy: 3.631831744506428, Validation Loss Force: 4.50446544732305, time: 0.050405263900756836
Test Loss Energy: 8.37275718693151, Test Loss Force: 9.780638104992665, time: 9.42050313949585


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.36028385385338, Training Loss Force: 4.425313468689246, time: 0.5912237167358398
Validation Loss Energy: 3.9391788492625106, Validation Loss Force: 4.555370286111894, time: 0.05041337013244629
Test Loss Energy: 10.02313657489597, Test Loss Force: 9.770393333081552, time: 9.413045883178711


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.478785775509447, Training Loss Force: 4.3834561226377415, time: 0.593111515045166
Validation Loss Energy: 3.5068237272985465, Validation Loss Force: 4.4799647158583245, time: 0.05324530601501465
Test Loss Energy: 8.467768428073521, Test Loss Force: 9.740660827986073, time: 9.139983177185059


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.4093681868166446, Training Loss Force: 4.4056609001682965, time: 0.5862047672271729
Validation Loss Energy: 3.994831884919118, Validation Loss Force: 4.525797151502933, time: 0.05452847480773926
Test Loss Energy: 9.839581798914919, Test Loss Force: 9.88578071766274, time: 10.222988843917847


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.369808532755696, Training Loss Force: 4.405478311468636, time: 0.5808196067810059
Validation Loss Energy: 3.5112824542766043, Validation Loss Force: 4.46779807372483, time: 0.05217576026916504
Test Loss Energy: 8.302722627307512, Test Loss Force: 9.784415632260401, time: 8.4388906955719


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.365143273959536, Training Loss Force: 4.401566261984847, time: 0.5903604030609131
Validation Loss Energy: 3.9401710629767646, Validation Loss Force: 4.485444158201315, time: 0.04791617393493652
Test Loss Energy: 9.793605190244454, Test Loss Force: 9.727867531922358, time: 8.246119976043701


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.414795079241195, Training Loss Force: 4.380712492385682, time: 0.5764939785003662
Validation Loss Energy: 3.2057180387028197, Validation Loss Force: 4.485393834974335, time: 0.04754066467285156
Test Loss Energy: 8.306152322053169, Test Loss Force: 9.751297968580067, time: 8.259453296661377


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.414754293675966, Training Loss Force: 4.385090545095121, time: 0.6024429798126221
Validation Loss Energy: 3.7076207510292853, Validation Loss Force: 4.508068679442454, time: 0.04870343208312988
Test Loss Energy: 9.832327480628456, Test Loss Force: 9.827540765495868, time: 8.212845087051392


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4553080850651785, Training Loss Force: 4.418787815364114, time: 0.6808121204376221
Validation Loss Energy: 3.16500810676028, Validation Loss Force: 4.577640763411008, time: 0.06994938850402832
Test Loss Energy: 8.361074298763677, Test Loss Force: 9.832372368862986, time: 8.296214580535889


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.2971007414658855, Training Loss Force: 4.398765677913466, time: 0.5848648548126221
Validation Loss Energy: 3.7377844042132473, Validation Loss Force: 4.522653508500724, time: 0.048352718353271484
Test Loss Energy: 9.86358744476949, Test Loss Force: 9.829297081791154, time: 8.253140211105347

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–ƒâ–‡â–‚â–‡â–‚â–†â–‚â–ˆâ–‚â–‡â–‚â–‡â–‚â–‡â–‚â–‡â–‚â–‡
wandb:   test_error_force â–ˆâ–ƒâ–‚â–ƒâ–„â–…â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:          test_loss â–„â–‡â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–ƒâ–â–‚â–â–ƒâ–â–ƒâ–â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–…â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:  train_error_force â–ˆâ–‡â–†â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–â–ˆâ–†â–…â–†â–…â–…â–†â–‡â–†â–†â–…â–†â–…â–†â–…â–†â–„â–†
wandb:  valid_error_force â–ˆâ–‚â–‚â–â–‚â–ƒâ–„â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–‚
wandb:         valid_loss â–‚â–â–ˆâ–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1128
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.86359
wandb:   test_error_force 9.8293
wandb:          test_loss 6.28943
wandb: train_error_energy 4.2971
wandb:  train_error_force 4.39877
wandb:         train_loss 1.81626
wandb: valid_error_energy 3.73778
wandb:  valid_error_force 4.52265
wandb:         valid_loss 1.65075
wandb: 
wandb: ğŸš€ View run al_73_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ghy7tfnd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_234905-ghy7tfnd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.311148166656494, Uncertainty Bias: -0.16239404678344727
0.000415802 0.05117941
2.143378 8.595343
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2837 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_003200-ca0ano23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ca0ano23
Training model 21. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.624513536810179, Training Loss Force: 4.982498682842987, time: 0.5693066120147705
Validation Loss Energy: 3.869238915864884, Validation Loss Force: 5.004787876720867, time: 0.04935932159423828
Test Loss Energy: 8.405624565828592, Test Loss Force: 9.934882388702704, time: 8.908601999282837


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.123970343982394, Training Loss Force: 4.6079438817033695, time: 0.5801420211791992
Validation Loss Energy: 3.5915119289075537, Validation Loss Force: 4.5160878860638975, time: 0.04791617393493652
Test Loss Energy: 8.35090939396172, Test Loss Force: 9.757572430706968, time: 8.919487476348877


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0220466288757217, Training Loss Force: 4.379255060973047, time: 0.6046285629272461
Validation Loss Energy: 3.746357166331467, Validation Loss Force: 4.479440552688811, time: 0.049276113510131836
Test Loss Energy: 8.385058566048626, Test Loss Force: 9.69906569525552, time: 9.05817198753357


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0724259777580567, Training Loss Force: 4.3469331314248905, time: 0.5843136310577393
Validation Loss Energy: 3.4591515991702826, Validation Loss Force: 4.459255594610457, time: 0.047411441802978516
Test Loss Energy: 8.271973794944826, Test Loss Force: 9.711965536756852, time: 9.356873035430908


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0804991476284904, Training Loss Force: 4.358671741607372, time: 0.5489461421966553
Validation Loss Energy: 3.575905716476913, Validation Loss Force: 4.432426189217617, time: 0.047510385513305664
Test Loss Energy: 8.340451270034595, Test Loss Force: 9.647721813532874, time: 8.907146215438843


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.13361374574364, Training Loss Force: 4.350809510548554, time: 0.5620346069335938
Validation Loss Energy: 3.647748580395638, Validation Loss Force: 4.440498836434083, time: 0.04811978340148926
Test Loss Energy: 8.411527095870147, Test Loss Force: 9.677301332101223, time: 9.067663192749023


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.157123683009917, Training Loss Force: 4.359926896656698, time: 0.5853183269500732
Validation Loss Energy: 3.290259278675515, Validation Loss Force: 4.430541517566485, time: 0.04823756217956543
Test Loss Energy: 8.350822487709612, Test Loss Force: 9.663410176888677, time: 8.9449462890625


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.080713265660689, Training Loss Force: 4.324679880058317, time: 0.5985846519470215
Validation Loss Energy: 3.4266047181174555, Validation Loss Force: 4.4381385434872485, time: 0.04870891571044922
Test Loss Energy: 8.324503134557792, Test Loss Force: 9.681745332604667, time: 8.949906349182129


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.099516682301015, Training Loss Force: 4.356908239083149, time: 0.5760560035705566
Validation Loss Energy: 3.349388847707493, Validation Loss Force: 4.4633749738101205, time: 0.04760551452636719
Test Loss Energy: 8.268798117896587, Test Loss Force: 9.724222458988045, time: 8.912708044052124


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.06562710011299, Training Loss Force: 4.36724262340836, time: 0.5655059814453125
Validation Loss Energy: 3.2575614279417486, Validation Loss Force: 4.441311133478428, time: 0.05041837692260742
Test Loss Energy: 8.404339883768907, Test Loss Force: 9.700829015719544, time: 9.1051664352417


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1028865633407405, Training Loss Force: 4.347635683506564, time: 0.5888230800628662
Validation Loss Energy: 3.2352938453415323, Validation Loss Force: 4.508599968024638, time: 0.05179738998413086
Test Loss Energy: 8.358780825213532, Test Loss Force: 9.737151217167364, time: 8.930468320846558


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0428840322926605, Training Loss Force: 4.391347789320599, time: 0.6259644031524658
Validation Loss Energy: 3.682484076483789, Validation Loss Force: 4.420956056172585, time: 0.047847747802734375
Test Loss Energy: 8.328073560866903, Test Loss Force: 9.680876260757145, time: 8.970382928848267


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.147817671394157, Training Loss Force: 4.344515092946214, time: 0.5698196887969971
Validation Loss Energy: 3.501108032991726, Validation Loss Force: 4.467782486884615, time: 0.05205273628234863
Test Loss Energy: 8.373071152758884, Test Loss Force: 9.755506863108007, time: 10.044931173324585


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.070375915506159, Training Loss Force: 4.352794197757733, time: 0.5732550621032715
Validation Loss Energy: 3.433212425022863, Validation Loss Force: 4.43780275841519, time: 0.05132603645324707
Test Loss Energy: 8.4838119685358, Test Loss Force: 9.734617899801881, time: 9.651913166046143


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.034314981326873, Training Loss Force: 4.360606742670738, time: 0.5700299739837646
Validation Loss Energy: 3.5116476316759258, Validation Loss Force: 4.438716147251785, time: 0.05457162857055664
Test Loss Energy: 8.342534609196179, Test Loss Force: 9.732478755788586, time: 9.960179090499878


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.034990052324785, Training Loss Force: 4.352446060733328, time: 0.6161518096923828
Validation Loss Energy: 3.360236175151365, Validation Loss Force: 4.466793390538403, time: 0.05079817771911621
Test Loss Energy: 8.31508278408431, Test Loss Force: 9.722952088375665, time: 9.834711074829102


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0298706381571163, Training Loss Force: 4.358426960178203, time: 0.6098134517669678
Validation Loss Energy: 3.176657488467784, Validation Loss Force: 4.491715412027226, time: 0.05408811569213867
Test Loss Energy: 8.280091491277192, Test Loss Force: 9.727572648024726, time: 10.303740501403809


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.114127186348862, Training Loss Force: 4.379473134475211, time: 0.5646235942840576
Validation Loss Energy: 3.4405133009795428, Validation Loss Force: 4.454592457356436, time: 0.05048632621765137
Test Loss Energy: 8.369212830399581, Test Loss Force: 9.741670803936492, time: 9.804605484008789


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.054120276140912, Training Loss Force: 4.356280411055696, time: 0.7643587589263916
Validation Loss Energy: 3.2938992512039964, Validation Loss Force: 4.4394411579909265, time: 0.07776713371276855
Test Loss Energy: 8.176860888433495, Test Loss Force: 9.700818919830517, time: 9.736124992370605


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0873332595732736, Training Loss Force: 4.325924309877113, time: 0.6062815189361572
Validation Loss Energy: 3.4184327604619056, Validation Loss Force: 4.446200947923002, time: 0.05269598960876465
Test Loss Energy: 8.332549565105394, Test Loss Force: 9.72405374805547, time: 9.695393323898315

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–†â–ƒâ–…â–†â–…â–„â–ƒâ–†â–…â–„â–…â–ˆâ–…â–„â–ƒâ–…â–â–…
wandb:   test_error_force â–ˆâ–„â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒ
wandb:          test_loss â–â–„â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–‡â–„â–…â–†â–‚â–„â–ƒâ–‚â–‚â–†â–„â–„â–„â–ƒâ–â–„â–‚â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–
wandb:         valid_loss â–ˆâ–„â–…â–‚â–„â–…â–â–‚â–‚â–â–‚â–…â–„â–ƒâ–„â–ƒâ–â–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1129
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.33255
wandb:   test_error_force 9.72405
wandb:          test_loss 7.0199
wandb: train_error_energy 3.08733
wandb:  train_error_force 4.32592
wandb:         train_loss 1.43888
wandb: valid_error_energy 3.41843
wandb:  valid_error_force 4.4462
wandb:         valid_loss 1.66534
wandb: 
wandb: ğŸš€ View run al_73_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ca0ano23
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_003200-ca0ano23/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1557538509368896, Uncertainty Bias: -0.016192525625228882
0.00015258789 0.18877125
3.0819812 8.970505
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3827 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3024 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1534 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3933 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2294 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1997 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_011426-vvkcjwmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vvkcjwmv
Training model 22. Added 6 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.208603297915628, Training Loss Force: 4.908121658485982, time: 0.552070140838623
Validation Loss Energy: 1.5554191351423488, Validation Loss Force: 4.6240766324410805, time: 0.05131220817565918
Test Loss Energy: 8.509014047188233, Test Loss Force: 9.867907473351583, time: 8.536057233810425


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.232190165594618, Training Loss Force: 4.576325914474812, time: 0.6080238819122314
Validation Loss Energy: 1.9092220378170646, Validation Loss Force: 4.565191776800477, time: 0.04875349998474121
Test Loss Energy: 8.089825861280659, Test Loss Force: 9.780706015584753, time: 8.361652135848999


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.274038422415293, Training Loss Force: 4.391828630970723, time: 0.586040735244751
Validation Loss Energy: 1.6421684737006366, Validation Loss Force: 4.446451673381317, time: 0.048172950744628906
Test Loss Energy: 8.264116887317202, Test Loss Force: 9.728685420177298, time: 8.621890544891357


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.217033967507898, Training Loss Force: 4.379308736607722, time: 0.6295428276062012
Validation Loss Energy: 1.9503169647129133, Validation Loss Force: 4.46296214521357, time: 0.053802490234375
Test Loss Energy: 8.723598468138551, Test Loss Force: 9.73516343687779, time: 8.508985757827759


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2140163026676256, Training Loss Force: 4.400957150536162, time: 0.6175796985626221
Validation Loss Energy: 1.735564708934015, Validation Loss Force: 4.477093619890732, time: 0.05306291580200195
Test Loss Energy: 8.378579910485872, Test Loss Force: 9.787179261802809, time: 8.44745683670044


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2345613322180804, Training Loss Force: 4.35323743306321, time: 0.565990686416626
Validation Loss Energy: 1.6300824377979681, Validation Loss Force: 4.452355523116446, time: 0.050280094146728516
Test Loss Energy: 8.097904852819072, Test Loss Force: 9.73141733044158, time: 8.477681875228882


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2155475427168847, Training Loss Force: 4.347708001496959, time: 0.5543098449707031
Validation Loss Energy: 1.9429123249342306, Validation Loss Force: 4.426102385473268, time: 0.04892086982727051
Test Loss Energy: 8.189018938569056, Test Loss Force: 9.687855910240167, time: 8.655887126922607


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2652352255646813, Training Loss Force: 4.365594080015974, time: 0.6100904941558838
Validation Loss Energy: 1.8072165227255341, Validation Loss Force: 4.463975735165834, time: 0.05109572410583496
Test Loss Energy: 8.160486624833355, Test Loss Force: 9.741984513286312, time: 8.443052768707275


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.185879016027282, Training Loss Force: 4.376526535111386, time: 0.6407644748687744
Validation Loss Energy: 2.0150845165197833, Validation Loss Force: 4.464975519631049, time: 0.04953360557556152
Test Loss Energy: 8.253889434635573, Test Loss Force: 9.77450526976903, time: 8.454605102539062


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.28089732795095, Training Loss Force: 4.361384928038978, time: 0.584061861038208
Validation Loss Energy: 1.6607075727868654, Validation Loss Force: 4.483468192200352, time: 0.05238819122314453
Test Loss Energy: 8.104372036840488, Test Loss Force: 9.760069803909587, time: 10.172532320022583


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2069565000803095, Training Loss Force: 4.366731071971861, time: 0.6811792850494385
Validation Loss Energy: 1.7657261354265177, Validation Loss Force: 4.4667951718915715, time: 0.05884432792663574
Test Loss Energy: 8.329536096118025, Test Loss Force: 9.770751091284827, time: 10.144853115081787


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2028340715503965, Training Loss Force: 4.393930776154378, time: 0.6801700592041016
Validation Loss Energy: 1.9582693705905783, Validation Loss Force: 4.445290676454449, time: 0.05353403091430664
Test Loss Energy: 8.181907326723186, Test Loss Force: 9.741552068820393, time: 9.459180116653442


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.20926777488877, Training Loss Force: 4.356116056484987, time: 0.6088013648986816
Validation Loss Energy: 1.7275114339332447, Validation Loss Force: 4.502220051655515, time: 0.05018305778503418
Test Loss Energy: 8.325387350238852, Test Loss Force: 9.778011401819509, time: 9.679712533950806


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2335544316180753, Training Loss Force: 4.381104340600483, time: 0.5774128437042236
Validation Loss Energy: 1.9853855738433726, Validation Loss Force: 4.455193664050442, time: 0.04887819290161133
Test Loss Energy: 8.211195244306547, Test Loss Force: 9.76123957003706, time: 8.942485332489014


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.202920204305719, Training Loss Force: 4.37030721267851, time: 0.5708985328674316
Validation Loss Energy: 1.637829431388515, Validation Loss Force: 4.489586249653864, time: 0.050282955169677734
Test Loss Energy: 8.318295442863688, Test Loss Force: 9.814320826022099, time: 8.974791765213013


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.193535018345447, Training Loss Force: 4.358378628603028, time: 0.6064431667327881
Validation Loss Energy: 1.7917462498084822, Validation Loss Force: 4.460208618555027, time: 0.051512956619262695
Test Loss Energy: 8.139312789580517, Test Loss Force: 9.789643316240033, time: 9.164320468902588


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1903690744097486, Training Loss Force: 4.362604963215786, time: 0.6146771907806396
Validation Loss Energy: 1.7781066512746755, Validation Loss Force: 4.502612394690639, time: 0.048686981201171875
Test Loss Energy: 8.369138708387549, Test Loss Force: 9.820908302677823, time: 8.95707082748413


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.251228059030861, Training Loss Force: 4.5281998876630825, time: 0.5960783958435059
Validation Loss Energy: 1.6870966499436324, Validation Loss Force: 4.593402621574652, time: 0.048941612243652344
Test Loss Energy: 8.577846925551043, Test Loss Force: 9.843916484023204, time: 8.966458320617676


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2313500070733903, Training Loss Force: 4.499842217328184, time: 0.599365234375
Validation Loss Energy: 1.7959678341461272, Validation Loss Force: 4.487032234550072, time: 0.049805641174316406
Test Loss Energy: 8.220532939060417, Test Loss Force: 9.860106951147584, time: 9.165898561477661


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.166650839435337, Training Loss Force: 4.357396533964406, time: 0.6161320209503174
Validation Loss Energy: 1.817593127594915, Validation Loss Force: 4.496706763602343, time: 0.05573105812072754
Test Loss Energy: 8.210470895745809, Test Loss Force: 9.773049661743379, time: 8.879938125610352

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–ƒâ–ˆâ–„â–â–‚â–‚â–ƒâ–â–„â–‚â–„â–‚â–„â–‚â–„â–†â–‚â–‚
wandb:   test_error_force â–ˆâ–…â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–„â–„â–„â–ƒâ–…â–„â–†â–…â–†â–‡â–ˆâ–„
wandb:          test_loss â–â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–†â–†â–ˆâ–†â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–ƒâ–ƒâ–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–‚â–‡â–„â–‚â–‡â–…â–ˆâ–ƒâ–„â–‡â–„â–ˆâ–‚â–…â–„â–ƒâ–…â–…
wandb:  valid_error_force â–ˆâ–†â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–ƒâ–‚â–„â–‡â–ƒâ–ƒ
wandb:         valid_loss â–ˆâ–…â–‚â–„â–‚â–â–„â–ƒâ–…â–â–‚â–„â–‚â–…â–â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1134
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.21047
wandb:   test_error_force 9.77305
wandb:          test_loss 8.62075
wandb: train_error_energy 2.16665
wandb:  train_error_force 4.3574
wandb:         train_loss 1.07733
wandb: valid_error_energy 1.81759
wandb:  valid_error_force 4.49671
wandb:         valid_loss 1.05362
wandb: 
wandb: ğŸš€ View run al_73_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vvkcjwmv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_011426-vvkcjwmv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0299954414367676, Uncertainty Bias: 0.0825190395116806
9.1552734e-05 0.0033855438
3.2131782 9.270836
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2716 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 781 steps.
Found uncertainty sample 11 after 1416 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3687 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2698 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1876 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3448 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1815 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3057 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2684 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2754 steps.
Found uncertainty sample 68 after 3012 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 627 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_015524-1q8n0n8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1q8n0n8l
Training model 23. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 10.461494054635066, Training Loss Force: 6.0279535424176665, time: 0.6604280471801758
Validation Loss Energy: 4.96243575982711, Validation Loss Force: 5.152320882061657, time: 0.054465532302856445
Test Loss Energy: 8.47433020101548, Test Loss Force: 10.231452103945454, time: 9.750779151916504


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.444795181937474, Training Loss Force: 4.700751231268818, time: 0.6049652099609375
Validation Loss Energy: 5.909666743897584, Validation Loss Force: 4.6252296132786945, time: 0.05675196647644043
Test Loss Energy: 10.81272017256949, Test Loss Force: 9.834906385712697, time: 9.591127872467041


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.425770899152777, Training Loss Force: 4.500989062393777, time: 0.6072380542755127
Validation Loss Energy: 5.350486179156676, Validation Loss Force: 4.618833219392773, time: 0.053412675857543945
Test Loss Energy: 8.826893999439907, Test Loss Force: 9.827365633298077, time: 9.993579149246216


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.330617532206849, Training Loss Force: 4.473720899819395, time: 0.5907790660858154
Validation Loss Energy: 5.737115078658639, Validation Loss Force: 4.600093829409782, time: 0.05697226524353027
Test Loss Energy: 10.89971157988587, Test Loss Force: 9.812500712101986, time: 9.794819593429565


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.481969236084627, Training Loss Force: 4.473418242968047, time: 0.6724715232849121
Validation Loss Energy: 5.4723926378309296, Validation Loss Force: 4.633838002460263, time: 0.05286526679992676
Test Loss Energy: 8.955905112423576, Test Loss Force: 9.79548514737189, time: 9.72775673866272


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.493315364063765, Training Loss Force: 4.46135788824021, time: 0.5741448402404785
Validation Loss Energy: 5.824469965959278, Validation Loss Force: 4.58266462468143, time: 0.056276559829711914
Test Loss Energy: 11.09409597120433, Test Loss Force: 9.716536017998411, time: 9.932010650634766


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.364398359072852, Training Loss Force: 4.461303321928949, time: 0.6105062961578369
Validation Loss Energy: 5.569833546765513, Validation Loss Force: 4.548305884788189, time: 0.05413317680358887
Test Loss Energy: 8.88231147212465, Test Loss Force: 9.605766194610556, time: 9.643134117126465


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.540912124871387, Training Loss Force: 4.468968094937362, time: 0.5972335338592529
Validation Loss Energy: 5.793202764488098, Validation Loss Force: 4.561571176487691, time: 0.05715775489807129
Test Loss Energy: 10.67314722546382, Test Loss Force: 9.693338649485485, time: 9.739957809448242


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.5624414850298045, Training Loss Force: 4.439720211912807, time: 0.5700681209564209
Validation Loss Energy: 5.553367608762445, Validation Loss Force: 4.525679136855591, time: 0.052491188049316406
Test Loss Energy: 8.835130687365922, Test Loss Force: 9.654878343924254, time: 9.813922882080078


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.455868172190235, Training Loss Force: 4.422185276451664, time: 0.6300601959228516
Validation Loss Energy: 6.028578302559109, Validation Loss Force: 4.601570125847283, time: 0.06031346321105957
Test Loss Energy: 11.165662324344481, Test Loss Force: 9.751760075840483, time: 8.94255805015564


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.364487952477817, Training Loss Force: 4.443670010002084, time: 0.6259438991546631
Validation Loss Energy: 5.477167109657913, Validation Loss Force: 4.5201400191814916, time: 0.0511319637298584
Test Loss Energy: 8.81874436465769, Test Loss Force: 9.668407450763592, time: 10.80099892616272


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.407222284053187, Training Loss Force: 4.421721815365431, time: 0.6248500347137451
Validation Loss Energy: 6.12816885942848, Validation Loss Force: 4.540063118344234, time: 0.05602860450744629
Test Loss Energy: 11.596921117864268, Test Loss Force: 9.722796280595484, time: 9.83641791343689


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.471163458084858, Training Loss Force: 4.463115582810876, time: 0.569180965423584
Validation Loss Energy: 5.806524614150666, Validation Loss Force: 4.529899607847506, time: 0.049040794372558594
Test Loss Energy: 8.818501643630558, Test Loss Force: 9.65718186673114, time: 8.522205352783203


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.506788430817434, Training Loss Force: 4.430475656981321, time: 0.5838029384613037
Validation Loss Energy: 6.124379475903081, Validation Loss Force: 4.533066408440892, time: 0.04845595359802246
Test Loss Energy: 10.633749326580089, Test Loss Force: 9.742165329959263, time: 8.410260438919067


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.35648946955008, Training Loss Force: 4.40644510378873, time: 0.5717291831970215
Validation Loss Energy: 5.1428151362220005, Validation Loss Force: 4.5302451903619865, time: 0.04947495460510254
Test Loss Energy: 8.639117022409284, Test Loss Force: 9.698719156779262, time: 8.650242567062378


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.342063134534304, Training Loss Force: 4.410432601001464, time: 0.5579688549041748
Validation Loss Energy: 6.1130816887769965, Validation Loss Force: 4.616120218518788, time: 0.048909664154052734
Test Loss Energy: 11.269468936128675, Test Loss Force: 9.860848441735136, time: 8.566829919815063


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.302013515573507, Training Loss Force: 4.410029953333087, time: 0.563119649887085
Validation Loss Energy: 5.567573900272638, Validation Loss Force: 4.523018685900046, time: 0.05330228805541992
Test Loss Energy: 8.842841223255599, Test Loss Force: 9.681031877344973, time: 8.465291976928711


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.558747038968872, Training Loss Force: 4.391587777177878, time: 0.5904123783111572
Validation Loss Energy: 5.927470032791095, Validation Loss Force: 4.538069784149888, time: 0.048597097396850586
Test Loss Energy: 11.009532594887435, Test Loss Force: 9.79526559326239, time: 8.662940263748169


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.47030687462149, Training Loss Force: 4.4112234042879725, time: 0.6151115894317627
Validation Loss Energy: 5.39243437421972, Validation Loss Force: 4.549469999083099, time: 0.049005985260009766
Test Loss Energy: 8.787437052429258, Test Loss Force: 9.740899589932473, time: 8.546862125396729


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.427660661267996, Training Loss Force: 4.4403758859540075, time: 0.5887935161590576
Validation Loss Energy: 6.266007740832158, Validation Loss Force: 4.517808673223628, time: 0.048999786376953125
Test Loss Energy: 11.273871499186448, Test Loss Force: 9.74450560833072, time: 8.500857591629028

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–‚â–†â–‚â–‡â–‚â–†â–‚â–‡â–‚â–ˆâ–‚â–†â–â–‡â–‚â–‡â–‚â–‡
wandb:   test_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–â–‡â–„â–ˆâ–„â–‡â–„â–†â–ƒâ–‡â–„â–ˆâ–„â–†â–ƒâ–‡â–„â–†â–ƒâ–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–ƒâ–…â–„â–†â–„â–…â–„â–‡â–„â–‡â–†â–‡â–‚â–‡â–„â–†â–ƒâ–ˆ
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–
wandb:         valid_loss â–â–‡â–‡â–†â–†â–…â–†â–„â–„â–†â–„â–…â–‡â–ˆâ–â–†â–‡â–ƒâ–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1145
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.27387
wandb:   test_error_force 9.74451
wandb:          test_loss 6.82054
wandb: train_error_energy 4.42766
wandb:  train_error_force 4.44038
wandb:         train_loss 1.8492
wandb: valid_error_energy 6.26601
wandb:  valid_error_force 4.51781
wandb:         valid_loss 2.32263
wandb: 
wandb: ğŸš€ View run al_73_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1q8n0n8l
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_015524-1q8n0n8l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.443688154220581, Uncertainty Bias: -0.17401716113090515
0.00025177002 0.3337078
1.8983252 8.545511
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 24.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 649 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2464 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 819 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1722 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3116 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_031439-g9piwgjg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g9piwgjg
Training model 25. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.335567553256669, Training Loss Force: 4.800759985535256, time: 0.6315171718597412
Validation Loss Energy: 3.403405265141531, Validation Loss Force: 4.600800581278957, time: 0.05875849723815918
Test Loss Energy: 9.568477879536644, Test Loss Force: 9.681405210730393, time: 9.592955589294434


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.928778777539251, Training Loss Force: 4.83945450192648, time: 0.5919437408447266
Validation Loss Energy: 10.844160197940507, Validation Loss Force: 4.722796552949873, time: 0.05254793167114258
Test Loss Energy: 11.629198878189388, Test Loss Force: 9.825947554932878, time: 9.268208026885986


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.6456722741107916, Training Loss Force: 4.6158034098061655, time: 0.5889041423797607
Validation Loss Energy: 2.7052902867989794, Validation Loss Force: 5.051369816710668, time: 0.0529940128326416
Test Loss Energy: 9.024875045394417, Test Loss Force: 9.996233413554513, time: 9.181219577789307


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0016590635229634, Training Loss Force: 5.285490577032852, time: 0.5868096351623535
Validation Loss Energy: 5.324962060297265, Validation Loss Force: 5.451078747182722, time: 0.0506289005279541
Test Loss Energy: 8.828019949875337, Test Loss Force: 10.151263996811752, time: 8.967117547988892


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.261324105646206, Training Loss Force: 4.749521427549209, time: 0.6041297912597656
Validation Loss Energy: 7.637055598465996, Validation Loss Force: 4.872966406316741, time: 0.050310373306274414
Test Loss Energy: 13.184377896134649, Test Loss Force: 10.00622591414717, time: 8.993132591247559


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.13027351582528, Training Loss Force: 4.566768707321429, time: 0.5968978404998779
Validation Loss Energy: 8.658990299642076, Validation Loss Force: 4.642660154021922, time: 0.054561614990234375
Test Loss Energy: 10.097545128310253, Test Loss Force: 9.674470789897558, time: 9.242964744567871


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.171735549919716, Training Loss Force: 4.481346229462709, time: 0.617753267288208
Validation Loss Energy: 6.629225206331274, Validation Loss Force: 4.5657511216950475, time: 0.062094688415527344
Test Loss Energy: 11.719637954664465, Test Loss Force: 9.685071790473105, time: 9.060952186584473


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.2093419564178385, Training Loss Force: 4.476877890599852, time: 0.5925469398498535
Validation Loss Energy: 2.1125076119226924, Validation Loss Force: 4.530315999150392, time: 0.051513671875
Test Loss Energy: 8.053227246982054, Test Loss Force: 9.667851794482516, time: 9.061136245727539


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.035542382154693, Training Loss Force: 4.471817573442038, time: 0.5856759548187256
Validation Loss Energy: 4.258812392152596, Validation Loss Force: 4.633526265655964, time: 0.0511324405670166
Test Loss Energy: 8.373037530883654, Test Loss Force: 9.597184665623345, time: 9.783597230911255


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.133066516775193, Training Loss Force: 4.487641420221806, time: 0.5792036056518555
Validation Loss Energy: 8.510421882772722, Validation Loss Force: 4.55384767449204, time: 0.05005383491516113
Test Loss Energy: 12.61777053661794, Test Loss Force: 9.629971370672793, time: 9.014791488647461


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.223607131546622, Training Loss Force: 4.611205304313265, time: 0.5727777481079102
Validation Loss Energy: 8.543481125530327, Validation Loss Force: 4.745948800066861, time: 0.05142068862915039
Test Loss Energy: 10.370610951724895, Test Loss Force: 9.653264195466704, time: 9.011724948883057


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.131183824405358, Training Loss Force: 4.507526108956877, time: 0.5835938453674316
Validation Loss Energy: 6.3196665516178365, Validation Loss Force: 4.660031464772332, time: 0.04976177215576172
Test Loss Energy: 11.10451203281321, Test Loss Force: 9.686419011086002, time: 8.954283475875854


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.181540024974398, Training Loss Force: 4.445018587128633, time: 0.675788402557373
Validation Loss Energy: 2.2668046379093316, Validation Loss Force: 4.587509459958527, time: 0.07480645179748535
Test Loss Energy: 7.777038550583551, Test Loss Force: 9.622668316988548, time: 9.108915567398071


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 5.3917784187494595, Training Loss Force: 4.797331672400488, time: 0.5681486129760742
Validation Loss Energy: 2.5653810276764646, Validation Loss Force: 6.535986509518639, time: 0.049965858459472656
Test Loss Energy: 8.054219204218757, Test Loss Force: 10.705808997966908, time: 8.98145079612732


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.384612233213905, Training Loss Force: 4.880799708942351, time: 0.5582940578460693
Validation Loss Energy: 2.271693339008176, Validation Loss Force: 4.516872572134147, time: 0.056420326232910156
Test Loss Energy: 8.560499544156077, Test Loss Force: 9.599673551750662, time: 9.057519435882568


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.28105231120406, Training Loss Force: 4.433171128845318, time: 0.5813677310943604
Validation Loss Energy: 1.986506490323973, Validation Loss Force: 4.509069354584254, time: 0.04924464225769043
Test Loss Energy: 7.779559295885842, Test Loss Force: 9.53073451732979, time: 9.185898303985596


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.389768022860663, Training Loss Force: 4.405479944375707, time: 0.5892062187194824
Validation Loss Energy: 2.3636632670273143, Validation Loss Force: 4.506317163940586, time: 0.05212116241455078
Test Loss Energy: 8.598086399098518, Test Loss Force: 9.615604193126922, time: 8.983108758926392


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.42486578000085, Training Loss Force: 4.416702722925883, time: 0.5702741146087646
Validation Loss Energy: 2.257474800694957, Validation Loss Force: 4.546055145061151, time: 0.054091691970825195
Test Loss Energy: 8.123569579666391, Test Loss Force: 9.626601824575909, time: 8.99834418296814


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.402982691348364, Training Loss Force: 4.379967391941377, time: 0.6168978214263916
Validation Loss Energy: 2.163861797048018, Validation Loss Force: 4.458889526534551, time: 0.04910850524902344
Test Loss Energy: 8.438057732896272, Test Loss Force: 9.535603128075797, time: 9.215914249420166


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.349744743804251, Training Loss Force: 4.3704373504237966, time: 0.6404280662536621
Validation Loss Energy: 2.0190629461500746, Validation Loss Force: 4.47849732618666, time: 0.04955458641052246
Test Loss Energy: 7.85056844455316, Test Loss Force: 9.589848689548102, time: 8.99209713935852

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–ƒâ–‚â–ˆâ–„â–†â–â–‚â–‡â–„â–…â–â–â–‚â–â–‚â–â–‚â–
wandb:   test_error_force â–‚â–ƒâ–„â–…â–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ˆâ–â–â–‚â–‚â–â–
wandb:          test_loss â–‚â–ˆâ–„â–…â–„â–‚â–ƒâ–â–â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–„â–„â–„â–„â–„
wandb:  train_error_force â–„â–…â–ƒâ–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–…â–â–â–â–â–
wandb:         train_loss â–†â–ƒâ–‚â–â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–‚â–„â–…â–†â–…â–â–ƒâ–†â–†â–„â–â–â–â–â–â–â–â–
wandb:  valid_error_force â–â–‚â–ƒâ–„â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–ˆâ–â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1149
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.85057
wandb:   test_error_force 9.58985
wandb:          test_loss 5.53455
wandb: train_error_energy 4.34974
wandb:  train_error_force 4.37044
wandb:         train_loss 1.81211
wandb: valid_error_energy 2.01906
wandb:  valid_error_force 4.4785
wandb:         valid_loss 1.32519
wandb: 
wandb: ğŸš€ View run al_73_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g9piwgjg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_031439-g9piwgjg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.241054058074951, Uncertainty Bias: -0.10564270615577698
0.0002593994 0.0014638901
2.2077076 8.289687
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3340 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1186 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 518 steps.
Found uncertainty sample 27 after 2258 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3401 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3859 steps.
Found uncertainty sample 47 after 3381 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3933 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1823 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_035628-1ln3a45y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1ln3a45y
Training model 26. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.794420894105151, Training Loss Force: 4.828363188610846, time: 0.6207525730133057
Validation Loss Energy: 2.0329011655620493, Validation Loss Force: 4.675962551486882, time: 0.06398391723632812
Test Loss Energy: 8.052752523357778, Test Loss Force: 9.655773539176078, time: 10.345093488693237


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.406276887613461, Training Loss Force: 4.43689674173275, time: 0.6164748668670654
Validation Loss Energy: 3.0193332754422566, Validation Loss Force: 4.48070041471647, time: 0.056153297424316406
Test Loss Energy: 7.935626652334276, Test Loss Force: 9.513306438771044, time: 10.27489972114563


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.346107543941277, Training Loss Force: 4.382105556032584, time: 0.6001970767974854
Validation Loss Energy: 5.531592347643874, Validation Loss Force: 4.501831271326725, time: 0.05294680595397949
Test Loss Energy: 10.122352896045268, Test Loss Force: 9.577196404841532, time: 10.326282262802124


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.465934001978738, Training Loss Force: 4.3763491192901425, time: 0.6179025173187256
Validation Loss Energy: 4.951443474769238, Validation Loss Force: 4.5092844529792195, time: 0.054859161376953125
Test Loss Energy: 8.436924922852182, Test Loss Force: 9.487610274770905, time: 10.33979058265686


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.355491393468751, Training Loss Force: 4.413280891435855, time: 0.5746650695800781
Validation Loss Energy: 2.3998234003111114, Validation Loss Force: 4.4729341602448, time: 0.05326104164123535
Test Loss Energy: 7.9995968445824905, Test Loss Force: 9.517348706829408, time: 10.330382823944092


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.271889949689742, Training Loss Force: 4.405908400267377, time: 0.64247727394104
Validation Loss Energy: 4.164590833729837, Validation Loss Force: 4.572070472056478, time: 0.05489993095397949
Test Loss Energy: 9.662239972417755, Test Loss Force: 9.585538808150543, time: 10.546225786209106


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.345893474638849, Training Loss Force: 4.396393874041668, time: 0.6028378009796143
Validation Loss Energy: 5.659315369748054, Validation Loss Force: 4.485938483705275, time: 0.05989575386047363
Test Loss Energy: 8.650223544899664, Test Loss Force: 9.510017482583688, time: 10.992435455322266


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.505065913792597, Training Loss Force: 4.376601565920775, time: 0.6010527610778809
Validation Loss Energy: 5.871860194948797, Validation Loss Force: 4.475244575302947, time: 0.05559563636779785
Test Loss Energy: 10.645143728799367, Test Loss Force: 9.51502304767832, time: 9.61362075805664


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.502801946314675, Training Loss Force: 4.425052723119364, time: 0.6949934959411621
Validation Loss Energy: 2.453262659318905, Validation Loss Force: 4.557985757899962, time: 0.052352190017700195
Test Loss Energy: 7.757454862152781, Test Loss Force: 9.520317924112899, time: 10.395466804504395


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.37704343177757, Training Loss Force: 4.419747095108067, time: 0.6485319137573242
Validation Loss Energy: 3.466648646644525, Validation Loss Force: 4.516143553350379, time: 0.05625653266906738
Test Loss Energy: 8.018431294472073, Test Loss Force: 9.476446282656346, time: 9.782830476760864


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.423319508614058, Training Loss Force: 4.412756222747198, time: 0.6005218029022217
Validation Loss Energy: 6.424310362084892, Validation Loss Force: 4.511870977778317, time: 0.055083274841308594
Test Loss Energy: 10.515018132258378, Test Loss Force: 9.516830272435723, time: 8.949487209320068


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.53475913327015, Training Loss Force: 4.432460696917151, time: 0.6060645580291748
Validation Loss Energy: 5.044351285231024, Validation Loss Force: 4.531362989474544, time: 0.05235004425048828
Test Loss Energy: 8.526985223954544, Test Loss Force: 9.44776337696119, time: 8.878498315811157


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.500153703044603, Training Loss Force: 4.4051788037474475, time: 0.6031198501586914
Validation Loss Energy: 2.413012761831852, Validation Loss Force: 4.520759484745462, time: 0.05436897277832031
Test Loss Energy: 8.229849504727373, Test Loss Force: 9.542587585347079, time: 8.77932596206665


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.313441510823038, Training Loss Force: 4.428341907489819, time: 0.6058783531188965
Validation Loss Energy: 3.2798960339548895, Validation Loss Force: 4.683014038000123, time: 0.05104398727416992
Test Loss Energy: 8.855869965710474, Test Loss Force: 9.463973252441283, time: 8.87912917137146


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.043142766573857, Training Loss Force: 5.020172340772589, time: 0.6297943592071533
Validation Loss Energy: 4.923562625669328, Validation Loss Force: 5.365545738834064, time: 0.051152706146240234
Test Loss Energy: 9.332083253567335, Test Loss Force: 10.02054761589176, time: 8.98423457145691


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.382667579053092, Training Loss Force: 5.353970361518113, time: 0.6038093566894531
Validation Loss Energy: 1.7426546058749288, Validation Loss Force: 4.957040486421279, time: 0.05053544044494629
Test Loss Energy: 7.931754650395089, Test Loss Force: 9.545470985242243, time: 8.790048360824585


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9583735104647926, Training Loss Force: 4.830603914244401, time: 0.5951857566833496
Validation Loss Energy: 2.4117622519083213, Validation Loss Force: 4.744776669682697, time: 0.050629377365112305
Test Loss Energy: 8.024459827270851, Test Loss Force: 9.68481294866613, time: 8.788015842437744


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0088452788281046, Training Loss Force: 4.431751200801204, time: 0.6020970344543457
Validation Loss Energy: 3.571518243625552, Validation Loss Force: 4.46265486179219, time: 0.052118539810180664
Test Loss Energy: 8.865186279563106, Test Loss Force: 9.425878655887388, time: 8.905847072601318


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.023974792725824, Training Loss Force: 4.369921593850385, time: 0.5958676338195801
Validation Loss Energy: 2.460693796725953, Validation Loss Force: 4.4601823435958075, time: 0.05127406120300293
Test Loss Energy: 8.252536308044174, Test Loss Force: 9.462522867231202, time: 8.824958324432373


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9614214418427625, Training Loss Force: 4.334932916925231, time: 0.633704423904419
Validation Loss Energy: 2.2434695794235373, Validation Loss Force: 4.452268236811243, time: 0.05399346351623535
Test Loss Energy: 7.565134089203898, Test Loss Force: 9.412197919520322, time: 9.37079405784607

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‡â–ƒâ–‚â–†â–ƒâ–ˆâ–â–‚â–ˆâ–ƒâ–ƒâ–„â–…â–‚â–‚â–„â–ƒâ–
wandb:   test_error_force â–„â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ˆâ–ƒâ–„â–â–‚â–
wandb:          test_loss â–â–â–ƒâ–‚â–â–ƒâ–‚â–„â–â–â–ƒâ–‚â–â–‚â–ˆâ–…â–†â–…â–„â–ƒ
wandb: train_error_energy â–ˆâ–…â–„â–…â–„â–„â–„â–…â–…â–…â–…â–…â–…â–„â–„â–‚â–â–â–â–
wandb:  train_error_force â–„â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–‚â–†â–ˆâ–„â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–†â–…â–‚â–â–â–
wandb: valid_error_energy â–â–ƒâ–‡â–†â–‚â–…â–‡â–‡â–‚â–„â–ˆâ–†â–‚â–ƒâ–†â–â–‚â–„â–‚â–‚
wandb:  valid_error_force â–ƒâ–â–â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–ƒâ–ˆâ–…â–ƒâ–â–â–
wandb:         valid_loss â–‚â–‚â–…â–…â–‚â–ƒâ–…â–…â–‚â–ƒâ–†â–…â–‚â–ƒâ–ˆâ–â–‚â–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1157
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.56513
wandb:   test_error_force 9.4122
wandb:          test_loss 6.44676
wandb: train_error_energy 2.96142
wandb:  train_error_force 4.33493
wandb:         train_loss 1.42512
wandb: valid_error_energy 2.24347
wandb:  valid_error_force 4.45227
wandb:         valid_loss 1.2329
wandb: 
wandb: ğŸš€ View run al_73_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1ln3a45y
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_035628-1ln3a45y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.059617042541504, Uncertainty Bias: 0.015889763832092285
0.0002861023 0.055813313
2.7038221 8.513924
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3830 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3182 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 713 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_043928-2himph2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2himph2b
Training model 27. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.984143470950315, Training Loss Force: 4.687727305902402, time: 0.59737229347229
Validation Loss Energy: 1.84636554395512, Validation Loss Force: 4.572334557663549, time: 0.05152535438537598
Test Loss Energy: 7.98614849319728, Test Loss Force: 9.409662494375697, time: 8.912248849868774


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.624433733726502, Training Loss Force: 4.66928081611758, time: 0.6187024116516113
Validation Loss Energy: 4.47061083037619, Validation Loss Force: 5.657794539481367, time: 0.05387473106384277
Test Loss Energy: 9.594499037898817, Test Loss Force: 10.245770490134806, time: 8.921007633209229


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1282447627601644, Training Loss Force: 4.927607139891282, time: 0.5782878398895264
Validation Loss Energy: 2.087036042981721, Validation Loss Force: 4.54529896064158, time: 0.05045628547668457
Test Loss Energy: 8.296462667820274, Test Loss Force: 9.461059154514965, time: 9.131070852279663


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.019711728737143, Training Loss Force: 4.414576958263025, time: 0.6129443645477295
Validation Loss Energy: 2.209452636669295, Validation Loss Force: 4.519583346316672, time: 0.05123639106750488
Test Loss Energy: 7.6220210640026735, Test Loss Force: 9.41515569790507, time: 8.93222427368164


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.074458218119829, Training Loss Force: 4.452485537825326, time: 0.5711088180541992
Validation Loss Energy: 3.3870190426927054, Validation Loss Force: 4.502496606734757, time: 0.05166339874267578
Test Loss Energy: 7.8175202839573394, Test Loss Force: 9.407369846216945, time: 8.885892391204834


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9539455659916385, Training Loss Force: 4.386262229305147, time: 0.5832016468048096
Validation Loss Energy: 2.0960663901948227, Validation Loss Force: 4.503417120984023, time: 0.04961252212524414
Test Loss Energy: 7.567922305616923, Test Loss Force: 9.425171952982106, time: 9.656115770339966


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0418827722264306, Training Loss Force: 4.391604687996797, time: 0.5950396060943604
Validation Loss Energy: 2.910813463152036, Validation Loss Force: 4.511174023351563, time: 0.051384925842285156
Test Loss Energy: 8.702308297000515, Test Loss Force: 9.467428350122486, time: 8.95193099975586


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.076895055090098, Training Loss Force: 4.438503191295089, time: 0.5727083683013916
Validation Loss Energy: 3.5131542111172736, Validation Loss Force: 4.557198399799961, time: 0.05615234375
Test Loss Energy: 8.747332380691825, Test Loss Force: 9.450423869885789, time: 8.97171926498413


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1222355905190113, Training Loss Force: 4.40721986135604, time: 0.6115367412567139
Validation Loss Energy: 2.19548705050585, Validation Loss Force: 4.508579927801504, time: 0.04971122741699219
Test Loss Energy: 8.028751132698927, Test Loss Force: 9.46201928988252, time: 8.931072235107422


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.039874708768986, Training Loss Force: 4.384759627818002, time: 0.6047892570495605
Validation Loss Energy: 2.332605819891598, Validation Loss Force: 4.487429476306407, time: 0.050054073333740234
Test Loss Energy: 7.445367184907019, Test Loss Force: 9.437229414954063, time: 9.073920965194702


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1175753238915482, Training Loss Force: 4.4085417517860535, time: 0.6035828590393066
Validation Loss Energy: 3.3391674432328236, Validation Loss Force: 4.4891248791835014, time: 0.05167675018310547
Test Loss Energy: 7.634914129833448, Test Loss Force: 9.427412685421457, time: 8.967149496078491


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.083577642018429, Training Loss Force: 4.401547888436928, time: 0.5933279991149902
Validation Loss Energy: 1.9164109111933432, Validation Loss Force: 4.483188965091359, time: 0.05235648155212402
Test Loss Energy: 7.327164276048541, Test Loss Force: 9.416389993784193, time: 8.894289016723633


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.042634370865212, Training Loss Force: 4.392906790963249, time: 0.6008148193359375
Validation Loss Energy: 2.7252187300212247, Validation Loss Force: 4.4798364584302695, time: 0.0507051944732666
Test Loss Energy: 8.320966437378164, Test Loss Force: 9.396582041383457, time: 9.095617771148682


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.156331502584952, Training Loss Force: 4.42097407431915, time: 0.6149194240570068
Validation Loss Energy: 3.2658625337019367, Validation Loss Force: 4.557325766551432, time: 0.055297136306762695
Test Loss Energy: 8.852634174987676, Test Loss Force: 9.5186348624692, time: 8.9978768825531


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.06738695016111, Training Loss Force: 4.380455944764444, time: 0.6056756973266602
Validation Loss Energy: 2.0983010977433536, Validation Loss Force: 4.520603616343313, time: 0.05124402046203613
Test Loss Energy: 7.999617145946402, Test Loss Force: 9.487026937567311, time: 8.968839168548584


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.079250678002952, Training Loss Force: 4.374129125959498, time: 0.5978758335113525
Validation Loss Energy: 2.5999626593847798, Validation Loss Force: 4.5120522304631026, time: 0.04978013038635254
Test Loss Energy: 7.647234056940677, Test Loss Force: 9.47473770849124, time: 9.193351030349731


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0275993559475993, Training Loss Force: 4.371010102943127, time: 0.5967681407928467
Validation Loss Energy: 3.418872309355967, Validation Loss Force: 4.518622751621139, time: 0.05332446098327637
Test Loss Energy: 7.80233533473723, Test Loss Force: 9.41245037270468, time: 8.981825351715088


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.2260578902535486, Training Loss Force: 4.37946961071926, time: 0.6364281177520752
Validation Loss Energy: 1.9166375883838978, Validation Loss Force: 4.534389508505994, time: 0.05267333984375
Test Loss Energy: 7.620238227928688, Test Loss Force: 9.490238922510214, time: 9.011785507202148


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0523637667986563, Training Loss Force: 4.39162685862203, time: 0.5682926177978516
Validation Loss Energy: 2.8357394472567528, Validation Loss Force: 4.502469886437246, time: 0.0500483512878418
Test Loss Energy: 8.246248959086179, Test Loss Force: 9.490456569359385, time: 9.692937135696411


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.133442080286222, Training Loss Force: 4.36690204977948, time: 0.5872759819030762
Validation Loss Energy: 3.8558498201202465, Validation Loss Force: 4.498527306539448, time: 0.05098414421081543
Test Loss Energy: 9.607611004987147, Test Loss Force: 9.48186388593035, time: 8.954627752304077

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–„â–‚â–ƒâ–‚â–…â–…â–ƒâ–â–‚â–â–„â–†â–ƒâ–‚â–‚â–‚â–„â–ˆ
wandb:   test_error_force â–â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:          test_loss â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒ
wandb:  train_error_force â–…â–…â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–…â–‚â–„â–…â–‚â–‚â–…â–â–ƒâ–…â–‚â–ƒâ–…â–â–„â–†
wandb:  valid_error_force â–‚â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–â–â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1159
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.60761
wandb:   test_error_force 9.48186
wandb:          test_loss 7.01697
wandb: train_error_energy 3.13344
wandb:  train_error_force 4.3669
wandb:         train_loss 1.47028
wandb: valid_error_energy 3.85585
wandb:  valid_error_force 4.49853
wandb:         valid_loss 1.71213
wandb: 
wandb: ğŸš€ View run al_73_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2himph2b
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_043928-2himph2b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.157670259475708, Uncertainty Bias: -0.02488306164741516
0.0006866455 0.11022568
2.5419164 8.713923
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1973 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_052215-v5dev2zq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v5dev2zq
Training model 28. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.788040493280183, Training Loss Force: 5.1689205659863235, time: 0.6126151084899902
Validation Loss Energy: 1.743328848048798, Validation Loss Force: 4.679340442430607, time: 0.051702260971069336
Test Loss Energy: 8.171022328556212, Test Loss Force: 9.634519668937866, time: 8.803137063980103


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.240297907190324, Training Loss Force: 4.613866168844987, time: 0.5810070037841797
Validation Loss Energy: 2.138431867237335, Validation Loss Force: 4.523221760161132, time: 0.05441093444824219
Test Loss Energy: 8.194651635574798, Test Loss Force: 9.522440145271103, time: 9.022028923034668


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.26433458712781, Training Loss Force: 4.4194813003648505, time: 0.6035451889038086
Validation Loss Energy: 2.222412871638876, Validation Loss Force: 4.50842539541423, time: 0.04934263229370117
Test Loss Energy: 8.036034367663376, Test Loss Force: 9.490486656507647, time: 8.951033115386963


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.185927969387658, Training Loss Force: 4.371358303324592, time: 0.5933094024658203
Validation Loss Energy: 1.882461659859463, Validation Loss Force: 4.49561880215534, time: 0.04934549331665039
Test Loss Energy: 7.589914075756987, Test Loss Force: 9.430390282525998, time: 8.830012321472168


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2721447254754814, Training Loss Force: 4.394431924160728, time: 0.604604959487915
Validation Loss Energy: 1.8162660194851854, Validation Loss Force: 4.465730368035745, time: 0.049928903579711914
Test Loss Energy: 7.509548497816558, Test Loss Force: 9.484811540446703, time: 9.430387258529663


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.254924197845375, Training Loss Force: 4.370592134901965, time: 0.6188266277313232
Validation Loss Energy: 1.9613110311239519, Validation Loss Force: 4.466661125065722, time: 0.04915046691894531
Test Loss Energy: 7.910405214290025, Test Loss Force: 9.444625639937481, time: 8.990703582763672


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1710665371054656, Training Loss Force: 4.3683275595974544, time: 0.6331503391265869
Validation Loss Energy: 1.8837551449281575, Validation Loss Force: 4.462611218639588, time: 0.04872584342956543
Test Loss Energy: 8.068465755709504, Test Loss Force: 9.440159740914472, time: 8.809141874313354


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.170463558085421, Training Loss Force: 4.354159789849507, time: 0.5712916851043701
Validation Loss Energy: 1.685500446171049, Validation Loss Force: 4.505928828950088, time: 0.049509286880493164
Test Loss Energy: 7.551304299742678, Test Loss Force: 9.488826607895053, time: 8.810092210769653


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2631473904677852, Training Loss Force: 4.367193686179795, time: 0.6195685863494873
Validation Loss Energy: 1.6907057827954028, Validation Loss Force: 4.471655594008883, time: 0.056803226470947266
Test Loss Energy: 7.531324943395088, Test Loss Force: 9.464640527752243, time: 8.880054473876953


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.150420073149836, Training Loss Force: 4.36179007170812, time: 0.5825984477996826
Validation Loss Energy: 2.1812270957314888, Validation Loss Force: 4.49199953785743, time: 0.052880048751831055
Test Loss Energy: 8.265593221060529, Test Loss Force: 9.49709479126424, time: 9.005045175552368


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2124450030682286, Training Loss Force: 4.39392131371869, time: 0.6025357246398926
Validation Loss Energy: 2.2051923079002584, Validation Loss Force: 4.528918972928841, time: 0.04957294464111328
Test Loss Energy: 8.309873032548671, Test Loss Force: 9.544416321576108, time: 9.169348001480103


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.192586517075357, Training Loss Force: 4.368576160671756, time: 0.6031439304351807
Validation Loss Energy: 2.015137957114806, Validation Loss Force: 4.479322538041469, time: 0.05058717727661133
Test Loss Energy: 7.448081901848977, Test Loss Force: 9.482081542105977, time: 10.038005590438843


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2537868429655283, Training Loss Force: 4.385478602417863, time: 0.6637589931488037
Validation Loss Energy: 1.8225418380285872, Validation Loss Force: 4.484526761320093, time: 0.0559687614440918
Test Loss Energy: 7.545530108735673, Test Loss Force: 9.484234755078713, time: 9.78188443183899


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1537752097140817, Training Loss Force: 4.370306185591999, time: 0.6096911430358887
Validation Loss Energy: 2.2521078062706597, Validation Loss Force: 4.509881206290307, time: 0.05972790718078613
Test Loss Energy: 8.54394777011177, Test Loss Force: 9.48759053532599, time: 9.921058893203735


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2293976205982315, Training Loss Force: 4.413794980331036, time: 0.6013879776000977
Validation Loss Energy: 1.735931779021077, Validation Loss Force: 4.52263079624784, time: 0.051039934158325195
Test Loss Energy: 7.66094729833982, Test Loss Force: 9.556304904739271, time: 9.820307731628418


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.174100022070333, Training Loss Force: 4.4022263191979745, time: 0.6617121696472168
Validation Loss Energy: 1.6102074351707458, Validation Loss Force: 4.481436558912907, time: 0.05591297149658203
Test Loss Energy: 7.728250954956821, Test Loss Force: 9.492021586044755, time: 9.824153900146484


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.251887869335334, Training Loss Force: 4.392958299752977, time: 0.6322760581970215
Validation Loss Energy: 1.6873836704727332, Validation Loss Force: 4.511980530998113, time: 0.055541276931762695
Test Loss Energy: 7.709565749353748, Test Loss Force: 9.540483466840696, time: 9.910634994506836


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.196450810714106, Training Loss Force: 4.39122034299667, time: 0.6306338310241699
Validation Loss Energy: 2.2020361954258783, Validation Loss Force: 4.49117655269408, time: 0.0552217960357666
Test Loss Energy: 8.395088743193417, Test Loss Force: 9.521416049065735, time: 10.34446907043457


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2031761049828176, Training Loss Force: 4.375285880136422, time: 0.6043186187744141
Validation Loss Energy: 1.9938648149203027, Validation Loss Force: 4.480826445453065, time: 0.05788826942443848
Test Loss Energy: 8.365830138662437, Test Loss Force: 9.483445923398603, time: 9.6061429977417


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.21396897778434, Training Loss Force: 4.36263756251369, time: 0.6169941425323486
Validation Loss Energy: 1.881123640961583, Validation Loss Force: 4.517459082664521, time: 0.05563664436340332
Test Loss Energy: 7.440201727044314, Test Loss Force: 9.480663822809348, time: 10.010610580444336

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–…â–‚â–â–„â–…â–‚â–‚â–†â–‡â–â–‚â–ˆâ–‚â–ƒâ–ƒâ–‡â–‡â–
wandb:   test_error_force â–ˆâ–„â–ƒâ–â–ƒâ–â–â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–„â–ƒâ–ƒ
wandb:          test_loss â–â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–ˆâ–†â–‡â–‡â–ˆâ–ˆâ–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‡â–ˆâ–„â–ƒâ–…â–„â–‚â–‚â–‡â–‡â–…â–ƒâ–ˆâ–‚â–â–‚â–‡â–…â–„
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒ
wandb:         valid_loss â–ˆâ–„â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–…â–…â–…â–ƒâ–…â–‚â–â–‚â–…â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1160
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.4402
wandb:   test_error_force 9.48066
wandb:          test_loss 7.66286
wandb: train_error_energy 2.21397
wandb:  train_error_force 4.36264
wandb:         train_loss 1.09756
wandb: valid_error_energy 1.88112
wandb:  valid_error_force 4.51746
wandb:         valid_loss 1.108
wandb: 
wandb: ğŸš€ View run al_73_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v5dev2zq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_052215-v5dev2zq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.029219627380371, Uncertainty Bias: 0.08888626098632812
4.386902e-05 0.00064373016
3.2248342 13.304432
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3742 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2872 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2529 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2709 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1215 steps.
Found uncertainty sample 49 after 1028 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3740 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 918 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2101 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_060405-v2avamh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v2avamh6
Training model 29. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 10.119911757593586, Training Loss Force: 5.735007412884987, time: 0.6913406848907471
Validation Loss Energy: 6.329453305919655, Validation Loss Force: 5.018938500944578, time: 0.05803561210632324
Test Loss Energy: 8.813333453116133, Test Loss Force: 9.92741523601856, time: 10.343337059020996


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.532005570503096, Training Loss Force: 4.673051290819833, time: 0.6790075302124023
Validation Loss Energy: 2.628240304902733, Validation Loss Force: 4.593428896533871, time: 0.05852365493774414
Test Loss Energy: 8.497882051813878, Test Loss Force: 9.552538681136662, time: 10.382060766220093


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.524267576958704, Training Loss Force: 4.472292812923677, time: 0.6623854637145996
Validation Loss Energy: 4.000990022818897, Validation Loss Force: 4.605449467707637, time: 0.05909085273742676
Test Loss Energy: 9.071230965708839, Test Loss Force: 9.596237531335973, time: 10.50508165359497


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.416918823833512, Training Loss Force: 4.484627419810223, time: 0.615455150604248
Validation Loss Energy: 5.873160137422723, Validation Loss Force: 4.685953716064661, time: 0.0580592155456543
Test Loss Energy: 8.420975880377497, Test Loss Force: 9.539776209011261, time: 10.759445190429688


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.5163127758832, Training Loss Force: 4.475284824255595, time: 0.6301655769348145
Validation Loss Energy: 4.721432481761919, Validation Loss Force: 4.549393400896901, time: 0.06284928321838379
Test Loss Energy: 9.41207786004742, Test Loss Force: 9.48245702990282, time: 10.515079736709595


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.526691697715315, Training Loss Force: 4.480736180195774, time: 0.6553082466125488
Validation Loss Energy: 1.8951687200101242, Validation Loss Force: 4.607360859656281, time: 0.060643672943115234
Test Loss Energy: 7.494993737253638, Test Loss Force: 9.404901324407119, time: 10.693900108337402


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.3927171520769805, Training Loss Force: 4.4504772366535255, time: 0.6053545475006104
Validation Loss Energy: 3.4639835196369155, Validation Loss Force: 4.523934746766392, time: 0.052278995513916016
Test Loss Energy: 7.658143073064428, Test Loss Force: 9.41840737158307, time: 10.391148805618286


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.363107833731806, Training Loss Force: 4.443993436100699, time: 0.661334753036499
Validation Loss Energy: 6.24087551966958, Validation Loss Force: 4.53618377648388, time: 0.058130502700805664
Test Loss Energy: 10.562923335526271, Test Loss Force: 9.46476679398186, time: 10.656185388565063


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.522178476977355, Training Loss Force: 4.44317421224049, time: 0.6920342445373535
Validation Loss Energy: 5.289379530778005, Validation Loss Force: 4.531353637370414, time: 0.058264732360839844
Test Loss Energy: 8.278883612585748, Test Loss Force: 9.384856862399195, time: 10.434196949005127


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.409480380471246, Training Loss Force: 4.445602575747045, time: 0.6679654121398926
Validation Loss Energy: 2.37932715076675, Validation Loss Force: 4.582614301454451, time: 0.05823397636413574
Test Loss Energy: 8.105561132048795, Test Loss Force: 9.349988590214876, time: 10.375236511230469


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.367071705614422, Training Loss Force: 4.480392589667437, time: 0.6451046466827393
Validation Loss Energy: 3.689888716262472, Validation Loss Force: 4.527900038917075, time: 0.06079459190368652
Test Loss Energy: 9.160866908382959, Test Loss Force: 9.395101032753873, time: 10.556822061538696


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.519302265637491, Training Loss Force: 4.420169685038528, time: 0.6633203029632568
Validation Loss Energy: 5.919143097409979, Validation Loss Force: 4.515292511874644, time: 0.05864143371582031
Test Loss Energy: 8.451208206591357, Test Loss Force: 9.385731073124179, time: 10.486915826797485


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.385874023703477, Training Loss Force: 4.42296747471243, time: 0.5937108993530273
Validation Loss Energy: 5.315967562816659, Validation Loss Force: 4.542752070950458, time: 0.0587460994720459
Test Loss Energy: 9.306432290238012, Test Loss Force: 9.372941447021045, time: 10.438898086547852


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.549671099412298, Training Loss Force: 4.42150478516517, time: 0.6039078235626221
Validation Loss Energy: 2.176408535413611, Validation Loss Force: 4.515674166790764, time: 0.051459312438964844
Test Loss Energy: 7.535226713051407, Test Loss Force: 9.400493864959747, time: 10.84726619720459


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.462982263671809, Training Loss Force: 4.4171600166451475, time: 0.5872600078582764
Validation Loss Energy: 3.401057218997723, Validation Loss Force: 4.51165098066214, time: 0.054776668548583984
Test Loss Energy: 7.583608582178114, Test Loss Force: 9.425399215407799, time: 10.44463324546814


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.445593253733339, Training Loss Force: 4.417834054204127, time: 0.6023910045623779
Validation Loss Energy: 6.351621355411641, Validation Loss Force: 4.498958394005965, time: 0.0562891960144043
Test Loss Energy: 10.602007217287118, Test Loss Force: 9.413960293349025, time: 10.518171787261963


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.507734802103348, Training Loss Force: 4.509902269587895, time: 0.6847560405731201
Validation Loss Energy: 5.200068272361245, Validation Loss Force: 4.6371303884519515, time: 0.08166217803955078
Test Loss Energy: 8.20082981369771, Test Loss Force: 9.475908197419079, time: 10.518933534622192


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.560960184387436, Training Loss Force: 4.471385508371043, time: 0.6529462337493896
Validation Loss Energy: 2.42675345215791, Validation Loss Force: 4.5442858160276085, time: 0.05812788009643555
Test Loss Energy: 8.172905545280152, Test Loss Force: 9.431876192208408, time: 11.074156999588013


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.44994442549583, Training Loss Force: 4.426278703328332, time: 0.6277754306793213
Validation Loss Energy: 4.51405090871695, Validation Loss Force: 4.5431493127067935, time: 0.05855202674865723
Test Loss Energy: 9.741510580079215, Test Loss Force: 9.4773270731963, time: 9.73858094215393


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.606811402475406, Training Loss Force: 4.443789669759836, time: 0.5866978168487549
Validation Loss Energy: 5.339011147390433, Validation Loss Force: 4.567180657611904, time: 0.04889392852783203
Test Loss Energy: 8.114358006582066, Test Loss Force: 9.420019239722038, time: 10.551507472991943

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–…â–ƒâ–…â–â–â–ˆâ–ƒâ–‚â–…â–ƒâ–…â–â–â–ˆâ–ƒâ–ƒâ–†â–‚
wandb:   test_error_force â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–ƒâ–„â–„â–†â–…â–â–ƒâ–ˆâ–„â–‚â–…â–„â–†â–â–‚â–ˆâ–„â–‚â–†â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–„â–‡â–…â–â–ƒâ–ˆâ–†â–‚â–„â–‡â–†â–â–ƒâ–ˆâ–†â–‚â–…â–†
wandb:  valid_error_force â–ˆâ–‚â–‚â–„â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–ƒâ–‚â–‚â–‚
wandb:         valid_loss â–ˆâ–‚â–ƒâ–ˆâ–…â–â–ƒâ–‡â–†â–â–ƒâ–‡â–†â–â–ƒâ–‡â–†â–â–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1168
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.11436
wandb:   test_error_force 9.42002
wandb:          test_loss 5.33009
wandb: train_error_energy 4.60681
wandb:  train_error_force 4.44379
wandb:         train_loss 1.88654
wandb: valid_error_energy 5.33901
wandb:  valid_error_force 4.56718
wandb:         valid_loss 2.16666
wandb: 
wandb: ğŸš€ View run al_73_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v2avamh6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_060405-v2avamh6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3306852579116821, Uncertainty Bias: 0.06496819853782654
0.0011482239 0.042524815
3.2443233 19.340221
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2840 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2895 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_064745-oolms7fw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oolms7fw
Training model 30. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.163657317329772, Training Loss Force: 4.7659064791461585, time: 0.6394481658935547
Validation Loss Energy: 4.163142148266431, Validation Loss Force: 5.084853021522122, time: 0.05079984664916992
Test Loss Energy: 7.804077941141647, Test Loss Force: 9.616903382489495, time: 8.738757610321045


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1717284180545913, Training Loss Force: 4.635725249851786, time: 0.6148862838745117
Validation Loss Energy: 3.0079597808065572, Validation Loss Force: 4.506666754499693, time: 0.0510101318359375
Test Loss Energy: 7.43447713646392, Test Loss Force: 9.349701423959894, time: 8.7477445602417


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.970616106849388, Training Loss Force: 4.413365228879397, time: 0.6370844841003418
Validation Loss Energy: 2.4520520071724956, Validation Loss Force: 4.495787140029661, time: 0.05085253715515137
Test Loss Energy: 7.938732516193327, Test Loss Force: 9.334415114811915, time: 9.00577425956726


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9688656445124004, Training Loss Force: 4.404258963523704, time: 0.6045951843261719
Validation Loss Energy: 3.757553416327008, Validation Loss Force: 4.522527477764129, time: 0.05111861228942871
Test Loss Energy: 8.780508369698707, Test Loss Force: 9.458880951302374, time: 8.720137596130371


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1025252908427547, Training Loss Force: 4.38449284610884, time: 0.6472835540771484
Validation Loss Energy: 2.3158762416197516, Validation Loss Force: 4.453128630391107, time: 0.060485124588012695
Test Loss Energy: 7.918491876838807, Test Loss Force: 9.364340542320717, time: 9.515063524246216


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.990908872902881, Training Loss Force: 4.367390206746288, time: 0.6084380149841309
Validation Loss Energy: 2.4904419492836136, Validation Loss Force: 4.478485747391072, time: 0.053177833557128906
Test Loss Energy: 7.624325449506774, Test Loss Force: 9.36340744435019, time: 8.936049461364746


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0163981951946774, Training Loss Force: 4.392065143718236, time: 0.6643667221069336
Validation Loss Energy: 3.0742339120547744, Validation Loss Force: 4.523562443954401, time: 0.053055524826049805
Test Loss Energy: 7.532291052357952, Test Loss Force: 9.38993685261569, time: 8.730678796768188


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.047856293331895, Training Loss Force: 4.384486442866373, time: 0.619281530380249
Validation Loss Energy: 2.0432768797548464, Validation Loss Force: 4.47783243611692, time: 0.0495302677154541
Test Loss Energy: 7.418522978427916, Test Loss Force: 9.340925797425859, time: 8.761252880096436


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.026963900331716, Training Loss Force: 4.415464938744646, time: 0.6178324222564697
Validation Loss Energy: 2.828794173926119, Validation Loss Force: 4.49292628684278, time: 0.052236080169677734
Test Loss Energy: 8.133518252908932, Test Loss Force: 9.425751144575845, time: 8.808319330215454


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0086795227122587, Training Loss Force: 4.376161655941612, time: 0.6056728363037109
Validation Loss Energy: 3.969201775546246, Validation Loss Force: 4.488491162794191, time: 0.05229330062866211
Test Loss Energy: 9.072550673275435, Test Loss Force: 9.400501694519873, time: 9.139623165130615


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1076136780208166, Training Loss Force: 4.386177530776504, time: 0.6442668437957764
Validation Loss Energy: 2.4115119717882987, Validation Loss Force: 4.50365404095529, time: 0.05380392074584961
Test Loss Energy: 8.497407675600105, Test Loss Force: 9.377948835437898, time: 8.802916288375854


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1568098380369998, Training Loss Force: 4.3969189218696805, time: 0.5875515937805176
Validation Loss Energy: 2.4937851038405734, Validation Loss Force: 4.479086063408493, time: 0.05058789253234863
Test Loss Energy: 7.396258143634907, Test Loss Force: 9.32605119070482, time: 8.791438341140747


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0963627958494175, Training Loss Force: 4.383308240234418, time: 0.6223688125610352
Validation Loss Energy: 3.380362125906048, Validation Loss Force: 4.526058565080252, time: 0.0513463020324707
Test Loss Energy: 7.719327152015529, Test Loss Force: 9.409414158821829, time: 9.074542045593262


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0769966102748953, Training Loss Force: 4.378474773119936, time: 0.5932066440582275
Validation Loss Energy: 1.9377056522950011, Validation Loss Force: 4.50367808922305, time: 0.0610349178314209
Test Loss Energy: 7.57248647984236, Test Loss Force: 9.394856679596874, time: 8.790494203567505


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.120283462152832, Training Loss Force: 4.3900608927176545, time: 0.6085784435272217
Validation Loss Energy: 3.3187119421421674, Validation Loss Force: 4.504703703309193, time: 0.05229759216308594
Test Loss Energy: 8.885345820716227, Test Loss Force: 9.384133413841495, time: 8.875526905059814


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0832044124213445, Training Loss Force: 4.3952684740877235, time: 0.5941359996795654
Validation Loss Energy: 4.011396688022978, Validation Loss Force: 4.530047905498694, time: 0.05182194709777832
Test Loss Energy: 9.31586111846034, Test Loss Force: 9.479491449937317, time: 8.991684198379517


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.13268967823309, Training Loss Force: 4.376988011232575, time: 0.6068699359893799
Validation Loss Energy: 2.165225200228534, Validation Loss Force: 4.5151633637700055, time: 0.05230522155761719
Test Loss Energy: 8.140075362622703, Test Loss Force: 9.405831741021437, time: 8.859693765640259


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1771223614636313, Training Loss Force: 4.415340773614407, time: 0.5796074867248535
Validation Loss Energy: 2.5736204540832306, Validation Loss Force: 4.468628629639141, time: 0.05379128456115723
Test Loss Energy: 7.304227787173309, Test Loss Force: 9.36628987429389, time: 9.718624830245972


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.040670335717811, Training Loss Force: 4.392908626479181, time: 0.6318137645721436
Validation Loss Energy: 3.135233233905108, Validation Loss Force: 4.55736139361478, time: 0.05227160453796387
Test Loss Energy: 7.595386609527419, Test Loss Force: 9.425971472781221, time: 9.1135892868042


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0974152806851976, Training Loss Force: 4.38705833168269, time: 0.6348419189453125
Validation Loss Energy: 1.9073019617717293, Validation Loss Force: 4.516682858021817, time: 0.05650162696838379
Test Loss Energy: 7.330896817153958, Test Loss Force: 9.355482628462092, time: 8.93347978591919

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–ƒâ–†â–ƒâ–‚â–‚â–â–„â–‡â–…â–â–‚â–‚â–‡â–ˆâ–„â–â–‚â–
wandb:   test_error_force â–ˆâ–‚â–â–„â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–…â–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–„â–ƒâ–„â–†â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–…â–â–„â–ƒâ–†â–ˆâ–ƒâ–â–…â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–†â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–ƒâ–‡â–‚â–ƒâ–…â–â–„â–‡â–ƒâ–ƒâ–†â–â–…â–ˆâ–‚â–ƒâ–…â–
wandb:  valid_error_force â–ˆâ–‚â–â–‚â–â–â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–ˆâ–„â–‚â–…â–â–‚â–„â–â–ƒâ–†â–‚â–‚â–…â–â–„â–†â–â–‚â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1169
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.3309
wandb:   test_error_force 9.35548
wandb:          test_loss 5.86327
wandb: train_error_energy 3.09742
wandb:  train_error_force 4.38706
wandb:         train_loss 1.46484
wandb: valid_error_energy 1.9073
wandb:  valid_error_force 4.51668
wandb:         valid_loss 1.17838
wandb: 
wandb: ğŸš€ View run al_73_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oolms7fw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_064745-oolms7fw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.982464075088501, Uncertainty Bias: 0.02591472864151001
0.0003633499 0.0048675537
2.8154302 13.945004
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2045 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2450 steps.
Found uncertainty sample 50 after 3357 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2561 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3451 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2104 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1999 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_072950-oqjgierw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oqjgierw
Training model 31. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.341077724766679, Training Loss Force: 4.854089274403695, time: 0.6094796657562256
Validation Loss Energy: 1.676598133716856, Validation Loss Force: 5.246643086938376, time: 0.04900765419006348
Test Loss Energy: 6.7635990457196415, Test Loss Force: 9.747667542845491, time: 8.319283485412598


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.264636258684904, Training Loss Force: 4.771514540002305, time: 0.6098761558532715
Validation Loss Energy: 1.9436838735248705, Validation Loss Force: 4.5597185691935715, time: 0.04892420768737793
Test Loss Energy: 7.727668862835156, Test Loss Force: 9.318392757063675, time: 8.349639177322388


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2033272010435425, Training Loss Force: 4.446138359838741, time: 0.6169788837432861
Validation Loss Energy: 2.161096691593887, Validation Loss Force: 4.558034745112066, time: 0.05515170097351074
Test Loss Energy: 8.086701258239136, Test Loss Force: 9.314996481342824, time: 8.48180890083313


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1504161282951015, Training Loss Force: 4.419979862600668, time: 0.7131597995758057
Validation Loss Energy: 1.7745643191666833, Validation Loss Force: 4.525467155828668, time: 0.05539989471435547
Test Loss Energy: 7.110792201909523, Test Loss Force: 9.307527915700541, time: 8.33921217918396


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.165414475020658, Training Loss Force: 4.404618237181616, time: 0.58461594581604
Validation Loss Energy: 1.7886760876244299, Validation Loss Force: 4.507311159008008, time: 0.05112791061401367
Test Loss Energy: 7.218135965538095, Test Loss Force: 9.297395238468585, time: 8.922558546066284


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.175441362951146, Training Loss Force: 4.414996430825444, time: 0.60591721534729
Validation Loss Energy: 2.156991563219562, Validation Loss Force: 4.5361134130337675, time: 0.05083274841308594
Test Loss Energy: 7.85520321072689, Test Loss Force: 9.333031726201197, time: 8.334946155548096


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.200007092743186, Training Loss Force: 4.424912688298916, time: 0.59316086769104
Validation Loss Energy: 1.8949832366115662, Validation Loss Force: 4.541114562051305, time: 0.051837921142578125
Test Loss Energy: 7.59006303092335, Test Loss Force: 9.371067472815374, time: 8.554143190383911


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.228293933895058, Training Loss Force: 4.4121080509176585, time: 0.5946767330169678
Validation Loss Energy: 1.7584169093768651, Validation Loss Force: 4.502401749678592, time: 0.051218509674072266
Test Loss Energy: 7.23117619119238, Test Loss Force: 9.292882408717103, time: 8.432387828826904


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.195608014014854, Training Loss Force: 4.438991558894873, time: 0.6180515289306641
Validation Loss Energy: 1.7432535858774745, Validation Loss Force: 4.5607539807221364, time: 0.05389142036437988
Test Loss Energy: 7.428538753192452, Test Loss Force: 9.383454205329608, time: 10.477621078491211


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2694573827070017, Training Loss Force: 4.417308302260166, time: 0.6499676704406738
Validation Loss Energy: 1.967545989879076, Validation Loss Force: 4.536940406241743, time: 0.05864834785461426
Test Loss Energy: 7.921581431057275, Test Loss Force: 9.39407591996476, time: 10.575831174850464


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2331817804258285, Training Loss Force: 4.404795993359001, time: 0.6160821914672852
Validation Loss Energy: 2.0103536878454014, Validation Loss Force: 4.56044046256467, time: 0.05752897262573242
Test Loss Energy: 7.996252797017334, Test Loss Force: 9.402270802050076, time: 9.629266500473022


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.148195512092657, Training Loss Force: 4.416224132206727, time: 0.6140260696411133
Validation Loss Energy: 1.8155875465975435, Validation Loss Force: 4.537043279387161, time: 0.055811166763305664
Test Loss Energy: 7.448641664102471, Test Loss Force: 9.384242967061294, time: 9.226309776306152


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1835601959611375, Training Loss Force: 4.409246042258452, time: 0.6164138317108154
Validation Loss Energy: 1.7013969078334068, Validation Loss Force: 4.569179335865751, time: 0.0504152774810791
Test Loss Energy: 7.226756066417255, Test Loss Force: 9.398966788298905, time: 9.185546875


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.186849612027866, Training Loss Force: 4.417265333133088, time: 0.5961132049560547
Validation Loss Energy: 2.4488538102295347, Validation Loss Force: 4.527590974142527, time: 0.05391359329223633
Test Loss Energy: 8.377457793224012, Test Loss Force: 9.373269495797542, time: 8.97397232055664


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2427837494269527, Training Loss Force: 4.425708628188162, time: 0.5801050662994385
Validation Loss Energy: 1.7989055081883525, Validation Loss Force: 4.536305799175849, time: 0.05065155029296875
Test Loss Energy: 7.6351543933393256, Test Loss Force: 9.301179835190249, time: 8.922226190567017


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2443722109331508, Training Loss Force: 4.4226100847151315, time: 0.6222453117370605
Validation Loss Energy: 1.8586087842748136, Validation Loss Force: 4.550116630282874, time: 0.054392337799072266
Test Loss Energy: 7.244070695629053, Test Loss Force: 9.442959230681637, time: 9.146366119384766


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2339885077324833, Training Loss Force: 4.4148582134666725, time: 0.6166958808898926
Validation Loss Energy: 1.683172774254093, Validation Loss Force: 4.489481595155278, time: 0.05206918716430664
Test Loss Energy: 7.175270441210635, Test Loss Force: 9.347297749001237, time: 8.928271293640137


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.121496831542733, Training Loss Force: 4.419685421772731, time: 0.622298002243042
Validation Loss Energy: 2.157699651103613, Validation Loss Force: 4.501436701600141, time: 0.05065464973449707
Test Loss Energy: 7.783064145548571, Test Loss Force: 9.390956010462407, time: 9.586003065109253


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1775476535923697, Training Loss Force: 4.433085855589556, time: 0.582674503326416
Validation Loss Energy: 1.977027687450973, Validation Loss Force: 4.53884066473309, time: 0.05441737174987793
Test Loss Energy: 7.901472315722154, Test Loss Force: 9.383968396185644, time: 9.148614883422852


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.179606368262428, Training Loss Force: 4.389739262181575, time: 0.6002545356750488
Validation Loss Energy: 1.7422208463786615, Validation Loss Force: 4.523309046466336, time: 0.05131840705871582
Test Loss Energy: 7.210511750665388, Test Loss Force: 9.386555611142514, time: 9.009719371795654

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–‡â–ƒâ–ƒâ–†â–…â–ƒâ–„â–†â–†â–„â–ƒâ–ˆâ–…â–ƒâ–ƒâ–…â–†â–ƒ
wandb:   test_error_force â–ˆâ–â–â–â–â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–‚â–‚
wandb:          test_loss â–â–…â–‡â–„â–…â–‡â–…â–…â–‡â–†â–‡â–†â–…â–ˆâ–…â–…â–…â–†â–‡â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‡â–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–…â–‚â–‚â–…â–ƒâ–‚â–‚â–„â–„â–‚â–â–ˆâ–‚â–ƒâ–â–…â–„â–‚
wandb:  valid_error_force â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–
wandb:         valid_loss â–‡â–ƒâ–…â–‚â–‚â–…â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–â–„â–â–†â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1175
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.21051
wandb:   test_error_force 9.38656
wandb:          test_loss 7.26955
wandb: train_error_energy 2.17961
wandb:  train_error_force 4.38974
wandb:         train_loss 1.08919
wandb: valid_error_energy 1.74222
wandb:  valid_error_force 4.52331
wandb:         valid_loss 1.04625
wandb: 
wandb: ğŸš€ View run al_73_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oqjgierw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_072950-oqjgierw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1463818550109863, Uncertainty Bias: 0.08174565434455872
0.0008058548 0.0035276413
3.1125844 12.804333
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1294 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3645 steps.
Found uncertainty sample 77 after 2377 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 782 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_081209-hrjruiui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hrjruiui
Training model 32. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 10.154533860923694, Training Loss Force: 5.909707727056605, time: 0.6154134273529053
Validation Loss Energy: 3.383114427884289, Validation Loss Force: 5.682160556112807, time: 0.17815876007080078
Test Loss Energy: 7.396001903909263, Test Loss Force: 9.719215396997166, time: 9.199153184890747


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2724947613728803, Training Loss Force: 4.7780447399906745, time: 0.5952920913696289
Validation Loss Energy: 1.6243119668812496, Validation Loss Force: 3.82593655839088, time: 0.05652141571044922
Test Loss Energy: 7.380598608355757, Test Loss Force: 9.390180492298775, time: 9.118756294250488


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.642762046297584, Training Loss Force: 4.658775394138239, time: 0.6207990646362305
Validation Loss Energy: 6.141260469194158, Validation Loss Force: 3.856578950238587, time: 0.05861353874206543
Test Loss Energy: 9.711206060098181, Test Loss Force: 9.475736073003471, time: 9.266479730606079


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.329123376678631, Training Loss Force: 4.902444166314225, time: 0.5941004753112793
Validation Loss Energy: 2.4627154655691177, Validation Loss Force: 5.6684416873630505, time: 0.055986642837524414
Test Loss Energy: 7.681426869848569, Test Loss Force: 9.703708675705702, time: 9.083323955535889


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.324435080820164, Training Loss Force: 4.929371943324884, time: 0.6053810119628906
Validation Loss Energy: 3.9301004055138886, Validation Loss Force: 6.222687235822761, time: 0.058123111724853516
Test Loss Energy: 7.985788951309224, Test Loss Force: 9.335171583688405, time: 9.103569746017456


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2119443314936094, Training Loss Force: 4.950564978789619, time: 0.5867800712585449
Validation Loss Energy: 3.37637968823113, Validation Loss Force: 5.558620819253173, time: 0.05779123306274414
Test Loss Energy: 8.945704757760943, Test Loss Force: 9.58800614550041, time: 9.867481708526611


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3223411995483634, Training Loss Force: 5.0878666859239585, time: 0.5950074195861816
Validation Loss Energy: 1.5450121359345488, Validation Loss Force: 4.245684932654424, time: 0.062320709228515625
Test Loss Energy: 7.48938640121439, Test Loss Force: 9.603820695810953, time: 9.162569999694824


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1649406832228033, Training Loss Force: 4.489871615209583, time: 0.6008563041687012
Validation Loss Energy: 2.080357638622482, Validation Loss Force: 4.20467172533513, time: 0.059824228286743164
Test Loss Energy: 7.241623424150073, Test Loss Force: 9.310360985373883, time: 9.195311546325684


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.132999760142109, Training Loss Force: 4.411043993304375, time: 0.5802900791168213
Validation Loss Energy: 2.451997675900889, Validation Loss Force: 4.48426712909594, time: 0.058876752853393555
Test Loss Energy: 7.1849790094970585, Test Loss Force: 9.299855529680663, time: 9.30278205871582


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0983590157936347, Training Loss Force: 4.403205630137935, time: 0.6159789562225342
Validation Loss Energy: 3.019511633428145, Validation Loss Force: 5.6637936916109535, time: 0.05860567092895508
Test Loss Energy: 8.165063809465433, Test Loss Force: 9.310700570976914, time: 9.046224355697632


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.109688313612911, Training Loss Force: 4.392804670078457, time: 0.6262831687927246
Validation Loss Energy: 2.067298427217536, Validation Loss Force: 6.801033601961112, time: 0.058338165283203125
Test Loss Energy: 7.960859396375267, Test Loss Force: 9.401075705267093, time: 9.06588363647461


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2092230045989933, Training Loss Force: 4.414495034071578, time: 0.626399040222168
Validation Loss Energy: 1.1708644544019893, Validation Loss Force: 4.151551551213451, time: 0.05672049522399902
Test Loss Energy: 7.095088412594876, Test Loss Force: 9.325292474152343, time: 9.212967157363892


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.169276860926453, Training Loss Force: 4.407420323768227, time: 0.696697473526001
Validation Loss Energy: 3.956223782712277, Validation Loss Force: 4.076751752371378, time: 0.06230521202087402
Test Loss Energy: 7.408085099905965, Test Loss Force: 9.310168258816143, time: 9.14347243309021


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.08802944827681, Training Loss Force: 4.404103708966227, time: 0.6097226142883301
Validation Loss Energy: 1.3398378821331614, Validation Loss Force: 4.60762717195481, time: 0.05822300910949707
Test Loss Energy: 8.038391125883244, Test Loss Force: 9.369642199089078, time: 9.113373041152954


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1259725957194964, Training Loss Force: 4.418453598003203, time: 0.6126973628997803
Validation Loss Energy: 2.462292895197433, Validation Loss Force: 3.5507467750168242, time: 0.059244394302368164
Test Loss Energy: 7.829906002219443, Test Loss Force: 9.331573730602717, time: 9.21692705154419


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1614072819529886, Training Loss Force: 4.403696808183427, time: 0.5914416313171387
Validation Loss Energy: 1.7766664272388146, Validation Loss Force: 4.941917243368156, time: 0.058702707290649414
Test Loss Energy: 7.247796085674042, Test Loss Force: 9.363283285899712, time: 9.331066846847534


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1382795434872652, Training Loss Force: 4.4054613708936285, time: 0.6232764720916748
Validation Loss Energy: 1.1363749520528017, Validation Loss Force: 4.085604743609748, time: 0.06350994110107422
Test Loss Energy: 7.18850067476063, Test Loss Force: 9.353672423901878, time: 9.089934349060059


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1057687468722492, Training Loss Force: 4.412130474302461, time: 0.5943119525909424
Validation Loss Energy: 2.1544475682273374, Validation Loss Force: 3.7093316294120218, time: 0.06099867820739746
Test Loss Energy: 7.873009442117385, Test Loss Force: 9.401349590648197, time: 9.09225583076477


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.263031199300207, Training Loss Force: 4.397852615725151, time: 0.584425687789917
Validation Loss Energy: 1.917324300029939, Validation Loss Force: 6.868330675265721, time: 0.05738186836242676
Test Loss Energy: 7.902400475334032, Test Loss Force: 9.46367672708733, time: 9.41275668144226


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1792097433598085, Training Loss Force: 4.413999998433587, time: 0.6085195541381836
Validation Loss Energy: 2.628972218385398, Validation Loss Force: 5.699984330567743, time: 0.056238651275634766
Test Loss Energy: 7.117976618405462, Test Loss Force: 9.37618652689439, time: 9.729598999023438

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ˆâ–ƒâ–ƒâ–†â–‚â–â–â–„â–ƒâ–â–‚â–„â–ƒâ–â–â–ƒâ–ƒâ–
wandb:   test_error_force â–ˆâ–ƒâ–„â–ˆâ–‚â–†â–†â–â–â–â–ƒâ–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‚
wandb:          test_loss â–â–†â–‡â–„â–…â–ˆâ–…â–…â–…â–†â–†â–…â–…â–†â–†â–†â–…â–†â–…â–…
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–„â–„â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–‚â–ˆâ–ƒâ–…â–„â–‚â–‚â–ƒâ–„â–‚â–â–…â–â–ƒâ–‚â–â–‚â–‚â–ƒ
wandb:  valid_error_force â–…â–‚â–‚â–…â–‡â–…â–‚â–‚â–ƒâ–…â–ˆâ–‚â–‚â–ƒâ–â–„â–‚â–â–ˆâ–†
wandb:         valid_loss â–ƒâ–â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–â–…â–â–‚â–‚â–â–â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1178
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.11798
wandb:   test_error_force 9.37619
wandb:          test_loss 7.23753
wandb: train_error_energy 2.17921
wandb:  train_error_force 4.414
wandb:         train_loss 1.11123
wandb: valid_error_energy 2.62897
wandb:  valid_error_force 5.69998
wandb:         valid_loss 1.70872
wandb: 
wandb: ğŸš€ View run al_73_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hrjruiui
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_081209-hrjruiui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1887094974517822, Uncertainty Bias: 0.08145458996295929
0.00010681152 0.011133194
3.0851738 12.403704
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 879 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1615 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2026 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1573 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 520 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1235 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1386 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2228 steps.
Found uncertainty sample 61 after 2202 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1208 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1270 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2040 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2139 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2401 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_085209-dkwzqq91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dkwzqq91
Training model 33. Added 14 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 9.643745318252586, Training Loss Force: 5.936361692284569, time: 0.7557694911956787
Validation Loss Energy: 3.857140410490044, Validation Loss Force: 4.838178137641005, time: 0.06971859931945801
Test Loss Energy: 8.94084344030382, Test Loss Force: 9.756156870484988, time: 10.45777678489685


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.524983243037138, Training Loss Force: 4.791763047158074, time: 0.6966369152069092
Validation Loss Energy: 3.760402245380008, Validation Loss Force: 4.569581699012444, time: 0.06369328498840332
Test Loss Energy: 7.781841535719281, Test Loss Force: 9.361549609577274, time: 10.649515867233276


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.343942152537694, Training Loss Force: 4.54483830505637, time: 0.5987892150878906
Validation Loss Energy: 2.9043251069088463, Validation Loss Force: 4.088261297855239, time: 0.06101655960083008
Test Loss Energy: 7.280006154578802, Test Loss Force: 9.308008960330623, time: 10.870543003082275


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.44307224426257, Training Loss Force: 4.617188198339802, time: 0.679718017578125
Validation Loss Energy: 2.748673807176674, Validation Loss Force: 5.982870784305366, time: 0.06546664237976074
Test Loss Energy: 9.46543830816724, Test Loss Force: 9.465834579972112, time: 10.57762885093689


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.347983105320275, Training Loss Force: 4.525772071925445, time: 0.783522367477417
Validation Loss Energy: 4.360748768474316, Validation Loss Force: 4.137473851135032, time: 0.06335902214050293
Test Loss Energy: 8.924472557544114, Test Loss Force: 9.303614996265626, time: 10.547746896743774


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.428700875809102, Training Loss Force: 4.486394861698997, time: 0.6751153469085693
Validation Loss Energy: 4.059242386750492, Validation Loss Force: 4.536216508848332, time: 0.07056736946105957
Test Loss Energy: 7.781596021418466, Test Loss Force: 9.319320557606984, time: 10.70691704750061


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.45373202275857, Training Loss Force: 4.472622739865077, time: 0.6992824077606201
Validation Loss Energy: 3.6773679188523793, Validation Loss Force: 4.1196639935017165, time: 0.07128453254699707
Test Loss Energy: 7.569428260185694, Test Loss Force: 9.33686856506824, time: 10.609133243560791


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.471787789164993, Training Loss Force: 4.4652543131211795, time: 0.6896836757659912
Validation Loss Energy: 5.028239836508273, Validation Loss Force: 4.191684992737184, time: 0.06542038917541504
Test Loss Energy: 9.904406406484464, Test Loss Force: 9.342038984605738, time: 11.508591890335083


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.528382141056865, Training Loss Force: 4.49587640691832, time: 0.6729366779327393
Validation Loss Energy: 5.051543609979065, Validation Loss Force: 6.25495511243574, time: 0.06427812576293945
Test Loss Energy: 8.393715364202002, Test Loss Force: 9.266491806101813, time: 10.824496030807495


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.397120460885603, Training Loss Force: 4.490065293022755, time: 0.729071855545044
Validation Loss Energy: 4.916298935460018, Validation Loss Force: 4.439355875708037, time: 0.06380939483642578
Test Loss Energy: 7.892589607479259, Test Loss Force: 9.273667376453881, time: 10.584073781967163


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.488281103753581, Training Loss Force: 4.511898096536406, time: 0.6786701679229736
Validation Loss Energy: 3.2426219982685884, Validation Loss Force: 4.362003063773328, time: 0.06451725959777832
Test Loss Energy: 7.152403182621068, Test Loss Force: 9.356766004817885, time: 10.75334644317627


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4425761637741585, Training Loss Force: 4.501955661343298, time: 0.618340253829956
Validation Loss Energy: 5.541731809872843, Validation Loss Force: 4.376039681394324, time: 0.06169605255126953
Test Loss Energy: 10.093743268317843, Test Loss Force: 9.337142455112573, time: 10.241734266281128


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.423448974964534, Training Loss Force: 4.474524797288735, time: 0.753058910369873
Validation Loss Energy: 4.096870243709673, Validation Loss Force: 4.590430211145662, time: 0.06630611419677734
Test Loss Energy: 8.060169310845888, Test Loss Force: 9.23055246035137, time: 10.85788345336914


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.614419448143335, Training Loss Force: 4.539876697391375, time: 0.7417654991149902
Validation Loss Energy: 6.355898384366622, Validation Loss Force: 5.2050916882933755, time: 0.08734130859375
Test Loss Energy: 7.918148136299462, Test Loss Force: 9.27984354705706, time: 9.456790685653687


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.508791492788707, Training Loss Force: 4.516165609315254, time: 0.6431071758270264
Validation Loss Energy: 3.6375412040771624, Validation Loss Force: 4.984954958562225, time: 0.06209301948547363
Test Loss Energy: 7.380423112426168, Test Loss Force: 9.263243816374079, time: 9.818632364273071


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.435299125135522, Training Loss Force: 4.47541784119705, time: 0.6282253265380859
Validation Loss Energy: 5.914712204075162, Validation Loss Force: 4.364521229144625, time: 0.058992624282836914
Test Loss Energy: 9.713544459188677, Test Loss Force: 9.290735589030211, time: 9.845280885696411


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.428313824096049, Training Loss Force: 4.479506931533154, time: 0.7486767768859863
Validation Loss Energy: 4.24585193451387, Validation Loss Force: 4.395712055098752, time: 0.06275725364685059
Test Loss Energy: 8.679991861256005, Test Loss Force: 9.2407929001235, time: 9.696838855743408


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.417839356137033, Training Loss Force: 4.486526892783104, time: 0.6268713474273682
Validation Loss Energy: 5.674345314429034, Validation Loss Force: 4.6581002552697, time: 0.058470726013183594
Test Loss Energy: 7.851569711924937, Test Loss Force: 9.243335026327028, time: 9.50337529182434


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.41208886098659, Training Loss Force: 4.488137716543033, time: 0.6841740608215332
Validation Loss Energy: 1.964172941989275, Validation Loss Force: 4.9946330503208305, time: 0.06108975410461426
Test Loss Energy: 7.6245716446389045, Test Loss Force: 9.25478021110126, time: 9.685166358947754


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.093450769143492, Training Loss Force: 4.716953263362723, time: 0.6613495349884033
Validation Loss Energy: 3.5489788933327304, Validation Loss Force: 4.741892658904641, time: 0.06376791000366211
Test Loss Energy: 7.150341674362243, Test Loss Force: 9.255583452156465, time: 8.265173435211182

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–â–‡â–…â–ƒâ–‚â–ˆâ–„â–ƒâ–â–ˆâ–ƒâ–ƒâ–‚â–‡â–…â–ƒâ–‚â–
wandb:   test_error_force â–ˆâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–â–â–
wandb:          test_loss â–„â–†â–‚â–ˆâ–…â–ƒâ–‚â–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–ƒâ–â–‡â–„â–‚â–‚â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–„â–‚â–‚â–…â–„â–„â–†â–†â–†â–ƒâ–‡â–„â–ˆâ–„â–‡â–…â–‡â–â–„
wandb:  valid_error_force â–ƒâ–ƒâ–â–‡â–â–‚â–â–â–ˆâ–‚â–‚â–‚â–ƒâ–…â–„â–‚â–‚â–ƒâ–„â–ƒ
wandb:         valid_loss â–„â–„â–â–…â–„â–ƒâ–‚â–„â–ˆâ–…â–‚â–…â–ƒâ–ˆâ–„â–†â–ƒâ–†â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1190
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.15034
wandb:   test_error_force 9.25558
wandb:          test_loss 5.85176
wandb: train_error_energy 3.09345
wandb:  train_error_force 4.71695
wandb:         train_loss 1.59978
wandb: valid_error_energy 3.54898
wandb:  valid_error_force 4.74189
wandb:         valid_loss 1.70761
wandb: 
wandb: ğŸš€ View run al_73_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dkwzqq91
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_085209-dkwzqq91/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1944799423217773, Uncertainty Bias: 0.013253599405288696
0.0007019043 0.017028809
2.7757854 10.96062
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1411 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1856 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1356 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 459 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2329 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3322 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1485 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3412 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1598 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 920 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 188 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 545 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2112 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2488 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3270 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_093225-53mkc4y3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/53mkc4y3
Training model 34. Added 15 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.467637842765335, Training Loss Force: 4.858240908955388, time: 0.6222677230834961
Validation Loss Energy: 1.9365812844426389, Validation Loss Force: 4.94207667447664, time: 0.06100916862487793
Test Loss Energy: 6.7664536012168535, Test Loss Force: 9.244560126320168, time: 8.42642879486084


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1698431914726712, Training Loss Force: 4.624118365326798, time: 0.6519050598144531
Validation Loss Energy: 3.430677225461902, Validation Loss Force: 4.825296504879937, time: 0.05553841590881348
Test Loss Energy: 7.2377707373020375, Test Loss Force: 9.158942645924517, time: 8.726681470870972


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.148714403341587, Training Loss Force: 4.509012128613749, time: 0.6533975601196289
Validation Loss Energy: 2.5330594877993162, Validation Loss Force: 4.297292737936961, time: 0.06473445892333984
Test Loss Energy: 7.964677181291938, Test Loss Force: 9.156041446487363, time: 10.835036039352417


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.04460172031457, Training Loss Force: 4.497116474830849, time: 0.6597976684570312
Validation Loss Energy: 2.1132517722083834, Validation Loss Force: 4.108720472986803, time: 0.06287002563476562
Test Loss Energy: 7.93247425645276, Test Loss Force: 9.216084902155547, time: 10.585702419281006


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0260737283169235, Training Loss Force: 4.485650314672158, time: 0.682422399520874
Validation Loss Energy: 3.7354335747051146, Validation Loss Force: 4.302005307741377, time: 0.05718660354614258
Test Loss Energy: 7.312663776808805, Test Loss Force: 9.221272654912214, time: 9.169574737548828


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0266684717459817, Training Loss Force: 4.49457586675353, time: 0.6024539470672607
Validation Loss Energy: 2.8419351049076202, Validation Loss Force: 4.770258481404381, time: 0.05693316459655762
Test Loss Energy: 7.856191656552769, Test Loss Force: 9.202810654726314, time: 9.162968873977661


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0862046492877098, Training Loss Force: 4.4877550654754685, time: 0.6243319511413574
Validation Loss Energy: 2.9268282734654543, Validation Loss Force: 4.427979263704294, time: 0.05713796615600586
Test Loss Energy: 7.7460860377401115, Test Loss Force: 9.237723642605717, time: 9.013220310211182


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.990720372226537, Training Loss Force: 4.497082968984101, time: 0.6324288845062256
Validation Loss Energy: 2.9601300029229765, Validation Loss Force: 4.569679005429213, time: 0.056082963943481445
Test Loss Energy: 7.352140351346893, Test Loss Force: 9.257827495487827, time: 8.989752769470215


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.101744893054012, Training Loss Force: 4.473977927726051, time: 0.6151633262634277
Validation Loss Energy: 2.9077153559901694, Validation Loss Force: 4.494398575235655, time: 0.058199405670166016
Test Loss Energy: 8.199316785011781, Test Loss Force: 9.285816079148539, time: 9.10411810874939


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.113534190091304, Training Loss Force: 4.484410727256207, time: 0.6401448249816895
Validation Loss Energy: 2.706509511707507, Validation Loss Force: 6.2148677634252145, time: 0.05787253379821777
Test Loss Energy: 8.19071783886729, Test Loss Force: 9.170071943621364, time: 8.938903093338013


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0075975449838475, Training Loss Force: 4.486071053883103, time: 0.63409423828125
Validation Loss Energy: 3.565042468189107, Validation Loss Force: 4.171020293983928, time: 0.06426811218261719
Test Loss Energy: 6.9903624337155525, Test Loss Force: 9.136684381620025, time: 8.997384786605835


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.020594338711361, Training Loss Force: 4.502310431889905, time: 0.601945161819458
Validation Loss Energy: 3.550037128448752, Validation Loss Force: 5.370430877226574, time: 0.05672478675842285
Test Loss Energy: 8.390638139558861, Test Loss Force: 9.291035947557733, time: 9.7853364944458


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0828879044634, Training Loss Force: 4.490232939450784, time: 0.6176514625549316
Validation Loss Energy: 2.7337024244810735, Validation Loss Force: 4.159399413927104, time: 0.05917549133300781
Test Loss Energy: 7.631022164614392, Test Loss Force: 9.172541971653894, time: 8.860433340072632


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9755982161504284, Training Loss Force: 4.4916394818484635, time: 0.594773530960083
Validation Loss Energy: 3.5355467111083554, Validation Loss Force: 5.3510920619027456, time: 0.05563807487487793
Test Loss Energy: 7.2191962623838775, Test Loss Force: 9.200227543410247, time: 8.97040343284607


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0600804282904526, Training Loss Force: 4.484539336267125, time: 0.6225831508636475
Validation Loss Energy: 3.0854327227454936, Validation Loss Force: 4.288380628040348, time: 0.05686640739440918
Test Loss Energy: 8.002169920631497, Test Loss Force: 9.22280702952517, time: 9.124140501022339


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.026260330920925, Training Loss Force: 4.486212085488478, time: 0.6159439086914062
Validation Loss Energy: 2.546753528939303, Validation Loss Force: 4.878140346591518, time: 0.058977365493774414
Test Loss Energy: 7.982395855909996, Test Loss Force: 9.253776241388747, time: 8.93114972114563


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0511912064381543, Training Loss Force: 4.47055587797486, time: 0.6191473007202148
Validation Loss Energy: 3.6908149085749584, Validation Loss Force: 4.08728578432693, time: 0.06367897987365723
Test Loss Energy: 7.3167701922341095, Test Loss Force: 9.205109402387533, time: 8.980057001113892


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1081571052388663, Training Loss Force: 4.4813453700379355, time: 0.6091079711914062
Validation Loss Energy: 2.6312065919302103, Validation Loss Force: 4.7904229539213095, time: 0.059056997299194336
Test Loss Energy: 7.9008199977156055, Test Loss Force: 9.249822653940814, time: 8.963134288787842


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1096932645183357, Training Loss Force: 4.489405313393654, time: 0.6180670261383057
Validation Loss Energy: 2.3867988139583574, Validation Loss Force: 4.464699187220953, time: 0.05780649185180664
Test Loss Energy: 8.165170706976776, Test Loss Force: 9.19107976328752, time: 9.285582542419434


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0895992140486648, Training Loss Force: 4.463776094697367, time: 0.6494836807250977
Validation Loss Energy: 3.2147254509938907, Validation Loss Force: 4.495321538845526, time: 0.058194637298583984
Test Loss Energy: 7.040268105916914, Test Loss Force: 9.201831432765786, time: 8.984482526779175

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–†â–†â–ƒâ–†â–…â–„â–‡â–‡â–‚â–ˆâ–…â–ƒâ–†â–†â–ƒâ–†â–‡â–‚
wandb:   test_error_force â–†â–‚â–‚â–…â–…â–„â–†â–†â–ˆâ–ƒâ–â–ˆâ–ƒâ–„â–…â–†â–„â–†â–ƒâ–„
wandb:          test_loss â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–…â–†â–â–ˆâ–â–„â–„â–…â–…â–†â–…â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–ƒâ–‚â–ˆâ–…â–…â–…â–…â–„â–‡â–‡â–„â–‡â–…â–ƒâ–ˆâ–„â–ƒâ–†
wandb:  valid_error_force â–„â–ƒâ–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–ˆâ–â–…â–â–…â–‚â–„â–â–ƒâ–‚â–‚
wandb:         valid_loss â–‚â–…â–ƒâ–â–…â–„â–ƒâ–„â–„â–†â–„â–†â–‚â–ˆâ–ƒâ–„â–†â–„â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1203
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.04027
wandb:   test_error_force 9.20183
wandb:          test_loss 5.67299
wandb: train_error_energy 3.0896
wandb:  train_error_force 4.46378
wandb:         train_loss 1.47502
wandb: valid_error_energy 3.21473
wandb:  valid_error_force 4.49532
wandb:         valid_loss 1.70168
wandb: 
wandb: ğŸš€ View run al_73_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/53mkc4y3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_093225-53mkc4y3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.148885488510132, Uncertainty Bias: 0.020214200019836426
0.00019073486 0.13843203
2.8195238 8.57383
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2559 steps.
Found uncertainty sample 13 after 3805 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3076 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2353 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3442 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3094 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2523 steps.
Found uncertainty sample 63 after 2783 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2813 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3003 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3713 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1934 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_101410-o58bjhyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o58bjhyb
Training model 35. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.629424242930254, Training Loss Force: 5.043420680553619, time: 0.6289846897125244
Validation Loss Energy: 2.5551493804210827, Validation Loss Force: 5.240301915000645, time: 0.05828595161437988
Test Loss Energy: 7.344870028861294, Test Loss Force: 9.636435574891394, time: 9.216992139816284


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0603456536119666, Training Loss Force: 4.836385275994567, time: 0.5946357250213623
Validation Loss Energy: 3.7124907479198717, Validation Loss Force: 4.6419360339593645, time: 0.05793881416320801
Test Loss Energy: 7.244595735485465, Test Loss Force: 9.14619594017362, time: 9.188243627548218


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0665560337951803, Training Loss Force: 4.5389344787600985, time: 0.6027097702026367
Validation Loss Energy: 2.974325160975873, Validation Loss Force: 4.587188148380953, time: 0.05758404731750488
Test Loss Energy: 8.193808987909797, Test Loss Force: 9.188900086494824, time: 9.523014307022095


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.991587064999347, Training Loss Force: 4.52756578909018, time: 0.6191756725311279
Validation Loss Energy: 2.4734053102595324, Validation Loss Force: 4.642529892571554, time: 0.05733847618103027
Test Loss Energy: 7.900948635196759, Test Loss Force: 9.169540573432688, time: 9.282814025878906


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.061575176968494, Training Loss Force: 4.528448355829209, time: 0.6142764091491699
Validation Loss Energy: 3.4866720582575086, Validation Loss Force: 4.837710087096265, time: 0.0586094856262207
Test Loss Energy: 7.303708970394911, Test Loss Force: 9.203374373728924, time: 9.266067504882812


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0961228721410556, Training Loss Force: 4.524648506853951, time: 0.6264290809631348
Validation Loss Energy: 2.724086902752474, Validation Loss Force: 4.573827331617848, time: 0.060527801513671875
Test Loss Energy: 8.233768924702378, Test Loss Force: 9.203763179705467, time: 9.467950820922852


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0977466868877337, Training Loss Force: 4.548924963611012, time: 0.6422970294952393
Validation Loss Energy: 2.856828998740438, Validation Loss Force: 4.472158603609534, time: 0.05862689018249512
Test Loss Energy: 8.289842077581193, Test Loss Force: 9.249396052499813, time: 9.236079454421997


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0084661275145397, Training Loss Force: 4.52546032926143, time: 0.611947774887085
Validation Loss Energy: 3.727674445646115, Validation Loss Force: 4.999179286273238, time: 0.057839393615722656
Test Loss Energy: 7.1029561598964195, Test Loss Force: 9.221071972887188, time: 9.278725624084473


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.167805007024563, Training Loss Force: 4.528316102075955, time: 0.6324338912963867
Validation Loss Energy: 2.982142072678241, Validation Loss Force: 4.954984804866074, time: 0.056813955307006836
Test Loss Energy: 8.527355127535634, Test Loss Force: 9.203138899358393, time: 9.384001970291138


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1123501908556896, Training Loss Force: 4.534884935636254, time: 0.6315765380859375
Validation Loss Energy: 2.8048581314154655, Validation Loss Force: 4.9467496091730805, time: 0.05700206756591797
Test Loss Energy: 8.083328067829425, Test Loss Force: 9.20456555340023, time: 9.241289615631104


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0006437897166682, Training Loss Force: 4.5237113510158835, time: 0.6552677154541016
Validation Loss Energy: 3.874903618937287, Validation Loss Force: 4.086684243629206, time: 0.05759859085083008
Test Loss Energy: 7.086063706722073, Test Loss Force: 9.22768211749513, time: 9.207048416137695


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.077391700407463, Training Loss Force: 4.529730918390324, time: 0.6131863594055176
Validation Loss Energy: 2.4508794314500397, Validation Loss Force: 4.445303368595767, time: 0.0596623420715332
Test Loss Energy: 7.942839689393213, Test Loss Force: 9.299309866697591, time: 9.381459474563599


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0870422690876884, Training Loss Force: 4.550840926136861, time: 0.5976238250732422
Validation Loss Energy: 2.5938724355745086, Validation Loss Force: 4.4711093865939215, time: 0.05814957618713379
Test Loss Energy: 8.132398434618567, Test Loss Force: 9.148906777309723, time: 9.265754222869873


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.049441516237312, Training Loss Force: 4.525488004692384, time: 0.6055889129638672
Validation Loss Energy: 3.2556292164279603, Validation Loss Force: 4.684015603818506, time: 0.06217837333679199
Test Loss Energy: 7.32023337128976, Test Loss Force: 9.252517589468802, time: 9.250699758529663


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.073824417635699, Training Loss Force: 4.534113258131899, time: 0.681523323059082
Validation Loss Energy: 2.6617446632830495, Validation Loss Force: 5.086259622516947, time: 0.06098198890686035
Test Loss Energy: 7.9272051886545825, Test Loss Force: 9.172407414204558, time: 10.245341777801514


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0257116917245015, Training Loss Force: 4.51485399429031, time: 0.6386916637420654
Validation Loss Energy: 2.3709864098985873, Validation Loss Force: 4.7753921185637465, time: 0.0662984848022461
Test Loss Energy: 8.08043521790234, Test Loss Force: 9.17452095243188, time: 10.420414209365845


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1241436482901803, Training Loss Force: 4.513813684040535, time: 0.6620869636535645
Validation Loss Energy: 4.5647526732447075, Validation Loss Force: 5.718110267053703, time: 0.06091046333312988
Test Loss Energy: 7.369352699643253, Test Loss Force: 9.19288681550548, time: 9.889774799346924


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1203668983089554, Training Loss Force: 4.509089031505096, time: 0.6666274070739746
Validation Loss Energy: 3.2975005906356594, Validation Loss Force: 4.4229433782999905, time: 0.06353187561035156
Test Loss Energy: 8.359352982327547, Test Loss Force: 9.20603484333738, time: 10.234326362609863


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.143618039825307, Training Loss Force: 4.526720712803669, time: 0.613755464553833
Validation Loss Energy: 2.7807874854060985, Validation Loss Force: 5.262527635801427, time: 0.0589447021484375
Test Loss Energy: 8.029024108750535, Test Loss Force: 9.204857131069078, time: 10.237839221954346


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.042796837464109, Training Loss Force: 4.5123352253684335, time: 0.6581213474273682
Validation Loss Energy: 3.2572832028439116, Validation Loss Force: 4.312304423747975, time: 0.060118675231933594
Test Loss Energy: 7.34094036843719, Test Loss Force: 9.222256125073617, time: 10.024784564971924

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–†â–…â–‚â–‡â–‡â–â–ˆâ–†â–â–…â–†â–‚â–…â–†â–‚â–‡â–†â–‚
wandb:   test_error_force â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–â–â–‚â–‚â–‚â–‚
wandb:          test_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–â–„â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–…â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–…â–ƒâ–â–…â–‚â–ƒâ–…â–ƒâ–‚â–†â–â–‚â–„â–‚â–â–ˆâ–„â–‚â–„
wandb:  valid_error_force â–†â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–â–ƒâ–ƒâ–„â–…â–„â–ˆâ–‚â–†â–‚
wandb:         valid_loss â–‚â–…â–‚â–â–…â–‚â–‚â–…â–ƒâ–‚â–„â–â–â–„â–ƒâ–â–ˆâ–‚â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1213
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.34094
wandb:   test_error_force 9.22226
wandb:          test_loss 5.78898
wandb: train_error_energy 3.0428
wandb:  train_error_force 4.51234
wandb:         train_loss 1.49016
wandb: valid_error_energy 3.25728
wandb:  valid_error_force 4.3123
wandb:         valid_loss 1.61361
wandb: 
wandb: ğŸš€ View run al_73_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o58bjhyb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_101410-o58bjhyb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3328328132629395, Uncertainty Bias: -0.004857510328292847
0.0 0.005346298
2.6881795 9.980293
(48745, 22, 3)
Found uncertainty sample 0 after 3417 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2755 steps.
Found uncertainty sample 4 after 2445 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 423 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3444 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1091 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2511 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1079 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2436 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2912 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3350 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3846 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 829 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_105519-uux2p6oa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_36
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uux2p6oa
Training model 36. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.728754679716689, Training Loss Force: 4.942931746834864, time: 0.6324808597564697
Validation Loss Energy: 2.214746372944582, Validation Loss Force: 4.5676600642830865, time: 0.06439518928527832
Test Loss Energy: 7.229770500692859, Test Loss Force: 9.303449017984768, time: 9.277299880981445


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.21261302553317, Training Loss Force: 4.653220666477443, time: 0.6027922630310059
Validation Loss Energy: 2.1508262999071137, Validation Loss Force: 4.560691633361277, time: 0.058118581771850586
Test Loss Energy: 6.857838182181052, Test Loss Force: 9.151734027274289, time: 9.29190444946289


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.232454199578608, Training Loss Force: 4.582605406107545, time: 0.6326148509979248
Validation Loss Energy: 1.8276828789370545, Validation Loss Force: 4.5349161210361135, time: 0.06417727470397949
Test Loss Energy: 7.174966986299597, Test Loss Force: 9.292094192583114, time: 9.487928867340088


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.080780941617916, Training Loss Force: 4.996566041176629, time: 0.6188173294067383
Validation Loss Energy: 7.942085608089554, Validation Loss Force: 4.925091694694414, time: 0.05951738357543945
Test Loss Energy: 8.764267161988425, Test Loss Force: 9.54278848654383, time: 9.213134527206421


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.718728412576711, Training Loss Force: 4.955143813474128, time: 0.6223647594451904
Validation Loss Energy: 2.490159270802858, Validation Loss Force: 5.58735159648309, time: 0.05884552001953125
Test Loss Energy: 7.81532443508929, Test Loss Force: 10.39724176188732, time: 9.825071096420288


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.4945767558432927, Training Loss Force: 5.755576474777137, time: 0.6079633235931396
Validation Loss Energy: 5.812698561559805, Validation Loss Force: 4.943006095491743, time: 0.05850839614868164
Test Loss Energy: 9.886734161297849, Test Loss Force: 9.44434960480818, time: 9.459247589111328


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.236914600199649, Training Loss Force: 5.028674749316527, time: 0.6533606052398682
Validation Loss Energy: 1.9411235123504198, Validation Loss Force: 4.902001572269141, time: 0.0596766471862793
Test Loss Energy: 7.693270110112456, Test Loss Force: 9.376722233885282, time: 9.283263444900513


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.218384195859385, Training Loss Force: 4.715899164904544, time: 0.6276788711547852
Validation Loss Energy: 1.6930283889892892, Validation Loss Force: 4.294436560802145, time: 0.06392455101013184
Test Loss Energy: 7.598641694356838, Test Loss Force: 9.230646969997037, time: 9.26840853691101


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.191505631970484, Training Loss Force: 4.562564926048106, time: 0.6495780944824219
Validation Loss Energy: 2.331230726580921, Validation Loss Force: 5.028891589098404, time: 0.05843210220336914
Test Loss Energy: 7.509658295855833, Test Loss Force: 9.21172087601551, time: 9.439378261566162


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.190054457180216, Training Loss Force: 4.517690858407571, time: 0.66023850440979
Validation Loss Energy: 1.7456968787484537, Validation Loss Force: 4.751905645058722, time: 0.05909848213195801
Test Loss Energy: 6.87274149107158, Test Loss Force: 9.16342710459571, time: 9.265705347061157


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1837257290220626, Training Loss Force: 4.521850312344037, time: 0.6359195709228516
Validation Loss Energy: 2.125361299705947, Validation Loss Force: 4.266229278734305, time: 0.06096529960632324
Test Loss Energy: 7.697160305636415, Test Loss Force: 9.173598705793344, time: 9.284568548202515


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1681965601159123, Training Loss Force: 4.544000456952905, time: 0.6123101711273193
Validation Loss Energy: 2.0912812302488346, Validation Loss Force: 4.057457470876735, time: 0.06168317794799805
Test Loss Energy: 7.88826945065839, Test Loss Force: 9.20658878821371, time: 9.473891973495483


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1922923563198387, Training Loss Force: 4.5476573923027335, time: 0.6136133670806885
Validation Loss Energy: 1.9447804077339919, Validation Loss Force: 4.9505897612637515, time: 0.06468415260314941
Test Loss Energy: 7.229057334553313, Test Loss Force: 9.190011627555153, time: 9.241563320159912


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1339802856550754, Training Loss Force: 4.522784278093502, time: 0.6478958129882812
Validation Loss Energy: 1.667704004353776, Validation Loss Force: 4.544951819443079, time: 0.05923199653625488
Test Loss Energy: 7.129188324670827, Test Loss Force: 9.172043999505492, time: 9.253279685974121


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1285006092240084, Training Loss Force: 4.5631355813933965, time: 0.6360220909118652
Validation Loss Energy: 3.300461533603634, Validation Loss Force: 5.648579376877146, time: 0.058999061584472656
Test Loss Energy: 8.009198340486511, Test Loss Force: 9.156207261555236, time: 9.436887264251709


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.149362832638097, Training Loss Force: 4.569962868624014, time: 0.6137959957122803
Validation Loss Energy: 2.9632656298359317, Validation Loss Force: 4.833472247910967, time: 0.061981916427612305
Test Loss Energy: 7.770492571995462, Test Loss Force: 9.227360336097316, time: 9.253401279449463


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1475234969960213, Training Loss Force: 4.554322564976183, time: 0.6267831325531006
Validation Loss Energy: 1.657482377209961, Validation Loss Force: 4.412202709377018, time: 0.0597689151763916
Test Loss Energy: 7.171985504725977, Test Loss Force: 9.233594745757323, time: 9.190351724624634


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1437429774154704, Training Loss Force: 4.550192292116766, time: 0.6315057277679443
Validation Loss Energy: 2.0891962677009395, Validation Loss Force: 4.612724514043389, time: 0.06005406379699707
Test Loss Energy: 6.993340499474526, Test Loss Force: 9.255574065078125, time: 9.63048243522644


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.188628072888194, Training Loss Force: 4.541286885132392, time: 0.6532261371612549
Validation Loss Energy: 1.7016612717769095, Validation Loss Force: 4.2819731006971296, time: 0.05848503112792969
Test Loss Energy: 7.9325245680216705, Test Loss Force: 9.162510859531851, time: 9.304548501968384


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.254337846331325, Training Loss Force: 4.560582548317632, time: 0.6858956813812256
Validation Loss Energy: 2.4943271918763346, Validation Loss Force: 4.742040288548391, time: 0.061034202575683594
Test Loss Energy: 8.240454713866354, Test Loss Force: 9.219979229299678, time: 9.890352487564087

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–…â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–â–ƒâ–„
wandb:   test_error_force â–‚â–â–‚â–ƒâ–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb:          test_loss â–â–‚â–ƒâ–ˆâ–ˆâ–†â–‚â–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„
wandb: train_error_energy â–ˆâ–â–â–„â–ƒâ–…â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ƒâ–‚â–â–„â–ƒâ–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–‡â–â–â–„â–ƒâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–â–ˆâ–‚â–†â–â–â–‚â–â–‚â–â–â–â–ƒâ–‚â–â–â–â–‚
wandb:  valid_error_force â–ƒâ–ƒâ–ƒâ–…â–ˆâ–…â–…â–‚â–…â–„â–‚â–â–…â–ƒâ–ˆâ–„â–ƒâ–ƒâ–‚â–„
wandb:         valid_loss â–â–â–â–ˆâ–‚â–„â–â–â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1224
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.24045
wandb:   test_error_force 9.21998
wandb:          test_loss 7.14364
wandb: train_error_energy 2.25434
wandb:  train_error_force 4.56058
wandb:         train_loss 1.18599
wandb: valid_error_energy 2.49433
wandb:  valid_error_force 4.74204
wandb:         valid_loss 1.24889
wandb: 
wandb: ğŸš€ View run al_73_36 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uux2p6oa
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_105519-uux2p6oa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.306990623474121, Uncertainty Bias: 0.06390385329723358
6.0081482e-05 0.0030765533
3.027276 9.41583
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 574 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2474 steps.
Found uncertainty sample 14 after 3923 steps.
Found uncertainty sample 15 after 970 steps.
Found uncertainty sample 16 after 3116 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 670 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3511 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2705 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2006 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3428 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1724 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1328 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2337 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 557 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1890 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1751 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1922 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3214 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3872 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2187 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1783 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_113452-oaky9z4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_37
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oaky9z4x
Training model 37. Added 21 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.027236806212046, Training Loss Force: 5.517904315716096, time: 0.6192817687988281
Validation Loss Energy: 7.843503742451237, Validation Loss Force: 5.534202252703294, time: 0.06916284561157227
Test Loss Energy: 12.381915861177173, Test Loss Force: 9.751382219123721, time: 9.53589129447937


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.538568580165164, Training Loss Force: 4.915827933121728, time: 0.606149435043335
Validation Loss Energy: 4.010423401186127, Validation Loss Force: 4.284079773486752, time: 0.05978798866271973
Test Loss Energy: 9.406938278437924, Test Loss Force: 9.317792231200986, time: 9.504536390304565


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.442249141529312, Training Loss Force: 4.712680750745026, time: 0.6288919448852539
Validation Loss Energy: 2.076419066769311, Validation Loss Force: 4.707968791853396, time: 0.06207537651062012
Test Loss Energy: 7.0184879507403615, Test Loss Force: 9.192519987323381, time: 9.74064040184021


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.4123798255542095, Training Loss Force: 4.666317289153637, time: 0.6171619892120361
Validation Loss Energy: 5.399726343410563, Validation Loss Force: 4.869662664198611, time: 0.06468558311462402
Test Loss Energy: 7.547582484062094, Test Loss Force: 9.156900977370013, time: 9.545503377914429


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.437298629759344, Training Loss Force: 4.671544030563328, time: 0.6054501533508301
Validation Loss Energy: 5.700259326962964, Validation Loss Force: 4.433767770821833, time: 0.06463217735290527
Test Loss Energy: 7.901094209522684, Test Loss Force: 9.136179852972791, time: 9.58259391784668


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.560009215233126, Training Loss Force: 4.641594716415448, time: 0.634082555770874
Validation Loss Energy: 3.4792621857538966, Validation Loss Force: 4.788763178107564, time: 0.06002378463745117
Test Loss Energy: 6.979057341642512, Test Loss Force: 9.111430296315238, time: 9.667445182800293


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.4551686794303755, Training Loss Force: 4.645347702099686, time: 0.6040606498718262
Validation Loss Energy: 2.4507454959587642, Validation Loss Force: 4.525381650876632, time: 0.06006026268005371
Test Loss Energy: 7.957012918615559, Test Loss Force: 9.12658444491317, time: 9.547947645187378


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.387037007910037, Training Loss Force: 4.6613072105324, time: 0.6053156852722168
Validation Loss Energy: 5.881282662527877, Validation Loss Force: 4.861704691592297, time: 0.05883908271789551
Test Loss Energy: 9.923709191375705, Test Loss Force: 9.21133532497224, time: 9.526525497436523


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.37190403021861, Training Loss Force: 4.618892415128798, time: 0.6159882545471191
Validation Loss Energy: 6.027972865151332, Validation Loss Force: 4.769341307192304, time: 0.059464454650878906
Test Loss Energy: 10.324720402930621, Test Loss Force: 9.10509712414546, time: 9.736970901489258


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.465232531210638, Training Loss Force: 4.641792241076282, time: 0.6350138187408447
Validation Loss Energy: 4.833247574742726, Validation Loss Force: 5.33499998539569, time: 0.05939888954162598
Test Loss Energy: 8.649743537837852, Test Loss Force: 9.088721177119947, time: 10.16667103767395


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.474455370190929, Training Loss Force: 4.6267489134086865, time: 0.6094729900360107
Validation Loss Energy: 1.9013297526087998, Validation Loss Force: 4.186644876619109, time: 0.0588381290435791
Test Loss Energy: 7.342012871282752, Test Loss Force: 9.133604463962605, time: 9.542948484420776


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4932070497979355, Training Loss Force: 4.632819228313525, time: 0.6218914985656738
Validation Loss Energy: 4.716856408143958, Validation Loss Force: 5.019030908640138, time: 0.05992841720581055
Test Loss Energy: 7.7041833417944865, Test Loss Force: 9.108039019575001, time: 9.731490135192871


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.479014184095347, Training Loss Force: 4.612569296520282, time: 0.6378772258758545
Validation Loss Energy: 6.5346794416320435, Validation Loss Force: 4.872456939310858, time: 0.059332847595214844
Test Loss Energy: 7.898041616050826, Test Loss Force: 9.04208164393042, time: 9.493386030197144


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.476998580131678, Training Loss Force: 4.618127814957405, time: 0.6401023864746094
Validation Loss Energy: 2.8904360075970272, Validation Loss Force: 5.332709610560677, time: 0.06003856658935547
Test Loss Energy: 7.149747541785397, Test Loss Force: 9.041580850528966, time: 9.54452109336853


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.526503161141621, Training Loss Force: 4.600104860096702, time: 0.6383845806121826
Validation Loss Energy: 2.4465413911490743, Validation Loss Force: 4.642195888852662, time: 0.06244826316833496
Test Loss Energy: 7.644309916752459, Test Loss Force: 9.035970539350135, time: 9.73967432975769


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.396684999367685, Training Loss Force: 4.64896520788229, time: 0.6222686767578125
Validation Loss Energy: 4.877668288002152, Validation Loss Force: 4.742298807426812, time: 0.06184053421020508
Test Loss Energy: 9.92451399927558, Test Loss Force: 9.040215079594336, time: 9.548657417297363


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.453610603466934, Training Loss Force: 4.623013552843768, time: 0.6531949043273926
Validation Loss Energy: 5.977934209340147, Validation Loss Force: 4.941218062249943, time: 0.06260538101196289
Test Loss Energy: 10.30909023666259, Test Loss Force: 9.087614621050546, time: 9.499843835830688


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.50526438707337, Training Loss Force: 4.6142902092882485, time: 0.6375207901000977
Validation Loss Energy: 4.29253786099482, Validation Loss Force: 4.533609943826101, time: 0.06723785400390625
Test Loss Energy: 9.12935365633972, Test Loss Force: 9.041423387302777, time: 9.734054803848267


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.5852050341294595, Training Loss Force: 4.621139877622765, time: 0.6697533130645752
Validation Loss Energy: 2.23737312087718, Validation Loss Force: 4.508318959562477, time: 0.059556007385253906
Test Loss Energy: 6.886167654817075, Test Loss Force: 9.080180493348424, time: 9.496007680892944


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.467865776564124, Training Loss Force: 4.602189728438422, time: 0.6241703033447266
Validation Loss Energy: 5.081089690286795, Validation Loss Force: 5.302090153635001, time: 0.06827473640441895
Test Loss Energy: 7.510983261212211, Test Loss Force: 9.088403895737333, time: 9.489918947219849

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–â–‚â–‚â–â–‚â–…â–…â–ƒâ–‚â–‚â–‚â–â–‚â–…â–…â–„â–â–‚
wandb:   test_error_force â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚
wandb:          test_loss â–ˆâ–ƒâ–â–â–‚â–â–â–‚â–ƒâ–‚â–â–â–‚â–â–â–‚â–ƒâ–‚â–â–
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–â–…â–…â–ƒâ–‚â–†â–†â–„â–â–„â–†â–‚â–‚â–…â–†â–„â–â–…
wandb:  valid_error_force â–ˆâ–‚â–„â–…â–‚â–„â–ƒâ–…â–„â–‡â–â–…â–…â–‡â–ƒâ–„â–…â–ƒâ–ƒâ–‡
wandb:         valid_loss â–ˆâ–‚â–â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1242
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.51098
wandb:   test_error_force 9.0884
wandb:          test_loss 4.85161
wandb: train_error_energy 4.46787
wandb:  train_error_force 4.60219
wandb:         train_loss 1.90213
wandb: valid_error_energy 5.08109
wandb:  valid_error_force 5.30209
wandb:         valid_loss 2.30232
wandb: 
wandb: ğŸš€ View run al_73_37 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oaky9z4x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_113452-oaky9z4x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.572937488555908, Uncertainty Bias: -0.13864758610725403
9.1552734e-05 0.08711815
2.3567066 8.962043
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2219 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3109 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1522 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2994 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3911 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2191 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2634 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2932 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3632 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3013 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 675 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_121647-f8h53hwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_38
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/f8h53hwi
Training model 38. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.776195809445601, Training Loss Force: 4.910532428054097, time: 0.6383183002471924
Validation Loss Energy: 1.67297358102673, Validation Loss Force: 4.64888175262829, time: 0.0670773983001709
Test Loss Energy: 6.843690945792618, Test Loss Force: 9.231575442045203, time: 9.487625360488892


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7447846873574497, Training Loss Force: 5.251095022507483, time: 0.6304755210876465
Validation Loss Energy: 3.013069703701881, Validation Loss Force: 5.212939885010746, time: 0.06079673767089844
Test Loss Energy: 8.630125800846479, Test Loss Force: 9.383829604525117, time: 10.139797449111938


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3434806247080777, Training Loss Force: 5.127743318608129, time: 0.678642749786377
Validation Loss Energy: 1.728670760841518, Validation Loss Force: 4.687039450820205, time: 0.0616607666015625
Test Loss Energy: 6.984298434734797, Test Loss Force: 9.133849740438786, time: 9.70375108718872


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.416707998657921, Training Loss Force: 5.240472590900998, time: 0.6535282135009766
Validation Loss Energy: 2.584359898325901, Validation Loss Force: 5.050918243682727, time: 0.06039547920227051
Test Loss Energy: 7.173749988665433, Test Loss Force: 9.205082206440748, time: 9.49792766571045


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.47963020835049, Training Loss Force: 4.837904538494675, time: 0.6416912078857422
Validation Loss Energy: 2.2678618710141967, Validation Loss Force: 4.556239809126742, time: 0.059845685958862305
Test Loss Energy: 7.522197438988518, Test Loss Force: 9.072842013119644, time: 9.503997325897217


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.4765677839192595, Training Loss Force: 4.668010401678734, time: 0.6269879341125488
Validation Loss Energy: 2.8372610568654504, Validation Loss Force: 4.532936814997962, time: 0.060463666915893555
Test Loss Energy: 7.875351310649653, Test Loss Force: 8.999336894881392, time: 9.709058284759521


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.439369864897129, Training Loss Force: 4.618789643040914, time: 0.6500186920166016
Validation Loss Energy: 3.06238279210106, Validation Loss Force: 4.675439056324805, time: 0.06071305274963379
Test Loss Energy: 8.273333296169156, Test Loss Force: 9.016484746068695, time: 9.478854417800903


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.339487288576331, Training Loss Force: 4.648639254794918, time: 0.6258459091186523
Validation Loss Energy: 2.468344040572594, Validation Loss Force: 4.408386605554107, time: 0.05959630012512207
Test Loss Energy: 8.053046567874334, Test Loss Force: 9.029719649841718, time: 9.50166654586792


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.381836549738291, Training Loss Force: 4.630614231965891, time: 0.6336555480957031
Validation Loss Energy: 2.8800943617835575, Validation Loss Force: 4.705871693837048, time: 0.0616452693939209
Test Loss Energy: 8.150134668622364, Test Loss Force: 9.010796885405117, time: 9.65639877319336


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.379188824324436, Training Loss Force: 4.6051191491631105, time: 0.6838724613189697
Validation Loss Energy: 2.3933197912314252, Validation Loss Force: 4.800358005874316, time: 0.06099820137023926
Test Loss Energy: 7.966100608379869, Test Loss Force: 9.043330829497148, time: 9.518923997879028


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.4088655112197115, Training Loss Force: 4.660853815328616, time: 0.6220223903656006
Validation Loss Energy: 3.135714978602323, Validation Loss Force: 4.675190334888804, time: 0.06130671501159668
Test Loss Energy: 8.170197174991756, Test Loss Force: 9.032923212994515, time: 9.517369270324707


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4529404248622395, Training Loss Force: 4.782182581170673, time: 0.650766134262085
Validation Loss Energy: 3.133911358520308, Validation Loss Force: 4.352960247088054, time: 0.060318946838378906
Test Loss Energy: 8.562905049431796, Test Loss Force: 9.101306222739288, time: 9.694952249526978


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.513986454349297, Training Loss Force: 4.653125648414357, time: 0.6853883266448975
Validation Loss Energy: 2.4813594974903648, Validation Loss Force: 4.855206983244978, time: 0.06089901924133301
Test Loss Energy: 7.598316870202634, Test Loss Force: 9.007762079817178, time: 9.54796576499939


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.446461262071414, Training Loss Force: 4.666065564824372, time: 0.6763150691986084
Validation Loss Energy: 2.418983634979906, Validation Loss Force: 5.030258554985254, time: 0.06369233131408691
Test Loss Energy: 7.993265549362059, Test Loss Force: 8.985709552477068, time: 9.521167516708374


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.411876159507786, Training Loss Force: 4.5719864701211765, time: 0.6397101879119873
Validation Loss Energy: 2.8992361149132395, Validation Loss Force: 4.520552402439749, time: 0.06580185890197754
Test Loss Energy: 8.160464542116276, Test Loss Force: 9.048584035324646, time: 9.658243417739868


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4025447023753745, Training Loss Force: 4.627085371341228, time: 0.6707484722137451
Validation Loss Energy: 2.5061425734321277, Validation Loss Force: 5.0666803245155165, time: 0.060021400451660156
Test Loss Energy: 7.89644890445325, Test Loss Force: 9.064241975779758, time: 10.166017532348633


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.308703295852, Training Loss Force: 4.637687217185173, time: 0.654991865158081
Validation Loss Energy: 2.842477749616246, Validation Loss Force: 5.095884496349676, time: 0.06048727035522461
Test Loss Energy: 7.863059155397892, Test Loss Force: 8.963036037028981, time: 9.515436172485352


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.24823427727288, Training Loss Force: 4.627122323285995, time: 0.6483573913574219
Validation Loss Energy: 2.611489684396596, Validation Loss Force: 4.794984331375641, time: 0.06169271469116211
Test Loss Energy: 7.597449407168838, Test Loss Force: 8.93314991120734, time: 9.75106430053711


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.501279085245196, Training Loss Force: 4.659607246648968, time: 0.6254329681396484
Validation Loss Energy: 2.318817255699166, Validation Loss Force: 4.526365403163341, time: 0.06000375747680664
Test Loss Energy: 7.9778588846261895, Test Loss Force: 8.991505231639557, time: 9.527429580688477


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.525666082876911, Training Loss Force: 4.6309287298676, time: 0.6548583507537842
Validation Loss Energy: 2.4525635895352647, Validation Loss Force: 4.77086770418764, time: 0.060547590255737305
Test Loss Energy: 8.080283586042999, Test Loss Force: 9.036474354523456, time: 9.52079725265503

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–‚â–‚â–„â–…â–‡â–†â–†â–…â–†â–ˆâ–„â–†â–†â–…â–…â–„â–…â–†
wandb:   test_error_force â–†â–ˆâ–„â–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–â–â–‚â–ƒ
wandb:          test_loss â–ƒâ–ˆâ–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡
wandb:  train_error_force â–„â–ˆâ–‡â–ˆâ–„â–‚â–â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–‡â–ƒâ–â–ˆâ–‡â–…â–…â–„â–…â–„â–…â–…â–…â–…â–„â–„â–„â–„â–…â–…
wandb: valid_error_energy â–â–‡â–â–…â–„â–‡â–ˆâ–…â–‡â–„â–ˆâ–ˆâ–…â–…â–‡â–…â–‡â–…â–„â–…
wandb:  valid_error_force â–ƒâ–ˆâ–„â–‡â–ƒâ–‚â–„â–â–„â–…â–„â–â–…â–‡â–‚â–‡â–‡â–…â–‚â–„
wandb:         valid_loss â–‚â–ˆâ–â–†â–„â–…â–†â–„â–†â–…â–†â–…â–†â–†â–…â–‡â–‡â–†â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1251
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.08028
wandb:   test_error_force 9.03647
wandb:          test_loss 5.06528
wandb: train_error_energy 4.52567
wandb:  train_error_force 4.63093
wandb:         train_loss 1.93879
wandb: valid_error_energy 2.45256
wandb:  valid_error_force 4.77087
wandb:         valid_loss 1.52892
wandb: 
wandb: ğŸš€ View run al_73_38 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/f8h53hwi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_121647-f8h53hwi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.512568473815918, Uncertainty Bias: -0.1394382119178772
0.00039672852 0.02152729
2.4144466 8.726939
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1933 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2283 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_125941-wdsgp62d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_39
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wdsgp62d
Training model 39. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.274984176462733, Training Loss Force: 5.4878858568034685, time: 0.6666252613067627
Validation Loss Energy: 4.307782013394181, Validation Loss Force: 5.01742101071508, time: 0.06268596649169922
Test Loss Energy: 7.097059857596111, Test Loss Force: 9.025295458731613, time: 9.331418991088867


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0307642966518067, Training Loss Force: 4.690464525355952, time: 0.6705062389373779
Validation Loss Energy: 2.746082272321794, Validation Loss Force: 4.917654990558718, time: 0.06091427803039551
Test Loss Energy: 7.810725386911858, Test Loss Force: 9.038834153168102, time: 9.35592794418335


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9889511671259537, Training Loss Force: 4.604040372818377, time: 0.6728975772857666
Validation Loss Energy: 2.774533154435279, Validation Loss Force: 4.555942100478637, time: 0.06008577346801758
Test Loss Energy: 8.012680102506486, Test Loss Force: 8.993242228180467, time: 9.49075984954834


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0447947853045614, Training Loss Force: 4.556411219835278, time: 0.6301991939544678
Validation Loss Energy: 3.752160146943491, Validation Loss Force: 4.601057096135065, time: 0.05831003189086914
Test Loss Energy: 7.192743892979641, Test Loss Force: 8.988387509191226, time: 9.583138227462769


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.076213426845251, Training Loss Force: 4.598705676553696, time: 0.6379351615905762
Validation Loss Energy: 2.254140330234689, Validation Loss Force: 4.899164990019166, time: 0.06184649467468262
Test Loss Energy: 7.639698839777917, Test Loss Force: 9.040623503771865, time: 10.010772705078125


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0512678553108827, Training Loss Force: 4.586318079826698, time: 0.7100841999053955
Validation Loss Energy: 2.8626374347465378, Validation Loss Force: 4.740141588741064, time: 0.05971050262451172
Test Loss Energy: 8.25012844783822, Test Loss Force: 8.980095300870417, time: 10.387575626373291


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1067794682261827, Training Loss Force: 4.598047589026364, time: 0.6429681777954102
Validation Loss Energy: 3.504117629168086, Validation Loss Force: 4.710714970430123, time: 0.059545278549194336
Test Loss Energy: 6.840053683765521, Test Loss Force: 9.010441309592633, time: 10.98859167098999


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1518662628352803, Training Loss Force: 4.582704293189778, time: 0.6692371368408203
Validation Loss Energy: 2.4045094724871614, Validation Loss Force: 4.696475278548041, time: 0.06596136093139648
Test Loss Energy: 7.771612621115619, Test Loss Force: 9.014010012838925, time: 10.035869121551514


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1054961090369, Training Loss Force: 4.606950224350818, time: 0.6771101951599121
Validation Loss Energy: 3.117138805103297, Validation Loss Force: 5.050210601136968, time: 0.06125998497009277
Test Loss Energy: 8.253432160811174, Test Loss Force: 9.026630340442729, time: 10.4102783203125


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.06472840001772, Training Loss Force: 4.60136815379847, time: 0.6610195636749268
Validation Loss Energy: 3.5289051584927673, Validation Loss Force: 4.762594432070692, time: 0.06615829467773438
Test Loss Energy: 7.057702300299426, Test Loss Force: 9.00377432023309, time: 10.418612718582153


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.981529532124708, Training Loss Force: 4.5967153261259055, time: 0.6600615978240967
Validation Loss Energy: 2.288242777940967, Validation Loss Force: 4.796030876361501, time: 0.07003426551818848
Test Loss Energy: 7.977930605075703, Test Loss Force: 9.03513273444761, time: 10.267168283462524


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0144423727022316, Training Loss Force: 4.566250100984157, time: 0.8412063121795654
Validation Loss Energy: 2.632600723452864, Validation Loss Force: 4.99056755705448, time: 0.06954145431518555
Test Loss Energy: 8.265742094620398, Test Loss Force: 9.017225989505157, time: 10.379648208618164


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0794035492483074, Training Loss Force: 4.558747130510633, time: 0.624401330947876
Validation Loss Energy: 3.0146906237496625, Validation Loss Force: 4.743248268665049, time: 0.061419010162353516
Test Loss Energy: 6.986833097441612, Test Loss Force: 9.05380868354273, time: 10.319868087768555


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1252003912299395, Training Loss Force: 4.576420536491324, time: 0.6876826286315918
Validation Loss Energy: 2.656282366464295, Validation Loss Force: 4.858382022596762, time: 0.06770133972167969
Test Loss Energy: 8.325024651345311, Test Loss Force: 8.995443677585566, time: 10.28168535232544


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0764881142870317, Training Loss Force: 4.5580791008059345, time: 0.6980926990509033
Validation Loss Energy: 3.0354104331165352, Validation Loss Force: 4.558475407351857, time: 0.06575751304626465
Test Loss Energy: 8.155163512552104, Test Loss Force: 9.016372320300336, time: 10.450774669647217


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.10313151300882, Training Loss Force: 4.655138711095032, time: 0.6276094913482666
Validation Loss Energy: 3.9502512952129156, Validation Loss Force: 4.903540884074939, time: 0.06058549880981445
Test Loss Energy: 7.214714342840433, Test Loss Force: 9.015770530702806, time: 10.099459171295166


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1486996403772123, Training Loss Force: 4.663383904632677, time: 0.690192699432373
Validation Loss Energy: 2.2377645732357214, Validation Loss Force: 4.573267541384986, time: 0.06435680389404297
Test Loss Energy: 7.552391724918439, Test Loss Force: 9.044889919219493, time: 10.23174524307251


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.038382854678982, Training Loss Force: 4.553519760774289, time: 0.8047034740447998
Validation Loss Energy: 2.9316063079987726, Validation Loss Force: 4.455050710458756, time: 0.06265974044799805
Test Loss Energy: 7.8924717677029745, Test Loss Force: 9.017536984856173, time: 10.571792125701904


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.159135761925935, Training Loss Force: 4.645434277576463, time: 0.6903998851776123
Validation Loss Energy: 3.1090696092585928, Validation Loss Force: 4.498933455061621, time: 0.06650209426879883
Test Loss Energy: 7.110851380606828, Test Loss Force: 9.08908585555385, time: 10.114166975021362


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.102830954195647, Training Loss Force: 4.648594386962013, time: 0.6745541095733643
Validation Loss Energy: 2.6268692196366827, Validation Loss Force: 4.92088703321186, time: 0.06676125526428223
Test Loss Energy: 8.017136155123179, Test Loss Force: 8.994668593102155, time: 10.35309648513794

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‡â–ƒâ–…â–ˆâ–â–…â–ˆâ–‚â–†â–ˆâ–‚â–ˆâ–‡â–ƒâ–„â–†â–‚â–‡
wandb:   test_error_force â–„â–…â–‚â–‚â–…â–â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–†â–‚â–ƒâ–ƒâ–…â–ƒâ–ˆâ–‚
wandb:          test_loss â–â–†â–†â–…â–†â–‡â–„â–…â–‡â–…â–†â–ˆâ–„â–‡â–‡â–…â–…â–†â–…â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–ƒâ–†â–â–ƒâ–…â–‚â–„â–…â–â–‚â–„â–‚â–„â–‡â–â–ƒâ–„â–‚
wandb:  valid_error_force â–ˆâ–†â–‚â–ƒâ–†â–„â–„â–„â–ˆâ–…â–…â–‡â–„â–†â–‚â–†â–‚â–â–‚â–†
wandb:         valid_loss â–‡â–ƒâ–‚â–‡â–‚â–ƒâ–…â–‚â–„â–†â–‚â–ƒâ–„â–ƒâ–ƒâ–ˆâ–â–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1252
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.01714
wandb:   test_error_force 8.99467
wandb:          test_loss 5.70414
wandb: train_error_energy 3.10283
wandb:  train_error_force 4.64859
wandb:         train_loss 1.55868
wandb: valid_error_energy 2.62687
wandb:  valid_error_force 4.92089
wandb:         valid_loss 1.48171
wandb: 
wandb: ğŸš€ View run al_73_39 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wdsgp62d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_125941-wdsgp62d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5445618629455566, Uncertainty Bias: -0.05416470766067505
0.00012207031 0.01550293
2.4107282 9.280437
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1070 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1819 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1695 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3093 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 565 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 661 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 758 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3269 steps.
Found uncertainty sample 90 after 3127 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3847 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_134115-5ss2gai3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_40
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5ss2gai3
Training model 40. Added 10 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.32454529383913, Training Loss Force: 5.117224517222158, time: 0.6340000629425049
Validation Loss Energy: 4.215658443664354, Validation Loss Force: 5.161636468450693, time: 0.0581812858581543
Test Loss Energy: 7.41730097948152, Test Loss Force: 9.07634964206637, time: 8.65636420249939


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.454949691033977, Training Loss Force: 4.659835437989715, time: 0.6391911506652832
Validation Loss Energy: 3.127834940197084, Validation Loss Force: 4.826396045122528, time: 0.06411433219909668
Test Loss Energy: 7.180035689172267, Test Loss Force: 9.00499257927048, time: 8.720319271087646


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.465727105932757, Training Loss Force: 4.637041287393208, time: 0.6370961666107178
Validation Loss Energy: 3.065526991776133, Validation Loss Force: 5.06160970272445, time: 0.058231353759765625
Test Loss Energy: 7.306865528207585, Test Loss Force: 9.006709379370111, time: 8.853108406066895


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.40580172850669, Training Loss Force: 4.6699276275590025, time: 0.6503257751464844
Validation Loss Energy: 2.808432750549617, Validation Loss Force: 4.208877834167133, time: 0.056891441345214844
Test Loss Energy: 7.0026749229738225, Test Loss Force: 8.955728091618372, time: 8.652782201766968


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.515282099308708, Training Loss Force: 4.781610967206163, time: 0.6471595764160156
Validation Loss Energy: 3.562599008316268, Validation Loss Force: 4.810448035552888, time: 0.05854463577270508
Test Loss Energy: 7.078343909661216, Test Loss Force: 9.00297899267612, time: 8.646960258483887


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.478781635718909, Training Loss Force: 4.643652980076327, time: 0.6367754936218262
Validation Loss Energy: 3.3739745274513906, Validation Loss Force: 4.50389897701581, time: 0.05973005294799805
Test Loss Energy: 6.971320509809089, Test Loss Force: 9.004964665186554, time: 8.612759113311768


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.432819681782208, Training Loss Force: 4.647533268280552, time: 0.6580259799957275
Validation Loss Energy: 3.545301289718587, Validation Loss Force: 4.681863283853968, time: 0.06318378448486328
Test Loss Energy: 7.078658055022873, Test Loss Force: 9.010524576195138, time: 8.890375137329102


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.295639029857442, Training Loss Force: 4.6395278003454115, time: 0.7028200626373291
Validation Loss Energy: 3.861222381273192, Validation Loss Force: 4.848407335535782, time: 0.06359601020812988
Test Loss Energy: 7.003763786755479, Test Loss Force: 8.965964987337076, time: 8.709332704544067


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.415574326617556, Training Loss Force: 4.625255854837542, time: 0.6343748569488525
Validation Loss Energy: 3.6377772333718457, Validation Loss Force: 4.650694724814434, time: 0.05632758140563965
Test Loss Energy: 7.024766831275971, Test Loss Force: 8.934881479750638, time: 8.701980590820312


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.4774639075469524, Training Loss Force: 4.591681767614178, time: 0.6841611862182617
Validation Loss Energy: 3.5559988721618225, Validation Loss Force: 4.811077075890134, time: 0.06135153770446777
Test Loss Energy: 7.0302605221126875, Test Loss Force: 8.974712447972864, time: 8.893255233764648


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.514517489645327, Training Loss Force: 4.626576628010071, time: 0.6556744575500488
Validation Loss Energy: 3.153001229738989, Validation Loss Force: 4.674990377995761, time: 0.05705714225769043
Test Loss Energy: 7.110606484183748, Test Loss Force: 8.947353470065815, time: 9.28534460067749


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.504578535415539, Training Loss Force: 4.630706249990447, time: 0.678166389465332
Validation Loss Energy: 3.1971721082166837, Validation Loss Force: 4.686271910274192, time: 0.06711959838867188
Test Loss Energy: 7.03961896823199, Test Loss Force: 8.92338445853188, time: 11.305601596832275


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.50648511771063, Training Loss Force: 4.6141040830039, time: 0.6661262512207031
Validation Loss Energy: 3.354996213474819, Validation Loss Force: 4.84627928650815, time: 0.06508612632751465
Test Loss Energy: 7.027798957839318, Test Loss Force: 8.902260552463238, time: 10.110008239746094


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.601255243841298, Training Loss Force: 4.669167145624914, time: 0.6782684326171875
Validation Loss Energy: 3.657244862796593, Validation Loss Force: 4.8421374177247465, time: 0.06362748146057129
Test Loss Energy: 7.133243684742327, Test Loss Force: 8.939398543713315, time: 9.542119264602661


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.338745652802082, Training Loss Force: 4.619048829926775, time: 0.6286787986755371
Validation Loss Energy: 3.712308604558503, Validation Loss Force: 4.471019650928113, time: 0.06206560134887695
Test Loss Energy: 6.866202199552711, Test Loss Force: 8.900131401747947, time: 9.439285278320312


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.523053656089414, Training Loss Force: 4.633360148906373, time: 0.638979434967041
Validation Loss Energy: 3.916303157224765, Validation Loss Force: 4.879045274000569, time: 0.0603940486907959
Test Loss Energy: 6.967263729784607, Test Loss Force: 8.892023903895623, time: 9.435366868972778


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.584139306767623, Training Loss Force: 4.581048191416939, time: 0.630481481552124
Validation Loss Energy: 3.348436380435787, Validation Loss Force: 4.644301893634847, time: 0.05772757530212402
Test Loss Energy: 7.296294300012398, Test Loss Force: 8.919367866207912, time: 9.21248173713684


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.373760612585195, Training Loss Force: 4.629978979159475, time: 0.6331615447998047
Validation Loss Energy: 3.5242936804806027, Validation Loss Force: 4.672735630224096, time: 0.05788230895996094
Test Loss Energy: 7.223320675538371, Test Loss Force: 8.95352578884251, time: 9.248526334762573


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.407206013742398, Training Loss Force: 4.582766807552496, time: 0.6346597671508789
Validation Loss Energy: 3.418461930120022, Validation Loss Force: 5.04439470571448, time: 0.05859231948852539
Test Loss Energy: 6.943184766324864, Test Loss Force: 8.887707195532, time: 9.414668083190918


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.524798769853336, Training Loss Force: 4.713448267596759, time: 0.6393721103668213
Validation Loss Energy: 3.1756347690805375, Validation Loss Force: 4.688045915359799, time: 0.06001639366149902
Test Loss Energy: 7.242767780347156, Test Loss Force: 8.982620951888764, time: 9.204533338546753

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–‡â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–â–‚â–†â–†â–‚â–†
wandb:   test_error_force â–ˆâ–…â–…â–„â–…â–…â–†â–„â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–â–â–‚â–ƒâ–â–…
wandb:          test_loss â–ˆâ–‡â–‡â–ƒâ–„â–„â–†â–„â–ƒâ–„â–…â–…â–ƒâ–„â–â–â–„â–…â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–ƒ
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–â–…â–„â–…â–†â–…â–…â–ƒâ–ƒâ–„â–…â–…â–‡â–„â–…â–„â–ƒ
wandb:  valid_error_force â–ˆâ–†â–‡â–â–…â–ƒâ–„â–†â–„â–…â–„â–…â–†â–†â–ƒâ–†â–„â–„â–‡â–…
wandb:         valid_loss â–ˆâ–„â–…â–â–…â–ƒâ–…â–†â–…â–…â–„â–„â–…â–†â–„â–†â–„â–„â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1261
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.24277
wandb:   test_error_force 8.98262
wandb:          test_loss 4.6582
wandb: train_error_energy 4.5248
wandb:  train_error_force 4.71345
wandb:         train_loss 1.96466
wandb: valid_error_energy 3.17563
wandb:  valid_error_force 4.68805
wandb:         valid_loss 1.64159
wandb: 
wandb: ğŸš€ View run al_73_40 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5ss2gai3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_134115-5ss2gai3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.887625217437744, Uncertainty Bias: -0.20762324333190918
0.00037002563 0.01613617
2.2066388 9.765151
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2525 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3802 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3675 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3921 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3122 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_142356-gi8a1e5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_41
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/gi8a1e5t
Training model 41. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.575867390149102, Training Loss Force: 4.931674139785216, time: 0.6997137069702148
Validation Loss Energy: 7.100158425834665, Validation Loss Force: 4.91450310879811, time: 0.0664358139038086
Test Loss Energy: 8.23419107742369, Test Loss Force: 9.163910546125084, time: 9.426333665847778


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.380787288188851, Training Loss Force: 4.995658898209577, time: 0.6385664939880371
Validation Loss Energy: 5.328393391836013, Validation Loss Force: 5.0034373883508145, time: 0.05962800979614258
Test Loss Energy: 7.434237509488691, Test Loss Force: 8.953172423400186, time: 9.46657133102417


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.443956145112066, Training Loss Force: 4.610886914649706, time: 0.6372551918029785
Validation Loss Energy: 5.199067819888592, Validation Loss Force: 4.810639531018386, time: 0.06304645538330078
Test Loss Energy: 7.538352036561683, Test Loss Force: 8.912160362069221, time: 9.570298671722412


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.413356358222069, Training Loss Force: 4.574738504896442, time: 0.6955657005310059
Validation Loss Energy: 5.306956810488399, Validation Loss Force: 4.950734050870313, time: 0.05987834930419922
Test Loss Energy: 7.588473520631925, Test Loss Force: 8.901326568479353, time: 10.121233701705933


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.402560264165311, Training Loss Force: 4.577151982368781, time: 0.685797929763794
Validation Loss Energy: 5.985917120890804, Validation Loss Force: 4.908352764318439, time: 0.05878138542175293
Test Loss Energy: 7.583616281167851, Test Loss Force: 8.88580124557065, time: 9.518285512924194


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.30907441295079, Training Loss Force: 4.582933263872535, time: 0.6267869472503662
Validation Loss Energy: 5.5184896044209, Validation Loss Force: 5.223119427685981, time: 0.059613943099975586
Test Loss Energy: 7.679558062499728, Test Loss Force: 8.892160293993635, time: 9.600340127944946


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.397999062062932, Training Loss Force: 4.561849401585528, time: 0.6644196510314941
Validation Loss Energy: 5.694561223518671, Validation Loss Force: 4.958939631566897, time: 0.06052446365356445
Test Loss Energy: 7.603975991390896, Test Loss Force: 8.889972866915693, time: 9.522537469863892


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.3927925118917335, Training Loss Force: 4.576388911905873, time: 0.67649245262146
Validation Loss Energy: 5.659737327779586, Validation Loss Force: 4.814124971159593, time: 0.06157493591308594
Test Loss Energy: 7.607075149527814, Test Loss Force: 8.879191296818295, time: 9.430694818496704


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.337051026483635, Training Loss Force: 4.591665646368012, time: 0.6303718090057373
Validation Loss Energy: 5.598089148038019, Validation Loss Force: 4.742255386943357, time: 0.06536698341369629
Test Loss Energy: 7.787529251822788, Test Loss Force: 8.872022548769062, time: 9.607759952545166


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.368807799472508, Training Loss Force: 4.588610035612648, time: 0.6409139633178711
Validation Loss Energy: 5.415209865141797, Validation Loss Force: 4.596535576457857, time: 0.06409835815429688
Test Loss Energy: 7.550045281759321, Test Loss Force: 8.941145305054047, time: 9.368425130844116


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.412602367093586, Training Loss Force: 4.577721414175663, time: 0.6516497135162354
Validation Loss Energy: 5.977064686325299, Validation Loss Force: 4.737965665847058, time: 0.05985069274902344
Test Loss Energy: 7.777423653956915, Test Loss Force: 8.884338353582573, time: 9.378998517990112


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.416370936620569, Training Loss Force: 4.599237187805026, time: 0.6701920032501221
Validation Loss Energy: 5.957089705251555, Validation Loss Force: 5.141537015324374, time: 0.05912446975708008
Test Loss Energy: 7.693795467068386, Test Loss Force: 8.930728851734003, time: 9.6294686794281


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.501288064378505, Training Loss Force: 4.580969644875713, time: 0.6594874858856201
Validation Loss Energy: 5.66661758171961, Validation Loss Force: 4.333113300773219, time: 0.05944085121154785
Test Loss Energy: 7.592819469767894, Test Loss Force: 8.874284410295326, time: 9.46501350402832


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.450217364909589, Training Loss Force: 4.557139732046738, time: 0.6415624618530273
Validation Loss Energy: 5.477938212910261, Validation Loss Force: 4.613587134314715, time: 0.06197333335876465
Test Loss Energy: 7.5775282572354765, Test Loss Force: 8.93482555831822, time: 9.430806636810303


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.5241533076665785, Training Loss Force: 4.577902065653754, time: 0.6475462913513184
Validation Loss Energy: 5.710357150061643, Validation Loss Force: 4.664837110279746, time: 0.05936145782470703
Test Loss Energy: 7.625152885721429, Test Loss Force: 8.883530952927826, time: 9.599757432937622


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.400064059538531, Training Loss Force: 4.567575438874177, time: 0.6900174617767334
Validation Loss Energy: 4.893396300455615, Validation Loss Force: 4.781635538746416, time: 0.06627702713012695
Test Loss Energy: 7.519793199779249, Test Loss Force: 8.923861987087909, time: 9.440516233444214


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.478651468902929, Training Loss Force: 4.5783799804416585, time: 0.6276578903198242
Validation Loss Energy: 5.48588928277305, Validation Loss Force: 4.877715271191943, time: 0.05939769744873047
Test Loss Energy: 7.605882731769425, Test Loss Force: 8.911313132782528, time: 9.372660398483276


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.408428422819712, Training Loss Force: 4.5897211880511986, time: 0.637345552444458
Validation Loss Energy: 5.597789880705893, Validation Loss Force: 4.881319839326222, time: 0.059250831604003906
Test Loss Energy: 7.520993838808934, Test Loss Force: 8.879406201689289, time: 9.614344120025635


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.425177579276214, Training Loss Force: 4.566323425933911, time: 0.6496219635009766
Validation Loss Energy: 5.291585514006711, Validation Loss Force: 4.226172769400491, time: 0.06017160415649414
Test Loss Energy: 7.627451815248549, Test Loss Force: 8.893118009145763, time: 10.161581754684448


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.452785564037976, Training Loss Force: 4.575915823471706, time: 0.6441669464111328
Validation Loss Energy: 5.474690138078612, Validation Loss Force: 4.787506878786239, time: 0.05977463722229004
Test Loss Energy: 7.506687290224336, Test Loss Force: 8.921004151009667, time: 9.57167911529541

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚
wandb:   test_error_force â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–ƒâ–â–‚â–â–ƒâ–â–‚â–‚â–â–‚â–‚
wandb:          test_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train_error_energy â–ˆâ–ƒâ–…â–„â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–†â–…â–‡â–ƒâ–…â–„â–„â–…
wandb:  train_error_force â–‡â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–‚â–ƒ
wandb:  valid_error_force â–†â–†â–…â–†â–†â–ˆâ–†â–…â–…â–„â–…â–‡â–‚â–„â–„â–…â–†â–†â–â–…
wandb:         valid_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1265
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.50669
wandb:   test_error_force 8.921
wandb:          test_loss 4.85679
wandb: train_error_energy 4.45279
wandb:  train_error_force 4.57592
wandb:         train_loss 1.88728
wandb: valid_error_energy 5.47469
wandb:  valid_error_force 4.78751
wandb:         valid_loss 2.23892
wandb: 
wandb: ğŸš€ View run al_73_41 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/gi8a1e5t
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_142356-gi8a1e5t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.8664391040802, Uncertainty Bias: -0.18247869610786438
4.7683716e-06 0.012765884
2.2194712 9.274131
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3660 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3281 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2706 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3344 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1323 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1282 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1653 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1912 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1557 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_150558-v9ezlhpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_42
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v9ezlhpk
Training model 42. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.260956975562179, Training Loss Force: 4.962144942789071, time: 0.7064599990844727
Validation Loss Energy: 3.3421286088699445, Validation Loss Force: 4.481886127918536, time: 0.06705212593078613
Test Loss Energy: 8.507833189572516, Test Loss Force: 9.016137848523869, time: 10.366524696350098


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.398716073413006, Training Loss Force: 4.6674982626431, time: 0.6787009239196777
Validation Loss Energy: 3.423410640553694, Validation Loss Force: 4.6652232185787845, time: 0.07101750373840332
Test Loss Energy: 8.596542348287075, Test Loss Force: 8.904614204973134, time: 10.477572441101074


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.37166350343539, Training Loss Force: 4.573444463154883, time: 0.7061061859130859
Validation Loss Energy: 3.8381471776806952, Validation Loss Force: 4.628814363858986, time: 0.07055068016052246
Test Loss Energy: 9.059497346281557, Test Loss Force: 8.869436858687811, time: 10.65578579902649


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.4398633999256205, Training Loss Force: 4.570576362087302, time: 0.6729145050048828
Validation Loss Energy: 4.4009234037900455, Validation Loss Force: 4.606375326016405, time: 0.07021546363830566
Test Loss Energy: 8.948004992991956, Test Loss Force: 8.896036560455, time: 10.590150833129883


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.476226078631282, Training Loss Force: 4.579393225256746, time: 0.6691873073577881
Validation Loss Energy: 3.9813979213415758, Validation Loss Force: 4.48649426589351, time: 0.06289958953857422
Test Loss Energy: 9.488472011360486, Test Loss Force: 8.923997141430453, time: 10.417287826538086


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.442057832192382, Training Loss Force: 4.6343990507737995, time: 0.6586763858795166
Validation Loss Energy: 3.7039231071920087, Validation Loss Force: 4.68343688670824, time: 0.0626213550567627
Test Loss Energy: 8.90678158949633, Test Loss Force: 8.857071917438892, time: 10.864604711532593


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.487119181284828, Training Loss Force: 4.585198777697405, time: 0.7049851417541504
Validation Loss Energy: 3.643036789933233, Validation Loss Force: 4.596666505915662, time: 0.06936836242675781
Test Loss Energy: 8.35082133589225, Test Loss Force: 8.818157562675554, time: 10.558047771453857


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.480233627819132, Training Loss Force: 4.568231644847225, time: 0.6762077808380127
Validation Loss Energy: 3.947136153861386, Validation Loss Force: 4.677428827812816, time: 0.06555986404418945
Test Loss Energy: 8.624930043658626, Test Loss Force: 8.861103105667086, time: 9.765461206436157


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.5035992977457635, Training Loss Force: 4.564043505415299, time: 0.6616389751434326
Validation Loss Energy: 4.08085899610259, Validation Loss Force: 4.340366080194379, time: 0.06830954551696777
Test Loss Energy: 8.926803080442202, Test Loss Force: 8.873037831473157, time: 10.987915992736816


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.468107483636554, Training Loss Force: 4.570583877170978, time: 0.7103662490844727
Validation Loss Energy: 3.9221085871973944, Validation Loss Force: 4.8486598423472635, time: 0.06857967376708984
Test Loss Energy: 8.606314441399471, Test Loss Force: 8.839274758358835, time: 9.411602973937988


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.563348972515508, Training Loss Force: 4.573317831211594, time: 0.6528546810150146
Validation Loss Energy: 3.816775393054546, Validation Loss Force: 4.661291772138283, time: 0.059037208557128906
Test Loss Energy: 8.745580221664468, Test Loss Force: 8.825752776932166, time: 9.133527040481567


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.414193900380834, Training Loss Force: 4.60475717819949, time: 0.6386163234710693
Validation Loss Energy: 4.303087925128878, Validation Loss Force: 4.407796309648253, time: 0.05990481376647949
Test Loss Energy: 8.38230309715554, Test Loss Force: 8.811813240727181, time: 9.68800163269043


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.385639802768117, Training Loss Force: 4.568431913477073, time: 0.683570384979248
Validation Loss Energy: 3.9935920631145922, Validation Loss Force: 4.836516357804946, time: 0.06266069412231445
Test Loss Energy: 9.509313050670537, Test Loss Force: 8.957440424345398, time: 8.988852262496948


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.4645638377806005, Training Loss Force: 4.600153894411896, time: 0.6290755271911621
Validation Loss Energy: 3.7962552065769977, Validation Loss Force: 4.866763957256922, time: 0.05843830108642578
Test Loss Energy: 8.34270949191126, Test Loss Force: 8.808730044820345, time: 9.140301704406738


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.405211705370539, Training Loss Force: 4.564548563572092, time: 0.672154426574707
Validation Loss Energy: 4.10767192397863, Validation Loss Force: 5.150126254959393, time: 0.06246018409729004
Test Loss Energy: 8.716035453472568, Test Loss Force: 8.824138847646342, time: 9.055760145187378


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.544947967266855, Training Loss Force: 4.551458022618315, time: 0.6595597267150879
Validation Loss Energy: 3.768998944431415, Validation Loss Force: 4.600929061376157, time: 0.060302734375
Test Loss Energy: 8.892847070924873, Test Loss Force: 8.861939390357223, time: 8.896732330322266


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.508833698260389, Training Loss Force: 4.589564885444214, time: 0.6297662258148193
Validation Loss Energy: 4.031986903946921, Validation Loss Force: 4.933016712267131, time: 0.059212446212768555
Test Loss Energy: 8.652379949852094, Test Loss Force: 8.86068897369826, time: 9.187901020050049


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.520047806321434, Training Loss Force: 4.56495539123516, time: 0.6609129905700684
Validation Loss Energy: 3.935935895821218, Validation Loss Force: 4.880046839818952, time: 0.0603635311126709
Test Loss Energy: 8.73631209294869, Test Loss Force: 8.847489100095375, time: 8.906551122665405


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.519726923381966, Training Loss Force: 4.56228643431824, time: 0.639981746673584
Validation Loss Energy: 3.728540183285482, Validation Loss Force: 4.765532996789501, time: 0.0589146614074707
Test Loss Energy: 8.461286303068995, Test Loss Force: 8.891062868525028, time: 8.944065570831299


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.517685203182211, Training Loss Force: 4.578621598731905, time: 0.6535491943359375
Validation Loss Energy: 3.961518353996862, Validation Loss Force: 4.680876636868362, time: 0.0597231388092041
Test Loss Energy: 8.66520416311869, Test Loss Force: 8.854310125208388, time: 8.965110301971436

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–…â–…â–ˆâ–„â–â–ƒâ–…â–ƒâ–ƒâ–â–ˆâ–â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒ
wandb:   test_error_force â–ˆâ–„â–ƒâ–„â–…â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–â–†â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒ
wandb:          test_loss â–â–„â–…â–…â–‡â–„â–‚â–‚â–…â–‚â–ƒâ–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–„â–ˆâ–…â–ƒâ–ƒâ–…â–†â–…â–„â–‡â–…â–„â–†â–„â–†â–…â–„â–…
wandb:  valid_error_force â–‚â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–â–…â–„â–‚â–…â–†â–ˆâ–ƒâ–†â–†â–…â–„
wandb:         valid_loss â–â–‚â–ƒâ–…â–ƒâ–„â–ƒâ–„â–‚â–…â–„â–„â–…â–…â–ˆâ–„â–†â–…â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1273
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.6652
wandb:   test_error_force 8.85431
wandb:          test_loss 5.07853
wandb: train_error_energy 4.51769
wandb:  train_error_force 4.57862
wandb:         train_loss 1.90508
wandb: valid_error_energy 3.96152
wandb:  valid_error_force 4.68088
wandb:         valid_loss 1.7939
wandb: 
wandb: ğŸš€ View run al_73_42 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v9ezlhpk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_150558-v9ezlhpk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6375443935394287, Uncertainty Bias: -0.19069066643714905
0.00040245056 0.1693039
2.3963249 8.769502
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3028 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3763 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_154906-svy01004
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_43
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svy01004
Training model 43. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.476967879222959, Training Loss Force: 5.0311960477568975, time: 0.6437749862670898
Validation Loss Energy: 6.427483620083509, Validation Loss Force: 4.391614052137097, time: 0.0635371208190918
Test Loss Energy: 9.933681532832907, Test Loss Force: 8.887903330909545, time: 10.130818605422974


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.402427723139562, Training Loss Force: 4.57670069881073, time: 0.6927070617675781
Validation Loss Energy: 5.998254772928371, Validation Loss Force: 4.741985066600201, time: 0.06598877906799316
Test Loss Energy: 9.833844689898456, Test Loss Force: 8.849462032666404, time: 10.040964126586914


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.374137112710587, Training Loss Force: 4.5542600800172135, time: 0.6654832363128662
Validation Loss Energy: 6.064872705337901, Validation Loss Force: 4.479846701210983, time: 0.07148623466491699
Test Loss Energy: 10.519512005987282, Test Loss Force: 8.950499498309242, time: 10.362935781478882


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.360296794641912, Training Loss Force: 4.546157283398388, time: 0.6802752017974854
Validation Loss Energy: 6.552603862540938, Validation Loss Force: 4.848287762204418, time: 0.06072282791137695
Test Loss Energy: 10.217785208039649, Test Loss Force: 8.835151378109385, time: 10.197885274887085


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.405026689577188, Training Loss Force: 4.591367169511354, time: 0.6944308280944824
Validation Loss Energy: 6.1442092766936796, Validation Loss Force: 4.784646248268505, time: 0.06979894638061523
Test Loss Energy: 10.07820906662267, Test Loss Force: 8.908819438866947, time: 10.686914443969727


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.488625248587139, Training Loss Force: 4.556973593030233, time: 0.6342113018035889
Validation Loss Energy: 6.07642500329778, Validation Loss Force: 4.468343167794061, time: 0.057851552963256836
Test Loss Energy: 10.531358372945668, Test Loss Force: 8.901331483521862, time: 10.076335906982422


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.380757979362518, Training Loss Force: 4.551730185548654, time: 0.663017749786377
Validation Loss Energy: 6.092815679129524, Validation Loss Force: 4.752352096696306, time: 0.06712937355041504
Test Loss Energy: 10.177944447038229, Test Loss Force: 8.870591478650132, time: 10.970616102218628


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.532171548460601, Training Loss Force: 4.581303726528807, time: 0.6567196846008301
Validation Loss Energy: 6.149426414782768, Validation Loss Force: 4.496993116124006, time: 0.05794548988342285
Test Loss Energy: 10.19870605758257, Test Loss Force: 8.867613541129932, time: 8.768532514572144


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.491738959289408, Training Loss Force: 4.565303278375301, time: 0.6575808525085449
Validation Loss Energy: 6.4466759191093175, Validation Loss Force: 5.098993625634265, time: 0.062381744384765625
Test Loss Energy: 10.458778947471583, Test Loss Force: 8.853550704508455, time: 8.970155715942383


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.387965406645381, Training Loss Force: 4.5529498836291165, time: 0.6554663181304932
Validation Loss Energy: 6.1295095503561114, Validation Loss Force: 5.094525323882933, time: 0.06327128410339355
Test Loss Energy: 10.442549164670359, Test Loss Force: 8.857960495569921, time: 8.78027606010437


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.547539780458168, Training Loss Force: 4.54342263908342, time: 0.6637873649597168
Validation Loss Energy: 5.7844088919079715, Validation Loss Force: 4.802076566342587, time: 0.05857491493225098
Test Loss Energy: 10.20063767861509, Test Loss Force: 8.8582106031505, time: 8.806766271591187


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.454370723420921, Training Loss Force: 4.560268829186988, time: 0.6433711051940918
Validation Loss Energy: 6.205631669921276, Validation Loss Force: 4.528307300784977, time: 0.05752730369567871
Test Loss Energy: 9.886529776669642, Test Loss Force: 8.843195992329605, time: 8.937861442565918


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.52923190101307, Training Loss Force: 4.555580463518735, time: 0.6464383602142334
Validation Loss Energy: 6.144686456673403, Validation Loss Force: 4.801700255485969, time: 0.06173563003540039
Test Loss Energy: 10.565596726940033, Test Loss Force: 8.879223295890112, time: 9.02547550201416


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.450395233023356, Training Loss Force: 4.567296935439908, time: 0.6749222278594971
Validation Loss Energy: 6.214825233618343, Validation Loss Force: 5.069925281979122, time: 0.05975079536437988
Test Loss Energy: 10.24765790842734, Test Loss Force: 8.882183755631067, time: 8.856651306152344


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.439792435268814, Training Loss Force: 4.5626720527451585, time: 0.6677894592285156
Validation Loss Energy: 6.515493822680613, Validation Loss Force: 4.853310955467403, time: 0.06066441535949707
Test Loss Energy: 10.264102899209393, Test Loss Force: 8.836212826772533, time: 9.042688608169556


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.388213872011865, Training Loss Force: 4.595129498735522, time: 0.699800968170166
Validation Loss Energy: 5.799382501295032, Validation Loss Force: 4.703654799820191, time: 0.061615943908691406
Test Loss Energy: 10.248889993936306, Test Loss Force: 8.86511798192308, time: 8.872473239898682


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.5514438497271765, Training Loss Force: 4.5657583695757475, time: 0.6649227142333984
Validation Loss Energy: 5.7198125726743205, Validation Loss Force: 4.811887368912165, time: 0.058982133865356445
Test Loss Energy: 9.663678676241227, Test Loss Force: 8.87886329001085, time: 8.822917222976685


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.380520725387532, Training Loss Force: 4.544486006723256, time: 0.6250977516174316
Validation Loss Energy: 5.590174150576871, Validation Loss Force: 4.525199730184409, time: 0.05977773666381836
Test Loss Energy: 10.045084506027848, Test Loss Force: 8.906180228915794, time: 9.044050931930542


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.553982684361944, Training Loss Force: 4.542445388735771, time: 0.6756980419158936
Validation Loss Energy: 6.184706782271004, Validation Loss Force: 4.762875440532854, time: 0.05780196189880371
Test Loss Energy: 10.279388900584314, Test Loss Force: 8.882894039895593, time: 8.836073160171509


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.525296140357867, Training Loss Force: 4.557149017350122, time: 0.660024881362915
Validation Loss Energy: 6.251584569573831, Validation Loss Force: 4.619676022110109, time: 0.05748248100280762
Test Loss Energy: 10.173826406185055, Test Loss Force: 8.8035784274189, time: 10.779566049575806

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ˆâ–…â–„â–ˆâ–…â–…â–‡â–‡â–…â–ƒâ–ˆâ–†â–†â–†â–â–„â–†â–…
wandb:   test_error_force â–…â–ƒâ–ˆâ–ƒâ–†â–†â–„â–„â–ƒâ–„â–„â–ƒâ–…â–…â–ƒâ–„â–…â–†â–…â–
wandb:          test_loss â–„â–‚â–ˆâ–†â–„â–‡â–„â–…â–†â–‡â–ƒâ–‚â–‡â–†â–†â–†â–â–…â–„â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–„â–„â–ˆâ–…â–…â–…â–…â–‡â–…â–‚â–…â–…â–†â–ˆâ–ƒâ–‚â–â–…â–†
wandb:  valid_error_force â–â–„â–‚â–†â–…â–‚â–…â–‚â–ˆâ–ˆâ–…â–‚â–…â–ˆâ–†â–„â–…â–‚â–…â–ƒ
wandb:         valid_loss â–„â–…â–‚â–‡â–…â–‚â–…â–…â–ˆâ–‡â–ƒâ–„â–†â–‡â–ˆâ–ƒâ–ƒâ–â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1274
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.17383
wandb:   test_error_force 8.80358
wandb:          test_loss 5.6733
wandb: train_error_energy 4.5253
wandb:  train_error_force 4.55715
wandb:         train_loss 1.90431
wandb: valid_error_energy 6.25158
wandb:  valid_error_force 4.61968
wandb:         valid_loss 2.347
wandb: 
wandb: ğŸš€ View run al_73_43 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svy01004
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_154906-svy01004/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6835432052612305, Uncertainty Bias: -0.20429280400276184
0.00010681152 0.23382568
2.4488306 8.730128
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3340 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2961 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2531 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2509 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_163158-6zcmjoyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_44
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6zcmjoyi
Training model 44. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.432737915487392, Training Loss Force: 4.867135391659245, time: 0.6571457386016846
Validation Loss Energy: 1.6284669174769757, Validation Loss Force: 4.729283127839896, time: 0.05894184112548828
Test Loss Energy: 6.534897470865924, Test Loss Force: 8.980107238734579, time: 9.285882472991943


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1965191114627003, Training Loss Force: 4.7602810555129045, time: 0.6488316059112549
Validation Loss Energy: 6.35762696494646, Validation Loss Force: 5.106213004683536, time: 0.06083822250366211
Test Loss Energy: 7.916669941928086, Test Loss Force: 9.066380373676544, time: 9.241744756698608


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.755873920377026, Training Loss Force: 5.057149584064229, time: 0.6756742000579834
Validation Loss Energy: 2.2170281750174774, Validation Loss Force: 5.430481405846109, time: 0.05878281593322754
Test Loss Energy: 7.355909403197397, Test Loss Force: 9.388689364464025, time: 9.506455659866333


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.36602610795037, Training Loss Force: 4.893801090695997, time: 0.6385998725891113
Validation Loss Energy: 2.3734087162025626, Validation Loss Force: 5.195748936268538, time: 0.06250286102294922
Test Loss Energy: 7.692244484368242, Test Loss Force: 8.883805952820465, time: 9.275370597839355


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9663864130669464, Training Loss Force: 4.742041023356572, time: 0.6421489715576172
Validation Loss Energy: 3.3283027475955693, Validation Loss Force: 4.597894971593745, time: 0.060384273529052734
Test Loss Energy: 8.682249288052263, Test Loss Force: 8.870840704880584, time: 9.55450701713562


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.085199560316064, Training Loss Force: 4.557259700615835, time: 0.6370179653167725
Validation Loss Energy: 2.4101816349759533, Validation Loss Force: 4.463813409358452, time: 0.06343197822570801
Test Loss Energy: 6.737676810748612, Test Loss Force: 8.801519243779325, time: 9.535232305526733


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.056453510766101, Training Loss Force: 4.5018946819327565, time: 0.6631104946136475
Validation Loss Energy: 2.680799352776674, Validation Loss Force: 4.5831453673674885, time: 0.06444931030273438
Test Loss Energy: 6.912852985111852, Test Loss Force: 8.855065092525402, time: 9.417311906814575


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.981486337093762, Training Loss Force: 4.507597812133018, time: 0.6414620876312256
Validation Loss Energy: 3.800686433915534, Validation Loss Force: 5.042047772916401, time: 0.05974888801574707
Test Loss Energy: 9.148435502142693, Test Loss Force: 8.862782795796804, time: 9.429985284805298


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0726545977369097, Training Loss Force: 4.5029251780399235, time: 0.6466019153594971
Validation Loss Energy: 2.3285592535026525, Validation Loss Force: 4.524097740581212, time: 0.058945655822753906
Test Loss Energy: 6.9568992364846345, Test Loss Force: 8.883711667009754, time: 9.574905633926392


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.945519096524354, Training Loss Force: 4.516062190044457, time: 0.6827535629272461
Validation Loss Energy: 2.540213958792549, Validation Loss Force: 4.565949074565777, time: 0.06121349334716797
Test Loss Energy: 6.766780756985154, Test Loss Force: 8.831771899336465, time: 9.384284019470215


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9883975698787126, Training Loss Force: 4.51935784927259, time: 0.655461311340332
Validation Loss Energy: 3.2353915970965943, Validation Loss Force: 4.795327909867807, time: 0.06112980842590332
Test Loss Energy: 8.77741674267531, Test Loss Force: 8.85051555850486, time: 9.443481206893921


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.052070160077304, Training Loss Force: 4.49791606860042, time: 0.6257574558258057
Validation Loss Energy: 2.2118691535754764, Validation Loss Force: 4.675884839954953, time: 0.0657358169555664
Test Loss Energy: 6.83871148078615, Test Loss Force: 8.86178334941563, time: 9.629729270935059


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9863745093533853, Training Loss Force: 4.516758732533291, time: 0.6175618171691895
Validation Loss Energy: 2.4864174271401147, Validation Loss Force: 4.539375516021609, time: 0.06161952018737793
Test Loss Energy: 6.727498326626174, Test Loss Force: 8.823965482812035, time: 9.44118070602417


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0324700369440007, Training Loss Force: 4.539404841548128, time: 0.751558780670166
Validation Loss Energy: 3.5353644564124136, Validation Loss Force: 4.724832639620237, time: 0.061527252197265625
Test Loss Energy: 8.421397314961668, Test Loss Force: 8.859217319504417, time: 10.154902458190918


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1242259131131584, Training Loss Force: 4.513666047365129, time: 0.6691734790802002
Validation Loss Energy: 2.313654226212538, Validation Loss Force: 4.567955100901441, time: 0.06066489219665527
Test Loss Energy: 6.8984036717963075, Test Loss Force: 8.85860999465503, time: 9.635142087936401


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0514142769745165, Training Loss Force: 4.504902825192939, time: 0.6319451332092285
Validation Loss Energy: 2.193769714717882, Validation Loss Force: 4.512754974287651, time: 0.06103157997131348
Test Loss Energy: 6.824631926491622, Test Loss Force: 8.839459683335818, time: 9.447023153305054


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0501731191551147, Training Loss Force: 4.531747127151641, time: 0.6582565307617188
Validation Loss Energy: 3.9622778784536212, Validation Loss Force: 4.672375574215131, time: 0.059265851974487305
Test Loss Energy: 8.710660705265601, Test Loss Force: 8.856211122821405, time: 9.449537754058838


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0712414057353645, Training Loss Force: 4.526264934844699, time: 0.6942470073699951
Validation Loss Energy: 2.160881259195202, Validation Loss Force: 4.615151385064857, time: 0.05957341194152832
Test Loss Energy: 6.940411043225045, Test Loss Force: 8.851190108451789, time: 9.56287956237793


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0335962028497163, Training Loss Force: 4.509393605394554, time: 0.6745476722717285
Validation Loss Energy: 2.713711522563395, Validation Loss Force: 4.768137557789419, time: 0.05933523178100586
Test Loss Energy: 6.868828434071434, Test Loss Force: 8.84590043151664, time: 9.406074523925781


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.022535491563301, Training Loss Force: 4.507276055217152, time: 0.681002140045166
Validation Loss Energy: 4.25302433037335, Validation Loss Force: 5.074739388914081, time: 0.05971670150756836
Test Loss Energy: 9.151175927461644, Test Loss Force: 8.830915716651653, time: 9.413270235061646

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–ƒâ–„â–‡â–‚â–‚â–ˆâ–‚â–‚â–‡â–‚â–‚â–†â–‚â–‚â–‡â–‚â–‚â–ˆ
wandb:   test_error_force â–ƒâ–„â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–
wandb:          test_loss â–â–ˆâ–†â–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–…â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:  train_error_force â–†â–„â–ˆâ–†â–„â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–…â–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–„â–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–„â–‚â–ƒâ–…
wandb:  valid_error_force â–ƒâ–†â–ˆâ–†â–‚â–â–‚â–…â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–…
wandb:         valid_loss â–â–ˆâ–‚â–‚â–‚â–â–â–ƒâ–â–â–‚â–â–â–‚â–â–â–‚â–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1277
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.15118
wandb:   test_error_force 8.83092
wandb:          test_loss 6.45955
wandb: train_error_energy 3.02254
wandb:  train_error_force 4.50728
wandb:         train_loss 1.48307
wandb: valid_error_energy 4.25302
wandb:  valid_error_force 5.07474
wandb:         valid_loss 2.22891
wandb: 
wandb: ğŸš€ View run al_73_44 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6zcmjoyi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_163158-6zcmjoyi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.399686813354492, Uncertainty Bias: -0.03245404362678528
0.00022888184 0.10889053
2.62622 8.836787
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1824 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1483 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2161 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3077 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3691 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_171437-3hvdnjqq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_45
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3hvdnjqq
Training model 45. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.419411579528791, Training Loss Force: 4.8847897252129435, time: 0.7886378765106201
Validation Loss Energy: 3.169825219728709, Validation Loss Force: 5.077157353169712, time: 0.07856154441833496
Test Loss Energy: 8.019656788507993, Test Loss Force: 9.091113921471733, time: 9.413946151733398


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.135157206771755, Training Loss Force: 4.982482853118406, time: 0.6567935943603516
Validation Loss Energy: 4.79075539895618, Validation Loss Force: 5.010067807509106, time: 0.06423306465148926
Test Loss Energy: 8.986640407434837, Test Loss Force: 9.092266592204671, time: 9.31846284866333


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1062044900567343, Training Loss Force: 5.088071861524196, time: 0.6765122413635254
Validation Loss Energy: 3.948857943032272, Validation Loss Force: 4.4461532967257735, time: 0.06291055679321289
Test Loss Energy: 9.398267014950711, Test Loss Force: 8.96967430556612, time: 9.541955709457397


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.402182352614709, Training Loss Force: 4.871458556031975, time: 0.6707837581634521
Validation Loss Energy: 2.37352205479784, Validation Loss Force: 4.548671062187511, time: 0.06676697731018066
Test Loss Energy: 7.282328789626413, Test Loss Force: 8.934995910707118, time: 9.245082139968872


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9654658345287537, Training Loss Force: 4.946045681400391, time: 0.674067497253418
Validation Loss Energy: 5.521601183066095, Validation Loss Force: 5.062080202629795, time: 0.06070303916931152
Test Loss Energy: 7.477922281402106, Test Loss Force: 9.047183285515388, time: 9.306438684463501


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.453177221143513, Training Loss Force: 4.708561499103173, time: 0.6928629875183105
Validation Loss Energy: 2.4884930375838805, Validation Loss Force: 4.9523869239405345, time: 0.06207394599914551
Test Loss Energy: 7.0059733618356965, Test Loss Force: 8.882214495631274, time: 9.492799758911133


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.299611440632101, Training Loss Force: 4.568798718261994, time: 0.6965718269348145
Validation Loss Energy: 3.971709252798539, Validation Loss Force: 4.8919560764197545, time: 0.06227564811706543
Test Loss Energy: 9.353775667773936, Test Loss Force: 8.873595273770627, time: 9.316978454589844


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.339573378034875, Training Loss Force: 4.518608549674393, time: 0.6584477424621582
Validation Loss Energy: 6.437916782915956, Validation Loss Force: 4.732358411414305, time: 0.0605311393737793
Test Loss Energy: 11.227411178519377, Test Loss Force: 8.821990283912108, time: 10.1061851978302


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.473054939248125, Training Loss Force: 4.514913827690787, time: 0.6728782653808594
Validation Loss Energy: 5.411587483475845, Validation Loss Force: 4.581047824012849, time: 0.06193208694458008
Test Loss Energy: 10.02055772577047, Test Loss Force: 8.860649527451024, time: 9.594634294509888


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.44738575415562, Training Loss Force: 4.592023734742063, time: 0.6746599674224854
Validation Loss Energy: 2.9577461070466735, Validation Loss Force: 4.398634364969908, time: 0.06378316879272461
Test Loss Energy: 8.286935333565724, Test Loss Force: 8.802310355778017, time: 9.358916521072388


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.396158843455533, Training Loss Force: 4.5223895260817955, time: 0.6627776622772217
Validation Loss Energy: 3.136753173495211, Validation Loss Force: 4.699956042637185, time: 0.0594632625579834
Test Loss Energy: 6.905956543940983, Test Loss Force: 8.827143118416112, time: 9.376704931259155


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.546072621873629, Training Loss Force: 4.564568971199317, time: 0.6645846366882324
Validation Loss Energy: 5.520116425201049, Validation Loss Force: 4.659536471260934, time: 0.06058907508850098
Test Loss Energy: 7.638468799094514, Test Loss Force: 8.847148050238692, time: 9.583094596862793


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.499386146866247, Training Loss Force: 4.5412872446894506, time: 0.651298999786377
Validation Loss Energy: 5.140177842857631, Validation Loss Force: 4.445659193890959, time: 0.05982565879821777
Test Loss Energy: 7.321492848601093, Test Loss Force: 8.78065414687506, time: 9.319396734237671


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.361267620170056, Training Loss Force: 4.520741052084944, time: 0.6645667552947998
Validation Loss Energy: 2.292148951433405, Validation Loss Force: 4.888013051183665, time: 0.06262373924255371
Test Loss Energy: 6.7983127831850725, Test Loss Force: 8.805703264648118, time: 9.31683349609375


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.322120947828412, Training Loss Force: 4.505631674259369, time: 0.6529839038848877
Validation Loss Energy: 4.105523166720427, Validation Loss Force: 4.273302364154701, time: 0.06106925010681152
Test Loss Energy: 9.028413153200574, Test Loss Force: 8.78924270334715, time: 9.508482694625854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.594072345194146, Training Loss Force: 4.60183700296511, time: 0.6492011547088623
Validation Loss Energy: 5.958610312849096, Validation Loss Force: 4.748999367366071, time: 0.06650829315185547
Test Loss Energy: 10.383333268792375, Test Loss Force: 8.880645813648547, time: 9.416707754135132


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.3960956542966825, Training Loss Force: 4.67823807809153, time: 0.6918251514434814
Validation Loss Energy: 5.297575536701315, Validation Loss Force: 4.880393535679162, time: 0.06473183631896973
Test Loss Energy: 9.635778591325046, Test Loss Force: 8.910404400179274, time: 9.40950632095337


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.473001148356519, Training Loss Force: 4.570116615472419, time: 0.6549110412597656
Validation Loss Energy: 2.8447863833212255, Validation Loss Force: 4.536971134583881, time: 0.05953574180603027
Test Loss Energy: 8.402716956784296, Test Loss Force: 8.912671526490163, time: 9.60335111618042


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.430656154159954, Training Loss Force: 4.632290821200989, time: 0.6518793106079102
Validation Loss Energy: 3.3897238048082903, Validation Loss Force: 4.9785396377988995, time: 0.06042957305908203
Test Loss Energy: 6.935941504552434, Test Loss Force: 8.829227539446634, time: 9.36109733581543


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.4952896808647935, Training Loss Force: 4.608529497936522, time: 0.6783552169799805
Validation Loss Energy: 4.876530225997316, Validation Loss Force: 4.448673243450238, time: 0.06488752365112305
Test Loss Energy: 7.293312939682712, Test Loss Force: 8.838018969660997, time: 9.368351459503174

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–…â–‚â–‚â–â–…â–ˆâ–†â–ƒâ–â–‚â–‚â–â–…â–‡â–…â–„â–â–‚
wandb:   test_error_force â–ˆâ–ˆâ–…â–„â–‡â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–â–‚â–â–ƒâ–„â–„â–‚â–‚
wandb:          test_loss â–…â–…â–ˆâ–„â–†â–‚â–„â–…â–„â–‚â–â–‚â–â–â–ƒâ–„â–ƒâ–ƒâ–â–
wandb: train_error_energy â–‡â–†â–‚â–ƒâ–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:  train_error_force â–†â–‡â–ˆâ–…â–†â–ƒâ–‚â–â–â–‚â–â–‚â–â–â–â–‚â–ƒâ–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–…â–â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–…â–„â–â–†â–â–„â–ˆâ–†â–‚â–‚â–†â–†â–â–„â–‡â–†â–‚â–ƒâ–…
wandb:  valid_error_force â–ˆâ–‡â–ƒâ–ƒâ–ˆâ–‡â–†â–…â–„â–‚â–…â–„â–ƒâ–†â–â–…â–†â–ƒâ–‡â–ƒ
wandb:         valid_loss â–‚â–„â–ƒâ–â–ˆâ–‚â–‚â–„â–ƒâ–â–‚â–„â–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1281
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.29331
wandb:   test_error_force 8.83802
wandb:          test_loss 4.67781
wandb: train_error_energy 4.49529
wandb:  train_error_force 4.60853
wandb:         train_loss 1.90698
wandb: valid_error_energy 4.87653
wandb:  valid_error_force 4.44867
wandb:         valid_loss 1.99173
wandb: 
wandb: ğŸš€ View run al_73_45 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3hvdnjqq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_171437-3hvdnjqq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8079447746276855, Uncertainty Bias: -0.008988380432128906
0.00062561035 0.10303497
3.0136163 18.561825
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2547 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1350 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1746 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2794 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_175650-g23huq6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_46
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g23huq6d
Training model 46. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.386323382438375, Training Loss Force: 4.837747397755595, time: 0.6815104484558105
Validation Loss Energy: 4.170413854564995, Validation Loss Force: 4.729087401660625, time: 0.06146574020385742
Test Loss Energy: 8.909743047168115, Test Loss Force: 8.860114599219239, time: 10.12933611869812


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9630081129686663, Training Loss Force: 4.597337185383197, time: 0.6844320297241211
Validation Loss Energy: 2.359613471935752, Validation Loss Force: 4.649928074945004, time: 0.06360507011413574
Test Loss Energy: 7.536946793732067, Test Loss Force: 8.840600122421222, time: 9.355521440505981


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.13356990704953, Training Loss Force: 4.896579415637156, time: 0.6494238376617432
Validation Loss Energy: 4.9808215512063665, Validation Loss Force: 5.054233787265591, time: 0.06379175186157227
Test Loss Energy: 10.414773410744099, Test Loss Force: 9.27142261498538, time: 9.57082986831665


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.295533086864834, Training Loss Force: 4.861695448107263, time: 0.6641280651092529
Validation Loss Energy: 2.5503274800660165, Validation Loss Force: 4.833366034728359, time: 0.06386446952819824
Test Loss Energy: 6.690290794985758, Test Loss Force: 8.853657613677871, time: 9.42908525466919


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0621084691442313, Training Loss Force: 4.595117662784226, time: 0.6748647689819336
Validation Loss Energy: 3.3918659933266886, Validation Loss Force: 4.9392946461674185, time: 0.06300854682922363
Test Loss Energy: 7.070584008837953, Test Loss Force: 8.91657000857061, time: 9.59281325340271


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.238718898696555, Training Loss Force: 5.266572996518412, time: 0.6859641075134277
Validation Loss Energy: 4.305802039348592, Validation Loss Force: 4.766499380882828, time: 0.06951785087585449
Test Loss Energy: 9.070535883568201, Test Loss Force: 9.046015608514143, time: 10.270296096801758


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9395435832364245, Training Loss Force: 4.672894605132378, time: 0.7092790603637695
Validation Loss Energy: 3.3758098778867005, Validation Loss Force: 4.8977091791430905, time: 0.06802821159362793
Test Loss Energy: 8.162223849872444, Test Loss Force: 8.86888255007968, time: 10.229782104492188


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1082348470698062, Training Loss Force: 4.734041366543046, time: 0.6363828182220459
Validation Loss Energy: 2.4506115604674887, Validation Loss Force: 4.8399937818569, time: 0.06428146362304688
Test Loss Energy: 6.7925950452184995, Test Loss Force: 8.984769510959769, time: 10.369446992874146


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.747189180457136, Training Loss Force: 5.173213699923961, time: 0.6595938205718994
Validation Loss Energy: 4.830926026227283, Validation Loss Force: 5.117957243447206, time: 0.06655573844909668
Test Loss Energy: 10.162730902902878, Test Loss Force: 9.090185925072841, time: 10.269824981689453


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.403772922574302, Training Loss Force: 4.662226787036808, time: 0.6474854946136475
Validation Loss Energy: 2.92489773197026, Validation Loss Force: 5.031808109571767, time: 0.06436944007873535
Test Loss Energy: 8.17331930185911, Test Loss Force: 8.869166596635006, time: 10.342333555221558


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.361841267484038, Training Loss Force: 4.5612617424082185, time: 0.6446373462677002
Validation Loss Energy: 3.2743482321840984, Validation Loss Force: 4.9523450621411005, time: 0.062072038650512695
Test Loss Energy: 6.990386437682643, Test Loss Force: 8.767764415252438, time: 10.28488802909851


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.292053055954586, Training Loss Force: 4.559716907321409, time: 0.796621561050415
Validation Loss Energy: 5.257568125914178, Validation Loss Force: 4.723585247064749, time: 0.09469723701477051
Test Loss Energy: 7.375483061024337, Test Loss Force: 8.754495679758922, time: 10.267006397247314


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.307682455846656, Training Loss Force: 4.511922528401077, time: 0.6889915466308594
Validation Loss Energy: 5.014242853995253, Validation Loss Force: 4.882157520653202, time: 0.06355643272399902
Test Loss Energy: 7.321481593899864, Test Loss Force: 8.725540926513377, time: 10.356464385986328


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.411818138038182, Training Loss Force: 4.535620206306491, time: 0.7404499053955078
Validation Loss Energy: 1.7483646221185278, Validation Loss Force: 4.5998938725167395, time: 0.06709909439086914
Test Loss Energy: 6.783315932268729, Test Loss Force: 8.789422298254314, time: 10.430262804031372


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.29459437891706, Training Loss Force: 4.533270558031024, time: 0.7140648365020752
Validation Loss Energy: 3.923906751885334, Validation Loss Force: 4.98634085132648, time: 0.06443047523498535
Test Loss Energy: 8.895689317831286, Test Loss Force: 8.761197969755836, time: 10.211437225341797


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.333455858245886, Training Loss Force: 4.530367929939986, time: 0.7123098373413086
Validation Loss Energy: 6.665580843125196, Validation Loss Force: 4.811618607253029, time: 0.06623077392578125
Test Loss Energy: 10.428738729937729, Test Loss Force: 8.79317574927492, time: 10.244734048843384


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.454588709997639, Training Loss Force: 4.486243225439819, time: 0.6787052154541016
Validation Loss Energy: 5.428527484090593, Validation Loss Force: 4.941949975732607, time: 0.06731557846069336
Test Loss Energy: 9.917994251346043, Test Loss Force: 8.780257026362658, time: 11.22132134437561


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.488628489916725, Training Loss Force: 4.516964768022471, time: 0.6658601760864258
Validation Loss Energy: 2.9152685160891862, Validation Loss Force: 4.903243175426834, time: 0.06135749816894531
Test Loss Energy: 8.130759883487917, Test Loss Force: 8.74328850615135, time: 10.245429277420044


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.396476983355516, Training Loss Force: 4.549135984502298, time: 0.6540937423706055
Validation Loss Energy: 3.2631239258761706, Validation Loss Force: 5.140797531090749, time: 0.06429553031921387
Test Loss Energy: 6.893135042341579, Test Loss Force: 8.75046790501376, time: 10.377723455429077


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.261026562545632, Training Loss Force: 4.53632147291134, time: 0.7059540748596191
Validation Loss Energy: 5.685654903019852, Validation Loss Force: 4.819315166282024, time: 0.06674766540527344
Test Loss Energy: 7.530814760583678, Test Loss Force: 8.794608488829539, time: 10.361132144927979

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–ˆâ–â–‚â–…â–„â–â–ˆâ–„â–‚â–‚â–‚â–â–…â–ˆâ–‡â–„â–â–ƒ
wandb:   test_error_force â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–…â–ƒâ–„â–†â–ƒâ–‚â–â–â–‚â–â–‚â–‚â–â–â–‚
wandb:          test_loss â–ƒâ–„â–ˆâ–ƒâ–„â–†â–…â–„â–‡â–ƒâ–â–‚â–‚â–â–ƒâ–…â–„â–‚â–â–‚
wandb: train_error_energy â–ˆâ–â–„â–…â–â–‚â–â–â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–„â–‚â–…â–„â–‚â–ˆâ–ƒâ–ƒâ–‡â–ƒâ–‚â–‚â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–ˆâ–‡â–â–„â–â–‚â–†â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–„â–‚â–†â–‚â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–ƒâ–†â–†â–â–„â–ˆâ–†â–ƒâ–ƒâ–‡
wandb:  valid_error_force â–ƒâ–‚â–‡â–„â–…â–ƒâ–…â–„â–ˆâ–‡â–†â–ƒâ–…â–â–†â–„â–…â–…â–ˆâ–„
wandb:         valid_loss â–„â–â–‡â–‚â–„â–…â–ƒâ–‚â–‡â–ƒâ–ƒâ–†â–†â–â–„â–ˆâ–†â–ƒâ–„â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1284
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.53081
wandb:   test_error_force 8.79461
wandb:          test_loss 4.76974
wandb: train_error_energy 4.26103
wandb:  train_error_force 4.53632
wandb:         train_loss 1.84704
wandb: valid_error_energy 5.68565
wandb:  valid_error_force 4.81932
wandb:         valid_loss 2.36709
wandb: 
wandb: ğŸš€ View run al_73_46 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g23huq6d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_175650-g23huq6d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0817859172821045, Uncertainty Bias: -0.050750017166137695
1.1444092e-05 0.073369026
2.878483 16.71957
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2632 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3166 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3760 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3353 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 887 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3917 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2928 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3353 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_183923-q1raoo8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_47
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q1raoo8q
Training model 47. Added 8 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.166365774544853, Training Loss Force: 4.897334426970494, time: 0.7474148273468018
Validation Loss Energy: 6.204711378341156, Validation Loss Force: 5.164082489018709, time: 0.07018542289733887
Test Loss Energy: 10.60429779963579, Test Loss Force: 8.899266839242081, time: 10.907039880752563


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.47068654331676, Training Loss Force: 4.586924035619109, time: 0.7029626369476318
Validation Loss Energy: 5.451335484707977, Validation Loss Force: 4.693679667420918, time: 0.0681304931640625
Test Loss Energy: 10.096108387705849, Test Loss Force: 8.791751496795598, time: 9.255018711090088


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.409935904885744, Training Loss Force: 4.549121994362788, time: 0.6705193519592285
Validation Loss Energy: 2.6525768178723377, Validation Loss Force: 4.480438778470004, time: 0.05835556983947754
Test Loss Energy: 8.122099268482268, Test Loss Force: 8.762876927758729, time: 9.030318021774292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.29794093596719, Training Loss Force: 4.542545303640122, time: 0.6499922275543213
Validation Loss Energy: 3.383267178918395, Validation Loss Force: 4.801129777134102, time: 0.06061434745788574
Test Loss Energy: 6.975764939329524, Test Loss Force: 8.686946259358393, time: 8.939175367355347


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.493634086886228, Training Loss Force: 4.549758285024664, time: 0.6827812194824219
Validation Loss Energy: 5.610753455712663, Validation Loss Force: 4.36810085833456, time: 0.06640434265136719
Test Loss Energy: 7.7197173569605315, Test Loss Force: 8.789651673122375, time: 8.886195182800293


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.647723107304841, Training Loss Force: 4.556859508221769, time: 0.6421713829040527
Validation Loss Energy: 5.2778160993608285, Validation Loss Force: 4.596635554904378, time: 0.058564186096191406
Test Loss Energy: 7.542870595088993, Test Loss Force: 8.787257436537567, time: 9.061777353286743


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.435360045298633, Training Loss Force: 4.5413176526052546, time: 0.6548211574554443
Validation Loss Energy: 2.0353771351301932, Validation Loss Force: 4.511510476431059, time: 0.06084394454956055
Test Loss Energy: 6.623126195833293, Test Loss Force: 8.770922451308445, time: 8.857561588287354


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.445185256191238, Training Loss Force: 4.527152370234597, time: 0.679114818572998
Validation Loss Energy: 4.1490042161840375, Validation Loss Force: 4.809540436114086, time: 0.06399250030517578
Test Loss Energy: 9.099649741496256, Test Loss Force: 8.804963266293585, time: 8.835441827774048


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.379568585466625, Training Loss Force: 4.564779969223425, time: 0.6646218299865723
Validation Loss Energy: 6.90397399346182, Validation Loss Force: 4.719817685115651, time: 0.06150364875793457
Test Loss Energy: 11.362765447644371, Test Loss Force: 8.861361583742262, time: 9.065033674240112


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.388685279429753, Training Loss Force: 4.555131150311078, time: 0.6863813400268555
Validation Loss Energy: 5.152786037907501, Validation Loss Force: 4.5506833232592605, time: 0.06099748611450195
Test Loss Energy: 9.408022427695885, Test Loss Force: 8.773523548695625, time: 8.957981824874878


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.529638688487072, Training Loss Force: 4.5622520444263905, time: 0.6582167148590088
Validation Loss Energy: 2.9444818173583283, Validation Loss Force: 4.878429371142934, time: 0.05931496620178223
Test Loss Energy: 8.340217122352486, Test Loss Force: 8.851340180461303, time: 8.89463210105896


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.438089849546702, Training Loss Force: 4.58460460517603, time: 0.6784176826477051
Validation Loss Energy: 3.5679938363838066, Validation Loss Force: 4.996261875123292, time: 0.059841156005859375
Test Loss Energy: 7.147704215453273, Test Loss Force: 8.783858092412567, time: 9.954588413238525


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.524495031216141, Training Loss Force: 4.538788983767416, time: 0.6737511157989502
Validation Loss Energy: 5.591180615116464, Validation Loss Force: 5.328547033546704, time: 0.0646204948425293
Test Loss Energy: 7.662050025898877, Test Loss Force: 8.739857680572863, time: 8.922354221343994


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.536373447148573, Training Loss Force: 4.54703152211127, time: 0.6781346797943115
Validation Loss Energy: 5.521581365512107, Validation Loss Force: 4.819639595227641, time: 0.058367252349853516
Test Loss Energy: 7.401607171806809, Test Loss Force: 8.719987096354346, time: 10.2533597946167


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4584565328029075, Training Loss Force: 4.526714868810488, time: 0.6927914619445801
Validation Loss Energy: 2.269304321741517, Validation Loss Force: 5.234542577541223, time: 0.06649422645568848
Test Loss Energy: 6.736873322542312, Test Loss Force: 8.80650535854919, time: 10.986794233322144


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.440761754385877, Training Loss Force: 4.568055540979119, time: 0.6839425563812256
Validation Loss Energy: 3.407804984795918, Validation Loss Force: 4.619292363171676, time: 0.0687413215637207
Test Loss Energy: 8.74404446207274, Test Loss Force: 8.829929131453818, time: 10.21739149093628


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.499424809833317, Training Loss Force: 4.771550755370161, time: 0.678152322769165
Validation Loss Energy: 5.828907316699327, Validation Loss Force: 4.961420833859971, time: 0.06375789642333984
Test Loss Energy: 10.21448088185219, Test Loss Force: 9.03658810464862, time: 9.603386640548706


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.576421057862983, Training Loss Force: 4.617810755260401, time: 0.672243595123291
Validation Loss Energy: 5.33830595420528, Validation Loss Force: 4.601530268070162, time: 0.06143021583557129
Test Loss Energy: 9.999093833061172, Test Loss Force: 8.782335301258428, time: 9.78425121307373


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4490400094038325, Training Loss Force: 4.587055529896212, time: 0.6549699306488037
Validation Loss Energy: 2.863943389287404, Validation Loss Force: 4.528396368443348, time: 0.061972856521606445
Test Loss Energy: 8.34397401949872, Test Loss Force: 8.710933821214056, time: 9.44177770614624


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.2981353940185185, Training Loss Force: 4.545161057837838, time: 0.6655945777893066
Validation Loss Energy: 3.706952632256929, Validation Loss Force: 4.4991127037240926, time: 0.06072092056274414
Test Loss Energy: 6.902783030630624, Test Loss Force: 8.773666770422931, time: 9.45262861251831

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–ƒâ–‚â–ƒâ–‚â–â–…â–ˆâ–…â–„â–‚â–ƒâ–‚â–â–„â–†â–†â–„â–
wandb:   test_error_force â–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–„â–ˆâ–ƒâ–â–ƒ
wandb:          test_loss â–†â–…â–ƒâ–â–ƒâ–‚â–â–„â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–„â–†â–…â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–†â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–‚â–â–
wandb: valid_error_energy â–‡â–†â–‚â–ƒâ–†â–†â–â–„â–ˆâ–…â–‚â–ƒâ–†â–†â–â–ƒâ–†â–†â–‚â–ƒ
wandb:  valid_error_force â–‡â–ƒâ–‚â–„â–â–ƒâ–‚â–„â–„â–‚â–…â–†â–ˆâ–„â–‡â–ƒâ–…â–ƒâ–‚â–‚
wandb:         valid_loss â–‡â–…â–â–ƒâ–†â–…â–â–„â–ˆâ–…â–ƒâ–„â–‡â–†â–ƒâ–ƒâ–†â–…â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1291
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.90278
wandb:   test_error_force 8.77367
wandb:          test_loss 4.60277
wandb: train_error_energy 4.29814
wandb:  train_error_force 4.54516
wandb:         train_loss 1.85165
wandb: valid_error_energy 3.70695
wandb:  valid_error_force 4.49911
wandb:         valid_loss 1.62927
wandb: 
wandb: ğŸš€ View run al_73_47 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q1raoo8q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_183923-q1raoo8q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1345367431640625, Uncertainty Bias: -0.059880614280700684
7.1525574e-05 0.16837692
2.8821323 17.474655
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3709 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3649 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2242 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_192228-jsxualur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_48
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jsxualur
Training model 48. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.627762250231593, Training Loss Force: 4.888652839380418, time: 0.7100906372070312
Validation Loss Energy: 1.660712137504357, Validation Loss Force: 4.812130523619518, time: 0.07006621360778809
Test Loss Energy: 6.8165814669148705, Test Loss Force: 8.8245271266781, time: 10.752680540084839


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.333478806745304, Training Loss Force: 4.796297215814805, time: 0.7426497936248779
Validation Loss Energy: 4.2261677593447065, Validation Loss Force: 4.742277876527096, time: 0.06585192680358887
Test Loss Energy: 9.365433621660655, Test Loss Force: 8.899542757790677, time: 10.793711423873901


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.406483664171099, Training Loss Force: 4.52383294895002, time: 0.7239241600036621
Validation Loss Energy: 6.0873809932848655, Validation Loss Force: 4.800248897992811, time: 0.06863617897033691
Test Loss Energy: 10.339689015668677, Test Loss Force: 8.745488155550373, time: 10.990556001663208


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.346557976909062, Training Loss Force: 4.532664458046764, time: 0.7293932437896729
Validation Loss Energy: 5.325939577847889, Validation Loss Force: 4.819861596366131, time: 0.06898641586303711
Test Loss Energy: 9.872583879821411, Test Loss Force: 8.806182089581583, time: 10.85523247718811


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.4897804062872035, Training Loss Force: 4.539572431579976, time: 0.6678965091705322
Validation Loss Energy: 2.5237636076296965, Validation Loss Force: 4.822089401171139, time: 0.07152438163757324
Test Loss Energy: 7.443810361513571, Test Loss Force: 8.736660086352144, time: 11.139700651168823


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.472407015481113, Training Loss Force: 4.535968612917457, time: 0.7127230167388916
Validation Loss Energy: 3.087700942000487, Validation Loss Force: 4.530644436140635, time: 0.06611037254333496
Test Loss Energy: 6.9477347969792085, Test Loss Force: 8.695717413856599, time: 11.061410427093506


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.4230855715580075, Training Loss Force: 4.515353001848969, time: 0.7434921264648438
Validation Loss Energy: 5.744575385723804, Validation Loss Force: 4.561398162561305, time: 0.07074618339538574
Test Loss Energy: 7.515570826190235, Test Loss Force: 8.721463227247245, time: 11.7647385597229


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.433603951501887, Training Loss Force: 4.514995101929051, time: 0.7394685745239258
Validation Loss Energy: 5.198738492221764, Validation Loss Force: 4.613195459287027, time: 0.06786155700683594
Test Loss Energy: 7.307646723851535, Test Loss Force: 8.693341079404803, time: 11.021158218383789


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.410842920496907, Training Loss Force: 4.506333130947636, time: 0.7177445888519287
Validation Loss Energy: 2.318535913233286, Validation Loss Force: 4.557939442717609, time: 0.07401394844055176
Test Loss Energy: 6.972544511611991, Test Loss Force: 8.74763747472757, time: 10.875746488571167


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.292117722333137, Training Loss Force: 4.5120732591200055, time: 0.7481420040130615
Validation Loss Energy: 4.095752444597116, Validation Loss Force: 4.877155480959081, time: 0.06698012351989746
Test Loss Energy: 8.618825001274985, Test Loss Force: 8.72748650458786, time: 11.118587017059326


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.403604093198575, Training Loss Force: 4.517628436127386, time: 0.7460834980010986
Validation Loss Energy: 6.217589893734182, Validation Loss Force: 4.704486023741939, time: 0.08051800727844238
Test Loss Energy: 10.655769514432723, Test Loss Force: 8.711010549970645, time: 11.05903959274292


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.392037308166822, Training Loss Force: 4.53198650653078, time: 0.7320356369018555
Validation Loss Energy: 5.4059405939351155, Validation Loss Force: 4.960038058463759, time: 0.06679058074951172
Test Loss Energy: 10.048884337515998, Test Loss Force: 8.828055390409556, time: 10.868205547332764


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.340267454055597, Training Loss Force: 4.52077843877764, time: 0.7438533306121826
Validation Loss Energy: 2.5870486282629788, Validation Loss Force: 4.559004691911728, time: 0.06847119331359863
Test Loss Energy: 7.986592761278267, Test Loss Force: 8.691487035836401, time: 11.13700795173645


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.269689399764334, Training Loss Force: 4.540176967449261, time: 0.7648670673370361
Validation Loss Energy: 3.4920863698753157, Validation Loss Force: 5.00350597044776, time: 0.07303023338317871
Test Loss Energy: 7.014554480458825, Test Loss Force: 8.710153928942384, time: 10.867633581161499


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.450637858755713, Training Loss Force: 4.523251929114927, time: 0.7304034233093262
Validation Loss Energy: 5.56966854892838, Validation Loss Force: 4.8713988155294095, time: 0.07427406311035156
Test Loss Energy: 7.681278178154601, Test Loss Force: 8.672441824354069, time: 11.098108530044556


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.524970674235661, Training Loss Force: 4.52225868895022, time: 0.6509950160980225
Validation Loss Energy: 4.919365089599443, Validation Loss Force: 4.6933579105050525, time: 0.06475710868835449
Test Loss Energy: 7.436713919148994, Test Loss Force: 8.700170558950518, time: 11.197176694869995


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.390940404652776, Training Loss Force: 4.508736730327875, time: 0.7065103054046631
Validation Loss Energy: 2.2802797952788705, Validation Loss Force: 4.551999965919132, time: 0.06955361366271973
Test Loss Energy: 7.081098753681722, Test Loss Force: 8.703711949669321, time: 11.023948192596436


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.412854736230365, Training Loss Force: 4.538683970825815, time: 0.7439248561859131
Validation Loss Energy: 4.240486944111885, Validation Loss Force: 4.4985201811267785, time: 0.0714116096496582
Test Loss Energy: 8.962865679976856, Test Loss Force: 8.77764231234917, time: 11.037369966506958


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.462566255764975, Training Loss Force: 4.603009654720933, time: 0.7065157890319824
Validation Loss Energy: 5.711823203718431, Validation Loss Force: 5.165895906543145, time: 0.07046365737915039
Test Loss Energy: 10.05099579594355, Test Loss Force: 8.78614377370841, time: 10.930447340011597


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.509304449754715, Training Loss Force: 4.516945955195117, time: 0.7302134037017822
Validation Loss Energy: 5.443863598847224, Validation Loss Force: 4.56559681197692, time: 0.06893181800842285
Test Loss Energy: 9.73766523082073, Test Loss Force: 8.728147815629965, time: 9.941998481750488

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–‡â–‡â–‚â–â–‚â–‚â–â–„â–ˆâ–‡â–ƒâ–â–ƒâ–‚â–â–…â–‡â–†
wandb:   test_error_force â–†â–ˆâ–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–†â–‚â–‚â–â–‚â–‚â–„â–…â–ƒ
wandb:          test_loss â–‚â–‡â–‡â–†â–‚â–â–‚â–‚â–â–„â–ˆâ–‡â–ƒâ–â–ƒâ–‚â–â–…â–‡â–†
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–†â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–ƒâ–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–
wandb: valid_error_energy â–â–…â–ˆâ–‡â–‚â–ƒâ–‡â–†â–‚â–…â–ˆâ–‡â–‚â–„â–‡â–†â–‚â–…â–‡â–‡
wandb:  valid_error_force â–„â–„â–„â–„â–„â–â–‚â–‚â–‚â–…â–ƒâ–†â–‚â–†â–…â–ƒâ–‚â–â–ˆâ–‚
wandb:         valid_loss â–â–„â–ˆâ–†â–‚â–‚â–‡â–†â–â–…â–ˆâ–‡â–â–„â–ˆâ–†â–â–„â–ˆâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1293
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.73767
wandb:   test_error_force 8.72815
wandb:          test_loss 5.55412
wandb: train_error_energy 4.5093
wandb:  train_error_force 4.51695
wandb:         train_loss 1.88618
wandb: valid_error_energy 5.44386
wandb:  valid_error_force 4.5656
wandb:         valid_loss 2.13151
wandb: 
wandb: ğŸš€ View run al_73_48 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jsxualur
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_192228-jsxualur/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6638622283935547, Uncertainty Bias: -0.19063565135002136
0.0004749298 0.048521042
2.4925396 11.323727
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3630 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1639 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3838 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3831 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_200557-g01k1t8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_49
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g01k1t8a
Training model 49. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.309050394677005, Training Loss Force: 4.880030557816526, time: 0.6674284934997559
Validation Loss Energy: 4.9843700067158725, Validation Loss Force: 5.263243517105585, time: 0.06406116485595703
Test Loss Energy: 7.354884651808468, Test Loss Force: 9.020337206750167, time: 9.632196187973022


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0653761795928824, Training Loss Force: 4.7565202621627485, time: 0.6981887817382812
Validation Loss Energy: 2.6015076492538, Validation Loss Force: 4.474576122526872, time: 0.06087160110473633
Test Loss Energy: 7.699871986816822, Test Loss Force: 8.724042095025661, time: 10.234779119491577


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.910822847841894, Training Loss Force: 4.514971086247019, time: 0.6804258823394775
Validation Loss Energy: 3.5173724554177292, Validation Loss Force: 4.559633286910682, time: 0.06462407112121582
Test Loss Energy: 8.507569395417208, Test Loss Force: 8.78689780837979, time: 9.630930423736572


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.996750697464874, Training Loss Force: 4.481140713082291, time: 0.6432540416717529
Validation Loss Energy: 2.9060113803509573, Validation Loss Force: 4.922000378941499, time: 0.0603940486907959
Test Loss Energy: 8.425548702559606, Test Loss Force: 8.758313352758115, time: 9.459156036376953


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.014237847765237, Training Loss Force: 4.499572797920082, time: 0.6588413715362549
Validation Loss Energy: 2.4006857979132894, Validation Loss Force: 4.958668643216303, time: 0.0605311393737793
Test Loss Energy: 6.848577612558167, Test Loss Force: 8.762942222279802, time: 9.503715991973877


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0197703260971203, Training Loss Force: 4.492538858821731, time: 0.6496944427490234
Validation Loss Energy: 3.095440142170926, Validation Loss Force: 4.728862728492384, time: 0.06490635871887207
Test Loss Energy: 6.9319158935451535, Test Loss Force: 8.713367149640755, time: 9.684466123580933


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.994929117215406, Training Loss Force: 4.494321944463727, time: 0.7053656578063965
Validation Loss Energy: 2.469824233720149, Validation Loss Force: 4.555605870068286, time: 0.06794476509094238
Test Loss Energy: 6.8584534135338275, Test Loss Force: 8.76318838010611, time: 9.46465015411377


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.083223456504623, Training Loss Force: 4.496565721706739, time: 0.6742074489593506
Validation Loss Energy: 2.834455314292187, Validation Loss Force: 4.8065337346366235, time: 0.060384511947631836
Test Loss Energy: 7.826513049048674, Test Loss Force: 8.722470176762572, time: 9.434777975082397


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9755428163384696, Training Loss Force: 4.492391848306825, time: 0.6487338542938232
Validation Loss Energy: 4.162253921043325, Validation Loss Force: 5.0917054418189025, time: 0.06037497520446777
Test Loss Energy: 9.082757631069182, Test Loss Force: 8.80157537972024, time: 9.67882490158081


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0507709572994184, Training Loss Force: 4.501248638498063, time: 0.6679763793945312
Validation Loss Energy: 3.1063453635927396, Validation Loss Force: 4.778212000627776, time: 0.06347870826721191
Test Loss Energy: 8.503684098614459, Test Loss Force: 8.811989725261146, time: 9.470683574676514


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0171041536307155, Training Loss Force: 4.49117041571518, time: 0.685232400894165
Validation Loss Energy: 2.4288874019179088, Validation Loss Force: 4.930024484284153, time: 0.05962634086608887
Test Loss Energy: 6.916324107976718, Test Loss Force: 8.743226904907, time: 9.473572731018066


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.973620516317152, Training Loss Force: 4.518001265741991, time: 0.6533615589141846
Validation Loss Energy: 3.2320989884357605, Validation Loss Force: 4.548846525474501, time: 0.060167551040649414
Test Loss Energy: 6.821244779039947, Test Loss Force: 8.781511043033786, time: 9.684220552444458


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0638843967878295, Training Loss Force: 4.5017486665045405, time: 0.6657848358154297
Validation Loss Energy: 2.4195106928483163, Validation Loss Force: 4.890256442828887, time: 0.0625619888305664
Test Loss Energy: 6.778676146129856, Test Loss Force: 8.68637465017369, time: 9.501933097839355


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.091937244225582, Training Loss Force: 4.482860631289256, time: 0.6842243671417236
Validation Loss Energy: 2.714989866130167, Validation Loss Force: 4.818353458240762, time: 0.06821608543395996
Test Loss Energy: 7.914495681474929, Test Loss Force: 8.741608270423933, time: 9.450012922286987


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.032895423129964, Training Loss Force: 4.48470426664608, time: 0.7069292068481445
Validation Loss Energy: 4.228258622624969, Validation Loss Force: 4.597253461784327, time: 0.06047940254211426
Test Loss Energy: 9.140338566502214, Test Loss Force: 8.797964199128392, time: 9.688498973846436


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.072999961112364, Training Loss Force: 4.505292570873942, time: 0.6871840953826904
Validation Loss Energy: 3.222111720568034, Validation Loss Force: 4.766106369840266, time: 0.06176257133483887
Test Loss Energy: 8.817591414131059, Test Loss Force: 8.826285331580802, time: 9.479770421981812


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.997190268082755, Training Loss Force: 4.506205449200787, time: 0.6550962924957275
Validation Loss Energy: 2.0729026756168194, Validation Loss Force: 4.664756949387211, time: 0.061231136322021484
Test Loss Energy: 6.661010403852691, Test Loss Force: 8.74769876819886, time: 9.550565481185913


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8985520427112204, Training Loss Force: 4.519210934885585, time: 0.6686182022094727
Validation Loss Energy: 3.423110037206692, Validation Loss Force: 4.867661759253303, time: 0.06216835975646973
Test Loss Energy: 6.831296304443378, Test Loss Force: 8.777621323159101, time: 10.429278135299683


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.073617906008997, Training Loss Force: 4.52850370040264, time: 0.6515331268310547
Validation Loss Energy: 3.1462403264611836, Validation Loss Force: 4.818679000532109, time: 0.0601954460144043
Test Loss Energy: 6.839735793831629, Test Loss Force: 8.683750278614628, time: 9.478529214859009


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0361927784452742, Training Loss Force: 4.499420090333613, time: 0.6996691226959229
Validation Loss Energy: 2.4661849291991054, Validation Loss Force: 4.573176915042593, time: 0.060274600982666016
Test Loss Energy: 7.907573566901279, Test Loss Force: 8.843534346840398, time: 9.459991693496704

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–†â–†â–‚â–‚â–‚â–„â–ˆâ–†â–‚â–â–â–…â–ˆâ–‡â–â–â–‚â–…
wandb:   test_error_force â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–â–„
wandb:          test_loss â–â–„â–†â–‡â–ƒâ–ƒâ–‚â–…â–ˆâ–†â–ƒâ–ƒâ–‚â–„â–ˆâ–‡â–‚â–ƒâ–‚â–„
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–
wandb:  train_error_force â–ˆâ–†â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–„â–‚â–ƒâ–†â–„â–â–„â–„â–‚
wandb:  valid_error_force â–ˆâ–â–‚â–…â–…â–ƒâ–‚â–„â–†â–„â–…â–‚â–…â–„â–‚â–„â–ƒâ–„â–„â–‚
wandb:         valid_loss â–ˆâ–â–„â–ƒâ–‚â–ƒâ–â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–â–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1296
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.90757
wandb:   test_error_force 8.84353
wandb:          test_loss 5.73192
wandb: train_error_energy 3.03619
wandb:  train_error_force 4.49942
wandb:         train_loss 1.47975
wandb: valid_error_energy 2.46618
wandb:  valid_error_force 4.57318
wandb:         valid_loss 1.34022
wandb: 
wandb: ğŸš€ View run al_73_49 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g01k1t8a
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_200557-g01k1t8a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.7692890167236328, Uncertainty Bias: 0.06264173984527588
0.00023913383 0.02768135
3.234486 19.297434
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2624 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2732 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_204848-svxcn0t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_50
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svxcn0t6
Training model 50. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.119498422698856, Training Loss Force: 4.92267972621286, time: 0.6824967861175537
Validation Loss Energy: 2.911412109150863, Validation Loss Force: 5.631876296233664, time: 0.06441926956176758
Test Loss Energy: 7.63899870502954, Test Loss Force: 9.252493172806016, time: 9.682177782058716


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9212535993304183, Training Loss Force: 5.063462098211332, time: 0.6632239818572998
Validation Loss Energy: 2.484331907919355, Validation Loss Force: 4.94829270635436, time: 0.07416272163391113
Test Loss Energy: 7.622414955229557, Test Loss Force: 8.808234511540286, time: 9.692562103271484


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2002739592192775, Training Loss Force: 4.663322862330251, time: 0.6864488124847412
Validation Loss Energy: 2.075018143837706, Validation Loss Force: 4.718460294002076, time: 0.0642251968383789
Test Loss Energy: 7.53147231539548, Test Loss Force: 8.87651545720973, time: 9.917613506317139


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.097460127973255, Training Loss Force: 4.52793441142987, time: 0.6892123222351074
Validation Loss Energy: 2.0223345125766192, Validation Loss Force: 4.934436896079857, time: 0.06245899200439453
Test Loss Energy: 6.849625073868366, Test Loss Force: 8.806069276765285, time: 9.707239389419556


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1385579305596587, Training Loss Force: 4.504570503712291, time: 0.6963510513305664
Validation Loss Energy: 1.9657725414663343, Validation Loss Force: 5.325416973362396, time: 0.0621485710144043
Test Loss Energy: 6.9268292232542805, Test Loss Force: 8.842243817092564, time: 9.786550760269165


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.140554471732801, Training Loss Force: 4.493811700831311, time: 0.6628425121307373
Validation Loss Energy: 1.7937222158094455, Validation Loss Force: 4.4295388384023715, time: 0.06159329414367676
Test Loss Energy: 7.42657586521494, Test Loss Force: 8.831210586559598, time: 9.932670831680298


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.155337913522807, Training Loss Force: 4.499892746328006, time: 0.6715435981750488
Validation Loss Energy: 2.134908128003028, Validation Loss Force: 4.427895540105425, time: 0.06241416931152344
Test Loss Energy: 8.003119374874892, Test Loss Force: 8.83765405806568, time: 9.73749589920044


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1503083307415247, Training Loss Force: 4.4954015531022815, time: 0.6558587551116943
Validation Loss Energy: 1.9160555312364425, Validation Loss Force: 4.638071833600934, time: 0.06314945220947266
Test Loss Energy: 6.739368058689391, Test Loss Force: 8.74802861231821, time: 9.708925247192383


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.091276402130036, Training Loss Force: 4.490743216812286, time: 0.6996119022369385
Validation Loss Energy: 1.8244977081391305, Validation Loss Force: 4.608137306968132, time: 0.06186556816101074
Test Loss Energy: 6.906287365006637, Test Loss Force: 8.83089632694885, time: 9.88900089263916


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1311768312544648, Training Loss Force: 4.506516903595438, time: 0.6549625396728516
Validation Loss Energy: 2.3990232387352197, Validation Loss Force: 4.849714626091524, time: 0.06258487701416016
Test Loss Energy: 7.826333885490116, Test Loss Force: 8.830424151778779, time: 9.749868392944336


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.163797117092081, Training Loss Force: 4.496451237180004, time: 0.6627895832061768
Validation Loss Energy: 1.8432134395253663, Validation Loss Force: 5.010896359401103, time: 0.060886383056640625
Test Loss Energy: 7.556648370903016, Test Loss Force: 8.822515694495163, time: 9.721438646316528


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1059026259256295, Training Loss Force: 4.49061770744735, time: 0.6474330425262451
Validation Loss Energy: 1.801597633829906, Validation Loss Force: 4.717901171776651, time: 0.0668342113494873
Test Loss Energy: 6.952790960431285, Test Loss Force: 8.810440003964226, time: 9.941160917282104


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.168194387385863, Training Loss Force: 4.496702733833897, time: 0.6538329124450684
Validation Loss Energy: 1.8603347484921864, Validation Loss Force: 4.653241614505556, time: 0.06448149681091309
Test Loss Energy: 6.730037407741698, Test Loss Force: 8.852114047842159, time: 9.805103063583374


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1934063295336372, Training Loss Force: 4.493958450660387, time: 0.6877901554107666
Validation Loss Energy: 2.1755541539006864, Validation Loss Force: 4.974329632256842, time: 0.06397652626037598
Test Loss Energy: 7.871231073416004, Test Loss Force: 8.809888110908298, time: 10.569986581802368


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.110587734107207, Training Loss Force: 4.4996865329750575, time: 0.6576836109161377
Validation Loss Energy: 2.27006885625406, Validation Loss Force: 4.888388026025408, time: 0.06192803382873535
Test Loss Energy: 7.797283207309154, Test Loss Force: 8.786038487342406, time: 9.917893171310425


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0965923102782074, Training Loss Force: 4.492637772801116, time: 0.6500892639160156
Validation Loss Energy: 1.9478652660816755, Validation Loss Force: 4.617467812189943, time: 0.06263041496276855
Test Loss Energy: 6.755607249553482, Test Loss Force: 8.784936524552771, time: 9.768849611282349


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.211680403457619, Training Loss Force: 4.492515380804222, time: 0.6363658905029297
Validation Loss Energy: 1.8817261836704635, Validation Loss Force: 4.787525360325352, time: 0.061786651611328125
Test Loss Energy: 7.067932499622455, Test Loss Force: 8.788797612206388, time: 9.801483154296875


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0786845596850054, Training Loss Force: 4.511708983259177, time: 0.7765512466430664
Validation Loss Energy: 1.922557358962961, Validation Loss Force: 4.798313457776407, time: 0.0629270076751709
Test Loss Energy: 7.103229245533892, Test Loss Force: 8.98199731506718, time: 9.77874755859375


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.118928219720495, Training Loss Force: 4.558182086915213, time: 0.6780130863189697
Validation Loss Energy: 2.0689474035777042, Validation Loss Force: 4.751153023345485, time: 0.0681772232055664
Test Loss Energy: 7.542406596889549, Test Loss Force: 8.85421184767435, time: 9.754904747009277


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.08827764070846, Training Loss Force: 4.511414104138511, time: 0.6811292171478271
Validation Loss Energy: 1.8110079102732466, Validation Loss Force: 4.733219250332461, time: 0.06315302848815918
Test Loss Energy: 6.726668437553495, Test Loss Force: 8.866093193507364, time: 10.002055883407593

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–…â–‚â–‚â–…â–ˆâ–â–‚â–‡â–†â–‚â–â–‡â–‡â–â–ƒâ–ƒâ–…â–
wandb:   test_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–ƒ
wandb:          test_loss â–â–ƒâ–…â–‚â–ƒâ–…â–ˆâ–â–ƒâ–‡â–„â–…â–â–…â–…â–‚â–‚â–ˆâ–…â–ƒ
wandb: train_error_energy â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–†â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–…â–â–â–â–ƒâ–„â–‚â–‚â–‚â–ƒâ–
wandb:  valid_error_force â–ˆâ–„â–ƒâ–„â–†â–â–â–‚â–‚â–ƒâ–„â–ƒâ–‚â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:         valid_loss â–ˆâ–…â–ƒâ–„â–†â–â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1297
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.72667
wandb:   test_error_force 8.86609
wandb:          test_loss 6.50565
wandb: train_error_energy 2.08828
wandb:  train_error_force 4.51141
wandb:         train_loss 1.10673
wandb: valid_error_energy 1.81101
wandb:  valid_error_force 4.73322
wandb:         valid_loss 1.09009
wandb: 
wandb: ğŸš€ View run al_73_50 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svxcn0t6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_204848-svxcn0t6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0729002952575684, Uncertainty Bias: 0.10535556077957153
0.00039291382 2.3841858e-06
3.313065 18.563992
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 835 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2687 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1414 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_213130-ymsj3j12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_51
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ymsj3j12
Training model 51. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.69420759473699, Training Loss Force: 5.860456916957091, time: 0.7181668281555176
Validation Loss Energy: 1.9488298688218344, Validation Loss Force: 5.048767037063918, time: 0.07178950309753418
Test Loss Energy: 6.767079842451381, Test Loss Force: 8.892374615961112, time: 10.429824113845825


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3864044486951705, Training Loss Force: 5.225090712203926, time: 0.7663054466247559
Validation Loss Energy: 1.9738365045861088, Validation Loss Force: 5.5446970948891625, time: 0.06604218482971191
Test Loss Energy: 6.633386433340688, Test Loss Force: 8.859147287143506, time: 10.75584077835083


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.794958568036461, Training Loss Force: 4.850559470847857, time: 0.6619281768798828
Validation Loss Energy: 3.77000618831302, Validation Loss Force: 6.268610075140616, time: 0.06431174278259277
Test Loss Energy: 8.508800508643095, Test Loss Force: 9.342972012627841, time: 11.034398555755615


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.5525586167617806, Training Loss Force: 5.721748898136354, time: 0.6862733364105225
Validation Loss Energy: 2.428951085293644, Validation Loss Force: 6.0009141105381865, time: 0.0672905445098877
Test Loss Energy: 7.004655225776999, Test Loss Force: 9.730697029562908, time: 9.724236011505127


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.103699746487579, Training Loss Force: 4.721609085549414, time: 0.7109830379486084
Validation Loss Energy: 1.931314268464863, Validation Loss Force: 4.5639588577394745, time: 0.05928206443786621
Test Loss Energy: 6.579471149667954, Test Loss Force: 8.768002799477355, time: 10.946807384490967


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.063710396340558, Training Loss Force: 4.4891500679517655, time: 0.8860466480255127
Validation Loss Energy: 2.007085350121473, Validation Loss Force: 4.717414639692798, time: 0.09522294998168945
Test Loss Energy: 7.601845266836093, Test Loss Force: 8.75046409515633, time: 10.077221155166626


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.085729944520553, Training Loss Force: 4.48680012640474, time: 0.7106418609619141
Validation Loss Energy: 2.26205276700066, Validation Loss Force: 4.688326923821959, time: 0.06554508209228516
Test Loss Energy: 7.865000809365857, Test Loss Force: 8.831259154081165, time: 9.101710557937622


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.052598317997655, Training Loss Force: 4.484944423466396, time: 0.6782257556915283
Validation Loss Energy: 1.8249371456986188, Validation Loss Force: 4.652770446592773, time: 0.06108546257019043
Test Loss Energy: 7.0001190355839125, Test Loss Force: 8.776115893203501, time: 9.0296311378479


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1200339322431927, Training Loss Force: 4.4942604008841744, time: 0.7913572788238525
Validation Loss Energy: 2.081813115494839, Validation Loss Force: 4.760464379020748, time: 0.08939003944396973
Test Loss Energy: 6.977139742937152, Test Loss Force: 8.793569465630744, time: 9.039900779724121


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.056205175279373, Training Loss Force: 4.5043829945675995, time: 0.6694374084472656
Validation Loss Energy: 1.857374195195217, Validation Loss Force: 4.526561352011758, time: 0.06720256805419922
Test Loss Energy: 7.542221445745998, Test Loss Force: 8.805849778614524, time: 9.029790878295898


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0761673528772264, Training Loss Force: 4.482969603396891, time: 0.680840253829956
Validation Loss Energy: 2.1978941039733293, Validation Loss Force: 4.513533648290959, time: 0.06716299057006836
Test Loss Energy: 7.947810347893249, Test Loss Force: 8.79119206796292, time: 9.815176725387573


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0652576074700826, Training Loss Force: 4.499519574563251, time: 0.6698064804077148
Validation Loss Energy: 2.120010894133021, Validation Loss Force: 4.870091524973667, time: 0.08606958389282227
Test Loss Energy: 7.088473688696855, Test Loss Force: 8.77479344365873, time: 9.208276748657227


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.104761978786318, Training Loss Force: 4.49682122640526, time: 0.6607887744903564
Validation Loss Energy: 1.6469150562170929, Validation Loss Force: 4.9088613406477375, time: 0.07029438018798828
Test Loss Energy: 6.857928807357636, Test Loss Force: 8.842279215657731, time: 9.025674819946289


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0758081956912773, Training Loss Force: 4.515130821488971, time: 0.67327880859375
Validation Loss Energy: 2.6907063484172933, Validation Loss Force: 4.808586744162078, time: 0.06690382957458496
Test Loss Energy: 8.107860763391757, Test Loss Force: 8.83313049822614, time: 9.113297700881958


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.147354874344712, Training Loss Force: 4.486695580525248, time: 0.7006332874298096
Validation Loss Energy: 1.9547941732300833, Validation Loss Force: 4.626663157240177, time: 0.06458425521850586
Test Loss Energy: 7.509453678066219, Test Loss Force: 8.803369337593452, time: 9.227588653564453


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1558560917801546, Training Loss Force: 4.493542015909865, time: 0.6505913734436035
Validation Loss Energy: 2.026358144043534, Validation Loss Force: 4.997445584303044, time: 0.06096243858337402
Test Loss Energy: 6.784899373368667, Test Loss Force: 8.819774490417101, time: 9.003384590148926


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.141497766121886, Training Loss Force: 4.528465873802606, time: 0.650597333908081
Validation Loss Energy: 1.6221973893369463, Validation Loss Force: 4.505499300167593, time: 0.059763193130493164
Test Loss Energy: 6.969558709557454, Test Loss Force: 8.806457784295226, time: 8.962957620620728


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.069871803675114, Training Loss Force: 4.498920529389247, time: 0.7019009590148926
Validation Loss Energy: 2.080640205768664, Validation Loss Force: 4.584916032415906, time: 0.0638115406036377
Test Loss Energy: 7.864211026387197, Test Loss Force: 8.84966291987347, time: 10.607207536697388


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1537267067376473, Training Loss Force: 4.486960556808904, time: 0.7118988037109375
Validation Loss Energy: 2.1326028343352377, Validation Loss Force: 4.822061344858751, time: 0.06649041175842285
Test Loss Energy: 7.551314360657492, Test Loss Force: 8.811150908438101, time: 11.166550874710083


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.092903874624758, Training Loss Force: 4.488509562868981, time: 0.6991884708404541
Validation Loss Energy: 1.9711035748235641, Validation Loss Force: 4.871530858332944, time: 0.06995820999145508
Test Loss Energy: 6.85775603475331, Test Loss Force: 8.758127597726515, time: 10.89609694480896

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–ƒâ–â–…â–†â–ƒâ–‚â–„â–†â–ƒâ–‚â–‡â–„â–‚â–‚â–†â–…â–‚
wandb:   test_error_force â–‚â–‚â–…â–ˆâ–â–â–‚â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–
wandb:          test_loss â–â–„â–ˆâ–†â–„â–†â–†â–…â–…â–†â–†â–…â–…â–‡â–†â–…â–…â–‡â–†â–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–ƒâ–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–ˆâ–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–â–„â–‚â–‚â–â–‚â–ƒâ–‚
wandb:  valid_error_force â–ƒâ–…â–ˆâ–‡â–â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–â–ƒâ–â–â–‚â–‚
wandb:         valid_loss â–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1299
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.85776
wandb:   test_error_force 8.75813
wandb:          test_loss 6.50068
wandb: train_error_energy 2.0929
wandb:  train_error_force 4.48851
wandb:         train_loss 1.09279
wandb: valid_error_energy 1.9711
wandb:  valid_error_force 4.87153
wandb:         valid_loss 1.5428
wandb: 
wandb: ğŸš€ View run al_73_51 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ymsj3j12
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_213130-ymsj3j12/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0578339099884033, Uncertainty Bias: 0.10118599236011505
1.9073486e-05 0.0005311966
3.213802 16.475449
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1993 steps.
Found uncertainty sample 8 after 1375 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2177 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2038 steps.
Found uncertainty sample 85 after 1783 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_221354-c38hssta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_52
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/c38hssta
Training model 52. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.863746633326809, Training Loss Force: 6.233449547100527, time: 1.0964696407318115
Validation Loss Energy: 3.7317549690798146, Validation Loss Force: 4.97679858774689, time: 0.1148984432220459
Test Loss Energy: 7.099138148813181, Test Loss Force: 8.894445271142025, time: 9.829506874084473


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.076990170483571, Training Loss Force: 4.916253440351837, time: 0.7131788730621338
Validation Loss Energy: 2.815657918996682, Validation Loss Force: 4.952120166303713, time: 0.07140660285949707
Test Loss Energy: 8.288370001365202, Test Loss Force: 8.88185078714883, time: 9.96554446220398


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.971884348693489, Training Loss Force: 4.5498826864748265, time: 0.6543705463409424
Validation Loss Energy: 4.051731756458349, Validation Loss Force: 4.784357891724529, time: 0.06478357315063477
Test Loss Energy: 8.692299370186571, Test Loss Force: 8.774545220022338, time: 10.163887739181519


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9598913151759287, Training Loss Force: 4.512630149223017, time: 0.6860973834991455
Validation Loss Energy: 2.984373774193302, Validation Loss Force: 4.9079163327924205, time: 0.06306886672973633
Test Loss Energy: 8.396078075032653, Test Loss Force: 8.742748112616132, time: 9.81762981414795


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.042124719793997, Training Loss Force: 4.519757777722255, time: 0.6907520294189453
Validation Loss Energy: 2.1905307693212164, Validation Loss Force: 4.612649474541213, time: 0.06476855278015137
Test Loss Energy: 6.817135803502368, Test Loss Force: 8.753097485398706, time: 9.84804391860962


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0043242019204914, Training Loss Force: 4.499511591059725, time: 0.6590278148651123
Validation Loss Energy: 3.264775685600663, Validation Loss Force: 4.559175479146654, time: 0.06216001510620117
Test Loss Energy: 6.9121772390468905, Test Loss Force: 8.747300808305386, time: 10.031033992767334


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9705725042821647, Training Loss Force: 4.513536857985234, time: 0.6808860301971436
Validation Loss Energy: 2.5202099193952616, Validation Loss Force: 4.725031260498405, time: 0.0669565200805664
Test Loss Energy: 6.918492809861876, Test Loss Force: 8.735925217548614, time: 9.797621011734009


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0119777858043215, Training Loss Force: 4.4917592506942, time: 0.6692750453948975
Validation Loss Energy: 2.786541033467727, Validation Loss Force: 5.036285318088936, time: 0.06199216842651367
Test Loss Energy: 8.093860201851106, Test Loss Force: 8.730168998623043, time: 10.65309453010559


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0774930253020103, Training Loss Force: 4.498814886456891, time: 0.7003190517425537
Validation Loss Energy: 3.947823756184011, Validation Loss Force: 4.822909268966445, time: 0.0920877456665039
Test Loss Energy: 8.6964068814705, Test Loss Force: 8.770695958315406, time: 10.026926755905151


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9227566785214103, Training Loss Force: 4.4936173432526445, time: 0.7089228630065918
Validation Loss Energy: 3.038847220049357, Validation Loss Force: 4.691488157686697, time: 0.06177330017089844
Test Loss Energy: 8.48172886953047, Test Loss Force: 8.77413301862998, time: 9.853669881820679


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.105958307592092, Training Loss Force: 4.51174720631891, time: 0.680124044418335
Validation Loss Energy: 2.0252995749237934, Validation Loss Force: 4.369446447983401, time: 0.06282496452331543
Test Loss Energy: 6.8874340127216005, Test Loss Force: 8.785209281432657, time: 10.009225368499756


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.982837541738863, Training Loss Force: 4.522119819436529, time: 0.6777660846710205
Validation Loss Energy: 3.232291597246988, Validation Loss Force: 4.62848436818472, time: 0.06290912628173828
Test Loss Energy: 6.9070396906048845, Test Loss Force: 8.772501341097675, time: 9.88993525505066


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9417990397476874, Training Loss Force: 4.517632417017239, time: 0.6698756217956543
Validation Loss Energy: 2.4102756013555346, Validation Loss Force: 4.741867719960297, time: 0.06236147880554199
Test Loss Energy: 6.933289356474677, Test Loss Force: 8.764884862520526, time: 9.853034019470215


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.026152903634084, Training Loss Force: 4.505382366280252, time: 0.6950075626373291
Validation Loss Energy: 2.32884427000944, Validation Loss Force: 4.591833694772445, time: 0.062380075454711914
Test Loss Energy: 7.6742555756767485, Test Loss Force: 8.733770918043712, time: 10.076021909713745


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.032435861167543, Training Loss Force: 4.5060907365739515, time: 0.6599247455596924
Validation Loss Energy: 3.6428258109174667, Validation Loss Force: 4.810981996164823, time: 0.06773877143859863
Test Loss Energy: 8.996181815312054, Test Loss Force: 8.741087014777195, time: 9.820373296737671


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0302981667642244, Training Loss Force: 4.507989908874343, time: 0.6646711826324463
Validation Loss Energy: 3.1071348370496263, Validation Loss Force: 4.648448215801169, time: 0.06847715377807617
Test Loss Energy: 8.327337267447163, Test Loss Force: 8.749485955064745, time: 9.820714235305786


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0599065102530156, Training Loss Force: 4.507630814144374, time: 0.6561055183410645
Validation Loss Energy: 2.132135785801654, Validation Loss Force: 4.803278979730597, time: 0.06367254257202148
Test Loss Energy: 6.7335741981858925, Test Loss Force: 8.754874553059429, time: 10.038854122161865


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.08117980722973, Training Loss Force: 4.506306367202486, time: 0.6834208965301514
Validation Loss Energy: 3.76659356098253, Validation Loss Force: 4.737220837553929, time: 0.06908869743347168
Test Loss Energy: 6.893118389953722, Test Loss Force: 8.714638951864186, time: 9.804537773132324


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9884355907032667, Training Loss Force: 4.5071439724961, time: 0.6664941310882568
Validation Loss Energy: 2.7000364083008135, Validation Loss Force: 4.894092809544077, time: 0.062150001525878906
Test Loss Energy: 6.609146504570389, Test Loss Force: 8.732891801602678, time: 9.813927412033081


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.069819186672334, Training Loss Force: 4.507507162165972, time: 0.6700270175933838
Validation Loss Energy: 2.652524490623045, Validation Loss Force: 4.635872530446605, time: 0.06258273124694824
Test Loss Energy: 8.189120335802754, Test Loss Force: 8.758268553124923, time: 9.96061086654663

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.050 MB of 0.058 MB uploadedwandb: - 0.050 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‡â–†â–‚â–‚â–‚â–…â–‡â–†â–‚â–‚â–‚â–„â–ˆâ–†â–â–‚â–â–†
wandb:   test_error_force â–ˆâ–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–ƒ
wandb:          test_loss â–â–ˆâ–†â–‡â–‚â–‚â–ƒâ–…â–‡â–‡â–‚â–ƒâ–ƒâ–…â–ˆâ–‡â–‚â–ƒâ–‚â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–„â–ˆâ–„â–‚â–…â–ƒâ–„â–ˆâ–…â–â–…â–‚â–‚â–‡â–…â–â–‡â–ƒâ–ƒ
wandb:  valid_error_force â–‡â–‡â–…â–‡â–„â–ƒâ–…â–ˆâ–†â–„â–â–„â–…â–ƒâ–†â–„â–†â–…â–‡â–„
wandb:         valid_loss â–‡â–„â–‡â–…â–‚â–„â–ƒâ–…â–ˆâ–„â–â–…â–ƒâ–‚â–†â–…â–ƒâ–†â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1303
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.18912
wandb:   test_error_force 8.75827
wandb:          test_loss 5.92018
wandb: train_error_energy 3.06982
wandb:  train_error_force 4.50751
wandb:         train_loss 1.49247
wandb: valid_error_energy 2.65252
wandb:  valid_error_force 4.63587
wandb:         valid_loss 1.4248
wandb: 
wandb: ğŸš€ View run al_73_52 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/c38hssta
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_221354-c38hssta/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2464747428894043, Uncertainty Bias: -0.002562969923019409
0.00013542175 0.0078372955
2.8326302 12.907632
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 416 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 661 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_225635-hto1k212
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_53
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hto1k212
Training model 53. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.475435257730414, Training Loss Force: 5.030640872477858, time: 0.6847467422485352
Validation Loss Energy: 4.456272718731608, Validation Loss Force: 5.065042370278071, time: 0.06450843811035156
Test Loss Energy: 7.116373785271106, Test Loss Force: 8.789391586233476, time: 9.688693046569824


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.422177347559406, Training Loss Force: 4.540927096354253, time: 0.6435091495513916
Validation Loss Energy: 5.605722023691278, Validation Loss Force: 4.769185438790155, time: 0.06332254409790039
Test Loss Energy: 7.5363421992027835, Test Loss Force: 8.700376631667329, time: 10.531757593154907


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.3938227942908314, Training Loss Force: 4.513840676457466, time: 0.6489269733428955
Validation Loss Energy: 4.920990797033863, Validation Loss Force: 5.049851435804587, time: 0.06374192237854004
Test Loss Energy: 7.349178660513697, Test Loss Force: 8.695551734022345, time: 9.965161800384521


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.354777048097318, Training Loss Force: 4.5167626061617865, time: 0.6416611671447754
Validation Loss Energy: 2.125679382580905, Validation Loss Force: 4.581001063492204, time: 0.06346321105957031
Test Loss Energy: 6.89359085890717, Test Loss Force: 8.682623824550557, time: 9.824584245681763


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.376217990501619, Training Loss Force: 4.510055322700512, time: 0.6527743339538574
Validation Loss Energy: 4.271244233238891, Validation Loss Force: 4.687575192785308, time: 0.06253838539123535
Test Loss Energy: 8.967194997709495, Test Loss Force: 8.717449558767354, time: 9.847507953643799


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.4156038230833765, Training Loss Force: 4.523701747944476, time: 0.6857538223266602
Validation Loss Energy: 6.540503575812931, Validation Loss Force: 4.860221937749564, time: 0.06548905372619629
Test Loss Energy: 10.741443009525357, Test Loss Force: 8.75642096812756, time: 9.96074652671814


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.446380278049795, Training Loss Force: 4.5328637686561875, time: 0.6367442607879639
Validation Loss Energy: 5.217498145097034, Validation Loss Force: 4.884697730269947, time: 0.062137603759765625
Test Loss Energy: 9.588947371477667, Test Loss Force: 8.737417935544176, time: 9.771414041519165


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.467993332841989, Training Loss Force: 4.497885769575256, time: 0.662442684173584
Validation Loss Energy: 3.077571165879367, Validation Loss Force: 4.727269976091563, time: 0.06201338768005371
Test Loss Energy: 8.01320678848245, Test Loss Force: 8.630827740264163, time: 9.837412118911743


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.2897985607223195, Training Loss Force: 4.529605228374681, time: 0.7140676975250244
Validation Loss Energy: 3.9773058191122876, Validation Loss Force: 4.935710118256273, time: 0.06691956520080566
Test Loss Energy: 7.008086869752034, Test Loss Force: 8.737836231775777, time: 10.054619073867798


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.570631247316297, Training Loss Force: 4.533846434751941, time: 0.6538896560668945
Validation Loss Energy: 5.770928501813504, Validation Loss Force: 4.882917267779108, time: 0.06375908851623535
Test Loss Energy: 7.691126787846704, Test Loss Force: 8.696906947408358, time: 9.78125286102295


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.425639445456975, Training Loss Force: 4.515398502388105, time: 0.6757416725158691
Validation Loss Energy: 5.221270605767343, Validation Loss Force: 4.700794614640749, time: 0.06451559066772461
Test Loss Energy: 7.4069431149604155, Test Loss Force: 8.701198292473872, time: 9.787763118743896


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.493443552699726, Training Loss Force: 4.50732363934209, time: 0.6670920848846436
Validation Loss Energy: 2.223945169366578, Validation Loss Force: 4.595245654095496, time: 0.06386685371398926
Test Loss Energy: 6.946755845485918, Test Loss Force: 8.684439265916025, time: 9.967557191848755


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.404428406230366, Training Loss Force: 4.515819998788482, time: 0.6721484661102295
Validation Loss Energy: 4.321070240015715, Validation Loss Force: 4.754132559187145, time: 0.06581377983093262
Test Loss Energy: 9.2768342819699, Test Loss Force: 8.72383314509706, time: 9.80218768119812


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.513597195892825, Training Loss Force: 4.535750951111835, time: 0.682450532913208
Validation Loss Energy: 6.011505591133387, Validation Loss Force: 4.728020816451631, time: 0.0632925033569336
Test Loss Energy: 10.192693020691056, Test Loss Force: 8.739106303941552, time: 9.819931030273438


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4261272348068585, Training Loss Force: 4.505737235727405, time: 0.868605375289917
Validation Loss Energy: 5.611993054848043, Validation Loss Force: 4.633781667166343, time: 0.06213831901550293
Test Loss Energy: 10.003387048081187, Test Loss Force: 8.725831730086345, time: 9.767715692520142


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.397448847282215, Training Loss Force: 4.522591334930417, time: 0.6929306983947754
Validation Loss Energy: 2.8684957486413247, Validation Loss Force: 4.678932067216975, time: 0.06106114387512207
Test Loss Energy: 7.980252913697342, Test Loss Force: 8.642833510351661, time: 9.798311948776245


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.424766587835893, Training Loss Force: 4.506862366628913, time: 0.6683480739593506
Validation Loss Energy: 3.8267988446584855, Validation Loss Force: 4.938047476281077, time: 0.062192678451538086
Test Loss Energy: 6.911963812419229, Test Loss Force: 8.653581006240701, time: 9.983060359954834


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.363452091386884, Training Loss Force: 4.5083266715182635, time: 0.6895921230316162
Validation Loss Energy: 5.6410464796704085, Validation Loss Force: 4.889904625578321, time: 0.06952071189880371
Test Loss Energy: 7.523495502181485, Test Loss Force: 8.623351704130323, time: 9.779983043670654


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.533628713205816, Training Loss Force: 4.495010763320224, time: 0.665886402130127
Validation Loss Energy: 4.809204651042027, Validation Loss Force: 4.7688928515324065, time: 0.06242799758911133
Test Loss Energy: 7.503592914227921, Test Loss Force: 8.672718437723661, time: 10.593291997909546


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.455115702694593, Training Loss Force: 4.515946192453721, time: 0.6837329864501953
Validation Loss Energy: 2.2375626123203647, Validation Loss Force: 5.073405155391682, time: 0.06343436241149902
Test Loss Energy: 7.0512187623367595, Test Loss Force: 8.673832482937527, time: 9.974096298217773

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.051 MB of 0.058 MB uploadedwandb: | 0.051 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‚â–â–…â–ˆâ–†â–ƒâ–â–‚â–‚â–â–…â–‡â–‡â–ƒâ–â–‚â–‚â–
wandb:   test_error_force â–ˆâ–„â–„â–ƒâ–…â–‡â–†â–â–†â–„â–„â–„â–…â–†â–…â–‚â–‚â–â–ƒâ–ƒ
wandb:          test_loss â–‚â–‚â–‚â–â–…â–ˆâ–†â–ƒâ–â–ƒâ–‚â–â–…â–†â–‡â–ƒâ–â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‡â–…â–â–„â–ˆâ–†â–ƒâ–„â–‡â–†â–â–„â–‡â–‡â–‚â–„â–‡â–…â–
wandb:  valid_error_force â–ˆâ–„â–ˆâ–â–ƒâ–…â–…â–ƒâ–†â–…â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–†â–…â–„â–ˆ
wandb:         valid_loss â–…â–†â–…â–â–„â–ˆâ–…â–‚â–„â–‡â–…â–â–„â–‡â–†â–‚â–„â–†â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1304
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.05122
wandb:   test_error_force 8.67383
wandb:          test_loss 4.61082
wandb: train_error_energy 4.45512
wandb:  train_error_force 4.51595
wandb:         train_loss 1.87751
wandb: valid_error_energy 2.23756
wandb:  valid_error_force 5.07341
wandb:         valid_loss 1.60262
wandb: 
wandb: ğŸš€ View run al_73_53 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hto1k212
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_225635-hto1k212/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1974916458129883, Uncertainty Bias: -0.07758495211601257
0.00032043457 0.002175331
2.9425888 13.795419
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2498 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3221 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_233941-7hzfmk4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_54
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/7hzfmk4g
Training model 54. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8655152197375333, Training Loss Force: 5.111607599220019, time: 0.6736495494842529
Validation Loss Energy: 1.514690053653259, Validation Loss Force: 5.08797862832351, time: 0.06186318397521973
Test Loss Energy: 6.71921527921714, Test Loss Force: 8.772595468358627, time: 9.64001727104187


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1756623032186724, Training Loss Force: 4.6103445067307085, time: 0.6769759654998779
Validation Loss Energy: 1.699315563659133, Validation Loss Force: 4.4992654547581985, time: 0.06629061698913574
Test Loss Energy: 6.793162746617981, Test Loss Force: 8.704891513239213, time: 9.652651071548462


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.168686611110323, Training Loss Force: 4.5977980236199905, time: 0.6849346160888672
Validation Loss Energy: 2.040348947487755, Validation Loss Force: 4.713522605691127, time: 0.061730146408081055
Test Loss Energy: 7.073032481098188, Test Loss Force: 8.772828993499775, time: 9.823811769485474


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0872290536836022, Training Loss Force: 4.548636325800746, time: 0.6635160446166992
Validation Loss Energy: 1.9709570585255438, Validation Loss Force: 4.619752620296309, time: 0.0645296573638916
Test Loss Energy: 7.509373915879695, Test Loss Force: 8.69203350089472, time: 9.639755964279175


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.113362145502351, Training Loss Force: 4.479483337750557, time: 0.6852848529815674
Validation Loss Energy: 1.777770921869903, Validation Loss Force: 4.488688447657483, time: 0.06788945198059082
Test Loss Energy: 6.66447239844838, Test Loss Force: 8.682626972229583, time: 9.73705506324768


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.078878667439752, Training Loss Force: 4.489454929167315, time: 0.7091083526611328
Validation Loss Energy: 1.8875815471990671, Validation Loss Force: 4.821029273367376, time: 0.0714406967163086
Test Loss Energy: 6.811639109546698, Test Loss Force: 8.675924831455967, time: 9.895208597183228


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1035924878461767, Training Loss Force: 4.468611326617215, time: 0.6682703495025635
Validation Loss Energy: 2.3366926893959565, Validation Loss Force: 4.787473033076058, time: 0.06532907485961914
Test Loss Energy: 7.45131219928897, Test Loss Force: 8.660192479868677, time: 9.69191312789917


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.103435831955584, Training Loss Force: 4.474057422897865, time: 0.6649131774902344
Validation Loss Energy: 2.194519219063075, Validation Loss Force: 4.716891144530722, time: 0.06229376792907715
Test Loss Energy: 7.7198972573091424, Test Loss Force: 8.689900530995542, time: 9.671130895614624


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.135108209808031, Training Loss Force: 4.476589355739527, time: 0.6326065063476562
Validation Loss Energy: 2.2194170809495635, Validation Loss Force: 4.5457247040485935, time: 0.06913113594055176
Test Loss Energy: 6.740485815832892, Test Loss Force: 8.74454014923933, time: 9.844716787338257


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1201186062591475, Training Loss Force: 4.484026125046681, time: 0.6674253940582275
Validation Loss Energy: 2.0274636963530654, Validation Loss Force: 4.739218402462048, time: 0.06362509727478027
Test Loss Energy: 6.606131501380944, Test Loss Force: 8.688322317374402, time: 9.641666889190674


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0736061995859716, Training Loss Force: 4.784144585544639, time: 0.6755423545837402
Validation Loss Energy: 1.8023834889131716, Validation Loss Force: 4.810705663754726, time: 0.06104421615600586
Test Loss Energy: 7.887894813900692, Test Loss Force: 8.888305142629502, time: 9.642983436584473


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.821874540935589, Training Loss Force: 5.559933958947212, time: 0.6674773693084717
Validation Loss Energy: 2.819195352383464, Validation Loss Force: 5.144743228356589, time: 0.06190037727355957
Test Loss Energy: 7.139221980583846, Test Loss Force: 8.74082454497869, time: 9.83076810836792


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.193202229624691, Training Loss Force: 4.882699111756601, time: 0.7290685176849365
Validation Loss Energy: 2.1793777171399853, Validation Loss Force: 4.7952804813397245, time: 0.061484575271606445
Test Loss Energy: 7.882422128575344, Test Loss Force: 8.756126769724473, time: 9.693522214889526


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.167483089807538, Training Loss Force: 4.576822340249673, time: 0.6788654327392578
Validation Loss Energy: 1.950250497972854, Validation Loss Force: 4.581917792365989, time: 0.06360459327697754
Test Loss Energy: 7.586228719525983, Test Loss Force: 8.696338467249769, time: 9.724624633789062


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1106491554902767, Training Loss Force: 4.485328391969252, time: 0.6861295700073242
Validation Loss Energy: 2.268173273814777, Validation Loss Force: 4.87973309899234, time: 0.06262493133544922
Test Loss Energy: 6.632704193730477, Test Loss Force: 8.696573922967385, time: 9.850284576416016


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0716715732101907, Training Loss Force: 4.459580897939792, time: 0.6523575782775879
Validation Loss Energy: 1.92000412320118, Validation Loss Force: 4.704335276730147, time: 0.07086610794067383
Test Loss Energy: 6.814316506673475, Test Loss Force: 8.668429261059252, time: 9.67870020866394


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.090360968538966, Training Loss Force: 4.46442401703518, time: 0.6687772274017334
Validation Loss Energy: 2.4107439859039936, Validation Loss Force: 4.841853514563689, time: 0.06245541572570801
Test Loss Energy: 7.910300872227727, Test Loss Force: 8.72844904618116, time: 10.48266887664795


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.091693923071515, Training Loss Force: 4.460998844199151, time: 0.7229132652282715
Validation Loss Energy: 1.9580885075767984, Validation Loss Force: 4.824064031157226, time: 0.09262824058532715
Test Loss Energy: 7.585462474191598, Test Loss Force: 8.671344757954028, time: 9.824181318283081


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.080390001682008, Training Loss Force: 4.475457957516203, time: 0.6506326198577881
Validation Loss Energy: 2.414184558212297, Validation Loss Force: 4.903192184192417, time: 0.061537742614746094
Test Loss Energy: 6.87639620756178, Test Loss Force: 8.74637197718865, time: 9.669735431671143


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.011202404872492, Training Loss Force: 4.4684892278918795, time: 0.6802787780761719
Validation Loss Energy: 1.699132139950175, Validation Loss Force: 4.78542625828669, time: 0.06287240982055664
Test Loss Energy: 6.810669249016759, Test Loss Force: 8.714643596439462, time: 9.865590810775757

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–†â–â–‚â–†â–‡â–‚â–â–ˆâ–„â–ˆâ–†â–â–‚â–ˆâ–†â–‚â–‚
wandb:   test_error_force â–„â–‚â–„â–‚â–‚â–â–â–‚â–„â–‚â–ˆâ–ƒâ–„â–‚â–‚â–â–ƒâ–â–„â–ƒ
wandb:          test_loss â–ƒâ–„â–‡â–‡â–„â–†â–‡â–ˆâ–…â–„â–„â–â–ƒâ–†â–„â–…â–ˆâ–‡â–…â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–…â–ˆâ–…â–‚â–â–â–â–â–â–
wandb:  train_error_force â–…â–‚â–‚â–‚â–â–â–â–â–â–â–ƒâ–ˆâ–„â–‚â–â–â–â–â–â–
wandb:         train_loss â–†â–‚â–‚â–â–â–â–â–â–â–â–…â–ˆâ–†â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–„â–ƒâ–‚â–ƒâ–…â–…â–…â–„â–ƒâ–ˆâ–…â–ƒâ–…â–ƒâ–†â–ƒâ–†â–‚
wandb:  valid_error_force â–‡â–â–ƒâ–‚â–â–…â–„â–ƒâ–‚â–„â–„â–ˆâ–„â–‚â–…â–ƒâ–…â–…â–…â–„
wandb:         valid_loss â–ƒâ–â–ƒâ–‚â–â–ƒâ–„â–…â–„â–ƒâ–‚â–ˆâ–ƒâ–‚â–‡â–ƒâ–„â–„â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1305
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.81067
wandb:   test_error_force 8.71464
wandb:          test_loss 6.60309
wandb: train_error_energy 2.0112
wandb:  train_error_force 4.46849
wandb:         train_loss 1.0624
wandb: valid_error_energy 1.69913
wandb:  valid_error_force 4.78543
wandb:         valid_loss 1.10415
wandb: 
wandb: ğŸš€ View run al_73_54 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/7hzfmk4g
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_233941-7hzfmk4g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5670504570007324, Uncertainty Bias: 0.06208565831184387
4.196167e-05 0.0022115707
3.0421984 10.473232
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1945 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2537 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3693 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2247 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2597 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_002214-tz6u62bc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tz6u62bc
Training model 55. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.861887302510674, Training Loss Force: 5.957782624478908, time: 0.7435140609741211
Validation Loss Energy: 1.957755227532631, Validation Loss Force: 5.143459763399461, time: 0.07062339782714844
Test Loss Energy: 6.801341554555736, Test Loss Force: 8.904255024485261, time: 10.344903469085693


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1353146675539443, Training Loss Force: 4.762689739896105, time: 0.6626906394958496
Validation Loss Energy: 2.2021098989131804, Validation Loss Force: 4.862902428928242, time: 0.06232285499572754
Test Loss Energy: 7.57646067409565, Test Loss Force: 8.748129380016103, time: 10.515189409255981


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1215771000268844, Training Loss Force: 4.514369086633617, time: 0.7412402629852295
Validation Loss Energy: 2.1268509562922038, Validation Loss Force: 4.7548021253089505, time: 0.06960225105285645
Test Loss Energy: 7.813027536398042, Test Loss Force: 8.806662094311783, time: 10.335585594177246


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.036911176194379, Training Loss Force: 4.489427459398044, time: 0.8237671852111816
Validation Loss Energy: 2.155987325371428, Validation Loss Force: 4.714994894084001, time: 0.06837773323059082
Test Loss Energy: 7.044110316822829, Test Loss Force: 8.760646375146512, time: 10.46406626701355


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.106690106222113, Training Loss Force: 4.491291819278304, time: 0.6826596260070801
Validation Loss Energy: 2.1113359268768206, Validation Loss Force: 4.64764326683864, time: 0.06769967079162598
Test Loss Energy: 6.736911850133591, Test Loss Force: 8.699201805937273, time: 10.559977293014526


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0974452906047993, Training Loss Force: 4.472915836203376, time: 0.7173349857330322
Validation Loss Energy: 2.5302760121406465, Validation Loss Force: 4.724156393424055, time: 0.06651115417480469
Test Loss Energy: 8.076676919456036, Test Loss Force: 8.757856006653679, time: 10.525807619094849


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.140194874639515, Training Loss Force: 4.4802573031160735, time: 0.7247433662414551
Validation Loss Energy: 2.2368806880609613, Validation Loss Force: 4.8685128007290395, time: 0.06990885734558105
Test Loss Energy: 7.909027533470609, Test Loss Force: 8.801929001640117, time: 10.57420563697815


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0868578343470894, Training Loss Force: 4.498288616076923, time: 0.6763291358947754
Validation Loss Energy: 1.7534752130212896, Validation Loss Force: 4.669388022284218, time: 0.06474876403808594
Test Loss Energy: 6.766064643685395, Test Loss Force: 8.738122428079295, time: 10.6038076877594


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.040692543630525, Training Loss Force: 4.487181911663774, time: 0.7319900989532471
Validation Loss Energy: 1.7482734947705572, Validation Loss Force: 4.763633406305592, time: 0.06975817680358887
Test Loss Energy: 6.815925280760541, Test Loss Force: 8.69251370614373, time: 10.228507995605469


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0343745021291957, Training Loss Force: 4.48846294355316, time: 0.701894998550415
Validation Loss Energy: 2.4350281716243054, Validation Loss Force: 4.647886866884285, time: 0.0680701732635498
Test Loss Energy: 7.963909168594071, Test Loss Force: 8.75151402098263, time: 10.520503282546997


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0933614923053683, Training Loss Force: 4.490448315967801, time: 0.7106521129608154
Validation Loss Energy: 2.3064330658100998, Validation Loss Force: 4.655343388573969, time: 0.0637209415435791
Test Loss Energy: 7.9595107254984, Test Loss Force: 8.746500714929207, time: 10.639502763748169


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0273917524951117, Training Loss Force: 4.503916736237937, time: 0.719810962677002
Validation Loss Energy: 2.266794283794046, Validation Loss Force: 5.008002996518918, time: 0.0707404613494873
Test Loss Energy: 6.9142223630534785, Test Loss Force: 8.82215555804551, time: 10.252424478530884


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0419810485136876, Training Loss Force: 4.492660930392292, time: 0.7047810554504395
Validation Loss Energy: 1.809107095109034, Validation Loss Force: 4.674625645934731, time: 0.07956957817077637
Test Loss Energy: 6.758041538605187, Test Loss Force: 8.78683141800009, time: 10.702965259552002


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.065401476177648, Training Loss Force: 4.532471327863876, time: 0.7193586826324463
Validation Loss Energy: 2.2013141907202076, Validation Loss Force: 4.871705876281643, time: 0.06771206855773926
Test Loss Energy: 7.862944248792138, Test Loss Force: 8.893294810779244, time: 11.431556701660156


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1067328804219496, Training Loss Force: 4.511109394989696, time: 0.6994848251342773
Validation Loss Energy: 2.1876339550672688, Validation Loss Force: 4.85012277863601, time: 0.06376981735229492
Test Loss Energy: 7.982504007829721, Test Loss Force: 8.692735908966839, time: 10.452771186828613


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1195310882866627, Training Loss Force: 4.51035752274822, time: 0.709665060043335
Validation Loss Energy: 1.5612427683176575, Validation Loss Force: 4.723988055549732, time: 0.0695950984954834
Test Loss Energy: 6.8003055018332965, Test Loss Force: 8.70292155580777, time: 10.99556040763855


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.07220935721429, Training Loss Force: 4.48637426351672, time: 0.6742260456085205
Validation Loss Energy: 1.7897764628763184, Validation Loss Force: 5.114477815372938, time: 0.06466007232666016
Test Loss Energy: 6.921246786521939, Test Loss Force: 8.769973689554439, time: 10.50215220451355


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.075825789269283, Training Loss Force: 4.502354489510107, time: 0.7361679077148438
Validation Loss Energy: 2.516412519780609, Validation Loss Force: 5.081018658829245, time: 0.06762146949768066
Test Loss Energy: 8.160555176619319, Test Loss Force: 8.728542338724269, time: 10.425552606582642


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0621755922272254, Training Loss Force: 4.501631216676497, time: 0.669701337814331
Validation Loss Energy: 2.2767739809108107, Validation Loss Force: 4.6854320022557525, time: 0.06848311424255371
Test Loss Energy: 7.797087132553577, Test Loss Force: 8.778824739141172, time: 10.963866233825684


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1441970918517375, Training Loss Force: 4.480180645189372, time: 0.7253358364105225
Validation Loss Energy: 1.9027062932689256, Validation Loss Force: 4.63432921059618, time: 0.06794571876525879
Test Loss Energy: 6.743932074365068, Test Loss Force: 8.781836886103347, time: 10.20836353302002

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–†â–ƒâ–â–ˆâ–‡â–â–â–‡â–‡â–‚â–â–‡â–‡â–â–‚â–ˆâ–†â–
wandb:   test_error_force â–ˆâ–ƒâ–…â–ƒâ–â–ƒâ–…â–ƒâ–â–ƒâ–ƒâ–…â–„â–ˆâ–â–â–„â–‚â–„â–„
wandb:          test_loss â–â–†â–‡â–†â–…â–ˆâ–ˆâ–…â–†â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–…â–†â–ˆâ–ˆâ–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–†â–…â–…â–…â–ˆâ–†â–‚â–‚â–‡â–†â–†â–ƒâ–†â–†â–â–ƒâ–ˆâ–†â–ƒ
wandb:  valid_error_force â–ˆâ–„â–ƒâ–‚â–â–‚â–„â–â–ƒâ–â–â–†â–‚â–„â–„â–‚â–ˆâ–‡â–‚â–
wandb:         valid_loss â–…â–„â–ƒâ–†â–ƒâ–…â–„â–â–‚â–…â–ƒâ–†â–‚â–„â–„â–â–†â–ˆâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1309
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.74393
wandb:   test_error_force 8.78184
wandb:          test_loss 6.48373
wandb: train_error_energy 2.1442
wandb:  train_error_force 4.48018
wandb:         train_loss 1.10752
wandb: valid_error_energy 1.90271
wandb:  valid_error_force 4.63433
wandb:         valid_loss 1.2207
wandb: 
wandb: ğŸš€ View run al_73_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tz6u62bc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_002214-tz6u62bc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9781653881072998, Uncertainty Bias: 0.11529923975467682
0.00017642975 0.032642365
3.3553658 14.660092
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3883 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_010554-j5a66dpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_56
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/j5a66dpu
Training model 56. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.795981593657258, Training Loss Force: 5.867397850954856, time: 0.7643206119537354
Validation Loss Energy: 2.3155764176147597, Validation Loss Force: 5.017383379629418, time: 0.07094192504882812
Test Loss Energy: 7.617419206230259, Test Loss Force: 8.961187813169358, time: 10.70774245262146


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.155643035424186, Training Loss Force: 4.728884316537629, time: 0.6697196960449219
Validation Loss Energy: 1.709624588442725, Validation Loss Force: 4.710587381009507, time: 0.06660962104797363
Test Loss Energy: 6.727627619290885, Test Loss Force: 8.700676090191811, time: 9.455862045288086


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0689865363223627, Training Loss Force: 4.502959628215372, time: 0.6508979797363281
Validation Loss Energy: 1.8530551931062287, Validation Loss Force: 4.797039344923409, time: 0.07047128677368164
Test Loss Energy: 6.977655481984946, Test Loss Force: 8.701891775127242, time: 9.895025968551636


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0895073908073485, Training Loss Force: 4.497581484040914, time: 0.7079389095306396
Validation Loss Energy: 2.167329089653833, Validation Loss Force: 4.588546430171113, time: 0.0652167797088623
Test Loss Energy: 7.807084168135641, Test Loss Force: 8.74310257391708, time: 9.415620565414429


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.093530441162102, Training Loss Force: 4.482737956882714, time: 0.6814098358154297
Validation Loss Energy: 1.9885454716932336, Validation Loss Force: 4.681676241771389, time: 0.060518741607666016
Test Loss Energy: 7.536021529984891, Test Loss Force: 8.755792784658494, time: 9.460951566696167


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.096321650500377, Training Loss Force: 4.496581417166049, time: 0.6613101959228516
Validation Loss Energy: 2.0742592873883847, Validation Loss Force: 5.012807751349747, time: 0.06286263465881348
Test Loss Energy: 6.593169855784839, Test Loss Force: 8.782536510228239, time: 9.618682146072388


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0746820926488634, Training Loss Force: 4.498738418613608, time: 0.7374176979064941
Validation Loss Energy: 1.817080042215411, Validation Loss Force: 4.869172346739277, time: 0.0690453052520752
Test Loss Energy: 7.130319726420007, Test Loss Force: 8.721132641674618, time: 10.068056106567383


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.047832712204348, Training Loss Force: 4.484282075083493, time: 0.7126970291137695
Validation Loss Energy: 2.2653568431225093, Validation Loss Force: 4.5401933797946015, time: 0.07041525840759277
Test Loss Energy: 8.124238617677602, Test Loss Force: 8.88509557790203, time: 10.778427362442017


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.072841172769428, Training Loss Force: 4.50727970291793, time: 0.6972675323486328
Validation Loss Energy: 2.475355446639568, Validation Loss Force: 4.827341498316137, time: 0.06932425498962402
Test Loss Energy: 7.945942692361771, Test Loss Force: 8.779209711944146, time: 10.891356229782104


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.033216815369266, Training Loss Force: 4.489152240333676, time: 0.7409970760345459
Validation Loss Energy: 1.686596702043738, Validation Loss Force: 4.666286241081444, time: 0.06935381889343262
Test Loss Energy: 6.9422816878857905, Test Loss Force: 8.75815400092451, time: 10.798256397247314


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0925635981530966, Training Loss Force: 4.4787786930918365, time: 0.6631741523742676
Validation Loss Energy: 1.6183221111885056, Validation Loss Force: 4.764005263779291, time: 0.0708155632019043
Test Loss Energy: 6.914640934415543, Test Loss Force: 8.743888066725805, time: 11.04622197151184


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.015942623667686, Training Loss Force: 4.506800725292175, time: 0.7754278182983398
Validation Loss Energy: 1.9862899445795583, Validation Loss Force: 4.751876252731458, time: 0.07598376274108887
Test Loss Energy: 7.940721047262641, Test Loss Force: 8.832202464521423, time: 11.619158506393433


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.014824566584777, Training Loss Force: 4.499950010315193, time: 0.7141022682189941
Validation Loss Energy: 2.116087241112628, Validation Loss Force: 4.858021075911214, time: 0.06476116180419922
Test Loss Energy: 7.920423912898635, Test Loss Force: 8.79937508679573, time: 10.68415904045105


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0809589973832208, Training Loss Force: 4.507885645404502, time: 0.7351720333099365
Validation Loss Energy: 1.9151714790598227, Validation Loss Force: 4.7884434252140124, time: 0.07199478149414062
Test Loss Energy: 6.810559315743866, Test Loss Force: 8.768144207208897, time: 11.056575059890747


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0946615026662294, Training Loss Force: 4.492022695448606, time: 0.7138841152191162
Validation Loss Energy: 1.7958229321994148, Validation Loss Force: 4.764542119090123, time: 0.07541584968566895
Test Loss Energy: 7.289774999752767, Test Loss Force: 8.708874283169141, time: 10.644168615341187


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0742259223177015, Training Loss Force: 4.510564952635038, time: 0.7106006145477295
Validation Loss Energy: 2.7887771883657066, Validation Loss Force: 4.954289186454195, time: 0.07377314567565918
Test Loss Energy: 8.11862921582827, Test Loss Force: 8.717925105451403, time: 10.85914921760559


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0975046455095763, Training Loss Force: 4.495704502621748, time: 0.9105088710784912
Validation Loss Energy: 1.845577573514968, Validation Loss Force: 4.630057525700701, time: 0.06808662414550781
Test Loss Energy: 7.813272733599342, Test Loss Force: 8.845811401164093, time: 10.769145011901855


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0932459949055664, Training Loss Force: 4.486588319168368, time: 0.774000883102417
Validation Loss Energy: 1.7170217131377326, Validation Loss Force: 4.6604545361495955, time: 0.06907224655151367
Test Loss Energy: 6.809771500647503, Test Loss Force: 8.734797998715122, time: 10.898963212966919


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.034994103467037, Training Loss Force: 4.523817438143173, time: 0.6675257682800293
Validation Loss Energy: 1.7935499255577838, Validation Loss Force: 4.743279887683771, time: 0.06836819648742676
Test Loss Energy: 6.996203050076466, Test Loss Force: 8.737549732362424, time: 10.97963261604309


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.020230055616546, Training Loss Force: 4.502594255301679, time: 0.7000372409820557
Validation Loss Energy: 2.3671902349642373, Validation Loss Force: 5.068163746365688, time: 0.07812881469726562
Test Loss Energy: 7.6560913575847955, Test Loss Force: 8.782542171387258, time: 10.585234880447388

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–ƒâ–‡â–…â–â–ƒâ–ˆâ–‡â–ƒâ–‚â–‡â–‡â–‚â–„â–ˆâ–‡â–‚â–ƒâ–†
wandb:   test_error_force â–ˆâ–â–â–‚â–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–‚â–…â–„â–ƒâ–â–â–…â–‚â–‚â–ƒ
wandb:          test_loss â–â–„â–…â–‡â–†â–…â–†â–ˆâ–‡â–…â–…â–‡â–‡â–…â–†â–‡â–‡â–…â–†â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–‚â–„â–ƒâ–„â–‚â–…â–†â–â–â–ƒâ–„â–ƒâ–‚â–ˆâ–‚â–‚â–‚â–…
wandb:  valid_error_force â–‡â–ƒâ–„â–‚â–ƒâ–‡â–…â–â–…â–ƒâ–„â–„â–…â–„â–„â–†â–‚â–ƒâ–„â–ˆ
wandb:         valid_loss â–…â–â–‚â–‚â–‚â–„â–ƒâ–ƒâ–‡â–â–â–ƒâ–ƒâ–‚â–‚â–ˆâ–â–â–‚â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1310
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.65609
wandb:   test_error_force 8.78254
wandb:          test_loss 7.20283
wandb: train_error_energy 2.02023
wandb:  train_error_force 4.50259
wandb:         train_loss 1.08524
wandb: valid_error_energy 2.36719
wandb:  valid_error_force 5.06816
wandb:         valid_loss 1.59895
wandb: 
wandb: ğŸš€ View run al_73_56 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/j5a66dpu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_010554-j5a66dpu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.613210678100586, Uncertainty Bias: 0.0531136691570282
0.0007133484 0.031562805
2.9588327 9.313924
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1825 steps.
Found uncertainty sample 9 after 1928 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3391 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 401 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3870 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2676 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2405 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3630 steps.
Found uncertainty sample 59 after 2956 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3892 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2230 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3257 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 935 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_014800-dlz9r7yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_57
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dlz9r7yr
Training model 57. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.915647902897233, Training Loss Force: 4.873661473357401, time: 0.7806382179260254
Validation Loss Energy: 2.9626477229559818, Validation Loss Force: 5.610590016559552, time: 0.07140159606933594
Test Loss Energy: 7.4805025994444865, Test Loss Force: 8.933513731607258, time: 9.565646648406982


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.6527278458713868, Training Loss Force: 5.041081367616489, time: 0.6928908824920654
Validation Loss Energy: 2.4628854177947472, Validation Loss Force: 6.409893870900944, time: 0.06024599075317383
Test Loss Energy: 7.740115137778495, Test Loss Force: 9.605680489139706, time: 9.428381204605103


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.537193535996669, Training Loss Force: 5.384367272525317, time: 0.6988365650177002
Validation Loss Energy: 5.467042566261722, Validation Loss Force: 4.9883457643164135, time: 0.06305098533630371
Test Loss Energy: 7.384210334545302, Test Loss Force: 9.143732706464556, time: 9.498037815093994


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.657134708836494, Training Loss Force: 4.812780855368432, time: 0.7232954502105713
Validation Loss Energy: 4.995609454525724, Validation Loss Force: 4.887836029212652, time: 0.06577396392822266
Test Loss Energy: 7.302976622066217, Test Loss Force: 8.76860706524905, time: 9.52736210823059


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.4127113917392435, Training Loss Force: 4.572745763956322, time: 0.725553035736084
Validation Loss Energy: 4.261306954594426, Validation Loss Force: 4.758861161170067, time: 0.06365418434143066
Test Loss Energy: 9.441517057416394, Test Loss Force: 8.741977868563577, time: 9.293291330337524


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.557744395149068, Training Loss Force: 4.585975863327474, time: 0.7259273529052734
Validation Loss Energy: 5.814725964133478, Validation Loss Force: 4.739261377607212, time: 0.06172537803649902
Test Loss Energy: 10.561409516423163, Test Loss Force: 8.751890017071345, time: 9.588952779769897


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.508021462980224, Training Loss Force: 4.545517208214468, time: 0.6932809352874756
Validation Loss Energy: 3.1216612154570904, Validation Loss Force: 4.780089769535385, time: 0.06076622009277344
Test Loss Energy: 7.04604059950886, Test Loss Force: 8.72049902554471, time: 9.426335334777832


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.478317717012238, Training Loss Force: 4.5523319125992465, time: 0.6923131942749023
Validation Loss Energy: 4.478721999354901, Validation Loss Force: 4.674299880974239, time: 0.06253337860107422
Test Loss Energy: 7.371598365778023, Test Loss Force: 8.686908328660321, time: 9.719830751419067


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.3820252029911915, Training Loss Force: 4.543820511735668, time: 0.7270777225494385
Validation Loss Energy: 3.9748716000090054, Validation Loss Force: 4.546080974682079, time: 0.06104326248168945
Test Loss Energy: 9.113118655386154, Test Loss Force: 8.725998575727646, time: 9.725106477737427


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.360911571429868, Training Loss Force: 4.539750353020547, time: 0.7360131740570068
Validation Loss Energy: 5.023549978956742, Validation Loss Force: 4.860618956836753, time: 0.06372380256652832
Test Loss Energy: 10.02231050267556, Test Loss Force: 8.691320143562818, time: 10.23384952545166


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.354849483456678, Training Loss Force: 4.519790174143361, time: 0.7249274253845215
Validation Loss Energy: 3.3538544774290746, Validation Loss Force: 4.7320827470116456, time: 0.06168532371520996
Test Loss Energy: 6.971292159713326, Test Loss Force: 8.663638591509162, time: 9.44095253944397


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.449383876124528, Training Loss Force: 4.535937631647996, time: 0.7238562107086182
Validation Loss Energy: 5.194864939759205, Validation Loss Force: 4.564652249459893, time: 0.06151270866394043
Test Loss Energy: 7.4104594711386955, Test Loss Force: 8.61956707942929, time: 9.738152265548706


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.447044821572898, Training Loss Force: 4.502475580405406, time: 0.6937997341156006
Validation Loss Energy: 4.232902164994147, Validation Loss Force: 4.785120310880185, time: 0.06914019584655762
Test Loss Energy: 9.019328900235438, Test Loss Force: 8.719736653021338, time: 9.546263456344604


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.511442488118503, Training Loss Force: 4.503777442075305, time: 0.6949462890625
Validation Loss Energy: 5.739927612640853, Validation Loss Force: 4.6102134740847625, time: 0.0605776309967041
Test Loss Energy: 10.201933627034073, Test Loss Force: 8.69128873672098, time: 9.424055814743042


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.516029403603213, Training Loss Force: 4.546653329816747, time: 0.724895715713501
Validation Loss Energy: 3.5229402974116537, Validation Loss Force: 4.848955992311348, time: 0.06412076950073242
Test Loss Energy: 6.738336034996103, Test Loss Force: 8.666101284283753, time: 9.701253652572632


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4048165829473245, Training Loss Force: 4.521598979235488, time: 0.7011969089508057
Validation Loss Energy: 5.362526567884429, Validation Loss Force: 4.602626913613857, time: 0.06810331344604492
Test Loss Energy: 7.2885994302378165, Test Loss Force: 8.697960272728002, time: 8.794664859771729


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.478353190327843, Training Loss Force: 4.520952793374006, time: 0.6563265323638916
Validation Loss Energy: 3.7310016793591405, Validation Loss Force: 4.790852037365513, time: 0.06068015098571777
Test Loss Energy: 8.676554283323101, Test Loss Force: 8.749722362080913, time: 9.231889247894287


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.404369288347973, Training Loss Force: 4.5131700931954155, time: 0.7031650543212891
Validation Loss Energy: 5.670548582821819, Validation Loss Force: 4.6672837988552, time: 0.06519103050231934
Test Loss Energy: 9.869802851774633, Test Loss Force: 8.621788809213776, time: 9.85714602470398


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.444700733108077, Training Loss Force: 4.513326963608723, time: 0.7348556518554688
Validation Loss Energy: 2.9513320109636507, Validation Loss Force: 4.735873689221066, time: 0.056944847106933594
Test Loss Energy: 6.861265200233726, Test Loss Force: 8.635048740532477, time: 7.732193470001221


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.510761443932391, Training Loss Force: 4.519781458236792, time: 0.7053492069244385
Validation Loss Energy: 5.229187161912513, Validation Loss Force: 4.772630353146804, time: 0.06254243850708008
Test Loss Energy: 7.3047477044735585, Test Loss Force: 8.69105585510532, time: 7.703311920166016

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.057 MB of 0.058 MB uploadedwandb: - 0.057 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–‚â–†â–ˆâ–‚â–‚â–…â–‡â–â–‚â–…â–‡â–â–‚â–…â–‡â–â–‚
wandb:   test_error_force â–ƒâ–ˆâ–…â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚
wandb:          test_loss â–†â–ˆâ–…â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–
wandb: train_error_energy â–…â–â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:  train_error_force â–„â–…â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–â–‡â–†â–…â–ˆâ–‚â–…â–„â–†â–ƒâ–‡â–…â–ˆâ–ƒâ–‡â–„â–ˆâ–‚â–‡
wandb:  valid_error_force â–…â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚
wandb:         valid_loss â–ƒâ–ƒâ–ˆâ–„â–‚â–„â–â–‚â–â–ƒâ–â–ƒâ–‚â–„â–‚â–ƒâ–‚â–„â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1321
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.30475
wandb:   test_error_force 8.69106
wandb:          test_loss 4.59868
wandb: train_error_energy 4.51076
wandb:  train_error_force 4.51978
wandb:         train_loss 1.88362
wandb: valid_error_energy 5.22919
wandb:  valid_error_force 4.77263
wandb:         valid_loss 2.2115
wandb: 
wandb: ğŸš€ View run al_73_57 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dlz9r7yr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_014800-dlz9r7yr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1015655994415283, Uncertainty Bias: -0.064891517162323
0.00025558472 0.18164301
2.869285 13.111611
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2255 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1329 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3542 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_023132-rq6vr5bl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_58
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rq6vr5bl
Training model 58. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.3157786068397535, Training Loss Force: 4.88187459299507, time: 0.6995401382446289
Validation Loss Energy: 2.1068177472368, Validation Loss Force: 4.98007338287605, time: 0.06102561950683594
Test Loss Energy: 7.023339571014471, Test Loss Force: 8.811620985155487, time: 8.456898212432861


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.268575342720097, Training Loss Force: 4.831241590820234, time: 0.7134013175964355
Validation Loss Energy: 2.0327142348140423, Validation Loss Force: 4.922156470012794, time: 0.0591278076171875
Test Loss Energy: 6.481239012153974, Test Loss Force: 8.733281703437845, time: 8.43655276298523


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.1978947441571135, Training Loss Force: 5.0356364177845325, time: 0.7042176723480225
Validation Loss Energy: 9.922960127705576, Validation Loss Force: 5.847039487921373, time: 0.06003880500793457
Test Loss Energy: 14.013137143236507, Test Loss Force: 9.587422882908468, time: 8.637638807296753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.6924539629040174, Training Loss Force: 4.819271841228202, time: 0.6671280860900879
Validation Loss Energy: 2.323274757996921, Validation Loss Force: 4.8630028527130555, time: 0.06112957000732422
Test Loss Energy: 6.681724255945554, Test Loss Force: 8.714940131119873, time: 8.451975584030151


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.161161674869529, Training Loss Force: 4.7925810844902275, time: 0.6661732196807861
Validation Loss Energy: 5.553038058426472, Validation Loss Force: 5.877564533129176, time: 0.05852866172790527
Test Loss Energy: 7.5239532166809475, Test Loss Force: 9.30909075932158, time: 8.456918954849243


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.465293361281099, Training Loss Force: 5.029088534656331, time: 0.6897156238555908
Validation Loss Energy: 3.8886834990330286, Validation Loss Force: 5.118472499850883, time: 0.05850672721862793
Test Loss Energy: 9.0402441408324, Test Loss Force: 8.652966607274156, time: 8.726656913757324


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.320769239045237, Training Loss Force: 4.534048220325043, time: 0.7136051654815674
Validation Loss Energy: 5.3145153146469175, Validation Loss Force: 4.680255389951224, time: 0.05967068672180176
Test Loss Energy: 9.905703949727487, Test Loss Force: 8.651294811989757, time: 8.731491565704346


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.329304767701269, Training Loss Force: 4.502498112402315, time: 0.6938731670379639
Validation Loss Energy: 3.3775549359833366, Validation Loss Force: 4.753498397459543, time: 0.05861544609069824
Test Loss Energy: 6.842835942904538, Test Loss Force: 8.60992611629351, time: 9.4030122756958


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.350482376879701, Training Loss Force: 4.555128403799661, time: 0.6529049873352051
Validation Loss Energy: 5.112104384946494, Validation Loss Force: 4.72772778385559, time: 0.06296849250793457
Test Loss Energy: 7.3233343504172845, Test Loss Force: 8.606164285451854, time: 8.602814674377441


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.263646608232091, Training Loss Force: 4.476703673199748, time: 0.691697359085083
Validation Loss Energy: 3.9811548779687955, Validation Loss Force: 4.580864344636605, time: 0.059034109115600586
Test Loss Energy: 8.753658247914649, Test Loss Force: 8.613570699588859, time: 8.793460607528687


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.365587766638802, Training Loss Force: 4.48931995856192, time: 0.720285177230835
Validation Loss Energy: 5.473628674259975, Validation Loss Force: 4.780691866905974, time: 0.061092376708984375
Test Loss Energy: 9.72055602846864, Test Loss Force: 8.643596503084387, time: 8.576213598251343


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.299977989994046, Training Loss Force: 4.505501622288686, time: 0.7118191719055176
Validation Loss Energy: 3.6539902192251397, Validation Loss Force: 4.861344635583332, time: 0.06190061569213867
Test Loss Energy: 6.836180017053871, Test Loss Force: 8.580006396576007, time: 8.594561576843262


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.3232017775266325, Training Loss Force: 4.483195443703176, time: 0.6780755519866943
Validation Loss Energy: 4.865048959494986, Validation Loss Force: 4.9815496793135505, time: 0.05953693389892578
Test Loss Energy: 7.213987049451093, Test Loss Force: 8.572632904829998, time: 8.779408931732178


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.402766468120767, Training Loss Force: 4.496775419922337, time: 0.6719670295715332
Validation Loss Energy: 4.319793455132964, Validation Loss Force: 4.6538352504486, time: 0.06213212013244629
Test Loss Energy: 9.529734749185872, Test Loss Force: 8.725845356039107, time: 8.642245292663574


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.421924804800176, Training Loss Force: 4.501319482199749, time: 0.6837215423583984
Validation Loss Energy: 5.310381239283622, Validation Loss Force: 4.760402031659888, time: 0.06494021415710449
Test Loss Energy: 9.879365831745444, Test Loss Force: 8.659357780676123, time: 8.590293169021606


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.469447463613412, Training Loss Force: 4.484637141596717, time: 0.6872076988220215
Validation Loss Energy: 3.492720197599199, Validation Loss Force: 4.691851108394559, time: 0.0591127872467041
Test Loss Energy: 6.951882104252486, Test Loss Force: 8.642729315181054, time: 8.79589319229126


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.334886717376082, Training Loss Force: 4.477930718036616, time: 0.7039749622344971
Validation Loss Energy: 5.386981874843386, Validation Loss Force: 4.882082703820171, time: 0.06180930137634277
Test Loss Energy: 7.343968633847596, Test Loss Force: 8.652347442488402, time: 8.615492105484009


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.3770908653207234, Training Loss Force: 4.477144070357222, time: 0.6677238941192627
Validation Loss Energy: 3.9454180387314075, Validation Loss Force: 4.695961803497532, time: 0.05873513221740723
Test Loss Energy: 9.073102603637187, Test Loss Force: 8.635872369221316, time: 8.649780750274658


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.368901380422402, Training Loss Force: 4.496280691493257, time: 0.6889908313751221
Validation Loss Energy: 5.485394734599945, Validation Loss Force: 4.923708028621619, time: 0.060768842697143555
Test Loss Energy: 10.011735331720944, Test Loss Force: 8.6685693957295, time: 8.570842266082764


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.493330092037275, Training Loss Force: 4.471417422849082, time: 0.6497297286987305
Validation Loss Energy: 3.3612576698583085, Validation Loss Force: 4.771315269170954, time: 0.06093859672546387
Test Loss Energy: 6.601725732353792, Test Loss Force: 8.564907451273351, time: 8.802207946777344

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–‚â–„â–„â–â–‚â–ƒâ–„â–
wandb:   test_error_force â–ƒâ–‚â–ˆâ–‚â–†â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–
wandb:          test_loss â–‚â–†â–ˆâ–‚â–ˆâ–„â–„â–â–‚â–‚â–ƒâ–â–â–ƒâ–ƒâ–â–‚â–ƒâ–„â–
wandb: train_error_energy â–†â–â–ˆâ–„â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–†â–…â–ˆâ–…â–…â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–„â–â–ˆâ–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–â–ˆâ–â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–‚
wandb:  valid_error_force â–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–„â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:         valid_loss â–â–â–ˆâ–â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1323
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.60173
wandb:   test_error_force 8.56491
wandb:          test_loss 4.399
wandb: train_error_energy 4.49333
wandb:  train_error_force 4.47142
wandb:         train_loss 1.86968
wandb: valid_error_energy 3.36126
wandb:  valid_error_force 4.77132
wandb:         valid_loss 1.66776
wandb: 
wandb: ğŸš€ View run al_73_58 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rq6vr5bl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_023132-rq6vr5bl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4201605319976807, Uncertainty Bias: -0.11225754022598267
4.9591064e-05 0.008005142
2.6921773 10.588612
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1748 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2072 steps.
Found uncertainty sample 33 after 3120 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3443 steps.
Found uncertainty sample 37 after 3758 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2861 steps.
Found uncertainty sample 48 after 1918 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3614 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1318 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_031415-bexqnqjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_59
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bexqnqjl
Training model 59. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.804818185503469, Training Loss Force: 4.816241282342247, time: 0.719353199005127
Validation Loss Energy: 3.8716982965816564, Validation Loss Force: 4.659935271701292, time: 0.06155753135681152
Test Loss Energy: 6.779343677918363, Test Loss Force: 8.634854139357007, time: 8.725672245025635


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9902630072894953, Training Loss Force: 4.533188325099933, time: 0.6838939189910889
Validation Loss Energy: 3.43104340487238, Validation Loss Force: 4.7791443163417755, time: 0.05959343910217285
Test Loss Energy: 6.803549173411729, Test Loss Force: 8.681556598147687, time: 8.768318891525269


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0104592631761817, Training Loss Force: 4.486521739024801, time: 0.7001562118530273
Validation Loss Energy: 3.588573475523318, Validation Loss Force: 4.756095165039353, time: 0.06746482849121094
Test Loss Energy: 6.714088551796141, Test Loss Force: 8.600211716640239, time: 8.91142725944519


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0034510805101777, Training Loss Force: 4.482059141844921, time: 0.6897904872894287
Validation Loss Energy: 3.404120701107397, Validation Loss Force: 4.7991279815122105, time: 0.05992460250854492
Test Loss Energy: 6.803985863746913, Test Loss Force: 8.603265482913987, time: 8.701122283935547


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.003061939669437, Training Loss Force: 4.487671104139618, time: 0.6977968215942383
Validation Loss Energy: 3.864624209150104, Validation Loss Force: 4.711734795118472, time: 0.06557536125183105
Test Loss Energy: 6.726092458923981, Test Loss Force: 8.699876057437598, time: 8.765135765075684


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0813580099161735, Training Loss Force: 4.53333494743088, time: 0.6886091232299805
Validation Loss Energy: 3.2412811960063843, Validation Loss Force: 4.899925182483364, time: 0.06031608581542969
Test Loss Energy: 6.5178421241361635, Test Loss Force: 8.621704661261141, time: 8.74739956855774


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.043603149368296, Training Loss Force: 4.486908494124692, time: 0.8097641468048096
Validation Loss Energy: 3.8582853752384043, Validation Loss Force: 4.8609509565333315, time: 0.09056806564331055
Test Loss Energy: 6.650742406733592, Test Loss Force: 8.59934868833645, time: 8.779270648956299


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9834392450419593, Training Loss Force: 4.508614102213758, time: 0.6743333339691162
Validation Loss Energy: 3.496917510999938, Validation Loss Force: 4.87656496238408, time: 0.060227155685424805
Test Loss Energy: 6.612627175394966, Test Loss Force: 8.616216783138363, time: 9.52958345413208


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9454852573086896, Training Loss Force: 4.4966549983275605, time: 0.6614270210266113
Validation Loss Energy: 3.566086897818081, Validation Loss Force: 4.762365305519533, time: 0.06312131881713867
Test Loss Energy: 6.67924703721516, Test Loss Force: 8.561936517921891, time: 8.755844116210938


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.972777387742529, Training Loss Force: 4.487463141760613, time: 0.7024779319763184
Validation Loss Energy: 3.8177119394823187, Validation Loss Force: 4.9644685064602845, time: 0.0599818229675293
Test Loss Energy: 6.702807617576725, Test Loss Force: 8.618976975881596, time: 8.950042009353638


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0303143130574353, Training Loss Force: 4.505463821550342, time: 0.7021806240081787
Validation Loss Energy: 3.569836868904651, Validation Loss Force: 4.879553627660723, time: 0.06902885437011719
Test Loss Energy: 6.690907371679868, Test Loss Force: 8.615593743209985, time: 8.68800663948059


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.081205640600603, Training Loss Force: 4.4755510210642075, time: 0.7427809238433838
Validation Loss Energy: 3.3411070028284278, Validation Loss Force: 4.7094965248636065, time: 0.06334137916564941
Test Loss Energy: 6.772134968335184, Test Loss Force: 8.601223348036664, time: 8.749485731124878


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0524455876796432, Training Loss Force: 4.476010520053414, time: 0.692368745803833
Validation Loss Energy: 3.529397034636122, Validation Loss Force: 4.837805389490722, time: 0.06295418739318848
Test Loss Energy: 6.733196765822896, Test Loss Force: 8.613181338688161, time: 8.9676194190979


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0215724893901696, Training Loss Force: 4.5197202348249546, time: 0.6769063472747803
Validation Loss Energy: 3.156034206175671, Validation Loss Force: 4.594698333334806, time: 0.06047320365905762
Test Loss Energy: 6.670964323226939, Test Loss Force: 8.59390239221941, time: 8.75587248802185


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.974951614109709, Training Loss Force: 4.474019895000344, time: 0.7073228359222412
Validation Loss Energy: 3.361359540992571, Validation Loss Force: 4.579411205790279, time: 0.060602664947509766
Test Loss Energy: 6.680032439090936, Test Loss Force: 8.645217347937614, time: 8.740337133407593


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.965508745795545, Training Loss Force: 4.481735513447901, time: 0.729339599609375
Validation Loss Energy: 3.5244116951279443, Validation Loss Force: 4.707170300296099, time: 0.06488466262817383
Test Loss Energy: 6.7392199055982775, Test Loss Force: 8.631353565874523, time: 8.941435098648071


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.035920687416898, Training Loss Force: 4.482424319244243, time: 0.6680097579956055
Validation Loss Energy: 3.380525676393732, Validation Loss Force: 4.712104203231567, time: 0.060770273208618164
Test Loss Energy: 6.8454162889262875, Test Loss Force: 8.658591784824447, time: 8.766356229782104


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9916566351557474, Training Loss Force: 4.486212345548181, time: 0.7061202526092529
Validation Loss Energy: 3.5271714565225736, Validation Loss Force: 4.671202107816091, time: 0.06178402900695801
Test Loss Energy: 6.763130897247111, Test Loss Force: 8.586961060482402, time: 8.753162384033203


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0976213402030326, Training Loss Force: 4.475505310269536, time: 0.7443313598632812
Validation Loss Energy: 3.430840330611294, Validation Loss Force: 4.954280502357504, time: 0.06212329864501953
Test Loss Energy: 6.900631349528347, Test Loss Force: 8.609301607448254, time: 8.998027324676514


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0216235442443438, Training Loss Force: 4.473141613665757, time: 0.6699349880218506
Validation Loss Energy: 3.7092937756572137, Validation Loss Force: 4.634393784648498, time: 0.06072545051574707
Test Loss Energy: 6.675891394533115, Test Loss Force: 8.594881586200566, time: 8.771087169647217

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–…â–†â–…â–â–ƒâ–ƒâ–„â–„â–„â–†â–…â–„â–„â–…â–‡â–…â–ˆâ–„
wandb:   test_error_force â–…â–‡â–ƒâ–ƒâ–ˆâ–„â–ƒâ–„â–â–„â–„â–ƒâ–„â–ƒâ–…â–…â–†â–‚â–ƒâ–ƒ
wandb:          test_loss â–â–ˆâ–†â–†â–†â–„â–…â–†â–†â–†â–†â–…â–†â–…â–‡â–†â–ˆâ–†â–…â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–…â–ƒâ–ˆâ–‚â–ˆâ–„â–…â–‡â–…â–ƒâ–…â–â–ƒâ–…â–ƒâ–…â–„â–†
wandb:  valid_error_force â–‚â–…â–„â–…â–ƒâ–‡â–†â–†â–„â–ˆâ–†â–ƒâ–†â–â–â–ƒâ–ƒâ–ƒâ–ˆâ–‚
wandb:         valid_loss â–„â–„â–‡â–…â–†â–ƒâ–ˆâ–ˆâ–…â–ˆâ–†â–‚â–†â–â–ƒâ–„â–ƒâ–…â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1331
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.67589
wandb:   test_error_force 8.59488
wandb:          test_loss 5.23921
wandb: train_error_energy 3.02162
wandb:  train_error_force 4.47314
wandb:         train_loss 1.46276
wandb: valid_error_energy 3.70929
wandb:  valid_error_force 4.63439
wandb:         valid_loss 1.83006
wandb: 
wandb: ğŸš€ View run al_73_59 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bexqnqjl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_031415-bexqnqjl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.402326822280884, Uncertainty Bias: -0.004715025424957275
3.3108518e-05 0.01338768
2.7652543 9.225626
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 891 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1946 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3051 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1947 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_035714-pla2u8dg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_60
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/pla2u8dg
Training model 60. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.480090727381446, Training Loss Force: 5.0845584620519375, time: 0.743910551071167
Validation Loss Energy: 5.3082756798397295, Validation Loss Force: 4.712853484907614, time: 0.06715583801269531
Test Loss Energy: 9.906102319985044, Test Loss Force: 8.592910323065231, time: 8.855933427810669


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.459880316756765, Training Loss Force: 4.563328046652354, time: 0.6662538051605225
Validation Loss Energy: 3.132446418209249, Validation Loss Force: 4.696528719143064, time: 0.061751365661621094
Test Loss Energy: 8.398873862196638, Test Loss Force: 8.550258875885767, time: 8.864843368530273


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.364222115560241, Training Loss Force: 4.493829464708542, time: 0.6672422885894775
Validation Loss Energy: 5.840721028236526, Validation Loss Force: 4.69288340255508, time: 0.07015776634216309
Test Loss Energy: 7.554563245725039, Test Loss Force: 8.62036110128237, time: 9.013921976089478


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.514633207089313, Training Loss Force: 4.504628971302503, time: 0.7034530639648438
Validation Loss Energy: 2.449016581375208, Validation Loss Force: 4.902666239669735, time: 0.06066417694091797
Test Loss Energy: 6.482388465259465, Test Loss Force: 8.61774842043637, time: 8.870843648910522


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.445810147666959, Training Loss Force: 4.5231653612474565, time: 0.6840200424194336
Validation Loss Energy: 5.761361521958716, Validation Loss Force: 4.9849420437517615, time: 0.062429189682006836
Test Loss Energy: 10.05780481790721, Test Loss Force: 8.669366430027988, time: 8.85736083984375


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.500668959591567, Training Loss Force: 4.505584995978897, time: 0.67421555519104
Validation Loss Energy: 2.7166518686353722, Validation Loss Force: 4.7653477360600895, time: 0.0648965835571289
Test Loss Energy: 7.69326685517918, Test Loss Force: 8.612036973164622, time: 9.008346557617188


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.380469408366948, Training Loss Force: 4.497771949176705, time: 0.7276067733764648
Validation Loss Energy: 5.7680213334442705, Validation Loss Force: 4.781876244093164, time: 0.0655817985534668
Test Loss Energy: 7.469104823379618, Test Loss Force: 8.550706881544144, time: 8.852249383926392


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.465256490981686, Training Loss Force: 4.4947756654342825, time: 0.6810340881347656
Validation Loss Energy: 2.1582596640056213, Validation Loss Force: 4.839950138704298, time: 0.06005215644836426
Test Loss Energy: 6.508161933924875, Test Loss Force: 8.569263382049256, time: 9.729047536849976


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.40254158818832, Training Loss Force: 4.494869637115512, time: 0.6753189563751221
Validation Loss Energy: 6.3569658602522, Validation Loss Force: 4.717479436414264, time: 0.060991764068603516
Test Loss Energy: 10.785963576489946, Test Loss Force: 8.671845975709248, time: 8.851760387420654


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.502502836169197, Training Loss Force: 4.502438161385598, time: 0.8977096080780029
Validation Loss Energy: 2.5183293671233287, Validation Loss Force: 4.662825517215434, time: 0.06098318099975586
Test Loss Energy: 7.894913732428274, Test Loss Force: 8.617459510134047, time: 8.872791051864624


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.330798845860567, Training Loss Force: 4.514409437851772, time: 0.7111308574676514
Validation Loss Energy: 5.769296782312145, Validation Loss Force: 4.708090369207072, time: 0.060706377029418945
Test Loss Energy: 7.423775787881019, Test Loss Force: 8.572703748592616, time: 8.834364652633667


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.50831749630809, Training Loss Force: 4.492682495937868, time: 0.6659517288208008
Validation Loss Energy: 2.2401663939782717, Validation Loss Force: 4.8522254433810055, time: 0.06604886054992676
Test Loss Energy: 6.525939915479015, Test Loss Force: 8.56038682460434, time: 8.894333600997925


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.346015816719187, Training Loss Force: 4.492171894379671, time: 0.7206876277923584
Validation Loss Energy: 6.355603347748268, Validation Loss Force: 4.837963929922623, time: 0.06255459785461426
Test Loss Energy: 11.283356272157336, Test Loss Force: 8.665848411408861, time: 9.123713493347168


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.5181624308767505, Training Loss Force: 4.501992144483011, time: 0.6490001678466797
Validation Loss Energy: 2.818426698491721, Validation Loss Force: 4.588467605293454, time: 0.060080766677856445
Test Loss Energy: 7.80552992817061, Test Loss Force: 8.54894822430831, time: 8.889812231063843


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.521280466927179, Training Loss Force: 4.4915427374062045, time: 0.693596601486206
Validation Loss Energy: 5.39841036875813, Validation Loss Force: 5.061743972219444, time: 0.061096906661987305
Test Loss Energy: 7.368138068597393, Test Loss Force: 8.586778896136506, time: 8.907601118087769


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4945919792938325, Training Loss Force: 4.484276454691838, time: 0.6570501327514648
Validation Loss Energy: 2.2547042398467507, Validation Loss Force: 4.631369492308507, time: 0.060549259185791016
Test Loss Energy: 6.61348873011865, Test Loss Force: 8.615058451246401, time: 9.08907413482666


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.447563847447117, Training Loss Force: 4.504106016908353, time: 0.7034540176391602
Validation Loss Energy: 5.736695569987711, Validation Loss Force: 4.703642553017165, time: 0.06231188774108887
Test Loss Energy: 10.226207021461455, Test Loss Force: 8.626328928176608, time: 8.831594944000244


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.4636346060342715, Training Loss Force: 4.5571265306822895, time: 0.7320504188537598
Validation Loss Energy: 1.924026028982214, Validation Loss Force: 4.872734385066684, time: 0.06284141540527344
Test Loss Energy: 7.08111699623039, Test Loss Force: 8.635137467775191, time: 8.831860780715942


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.44025162066564, Training Loss Force: 4.557791399545445, time: 0.6941537857055664
Validation Loss Energy: 5.644127775311757, Validation Loss Force: 4.793853840121765, time: 0.06460404396057129
Test Loss Energy: 7.358098418104539, Test Loss Force: 8.636182110163952, time: 9.012798547744751


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.431794665059066, Training Loss Force: 4.509259598861218, time: 0.7005515098571777
Validation Loss Energy: 2.2358788995734318, Validation Loss Force: 4.536274180157127, time: 0.06019735336303711
Test Loss Energy: 6.538800562547435, Test Loss Force: 8.54518724683741, time: 8.857033491134644

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–ƒâ–â–†â–ƒâ–‚â–â–‡â–ƒâ–‚â–â–ˆâ–ƒâ–‚â–â–†â–‚â–‚â–
wandb:   test_error_force â–„â–â–…â–…â–ˆâ–…â–â–‚â–ˆâ–…â–ƒâ–‚â–ˆâ–â–ƒâ–…â–…â–†â–†â–
wandb:          test_loss â–…â–„â–ƒâ–â–†â–ƒâ–‚â–â–‡â–ƒâ–‚â–â–ˆâ–ƒâ–‚â–â–†â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–ƒâ–‡â–‚â–‡â–‚â–‡â–â–ˆâ–‚â–‡â–â–ˆâ–‚â–†â–‚â–‡â–â–‡â–
wandb:  valid_error_force â–ƒâ–ƒâ–ƒâ–†â–‡â–„â–„â–…â–ƒâ–ƒâ–ƒâ–…â–…â–‚â–ˆâ–‚â–ƒâ–…â–„â–
wandb:         valid_loss â–†â–‚â–‡â–‚â–‡â–‚â–‡â–‚â–ˆâ–â–‡â–‚â–ˆâ–‚â–‡â–â–†â–â–‡â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1334
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.5388
wandb:   test_error_force 8.54519
wandb:          test_loss 4.38729
wandb: train_error_energy 4.43179
wandb:  train_error_force 4.50926
wandb:         train_loss 1.87258
wandb: valid_error_energy 2.23588
wandb:  valid_error_force 4.53627
wandb:         valid_loss 1.3999
wandb: 
wandb: ğŸš€ View run al_73_60 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/pla2u8dg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_035714-pla2u8dg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4204928874969482, Uncertainty Bias: -0.12711045145988464
2.2888184e-05 0.01859665
2.6279652 9.28681
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2640 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3202 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2828 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_044035-ufdhlayi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_61
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ufdhlayi
Training model 61. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.192743035339671, Training Loss Force: 4.907253425538408, time: 0.6995728015899658
Validation Loss Energy: 2.6438507480471465, Validation Loss Force: 4.876403972591573, time: 0.06121540069580078
Test Loss Energy: 7.563404332324751, Test Loss Force: 8.61499039609424, time: 8.697410106658936


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9432153282727547, Training Loss Force: 4.554789040116327, time: 0.6975088119506836
Validation Loss Energy: 2.213819623959231, Validation Loss Force: 4.8801029524437265, time: 0.05969405174255371
Test Loss Energy: 7.127219323201161, Test Loss Force: 8.570648626624793, time: 8.739986181259155


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0222179065129344, Training Loss Force: 4.484376947398054, time: 0.6906263828277588
Validation Loss Energy: 2.0910898461179093, Validation Loss Force: 4.539566120810523, time: 0.0606076717376709
Test Loss Energy: 7.344488623427881, Test Loss Force: 8.604992322943902, time: 8.839237689971924


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.979312700667278, Training Loss Force: 4.4814055283769285, time: 0.7019233703613281
Validation Loss Energy: 2.3844197054686918, Validation Loss Force: 4.649913601450519, time: 0.06516218185424805
Test Loss Energy: 7.355542768539268, Test Loss Force: 8.6005471379805, time: 8.74513840675354


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0298439695506567, Training Loss Force: 4.467578193244873, time: 0.717923641204834
Validation Loss Energy: 2.810675140183683, Validation Loss Force: 4.830280953711529, time: 0.06191682815551758
Test Loss Energy: 7.621105247955806, Test Loss Force: 8.567583188290893, time: 8.707765102386475


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.994417578817508, Training Loss Force: 4.472259186443738, time: 0.6745495796203613
Validation Loss Energy: 2.526273979580886, Validation Loss Force: 4.9261431384014855, time: 0.0636897087097168
Test Loss Energy: 7.396720554005156, Test Loss Force: 8.590717915659583, time: 8.656371593475342


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0117679268583237, Training Loss Force: 4.461142609589268, time: 0.693488359451294
Validation Loss Energy: 2.5721526190732744, Validation Loss Force: 4.72285689628842, time: 0.0911414623260498
Test Loss Energy: 7.7196162908160355, Test Loss Force: 8.597258083865352, time: 8.756816387176514


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.021257330373164, Training Loss Force: 4.465096725869483, time: 0.6810507774353027
Validation Loss Energy: 2.6149828066233387, Validation Loss Force: 4.836067456806755, time: 0.06053876876831055
Test Loss Energy: 7.7500213989606745, Test Loss Force: 8.579223543154434, time: 8.696585893630981


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.011326063795639, Training Loss Force: 4.541282762082822, time: 0.6996181011199951
Validation Loss Energy: 3.032795406666759, Validation Loss Force: 4.636463494359898, time: 0.07722806930541992
Test Loss Energy: 8.103342099941814, Test Loss Force: 8.689626701573177, time: 9.52773666381836


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.013783705572414, Training Loss Force: 4.476172639096588, time: 0.7043192386627197
Validation Loss Energy: 2.6643806206325427, Validation Loss Force: 4.785034137920712, time: 0.05915999412536621
Test Loss Energy: 7.5138907746603305, Test Loss Force: 8.64802797815692, time: 8.882800817489624


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9895653636487185, Training Loss Force: 4.471038927714176, time: 0.6792941093444824
Validation Loss Energy: 2.9655682514739707, Validation Loss Force: 4.973409118007577, time: 0.06197714805603027
Test Loss Energy: 8.224794134024089, Test Loss Force: 8.56510211307079, time: 8.716762065887451


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0480756606268162, Training Loss Force: 4.466286118414102, time: 0.680556058883667
Validation Loss Energy: 2.6321245454842974, Validation Loss Force: 4.715715896778516, time: 0.06064891815185547
Test Loss Energy: 7.995582441644157, Test Loss Force: 8.566622460693358, time: 8.734539031982422


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.015234482535298, Training Loss Force: 4.481352670963002, time: 0.7205996513366699
Validation Loss Energy: 2.6360410730920214, Validation Loss Force: 4.760083392112065, time: 0.06012988090515137
Test Loss Energy: 7.744123119451614, Test Loss Force: 8.630144577334772, time: 8.927048683166504


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.004702550031694, Training Loss Force: 4.4638783757326, time: 0.6697304248809814
Validation Loss Energy: 2.7989401421895694, Validation Loss Force: 4.80242793825486, time: 0.05954766273498535
Test Loss Energy: 7.878687817774832, Test Loss Force: 8.582173109594343, time: 8.757009267807007


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9648804476887856, Training Loss Force: 4.472500559797924, time: 0.7026357650756836
Validation Loss Energy: 2.400974488460985, Validation Loss Force: 4.880477481947176, time: 0.06162905693054199
Test Loss Energy: 7.618284242053784, Test Loss Force: 8.614671981547179, time: 8.756609439849854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0047759804842102, Training Loss Force: 4.479922175448159, time: 0.712587833404541
Validation Loss Energy: 2.555255704938263, Validation Loss Force: 5.057421073420402, time: 0.0672454833984375
Test Loss Energy: 7.748201630119448, Test Loss Force: 8.62557980854774, time: 8.927761316299438


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0212801857704994, Training Loss Force: 4.477994348395887, time: 0.7267541885375977
Validation Loss Energy: 2.7586916920519653, Validation Loss Force: 4.867502550813965, time: 0.059679269790649414
Test Loss Energy: 7.9747088273536075, Test Loss Force: 8.610799599554893, time: 8.727688312530518


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.999581106658891, Training Loss Force: 4.470913607398189, time: 0.6464006900787354
Validation Loss Energy: 2.342432877308829, Validation Loss Force: 4.8688661766636265, time: 0.05988883972167969
Test Loss Energy: 7.517285096488573, Test Loss Force: 8.618363365000615, time: 8.720554828643799


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9614396951245063, Training Loss Force: 4.476087229574186, time: 0.6895978450775146
Validation Loss Energy: 2.536394180928731, Validation Loss Force: 4.635777896059586, time: 0.059569358825683594
Test Loss Energy: 7.632266141355234, Test Loss Force: 8.572857593153733, time: 8.852763652801514


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0101451830442043, Training Loss Force: 4.4696434813832315, time: 0.6912648677825928
Validation Loss Energy: 2.852643152800715, Validation Loss Force: 4.915809286008123, time: 0.06075930595397949
Test Loss Energy: 7.555701162003994, Test Loss Force: 8.539400031434079, time: 8.727451086044312

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–‚â–‚â–„â–ƒâ–…â–…â–‡â–ƒâ–ˆâ–‡â–…â–†â–„â–…â–†â–ƒâ–„â–„
wandb:   test_error_force â–…â–‚â–„â–„â–‚â–ƒâ–„â–ƒâ–ˆâ–†â–‚â–‚â–…â–ƒâ–…â–…â–„â–…â–ƒâ–
wandb:          test_loss â–â–ƒâ–„â–†â–…â–„â–†â–†â–ˆâ–†â–ˆâ–†â–†â–†â–…â–‡â–†â–†â–†â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–â–ƒâ–†â–„â–…â–…â–ˆâ–…â–ˆâ–…â–…â–†â–ƒâ–„â–†â–ƒâ–„â–‡
wandb:  valid_error_force â–†â–†â–â–‚â–…â–†â–ƒâ–…â–‚â–„â–‡â–ƒâ–„â–…â–†â–ˆâ–…â–…â–‚â–†
wandb:         valid_loss â–†â–ƒâ–â–‚â–…â–…â–„â–„â–…â–„â–ˆâ–„â–„â–…â–„â–…â–…â–„â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1336
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.5557
wandb:   test_error_force 8.5394
wandb:          test_loss 5.54258
wandb: train_error_energy 3.01015
wandb:  train_error_force 4.46964
wandb:         train_loss 1.46538
wandb: valid_error_energy 2.85264
wandb:  valid_error_force 4.91581
wandb:         valid_loss 1.53873
wandb: 
wandb: ğŸš€ View run al_73_61 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ufdhlayi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_044035-ufdhlayi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.348393678665161, Uncertainty Bias: -0.025432825088500977
4.196167e-05 0.0013370514
2.7051022 9.337119
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1256 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 615 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3814 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1612 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3490 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2164 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_052312-541yw0lg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_62
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/541yw0lg
Training model 62. Added 6 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.29196915538594, Training Loss Force: 5.006122226879486, time: 0.6820869445800781
Validation Loss Energy: 4.846807680391436, Validation Loss Force: 4.764134189214784, time: 0.06110858917236328
Test Loss Energy: 7.051520655066358, Test Loss Force: 8.566147515565744, time: 8.78572678565979


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.5295879399646095, Training Loss Force: 4.561665280710077, time: 0.708928108215332
Validation Loss Energy: 3.775224662416983, Validation Loss Force: 4.995081505980728, time: 0.06574249267578125
Test Loss Energy: 8.492994790486737, Test Loss Force: 8.679249531287377, time: 8.779927730560303


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.4217753354851475, Training Loss Force: 4.55430848298789, time: 0.6649062633514404
Validation Loss Energy: 5.6254674328755705, Validation Loss Force: 4.775553331025398, time: 0.0603787899017334
Test Loss Energy: 9.436699840108234, Test Loss Force: 8.578226470356409, time: 8.937784671783447


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.410986047814491, Training Loss Force: 4.492834059403196, time: 0.6789565086364746
Validation Loss Energy: 3.5987524615256876, Validation Loss Force: 4.727209187414724, time: 0.059418678283691406
Test Loss Energy: 6.597285693262694, Test Loss Force: 8.54406744719996, time: 8.771390438079834


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.526031733448169, Training Loss Force: 4.532126771153307, time: 0.7160124778747559
Validation Loss Energy: 5.428435521733324, Validation Loss Force: 4.707091698087586, time: 0.06486248970031738
Test Loss Energy: 7.289025159655145, Test Loss Force: 8.553956288893247, time: 8.802924871444702


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.415151739545685, Training Loss Force: 4.517394635851713, time: 0.7086701393127441
Validation Loss Energy: 4.215808077330417, Validation Loss Force: 4.659029676284803, time: 0.06626129150390625
Test Loss Energy: 8.54727691399964, Test Loss Force: 8.600132003417611, time: 8.774580955505371


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.553778429689302, Training Loss Force: 4.51533470237615, time: 0.889277458190918
Validation Loss Energy: 5.720302444795362, Validation Loss Force: 4.662484388083873, time: 0.05943012237548828
Test Loss Energy: 9.632901486787935, Test Loss Force: 8.600225151400647, time: 8.85893440246582


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.382550280694697, Training Loss Force: 4.556936196277339, time: 0.738283634185791
Validation Loss Energy: 4.31099668785394, Validation Loss Force: 4.695749822470608, time: 0.05901145935058594
Test Loss Energy: 6.885753965854924, Test Loss Force: 8.594912125681963, time: 8.7746422290802


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.451448151648437, Training Loss Force: 4.52570425605591, time: 0.6517374515533447
Validation Loss Energy: 4.869685153782349, Validation Loss Force: 4.634312065071943, time: 0.059139251708984375
Test Loss Energy: 7.198223237394839, Test Loss Force: 8.542507345557096, time: 8.803443908691406


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.416270932991228, Training Loss Force: 4.511476980629537, time: 0.7079100608825684
Validation Loss Energy: 3.9558447441586218, Validation Loss Force: 4.877084449501529, time: 0.06089186668395996
Test Loss Energy: 8.343378098573865, Test Loss Force: 8.533229489347322, time: 9.89424991607666


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.379081808472574, Training Loss Force: 4.517182999431802, time: 0.6662626266479492
Validation Loss Energy: 5.598816830806912, Validation Loss Force: 4.95504514820462, time: 0.061690568923950195
Test Loss Energy: 9.976983248530134, Test Loss Force: 8.689340379362497, time: 8.885299444198608


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.372419571483824, Training Loss Force: 4.517707835910401, time: 0.6575267314910889
Validation Loss Energy: 3.4235852131641016, Validation Loss Force: 4.796589107910343, time: 0.06513667106628418
Test Loss Energy: 6.738117739958215, Test Loss Force: 8.612008928510306, time: 8.905442237854004


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.4310899622761974, Training Loss Force: 4.509146016390209, time: 0.6943299770355225
Validation Loss Energy: 5.309640196365974, Validation Loss Force: 4.603364839163461, time: 0.06397390365600586
Test Loss Energy: 7.27990072132111, Test Loss Force: 8.599553739806286, time: 9.053023338317871


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.580910818868348, Training Loss Force: 4.487333707367073, time: 0.686211109161377
Validation Loss Energy: 3.7544427283583968, Validation Loss Force: 4.647744803969183, time: 0.0599057674407959
Test Loss Energy: 8.329214860317908, Test Loss Force: 8.560823032295405, time: 8.870228290557861


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.407964398345197, Training Loss Force: 4.501062320542788, time: 0.6937072277069092
Validation Loss Energy: 6.036855137382391, Validation Loss Force: 4.630681444647591, time: 0.0694420337677002
Test Loss Energy: 10.057008954078997, Test Loss Force: 8.560948142044433, time: 8.9375


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.397181936544191, Training Loss Force: 4.50430316392884, time: 0.6745095252990723
Validation Loss Energy: 3.38149473251681, Validation Loss Force: 4.857429443990483, time: 0.05986618995666504
Test Loss Energy: 6.92411477677956, Test Loss Force: 8.499837114894495, time: 9.060779571533203


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.4067010186751965, Training Loss Force: 4.507199129919375, time: 0.6561181545257568
Validation Loss Energy: 4.83001686810446, Validation Loss Force: 4.837011573985489, time: 0.06281256675720215
Test Loss Energy: 7.244942490801833, Test Loss Force: 8.477773139329186, time: 8.871851921081543


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.3194063501244155, Training Loss Force: 4.533902032729094, time: 0.6980926990509033
Validation Loss Energy: 3.583302674170061, Validation Loss Force: 4.94551936214183, time: 0.06003236770629883
Test Loss Energy: 8.096796349851907, Test Loss Force: 8.492415372726436, time: 8.860469102859497


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.494857263072975, Training Loss Force: 4.502249306139973, time: 0.6930599212646484
Validation Loss Energy: 5.485629873218045, Validation Loss Force: 4.618713868730556, time: 0.06067705154418945
Test Loss Energy: 9.774096052842712, Test Loss Force: 8.633241730283569, time: 9.068222045898438


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.358681174119804, Training Loss Force: 4.503817840620351, time: 0.6914746761322021
Validation Loss Energy: 3.867036050004221, Validation Loss Force: 4.816477248017175, time: 0.0599825382232666
Test Loss Energy: 6.798861488924534, Test Loss Force: 8.472267027984195, time: 8.86328125

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‡â–â–‚â–…â–‡â–‚â–‚â–…â–ˆâ–â–‚â–…â–ˆâ–‚â–‚â–„â–‡â–
wandb:   test_error_force â–„â–ˆâ–„â–ƒâ–„â–…â–…â–…â–ƒâ–ƒâ–ˆâ–†â–…â–„â–„â–‚â–â–‚â–†â–
wandb:          test_loss â–â–…â–‡â–â–ƒâ–…â–‡â–‚â–‚â–„â–ˆâ–‚â–‚â–„â–ˆâ–‚â–‚â–„â–‡â–
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–‡â–‚â–†â–ƒâ–‡â–ƒâ–…â–ƒâ–‡â–â–†â–‚â–ˆâ–â–…â–‚â–‡â–‚
wandb:  valid_error_force â–„â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–†â–‡â–„â–â–‚â–â–†â–…â–‡â–â–…
wandb:         valid_loss â–„â–‚â–ˆâ–â–‡â–‚â–‡â–„â–„â–ƒâ–ˆâ–â–†â–â–ˆâ–â–†â–‚â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1341
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.79886
wandb:   test_error_force 8.47227
wandb:          test_loss 4.44143
wandb: train_error_energy 4.35868
wandb:  train_error_force 4.50382
wandb:         train_loss 1.84263
wandb: valid_error_energy 3.86704
wandb:  valid_error_force 4.81648
wandb:         valid_loss 1.85539
wandb: 
wandb: ğŸš€ View run al_73_62 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/541yw0lg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_052312-541yw0lg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3664917945861816, Uncertainty Bias: -0.11263874173164368
0.0004196167 0.07728052
2.7061658 9.217311
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2179 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3628 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2770 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2348 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3378 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3280 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1106 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_060612-a7q5tuzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_63
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a7q5tuzc
Training model 63. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.313489321359564, Training Loss Force: 4.815783084722273, time: 0.6977732181549072
Validation Loss Energy: 1.7013632291250853, Validation Loss Force: 4.814558953325006, time: 0.06043386459350586
Test Loss Energy: 6.622259819331662, Test Loss Force: 8.667504985916455, time: 8.67726469039917


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7025603682482573, Training Loss Force: 5.122070470764419, time: 0.7104842662811279
Validation Loss Energy: 4.4306472854108, Validation Loss Force: 4.808566035931506, time: 0.060103654861450195
Test Loss Energy: 10.018244596713517, Test Loss Force: 8.628322905896445, time: 8.715213775634766


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.370447889521331, Training Loss Force: 4.853729873806176, time: 0.7341229915618896
Validation Loss Energy: 3.8358485640872826, Validation Loss Force: 5.023305933572805, time: 0.059613704681396484
Test Loss Energy: 6.8083940879637055, Test Loss Force: 8.484056969881516, time: 8.879974126815796


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.472168175793633, Training Loss Force: 4.535779160753969, time: 0.7068259716033936
Validation Loss Energy: 2.169854157768654, Validation Loss Force: 4.59913212136852, time: 0.06345486640930176
Test Loss Energy: 6.61344545769269, Test Loss Force: 8.454245740167783, time: 8.67142128944397


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.4108512681901555, Training Loss Force: 4.504496051384735, time: 0.722327470779419
Validation Loss Energy: 5.7863450001318135, Validation Loss Force: 4.676090808914936, time: 0.06133627891540527
Test Loss Energy: 10.251323075211909, Test Loss Force: 8.53276727016943, time: 8.726048707962036


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.321321845793908, Training Loss Force: 4.479866140745258, time: 0.781287670135498
Validation Loss Energy: 5.523106426492566, Validation Loss Force: 4.65951977107499, time: 0.06397032737731934
Test Loss Energy: 7.192933292324068, Test Loss Force: 8.501550235707084, time: 8.716422319412231


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.348802190775578, Training Loss Force: 4.477889667265775, time: 0.8521385192871094
Validation Loss Energy: 3.886320534056442, Validation Loss Force: 4.853236583972663, time: 0.08330059051513672
Test Loss Energy: 8.470606100353082, Test Loss Force: 8.506979128656528, time: 8.674328327178955


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.411535784214851, Training Loss Force: 4.476794337023547, time: 0.6966423988342285
Validation Loss Energy: 2.760673447450723, Validation Loss Force: 4.558877770498548, time: 0.0607457160949707
Test Loss Energy: 7.968237264560927, Test Loss Force: 8.502330958033376, time: 8.70530104637146


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.337163326301455, Training Loss Force: 4.478673970137959, time: 0.7184278964996338
Validation Loss Energy: 4.672467313903253, Validation Loss Force: 4.808022723215442, time: 0.06372594833374023
Test Loss Energy: 7.107008113479728, Test Loss Force: 8.481377721453148, time: 8.677009105682373


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.410888653304085, Training Loss Force: 4.492883544723466, time: 0.7016708850860596
Validation Loss Energy: 5.7265378488887775, Validation Loss Force: 4.7098654876384085, time: 0.06008410453796387
Test Loss Energy: 9.824911977859713, Test Loss Force: 8.497132848246904, time: 8.856300354003906


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.40671579985011, Training Loss Force: 4.519658442780724, time: 0.7690863609313965
Validation Loss Energy: 3.8807740683005276, Validation Loss Force: 4.729793930860653, time: 0.06184220314025879
Test Loss Energy: 6.68593027093009, Test Loss Force: 8.548526570552413, time: 9.54370641708374


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.499583043100519, Training Loss Force: 4.52038634304041, time: 0.6988029479980469
Validation Loss Energy: 2.303715834222343, Validation Loss Force: 4.787265950770346, time: 0.060263872146606445
Test Loss Energy: 6.459918140653169, Test Loss Force: 8.533698092484602, time: 8.716926574707031


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.447629132289927, Training Loss Force: 4.488306057415346, time: 0.7428333759307861
Validation Loss Energy: 5.821647411865497, Validation Loss Force: 4.5867799958364674, time: 0.06588077545166016
Test Loss Energy: 9.928448649353847, Test Loss Force: 8.612576093638545, time: 8.922365427017212


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.3738561152524245, Training Loss Force: 4.489439867993001, time: 0.6841647624969482
Validation Loss Energy: 5.815284641020611, Validation Loss Force: 4.702062715426807, time: 0.06013083457946777
Test Loss Energy: 7.561579737042351, Test Loss Force: 8.520688441285923, time: 8.694925785064697


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.496610870875731, Training Loss Force: 4.505064385898779, time: 0.7027297019958496
Validation Loss Energy: 3.705324364127332, Validation Loss Force: 4.858591108924789, time: 0.06273102760314941
Test Loss Energy: 8.131790678420574, Test Loss Force: 8.566175933278315, time: 8.720398187637329


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.475432508062111, Training Loss Force: 4.512444873842656, time: 0.7357816696166992
Validation Loss Energy: 2.5275323942590973, Validation Loss Force: 4.800349544446771, time: 0.06099414825439453
Test Loss Energy: 7.439268678037682, Test Loss Force: 8.534860406773433, time: 8.924334049224854


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.464978947700226, Training Loss Force: 4.507618835984157, time: 0.7095646858215332
Validation Loss Energy: 5.361030899231233, Validation Loss Force: 4.702382245651213, time: 0.05996823310852051
Test Loss Energy: 7.236609975868193, Test Loss Force: 8.556834148873326, time: 8.736643314361572


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.374202236315536, Training Loss Force: 4.5112499379952675, time: 0.6906108856201172
Validation Loss Energy: 6.616706078939776, Validation Loss Force: 4.576031756162534, time: 0.06011390686035156
Test Loss Energy: 10.369380251194702, Test Loss Force: 8.561334816925697, time: 8.749497890472412


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.600048482579296, Training Loss Force: 4.480190678436271, time: 0.7079184055328369
Validation Loss Energy: 3.5102335712647115, Validation Loss Force: 4.761401148117665, time: 0.05981779098510742
Test Loss Energy: 6.675150402910977, Test Loss Force: 8.499839273969146, time: 8.942100763320923


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.451410481601839, Training Loss Force: 4.493834844276745, time: 0.6993818283081055
Validation Loss Energy: 2.6208631647635725, Validation Loss Force: 4.790769204443228, time: 0.060990095138549805
Test Loss Energy: 6.41095717086568, Test Loss Force: 8.47552813070959, time: 8.712177515029907

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–‚â–â–ˆâ–‚â–…â–„â–‚â–‡â–â–â–‡â–ƒâ–„â–ƒâ–‚â–ˆâ–â–
wandb:   test_error_force â–ˆâ–‡â–‚â–â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–„â–†â–ƒâ–…â–„â–„â–…â–‚â–‚
wandb:          test_loss â–„â–ˆâ–‚â–â–„â–‚â–‚â–‚â–â–ƒâ–â–â–ƒâ–‚â–‚â–â–â–„â–â–
wandb: train_error_energy â–‡â–â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:  train_error_force â–…â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–†â–â–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–â–…â–„â–‚â–‡â–†â–„â–ƒâ–…â–‡â–„â–‚â–‡â–‡â–„â–‚â–†â–ˆâ–„â–‚
wandb:  valid_error_force â–…â–…â–ˆâ–‚â–ƒâ–ƒâ–…â–â–…â–ƒâ–„â–„â–â–ƒâ–†â–…â–ƒâ–â–„â–„
wandb:         valid_loss â–â–ˆâ–†â–‚â–‡â–‡â–„â–ƒâ–†â–‡â–„â–ƒâ–‡â–‡â–„â–ƒâ–†â–ˆâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1347
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.41096
wandb:   test_error_force 8.47553
wandb:          test_loss 4.30444
wandb: train_error_energy 4.45141
wandb:  train_error_force 4.49383
wandb:         train_loss 1.86113
wandb: valid_error_energy 2.62086
wandb:  valid_error_force 4.79077
wandb:         valid_loss 1.56972
wandb: 
wandb: ğŸš€ View run al_73_63 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a7q5tuzc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_060612-a7q5tuzc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.279831647872925, Uncertainty Bias: -0.11071869730949402
7.1525574e-06 0.009983063
2.7043185 9.234198
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3245 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2220 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1620 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_064913-tq50gys2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_64
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tq50gys2
Training model 64. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.865798199744215, Training Loss Force: 4.914203535943202, time: 0.7449054718017578
Validation Loss Energy: 3.8949033162862294, Validation Loss Force: 4.728703074714754, time: 0.06090974807739258
Test Loss Energy: 6.682911287675388, Test Loss Force: 8.560691645841237, time: 8.721495866775513


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.950470159677633, Training Loss Force: 4.49576427242621, time: 0.709181547164917
Validation Loss Energy: 2.1680584424413194, Validation Loss Force: 4.796884367197842, time: 0.05999159812927246
Test Loss Energy: 6.334453009336454, Test Loss Force: 8.506053454545276, time: 8.74777865409851


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.925456763574521, Training Loss Force: 4.469780279640231, time: 0.6888227462768555
Validation Loss Energy: 3.2382952027594927, Validation Loss Force: 4.678939415298791, time: 0.060520172119140625
Test Loss Energy: 8.288502161915249, Test Loss Force: 8.548619965686543, time: 8.918160438537598


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9942877036475584, Training Loss Force: 4.499900833398576, time: 0.753753662109375
Validation Loss Energy: 3.9329681614442924, Validation Loss Force: 4.968055706401181, time: 0.062059640884399414
Test Loss Energy: 8.537765215549204, Test Loss Force: 8.539413335624095, time: 8.772193431854248


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1166794205310158, Training Loss Force: 4.546357819749047, time: 0.7067544460296631
Validation Loss Energy: 2.3505778919977214, Validation Loss Force: 4.764011275846231, time: 0.060347795486450195
Test Loss Energy: 7.379802189603387, Test Loss Force: 8.574053244860872, time: 8.765831708908081


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9498352134296675, Training Loss Force: 4.452238207546656, time: 0.7035415172576904
Validation Loss Energy: 2.5192053475434086, Validation Loss Force: 4.752234304718111, time: 0.06067657470703125
Test Loss Energy: 6.522325221144728, Test Loss Force: 8.470783030225341, time: 8.79421067237854


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.930366965191828, Training Loss Force: 4.48926189838353, time: 0.9104666709899902
Validation Loss Energy: 3.6611839913226287, Validation Loss Force: 4.902819881380426, time: 0.06440591812133789
Test Loss Energy: 6.486513752769242, Test Loss Force: 8.50094944404039, time: 8.76251220703125


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0775805930696034, Training Loss Force: 4.46982827778706, time: 0.7391407489776611
Validation Loss Energy: 2.240956869446315, Validation Loss Force: 4.549839184527048, time: 0.06330490112304688
Test Loss Energy: 6.355877714607684, Test Loss Force: 8.509730703754075, time: 8.820229530334473


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0441732304049234, Training Loss Force: 4.465987628574575, time: 0.7119500637054443
Validation Loss Energy: 2.81266702702858, Validation Loss Force: 4.442660285833604, time: 0.06264925003051758
Test Loss Energy: 8.021982023305318, Test Loss Force: 8.495146746719477, time: 8.720433235168457


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9374414668915594, Training Loss Force: 4.492821766981352, time: 0.7080516815185547
Validation Loss Energy: 3.9812902608095198, Validation Loss Force: 4.861584004915205, time: 0.07031488418579102
Test Loss Energy: 8.481772293511346, Test Loss Force: 8.5936833324121, time: 8.995190858840942


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.015956337315343, Training Loss Force: 4.484043351782637, time: 0.7071499824523926
Validation Loss Energy: 2.5122776650753034, Validation Loss Force: 4.777890689050202, time: 0.061530351638793945
Test Loss Energy: 7.553494569058201, Test Loss Force: 8.553311728166788, time: 8.800307750701904


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.051565928903362, Training Loss Force: 4.463308628761339, time: 0.7296850681304932
Validation Loss Energy: 2.8267672166907385, Validation Loss Force: 4.967079302196288, time: 0.06385922431945801
Test Loss Energy: 6.533990479978401, Test Loss Force: 8.557018155194354, time: 8.785704612731934


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0270850849003783, Training Loss Force: 4.469008202857664, time: 0.7093648910522461
Validation Loss Energy: 3.5867544912702334, Validation Loss Force: 4.641815347282272, time: 0.06847262382507324
Test Loss Energy: 6.616866928835435, Test Loss Force: 8.533893122677068, time: 9.80550765991211


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9776687608711243, Training Loss Force: 4.46077899333985, time: 0.749631404876709
Validation Loss Energy: 2.0440182566762126, Validation Loss Force: 4.665713090699826, time: 0.06298708915710449
Test Loss Energy: 6.61288128868856, Test Loss Force: 8.568170489238444, time: 8.782772779464722


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9269857989403176, Training Loss Force: 4.470612187104474, time: 0.7000596523284912
Validation Loss Energy: 2.6293110094909267, Validation Loss Force: 4.929755722625018, time: 0.06137990951538086
Test Loss Energy: 7.4007644495301586, Test Loss Force: 8.59032979984081, time: 8.856760740280151


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.499326299215415, Training Loss Force: 5.621022884225922, time: 0.7569153308868408
Validation Loss Energy: 3.931007782283544, Validation Loss Force: 4.8199851777421205, time: 0.06164813041687012
Test Loss Energy: 6.842591748297299, Test Loss Force: 8.604495898987258, time: 8.991128921508789


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0550952296879648, Training Loss Force: 4.552032952022842, time: 0.6877381801605225
Validation Loss Energy: 1.9922087131474646, Validation Loss Force: 4.874794297335662, time: 0.06565523147583008
Test Loss Energy: 6.397089003036482, Test Loss Force: 8.451989502494712, time: 8.854050397872925


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.963242977134098, Training Loss Force: 4.468169661924214, time: 0.7226531505584717
Validation Loss Energy: 3.131603949495631, Validation Loss Force: 4.715545332212735, time: 0.060654401779174805
Test Loss Energy: 7.9480614720575735, Test Loss Force: 8.563854363778345, time: 8.782361268997192


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0608571071291566, Training Loss Force: 4.487787849350896, time: 0.7124927043914795
Validation Loss Energy: 3.958301230176497, Validation Loss Force: 4.86740324037488, time: 0.06046628952026367
Test Loss Energy: 8.292699286455244, Test Loss Force: 8.505419134267916, time: 8.946157217025757


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.03709832997207, Training Loss Force: 4.473043485617098, time: 0.7222464084625244
Validation Loss Energy: 2.5277607414682457, Validation Loss Force: 4.704325924626017, time: 0.0606379508972168
Test Loss Energy: 7.702769842719366, Test Loss Force: 8.54242757637573, time: 8.833425521850586

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‡â–ˆâ–„â–‚â–â–â–†â–ˆâ–…â–‚â–‚â–‚â–„â–ƒâ–â–†â–‡â–…
wandb:   test_error_force â–†â–ƒâ–…â–…â–‡â–‚â–ƒâ–„â–ƒâ–ˆâ–†â–†â–…â–†â–‡â–ˆâ–â–†â–ƒâ–…
wandb:          test_loss â–â–‚â–ˆâ–ˆâ–†â–ƒâ–‚â–‚â–†â–ˆâ–†â–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–ˆâ–†â–…
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–ƒâ–â–â–â–
wandb:  train_error_force â–„â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–ˆâ–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‡â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–…â–ˆâ–‚â–ƒâ–‡â–‚â–„â–ˆâ–ƒâ–„â–‡â–â–ƒâ–ˆâ–â–…â–ˆâ–ƒ
wandb:  valid_error_force â–…â–†â–„â–ˆâ–…â–…â–‡â–‚â–â–‡â–…â–ˆâ–„â–„â–‡â–†â–‡â–…â–‡â–„
wandb:         valid_loss â–†â–‚â–„â–ˆâ–‚â–ƒâ–‡â–â–‚â–‡â–‚â–„â–†â–â–ƒâ–ˆâ–‚â–„â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1349
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.70277
wandb:   test_error_force 8.54243
wandb:          test_loss 5.61198
wandb: train_error_energy 3.0371
wandb:  train_error_force 4.47304
wandb:         train_loss 1.46811
wandb: valid_error_energy 2.52776
wandb:  valid_error_force 4.70433
wandb:         valid_loss 1.37726
wandb: 
wandb: ğŸš€ View run al_73_64 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tq50gys2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_064913-tq50gys2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1262173652648926, Uncertainty Bias: -0.00011032819747924805
0.0001296997 0.0030293465
2.8059607 9.308057
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3358 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3355 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1056 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_073233-w26exn28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_65
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w26exn28
Training model 65. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.765460138781292, Training Loss Force: 4.938716762771862, time: 0.7147164344787598
Validation Loss Energy: 1.921704925805063, Validation Loss Force: 4.73731213190376, time: 0.06388425827026367
Test Loss Energy: 7.118654726395498, Test Loss Force: 8.609183138136162, time: 8.611545085906982


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.126733998028717, Training Loss Force: 4.477773755029439, time: 0.6956648826599121
Validation Loss Energy: 1.6778109568874382, Validation Loss Force: 4.683459598961124, time: 0.0640115737915039
Test Loss Energy: 6.544488413884559, Test Loss Force: 8.513356466260465, time: 8.619431495666504


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.127369951466192, Training Loss Force: 4.491504684161542, time: 0.6931731700897217
Validation Loss Energy: 1.8426356130916837, Validation Loss Force: 4.785592592138698, time: 0.060781002044677734
Test Loss Energy: 6.826176077562474, Test Loss Force: 8.490287658285427, time: 8.833304166793823


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1512607843726936, Training Loss Force: 4.489807002809466, time: 0.7159521579742432
Validation Loss Energy: 2.279958149697578, Validation Loss Force: 4.973009426890636, time: 0.0634608268737793
Test Loss Energy: 7.544591524477184, Test Loss Force: 8.568463139449776, time: 8.623525381088257


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0809455939131283, Training Loss Force: 4.46161052278438, time: 0.7092564105987549
Validation Loss Energy: 2.4952277772370395, Validation Loss Force: 4.99955426111498, time: 0.06034660339355469
Test Loss Energy: 7.396445080794853, Test Loss Force: 8.565312410672336, time: 8.641340970993042


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.060970276246489, Training Loss Force: 4.4671913883341645, time: 0.7216107845306396
Validation Loss Energy: 1.8346613856377179, Validation Loss Force: 4.781058602989317, time: 0.06429767608642578
Test Loss Energy: 6.689273301911502, Test Loss Force: 8.60037831046722, time: 8.611890316009521


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.078714974673683, Training Loss Force: 4.469344174350403, time: 0.7120883464813232
Validation Loss Energy: 2.140044882530436, Validation Loss Force: 4.685375221623541, time: 0.06159210205078125
Test Loss Energy: 6.583238016796053, Test Loss Force: 8.568973935475691, time: 8.813104629516602


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0952544892944234, Training Loss Force: 4.527418545369944, time: 0.7044758796691895
Validation Loss Energy: 2.298858640807647, Validation Loss Force: 4.623311095917381, time: 0.06292557716369629
Test Loss Energy: 7.658854394897225, Test Loss Force: 8.55447565593257, time: 8.665346384048462


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.055706175681019, Training Loss Force: 4.46842651855157, time: 0.696260929107666
Validation Loss Energy: 2.182923277950594, Validation Loss Force: 4.774179017056732, time: 0.0598599910736084
Test Loss Energy: 7.503504061078048, Test Loss Force: 8.59857701267284, time: 8.583138704299927


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0919223309684263, Training Loss Force: 4.5033288507918945, time: 0.7328999042510986
Validation Loss Energy: 1.7702196544586268, Validation Loss Force: 4.878998736149071, time: 0.061606407165527344
Test Loss Energy: 6.644128242422952, Test Loss Force: 8.611268403210987, time: 8.822652578353882


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0958993610359373, Training Loss Force: 5.04651662357307, time: 0.6753954887390137
Validation Loss Energy: 3.636888226806729, Validation Loss Force: 5.142779286489506, time: 0.06301140785217285
Test Loss Energy: 8.887881912702483, Test Loss Force: 8.824967554590675, time: 8.617609977722168


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.531701078913346, Training Loss Force: 5.391812164129067, time: 0.721177339553833
Validation Loss Energy: 6.071579500013246, Validation Loss Force: 4.872774465512951, time: 0.060251712799072266
Test Loss Energy: 7.566968845660518, Test Loss Force: 8.587397487345193, time: 8.850964069366455


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.473344570550858, Training Loss Force: 4.642175398112886, time: 0.7378566265106201
Validation Loss Energy: 4.061552245135775, Validation Loss Force: 4.711680463846866, time: 0.06041765213012695
Test Loss Energy: 8.638560724934333, Test Loss Force: 8.535611811384113, time: 8.847151756286621


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.458154933254607, Training Loss Force: 4.548503117867959, time: 0.7029838562011719
Validation Loss Energy: 2.4934105743371227, Validation Loss Force: 4.920357748651989, time: 0.061280012130737305
Test Loss Energy: 7.522661488483474, Test Loss Force: 8.556119257339349, time: 8.66136360168457


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.474144781321097, Training Loss Force: 4.5110514258624965, time: 0.6784460544586182
Validation Loss Energy: 5.5793468633561325, Validation Loss Force: 4.95253477625343, time: 0.06098818778991699
Test Loss Energy: 7.214477865875844, Test Loss Force: 8.448601858409237, time: 9.564531564712524


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.423386500257091, Training Loss Force: 4.496271605950973, time: 0.7414753437042236
Validation Loss Energy: 6.225040626026072, Validation Loss Force: 4.886281353235784, time: 0.06081056594848633
Test Loss Energy: 10.150320429893943, Test Loss Force: 8.609322391456283, time: 8.839843511581421


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.512023076340042, Training Loss Force: 4.485717295568086, time: 0.7443451881408691
Validation Loss Energy: 3.3702815596661786, Validation Loss Force: 4.743813848295705, time: 0.059348106384277344
Test Loss Energy: 6.685733529332881, Test Loss Force: 8.451022409590701, time: 8.6539785861969


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.554798230951772, Training Loss Force: 4.532078109560924, time: 0.7092320919036865
Validation Loss Energy: 2.408146661651319, Validation Loss Force: 4.58959097113466, time: 0.06053972244262695
Test Loss Energy: 6.354439679957457, Test Loss Force: 8.546634363124532, time: 8.648912191390991


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.408396211397495, Training Loss Force: 4.491059946558545, time: 0.7029237747192383
Validation Loss Energy: 5.725075357938324, Validation Loss Force: 4.663507775478557, time: 0.06059980392456055
Test Loss Energy: 9.699660107626059, Test Loss Force: 8.566664835447892, time: 8.869117498397827


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.394357763228986, Training Loss Force: 4.4878629561716545, time: 0.7353808879852295
Validation Loss Energy: 5.935985346269665, Validation Loss Force: 4.721921017868086, time: 0.06044602394104004
Test Loss Energy: 7.4401933845290875, Test Loss Force: 8.513026379653251, time: 8.686302661895752

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–†â–ƒâ–…â–ƒâ–ƒâ–ˆâ–‚â–â–‡â–ƒ
wandb:   test_error_force â–„â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ˆâ–„â–ƒâ–ƒâ–â–„â–â–ƒâ–ƒâ–‚
wandb:          test_loss â–†â–…â–†â–‡â–‡â–†â–†â–ˆâ–ˆâ–†â–‡â–‚â–ƒâ–‚â–‚â–…â–â–â–„â–‚
wandb: train_error_energy â–†â–â–â–â–â–â–â–â–â–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–…â–â–â–â–â–â–â–â–â–â–…â–ˆâ–‚â–‚â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–…â–†â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–„â–ˆâ–…â–‚â–‡â–ˆâ–„â–‚â–‡â–ˆ
wandb:  valid_error_force â–ƒâ–‚â–ƒâ–†â–†â–ƒâ–‚â–â–ƒâ–…â–ˆâ–…â–ƒâ–…â–†â–…â–ƒâ–â–‚â–ƒ
wandb:         valid_loss â–â–â–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–…â–ˆâ–„â–ƒâ–‡â–‡â–„â–ƒâ–†â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1351
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.44019
wandb:   test_error_force 8.51303
wandb:          test_loss 4.67667
wandb: train_error_energy 4.39436
wandb:  train_error_force 4.48786
wandb:         train_loss 1.84432
wandb: valid_error_energy 5.93599
wandb:  valid_error_force 4.72192
wandb:         valid_loss 2.40146
wandb: 
wandb: ğŸš€ View run al_73_65 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w26exn28
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_073233-w26exn28/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5925066471099854, Uncertainty Bias: 0.0272161066532135
9.536743e-05 0.14774704
3.252818 13.98726
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2507 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2135 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2952 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3514 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2625 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_081559-i0s6nwi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_66
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/i0s6nwi6
Training model 66. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.042766937295874, Training Loss Force: 4.941143918602701, time: 0.7132618427276611
Validation Loss Energy: 2.0809969217404403, Validation Loss Force: 5.074522509165948, time: 0.061158180236816406
Test Loss Energy: 7.1587737748654305, Test Loss Force: 8.745562487407673, time: 8.67612075805664


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.840765458724848, Training Loss Force: 4.784417929540293, time: 0.7309648990631104
Validation Loss Energy: 2.625918645052717, Validation Loss Force: 5.038661643214278, time: 0.06059885025024414
Test Loss Energy: 8.03852948386355, Test Loss Force: 8.601791776899743, time: 8.664112567901611


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.904380660271579, Training Loss Force: 5.100689178683575, time: 0.6916708946228027
Validation Loss Energy: 6.380715528687712, Validation Loss Force: 5.249545356586399, time: 0.06151461601257324
Test Loss Energy: 10.367276580358224, Test Loss Force: 8.766608895287076, time: 8.84480595588684


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.660538991303808, Training Loss Force: 4.697030107919466, time: 0.7275185585021973
Validation Loss Energy: 3.684726577452428, Validation Loss Force: 5.234182298863112, time: 0.060329437255859375
Test Loss Energy: 8.77243365434054, Test Loss Force: 9.078273699342773, time: 8.722543478012085


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0751259816152356, Training Loss Force: 5.258078090041875, time: 0.7293736934661865
Validation Loss Energy: 2.540134688576599, Validation Loss Force: 5.80481451510994, time: 0.06111741065979004
Test Loss Energy: 8.054730949211612, Test Loss Force: 9.223185879509536, time: 9.021360397338867


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0021706238058137, Training Loss Force: 4.968675249640436, time: 0.7609095573425293
Validation Loss Energy: 3.057188700268575, Validation Loss Force: 5.094627974359206, time: 0.06659770011901855
Test Loss Energy: 7.8570167005313625, Test Loss Force: 8.6586483078133, time: 10.640049934387207


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.5107855473640575, Training Loss Force: 5.085056737898884, time: 0.7161509990692139
Validation Loss Energy: 2.1541321573821306, Validation Loss Force: 5.72636327627837, time: 0.06199812889099121
Test Loss Energy: 6.791803846950086, Test Loss Force: 9.29938833950152, time: 10.51462435722351


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.8212790307000057, Training Loss Force: 4.730771163601903, time: 0.739722490310669
Validation Loss Energy: 3.592332019372006, Validation Loss Force: 4.734456622776381, time: 0.06744861602783203
Test Loss Energy: 6.484453883635126, Test Loss Force: 8.518160640519387, time: 10.25390887260437


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9716541565384813, Training Loss Force: 4.44929862787081, time: 0.7443315982818604
Validation Loss Energy: 1.9384898930269587, Validation Loss Force: 4.625632421763678, time: 0.06879782676696777
Test Loss Energy: 6.44587387067472, Test Loss Force: 8.505568744617836, time: 10.549778461456299


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.933567060000882, Training Loss Force: 4.451105499958024, time: 0.7504878044128418
Validation Loss Energy: 2.9145303678704355, Validation Loss Force: 4.808740608541914, time: 0.06739425659179688
Test Loss Energy: 7.962063304327908, Test Loss Force: 8.536737477362621, time: 10.323323965072632


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.914269329723653, Training Loss Force: 4.459910034765395, time: 0.7389299869537354
Validation Loss Energy: 4.019000616687267, Validation Loss Force: 4.568049289950168, time: 0.0699758529663086
Test Loss Energy: 8.922451267296788, Test Loss Force: 8.491621388179183, time: 10.391732692718506


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9692446485320447, Training Loss Force: 4.446873056615752, time: 0.74249267578125
Validation Loss Energy: 2.216797378447723, Validation Loss Force: 4.723393306260959, time: 0.061962127685546875
Test Loss Energy: 7.198256458232444, Test Loss Force: 8.427845666536047, time: 10.807826280593872


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9058505951033644, Training Loss Force: 4.442475227059929, time: 0.667043924331665
Validation Loss Energy: 2.659054931334815, Validation Loss Force: 4.786426488090198, time: 0.06199169158935547
Test Loss Energy: 6.523431254932569, Test Loss Force: 8.46198945492601, time: 10.464153051376343


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.987635602728476, Training Loss Force: 4.466730680692888, time: 0.738006591796875
Validation Loss Energy: 3.4240232033741416, Validation Loss Force: 4.7511715048845975, time: 0.07349896430969238
Test Loss Energy: 6.5850280155885335, Test Loss Force: 8.48911846573502, time: 10.479624032974243


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.98127419120105, Training Loss Force: 4.449463076802606, time: 0.725947380065918
Validation Loss Energy: 1.9801767858472568, Validation Loss Force: 4.692884961239102, time: 0.0695946216583252
Test Loss Energy: 6.4863285153559715, Test Loss Force: 8.478113741515962, time: 10.330324172973633


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.969422079592883, Training Loss Force: 4.448915756041914, time: 0.7556843757629395
Validation Loss Energy: 3.0882149737238613, Validation Loss Force: 4.643049379689003, time: 0.06861042976379395
Test Loss Energy: 8.156232503986843, Test Loss Force: 8.49668869441501, time: 10.371044635772705


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9156463985757064, Training Loss Force: 4.465646126601653, time: 0.774346113204956
Validation Loss Energy: 4.069724202791324, Validation Loss Force: 4.920294955952839, time: 0.07017993927001953
Test Loss Energy: 8.886988377559891, Test Loss Force: 8.477589319537282, time: 11.26840591430664


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.999542679956397, Training Loss Force: 4.435891542530522, time: 0.7097368240356445
Validation Loss Energy: 2.7017350398805235, Validation Loss Force: 4.586037616903944, time: 0.06852126121520996
Test Loss Energy: 7.818111574296602, Test Loss Force: 8.526922212083669, time: 10.441227197647095


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9161588742042355, Training Loss Force: 4.438799694786678, time: 0.7057461738586426
Validation Loss Energy: 2.444526458047574, Validation Loss Force: 4.87826659999726, time: 0.06223344802856445
Test Loss Energy: 6.611120686886569, Test Loss Force: 8.450099001808347, time: 10.500269412994385


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9257401152410663, Training Loss Force: 4.443115789230888, time: 0.7360556125640869
Validation Loss Energy: 3.711882304478624, Validation Loss Force: 4.708526132725654, time: 0.07003617286682129
Test Loss Energy: 6.570400611256915, Test Loss Force: 8.504651086595835, time: 10.511942148208618

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ˆâ–…â–„â–„â–‚â–â–â–„â–…â–‚â–â–â–â–„â–…â–ƒâ–â–
wandb:   test_error_force â–„â–‚â–„â–†â–‡â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–‚
wandb:          test_loss â–â–‚â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–â–â–â–‚â–ƒâ–‚â–â–‚
wandb: train_error_energy â–ˆâ–„â–â–„â–‚â–‚â–ƒâ–â–â–â–â–â–â–‚â–‚â–â–â–‚â–â–
wandb:  train_error_force â–…â–„â–‡â–ƒâ–ˆâ–†â–‡â–„â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–‡â–ˆâ–ƒâ–…â–…â–ƒâ–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–ˆâ–„â–‚â–ƒâ–â–„â–â–ƒâ–„â–â–‚â–ƒâ–â–ƒâ–„â–‚â–‚â–„
wandb:  valid_error_force â–„â–„â–…â–…â–ˆâ–„â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–â–ƒâ–‚
wandb:         valid_loss â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–â–‚â–‚â–â–‚â–ƒâ–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1355
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.5704
wandb:   test_error_force 8.50465
wandb:          test_loss 5.33721
wandb: train_error_energy 2.92574
wandb:  train_error_force 4.44312
wandb:         train_loss 1.426
wandb: valid_error_energy 3.71188
wandb:  valid_error_force 4.70853
wandb:         valid_loss 1.92744
wandb: 
wandb: ğŸš€ View run al_73_66 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/i0s6nwi6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_081559-i0s6nwi6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8515669107437134, Uncertainty Bias: 0.06665179133415222
0.00016498566 0.019039154
3.162777 14.234683
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3338 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_090008-o6dks5v8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_67
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o6dks5v8
Training model 67. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.450453391243087, Training Loss Force: 4.856000809106916, time: 0.7606792449951172
Validation Loss Energy: 1.8388035884248395, Validation Loss Force: 5.022979277935729, time: 0.07424736022949219
Test Loss Energy: 6.233032163383068, Test Loss Force: 8.680249248135786, time: 10.797006130218506


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.578089027245693, Training Loss Force: 4.910489409410775, time: 0.7563998699188232
Validation Loss Energy: 7.719818157301019, Validation Loss Force: 4.879581238634818, time: 0.06993412971496582
Test Loss Energy: 11.988505319855852, Test Loss Force: 8.66221647945158, time: 11.693646669387817


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.368849904169398, Training Loss Force: 4.634498843058558, time: 0.7308785915374756
Validation Loss Energy: 3.14291242474072, Validation Loss Force: 5.093082873155613, time: 0.07062292098999023
Test Loss Energy: 8.012908920118779, Test Loss Force: 8.454852486776874, time: 10.923628568649292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.352042060281934, Training Loss Force: 4.6787817085815995, time: 0.7875821590423584
Validation Loss Energy: 8.317244374546485, Validation Loss Force: 5.064107605203468, time: 0.06851458549499512
Test Loss Energy: 8.504706243258832, Test Loss Force: 8.50284260276682, time: 10.74021863937378


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.2361334953976755, Training Loss Force: 4.677752531789121, time: 0.7723443508148193
Validation Loss Energy: 5.507318070700557, Validation Loss Force: 4.935796513884893, time: 0.07403874397277832
Test Loss Energy: 9.565934498924731, Test Loss Force: 8.482624388876651, time: 11.114915370941162


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.30944405192167, Training Loss Force: 4.890509213736334, time: 0.7103128433227539
Validation Loss Energy: 6.221541825736108, Validation Loss Force: 5.1118897318898195, time: 0.06423115730285645
Test Loss Energy: 10.062460356430899, Test Loss Force: 8.48833025892749, time: 11.125730276107788


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.095762575817073, Training Loss Force: 4.6066134473653895, time: 0.7112076282501221
Validation Loss Energy: 8.378733568517859, Validation Loss Force: 4.654015835125947, time: 0.06486320495605469
Test Loss Energy: 8.823730852485808, Test Loss Force: 8.392293904996365, time: 10.852848291397095


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.380248643272223, Training Loss Force: 4.742255133204098, time: 0.723067045211792
Validation Loss Energy: 1.8970461549140143, Validation Loss Force: 4.679438416854815, time: 0.07125091552734375
Test Loss Energy: 6.312908564023456, Test Loss Force: 8.504307546575301, time: 9.337524890899658


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.046602639774299, Training Loss Force: 4.637531389692007, time: 0.7242300510406494
Validation Loss Energy: 2.542934753086641, Validation Loss Force: 5.082799121320083, time: 0.07522249221801758
Test Loss Energy: 7.178637548439178, Test Loss Force: 8.560622494830454, time: 10.970225811004639


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.962071711534756, Training Loss Force: 4.572653885932218, time: 0.7153916358947754
Validation Loss Energy: 2.3104119407786836, Validation Loss Force: 4.871909841219313, time: 0.06809258460998535
Test Loss Energy: 6.599583885999762, Test Loss Force: 8.515193503035668, time: 8.138889074325562


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.971977000908315, Training Loss Force: 4.472123520273169, time: 0.6659801006317139
Validation Loss Energy: 3.6640363830819638, Validation Loss Force: 4.771418142316373, time: 0.06017422676086426
Test Loss Energy: 6.556732519233082, Test Loss Force: 8.475143120600787, time: 8.24729609489441


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0388707064659, Training Loss Force: 4.461663393760658, time: 0.6950345039367676
Validation Loss Energy: 2.152937426079655, Validation Loss Force: 4.671764792747851, time: 0.06701374053955078
Test Loss Energy: 6.427686821417563, Test Loss Force: 8.432677647624649, time: 7.971681356430054


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.97869154757695, Training Loss Force: 4.439030866786969, time: 0.6901462078094482
Validation Loss Energy: 2.9360728283969384, Validation Loss Force: 4.81358655716474, time: 0.05738377571105957
Test Loss Energy: 8.119109055013865, Test Loss Force: 8.494291249529208, time: 7.96668004989624


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9771322784016534, Training Loss Force: 4.458394817832526, time: 0.7039415836334229
Validation Loss Energy: 3.890981889957295, Validation Loss Force: 4.822182031535844, time: 0.06198000907897949
Test Loss Energy: 8.477791673329614, Test Loss Force: 8.463777299307072, time: 8.047059059143066


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9576337212682065, Training Loss Force: 4.4586347619614966, time: 0.8669590950012207
Validation Loss Energy: 2.740756137685774, Validation Loss Force: 4.792726243566787, time: 0.05898594856262207
Test Loss Energy: 7.712644839288165, Test Loss Force: 8.461478215893418, time: 8.033634185791016


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.906021718931186, Training Loss Force: 4.446070960925303, time: 0.6896748542785645
Validation Loss Energy: 2.721728168489661, Validation Loss Force: 4.639284935107948, time: 0.05913901329040527
Test Loss Energy: 6.499675040490491, Test Loss Force: 8.474635999198682, time: 7.974959373474121


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0045449371413135, Training Loss Force: 4.444521411517144, time: 0.7402441501617432
Validation Loss Energy: 3.4240766439691646, Validation Loss Force: 4.712836562052523, time: 0.06014442443847656
Test Loss Energy: 6.4434800980811175, Test Loss Force: 8.387412829441413, time: 7.9711833000183105


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9776800211980508, Training Loss Force: 4.436286547238692, time: 0.7003076076507568
Validation Loss Energy: 2.24767268222207, Validation Loss Force: 4.661456769975416, time: 0.05836820602416992
Test Loss Energy: 6.325157941151442, Test Loss Force: 8.418666008585436, time: 8.204689502716064


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.069839054873132, Training Loss Force: 4.440548672895954, time: 0.7248208522796631
Validation Loss Energy: 3.0351712864538083, Validation Loss Force: 4.611044698006511, time: 0.06149029731750488
Test Loss Energy: 7.972289152859041, Test Loss Force: 8.447203995138226, time: 8.062148809432983


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0837810873014546, Training Loss Force: 4.451185148193689, time: 0.6878314018249512
Validation Loss Energy: 3.8303473001679906, Validation Loss Force: 4.577098786709819, time: 0.05931258201599121
Test Loss Energy: 8.642631266145195, Test Loss Force: 8.480884683000168, time: 8.88265085220337

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–ƒâ–„â–…â–†â–„â–â–‚â–â–â–â–ƒâ–„â–ƒâ–â–â–â–ƒâ–„
wandb:   test_error_force â–ˆâ–ˆâ–ƒâ–„â–ƒâ–ƒâ–â–„â–…â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒ
wandb:          test_loss â–„â–‡â–ƒâ–ƒâ–„â–„â–ƒâ–â–‚â–„â–„â–„â–‡â–ˆâ–†â–…â–„â–„â–†â–‡
wandb: train_error_energy â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–‡â–ˆâ–„â–…â–…â–ˆâ–„â–†â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–‚â–ˆâ–…â–†â–ˆâ–â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–ƒ
wandb:  valid_error_force â–‡â–…â–ˆâ–‡â–†â–ˆâ–‚â–‚â–ˆâ–…â–„â–‚â–„â–„â–„â–‚â–ƒâ–‚â–â–
wandb:         valid_loss â–â–‡â–ƒâ–ˆâ–„â–…â–‡â–‚â–ƒâ–â–ƒâ–â–‚â–„â–‚â–‚â–ƒâ–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1356
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.64263
wandb:   test_error_force 8.48088
wandb:          test_loss 6.04009
wandb: train_error_energy 3.08378
wandb:  train_error_force 4.45119
wandb:         train_loss 1.46968
wandb: valid_error_energy 3.83035
wandb:  valid_error_force 4.5771
wandb:         valid_loss 1.77843
wandb: 
wandb: ğŸš€ View run al_73_67 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o6dks5v8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_090008-o6dks5v8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9797080755233765, Uncertainty Bias: 0.0023628175258636475
0.0002784729 0.023781657
2.8372178 9.710177
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2287 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
