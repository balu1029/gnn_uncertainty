wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_101105-4olmz3dp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/4olmz3dp
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
72
Uncertainty Slope: 0.044184185564517975, Uncertainty Bias: 0.2551637291908264
0.0014572144 0.0016615391
3.8687816 7.0848565
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 11.451026320906859, Test Loss Force: 12.623542414663762, time: 6.9197447299957275

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.050 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.45103
wandb:   test_error_force 12.62354
wandb:          test_loss 10.20482
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_73 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/4olmz3dp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_101105-4olmz3dp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 801 steps.
Found uncertainty sample 1 after 502 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 667 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1228 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1114 steps.
Found uncertainty sample 9 after 866 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 929 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2936 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1742 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3095 steps.
Found uncertainty sample 21 after 759 steps.
Found uncertainty sample 22 after 2021 steps.
Found uncertainty sample 23 after 644 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2126 steps.
Found uncertainty sample 26 after 2650 steps.
Found uncertainty sample 27 after 3016 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2061 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1713 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1756 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 388 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2012 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1307 steps.
Found uncertainty sample 54 after 508 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2396 steps.
Found uncertainty sample 58 after 1683 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 984 steps.
Found uncertainty sample 61 after 888 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 553 steps.
Found uncertainty sample 64 after 978 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1590 steps.
Found uncertainty sample 69 after 629 steps.
Found uncertainty sample 70 after 730 steps.
Found uncertainty sample 71 after 1782 steps.
Found uncertainty sample 72 after 3654 steps.
Found uncertainty sample 73 after 1531 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1419 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1276 steps.
Found uncertainty sample 78 after 1560 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3003 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1347 steps.
Found uncertainty sample 85 after 3915 steps.
Found uncertainty sample 86 after 1161 steps.
Found uncertainty sample 87 after 1728 steps.
Found uncertainty sample 88 after 340 steps.
Found uncertainty sample 89 after 2677 steps.
Found uncertainty sample 90 after 2681 steps.
Found uncertainty sample 91 after 1165 steps.
Found uncertainty sample 92 after 2172 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1954 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3975 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_104008-sgn1qt1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/sgn1qt1r
Training model 0. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.984426568802441, Training Loss Force: 4.152210816825505, time: 0.6339781284332275
Validation Loss Energy: 1.6669938567801257, Validation Loss Force: 4.307779564033576, time: 0.050642967224121094
Test Loss Energy: 10.595034035701595, Test Loss Force: 12.210026295065898, time: 8.53928804397583


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3835221062259637, Training Loss Force: 3.9774389257795204, time: 0.4616246223449707
Validation Loss Energy: 3.072388652842471, Validation Loss Force: 4.485175619211327, time: 0.03653669357299805
Test Loss Energy: 11.85208693470119, Test Loss Force: 12.38994661628322, time: 8.25227952003479


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.620067143184394, Training Loss Force: 3.9839252780003966, time: 0.4408407211303711
Validation Loss Energy: 2.5770865220087424, Validation Loss Force: 4.3552521806070885, time: 0.04076337814331055
Test Loss Energy: 11.460395291932176, Test Loss Force: 11.814083532237714, time: 8.43004059791565


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.746065073894042, Training Loss Force: 4.416891519558863, time: 0.4375576972961426
Validation Loss Energy: 2.3331573713660614, Validation Loss Force: 4.404005590107978, time: 0.0369870662689209
Test Loss Energy: 11.010072004481508, Test Loss Force: 11.842886152326885, time: 8.64626693725586


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.3786320340624707, Training Loss Force: 3.8891051849133835, time: 0.45798420906066895
Validation Loss Energy: 4.769934275127911, Validation Loss Force: 5.178055200594824, time: 0.04093289375305176
Test Loss Energy: 9.809951889502779, Test Loss Force: 12.154067053193621, time: 8.293073177337646


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 5.324839109817189, Training Loss Force: 4.240701259041338, time: 0.4499642848968506
Validation Loss Energy: 10.898606366826186, Validation Loss Force: 4.663035271550898, time: 0.03955388069152832
Test Loss Energy: 11.229585590527451, Test Loss Force: 12.204354363989806, time: 8.44908094406128


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.8326697228660067, Training Loss Force: 4.2220273915162885, time: 0.44342517852783203
Validation Loss Energy: 1.9197429322930066, Validation Loss Force: 4.99296637176356, time: 0.04885125160217285
Test Loss Energy: 9.89247723924639, Test Loss Force: 11.822325676140709, time: 8.665773868560791


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.4362677955007013, Training Loss Force: 4.267420740099138, time: 0.48285341262817383
Validation Loss Energy: 1.9090100567901414, Validation Loss Force: 4.312502821956997, time: 0.040474653244018555
Test Loss Energy: 10.344937082618717, Test Loss Force: 11.601511427152076, time: 8.468175411224365


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.486353096374455, Training Loss Force: 3.948067446946715, time: 0.42675352096557617
Validation Loss Energy: 2.686392356384088, Validation Loss Force: 4.413016119767092, time: 0.039575815200805664
Test Loss Energy: 9.689906466907592, Test Loss Force: 11.690781222475415, time: 8.361344337463379


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0039127732028224, Training Loss Force: 3.908736851399133, time: 0.504169225692749
Validation Loss Energy: 3.483322112291598, Validation Loss Force: 4.159369242257831, time: 0.04073905944824219
Test Loss Energy: 11.284414978842305, Test Loss Force: 11.627488494691743, time: 8.712056636810303


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.01724769849246, Training Loss Force: 3.769308986476103, time: 0.47263312339782715
Validation Loss Energy: 2.7159781831343675, Validation Loss Force: 4.11718190053206, time: 0.04080700874328613
Test Loss Energy: 9.753131032284854, Test Loss Force: 11.64881110557666, time: 8.838737487792969


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9189303802935145, Training Loss Force: 3.665221370547554, time: 0.4321784973144531
Validation Loss Energy: 2.4859551659931687, Validation Loss Force: 4.056047641179294, time: 0.037442922592163086
Test Loss Energy: 10.644245614366694, Test Loss Force: 11.477562630750077, time: 8.496470928192139


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.894665517306866, Training Loss Force: 3.631140793899609, time: 0.4745044708251953
Validation Loss Energy: 2.8649287002581345, Validation Loss Force: 4.0525726664879445, time: 0.04319357872009277
Test Loss Energy: 9.58858148993089, Test Loss Force: 11.476140299520768, time: 8.229812860488892


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9693098147385304, Training Loss Force: 3.6190443915111468, time: 0.4479787349700928
Validation Loss Energy: 2.272325274044319, Validation Loss Force: 4.075473297470034, time: 0.042687177658081055
Test Loss Energy: 10.580753682801335, Test Loss Force: 11.482758791307164, time: 8.787230014801025


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9222628838429934, Training Loss Force: 3.629844867717314, time: 0.45330333709716797
Validation Loss Energy: 3.026776659652331, Validation Loss Force: 4.073839351277216, time: 0.035578012466430664
Test Loss Energy: 9.535134002656958, Test Loss Force: 11.513548039868551, time: 8.345810413360596


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9639726332387712, Training Loss Force: 3.6789036143463085, time: 0.5001363754272461
Validation Loss Energy: 2.372628372180659, Validation Loss Force: 4.063641995070307, time: 0.04185795783996582
Test Loss Energy: 10.480328652905976, Test Loss Force: 11.461614665481104, time: 8.372413158416748


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.885209175153087, Training Loss Force: 3.65620066408377, time: 0.45662450790405273
Validation Loss Energy: 2.8998875334996512, Validation Loss Force: 4.06547634349446, time: 0.04090714454650879
Test Loss Energy: 9.495255600077614, Test Loss Force: 11.384341719489747, time: 8.50486135482788


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.958201387103545, Training Loss Force: 3.614909301766186, time: 0.4532647132873535
Validation Loss Energy: 2.3082656328810858, Validation Loss Force: 4.038600177580976, time: 0.03710460662841797
Test Loss Energy: 10.369933790370178, Test Loss Force: 11.408469849695878, time: 7.9564409255981445


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.87082952334228, Training Loss Force: 3.5957155430204213, time: 0.4255256652832031
Validation Loss Energy: 2.9288968698311235, Validation Loss Force: 4.051172968236642, time: 0.032788991928100586
Test Loss Energy: 9.466455008492705, Test Loss Force: 11.431493769436388, time: 8.114354372024536


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9227174629044055, Training Loss Force: 3.6254053232738275, time: 0.44121384620666504
Validation Loss Energy: 2.2677707993335123, Validation Loss Force: 4.081274274059744, time: 0.04333066940307617
Test Loss Energy: 10.378200980471766, Test Loss Force: 11.49988127453313, time: 9.150200843811035

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–‡â–†â–‚â–†â–‚â–„â–‚â–†â–‚â–„â–â–„â–â–„â–â–„â–â–„
wandb:   test_error_force â–‡â–ˆâ–„â–„â–†â–‡â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚
wandb:          test_loss â–â–‚â–…â–„â–„â–ˆâ–…â–†â–…â–‡â–ƒâ–…â–„â–…â–‚â–„â–ƒâ–ƒâ–‚â–‚
wandb: train_error_energy â–‡â–ƒâ–â–„â–ƒâ–ˆâ–„â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–†â–„â–„â–ˆâ–„â–†â–†â–‡â–„â–„â–‚â–‚â–â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–‡â–‚â–â–„â–ƒâ–ˆâ–„â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–‚â–‚â–ƒâ–ˆâ–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–
wandb:  valid_error_force â–ƒâ–„â–ƒâ–ƒâ–ˆâ–…â–‡â–ƒâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–‚â–â–â–ƒâ–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 845
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.3782
wandb:   test_error_force 11.49988
wandb:          test_loss 10.53395
wandb: train_error_energy 2.92272
wandb:  train_error_force 3.62541
wandb:         train_loss 1.06695
wandb: valid_error_energy 2.26777
wandb:  valid_error_force 4.08127
wandb:         valid_loss 1.03877
wandb: 
wandb: ğŸš€ View run al_73_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/sgn1qt1r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_104008-sgn1qt1r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.16490259766578674, Uncertainty Bias: 0.24581125378608704
1.335144e-05 0.0016336441
3.858809 11.501208
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1181 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2608 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 945 steps.
Found uncertainty sample 9 after 1356 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1320 steps.
Found uncertainty sample 14 after 421 steps.
Found uncertainty sample 15 after 1180 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 203 steps.
Found uncertainty sample 19 after 1160 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 855 steps.
Found uncertainty sample 22 after 518 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 967 steps.
Found uncertainty sample 25 after 870 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 432 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2436 steps.
Found uncertainty sample 31 after 1019 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1574 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 690 steps.
Found uncertainty sample 40 after 3066 steps.
Found uncertainty sample 41 after 481 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1557 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2994 steps.
Found uncertainty sample 47 after 2250 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2106 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2082 steps.
Found uncertainty sample 52 after 1122 steps.
Found uncertainty sample 53 after 1556 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1764 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 311 steps.
Found uncertainty sample 61 after 2108 steps.
Found uncertainty sample 62 after 2839 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1059 steps.
Found uncertainty sample 66 after 634 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2902 steps.
Found uncertainty sample 71 after 1545 steps.
Found uncertainty sample 72 after 1303 steps.
Found uncertainty sample 73 after 3577 steps.
Found uncertainty sample 74 after 2625 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1226 steps.
Found uncertainty sample 79 after 680 steps.
Found uncertainty sample 80 after 1246 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 798 steps.
Found uncertainty sample 83 after 2801 steps.
Found uncertainty sample 84 after 3028 steps.
Found uncertainty sample 85 after 1556 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 827 steps.
Found uncertainty sample 88 after 1683 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2609 steps.
Found uncertainty sample 91 after 915 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2054 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2872 steps.
Found uncertainty sample 96 after 2858 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1568 steps.
Found uncertainty sample 99 after 1095 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_111043-uev4o3gv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uev4o3gv
Training model 1. Added 54 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.15559590880899, Training Loss Force: 4.420833174613911, time: 0.5014481544494629
Validation Loss Energy: 2.1072040782049846, Validation Loss Force: 4.382687246076852, time: 0.04241371154785156
Test Loss Energy: 10.300021899295256, Test Loss Force: 11.504346208267908, time: 8.588073968887329


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.909278645488059, Training Loss Force: 4.309576623328256, time: 0.5141720771789551
Validation Loss Energy: 2.419654982454878, Validation Loss Force: 4.897627459566535, time: 0.04342246055603027
Test Loss Energy: 10.177371168417835, Test Loss Force: 12.057062897547802, time: 8.29610800743103


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.344357674141367, Training Loss Force: 4.196230687921666, time: 0.4799172878265381
Validation Loss Energy: 4.003621972123764, Validation Loss Force: 4.265849627840498, time: 0.04314708709716797
Test Loss Energy: 9.54468455978788, Test Loss Force: 11.192257684646231, time: 8.480543375015259


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.3689249160847345, Training Loss Force: 3.971600598207796, time: 0.6382772922515869
Validation Loss Energy: 2.32113435083169, Validation Loss Force: 4.232728928398616, time: 0.04279685020446777
Test Loss Energy: 10.003736445116326, Test Loss Force: 11.141638044230074, time: 8.189374446868896


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.33197943667572, Training Loss Force: 3.950076937319185, time: 0.49266719818115234
Validation Loss Energy: 2.948425399267282, Validation Loss Force: 4.256905008248579, time: 0.0472254753112793
Test Loss Energy: 10.394175498162033, Test Loss Force: 11.203770019906356, time: 8.343416929244995


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.32087850100334, Training Loss Force: 3.969242508095012, time: 0.4598703384399414
Validation Loss Energy: 4.083533029876036, Validation Loss Force: 4.252972671131494, time: 0.047846317291259766
Test Loss Energy: 9.493371007701361, Test Loss Force: 11.1950382976657, time: 9.740389108657837


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.378729137985805, Training Loss Force: 3.9477253443739793, time: 0.5017590522766113
Validation Loss Energy: 2.265868982158143, Validation Loss Force: 4.225436959207772, time: 0.05170392990112305
Test Loss Energy: 10.023169124228716, Test Loss Force: 11.18991130210908, time: 9.733780145645142


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.236177444227391, Training Loss Force: 3.9480244049419007, time: 0.5090532302856445
Validation Loss Energy: 2.7541452334304117, Validation Loss Force: 4.242965474375207, time: 0.045287132263183594
Test Loss Energy: 10.024773899597609, Test Loss Force: 11.106810155601858, time: 8.570896625518799


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2671862938220078, Training Loss Force: 3.9571854430387225, time: 0.47565555572509766
Validation Loss Energy: 3.879972904713479, Validation Loss Force: 4.248874222831548, time: 0.03496241569519043
Test Loss Energy: 9.572030620552852, Test Loss Force: 11.102630886562586, time: 8.422610521316528


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.237688914437478, Training Loss Force: 3.9501415193239735, time: 0.5201220512390137
Validation Loss Energy: 2.4547006566633063, Validation Loss Force: 4.244423511942743, time: 0.04757285118103027
Test Loss Energy: 9.966989437570357, Test Loss Force: 11.164405864141782, time: 8.874531984329224


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.159766586399712, Training Loss Force: 3.936636937817294, time: 0.4853665828704834
Validation Loss Energy: 2.521605164263645, Validation Loss Force: 4.22677564611309, time: 0.047162771224975586
Test Loss Energy: 9.954112403918087, Test Loss Force: 11.139695399326119, time: 7.996690988540649


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.135340401384055, Training Loss Force: 3.946355324738842, time: 0.43960142135620117
Validation Loss Energy: 3.7310402011213863, Validation Loss Force: 4.246788258272496, time: 0.035657644271850586
Test Loss Energy: 9.414971225261223, Test Loss Force: 11.06237426353468, time: 7.9195239543914795


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.160015582195912, Training Loss Force: 3.95303107297327, time: 0.4946708679199219
Validation Loss Energy: 2.1453475255715606, Validation Loss Force: 4.283968661582934, time: 0.03961515426635742
Test Loss Energy: 9.849772402767412, Test Loss Force: 11.144603372381253, time: 8.323221683502197


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.2023198411282334, Training Loss Force: 3.9442518249845486, time: 0.6293931007385254
Validation Loss Energy: 2.570251915243635, Validation Loss Force: 4.2505339986452935, time: 0.03945159912109375
Test Loss Energy: 10.069784287387735, Test Loss Force: 11.1857512222538, time: 8.463074207305908


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1021732356628995, Training Loss Force: 3.9510079011133703, time: 0.47729969024658203
Validation Loss Energy: 3.8436194946110165, Validation Loss Force: 4.26655326234163, time: 0.04201626777648926
Test Loss Energy: 9.672392598939894, Test Loss Force: 11.225378178906075, time: 8.514312028884888


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.2736941336154666, Training Loss Force: 3.9486012134594866, time: 0.48128747940063477
Validation Loss Energy: 2.3135934375356997, Validation Loss Force: 4.23807254256259, time: 0.038735151290893555
Test Loss Energy: 9.85768119114023, Test Loss Force: 11.090848998060343, time: 8.40805697441101


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.049815747104605, Training Loss Force: 3.945384304355799, time: 0.5232288837432861
Validation Loss Energy: 2.3537353404869776, Validation Loss Force: 4.260544312769623, time: 0.04137611389160156
Test Loss Energy: 9.849128951889263, Test Loss Force: 11.12181884878618, time: 8.571433782577515


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.069184129710025, Training Loss Force: 3.9441307565889203, time: 0.4511086940765381
Validation Loss Energy: 4.006218739703574, Validation Loss Force: 4.284132991412629, time: 0.0452275276184082
Test Loss Energy: 9.423887224290143, Test Loss Force: 11.082588560313173, time: 8.815617084503174


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0979233802961907, Training Loss Force: 3.970296393210218, time: 0.5074646472930908
Validation Loss Energy: 2.154890011820296, Validation Loss Force: 4.258572354813286, time: 0.044030189514160156
Test Loss Energy: 9.752750261050474, Test Loss Force: 11.065214057583068, time: 8.331180334091187


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.1305162822899995, Training Loss Force: 3.9585127499601893, time: 0.5008265972137451
Validation Loss Energy: 2.660384154801431, Validation Loss Force: 4.25959084348676, time: 0.04265284538269043
Test Loss Energy: 9.953935625600748, Test Loss Force: 11.111682380349707, time: 8.715696573257446

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–‚â–…â–ˆâ–‚â–…â–…â–‚â–…â–…â–â–„â–†â–ƒâ–„â–„â–â–ƒâ–…
wandb:   test_error_force â–„â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–
wandb:          test_loss â–„â–â–…â–‡â–‡â–…â–‡â–ˆâ–†â–‡â–†â–…â–‡â–‡â–…â–‡â–†â–„â–ˆâ–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–ˆâ–‚â–„â–ˆâ–‚â–ƒâ–‡â–‚â–‚â–‡â–â–ƒâ–‡â–‚â–‚â–ˆâ–â–ƒ
wandb:  valid_error_force â–ƒâ–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–â–
wandb:         valid_loss â–‚â–„â–ˆâ–â–ƒâ–ˆâ–â–ƒâ–‡â–‚â–‚â–‡â–â–‚â–‡â–â–‚â–ˆâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 893
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.95394
wandb:   test_error_force 11.11168
wandb:          test_loss 10.96439
wandb: train_error_energy 3.13052
wandb:  train_error_force 3.95851
wandb:         train_loss 1.21258
wandb: valid_error_energy 2.66038
wandb:  valid_error_force 4.25959
wandb:         valid_loss 1.20746
wandb: 
wandb: ğŸš€ View run al_73_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uev4o3gv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_111043-uev4o3gv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 0.349067360162735, Uncertainty Bias: 0.2268189787864685
6.1035156e-05 0.055938244
3.8525083 14.577389
(48745, 22, 3)
Found uncertainty sample 0 after 3387 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1798 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3508 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3661 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3091 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2018 steps.
Found uncertainty sample 25 after 1951 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1979 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1086 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1849 steps.
Found uncertainty sample 34 after 427 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1887 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1499 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 772 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 610 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1444 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1368 steps.
Found uncertainty sample 58 after 2585 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2438 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3693 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 529 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2027 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2872 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1083 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1022 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3447 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_114835-s3iwgnqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/s3iwgnqx
Training model 2. Added 26 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.207906034341742, Training Loss Force: 4.577203548703855, time: 0.4884912967681885
Validation Loss Energy: 2.8862042918132427, Validation Loss Force: 4.384589731259658, time: 0.05273580551147461
Test Loss Energy: 9.950133621048261, Test Loss Force: 11.004788156581586, time: 9.597780227661133


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2235088235720495, Training Loss Force: 4.593958296267438, time: 0.5478277206420898
Validation Loss Energy: 3.8964597736162645, Validation Loss Force: 4.515777039936182, time: 0.046485185623168945
Test Loss Energy: 10.459554675480486, Test Loss Force: 10.928275032327788, time: 9.421550989151001


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.52568943211325, Training Loss Force: 4.76932803150426, time: 0.5227696895599365
Validation Loss Energy: 5.239704271012974, Validation Loss Force: 4.862681318466336, time: 0.044692277908325195
Test Loss Energy: 10.649118538598774, Test Loss Force: 10.86592406679262, time: 9.517577409744263


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.467916322558687, Training Loss Force: 4.946563565262535, time: 0.48267054557800293
Validation Loss Energy: 5.223785653770597, Validation Loss Force: 4.766852979486561, time: 0.04164743423461914
Test Loss Energy: 11.71738199678509, Test Loss Force: 11.391635656562883, time: 9.838995218276978


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.040667553105465, Training Loss Force: 4.731303512496348, time: 0.5503673553466797
Validation Loss Energy: 2.3991892385835087, Validation Loss Force: 4.496159442841653, time: 0.04482460021972656
Test Loss Energy: 9.562806960381065, Test Loss Force: 11.080480039719378, time: 9.456178426742554


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.164994021017238, Training Loss Force: 4.58916962736284, time: 0.54154372215271
Validation Loss Energy: 6.231095890780432, Validation Loss Force: 4.649887994498738, time: 0.044567108154296875
Test Loss Energy: 11.992336968549921, Test Loss Force: 11.02829736448983, time: 9.648821115493774


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.3660019252173194, Training Loss Force: 4.5821590121552465, time: 0.5033748149871826
Validation Loss Energy: 5.5495439341885735, Validation Loss Force: 4.44909252945202, time: 0.047582387924194336
Test Loss Energy: 10.453262064069477, Test Loss Force: 10.747590804385014, time: 9.473264932632446


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.41719449861218, Training Loss Force: 4.283495727673476, time: 0.5062739849090576
Validation Loss Energy: 2.3592798022205796, Validation Loss Force: 4.410552953674839, time: 0.044801950454711914
Test Loss Energy: 9.99138942931656, Test Loss Force: 10.808472890347115, time: 9.483973026275635


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.330600041801378, Training Loss Force: 4.260450469241984, time: 0.5165097713470459
Validation Loss Energy: 3.402903814224902, Validation Loss Force: 4.380465008000492, time: 0.05031991004943848
Test Loss Energy: 10.29944909166091, Test Loss Force: 10.872862763805703, time: 9.503478288650513


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.31094831490155, Training Loss Force: 4.242647856034157, time: 0.49990391731262207
Validation Loss Energy: 5.632530052846109, Validation Loss Force: 4.401513031688462, time: 0.04618477821350098
Test Loss Energy: 10.593252985644003, Test Loss Force: 10.739051808702097, time: 9.443115472793579


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.371985152663849, Training Loss Force: 4.213386588759684, time: 0.5238630771636963
Validation Loss Energy: 5.058954373159261, Validation Loss Force: 4.40941555967744, time: 0.045316457748413086
Test Loss Energy: 10.892268792569004, Test Loss Force: 10.944454517549785, time: 9.392678499221802


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.318156944405845, Training Loss Force: 4.199856213281079, time: 0.49889087677001953
Validation Loss Energy: 2.3592864822949573, Validation Loss Force: 4.3593577543197055, time: 0.04642128944396973
Test Loss Energy: 9.66165458339376, Test Loss Force: 10.783621437490444, time: 9.514085054397583


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.178827792156197, Training Loss Force: 4.214252979049997, time: 0.48880863189697266
Validation Loss Energy: 3.6211164598660908, Validation Loss Force: 4.359983454619763, time: 0.04655599594116211
Test Loss Energy: 9.850035101064096, Test Loss Force: 10.839884665881774, time: 9.653175830841064


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.2400316394561886, Training Loss Force: 4.194833833912212, time: 0.5228128433227539
Validation Loss Energy: 5.851741592275929, Validation Loss Force: 4.361489143384526, time: 0.047289133071899414
Test Loss Energy: 11.459252330040323, Test Loss Force: 10.877401311260636, time: 9.516597509384155


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.37749328861368, Training Loss Force: 4.186568677701723, time: 0.5257208347320557
Validation Loss Energy: 4.58641570911373, Validation Loss Force: 4.440203577146583, time: 0.04638314247131348
Test Loss Energy: 10.052479933599248, Test Loss Force: 10.825079536597498, time: 9.783217191696167


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.358050920619625, Training Loss Force: 4.197025067229563, time: 0.48200201988220215
Validation Loss Energy: 3.0808418416293275, Validation Loss Force: 4.406785391725741, time: 0.045285940170288086
Test Loss Energy: 10.43657547143506, Test Loss Force: 10.893230774574919, time: 9.346544742584229


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.322457464955721, Training Loss Force: 4.191515595264858, time: 0.5041699409484863
Validation Loss Energy: 3.539128344320604, Validation Loss Force: 4.293615134322818, time: 0.04439878463745117
Test Loss Energy: 10.05094826365864, Test Loss Force: 10.793846623843177, time: 9.487837791442871


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.401151079152633, Training Loss Force: 4.181145816356537, time: 0.5209476947784424
Validation Loss Energy: 5.25260794801949, Validation Loss Force: 4.374684962310499, time: 0.047042131423950195
Test Loss Energy: 10.296840617046737, Test Loss Force: 10.748877225828814, time: 9.341717004776001


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.336677803817723, Training Loss Force: 4.16181990048668, time: 0.4894566535949707
Validation Loss Energy: 5.365566669733782, Validation Loss Force: 4.319805924605136, time: 0.046395301818847656
Test Loss Energy: 10.842301216013457, Test Loss Force: 10.797014951643792, time: 9.932812452316284


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.346837974277262, Training Loss Force: 4.125240381383897, time: 0.5916843414306641
Validation Loss Energy: 2.3512076003424056, Validation Loss Force: 4.288527144338368, time: 0.05167889595031738
Test Loss Energy: 9.359366206865253, Test Loss Force: 10.699834642553208, time: 8.24613904953003

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–„â–‡â–‚â–ˆâ–„â–ƒâ–ƒâ–„â–…â–‚â–‚â–‡â–ƒâ–„â–ƒâ–ƒâ–…â–
wandb:   test_error_force â–„â–ƒâ–ƒâ–ˆâ–…â–„â–â–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–
wandb:          test_loss â–†â–ˆâ–‡â–…â–ƒâ–†â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–…â–„â–â–…â–…â–…â–…â–…â–…â–„â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–…â–…â–†â–ˆâ–†â–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–„â–†â–†â–â–ˆâ–‡â–â–ƒâ–‡â–†â–â–ƒâ–‡â–…â–‚â–ƒâ–†â–†â–
wandb:  valid_error_force â–‚â–„â–ˆâ–‡â–„â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–
wandb:         valid_loss â–â–„â–ˆâ–…â–â–ˆâ–†â–â–‚â–…â–„â–â–‚â–…â–ƒâ–‚â–‚â–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 916
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.35937
wandb:   test_error_force 10.69983
wandb:          test_loss 7.22273
wandb: train_error_energy 4.34684
wandb:  train_error_force 4.12524
wandb:         train_loss 1.79897
wandb: valid_error_energy 2.35121
wandb:  valid_error_force 4.28853
wandb:         valid_loss 1.32629
wandb: 
wandb: ğŸš€ View run al_73_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/s3iwgnqx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_114835-s3iwgnqx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.767943859100342, Uncertainty Bias: -0.5018616914749146
0.0002708435 0.022019386
1.7532096 6.0994964
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 3.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1128 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_130836-3feiat68
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3feiat68
Training model 4. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.437324326881301, Training Loss Force: 4.528101946084707, time: 0.5203120708465576
Validation Loss Energy: 1.7190644798824741, Validation Loss Force: 4.76407095117734, time: 0.046625614166259766
Test Loss Energy: 9.971115009537053, Test Loss Force: 10.805258489852012, time: 8.865105390548706


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.828883944144036, Training Loss Force: 4.461429137248075, time: 0.5189356803894043
Validation Loss Energy: 1.8633947235628125, Validation Loss Force: 4.539131025299381, time: 0.04128146171569824
Test Loss Energy: 8.999853776420093, Test Loss Force: 10.629053469785495, time: 8.831305503845215


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.981859804983668, Training Loss Force: 4.493333863518785, time: 0.46445488929748535
Validation Loss Energy: 2.8003715707941663, Validation Loss Force: 4.334642815136596, time: 0.04334306716918945
Test Loss Energy: 9.34825316051864, Test Loss Force: 10.565581342950244, time: 9.055842161178589


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.094094130218532, Training Loss Force: 4.253544462463497, time: 0.46385955810546875
Validation Loss Energy: 1.5965923302429912, Validation Loss Force: 4.703015516702233, time: 0.0448613166809082
Test Loss Energy: 9.69710146426829, Test Loss Force: 10.691815941892024, time: 8.813380241394043


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.900387233776099, Training Loss Force: 4.377623004908552, time: 0.437603235244751
Validation Loss Energy: 2.7999030749111347, Validation Loss Force: 4.440673854382783, time: 0.041596412658691406
Test Loss Energy: 9.69911086328374, Test Loss Force: 10.561273718555128, time: 8.846216917037964


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9593570799262294, Training Loss Force: 4.1920918553362725, time: 0.5046236515045166
Validation Loss Energy: 3.365179875529254, Validation Loss Force: 4.2600615660612515, time: 0.04566764831542969
Test Loss Energy: 10.258871326097454, Test Loss Force: 10.567824141199681, time: 8.87065601348877


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.938108185633893, Training Loss Force: 4.113481001118305, time: 0.4870424270629883
Validation Loss Energy: 2.4770964966915776, Validation Loss Force: 4.268452184818102, time: 0.0475926399230957
Test Loss Energy: 9.930440295459588, Test Loss Force: 10.570596537611081, time: 9.369144916534424


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9599550348828787, Training Loss Force: 4.114137928846516, time: 0.5059647560119629
Validation Loss Energy: 2.2558092354834174, Validation Loss Force: 4.279779809609741, time: 0.04317164421081543
Test Loss Energy: 9.379848634601268, Test Loss Force: 10.524522817213624, time: 8.856382131576538


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9475774828378354, Training Loss Force: 4.096110366053578, time: 0.4686150550842285
Validation Loss Energy: 3.4578837210533697, Validation Loss Force: 4.2532959867313815, time: 0.04092979431152344
Test Loss Energy: 9.60050992037891, Test Loss Force: 10.489652763676137, time: 8.876367568969727


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.988142541627087, Training Loss Force: 4.094182366057946, time: 0.49603796005249023
Validation Loss Energy: 2.5178908202404235, Validation Loss Force: 4.256721974210627, time: 0.04228854179382324
Test Loss Energy: 9.428429945334303, Test Loss Force: 10.504071087508764, time: 8.946042776107788


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9784843211701935, Training Loss Force: 4.100753823962046, time: 0.48046088218688965
Validation Loss Energy: 2.278034288276762, Validation Loss Force: 4.27624204221924, time: 0.0392298698425293
Test Loss Energy: 10.160977053455303, Test Loss Force: 10.519253751747062, time: 8.743651628494263


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0091451561657805, Training Loss Force: 4.097336996630769, time: 0.47885918617248535
Validation Loss Energy: 3.808358054000184, Validation Loss Force: 4.2494509359195005, time: 0.04453253746032715
Test Loss Energy: 10.685656591552917, Test Loss Force: 10.490771201650958, time: 8.821863889694214


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.955635019265364, Training Loss Force: 4.076386801480326, time: 0.4534897804260254
Validation Loss Energy: 2.8747898260546925, Validation Loss Force: 4.244021816803489, time: 0.042101383209228516
Test Loss Energy: 10.0774738107712, Test Loss Force: 10.48196406568406, time: 9.029300928115845


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.983186022416815, Training Loss Force: 4.081636779429315, time: 0.4795536994934082
Validation Loss Energy: 1.9220292990833932, Validation Loss Force: 4.295449482746971, time: 0.04499101638793945
Test Loss Energy: 9.325330866510008, Test Loss Force: 10.391289076495005, time: 8.813232421875


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9114827067874915, Training Loss Force: 4.097289552746194, time: 0.49100780487060547
Validation Loss Energy: 3.41231492567754, Validation Loss Force: 4.305574248812308, time: 0.04529595375061035
Test Loss Energy: 9.557223723905091, Test Loss Force: 10.446862515509688, time: 8.852225303649902


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0196437453358977, Training Loss Force: 4.082268852673894, time: 0.5932071208953857
Validation Loss Energy: 2.4091993300386925, Validation Loss Force: 4.245138725239463, time: 0.042949676513671875
Test Loss Energy: 9.37709050300489, Test Loss Force: 10.36657948370301, time: 9.050102233886719


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9302337216355485, Training Loss Force: 4.091649711835671, time: 0.47530698776245117
Validation Loss Energy: 2.5560759067372882, Validation Loss Force: 4.27970053939379, time: 0.04173469543457031
Test Loss Energy: 10.120377417351648, Test Loss Force: 10.38187899444999, time: 8.845425128936768


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.990521488873578, Training Loss Force: 4.076759772299754, time: 0.4832179546356201
Validation Loss Energy: 3.5881275805585973, Validation Loss Force: 4.256507321153952, time: 0.044156789779663086
Test Loss Energy: 10.674042458021471, Test Loss Force: 10.398262267406984, time: 9.212309837341309


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.980253304682648, Training Loss Force: 4.067418870732302, time: 0.4875516891479492
Validation Loss Energy: 2.580905075192258, Validation Loss Force: 4.272587150857981, time: 0.05017828941345215
Test Loss Energy: 9.996595611151022, Test Loss Force: 10.373511904010956, time: 8.902491807937622


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9945142576290427, Training Loss Force: 4.071420841866091, time: 0.5552186965942383
Validation Loss Energy: 2.013703522476739, Validation Loss Force: 4.247378776847497, time: 0.06742095947265625
Test Loss Energy: 9.365690947918468, Test Loss Force: 10.349231468109009, time: 8.923109292984009

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‚â–„â–„â–†â–…â–ƒâ–ƒâ–ƒâ–†â–ˆâ–…â–‚â–ƒâ–ƒâ–†â–ˆâ–…â–ƒ
wandb:   test_error_force â–ˆâ–…â–„â–†â–„â–„â–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–
wandb:          test_loss â–„â–…â–†â–ˆâ–…â–†â–„â–ƒâ–„â–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–â–ƒâ–…â–‚â–‚
wandb: train_error_energy â–ˆâ–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‡â–‡â–„â–†â–ƒâ–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–…â–â–…â–‡â–„â–ƒâ–‡â–„â–ƒâ–ˆâ–…â–‚â–‡â–„â–„â–‡â–„â–‚
wandb:  valid_error_force â–ˆâ–…â–‚â–‡â–„â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–
wandb:         valid_loss â–„â–‚â–„â–‚â–…â–†â–ƒâ–‚â–‡â–ƒâ–‚â–ˆâ–„â–â–†â–‚â–ƒâ–‡â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 917
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.36569
wandb:   test_error_force 10.34923
wandb:          test_loss 8.14535
wandb: train_error_energy 2.99451
wandb:  train_error_force 4.07142
wandb:         train_loss 1.38048
wandb: valid_error_energy 2.0137
wandb:  valid_error_force 4.24738
wandb:         valid_loss 1.05633
wandb: 
wandb: ğŸš€ View run al_73_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3feiat68
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_130836-3feiat68/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.590474009513855, Uncertainty Bias: 0.07543489336967468
7.6293945e-05 0.009707451
3.4549375 13.540712
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3582 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2994 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2747 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_135107-u4mnl2ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/u4mnl2ne
Training model 5. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.935993597816213, Training Loss Force: 4.609943192132837, time: 0.505396842956543
Validation Loss Energy: 5.344806779920642, Validation Loss Force: 5.1104163301512155, time: 0.03983640670776367
Test Loss Energy: 12.527487654970987, Test Loss Force: 11.014537068786668, time: 7.747786283493042


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2375579068260936, Training Loss Force: 4.326800438530006, time: 0.48043298721313477
Validation Loss Energy: 1.953903941984664, Validation Loss Force: 4.298551263949745, time: 0.03884387016296387
Test Loss Energy: 9.145843041054112, Test Loss Force: 10.355230375419115, time: 7.7045204639434814


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9682616075545116, Training Loss Force: 4.093567522798315, time: 0.47272419929504395
Validation Loss Energy: 3.240320378641706, Validation Loss Force: 4.286153491242778, time: 0.03567767143249512
Test Loss Energy: 9.475878683847887, Test Loss Force: 10.35784877338287, time: 7.649429559707642


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.01966453802718, Training Loss Force: 4.080603847974342, time: 0.47389984130859375
Validation Loss Energy: 2.671990338694625, Validation Loss Force: 4.2610649132328025, time: 0.03652620315551758
Test Loss Energy: 9.215115048620449, Test Loss Force: 10.306720220884987, time: 7.8910181522369385


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.982979354736408, Training Loss Force: 4.096149294762884, time: 0.4680216312408447
Validation Loss Energy: 2.267016841605401, Validation Loss Force: 4.325304516494677, time: 0.03625297546386719
Test Loss Energy: 9.781470551846006, Test Loss Force: 10.45858249965775, time: 7.987722873687744


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9345282493141016, Training Loss Force: 4.082750248010897, time: 0.48918581008911133
Validation Loss Energy: 3.7963152159118256, Validation Loss Force: 4.32630830900452, time: 0.03673100471496582
Test Loss Energy: 10.447869222537147, Test Loss Force: 10.458011617936645, time: 7.733996391296387


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9693584143413814, Training Loss Force: 4.0790749785836615, time: 0.4520702362060547
Validation Loss Energy: 2.7715641953780508, Validation Loss Force: 4.267056939949719, time: 0.03899669647216797
Test Loss Energy: 10.421031402349044, Test Loss Force: 10.362523748241642, time: 7.921738862991333


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.110410557407479, Training Loss Force: 4.0643660460286455, time: 0.45676112174987793
Validation Loss Energy: 2.403530396252517, Validation Loss Force: 4.232352617541998, time: 0.04183626174926758
Test Loss Energy: 9.380981617184803, Test Loss Force: 10.377189572910293, time: 7.760090351104736


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0121788620358716, Training Loss Force: 4.052604922801118, time: 0.4586293697357178
Validation Loss Energy: 3.6901209601816745, Validation Loss Force: 4.267747659640387, time: 0.037352561950683594
Test Loss Energy: 9.519911024810987, Test Loss Force: 10.297988992946516, time: 7.699939966201782


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.993875634840275, Training Loss Force: 4.051615288977659, time: 0.45905613899230957
Validation Loss Energy: 2.582541916083973, Validation Loss Force: 4.232471522865923, time: 0.037989139556884766
Test Loss Energy: 9.288900753298712, Test Loss Force: 10.306956833083193, time: 8.62916111946106


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.991591602236798, Training Loss Force: 4.061192795708276, time: 0.4795410633087158
Validation Loss Energy: 2.1918766929737767, Validation Loss Force: 4.266130636302659, time: 0.04136490821838379
Test Loss Energy: 9.905547834174245, Test Loss Force: 10.390742769986444, time: 9.998024702072144


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9241951186759008, Training Loss Force: 4.040351892717251, time: 0.4740121364593506
Validation Loss Energy: 3.699706198906428, Validation Loss Force: 4.230806848330967, time: 0.04762554168701172
Test Loss Energy: 10.687453510576026, Test Loss Force: 10.392756892852047, time: 9.004753351211548


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.937519575103125, Training Loss Force: 4.053448224604472, time: 0.5022943019866943
Validation Loss Energy: 2.764940456294137, Validation Loss Force: 4.241588043038498, time: 0.04106307029724121
Test Loss Energy: 9.617362467978047, Test Loss Force: 10.364130430870867, time: 8.43521761894226


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9715899239002823, Training Loss Force: 4.039972694839983, time: 0.4799022674560547
Validation Loss Energy: 2.2371197233891147, Validation Loss Force: 4.247004692682338, time: 0.04053235054016113
Test Loss Energy: 9.252994423203834, Test Loss Force: 10.439992209401195, time: 8.497345924377441


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0342010363634135, Training Loss Force: 4.04115251882705, time: 0.4823465347290039
Validation Loss Energy: 3.519150468547963, Validation Loss Force: 4.254046381753158, time: 0.04812264442443848
Test Loss Energy: 9.461872603376673, Test Loss Force: 10.392828240243306, time: 8.307075023651123


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.020352574170727, Training Loss Force: 4.034741014152191, time: 0.4630911350250244
Validation Loss Energy: 2.491233092759095, Validation Loss Force: 4.226882972641428, time: 0.03772592544555664
Test Loss Energy: 9.11396428984881, Test Loss Force: 10.327141774840248, time: 8.633591175079346


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0449178681704026, Training Loss Force: 4.060922928381658, time: 0.4861929416656494
Validation Loss Energy: 2.3718797585120495, Validation Loss Force: 4.282162369471168, time: 0.03821372985839844
Test Loss Energy: 9.701727288701973, Test Loss Force: 10.33649047014941, time: 8.526253700256348


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0221143017403214, Training Loss Force: 4.073636461294044, time: 0.6179370880126953
Validation Loss Energy: 3.9432461238820276, Validation Loss Force: 4.244461811035842, time: 0.03814053535461426
Test Loss Energy: 10.125752426699393, Test Loss Force: 10.343634517078934, time: 8.379602670669556


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9900318202260667, Training Loss Force: 4.053355509779055, time: 0.4555187225341797
Validation Loss Energy: 2.9217892706931083, Validation Loss Force: 4.28842916991416, time: 0.03920936584472656
Test Loss Energy: 10.442021389830614, Test Loss Force: 10.471655113763408, time: 8.406062602996826


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0608007930843373, Training Loss Force: 4.065293163569826, time: 0.47557640075683594
Validation Loss Energy: 2.10396179277113, Validation Loss Force: 4.2440921802536025, time: 0.04065561294555664
Test Loss Energy: 9.276859407443371, Test Loss Force: 10.321689188028385, time: 8.467475414276123

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–â–‚â–„â–„â–‚â–‚â–â–ƒâ–„â–‚â–â–‚â–â–‚â–ƒâ–„â–
wandb:   test_error_force â–ˆâ–‚â–‚â–â–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–ƒâ–
wandb:          test_loss â–ˆâ–â–ƒâ–‚â–ƒâ–…â–…â–‚â–ƒâ–‚â–ƒâ–…â–‚â–â–‚â–â–â–‚â–„â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–â–„â–‚â–‚â–…â–ƒâ–‚â–…â–‚â–â–…â–ƒâ–‚â–„â–‚â–‚â–…â–ƒâ–
wandb:  valid_error_force â–ˆâ–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–ˆâ–â–ƒâ–‚â–‚â–„â–‚â–‚â–„â–‚â–â–„â–‚â–â–„â–‚â–‚â–…â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 919
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.27686
wandb:   test_error_force 10.32169
wandb:          test_loss 7.56679
wandb: train_error_energy 3.0608
wandb:  train_error_force 4.06529
wandb:         train_loss 1.36645
wandb: valid_error_energy 2.10396
wandb:  valid_error_force 4.24409
wandb:         valid_loss 1.07026
wandb: 
wandb: ğŸš€ View run al_73_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/u4mnl2ne
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_135107-u4mnl2ne/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.332857608795166, Uncertainty Bias: -0.028392165899276733
0.0004696846 0.024458885
2.9690912 11.450408
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2746 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_143329-d0rmiei7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/d0rmiei7
Training model 6. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.835177632508397, Training Loss Force: 4.478455003692441, time: 0.5014193058013916
Validation Loss Energy: 1.6110532439215524, Validation Loss Force: 4.4328505966097556, time: 0.05028724670410156
Test Loss Energy: 9.710252052212462, Test Loss Force: 10.402399954440511, time: 9.639745712280273


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.060394905622543, Training Loss Force: 4.385728783758283, time: 0.5188119411468506
Validation Loss Energy: 4.704624078612414, Validation Loss Force: 4.49722691872723, time: 0.044562578201293945
Test Loss Energy: 10.840191473653878, Test Loss Force: 10.449412779046405, time: 9.631990671157837


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.731884534378103, Training Loss Force: 4.577605397408037, time: 0.5867946147918701
Validation Loss Energy: 2.8128771153677627, Validation Loss Force: 4.615512777088698, time: 0.048319339752197266
Test Loss Energy: 9.34436656500684, Test Loss Force: 10.573365963546129, time: 9.993642330169678


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9295445606289023, Training Loss Force: 4.220572605828298, time: 0.5112142562866211
Validation Loss Energy: 2.885338999512167, Validation Loss Force: 4.260825321231784, time: 0.044408321380615234
Test Loss Energy: 9.179770754102805, Test Loss Force: 10.339137103959839, time: 9.572442770004272


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9236637955416094, Training Loss Force: 4.027360929405531, time: 0.4990561008453369
Validation Loss Energy: 2.024675099304039, Validation Loss Force: 4.210073233477047, time: 0.05105781555175781
Test Loss Energy: 9.851525841850908, Test Loss Force: 10.343051557596825, time: 9.997897386550903


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.96645910465735, Training Loss Force: 4.018992539172041, time: 0.5187692642211914
Validation Loss Energy: 3.533130305536747, Validation Loss Force: 4.234431011350088, time: 0.047905921936035156
Test Loss Energy: 10.633160850499035, Test Loss Force: 10.43522037462975, time: 8.850075721740723


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.954929503593861, Training Loss Force: 4.032806295690949, time: 0.5077807903289795
Validation Loss Energy: 2.759081808395631, Validation Loss Force: 4.253168619979911, time: 0.047751665115356445
Test Loss Energy: 10.150122326634106, Test Loss Force: 10.414212969990905, time: 8.63660192489624


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.899104310135343, Training Loss Force: 4.027608391609121, time: 0.49586057662963867
Validation Loss Energy: 2.04052736114093, Validation Loss Force: 4.228437203280003, time: 0.04793357849121094
Test Loss Energy: 9.126474294800166, Test Loss Force: 10.364910206561834, time: 8.846730709075928


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.931739018809746, Training Loss Force: 4.00690169668712, time: 0.5126078128814697
Validation Loss Energy: 3.4670581352038865, Validation Loss Force: 4.236082325736288, time: 0.04121661186218262
Test Loss Energy: 9.304642128232544, Test Loss Force: 10.327744235942633, time: 8.804131031036377


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9159916341405867, Training Loss Force: 4.010727114222927, time: 0.5105886459350586
Validation Loss Energy: 2.4781412603242705, Validation Loss Force: 4.214322651457933, time: 0.04558205604553223
Test Loss Energy: 9.152477690926178, Test Loss Force: 10.312461834579876, time: 8.514094352722168


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.906159121329281, Training Loss Force: 4.014799825040903, time: 0.5114507675170898
Validation Loss Energy: 2.201561687475906, Validation Loss Force: 4.244939659023004, time: 0.04285478591918945
Test Loss Energy: 9.878242138312459, Test Loss Force: 10.40492045259171, time: 8.804730415344238


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.936885017945833, Training Loss Force: 4.01057748823511, time: 0.503131628036499
Validation Loss Energy: 3.7102509189809845, Validation Loss Force: 4.220357430650868, time: 0.04890251159667969
Test Loss Energy: 10.476948190191907, Test Loss Force: 10.399913502518308, time: 8.550784587860107


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.008914547713063, Training Loss Force: 4.018918459450665, time: 0.47957396507263184
Validation Loss Energy: 2.6555845213609572, Validation Loss Force: 4.21354909884498, time: 0.04649019241333008
Test Loss Energy: 10.077536633781337, Test Loss Force: 10.410756659870373, time: 8.789221286773682


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0095309650132087, Training Loss Force: 4.008870299249773, time: 0.5103645324707031
Validation Loss Energy: 1.9196086627980122, Validation Loss Force: 4.230436772210435, time: 0.0438227653503418
Test Loss Energy: 9.08938110318328, Test Loss Force: 10.372942230065949, time: 9.17484998703003


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.8944167906098444, Training Loss Force: 4.012167591640919, time: 0.5154221057891846
Validation Loss Energy: 2.996017589172158, Validation Loss Force: 4.249591662819727, time: 0.046834468841552734
Test Loss Energy: 9.208551037328961, Test Loss Force: 10.337233033279446, time: 8.648228883743286


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.91183936517242, Training Loss Force: 4.01311560936883, time: 0.5243136882781982
Validation Loss Energy: 2.2871033799212546, Validation Loss Force: 4.21144443007767, time: 0.043367624282836914
Test Loss Energy: 9.153984132802293, Test Loss Force: 10.327224966831103, time: 8.894946813583374


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8892682192612096, Training Loss Force: 4.023252491707004, time: 0.4673922061920166
Validation Loss Energy: 2.292914599291678, Validation Loss Force: 4.219004938258502, time: 0.04340028762817383
Test Loss Energy: 10.018462639937084, Test Loss Force: 10.387335717545254, time: 8.570321083068848


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8984460425531324, Training Loss Force: 4.002000050064826, time: 0.5104775428771973
Validation Loss Energy: 3.507423152639384, Validation Loss Force: 4.229753177932436, time: 0.045371055603027344
Test Loss Energy: 10.329546158609592, Test Loss Force: 10.408563529664356, time: 8.482239723205566


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9859079876434835, Training Loss Force: 4.012121376275769, time: 0.5033507347106934
Validation Loss Energy: 2.7046643638297767, Validation Loss Force: 4.231161782949576, time: 0.04697394371032715
Test Loss Energy: 10.181243149372497, Test Loss Force: 10.387784772429972, time: 10.060293197631836


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0625760382067386, Training Loss Force: 4.007795575099585, time: 0.49724459648132324
Validation Loss Energy: 1.978958228946167, Validation Loss Force: 4.208530136295767, time: 0.049010515213012695
Test Loss Energy: 9.074665092852884, Test Loss Force: 10.323800525212004, time: 10.093756675720215

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–‚â–â–„â–‡â–…â–â–‚â–â–„â–‡â–…â–â–‚â–â–…â–†â–…â–
wandb:   test_error_force â–ƒâ–…â–ˆâ–‚â–‚â–„â–„â–‚â–â–â–ƒâ–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–ƒâ–
wandb:          test_loss â–ƒâ–ˆâ–…â–„â–„â–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–‡â–†â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–„â–„â–‚â–…â–„â–‚â–…â–ƒâ–‚â–†â–ƒâ–‚â–„â–ƒâ–ƒâ–…â–ƒâ–‚
wandb:  valid_error_force â–…â–†â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–ƒâ–ƒâ–â–„â–‚â–â–„â–‚â–â–„â–‚â–â–ƒâ–â–â–„â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 920
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.07467
wandb:   test_error_force 10.3238
wandb:          test_loss 7.32854
wandb: train_error_energy 3.06258
wandb:  train_error_force 4.0078
wandb:         train_loss 1.33808
wandb: valid_error_energy 1.97896
wandb:  valid_error_force 4.20853
wandb:         valid_loss 1.01825
wandb: 
wandb: ğŸš€ View run al_73_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/d0rmiei7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_143329-d0rmiei7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.696397542953491, Uncertainty Bias: -0.07505148649215698
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:925: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
4.9591064e-05 0.006954193
2.7268949 11.273825
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2703 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2667 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2510 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2743 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2147 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2880 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2725 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1889 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_151502-bznvp3xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bznvp3xx
Training model 7. Added 8 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.622752182275388, Training Loss Force: 4.387237989159902, time: 0.4929773807525635
Validation Loss Energy: 2.005179302232331, Validation Loss Force: 4.329036896718718, time: 0.04907703399658203
Test Loss Energy: 9.017353584754808, Test Loss Force: 10.439025517534807, time: 8.453581809997559


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.5978870738953153, Training Loss Force: 4.5665870830948325, time: 0.48716092109680176
Validation Loss Energy: 4.295140417972423, Validation Loss Force: 4.578312778893418, time: 0.040245771408081055
Test Loss Energy: 10.176827184196911, Test Loss Force: 10.350410336857903, time: 7.9890525341033936


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.8839811553820534, Training Loss Force: 4.137603617338506, time: 0.49558234214782715
Validation Loss Energy: 2.5790526905672846, Validation Loss Force: 4.282369006438589, time: 0.04486417770385742
Test Loss Energy: 10.277791166689981, Test Loss Force: 10.274854475423096, time: 8.334125757217407


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9352734615195493, Training Loss Force: 4.052630391544465, time: 0.605351448059082
Validation Loss Energy: 2.3260707031277637, Validation Loss Force: 4.299978127836851, time: 0.06029248237609863
Test Loss Energy: 9.191596747417242, Test Loss Force: 10.327330332471986, time: 7.9827721118927


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.8309854110825925, Training Loss Force: 4.049542738315087, time: 0.4892153739929199
Validation Loss Energy: 3.460338425718078, Validation Loss Force: 4.270258922268161, time: 0.038818359375
Test Loss Energy: 9.34536030825994, Test Loss Force: 10.276934461723611, time: 7.937709331512451


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.945786570253632, Training Loss Force: 4.036653066430026, time: 0.46767592430114746
Validation Loss Energy: 2.3658140283078306, Validation Loss Force: 4.259112550161307, time: 0.03861498832702637
Test Loss Energy: 9.146384581743465, Test Loss Force: 10.300887245223457, time: 7.911578178405762


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8517643352685855, Training Loss Force: 4.020788051025847, time: 0.4723391532897949
Validation Loss Energy: 2.4422222777255134, Validation Loss Force: 4.234123727928707, time: 0.04158926010131836
Test Loss Energy: 9.834759060344586, Test Loss Force: 10.313137699557156, time: 8.124180316925049


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.914131148965649, Training Loss Force: 4.025606941508319, time: 0.46169614791870117
Validation Loss Energy: 3.740735215735082, Validation Loss Force: 4.262910395114251, time: 0.0392303466796875
Test Loss Energy: 10.562583194999085, Test Loss Force: 10.383908902343006, time: 7.935896635055542


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.850930458512702, Training Loss Force: 4.051290046137922, time: 0.46201038360595703
Validation Loss Energy: 2.8349877162201005, Validation Loss Force: 4.241735895351394, time: 0.03761172294616699
Test Loss Energy: 10.216202037406942, Test Loss Force: 10.363213668188676, time: 7.945054292678833


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9324929803769804, Training Loss Force: 4.025807842825672, time: 0.45177674293518066
Validation Loss Energy: 1.8182063584228, Validation Loss Force: 4.251655360464185, time: 0.04079079627990723
Test Loss Energy: 8.98079679961304, Test Loss Force: 10.316959830602498, time: 7.972645998001099


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.929995861079097, Training Loss Force: 4.022125655298421, time: 0.4491236209869385
Validation Loss Energy: 3.38293306386493, Validation Loss Force: 4.255231872286077, time: 0.04145312309265137
Test Loss Energy: 9.16246829358496, Test Loss Force: 10.31231053614135, time: 8.126400709152222


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9867358830454127, Training Loss Force: 4.02506911873844, time: 0.46939897537231445
Validation Loss Energy: 2.5387386643662047, Validation Loss Force: 4.249523971399364, time: 0.04008817672729492
Test Loss Energy: 9.125884083998226, Test Loss Force: 10.337608581698255, time: 7.992307662963867


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.905991013802351, Training Loss Force: 4.01621001945505, time: 0.4747011661529541
Validation Loss Energy: 2.3188384092680288, Validation Loss Force: 4.254033466942694, time: 0.0403437614440918
Test Loss Energy: 10.165783251555256, Test Loss Force: 10.38572970642089, time: 7.881702184677124


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9465394875793542, Training Loss Force: 4.045445687455987, time: 0.47368335723876953
Validation Loss Energy: 3.860503605270137, Validation Loss Force: 4.273734342297801, time: 0.04036974906921387
Test Loss Energy: 10.582219563918681, Test Loss Force: 10.40468050618535, time: 8.507540702819824


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.8865712275309923, Training Loss Force: 4.02741048480787, time: 0.47644901275634766
Validation Loss Energy: 2.7228735785763134, Validation Loss Force: 4.260543867431331, time: 0.040131330490112305
Test Loss Energy: 10.097720740820547, Test Loss Force: 10.380361477406927, time: 8.849362134933472


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.97909682256467, Training Loss Force: 4.040489494571188, time: 0.5256142616271973
Validation Loss Energy: 2.115509192009799, Validation Loss Force: 4.239860575804391, time: 0.043707847595214844
Test Loss Energy: 9.092045079539336, Test Loss Force: 10.31604563735904, time: 9.943582773208618


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9339600091710634, Training Loss Force: 4.02833779430521, time: 0.4967803955078125
Validation Loss Energy: 3.4458057012399546, Validation Loss Force: 4.229542978258681, time: 0.04262518882751465
Test Loss Energy: 9.071240931027473, Test Loss Force: 10.31109299057787, time: 9.479583978652954


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.985868997508207, Training Loss Force: 4.018263259327896, time: 0.49263882637023926
Validation Loss Energy: 2.3649097689062177, Validation Loss Force: 4.282968877117718, time: 0.04528665542602539
Test Loss Energy: 9.16051331910568, Test Loss Force: 10.365212239188278, time: 8.585115671157837


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9996832147218995, Training Loss Force: 4.025210552037335, time: 0.48130154609680176
Validation Loss Energy: 2.3085314998413233, Validation Loss Force: 4.26704536115413, time: 0.03992462158203125
Test Loss Energy: 9.883235784195842, Test Loss Force: 10.364509574638607, time: 8.44633936882019


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.907239696303236, Training Loss Force: 4.031794947786638, time: 0.48557066917419434
Validation Loss Energy: 3.9223459525069533, Validation Loss Force: 4.253279954552875, time: 0.04319405555725098
Test Loss Energy: 11.000757084934099, Test Loss Force: 10.409612886576813, time: 8.371692657470703

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–…â–‚â–‚â–‚â–„â–†â–…â–â–‚â–‚â–…â–‡â–…â–â–â–‚â–„â–ˆ
wandb:   test_error_force â–ˆâ–„â–â–ƒâ–â–‚â–ƒâ–†â–…â–ƒâ–ƒâ–„â–†â–‡â–…â–ƒâ–ƒâ–…â–…â–‡
wandb:          test_loss â–â–ˆâ–†â–„â–„â–ƒâ–„â–…â–„â–ƒâ–ƒâ–ƒâ–„â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–…
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–†â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–ƒâ–‚â–†â–ƒâ–ƒâ–†â–„â–â–…â–ƒâ–‚â–‡â–„â–‚â–†â–ƒâ–‚â–‡
wandb:  valid_error_force â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–‚â–‚â–â–â–‚â–‚â–
wandb:         valid_loss â–‚â–ˆâ–‚â–‚â–„â–‚â–‚â–…â–ƒâ–â–„â–‚â–‚â–…â–‚â–â–„â–‚â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 927
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.00076
wandb:   test_error_force 10.40961
wandb:          test_loss 8.03358
wandb: train_error_energy 2.90724
wandb:  train_error_force 4.03179
wandb:         train_loss 1.28207
wandb: valid_error_energy 3.92235
wandb:  valid_error_force 4.25328
wandb:         valid_loss 1.7368
wandb: 
wandb: ğŸš€ View run al_73_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bznvp3xx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_151502-bznvp3xx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.992623805999756, Uncertainty Bias: -0.1358906626701355
3.0517578e-05 0.014289141
2.3793511 9.275897
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1619 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 518 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3803 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2216 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1040 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1114 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 953 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 385 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1286 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3566 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1055 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1622 steps.
Found uncertainty sample 75 after 1728 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_155439-a0zanv9r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a0zanv9r
Training model 8. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.840747928196075, Training Loss Force: 4.670457286945267, time: 0.4929802417755127
Validation Loss Energy: 6.019714289198015, Validation Loss Force: 4.556985528096455, time: 0.040441036224365234
Test Loss Energy: 12.57110084633173, Test Loss Force: 10.685649400855054, time: 7.788430452346802


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.31385343279508, Training Loss Force: 4.215232047094512, time: 0.5392570495605469
Validation Loss Energy: 3.9005969663476026, Validation Loss Force: 4.366288108817562, time: 0.03916478157043457
Test Loss Energy: 10.365625834885863, Test Loss Force: 10.400362384863584, time: 7.818220853805542


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.466906643777175, Training Loss Force: 4.161957169872546, time: 0.4773991107940674
Validation Loss Energy: 4.825963621641136, Validation Loss Force: 4.312936581453264, time: 0.03697538375854492
Test Loss Energy: 9.519826788257017, Test Loss Force: 10.274611982894145, time: 8.127736568450928


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.389957185866858, Training Loss Force: 4.11662356507095, time: 0.491619348526001
Validation Loss Energy: 3.2082722764757574, Validation Loss Force: 4.335734339289934, time: 0.03708958625793457
Test Loss Energy: 9.242791317236568, Test Loss Force: 10.291936654367843, time: 7.980025053024292


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.295951044998174, Training Loss Force: 4.128456871492991, time: 0.48775720596313477
Validation Loss Energy: 5.5823675929897885, Validation Loss Force: 4.306710752133123, time: 0.03741168975830078
Test Loss Energy: 11.69301306213861, Test Loss Force: 10.33821469877154, time: 7.850617408752441


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.366580213625495, Training Loss Force: 4.174135168132484, time: 0.4610733985900879
Validation Loss Energy: 3.7941081193373893, Validation Loss Force: 4.290412261327792, time: 0.04043078422546387
Test Loss Energy: 10.915837587207017, Test Loss Force: 10.343321241409333, time: 7.858919620513916


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.247507234677782, Training Loss Force: 4.116374168205207, time: 0.48011136054992676
Validation Loss Energy: 4.681620129146615, Validation Loss Force: 4.385684372781039, time: 0.03951430320739746
Test Loss Energy: 9.445620726200298, Test Loss Force: 10.186234253796522, time: 8.007115364074707


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.29009653503463, Training Loss Force: 4.09839844432509, time: 0.48070836067199707
Validation Loss Energy: 3.5366466966892385, Validation Loss Force: 4.322163100183928, time: 0.039803504943847656
Test Loss Energy: 9.107853674907483, Test Loss Force: 10.25087921050016, time: 7.830728769302368


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.321515934578203, Training Loss Force: 4.213635702298136, time: 0.4748983383178711
Validation Loss Energy: 5.450105237676725, Validation Loss Force: 4.319841997006776, time: 0.0363621711730957
Test Loss Energy: 12.161950468941875, Test Loss Force: 10.39394162327877, time: 7.834020376205444


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.267794349649136, Training Loss Force: 4.1788198894490485, time: 0.5017378330230713
Validation Loss Energy: 3.7842487748939986, Validation Loss Force: 4.301233091143299, time: 0.03850412368774414
Test Loss Energy: 10.898619726974943, Test Loss Force: 10.370987176311791, time: 9.580178260803223


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.260701569142781, Training Loss Force: 4.158822804751418, time: 0.539283037185669
Validation Loss Energy: 4.51507340543505, Validation Loss Force: 4.316573659282849, time: 0.04485130310058594
Test Loss Energy: 9.398311632718004, Test Loss Force: 10.217073091126444, time: 9.718413829803467


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.224404542579221, Training Loss Force: 4.102694741583498, time: 0.46935057640075684
Validation Loss Energy: 3.4527859336264988, Validation Loss Force: 4.285892968342043, time: 0.04699277877807617
Test Loss Energy: 9.17191668871276, Test Loss Force: 10.256460558368723, time: 8.783257484436035


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.449778246509211, Training Loss Force: 4.118786313373823, time: 0.46454286575317383
Validation Loss Energy: 5.050721849496019, Validation Loss Force: 4.310024959701112, time: 0.04241466522216797
Test Loss Energy: 11.353854093190723, Test Loss Force: 10.342345885264976, time: 8.395795822143555


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.305573781207101, Training Loss Force: 4.088583039926495, time: 0.5063719749450684
Validation Loss Energy: 3.917827550197787, Validation Loss Force: 4.272184119703852, time: 0.04065752029418945
Test Loss Energy: 10.725258264181962, Test Loss Force: 10.255773469001197, time: 8.466182231903076


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.378890135932088, Training Loss Force: 4.0602661229935055, time: 0.4586653709411621
Validation Loss Energy: 5.188654697279278, Validation Loss Force: 4.353528276079316, time: 0.0397038459777832
Test Loss Energy: 9.59819629235654, Test Loss Force: 10.270276747524935, time: 8.647841930389404


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.465461981203005, Training Loss Force: 4.115295306503968, time: 0.4737832546234131
Validation Loss Energy: 3.189371228692823, Validation Loss Force: 4.263360186789026, time: 0.04114651679992676
Test Loss Energy: 9.020289264101176, Test Loss Force: 10.199005152375252, time: 8.28100037574768


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.324182137820018, Training Loss Force: 4.073947412613735, time: 0.46941471099853516
Validation Loss Energy: 5.264339939980133, Validation Loss Force: 4.286665630278412, time: 0.03840899467468262
Test Loss Energy: 11.981207857382202, Test Loss Force: 10.332407785892348, time: 8.423481225967407


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.348006571132428, Training Loss Force: 4.09053515806193, time: 0.4655733108520508
Validation Loss Energy: 3.6626596197526924, Validation Loss Force: 4.3774019712291095, time: 0.038687944412231445
Test Loss Energy: 10.11711040631614, Test Loss Force: 10.346928919916813, time: 8.309840202331543


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.350241887309958, Training Loss Force: 4.10438150489773, time: 0.47751808166503906
Validation Loss Energy: 4.763745408885994, Validation Loss Force: 4.349595938962231, time: 0.04117321968078613
Test Loss Energy: 9.387599376844374, Test Loss Force: 10.162563110626257, time: 8.466946601867676


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.295829163329997, Training Loss Force: 4.058847965470005, time: 0.4816770553588867
Validation Loss Energy: 3.422440359750314, Validation Loss Force: 4.276225564702441, time: 0.04280734062194824
Test Loss Energy: 9.116460487917925, Test Loss Force: 10.215934335466416, time: 8.37947964668274

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–‚â–â–†â–…â–‚â–â–‡â–…â–‚â–â–†â–„â–‚â–â–‡â–ƒâ–‚â–
wandb:   test_error_force â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–„â–„â–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–ƒâ–â–‚
wandb:          test_loss â–ˆâ–„â–ƒâ–‚â–†â–…â–ƒâ–‚â–ˆâ–…â–ƒâ–‚â–…â–„â–‚â–â–‡â–„â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–…â–â–‡â–‚â–…â–‚â–‡â–‚â–„â–‚â–†â–ƒâ–†â–â–†â–‚â–…â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–„â–ƒâ–
wandb:         valid_loss â–ˆâ–ƒâ–…â–â–†â–‚â–…â–‚â–†â–‚â–„â–â–…â–‚â–†â–â–…â–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 938
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.11646
wandb:   test_error_force 10.21593
wandb:          test_loss 6.12526
wandb: train_error_energy 4.29583
wandb:  train_error_force 4.05885
wandb:         train_loss 1.69611
wandb: valid_error_energy 3.42244
wandb:  valid_error_force 4.27623
wandb:         valid_loss 1.4824
wandb: 
wandb: ğŸš€ View run al_73_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a0zanv9r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_155439-a0zanv9r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6097054481506348, Uncertainty Bias: -0.17593088746070862
0.00044250488 0.011774063
2.038451 7.355783
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1991 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 761 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 948 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_163615-g7cvhu56
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g7cvhu56
Training model 9. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.718399178086114, Training Loss Force: 4.43197825311906, time: 0.499622106552124
Validation Loss Energy: 5.674080115476234, Validation Loss Force: 4.627660715013934, time: 0.04364371299743652
Test Loss Energy: 9.650135845521335, Test Loss Force: 10.329291672257742, time: 8.55851411819458


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.346831820674647, Training Loss Force: 4.155115556451648, time: 0.4632091522216797
Validation Loss Energy: 3.3058042570910255, Validation Loss Force: 4.299998613398276, time: 0.04111051559448242
Test Loss Energy: 9.08296234212336, Test Loss Force: 10.16174723688589, time: 8.472962379455566


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.234496995640331, Training Loss Force: 4.117300731632937, time: 0.4991624355316162
Validation Loss Energy: 5.1680128221134805, Validation Loss Force: 4.325350386338738, time: 0.03990745544433594
Test Loss Energy: 11.04234821195164, Test Loss Force: 10.269895621885214, time: 8.665287494659424


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.24920543576381, Training Loss Force: 4.079441283917381, time: 0.47325825691223145
Validation Loss Energy: 3.8780347924673237, Validation Loss Force: 4.351420935282255, time: 0.038897037506103516
Test Loss Energy: 10.129748370248949, Test Loss Force: 10.19963101821991, time: 8.53162407875061


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.406449235538437, Training Loss Force: 4.155700938791681, time: 0.47219228744506836
Validation Loss Energy: 5.448794161745503, Validation Loss Force: 4.3200757996100005, time: 0.039957523345947266
Test Loss Energy: 9.60333990765842, Test Loss Force: 10.134028989889632, time: 8.993367433547974


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.26038523422062, Training Loss Force: 4.06352208031292, time: 0.4583396911621094
Validation Loss Energy: 3.5891211302877273, Validation Loss Force: 4.322838233034381, time: 0.04071998596191406
Test Loss Energy: 9.060145609611197, Test Loss Force: 10.121721466969381, time: 8.536953449249268


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.352060377979769, Training Loss Force: 4.136115918193201, time: 0.4781148433685303
Validation Loss Energy: 5.2874899604056615, Validation Loss Force: 4.363553286367277, time: 0.04192090034484863
Test Loss Energy: 10.874442544271515, Test Loss Force: 10.190110189168683, time: 8.678010940551758


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.3000666907784915, Training Loss Force: 4.07219404153565, time: 0.48392486572265625
Validation Loss Energy: 3.464133153302979, Validation Loss Force: 4.315702577583979, time: 0.04100942611694336
Test Loss Energy: 10.271811667735587, Test Loss Force: 10.173776407052433, time: 8.5516357421875


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.352025689837986, Training Loss Force: 4.075577640231815, time: 0.47927355766296387
Validation Loss Energy: 4.734724048420641, Validation Loss Force: 4.330177853422453, time: 0.04527783393859863
Test Loss Energy: 9.440651296460889, Test Loss Force: 10.090784422053838, time: 8.54699993133545


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.379355896695778, Training Loss Force: 4.048860022172537, time: 0.49942564964294434
Validation Loss Energy: 3.2166620045560244, Validation Loss Force: 4.304145158233743, time: 0.0455782413482666
Test Loss Energy: 9.057920116601563, Test Loss Force: 10.114006939356376, time: 8.771606922149658


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.333307104575529, Training Loss Force: 4.072437545091332, time: 0.5079410076141357
Validation Loss Energy: 5.362215499087569, Validation Loss Force: 4.373284818720905, time: 0.03923678398132324
Test Loss Energy: 11.749098192519021, Test Loss Force: 10.292293741066258, time: 8.552053451538086


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.3211901696177115, Training Loss Force: 4.048306637388772, time: 0.48978281021118164
Validation Loss Energy: 3.663878510657501, Validation Loss Force: 4.312431122492008, time: 0.042406320571899414
Test Loss Energy: 10.913678708412037, Test Loss Force: 10.207074943364455, time: 8.573424577713013


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.364369799280784, Training Loss Force: 4.057301595052282, time: 0.5126535892486572
Validation Loss Energy: 4.787825295664916, Validation Loss Force: 4.293447241786788, time: 0.04145359992980957
Test Loss Energy: 9.368021433510734, Test Loss Force: 10.143486893339706, time: 8.748159646987915


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.344835666004454, Training Loss Force: 4.0442568719864305, time: 0.4895496368408203
Validation Loss Energy: 3.1460371408655243, Validation Loss Force: 4.421246862077167, time: 0.041889190673828125
Test Loss Energy: 8.864692154577957, Test Loss Force: 10.153193286230179, time: 8.578287363052368


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.30350351853399, Training Loss Force: 4.065933216048075, time: 0.4846611022949219
Validation Loss Energy: 5.261423419506771, Validation Loss Force: 4.304632803663325, time: 0.040329933166503906
Test Loss Energy: 11.349933418807336, Test Loss Force: 10.253790729661292, time: 8.583327293395996


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.341058815040818, Training Loss Force: 4.08585648592383, time: 0.5188412666320801
Validation Loss Energy: 3.8596240621437223, Validation Loss Force: 4.33693808869282, time: 0.03966999053955078
Test Loss Energy: 10.80431385039172, Test Loss Force: 10.254124831307976, time: 8.970451593399048


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.345113794612327, Training Loss Force: 4.034351078759198, time: 0.47269415855407715
Validation Loss Energy: 5.10597274467508, Validation Loss Force: 4.284055947888138, time: 0.040525197982788086
Test Loss Energy: 9.363673439549203, Test Loss Force: 10.144847003115315, time: 8.754140853881836


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.388956373412419, Training Loss Force: 4.041590928525286, time: 0.5201499462127686
Validation Loss Energy: 3.420864752873729, Validation Loss Force: 4.300947183959928, time: 0.04417061805725098
Test Loss Energy: 9.141411262871747, Test Loss Force: 10.14466671338715, time: 8.631162405014038


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.326375684976925, Training Loss Force: 4.054255666693611, time: 0.5179674625396729
Validation Loss Energy: 5.136303399718488, Validation Loss Force: 4.417487316217322, time: 0.04064512252807617
Test Loss Energy: 11.67600027669251, Test Loss Force: 10.317561083928783, time: 8.563898086547852


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.354616883266842, Training Loss Force: 4.045113138764791, time: 0.4972116947174072
Validation Loss Energy: 3.7621537608818763, Validation Loss Force: 4.296987235868748, time: 0.04327821731567383
Test Loss Energy: 10.614173421077163, Test Loss Force: 10.19840702807508, time: 8.813488006591797

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–†â–„â–ƒâ–â–†â–„â–‚â–â–ˆâ–†â–‚â–â–‡â–†â–‚â–‚â–ˆâ–…
wandb:   test_error_force â–ˆâ–ƒâ–†â–„â–‚â–‚â–„â–ƒâ–â–‚â–‡â–„â–ƒâ–ƒâ–†â–†â–ƒâ–ƒâ–ˆâ–„
wandb:          test_loss â–‚â–â–†â–„â–„â–‚â–†â–„â–ƒâ–‚â–ˆâ–†â–‚â–â–†â–†â–‚â–‚â–ˆâ–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–â–‡â–ƒâ–‡â–‚â–‡â–‚â–…â–â–‡â–‚â–†â–â–‡â–ƒâ–†â–‚â–‡â–ƒ
wandb:  valid_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–„â–â–‚â–â–â–„â–
wandb:         valid_loss â–ˆâ–â–†â–ƒâ–ˆâ–‚â–‡â–‚â–…â–â–†â–‚â–…â–â–†â–ƒâ–†â–â–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 940
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.61417
wandb:   test_error_force 10.19841
wandb:          test_loss 6.62172
wandb: train_error_energy 4.35462
wandb:  train_error_force 4.04511
wandb:         train_loss 1.70149
wandb: valid_error_energy 3.76215
wandb:  valid_error_force 4.29699
wandb:         valid_loss 1.59624
wandb: 
wandb: ğŸš€ View run al_73_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g7cvhu56
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_163615-g7cvhu56/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.0527915954589844, Uncertainty Bias: -0.29591104388237
0.00013828278 0.026508331
1.5452895 8.785131
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3385 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1760 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1581 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3260 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1134 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1504 steps.
Found uncertainty sample 53 after 994 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 798 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1258 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3266 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2918 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1534 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_171644-36qmvrc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/36qmvrc5
Training model 10. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.549411822399862, Training Loss Force: 4.642418557998591, time: 0.5620112419128418
Validation Loss Energy: 5.041485087984642, Validation Loss Force: 4.586319961380981, time: 0.05121254920959473
Test Loss Energy: 11.847036523341082, Test Loss Force: 10.325283212603733, time: 9.206095218658447


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.2598776190798, Training Loss Force: 4.188201148391522, time: 0.4920003414154053
Validation Loss Energy: 3.4387261584143265, Validation Loss Force: 4.42911242698792, time: 0.04436945915222168
Test Loss Energy: 10.0904134016296, Test Loss Force: 10.130012737981325, time: 9.255375146865845


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.207604856926779, Training Loss Force: 4.113025261361977, time: 0.5261714458465576
Validation Loss Energy: 5.57600326346088, Validation Loss Force: 4.43460612015625, time: 0.04400038719177246
Test Loss Energy: 9.5566646075087, Test Loss Force: 10.10484904469171, time: 9.35469126701355


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.096292866325434, Training Loss Force: 4.081633817929675, time: 0.5280637741088867
Validation Loss Energy: 3.9025653615976044, Validation Loss Force: 4.394621421621998, time: 0.046730756759643555
Test Loss Energy: 9.206326803390937, Test Loss Force: 10.102992851375117, time: 9.17206883430481


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.273299246786659, Training Loss Force: 4.089512104670964, time: 0.5334925651550293
Validation Loss Energy: 5.502938836607595, Validation Loss Force: 4.42393091596218, time: 0.04236459732055664
Test Loss Energy: 11.407657697211606, Test Loss Force: 10.168670731775084, time: 9.073169469833374


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.288690713381814, Training Loss Force: 4.073456560748451, time: 0.48381853103637695
Validation Loss Energy: 3.6193513615463213, Validation Loss Force: 4.407971327596952, time: 0.04365730285644531
Test Loss Energy: 10.2642163089189, Test Loss Force: 10.165105101596165, time: 9.684560060501099


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.310815932463582, Training Loss Force: 4.105436719135673, time: 0.4869225025177002
Validation Loss Energy: 5.0701711087162264, Validation Loss Force: 4.40280362205826, time: 0.048439979553222656
Test Loss Energy: 9.252050884265392, Test Loss Force: 10.076087540285465, time: 9.183814764022827


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.2848225161122135, Training Loss Force: 4.108776273874773, time: 0.51031494140625
Validation Loss Energy: 3.644648803215177, Validation Loss Force: 4.406035442042255, time: 0.044213056564331055
Test Loss Energy: 8.890732035801303, Test Loss Force: 10.082915145213448, time: 9.158681154251099


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.3901520287918485, Training Loss Force: 4.066100284708264, time: 0.5285398960113525
Validation Loss Energy: 5.355626719059565, Validation Loss Force: 4.40464197852704, time: 0.04259920120239258
Test Loss Energy: 11.504065066903745, Test Loss Force: 10.166497494900515, time: 9.359725952148438


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.212871557456598, Training Loss Force: 4.107543466148344, time: 0.48336029052734375
Validation Loss Energy: 3.935717234719917, Validation Loss Force: 4.414692818435928, time: 0.04279136657714844
Test Loss Energy: 10.647552234862424, Test Loss Force: 10.116973246785477, time: 9.22403883934021


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.408724483716139, Training Loss Force: 4.0925314092220875, time: 0.5451295375823975
Validation Loss Energy: 5.30741929430449, Validation Loss Force: 4.395820717641964, time: 0.041375160217285156
Test Loss Energy: 9.291477569256724, Test Loss Force: 10.054541943155101, time: 9.132348537445068


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.390150536908572, Training Loss Force: 4.076942364582597, time: 0.4808077812194824
Validation Loss Energy: 3.7377991003768782, Validation Loss Force: 4.365257150671916, time: 0.04614686965942383
Test Loss Energy: 8.86313448247698, Test Loss Force: 10.037906254319575, time: 9.168559551239014


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.471051744974346, Training Loss Force: 4.093626889463917, time: 0.4981718063354492
Validation Loss Energy: 5.050630109807896, Validation Loss Force: 4.413916593793224, time: 0.04390883445739746
Test Loss Energy: 11.018644939139163, Test Loss Force: 10.158696716218962, time: 9.379867315292358


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.300581026816364, Training Loss Force: 4.064196611956678, time: 0.48291563987731934
Validation Loss Energy: 3.55100618457183, Validation Loss Force: 4.405289055065106, time: 0.04519033432006836
Test Loss Energy: 10.36379932301668, Test Loss Force: 10.134346238629648, time: 9.254051685333252


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.327529619580714, Training Loss Force: 4.076660072061695, time: 0.5408518314361572
Validation Loss Energy: 4.574467282743245, Validation Loss Force: 4.4023720892534515, time: 0.0429692268371582
Test Loss Energy: 9.265479339987543, Test Loss Force: 9.950819847718568, time: 9.10292673110962


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.331086633007728, Training Loss Force: 4.097615561874922, time: 0.514005184173584
Validation Loss Energy: 3.5845241257700478, Validation Loss Force: 4.369164103506365, time: 0.04200124740600586
Test Loss Energy: 8.994524872409432, Test Loss Force: 10.067365792689898, time: 8.646876573562622


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.364835504377187, Training Loss Force: 4.081214984688489, time: 0.5347871780395508
Validation Loss Energy: 4.9397885263330865, Validation Loss Force: 4.40865492187495, time: 0.05183148384094238
Test Loss Energy: 11.1377984540584, Test Loss Force: 10.173848425948552, time: 10.394093036651611


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.252913263003361, Training Loss Force: 4.125297708451312, time: 0.5172452926635742
Validation Loss Energy: 3.5480910001133434, Validation Loss Force: 4.4547505524500455, time: 0.052988529205322266
Test Loss Energy: 10.414610757344937, Test Loss Force: 10.18157701785777, time: 8.394939422607422


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.21383010730714, Training Loss Force: 4.106325250673278, time: 0.5224659442901611
Validation Loss Energy: 4.6202899209454324, Validation Loss Force: 4.437559158369544, time: 0.03970766067504883
Test Loss Energy: 9.210717787653124, Test Loss Force: 10.082944938578336, time: 8.265375137329102


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.225817597268126, Training Loss Force: 4.065614710101738, time: 0.5080935955047607
Validation Loss Energy: 3.201048221374422, Validation Loss Force: 4.366268959271012, time: 0.04020571708679199
Test Loss Energy: 9.004023625738423, Test Loss Force: 10.01937897360228, time: 8.04873013496399

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–ƒâ–‚â–‡â–„â–‚â–â–‡â–…â–‚â–â–†â–…â–‚â–â–†â–…â–‚â–
wandb:   test_error_force â–ˆâ–„â–„â–„â–…â–…â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–„â–â–ƒâ–…â–…â–ƒâ–‚
wandb:          test_loss â–‡â–„â–„â–ƒâ–ˆâ–…â–ƒâ–â–‡â–†â–ƒâ–â–†â–…â–ƒâ–â–†â–…â–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–‚â–ˆâ–ƒâ–ˆâ–‚â–‡â–‚â–‡â–ƒâ–‡â–ƒâ–†â–‚â–…â–‚â–†â–‚â–…â–
wandb:  valid_error_force â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–â–‚â–„â–ƒâ–
wandb:         valid_loss â–†â–‚â–ˆâ–ƒâ–‡â–‚â–†â–‚â–†â–ƒâ–‡â–‚â–…â–‚â–…â–‚â–…â–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 950
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.00402
wandb:   test_error_force 10.01938
wandb:          test_loss 6.10576
wandb: train_error_energy 4.22582
wandb:  train_error_force 4.06561
wandb:         train_loss 1.68849
wandb: valid_error_energy 3.20105
wandb:  valid_error_force 4.36627
wandb:         valid_loss 1.4581
wandb: 
wandb: ğŸš€ View run al_73_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/36qmvrc5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_171644-36qmvrc5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.0079996585845947, Uncertainty Bias: -0.24891000986099243
3.0517578e-05 0.13466454
1.786866 9.203436
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1860 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3517 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1658 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1960 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1305 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 725 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3424 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2814 steps.
Found uncertainty sample 83 after 1446 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2855 steps.
Found uncertainty sample 94 after 3770 steps.
Found uncertainty sample 95 after 3860 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_175749-zwzhvpf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zwzhvpf5
Training model 11. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.452721453222, Training Loss Force: 4.648049489583861, time: 0.5322864055633545
Validation Loss Energy: 4.474207827759507, Validation Loss Force: 4.690847093215571, time: 0.0468144416809082
Test Loss Energy: 9.181776338597599, Test Loss Force: 10.162913328389555, time: 9.285048007965088


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.3326356457659845, Training Loss Force: 4.1614934316869325, time: 0.47559523582458496
Validation Loss Energy: 3.400218201655867, Validation Loss Force: 4.3640004060123, time: 0.04530501365661621
Test Loss Energy: 8.897564322610387, Test Loss Force: 9.999948080506286, time: 9.47833514213562


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.329722257505275, Training Loss Force: 4.080817564796837, time: 0.5294644832611084
Validation Loss Energy: 4.8915895630055575, Validation Loss Force: 4.402680708689708, time: 0.04690408706665039
Test Loss Energy: 10.757211421856216, Test Loss Force: 10.082402586487278, time: 9.76744818687439


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.2395027167976655, Training Loss Force: 4.088696393366383, time: 0.512993574142456
Validation Loss Energy: 3.3765665076445632, Validation Loss Force: 4.412598392449332, time: 0.04626059532165527
Test Loss Energy: 10.273222238303408, Test Loss Force: 10.161212308654106, time: 9.575356483459473


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.379835344189638, Training Loss Force: 4.107357270208519, time: 0.5129005908966064
Validation Loss Energy: 4.821374410543564, Validation Loss Force: 4.368482735919826, time: 0.04894876480102539
Test Loss Energy: 9.279977339736972, Test Loss Force: 10.019766105479905, time: 9.456023454666138


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.368376040287402, Training Loss Force: 4.083527426035863, time: 0.4910142421722412
Validation Loss Energy: 3.318028125195023, Validation Loss Force: 4.376110490182729, time: 0.049286603927612305
Test Loss Energy: 8.854553084060157, Test Loss Force: 10.070179691832164, time: 9.751628637313843


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.329853409632225, Training Loss Force: 4.081918611767316, time: 0.4983949661254883
Validation Loss Energy: 5.1852086695769, Validation Loss Force: 4.391793078130423, time: 0.04606008529663086
Test Loss Energy: 11.067243853558606, Test Loss Force: 10.043441300995465, time: 9.60874605178833


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.232582493745947, Training Loss Force: 4.0899198415663784, time: 0.5033478736877441
Validation Loss Energy: 3.6855573560358845, Validation Loss Force: 4.42525802407191, time: 0.05214881896972656
Test Loss Energy: 10.16417743162325, Test Loss Force: 10.077553626584852, time: 10.13263726234436


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.2919336853788685, Training Loss Force: 4.0972372618406006, time: 0.5142102241516113
Validation Loss Energy: 4.9034271001413705, Validation Loss Force: 4.367732786236341, time: 0.045728445053100586
Test Loss Energy: 9.269238937142898, Test Loss Force: 10.00876839009281, time: 9.78984522819519


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.285786332088057, Training Loss Force: 4.071758062770229, time: 0.5200765132904053
Validation Loss Energy: 3.456011073536117, Validation Loss Force: 4.373452265918642, time: 0.05097460746765137
Test Loss Energy: 9.158719253978221, Test Loss Force: 10.00274596145973, time: 9.685870170593262


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.409377772723375, Training Loss Force: 4.085953532559929, time: 0.5661072731018066
Validation Loss Energy: 5.13681999213704, Validation Loss Force: 4.400297258151697, time: 0.05464529991149902
Test Loss Energy: 11.186026520593044, Test Loss Force: 10.106836680421214, time: 9.71602725982666


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.224971320912113, Training Loss Force: 4.09139502465815, time: 0.5091307163238525
Validation Loss Energy: 3.7927467201791867, Validation Loss Force: 4.401561128223983, time: 0.0485532283782959
Test Loss Energy: 10.733007211082215, Test Loss Force: 10.063111133240533, time: 9.7007155418396


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.457841200195523, Training Loss Force: 4.087043542563075, time: 0.5364723205566406
Validation Loss Energy: 5.057818760515029, Validation Loss Force: 4.370810964509647, time: 0.04426312446594238
Test Loss Energy: 9.311832784127798, Test Loss Force: 10.033655138923626, time: 9.597436666488647


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.214478742529228, Training Loss Force: 4.107747312329136, time: 0.49138665199279785
Validation Loss Energy: 3.307335107469279, Validation Loss Force: 4.340392132484452, time: 0.04864954948425293
Test Loss Energy: 8.756452594141125, Test Loss Force: 9.933250855730472, time: 9.672790050506592


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.373106765049516, Training Loss Force: 4.084483530236953, time: 0.5739219188690186
Validation Loss Energy: 5.244780682201837, Validation Loss Force: 4.432976627346351, time: 0.049172163009643555
Test Loss Energy: 11.593325344578352, Test Loss Force: 10.055347767638724, time: 9.776015758514404


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.347226880273353, Training Loss Force: 4.091419495997287, time: 0.521327018737793
Validation Loss Energy: 3.853868064721489, Validation Loss Force: 4.34117637321641, time: 0.05042123794555664
Test Loss Energy: 10.25171899261144, Test Loss Force: 10.004362800599944, time: 9.737725973129272


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.347023312428992, Training Loss Force: 4.0955533338468255, time: 0.5362422466278076
Validation Loss Energy: 4.847853334700713, Validation Loss Force: 4.386023275221142, time: 0.04787278175354004
Test Loss Energy: 9.210665946545369, Test Loss Force: 9.963839412940374, time: 9.523028135299683


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.268456166884662, Training Loss Force: 4.104073456978949, time: 0.5083050727844238
Validation Loss Energy: 3.55853017501273, Validation Loss Force: 4.384266415659772, time: 0.04867267608642578
Test Loss Energy: 8.764166436259586, Test Loss Force: 9.99525086671229, time: 9.302136182785034


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.36167216257787, Training Loss Force: 4.074687616810933, time: 0.49584269523620605
Validation Loss Energy: 5.114059197378594, Validation Loss Force: 4.360334381193745, time: 0.04789376258850098
Test Loss Energy: 11.641272829336211, Test Loss Force: 10.047441600000147, time: 10.451698541641235


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.336388845555171, Training Loss Force: 4.07227175306758, time: 0.5578467845916748
Validation Loss Energy: 3.7030631589504353, Validation Loss Force: 4.374896943337422, time: 0.051216840744018555
Test Loss Energy: 10.511167219768666, Test Loss Force: 10.072401225761068, time: 9.108176946640015

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–†â–…â–‚â–â–‡â–„â–‚â–‚â–‡â–†â–‚â–â–ˆâ–…â–‚â–â–ˆâ–…
wandb:   test_error_force â–ˆâ–ƒâ–†â–ˆâ–„â–…â–„â–…â–ƒâ–ƒâ–†â–…â–„â–â–…â–ƒâ–‚â–ƒâ–„â–…
wandb:          test_loss â–â–‚â–†â–…â–ƒâ–ƒâ–‡â–…â–ƒâ–ƒâ–‡â–†â–ƒâ–‚â–‡â–…â–ƒâ–‚â–ˆâ–…
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–â–‡â–â–†â–â–ˆâ–‚â–‡â–‚â–ˆâ–ƒâ–‡â–â–ˆâ–ƒâ–‡â–‚â–ˆâ–‚
wandb:  valid_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–‚â–‚â–â–‚
wandb:         valid_loss â–†â–â–‡â–‚â–‡â–â–ˆâ–ƒâ–‡â–â–‡â–ƒâ–‡â–â–ˆâ–ƒâ–‡â–‚â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 960
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.51117
wandb:   test_error_force 10.0724
wandb:          test_loss 6.56197
wandb: train_error_energy 4.33639
wandb:  train_error_force 4.07227
wandb:         train_loss 1.71102
wandb: valid_error_energy 3.70306
wandb:  valid_error_force 4.3749
wandb:         valid_loss 1.59617
wandb: 
wandb: ğŸš€ View run al_73_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zwzhvpf5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_175749-zwzhvpf5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.2519052028656006, Uncertainty Bias: -0.3482067883014679
0.0 0.18837166
1.4448338 9.297835
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2816 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1744 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1763 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2455 steps.
Found uncertainty sample 21 after 2093 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1078 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1853 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3702 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1342 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3695 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_183915-jjvv9qcj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jjvv9qcj
Training model 12. Added 10 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.734691454296978, Training Loss Force: 4.501516101107854, time: 0.5148961544036865
Validation Loss Energy: 2.125774684975362, Validation Loss Force: 4.490937406031354, time: 0.04104042053222656
Test Loss Energy: 9.336732044399838, Test Loss Force: 10.02679953131038, time: 8.200975894927979


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.004105501795153, Training Loss Force: 4.446986539035586, time: 0.5067498683929443
Validation Loss Energy: 6.117609443190292, Validation Loss Force: 4.510981637209482, time: 0.04018831253051758
Test Loss Energy: 11.648870659663839, Test Loss Force: 10.006657733740509, time: 8.169223546981812


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.621663053331051, Training Loss Force: 4.851589277631089, time: 0.5114214420318604
Validation Loss Energy: 2.5748820974640574, Validation Loss Force: 5.573058241336839, time: 0.03861808776855469
Test Loss Energy: 9.360633476430888, Test Loss Force: 10.810455051446725, time: 8.122815370559692


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.883680613584865, Training Loss Force: 4.449877668043436, time: 0.5207920074462891
Validation Loss Energy: 1.8487718180805888, Validation Loss Force: 4.351833318540514, time: 0.039539337158203125
Test Loss Energy: 9.135126124283909, Test Loss Force: 9.922788884640093, time: 8.376566410064697


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9076596851122494, Training Loss Force: 4.090792949075617, time: 0.4903683662414551
Validation Loss Energy: 2.6020577533788143, Validation Loss Force: 4.308994446893759, time: 0.0411837100982666
Test Loss Energy: 8.806295748773799, Test Loss Force: 9.896420912671198, time: 8.170899152755737


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.8751477056523282, Training Loss Force: 4.060907481483675, time: 0.4979109764099121
Validation Loss Energy: 3.4665426561310637, Validation Loss Force: 4.30786195161757, time: 0.042009592056274414
Test Loss Energy: 8.714419360448861, Test Loss Force: 9.879475002580527, time: 8.260108709335327


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.914894701281865, Training Loss Force: 4.05013049594129, time: 0.505612850189209
Validation Loss Energy: 2.079832473441811, Validation Loss Force: 4.310134512920909, time: 0.04154777526855469
Test Loss Energy: 8.76025947876191, Test Loss Force: 9.892523535775831, time: 8.484885454177856


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.931712251823543, Training Loss Force: 4.070591427285956, time: 0.5085532665252686
Validation Loss Energy: 2.709167179298728, Validation Loss Force: 4.345831049042884, time: 0.04197955131530762
Test Loss Energy: 9.462824074466257, Test Loss Force: 9.943417210796394, time: 8.223618268966675


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.8659465209241706, Training Loss Force: 4.108085822823656, time: 0.5150303840637207
Validation Loss Energy: 3.5726347067232336, Validation Loss Force: 4.336063889625907, time: 0.04185986518859863
Test Loss Energy: 10.4759862268389, Test Loss Force: 9.948889350524045, time: 8.192345380783081


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1867464119835014, Training Loss Force: 4.097571400118697, time: 0.528095006942749
Validation Loss Energy: 2.227651163296827, Validation Loss Force: 4.321970714041846, time: 0.04096841812133789
Test Loss Energy: 9.402951227664522, Test Loss Force: 9.934564314571297, time: 8.573299169540405


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9718608599892637, Training Loss Force: 4.0750239080362975, time: 0.5899791717529297
Validation Loss Energy: 2.277019807647915, Validation Loss Force: 4.338143619448873, time: 0.04968404769897461
Test Loss Energy: 8.673232162256879, Test Loss Force: 9.895438030076546, time: 10.531468868255615


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.872238554809409, Training Loss Force: 4.066252683063175, time: 0.5576560497283936
Validation Loss Energy: 3.1942748486244446, Validation Loss Force: 4.329595796274997, time: 0.0510706901550293
Test Loss Energy: 8.712122153984556, Test Loss Force: 9.936496616435134, time: 9.860321044921875


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9353929404827883, Training Loss Force: 4.094271931811592, time: 0.5199763774871826
Validation Loss Energy: 2.0407662851345103, Validation Loss Force: 4.333731207653168, time: 0.04796600341796875
Test Loss Energy: 8.702576001272657, Test Loss Force: 9.930582029617103, time: 9.051527261734009


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.882767626989307, Training Loss Force: 4.069332570860891, time: 0.5136623382568359
Validation Loss Energy: 2.6506174407227463, Validation Loss Force: 4.3502394527939625, time: 0.043666839599609375
Test Loss Energy: 9.727850553108528, Test Loss Force: 9.994760892000228, time: 8.672690629959106


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.915617320123406, Training Loss Force: 4.049145407639704, time: 0.5076243877410889
Validation Loss Energy: 3.5547499209223137, Validation Loss Force: 4.34347565481726, time: 0.04224109649658203
Test Loss Energy: 10.224977085700687, Test Loss Force: 9.9852125172601, time: 8.638139724731445


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.962963288233016, Training Loss Force: 4.048460261860561, time: 0.4995608329772949
Validation Loss Energy: 2.484581074693648, Validation Loss Force: 4.353806612511725, time: 0.04296708106994629
Test Loss Energy: 9.831173751342718, Test Loss Force: 9.97249253646994, time: 8.709874629974365


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8477901972826674, Training Loss Force: 4.069386894949622, time: 0.5256330966949463
Validation Loss Energy: 2.464923619821997, Validation Loss Force: 4.315939497555246, time: 0.04277467727661133
Test Loss Energy: 8.533498926008738, Test Loss Force: 9.90960776654098, time: 8.871546983718872


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9103374539810476, Training Loss Force: 4.058313752260277, time: 0.5319035053253174
Validation Loss Energy: 3.3080376286246813, Validation Loss Force: 4.356118363584748, time: 0.04257488250732422
Test Loss Energy: 8.750940523190511, Test Loss Force: 9.943844884779876, time: 8.688217639923096


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9464937372434834, Training Loss Force: 4.048724462393642, time: 0.4772307872772217
Validation Loss Energy: 2.0216118398635103, Validation Loss Force: 4.345470770364773, time: 0.04285836219787598
Test Loss Energy: 8.571434203371625, Test Loss Force: 9.992705098527546, time: 8.700543880462646


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9237414936985275, Training Loss Force: 4.0573483881352965, time: 0.5106306076049805
Validation Loss Energy: 2.6111397598337707, Validation Loss Force: 4.346676746459118, time: 0.04309439659118652
Test Loss Energy: 9.883705128786405, Test Loss Force: 9.975375316155755, time: 8.891380071640015

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–‚â–‚â–â–‚â–ƒâ–…â–ƒâ–â–â–â–„â–…â–„â–â–â–â–„
wandb:   test_error_force â–‚â–‚â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚
wandb:          test_loss â–â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–„â–…â–„â–‚â–ƒâ–ƒâ–„
wandb: train_error_energy â–ˆâ–â–…â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–…â–„â–ˆâ–„â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–†â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–â–‚â–„â–â–‚â–„â–‚â–‚â–ƒâ–â–‚â–„â–‚â–‚â–ƒâ–â–‚
wandb:  valid_error_force â–‚â–‚â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–ˆâ–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 969
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.88371
wandb:   test_error_force 9.97538
wandb:          test_loss 7.55947
wandb: train_error_energy 2.92374
wandb:  train_error_force 4.05735
wandb:         train_loss 1.29638
wandb: valid_error_energy 2.61114
wandb:  valid_error_force 4.34668
wandb:         valid_loss 1.2461
wandb: 
wandb: ğŸš€ View run al_73_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jjvv9qcj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_183915-jjvv9qcj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.047636032104492, Uncertainty Bias: -0.15166980028152466
0.000289917 0.16128683
2.523892 10.600017
(48745, 22, 3)
Found uncertainty sample 0 after 2091 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2622 steps.
Found uncertainty sample 7 after 1570 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3418 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2047 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 928 steps.
Found uncertainty sample 18 after 3804 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 534 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1373 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1291 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3323 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1267 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2477 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1269 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1956 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3592 steps.
Found uncertainty sample 65 after 1852 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 257 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2456 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2126 steps.
Found uncertainty sample 84 after 939 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 412 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 592 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1604 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_191715-uiv433ap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uiv433ap
Training model 13. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.373024073151022, Training Loss Force: 4.442522575741162, time: 0.5039322376251221
Validation Loss Energy: 1.7664441320875617, Validation Loss Force: 5.13960157510797, time: 0.04582524299621582
Test Loss Energy: 9.144397472958751, Test Loss Force: 10.327414228610301, time: 8.674793720245361


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.5830629528772806, Training Loss Force: 4.644589862303538, time: 0.5065157413482666
Validation Loss Energy: 2.9422757227950487, Validation Loss Force: 5.0737039773855175, time: 0.04475116729736328
Test Loss Energy: 9.501903959840549, Test Loss Force: 10.39231996236061, time: 9.076303720474243


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.76598242937963, Training Loss Force: 4.8316719391346385, time: 0.5077264308929443
Validation Loss Energy: 5.320599526390248, Validation Loss Force: 6.333806933060835, time: 0.041078805923461914
Test Loss Energy: 11.394188083837482, Test Loss Force: 10.903044347102043, time: 8.882957935333252


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.1844602193482805, Training Loss Force: 5.092511374835397, time: 0.5277676582336426
Validation Loss Energy: 5.045126619197145, Validation Loss Force: 4.620780238404765, time: 0.05053377151489258
Test Loss Energy: 11.200764560013397, Test Loss Force: 10.135158092667314, time: 8.728879928588867


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.225963420897501, Training Loss Force: 4.236586204464895, time: 0.49561023712158203
Validation Loss Energy: 3.8526358136679244, Validation Loss Force: 4.415927296180952, time: 0.04580354690551758
Test Loss Energy: 10.739618535486889, Test Loss Force: 10.007228671420352, time: 8.68454909324646


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.386201381806382, Training Loss Force: 4.168527609864089, time: 0.5167548656463623
Validation Loss Energy: 2.196094937274233, Validation Loss Force: 4.379430487148512, time: 0.04394268989562988
Test Loss Energy: 8.6884909490321, Test Loss Force: 9.979055172109112, time: 8.667726516723633


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.1666700535686285, Training Loss Force: 4.142828731639503, time: 0.5102050304412842
Validation Loss Energy: 4.6099932542994395, Validation Loss Force: 4.376762910780297, time: 0.04363656044006348
Test Loss Energy: 8.96191035239756, Test Loss Force: 9.915388150315016, time: 8.893954277038574


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.212307811733815, Training Loss Force: 4.127885900874711, time: 0.488436222076416
Validation Loss Energy: 5.3615234433820245, Validation Loss Force: 4.402423303157015, time: 0.0435941219329834
Test Loss Energy: 9.28128174258866, Test Loss Force: 9.936542656487024, time: 8.731069087982178


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.234202344502972, Training Loss Force: 4.1317171749310475, time: 0.4828782081604004
Validation Loss Energy: 3.373640635067072, Validation Loss Force: 4.362939164862808, time: 0.04242706298828125
Test Loss Energy: 8.834804443258731, Test Loss Force: 9.949845974480775, time: 8.6588773727417


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.335739381668658, Training Loss Force: 4.118760560130806, time: 0.48478126525878906
Validation Loss Energy: 2.400077465806615, Validation Loss Force: 4.371573383665304, time: 0.04140353202819824
Test Loss Energy: 9.39129166496408, Test Loss Force: 10.027429733957248, time: 8.882796287536621


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.299541768139589, Training Loss Force: 4.111477820935206, time: 0.4904336929321289
Validation Loss Energy: 5.346426475288121, Validation Loss Force: 4.4231003600478696, time: 0.04383659362792969
Test Loss Energy: 11.362878479632398, Test Loss Force: 10.024480638503388, time: 8.718187093734741


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.187818436395532, Training Loss Force: 4.131504777297335, time: 0.4980947971343994
Validation Loss Energy: 5.889457292213178, Validation Loss Force: 4.436473868952293, time: 0.04554271697998047
Test Loss Energy: 12.054612207922567, Test Loss Force: 10.09079033969041, time: 8.698348999023438


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.351482607452802, Training Loss Force: 4.132926447965327, time: 0.5562083721160889
Validation Loss Energy: 3.7764593628311527, Validation Loss Force: 4.370885336004387, time: 0.053498029708862305
Test Loss Energy: 10.187896260964953, Test Loss Force: 9.97618503909814, time: 8.951932191848755


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.290668840829783, Training Loss Force: 4.118092409035509, time: 0.4877002239227295
Validation Loss Energy: 2.1225971962629724, Validation Loss Force: 4.366887088820108, time: 0.043467044830322266
Test Loss Energy: 8.574370745415209, Test Loss Force: 9.89818456422442, time: 9.13534927368164


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.249772312142955, Training Loss Force: 4.1201127652081455, time: 0.49953794479370117
Validation Loss Energy: 5.008778998492477, Validation Loss Force: 4.360996153895442, time: 0.04506516456604004
Test Loss Energy: 8.997234189333149, Test Loss Force: 9.955737963295011, time: 8.776175498962402


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.23173063797154, Training Loss Force: 4.107048479101535, time: 0.5268359184265137
Validation Loss Energy: 5.256674331962423, Validation Loss Force: 4.378409771783579, time: 0.04275369644165039
Test Loss Energy: 9.103147950722047, Test Loss Force: 9.97092188194169, time: 8.885411262512207


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.3236325154265325, Training Loss Force: 4.111358463090113, time: 0.5131115913391113
Validation Loss Energy: 3.229237689910588, Validation Loss Force: 4.3538872187425515, time: 0.043050289154052734
Test Loss Energy: 8.471677749827888, Test Loss Force: 9.908386830810613, time: 8.71002984046936


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.410342315845667, Training Loss Force: 4.108211444136336, time: 0.49245524406433105
Validation Loss Energy: 2.584238877645089, Validation Loss Force: 4.380219181263388, time: 0.04282712936401367
Test Loss Energy: 9.538135489479503, Test Loss Force: 10.01694762704756, time: 8.695062398910522


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.365231227673604, Training Loss Force: 4.105708879971006, time: 0.5126156806945801
Validation Loss Energy: 5.271698264576463, Validation Loss Force: 4.384915273551005, time: 0.044135332107543945
Test Loss Energy: 11.055313800307179, Test Loss Force: 9.997596372562544, time: 8.67176342010498


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.36824566510817, Training Loss Force: 4.107822951122574, time: 0.5027320384979248
Validation Loss Energy: 6.177645498315342, Validation Loss Force: 4.40026207642664, time: 0.044911861419677734
Test Loss Energy: 11.783739416786146, Test Loss Force: 9.995413921149074, time: 8.891316175460815

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‡â–†â–…â–â–‚â–ƒâ–‚â–ƒâ–‡â–ˆâ–„â–â–‚â–‚â–â–ƒâ–†â–‡
wandb:   test_error_force â–„â–„â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚
wandb:          test_loss â–…â–…â–ˆâ–†â–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–â–‚â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–„â–â–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–ƒâ–…â–†â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–‡â–†â–„â–‚â–†â–‡â–„â–‚â–‡â–ˆâ–„â–‚â–†â–‡â–ƒâ–‚â–‡â–ˆ
wandb:  valid_error_force â–„â–„â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–‚â–ˆâ–…â–‚â–â–ƒâ–„â–‚â–â–„â–„â–‚â–â–ƒâ–„â–‚â–â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 990
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.78374
wandb:   test_error_force 9.99541
wandb:          test_loss 7.09642
wandb: train_error_energy 4.36825
wandb:  train_error_force 4.10782
wandb:         train_loss 1.71513
wandb: valid_error_energy 6.17765
wandb:  valid_error_force 4.40026
wandb:         valid_loss 2.35316
wandb: 
wandb: ğŸš€ View run al_73_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uiv433ap
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_191715-uiv433ap/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.001185655593872, Uncertainty Bias: -0.2881906032562256
6.4373016e-05 0.05095482
1.5064405 9.322343
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1215 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1621 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1582 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3382 steps.
Found uncertainty sample 18 after 2566 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 561 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1696 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3686 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 855 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 758 steps.
Found uncertainty sample 38 after 2910 steps.
Found uncertainty sample 39 after 2398 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2392 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 772 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1149 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1193 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2852 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1033 steps.
Found uncertainty sample 71 after 632 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3331 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1127 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 685 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 530 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3599 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_195512-y8wvye2x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/y8wvye2x
Training model 14. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.260129358880595, Training Loss Force: 4.63806810389274, time: 0.5359256267547607
Validation Loss Energy: 1.6239133891100388, Validation Loss Force: 4.586270083492293, time: 0.04544687271118164
Test Loss Energy: 8.984724095780457, Test Loss Force: 9.968648656128334, time: 8.762348175048828


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2185067294592864, Training Loss Force: 4.609593305721299, time: 0.48789286613464355
Validation Loss Energy: 2.147501626889266, Validation Loss Force: 4.651274332601284, time: 0.043271780014038086
Test Loss Energy: 8.324128723966664, Test Loss Force: 9.980303872700107, time: 8.808050155639648


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.478595126650598, Training Loss Force: 4.916345640313377, time: 0.5478992462158203
Validation Loss Energy: 1.9060416544057779, Validation Loss Force: 4.905908970441882, time: 0.04296231269836426
Test Loss Energy: 8.573620203501743, Test Loss Force: 10.229756894592333, time: 8.917304754257202


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0053136154684053, Training Loss Force: 4.324486075173587, time: 0.5127396583557129
Validation Loss Energy: 3.5231671972713543, Validation Loss Force: 4.4103218231013654, time: 0.04451727867126465
Test Loss Energy: 10.108020333642227, Test Loss Force: 9.949109678729423, time: 8.803276538848877


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9770275781070152, Training Loss Force: 4.169936785919845, time: 0.5507025718688965
Validation Loss Energy: 2.412362345256597, Validation Loss Force: 4.364603839397764, time: 0.04248404502868652
Test Loss Energy: 8.510258627817125, Test Loss Force: 9.857764695567376, time: 8.765702247619629


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9694042981022637, Training Loss Force: 4.153480610567144, time: 0.53847336769104
Validation Loss Energy: 1.7912140705497148, Validation Loss Force: 4.3615724216451035, time: 0.04448556900024414
Test Loss Energy: 8.606421122070707, Test Loss Force: 9.854815679388391, time: 9.243996858596802


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8785340842859872, Training Loss Force: 4.156725143567689, time: 0.5791571140289307
Validation Loss Energy: 3.5244390834328936, Validation Loss Force: 4.3794420659441, time: 0.06832671165466309
Test Loss Energy: 9.980060484831345, Test Loss Force: 9.913580072186855, time: 8.986047267913818


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.012707664545835, Training Loss Force: 4.1599737820306135, time: 0.5141091346740723
Validation Loss Energy: 2.4706738278464364, Validation Loss Force: 4.358039998314105, time: 0.04446005821228027
Test Loss Energy: 8.485244554203891, Test Loss Force: 9.87382700319149, time: 8.733197212219238


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9217651319660076, Training Loss Force: 4.156167830529075, time: 0.5287580490112305
Validation Loss Energy: 2.031255195235351, Validation Loss Force: 4.373421092238213, time: 0.0427699089050293
Test Loss Energy: 8.540762636036767, Test Loss Force: 9.933418079093258, time: 8.827839136123657


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9006237472801963, Training Loss Force: 4.167225044518217, time: 0.5243091583251953
Validation Loss Energy: 3.7016968610710226, Validation Loss Force: 4.388774575188226, time: 0.04262566566467285
Test Loss Energy: 10.209351909086818, Test Loss Force: 9.954534855086003, time: 9.02121376991272


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9868685349498394, Training Loss Force: 4.156949573191552, time: 0.49607110023498535
Validation Loss Energy: 2.6223181962976376, Validation Loss Force: 4.379088022002075, time: 0.04591774940490723
Test Loss Energy: 8.537070872530235, Test Loss Force: 9.93087517413062, time: 8.76423692703247


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.958510860749157, Training Loss Force: 4.149234351704765, time: 0.5616211891174316
Validation Loss Energy: 1.9348456897847046, Validation Loss Force: 4.349314039823486, time: 0.04270815849304199
Test Loss Energy: 8.489377967388783, Test Loss Force: 9.877254993527243, time: 8.752991676330566


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.93507241767475, Training Loss Force: 4.148373756330987, time: 0.500307559967041
Validation Loss Energy: 3.6016607432406507, Validation Loss Force: 4.395199025386534, time: 0.04828977584838867
Test Loss Energy: 10.167883919272782, Test Loss Force: 9.962069825097668, time: 9.024582386016846


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9889273582275253, Training Loss Force: 4.164504076263855, time: 0.49599123001098633
Validation Loss Energy: 2.258888527102453, Validation Loss Force: 4.376549148400207, time: 0.05170559883117676
Test Loss Energy: 8.696187164148014, Test Loss Force: 9.906723849027488, time: 8.82515811920166


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.007976654952772, Training Loss Force: 4.163583527222535, time: 0.5931808948516846
Validation Loss Energy: 2.0256873532414263, Validation Loss Force: 4.43024759429386, time: 0.044258832931518555
Test Loss Energy: 8.772089620017818, Test Loss Force: 9.952501020754852, time: 8.784497261047363


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.8608692121003143, Training Loss Force: 4.1746190518451805, time: 0.5153489112854004
Validation Loss Energy: 3.821287560627627, Validation Loss Force: 4.418313864087006, time: 0.04260659217834473
Test Loss Energy: 10.102337886986573, Test Loss Force: 9.95867588099091, time: 9.004643440246582


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0066349759308055, Training Loss Force: 4.161258457751222, time: 0.5122237205505371
Validation Loss Energy: 2.48005398828779, Validation Loss Force: 4.373216681962251, time: 0.042611122131347656
Test Loss Energy: 8.42906875667784, Test Loss Force: 9.956164811887106, time: 9.26680064201355


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9371206920016473, Training Loss Force: 4.16830674339549, time: 0.5406298637390137
Validation Loss Energy: 1.9779493150459682, Validation Loss Force: 4.378403982385785, time: 0.04623603820800781
Test Loss Energy: 8.552701638023088, Test Loss Force: 9.922352266584948, time: 8.808194875717163


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.858436120259583, Training Loss Force: 4.176995370012112, time: 0.5150251388549805
Validation Loss Energy: 3.956012636694651, Validation Loss Force: 4.426040038112408, time: 0.04496145248413086
Test Loss Energy: 10.231616818491476, Test Loss Force: 9.972154396467646, time: 8.936466217041016


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0346247937440043, Training Loss Force: 4.1663360657867425, time: 0.5674426555633545
Validation Loss Energy: 2.269266913325001, Validation Loss Force: 4.391472879898578, time: 0.04437375068664551
Test Loss Energy: 8.356223939892791, Test Loss Force: 9.911542451314418, time: 8.828964471817017

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–‚â–ˆâ–‚â–‚â–‡â–‚â–‚â–ˆâ–‚â–‚â–ˆâ–‚â–ƒâ–ˆâ–â–‚â–ˆâ–
wandb:   test_error_force â–ƒâ–ƒâ–ˆâ–ƒâ–â–â–‚â–â–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–â–‡â–†â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–ˆâ–…â–…â–‡â–…â–…â–‡â–…
wandb: train_error_energy â–ˆâ–â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–…â–…â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–‚â–‡â–ƒâ–‚â–‡â–„â–‚â–‡â–„â–‚â–‡â–ƒâ–‚â–ˆâ–„â–‚â–ˆâ–ƒ
wandb:  valid_error_force â–„â–…â–ˆâ–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚
wandb:         valid_loss â–„â–ƒâ–ƒâ–†â–ƒâ–â–†â–ƒâ–‚â–‡â–ƒâ–â–‡â–‚â–‚â–ˆâ–ƒâ–â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1011
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.35622
wandb:   test_error_force 9.91154
wandb:          test_loss 7.01425
wandb: train_error_energy 3.03462
wandb:  train_error_force 4.16634
wandb:         train_loss 1.36133
wandb: valid_error_energy 2.26927
wandb:  valid_error_force 4.39147
wandb:         valid_loss 1.18676
wandb: 
wandb: ğŸš€ View run al_73_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/y8wvye2x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_195512-y8wvye2x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.682526111602783, Uncertainty Bias: -0.07712849974632263
4.5776367e-05 0.015168011
2.858672 9.971728
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 171 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1341 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3315 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3575 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1940 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3318 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 208 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3285 steps.
Found uncertainty sample 32 after 886 steps.
Found uncertainty sample 33 after 995 steps.
Found uncertainty sample 34 after 3834 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2929 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1653 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3766 steps.
Found uncertainty sample 48 after 251 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 576 steps.
Found uncertainty sample 52 after 642 steps.
Found uncertainty sample 53 after 610 steps.
Found uncertainty sample 54 after 3244 steps.
Found uncertainty sample 55 after 612 steps.
Found uncertainty sample 56 after 3926 steps.
Found uncertainty sample 57 after 2873 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3848 steps.
Found uncertainty sample 60 after 1260 steps.
Found uncertainty sample 61 after 1325 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2458 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2083 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 474 steps.
Found uncertainty sample 71 after 1488 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2113 steps.
Found uncertainty sample 81 after 3800 steps.
Found uncertainty sample 82 after 930 steps.
Found uncertainty sample 83 after 1569 steps.
Found uncertainty sample 84 after 539 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 540 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2932 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1366 steps.
Found uncertainty sample 91 after 3059 steps.
Found uncertainty sample 92 after 2587 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3754 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2480 steps.
Found uncertainty sample 98 after 1942 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_203024-vekfffbw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vekfffbw
Training model 15. Added 42 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.575518254121825, Training Loss Force: 4.762582455169662, time: 0.5780620574951172
Validation Loss Energy: 1.8485277726966518, Validation Loss Force: 5.522131135633403, time: 0.046694040298461914
Test Loss Energy: 8.629649461413633, Test Loss Force: 10.409223175934002, time: 8.473106861114502


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.6921397101949296, Training Loss Force: 4.738086932813441, time: 0.507072925567627
Validation Loss Energy: 3.287251241183176, Validation Loss Force: 4.926981933074195, time: 0.047168731689453125
Test Loss Energy: 9.955900472134099, Test Loss Force: 10.101642762876882, time: 8.402979850769043


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.135915930758973, Training Loss Force: 4.684650386320697, time: 0.5267605781555176
Validation Loss Energy: 1.4598574424648225, Validation Loss Force: 4.534438050379807, time: 0.04704403877258301
Test Loss Energy: 8.544173244189452, Test Loss Force: 9.926694991098627, time: 8.51945447921753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.3877191785892267, Training Loss Force: 4.429324704907037, time: 0.6218104362487793
Validation Loss Energy: 5.863448645292229, Validation Loss Force: 4.771435955848047, time: 0.043616294860839844
Test Loss Energy: 9.163618567418611, Test Loss Force: 9.965453197666125, time: 8.772185564041138


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.349302927781139, Training Loss Force: 4.558637321558695, time: 0.5372023582458496
Validation Loss Energy: 1.6147614645432609, Validation Loss Force: 5.068529591772447, time: 0.05315589904785156
Test Loss Energy: 8.691984075339166, Test Loss Force: 10.402451259277026, time: 10.230686902999878


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0271910536804523, Training Loss Force: 4.7070972378260345, time: 0.5659117698669434
Validation Loss Energy: 2.168001216470816, Validation Loss Force: 4.482630956211664, time: 0.05153965950012207
Test Loss Energy: 9.345032921661845, Test Loss Force: 9.996804603048679, time: 9.753509759902954


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.955508525041895, Training Loss Force: 4.26534424984984, time: 0.6135473251342773
Validation Loss Energy: 1.9730837715383, Validation Loss Force: 4.432307283893691, time: 0.049721479415893555
Test Loss Energy: 8.51486586928648, Test Loss Force: 9.995573137749064, time: 9.333489418029785


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.966610886254678, Training Loss Force: 4.253995093626546, time: 0.5343070030212402
Validation Loss Energy: 2.4767571489131837, Validation Loss Force: 4.429931404106642, time: 0.05251193046569824
Test Loss Energy: 9.46849685424988, Test Loss Force: 10.025962831592931, time: 9.001193523406982


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.95039072438209, Training Loss Force: 4.240536693797125, time: 0.5522894859313965
Validation Loss Energy: 1.822280535785841, Validation Loss Force: 4.42486701705166, time: 0.05024218559265137
Test Loss Energy: 8.500980142071544, Test Loss Force: 9.981826593905822, time: 8.959072351455688


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.988667007389312, Training Loss Force: 4.240436452196159, time: 0.5555858612060547
Validation Loss Energy: 2.5755349633999174, Validation Loss Force: 4.434422195441714, time: 0.05059218406677246
Test Loss Energy: 9.483947122500913, Test Loss Force: 9.975776554298648, time: 9.649233341217041


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.97270845477299, Training Loss Force: 4.240283944073848, time: 0.5663259029388428
Validation Loss Energy: 1.7922932365654538, Validation Loss Force: 4.41244920412156, time: 0.04527783393859863
Test Loss Energy: 8.355133161855962, Test Loss Force: 9.986786193560215, time: 8.92923355102539


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0060087739925874, Training Loss Force: 4.237269186021832, time: 0.525212287902832
Validation Loss Energy: 2.3990422769471964, Validation Loss Force: 4.452803533438053, time: 0.04588961601257324
Test Loss Energy: 9.310997026382443, Test Loss Force: 9.967658760038487, time: 8.921439170837402


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9584172520951495, Training Loss Force: 4.245865861456815, time: 0.5528872013092041
Validation Loss Energy: 1.9202238976482107, Validation Loss Force: 4.4167119822512015, time: 0.045296669006347656
Test Loss Energy: 8.464264676601031, Test Loss Force: 10.00159470834816, time: 9.13438606262207


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.995085502874854, Training Loss Force: 4.223847884221634, time: 0.5537123680114746
Validation Loss Energy: 2.3524932919909927, Validation Loss Force: 4.413434292423144, time: 0.05323934555053711
Test Loss Energy: 9.160769314011848, Test Loss Force: 9.955282687663889, time: 8.93109679222107


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9568781224731975, Training Loss Force: 4.222581301634297, time: 0.5389699935913086
Validation Loss Energy: 1.8993375317601842, Validation Loss Force: 4.445369946670399, time: 0.05260920524597168
Test Loss Energy: 8.596578346077063, Test Loss Force: 9.96806863914321, time: 8.92558240890503


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0176390061535416, Training Loss Force: 4.23704840618987, time: 0.5357565879821777
Validation Loss Energy: 2.46256510822833, Validation Loss Force: 4.429514567465465, time: 0.04950976371765137
Test Loss Energy: 9.102856764764368, Test Loss Force: 9.963232195345237, time: 9.109187364578247


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.8868675489759124, Training Loss Force: 4.224197002452248, time: 0.5357255935668945
Validation Loss Energy: 1.7483157462409968, Validation Loss Force: 4.431751501705456, time: 0.05253148078918457
Test Loss Energy: 8.464261869337664, Test Loss Force: 9.925644636255338, time: 9.028323411941528


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0785947860645217, Training Loss Force: 4.224647286698163, time: 0.544370174407959
Validation Loss Energy: 2.3186486951556984, Validation Loss Force: 4.427427266891538, time: 0.05492544174194336
Test Loss Energy: 9.304725609343546, Test Loss Force: 9.96000100722866, time: 8.944729328155518


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0509039952019856, Training Loss Force: 4.231474963729548, time: 0.5682599544525146
Validation Loss Energy: 2.146437713710023, Validation Loss Force: 4.424819811192724, time: 0.04550933837890625
Test Loss Energy: 8.590708526249628, Test Loss Force: 9.934178544356303, time: 9.105118989944458


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0071747404899387, Training Loss Force: 4.2273173394171835, time: 0.5397844314575195
Validation Loss Energy: 2.4849930126136144, Validation Loss Force: 4.453101910093596, time: 0.04603457450866699
Test Loss Energy: 9.320695477795315, Test Loss Force: 9.982721103663105, time: 8.921846628189087

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–‚â–…â–‚â–…â–‚â–†â–‚â–†â–â–…â–â–…â–‚â–„â–â–…â–‚â–…
wandb:   test_error_force â–ˆâ–„â–â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚
wandb:          test_loss â–„â–†â–†â–ˆâ–‡â–…â–‚â–ƒâ–‚â–„â–â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–â–ƒ
wandb: train_error_energy â–ˆâ–â–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ˆâ–‡â–„â–…â–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–„â–„â–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–„â–â–ˆâ–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒ
wandb:  valid_error_force â–ˆâ–„â–‚â–ƒâ–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–ƒâ–â–ˆâ–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1048
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.3207
wandb:   test_error_force 9.98272
wandb:          test_loss 7.4054
wandb: train_error_energy 3.00717
wandb:  train_error_force 4.22732
wandb:         train_loss 1.37371
wandb: valid_error_energy 2.48499
wandb:  valid_error_force 4.4531
wandb:         valid_loss 1.24958
wandb: 
wandb: ğŸš€ View run al_73_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vekfffbw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_203024-vekfffbw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4001522064208984, Uncertainty Bias: -0.04556635022163391
0.00018310547 0.03818512
2.8394935 9.669413
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2441 steps.
Found uncertainty sample 4 after 2293 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1050 steps.
Found uncertainty sample 18 after 2816 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1174 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1095 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 291 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1014 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 995 steps.
Found uncertainty sample 44 after 1319 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1083 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2042 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3968 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3147 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1987 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 364 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3823 steps.
Found uncertainty sample 74 after 148 steps.
Found uncertainty sample 75 after 2615 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1233 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1183 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2919 steps.
Found uncertainty sample 88 after 2453 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3641 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 951 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_210830-hmfctn4i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hmfctn4i
Training model 16. Added 25 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.891749111123094, Training Loss Force: 4.789633238147999, time: 0.5795960426330566
Validation Loss Energy: 1.6973360906191217, Validation Loss Force: 5.155623065495766, time: 0.05217409133911133
Test Loss Energy: 8.182614446987387, Test Loss Force: 10.522298597265285, time: 10.117145776748657


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.785515039534217, Training Loss Force: 4.723437604322814, time: 0.609504222869873
Validation Loss Energy: 1.5924512408015992, Validation Loss Force: 5.146694032744063, time: 0.05053234100341797
Test Loss Energy: 8.6453524929537, Test Loss Force: 10.31244173606639, time: 9.825649738311768


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.238143424265627, Training Loss Force: 4.936854198877143, time: 0.6000475883483887
Validation Loss Energy: 2.2881911186991117, Validation Loss Force: 4.5192359824490245, time: 0.05046510696411133
Test Loss Energy: 9.12343986693371, Test Loss Force: 9.938541651840387, time: 10.506789684295654


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.085841743044739, Training Loss Force: 4.602185714348478, time: 0.5650050640106201
Validation Loss Energy: 6.633170903597114, Validation Loss Force: 5.083890645473422, time: 0.04791092872619629
Test Loss Energy: 12.044834397692409, Test Loss Force: 10.355483290263065, time: 10.278838157653809


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.50610401477526, Training Loss Force: 4.681033644812611, time: 0.5557506084442139
Validation Loss Energy: 2.2331695727403553, Validation Loss Force: 4.6644590180699605, time: 0.05555105209350586
Test Loss Energy: 9.163882098101528, Test Loss Force: 9.974162452473378, time: 9.844846487045288


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0056771306261796, Training Loss Force: 5.024656186175527, time: 0.560713529586792
Validation Loss Energy: 1.6206498387727482, Validation Loss Force: 5.135497782748521, time: 0.05308794975280762
Test Loss Energy: 9.119387078632556, Test Loss Force: 10.399831266489231, time: 10.139204740524292


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.550198669239644, Training Loss Force: 4.66696462228179, time: 0.5348126888275146
Validation Loss Energy: 2.086480038124339, Validation Loss Force: 5.071638498387891, time: 0.04937577247619629
Test Loss Energy: 10.098529815574215, Test Loss Force: 10.283460421073094, time: 10.067310333251953


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.2781229490167827, Training Loss Force: 5.114692887571533, time: 0.6275744438171387
Validation Loss Energy: 2.7413375268257916, Validation Loss Force: 5.351329649881451, time: 0.051009178161621094
Test Loss Energy: 10.061575709401232, Test Loss Force: 10.44543563296967, time: 9.795457363128662


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.5845501518637506, Training Loss Force: 5.153927453047712, time: 0.597569465637207
Validation Loss Energy: 3.1452497827655237, Validation Loss Force: 4.772448209785435, time: 0.050768136978149414
Test Loss Energy: 9.714045700260039, Test Loss Force: 10.036389329506493, time: 10.182287216186523


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.861675936276236, Training Loss Force: 4.457038838124542, time: 0.5266134738922119
Validation Loss Energy: 2.727653617131945, Validation Loss Force: 4.478674125488527, time: 0.04771161079406738
Test Loss Energy: 9.723245517346104, Test Loss Force: 9.91869571278284, time: 10.057424545288086


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0294484339888563, Training Loss Force: 4.294466005522147, time: 0.6022007465362549
Validation Loss Energy: 3.247147859994144, Validation Loss Force: 4.44906358246305, time: 0.052486419677734375
Test Loss Energy: 8.57507230711141, Test Loss Force: 9.958557369709768, time: 9.925016164779663


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0018969714976054, Training Loss Force: 4.268607123249113, time: 0.6170105934143066
Validation Loss Energy: 2.3815625263227194, Validation Loss Force: 4.468954617268779, time: 0.0751349925994873
Test Loss Energy: 9.573800828604908, Test Loss Force: 10.022735630536456, time: 10.073511362075806


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9115962368872674, Training Loss Force: 4.270567351780733, time: 0.5788273811340332
Validation Loss Energy: 3.0159026119109473, Validation Loss Force: 4.43454377279539, time: 0.054383277893066406
Test Loss Energy: 9.591295092361309, Test Loss Force: 9.982204427306446, time: 10.217005968093872


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9091128963154835, Training Loss Force: 4.260501665079085, time: 0.5612936019897461
Validation Loss Energy: 2.939814115386817, Validation Loss Force: 4.44164291050586, time: 0.052062273025512695
Test Loss Energy: 8.620883277916676, Test Loss Force: 9.977397385162188, time: 10.020238161087036


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9070397385068696, Training Loss Force: 4.262896982572756, time: 0.5391967296600342
Validation Loss Energy: 2.2853246987835836, Validation Loss Force: 4.425459762318121, time: 0.053969621658325195
Test Loss Energy: 9.000970274491987, Test Loss Force: 9.997149416130506, time: 10.44339394569397


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0205280067447324, Training Loss Force: 4.260396997482314, time: 0.554255485534668
Validation Loss Energy: 2.851507317487337, Validation Loss Force: 4.4528966091410505, time: 0.04817795753479004
Test Loss Energy: 9.635434277208633, Test Loss Force: 10.0181437917098, time: 10.05643367767334


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.944915959976509, Training Loss Force: 4.26857057931281, time: 0.5989902019500732
Validation Loss Energy: 3.195788776147608, Validation Loss Force: 4.421772806599848, time: 0.055529117584228516
Test Loss Energy: 8.55231410044461, Test Loss Force: 9.921318741332184, time: 10.074857950210571


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0328407787797884, Training Loss Force: 4.266499533586536, time: 0.6085891723632812
Validation Loss Energy: 2.3826662972790835, Validation Loss Force: 4.448409380512314, time: 0.05303025245666504
Test Loss Energy: 9.35379178389055, Test Loss Force: 10.026719188551944, time: 9.823933362960815


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0148137270418975, Training Loss Force: 4.2674876606670535, time: 0.5439116954803467
Validation Loss Energy: 3.0289323196540576, Validation Loss Force: 4.458486495380422, time: 0.044879913330078125
Test Loss Energy: 9.927918430982531, Test Loss Force: 10.012490238415992, time: 9.519562482833862


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0212872332177816, Training Loss Force: 4.25611931361808, time: 0.5753438472747803
Validation Loss Energy: 3.4248440731806045, Validation Loss Force: 4.407441375029644, time: 0.0548548698425293
Test Loss Energy: 8.488405462808462, Test Loss Force: 9.878157211600717, time: 10.428043127059937

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–ƒâ–ˆâ–ƒâ–ƒâ–„â–„â–„â–„â–‚â–„â–„â–‚â–‚â–„â–‚â–ƒâ–„â–‚
wandb:   test_error_force â–ˆâ–†â–‚â–†â–‚â–‡â–…â–‡â–ƒâ–â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–
wandb:          test_loss â–â–‚â–ƒâ–ˆâ–ƒâ–„â–†â–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–…â–…â–†â–„â–„â–‡â–„â–ˆâ–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–â–‚â–ˆâ–‚â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„
wandb:  valid_error_force â–‡â–†â–‚â–†â–ƒâ–†â–†â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–â–â–ˆâ–â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1070
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.48841
wandb:   test_error_force 9.87816
wandb:          test_loss 7.07693
wandb: train_error_energy 3.02129
wandb:  train_error_force 4.25612
wandb:         train_loss 1.40254
wandb: valid_error_energy 3.42484
wandb:  valid_error_force 4.40744
wandb:         valid_loss 1.67826
wandb: 
wandb: ğŸš€ View run al_73_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hmfctn4i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_210830-hmfctn4i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.20137619972229, Uncertainty Bias: -0.00459522008895874
0.0001449585 0.27315378
2.9547117 9.21393
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3736 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3175 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3296 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1225 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2091 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2515 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3717 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1537 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3387 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2624 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2397 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1187 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 747 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3560 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2090 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1299 steps.
Found uncertainty sample 96 after 2146 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_214926-mivu2ual
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/mivu2ual
Training model 17. Added 17 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.848994684349998, Training Loss Force: 4.902942126741539, time: 0.5996360778808594
Validation Loss Energy: 3.734978550305411, Validation Loss Force: 5.411089149927259, time: 0.05175280570983887
Test Loss Energy: 10.003715745046403, Test Loss Force: 10.31726610210336, time: 10.031097650527954


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.70300329129571, Training Loss Force: 5.068903649741236, time: 0.5947871208190918
Validation Loss Energy: 3.8049979765881337, Validation Loss Force: 4.716420199287085, time: 0.0529327392578125
Test Loss Energy: 8.547094933851259, Test Loss Force: 9.994178706613997, time: 10.033039331436157


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.307802932070327, Training Loss Force: 4.654803311109614, time: 0.6346025466918945
Validation Loss Energy: 2.1018767188886622, Validation Loss Force: 4.949478642225571, time: 0.05163764953613281
Test Loss Energy: 8.613745057690771, Test Loss Force: 10.116689946346662, time: 10.240459680557251


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.472149989152928, Training Loss Force: 4.54113255895757, time: 0.5965890884399414
Validation Loss Energy: 7.6790875171279085, Validation Loss Force: 4.602707965182974, time: 0.056255340576171875
Test Loss Energy: 12.950655407170721, Test Loss Force: 10.049423402031186, time: 10.139160394668579


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0767873148184144, Training Loss Force: 4.619459535307527, time: 0.5721533298492432
Validation Loss Energy: 6.901389250015891, Validation Loss Force: 5.263106352911693, time: 0.05268669128417969
Test Loss Energy: 9.83751126031471, Test Loss Force: 10.337358525413185, time: 10.160844564437866


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.478269670781386, Training Loss Force: 4.698091489798295, time: 0.56424880027771
Validation Loss Energy: 2.4441606126408146, Validation Loss Force: 5.181601874751162, time: 0.05350756645202637
Test Loss Energy: 9.625129307684853, Test Loss Force: 10.487152406007478, time: 10.276595830917358


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.952330986615939, Training Loss Force: 4.835280609535972, time: 0.5895354747772217
Validation Loss Energy: 2.88531205654551, Validation Loss Force: 4.489228197667212, time: 0.05420827865600586
Test Loss Energy: 9.568235186488883, Test Loss Force: 9.970849825739744, time: 10.390694856643677


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9651134759397837, Training Loss Force: 4.32437892014961, time: 0.6012437343597412
Validation Loss Energy: 3.2697256207146377, Validation Loss Force: 4.489335078857257, time: 0.05052757263183594
Test Loss Energy: 8.560115947005416, Test Loss Force: 10.00206436537501, time: 10.326777219772339


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9749839112713694, Training Loss Force: 4.29629933883696, time: 0.6241166591644287
Validation Loss Energy: 2.3032898681461833, Validation Loss Force: 4.4506739257264, time: 0.057242393493652344
Test Loss Energy: 9.307663354500002, Test Loss Force: 9.97624231752996, time: 10.882116794586182


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9593404345042478, Training Loss Force: 4.290325328673585, time: 0.6285278797149658
Validation Loss Energy: 2.937297954037833, Validation Loss Force: 4.455647463769842, time: 0.0524449348449707
Test Loss Energy: 9.727649866420274, Test Loss Force: 9.965661200959406, time: 10.33313250541687


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.953965695778037, Training Loss Force: 4.28532410761603, time: 0.5834956169128418
Validation Loss Energy: 3.2061344300057044, Validation Loss Force: 4.446458353455695, time: 0.0568239688873291
Test Loss Energy: 8.584946774403813, Test Loss Force: 9.942897937021634, time: 10.444355010986328


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0565811998966517, Training Loss Force: 4.299340468893839, time: 0.6193749904632568
Validation Loss Energy: 2.294000111378076, Validation Loss Force: 4.438451616306423, time: 0.05578041076660156
Test Loss Energy: 9.27431322423132, Test Loss Force: 9.954436824703055, time: 9.306080341339111


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9792887214768506, Training Loss Force: 4.279339533766408, time: 0.6130483150482178
Validation Loss Energy: 2.6929410559658247, Validation Loss Force: 4.428882632429322, time: 0.052376747131347656
Test Loss Energy: 9.45862722971995, Test Loss Force: 9.956650888140404, time: 10.489917039871216


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.995644546312711, Training Loss Force: 4.2870328706418785, time: 0.5904088020324707
Validation Loss Energy: 3.1051918260822604, Validation Loss Force: 4.453336158035112, time: 0.052361488342285156
Test Loss Energy: 8.650274157246791, Test Loss Force: 9.928943706984633, time: 9.331605195999146


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.115365684145181, Training Loss Force: 4.2899433201064685, time: 0.595984697341919
Validation Loss Energy: 2.545410499985639, Validation Loss Force: 4.448665895368422, time: 0.05074167251586914
Test Loss Energy: 9.327607603734187, Test Loss Force: 10.019610129823509, time: 8.74263858795166


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9378206993288147, Training Loss Force: 4.284732338164356, time: 0.5600054264068604
Validation Loss Energy: 2.9306305718013173, Validation Loss Force: 4.426102385473268, time: 0.049773216247558594
Test Loss Energy: 9.397013763049006, Test Loss Force: 9.981218238483008, time: 8.965065479278564


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.960064128875791, Training Loss Force: 4.276372637673328, time: 0.6431674957275391
Validation Loss Energy: 3.3554472298298963, Validation Loss Force: 4.450461499361184, time: 0.0522456169128418
Test Loss Energy: 8.617792979913311, Test Loss Force: 9.90407994320555, time: 8.773076295852661


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9789223324954115, Training Loss Force: 4.286793619193673, time: 0.7702078819274902
Validation Loss Energy: 2.5881226728883613, Validation Loss Force: 4.468161915109276, time: 0.04836630821228027
Test Loss Energy: 9.547231377198965, Test Loss Force: 9.952051522863453, time: 8.983899116516113


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.954607022212864, Training Loss Force: 4.287345629104613, time: 0.5996584892272949
Validation Loss Energy: 2.8088049420270353, Validation Loss Force: 4.438364330001219, time: 0.04902148246765137
Test Loss Energy: 9.544934476176104, Test Loss Force: 9.991901484414086, time: 8.846553325653076


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.966264341420511, Training Loss Force: 4.275332052361666, time: 0.5757253170013428
Validation Loss Energy: 3.1952677303461368, Validation Loss Force: 4.43910849028691, time: 0.05221366882324219
Test Loss Energy: 8.494891738086073, Test Loss Force: 9.947936298600103, time: 8.919240236282349

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–‚â–â–ƒâ–ƒâ–
wandb:   test_error_force â–†â–‚â–„â–ƒâ–†â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚
wandb:          test_loss â–‚â–‚â–ƒâ–ˆâ–†â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–
wandb: train_error_energy â–ˆâ–â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–‡â–ˆâ–„â–ƒâ–„â–…â–†â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–„â–„â–ƒâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–ƒâ–â–ˆâ–‡â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚
wandb:  valid_error_force â–ˆâ–ƒâ–…â–‚â–‡â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–‚â–‚â–â–ˆâ–ˆâ–â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1085
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.49489
wandb:   test_error_force 9.94794
wandb:          test_loss 7.28404
wandb: train_error_energy 2.96626
wandb:  train_error_force 4.27533
wandb:         train_loss 1.40003
wandb: valid_error_energy 3.19527
wandb:  valid_error_force 4.43911
wandb:         valid_loss 1.61636
wandb: 
wandb: ğŸš€ View run al_73_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/mivu2ual
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_214926-mivu2ual/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.199585199356079, Uncertainty Bias: 0.0012504160404205322
0.000828743 0.03722
3.0427706 9.211215
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3346 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 894 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2065 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3105 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 222 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3813 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 945 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3284 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3881 steps.
Found uncertainty sample 72 after 3628 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1045 steps.
Found uncertainty sample 76 after 2418 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1690 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_223026-0jx1mmhh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0jx1mmhh
Training model 18. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.869047095344693, Training Loss Force: 4.895922882720629, time: 0.612389087677002
Validation Loss Energy: 2.078901493742687, Validation Loss Force: 4.7637601050496245, time: 0.05704617500305176
Test Loss Energy: 8.394737114803593, Test Loss Force: 9.999338279482732, time: 8.75903868675232


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0021326374112123, Training Loss Force: 4.475365516459064, time: 0.5830886363983154
Validation Loss Energy: 3.3847956912706163, Validation Loss Force: 4.44011406414992, time: 0.04738616943359375
Test Loss Energy: 8.358550541015974, Test Loss Force: 9.93477750803755, time: 8.796577453613281


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0810241631260125, Training Loss Force: 4.3299172923498634, time: 0.5729272365570068
Validation Loss Energy: 2.6047723129368197, Validation Loss Force: 4.495056785231018, time: 0.046590566635131836
Test Loss Energy: 8.325190277552444, Test Loss Force: 9.925610174999035, time: 9.476853609085083


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0951595376942156, Training Loss Force: 4.348144963187609, time: 0.5426528453826904
Validation Loss Energy: 2.425994818377734, Validation Loss Force: 4.44048859365337, time: 0.04694008827209473
Test Loss Energy: 9.1746882970386, Test Loss Force: 9.964449591685412, time: 8.81290054321289


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.026599052379563, Training Loss Force: 4.31899914975561, time: 0.5545039176940918
Validation Loss Energy: 3.703979665155074, Validation Loss Force: 4.443201594527355, time: 0.04697585105895996
Test Loss Energy: 9.90513669599791, Test Loss Force: 9.955237127924502, time: 8.799317598342896


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0893402099858926, Training Loss Force: 4.334676482711461, time: 0.6209323406219482
Validation Loss Energy: 2.703984554927259, Validation Loss Force: 4.4598372064196194, time: 0.046186208724975586
Test Loss Energy: 9.381208361992165, Test Loss Force: 9.977022652808312, time: 8.899784326553345


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0124943934295474, Training Loss Force: 4.3411680962861565, time: 0.7298905849456787
Validation Loss Energy: 2.1601750639988917, Validation Loss Force: 4.431364948068126, time: 0.04783892631530762
Test Loss Energy: 8.256847175714496, Test Loss Force: 9.846810175662975, time: 8.87105417251587


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0738710408716066, Training Loss Force: 4.3093488661923445, time: 0.5760781764984131
Validation Loss Energy: 3.5889966582351533, Validation Loss Force: 4.474230985350684, time: 0.04762601852416992
Test Loss Energy: 8.480676341622846, Test Loss Force: 9.922378940250175, time: 8.869879007339478


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0684068513651117, Training Loss Force: 4.321490321264447, time: 0.5839102268218994
Validation Loss Energy: 2.5960031566318915, Validation Loss Force: 4.446388435343873, time: 0.047676801681518555
Test Loss Energy: 8.267440544917111, Test Loss Force: 9.909075598940284, time: 8.795917510986328


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.061575928183876, Training Loss Force: 4.345079203490672, time: 0.5647940635681152
Validation Loss Energy: 2.360169810796853, Validation Loss Force: 4.446809280029677, time: 0.04650998115539551
Test Loss Energy: 9.285030357841634, Test Loss Force: 9.940224149233472, time: 9.011329412460327


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9545472802681285, Training Loss Force: 4.317825944197572, time: 0.560302734375
Validation Loss Energy: 3.808888006567492, Validation Loss Force: 4.457056959463565, time: 0.0466763973236084
Test Loss Energy: 10.158521360186217, Test Loss Force: 9.94142189473007, time: 8.910570859909058


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.013659563812407, Training Loss Force: 4.322729513233388, time: 0.5627992153167725
Validation Loss Energy: 2.922413189639998, Validation Loss Force: 4.447576152568252, time: 0.04702925682067871
Test Loss Energy: 9.60746014022884, Test Loss Force: 9.975450394129563, time: 8.841978788375854


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0768433399660235, Training Loss Force: 4.3924711247657, time: 0.5600395202636719
Validation Loss Energy: 2.0138961312879666, Validation Loss Force: 4.449056011712088, time: 0.04816126823425293
Test Loss Energy: 8.433857985290421, Test Loss Force: 9.96048817934058, time: 8.970104455947876


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.010657188478351, Training Loss Force: 4.360994709726982, time: 0.5626420974731445
Validation Loss Energy: 3.598569427487735, Validation Loss Force: 4.4548458548445025, time: 0.04710555076599121
Test Loss Energy: 8.392307393383895, Test Loss Force: 9.94873061423656, time: 8.821568250656128


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1627956406784388, Training Loss Force: 4.344215266290398, time: 0.5576646327972412
Validation Loss Energy: 2.7685612792760685, Validation Loss Force: 4.498109133883396, time: 0.047768592834472656
Test Loss Energy: 8.311140516622801, Test Loss Force: 9.937723348558139, time: 8.823665857315063


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0781373339927662, Training Loss Force: 4.346168386436989, time: 0.6000106334686279
Validation Loss Energy: 2.4423084506849873, Validation Loss Force: 4.455772603829854, time: 0.05176663398742676
Test Loss Energy: 9.320723769600724, Test Loss Force: 9.963047363632818, time: 9.487672328948975


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.069519840824117, Training Loss Force: 4.315614419688118, time: 0.6246528625488281
Validation Loss Energy: 3.6449934950530736, Validation Loss Force: 4.469068623871494, time: 0.048493385314941406
Test Loss Energy: 10.002352398990434, Test Loss Force: 9.94741212377252, time: 8.858486890792847


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.060681122678001, Training Loss Force: 4.317436451327514, time: 0.6090424060821533
Validation Loss Energy: 2.978346343082183, Validation Loss Force: 4.494603430849909, time: 0.04943370819091797
Test Loss Energy: 9.375918741015754, Test Loss Force: 9.950365784526777, time: 8.799981355667114


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0546060276457023, Training Loss Force: 4.313173501424531, time: 0.5567913055419922
Validation Loss Energy: 1.9626864584383479, Validation Loss Force: 4.414409583282308, time: 0.046392202377319336
Test Loss Energy: 8.184837759937844, Test Loss Force: 9.917688250312416, time: 8.976434707641602


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9504046353237023, Training Loss Force: 4.33148259282598, time: 0.5507054328918457
Validation Loss Energy: 3.4082122466638203, Validation Loss Force: 4.471622638975286, time: 0.05126190185546875
Test Loss Energy: 8.431013159618818, Test Loss Force: 9.90194924896173, time: 8.840521097183228

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–…â–‡â–…â–â–‚â–â–…â–ˆâ–†â–‚â–‚â–â–…â–‡â–…â–â–‚
wandb:   test_error_force â–ˆâ–…â–…â–†â–†â–‡â–â–„â–„â–…â–…â–‡â–†â–†â–…â–†â–†â–†â–„â–„
wandb:          test_loss â–‚â–„â–‚â–„â–ˆâ–…â–„â–„â–‚â–…â–ˆâ–‡â–„â–ƒâ–‚â–…â–ˆâ–†â–â–„
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–ƒâ–ƒâ–ˆâ–„â–‚â–‡â–ƒâ–ƒâ–ˆâ–…â–â–‡â–„â–ƒâ–‡â–…â–â–†
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚
wandb:         valid_loss â–ƒâ–‡â–ƒâ–‚â–ˆâ–ƒâ–â–ˆâ–ƒâ–‚â–ˆâ–„â–â–ˆâ–„â–‚â–‡â–…â–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1096
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.43101
wandb:   test_error_force 9.90195
wandb:          test_loss 7.12373
wandb: train_error_energy 2.9504
wandb:  train_error_force 4.33148
wandb:         train_loss 1.39729
wandb: valid_error_energy 3.40821
wandb:  valid_error_force 4.47162
wandb:         valid_loss 1.66835
wandb: 
wandb: ğŸš€ View run al_73_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0jx1mmhh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_223026-0jx1mmhh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.085167646408081, Uncertainty Bias: 0.0055130720138549805
0.0002861023 0.02063036
3.1621144 8.962717
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1638 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2348 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2173 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3000 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3916 steps.
Found uncertainty sample 28 after 1095 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1360 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 617 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3323 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2265 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2873 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3252 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 618 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_231111-p4vc6zr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/p4vc6zr7
Training model 19. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.82420349461136, Training Loss Force: 4.8069639505124835, time: 0.567533016204834
Validation Loss Energy: 7.169549702456725, Validation Loss Force: 4.602394001687216, time: 0.0490717887878418
Test Loss Energy: 12.520001406367413, Test Loss Force: 10.068251600863384, time: 8.662310361862183


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.8597614967215756, Training Loss Force: 4.700310061131307, time: 0.5715117454528809
Validation Loss Energy: 3.7972628957968944, Validation Loss Force: 4.648535502106372, time: 0.046448707580566406
Test Loss Energy: 9.781343600121843, Test Loss Force: 10.058932493737066, time: 8.709405660629272


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1453830534303497, Training Loss Force: 4.464565286720543, time: 0.5574643611907959
Validation Loss Energy: 2.5192635755250685, Validation Loss Force: 4.473246342387391, time: 0.04607439041137695
Test Loss Energy: 9.571872952144624, Test Loss Force: 9.94597037952427, time: 8.829957008361816


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.196008601490443, Training Loss Force: 4.324599456911011, time: 0.5655515193939209
Validation Loss Energy: 2.1264487044800853, Validation Loss Force: 4.469395056839424, time: 0.0490717887878418
Test Loss Energy: 8.590581236441421, Test Loss Force: 9.940690817131058, time: 8.662750244140625


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0520990975233113, Training Loss Force: 4.334232041458164, time: 0.5746357440948486
Validation Loss Energy: 3.212762845141683, Validation Loss Force: 4.464083507032463, time: 0.04603385925292969
Test Loss Energy: 8.413638136938774, Test Loss Force: 9.903310393973996, time: 8.68782639503479


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1182008955765315, Training Loss Force: 4.3895196643223535, time: 0.5468981266021729
Validation Loss Energy: 2.435864405601837, Validation Loss Force: 4.454107483956606, time: 0.05327916145324707
Test Loss Energy: 8.154308950339088, Test Loss Force: 9.866609118706855, time: 8.742257595062256


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0941086220311194, Training Loss Force: 4.353865505319836, time: 0.547316312789917
Validation Loss Energy: 2.4351948394800322, Validation Loss Force: 4.511130380198961, time: 0.04727673530578613
Test Loss Energy: 9.029331580655226, Test Loss Force: 9.919832836313004, time: 8.953901767730713


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.140567295562723, Training Loss Force: 4.358649042962047, time: 0.5551245212554932
Validation Loss Energy: 3.415632473282718, Validation Loss Force: 4.477245034909962, time: 0.04774308204650879
Test Loss Energy: 9.871442204980536, Test Loss Force: 9.889469774165311, time: 8.752434492111206


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.118806142125041, Training Loss Force: 4.342974502913483, time: 0.5567069053649902
Validation Loss Energy: 2.7810325328011922, Validation Loss Force: 4.4695348930630665, time: 0.04928421974182129
Test Loss Energy: 9.319622832721292, Test Loss Force: 9.915196211842842, time: 8.812736988067627


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.16303020035676, Training Loss Force: 4.333186991536569, time: 0.5780658721923828
Validation Loss Energy: 2.2152507185601085, Validation Loss Force: 4.461191925503444, time: 0.0521240234375
Test Loss Energy: 8.183292328810856, Test Loss Force: 9.879832079952491, time: 8.930295705795288


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.051824959994796, Training Loss Force: 4.315136730750347, time: 0.603626012802124
Validation Loss Energy: 3.5251456126329224, Validation Loss Force: 4.478173119910189, time: 0.046144962310791016
Test Loss Energy: 8.442344342453564, Test Loss Force: 9.937502805844263, time: 8.727864503860474


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.011864093421133, Training Loss Force: 4.3177164100637, time: 0.6034066677093506
Validation Loss Energy: 2.4544742021418977, Validation Loss Force: 4.4478682944877095, time: 0.04780721664428711
Test Loss Energy: 8.183792674542406, Test Loss Force: 9.906953620269944, time: 9.261610746383667


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.141684703413781, Training Loss Force: 4.328684316031081, time: 0.5625815391540527
Validation Loss Energy: 2.443771386973733, Validation Loss Force: 4.485115943880218, time: 0.04646563529968262
Test Loss Energy: 9.228724530860816, Test Loss Force: 9.903852331037744, time: 8.937203168869019


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0311093877036717, Training Loss Force: 4.320932019733874, time: 0.5591492652893066
Validation Loss Energy: 3.9187253521941674, Validation Loss Force: 4.498672486822593, time: 0.05387401580810547
Test Loss Energy: 10.523818669757391, Test Loss Force: 9.919896470724844, time: 8.782335758209229


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0701676235414745, Training Loss Force: 4.342991094945844, time: 0.5902855396270752
Validation Loss Energy: 2.719513723833409, Validation Loss Force: 4.487590688768059, time: 0.05126810073852539
Test Loss Energy: 9.643292385617515, Test Loss Force: 9.901358012249588, time: 8.768782615661621


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.084373488799303, Training Loss Force: 4.3319661347813, time: 0.5481102466583252
Validation Loss Energy: 2.112259113155837, Validation Loss Force: 4.4496679065250975, time: 0.046741485595703125
Test Loss Energy: 8.280999251597366, Test Loss Force: 9.795975644365507, time: 8.996779680252075


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.091572449087893, Training Loss Force: 4.339237752012206, time: 0.6034853458404541
Validation Loss Energy: 3.226129673971728, Validation Loss Force: 4.549196116033609, time: 0.04934263229370117
Test Loss Energy: 8.388919732977119, Test Loss Force: 9.885986496596175, time: 8.766062498092651


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0633941585428515, Training Loss Force: 4.346826545536547, time: 0.5776901245117188
Validation Loss Energy: 2.315387705513586, Validation Loss Force: 4.4424414020631575, time: 0.0469970703125
Test Loss Energy: 8.107282215323513, Test Loss Force: 9.848819672606217, time: 8.765486717224121


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.03263023069431, Training Loss Force: 4.329925842845067, time: 0.5629947185516357
Validation Loss Energy: 2.4590671986149504, Validation Loss Force: 4.46032930523212, time: 0.048859596252441406
Test Loss Energy: 9.364244461167154, Test Loss Force: 9.915969002017986, time: 8.828710317611694


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.018476740400592, Training Loss Force: 4.318489103809949, time: 0.7222352027893066
Validation Loss Energy: 4.071948444889997, Validation Loss Force: 4.4768691693916365, time: 0.04736495018005371
Test Loss Energy: 10.403144205659153, Test Loss Force: 9.965204708225727, time: 8.718148946762085

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–ƒâ–‚â–â–â–‚â–„â–ƒâ–â–‚â–â–ƒâ–…â–ƒâ–â–â–â–ƒâ–…
wandb:   test_error_force â–ˆâ–ˆâ–…â–…â–„â–ƒâ–„â–ƒâ–„â–ƒâ–…â–„â–„â–„â–„â–â–ƒâ–‚â–„â–…
wandb:          test_loss â–‡â–†â–†â–ƒâ–ƒâ–‚â–…â–†â–…â–â–‚â–â–ƒâ–ˆâ–…â–â–‚â–â–„â–‡
wandb: train_error_energy â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–ƒâ–â–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–â–ƒâ–â–â–ƒâ–‚â–â–ƒâ–â–â–„â–‚â–â–ƒâ–â–â–„
wandb:  valid_error_force â–†â–ˆâ–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–â–…â–â–‚â–‚
wandb:         valid_loss â–ˆâ–„â–â–â–ƒâ–â–â–ƒâ–‚â–â–ƒâ–â–â–ƒâ–‚â–â–ƒâ–â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1107
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.40314
wandb:   test_error_force 9.9652
wandb:          test_loss 7.96212
wandb: train_error_energy 3.01848
wandb:  train_error_force 4.31849
wandb:         train_loss 1.41597
wandb: valid_error_energy 4.07195
wandb:  valid_error_force 4.47687
wandb:         valid_loss 1.87478
wandb: 
wandb: ğŸš€ View run al_73_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/p4vc6zr7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_231111-p4vc6zr7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.202641487121582, Uncertainty Bias: -0.03620585799217224
0.00042152405 0.019586563
2.8465452 9.282002
(48745, 22, 3)
Found uncertainty sample 0 after 959 steps.
Found uncertainty sample 1 after 580 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2950 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1023 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 836 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1526 steps.
Found uncertainty sample 18 after 511 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2756 steps.
Found uncertainty sample 23 after 1423 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3025 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1701 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2917 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3130 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1721 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1452 steps.
Found uncertainty sample 63 after 912 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 537 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1601 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3734 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1639 steps.
Found uncertainty sample 87 after 1683 steps.
Found uncertainty sample 88 after 3154 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1203 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1681 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241203_234905-ghy7tfnd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ghy7tfnd
Training model 20. Added 24 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.9590653712676955, Training Loss Force: 4.812074076991026, time: 0.6419088840484619
Validation Loss Energy: 2.0386473655418618, Validation Loss Force: 5.083329073887391, time: 0.055724382400512695
Test Loss Energy: 8.87204642449738, Test Loss Force: 10.234313460760978, time: 9.448881149291992


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0021788413473534, Training Loss Force: 4.775313541096249, time: 0.6221270561218262
Validation Loss Energy: 1.734146195139882, Validation Loss Force: 4.579988141547378, time: 0.04958224296569824
Test Loss Energy: 8.048923542030229, Test Loss Force: 9.886234762201623, time: 9.55044937133789


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.576705441992393, Training Loss Force: 4.678968782885036, time: 0.6224241256713867
Validation Loss Energy: 4.674251561769572, Validation Loss Force: 4.573936439499353, time: 0.05350136756896973
Test Loss Energy: 8.590824680268925, Test Loss Force: 9.792476339281095, time: 9.55695128440857


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.517022409913595, Training Loss Force: 4.487700773919704, time: 0.6449451446533203
Validation Loss Energy: 3.8207210903203865, Validation Loss Force: 4.511475072036857, time: 0.05453896522521973
Test Loss Energy: 10.015565707353723, Test Loss Force: 9.881340680903257, time: 9.391703605651855


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.393772634671364, Training Loss Force: 4.4117089158049065, time: 0.6156425476074219
Validation Loss Energy: 3.358638746698479, Validation Loss Force: 4.564094908587637, time: 0.05094170570373535
Test Loss Energy: 8.42538455459581, Test Loss Force: 9.94474092873923, time: 9.505329608917236


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.461433639046603, Training Loss Force: 4.461770556020153, time: 0.5738589763641357
Validation Loss Energy: 3.9032992791025825, Validation Loss Force: 4.611021095077042, time: 0.05698370933532715
Test Loss Energy: 9.95070184006607, Test Loss Force: 9.998763951635997, time: 9.653305530548096


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.376166621363264, Training Loss Force: 4.45240653909188, time: 0.585310697555542
Validation Loss Energy: 3.477756496989133, Validation Loss Force: 4.695032382482429, time: 0.05996441841125488
Test Loss Energy: 8.32570338187631, Test Loss Force: 9.875198626477495, time: 9.597211837768555


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.514206665784526, Training Loss Force: 4.456361353422194, time: 0.5619969367980957
Validation Loss Energy: 3.349780745404326, Validation Loss Force: 4.54775188395312, time: 0.0505528450012207
Test Loss Energy: 9.490363845730114, Test Loss Force: 9.829003065253966, time: 9.975690841674805


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.328243143066026, Training Loss Force: 4.4038763430392756, time: 0.608290433883667
Validation Loss Energy: 3.626783166960807, Validation Loss Force: 4.499436241993125, time: 0.05465340614318848
Test Loss Energy: 8.43939704001094, Test Loss Force: 9.80888060142816, time: 9.600317239761353


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.450875985605822, Training Loss Force: 4.421536851528213, time: 0.6125810146331787
Validation Loss Energy: 4.058061906273356, Validation Loss Force: 4.532230508467078, time: 0.05762839317321777
Test Loss Energy: 10.220654837421977, Test Loss Force: 9.88905254114974, time: 9.697633266448975


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.334988484244633, Training Loss Force: 4.397566691156199, time: 0.5934488773345947
Validation Loss Energy: 3.631831744506428, Validation Loss Force: 4.50446544732305, time: 0.050405263900756836
Test Loss Energy: 8.37275718693151, Test Loss Force: 9.780638104992665, time: 9.42050313949585


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.36028385385338, Training Loss Force: 4.425313468689246, time: 0.5912237167358398
Validation Loss Energy: 3.9391788492625106, Validation Loss Force: 4.555370286111894, time: 0.05041337013244629
Test Loss Energy: 10.02313657489597, Test Loss Force: 9.770393333081552, time: 9.413045883178711


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.478785775509447, Training Loss Force: 4.3834561226377415, time: 0.593111515045166
Validation Loss Energy: 3.5068237272985465, Validation Loss Force: 4.4799647158583245, time: 0.05324530601501465
Test Loss Energy: 8.467768428073521, Test Loss Force: 9.740660827986073, time: 9.139983177185059


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.4093681868166446, Training Loss Force: 4.4056609001682965, time: 0.5862047672271729
Validation Loss Energy: 3.994831884919118, Validation Loss Force: 4.525797151502933, time: 0.05452847480773926
Test Loss Energy: 9.839581798914919, Test Loss Force: 9.88578071766274, time: 10.222988843917847


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.369808532755696, Training Loss Force: 4.405478311468636, time: 0.5808196067810059
Validation Loss Energy: 3.5112824542766043, Validation Loss Force: 4.46779807372483, time: 0.05217576026916504
Test Loss Energy: 8.302722627307512, Test Loss Force: 9.784415632260401, time: 8.4388906955719


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.365143273959536, Training Loss Force: 4.401566261984847, time: 0.5903604030609131
Validation Loss Energy: 3.9401710629767646, Validation Loss Force: 4.485444158201315, time: 0.04791617393493652
Test Loss Energy: 9.793605190244454, Test Loss Force: 9.727867531922358, time: 8.246119976043701


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.414795079241195, Training Loss Force: 4.380712492385682, time: 0.5764939785003662
Validation Loss Energy: 3.2057180387028197, Validation Loss Force: 4.485393834974335, time: 0.04754066467285156
Test Loss Energy: 8.306152322053169, Test Loss Force: 9.751297968580067, time: 8.259453296661377


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.414754293675966, Training Loss Force: 4.385090545095121, time: 0.6024429798126221
Validation Loss Energy: 3.7076207510292853, Validation Loss Force: 4.508068679442454, time: 0.04870343208312988
Test Loss Energy: 9.832327480628456, Test Loss Force: 9.827540765495868, time: 8.212845087051392


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4553080850651785, Training Loss Force: 4.418787815364114, time: 0.6808121204376221
Validation Loss Energy: 3.16500810676028, Validation Loss Force: 4.577640763411008, time: 0.06994938850402832
Test Loss Energy: 8.361074298763677, Test Loss Force: 9.832372368862986, time: 8.296214580535889


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.2971007414658855, Training Loss Force: 4.398765677913466, time: 0.5848648548126221
Validation Loss Energy: 3.7377844042132473, Validation Loss Force: 4.522653508500724, time: 0.048352718353271484
Test Loss Energy: 9.86358744476949, Test Loss Force: 9.829297081791154, time: 8.253140211105347

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–ƒâ–‡â–‚â–‡â–‚â–†â–‚â–ˆâ–‚â–‡â–‚â–‡â–‚â–‡â–‚â–‡â–‚â–‡
wandb:   test_error_force â–ˆâ–ƒâ–‚â–ƒâ–„â–…â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–â–‚â–‚â–‚
wandb:          test_loss â–„â–‡â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–ƒâ–â–‚â–â–ƒâ–â–ƒâ–â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–…â–„â–„â–„â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb:  train_error_force â–ˆâ–‡â–†â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–â–ˆâ–†â–…â–†â–…â–…â–†â–‡â–†â–†â–…â–†â–…â–†â–…â–†â–„â–†
wandb:  valid_error_force â–ˆâ–‚â–‚â–â–‚â–ƒâ–„â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–‚
wandb:         valid_loss â–‚â–â–ˆâ–„â–ƒâ–„â–„â–ƒâ–„â–„â–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–„â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1128
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.86359
wandb:   test_error_force 9.8293
wandb:          test_loss 6.28943
wandb: train_error_energy 4.2971
wandb:  train_error_force 4.39877
wandb:         train_loss 1.81626
wandb: valid_error_energy 3.73778
wandb:  valid_error_force 4.52265
wandb:         valid_loss 1.65075
wandb: 
wandb: ğŸš€ View run al_73_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ghy7tfnd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241203_234905-ghy7tfnd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.311148166656494, Uncertainty Bias: -0.16239404678344727
0.000415802 0.05117941
2.143378 8.595343
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2837 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_003200-ca0ano23
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ca0ano23
Training model 21. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.624513536810179, Training Loss Force: 4.982498682842987, time: 0.5693066120147705
Validation Loss Energy: 3.869238915864884, Validation Loss Force: 5.004787876720867, time: 0.04935932159423828
Test Loss Energy: 8.405624565828592, Test Loss Force: 9.934882388702704, time: 8.908601999282837


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.123970343982394, Training Loss Force: 4.6079438817033695, time: 0.5801420211791992
Validation Loss Energy: 3.5915119289075537, Validation Loss Force: 4.5160878860638975, time: 0.04791617393493652
Test Loss Energy: 8.35090939396172, Test Loss Force: 9.757572430706968, time: 8.919487476348877


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0220466288757217, Training Loss Force: 4.379255060973047, time: 0.6046285629272461
Validation Loss Energy: 3.746357166331467, Validation Loss Force: 4.479440552688811, time: 0.049276113510131836
Test Loss Energy: 8.385058566048626, Test Loss Force: 9.69906569525552, time: 9.05817198753357


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0724259777580567, Training Loss Force: 4.3469331314248905, time: 0.5843136310577393
Validation Loss Energy: 3.4591515991702826, Validation Loss Force: 4.459255594610457, time: 0.047411441802978516
Test Loss Energy: 8.271973794944826, Test Loss Force: 9.711965536756852, time: 9.356873035430908


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0804991476284904, Training Loss Force: 4.358671741607372, time: 0.5489461421966553
Validation Loss Energy: 3.575905716476913, Validation Loss Force: 4.432426189217617, time: 0.047510385513305664
Test Loss Energy: 8.340451270034595, Test Loss Force: 9.647721813532874, time: 8.907146215438843


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.13361374574364, Training Loss Force: 4.350809510548554, time: 0.5620346069335938
Validation Loss Energy: 3.647748580395638, Validation Loss Force: 4.440498836434083, time: 0.04811978340148926
Test Loss Energy: 8.411527095870147, Test Loss Force: 9.677301332101223, time: 9.067663192749023


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.157123683009917, Training Loss Force: 4.359926896656698, time: 0.5853183269500732
Validation Loss Energy: 3.290259278675515, Validation Loss Force: 4.430541517566485, time: 0.04823756217956543
Test Loss Energy: 8.350822487709612, Test Loss Force: 9.663410176888677, time: 8.9449462890625


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.080713265660689, Training Loss Force: 4.324679880058317, time: 0.5985846519470215
Validation Loss Energy: 3.4266047181174555, Validation Loss Force: 4.4381385434872485, time: 0.04870891571044922
Test Loss Energy: 8.324503134557792, Test Loss Force: 9.681745332604667, time: 8.949906349182129


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.099516682301015, Training Loss Force: 4.356908239083149, time: 0.5760560035705566
Validation Loss Energy: 3.349388847707493, Validation Loss Force: 4.4633749738101205, time: 0.04760551452636719
Test Loss Energy: 8.268798117896587, Test Loss Force: 9.724222458988045, time: 8.912708044052124


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.06562710011299, Training Loss Force: 4.36724262340836, time: 0.5655059814453125
Validation Loss Energy: 3.2575614279417486, Validation Loss Force: 4.441311133478428, time: 0.05041837692260742
Test Loss Energy: 8.404339883768907, Test Loss Force: 9.700829015719544, time: 9.1051664352417


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1028865633407405, Training Loss Force: 4.347635683506564, time: 0.5888230800628662
Validation Loss Energy: 3.2352938453415323, Validation Loss Force: 4.508599968024638, time: 0.05179738998413086
Test Loss Energy: 8.358780825213532, Test Loss Force: 9.737151217167364, time: 8.930468320846558


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0428840322926605, Training Loss Force: 4.391347789320599, time: 0.6259644031524658
Validation Loss Energy: 3.682484076483789, Validation Loss Force: 4.420956056172585, time: 0.047847747802734375
Test Loss Energy: 8.328073560866903, Test Loss Force: 9.680876260757145, time: 8.970382928848267


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.147817671394157, Training Loss Force: 4.344515092946214, time: 0.5698196887969971
Validation Loss Energy: 3.501108032991726, Validation Loss Force: 4.467782486884615, time: 0.05205273628234863
Test Loss Energy: 8.373071152758884, Test Loss Force: 9.755506863108007, time: 10.044931173324585


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.070375915506159, Training Loss Force: 4.352794197757733, time: 0.5732550621032715
Validation Loss Energy: 3.433212425022863, Validation Loss Force: 4.43780275841519, time: 0.05132603645324707
Test Loss Energy: 8.4838119685358, Test Loss Force: 9.734617899801881, time: 9.651913166046143


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.034314981326873, Training Loss Force: 4.360606742670738, time: 0.5700299739837646
Validation Loss Energy: 3.5116476316759258, Validation Loss Force: 4.438716147251785, time: 0.05457162857055664
Test Loss Energy: 8.342534609196179, Test Loss Force: 9.732478755788586, time: 9.960179090499878


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.034990052324785, Training Loss Force: 4.352446060733328, time: 0.6161518096923828
Validation Loss Energy: 3.360236175151365, Validation Loss Force: 4.466793390538403, time: 0.05079817771911621
Test Loss Energy: 8.31508278408431, Test Loss Force: 9.722952088375665, time: 9.834711074829102


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0298706381571163, Training Loss Force: 4.358426960178203, time: 0.6098134517669678
Validation Loss Energy: 3.176657488467784, Validation Loss Force: 4.491715412027226, time: 0.05408811569213867
Test Loss Energy: 8.280091491277192, Test Loss Force: 9.727572648024726, time: 10.303740501403809


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.114127186348862, Training Loss Force: 4.379473134475211, time: 0.5646235942840576
Validation Loss Energy: 3.4405133009795428, Validation Loss Force: 4.454592457356436, time: 0.05048632621765137
Test Loss Energy: 8.369212830399581, Test Loss Force: 9.741670803936492, time: 9.804605484008789


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.054120276140912, Training Loss Force: 4.356280411055696, time: 0.7643587589263916
Validation Loss Energy: 3.2938992512039964, Validation Loss Force: 4.4394411579909265, time: 0.07776713371276855
Test Loss Energy: 8.176860888433495, Test Loss Force: 9.700818919830517, time: 9.736124992370605


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0873332595732736, Training Loss Force: 4.325924309877113, time: 0.6062815189361572
Validation Loss Energy: 3.4184327604619056, Validation Loss Force: 4.446200947923002, time: 0.05269598960876465
Test Loss Energy: 8.332549565105394, Test Loss Force: 9.72405374805547, time: 9.695393323898315

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–†â–ƒâ–…â–†â–…â–„â–ƒâ–†â–…â–„â–…â–ˆâ–…â–„â–ƒâ–…â–â–…
wandb:   test_error_force â–ˆâ–„â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒ
wandb:          test_loss â–â–„â–…â–†â–†â–‡â–‡â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–ˆ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–‡â–„â–…â–†â–‚â–„â–ƒâ–‚â–‚â–†â–„â–„â–„â–ƒâ–â–„â–‚â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–‚â–â–â–
wandb:         valid_loss â–ˆâ–„â–…â–‚â–„â–…â–â–‚â–‚â–â–‚â–…â–„â–ƒâ–„â–ƒâ–â–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1129
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.33255
wandb:   test_error_force 9.72405
wandb:          test_loss 7.0199
wandb: train_error_energy 3.08733
wandb:  train_error_force 4.32592
wandb:         train_loss 1.43888
wandb: valid_error_energy 3.41843
wandb:  valid_error_force 4.4462
wandb:         valid_loss 1.66534
wandb: 
wandb: ğŸš€ View run al_73_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ca0ano23
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_003200-ca0ano23/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1557538509368896, Uncertainty Bias: -0.016192525625228882
0.00015258789 0.18877125
3.0819812 8.970505
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3827 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3024 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1534 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3933 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2294 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1997 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_011426-vvkcjwmv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vvkcjwmv
Training model 22. Added 6 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.208603297915628, Training Loss Force: 4.908121658485982, time: 0.552070140838623
Validation Loss Energy: 1.5554191351423488, Validation Loss Force: 4.6240766324410805, time: 0.05131220817565918
Test Loss Energy: 8.509014047188233, Test Loss Force: 9.867907473351583, time: 8.536057233810425


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.232190165594618, Training Loss Force: 4.576325914474812, time: 0.6080238819122314
Validation Loss Energy: 1.9092220378170646, Validation Loss Force: 4.565191776800477, time: 0.04875349998474121
Test Loss Energy: 8.089825861280659, Test Loss Force: 9.780706015584753, time: 8.361652135848999


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.274038422415293, Training Loss Force: 4.391828630970723, time: 0.586040735244751
Validation Loss Energy: 1.6421684737006366, Validation Loss Force: 4.446451673381317, time: 0.048172950744628906
Test Loss Energy: 8.264116887317202, Test Loss Force: 9.728685420177298, time: 8.621890544891357


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.217033967507898, Training Loss Force: 4.379308736607722, time: 0.6295428276062012
Validation Loss Energy: 1.9503169647129133, Validation Loss Force: 4.46296214521357, time: 0.053802490234375
Test Loss Energy: 8.723598468138551, Test Loss Force: 9.73516343687779, time: 8.508985757827759


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2140163026676256, Training Loss Force: 4.400957150536162, time: 0.6175796985626221
Validation Loss Energy: 1.735564708934015, Validation Loss Force: 4.477093619890732, time: 0.05306291580200195
Test Loss Energy: 8.378579910485872, Test Loss Force: 9.787179261802809, time: 8.44745683670044


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2345613322180804, Training Loss Force: 4.35323743306321, time: 0.565990686416626
Validation Loss Energy: 1.6300824377979681, Validation Loss Force: 4.452355523116446, time: 0.050280094146728516
Test Loss Energy: 8.097904852819072, Test Loss Force: 9.73141733044158, time: 8.477681875228882


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2155475427168847, Training Loss Force: 4.347708001496959, time: 0.5543098449707031
Validation Loss Energy: 1.9429123249342306, Validation Loss Force: 4.426102385473268, time: 0.04892086982727051
Test Loss Energy: 8.189018938569056, Test Loss Force: 9.687855910240167, time: 8.655887126922607


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2652352255646813, Training Loss Force: 4.365594080015974, time: 0.6100904941558838
Validation Loss Energy: 1.8072165227255341, Validation Loss Force: 4.463975735165834, time: 0.05109572410583496
Test Loss Energy: 8.160486624833355, Test Loss Force: 9.741984513286312, time: 8.443052768707275


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.185879016027282, Training Loss Force: 4.376526535111386, time: 0.6407644748687744
Validation Loss Energy: 2.0150845165197833, Validation Loss Force: 4.464975519631049, time: 0.04953360557556152
Test Loss Energy: 8.253889434635573, Test Loss Force: 9.77450526976903, time: 8.454605102539062


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.28089732795095, Training Loss Force: 4.361384928038978, time: 0.584061861038208
Validation Loss Energy: 1.6607075727868654, Validation Loss Force: 4.483468192200352, time: 0.05238819122314453
Test Loss Energy: 8.104372036840488, Test Loss Force: 9.760069803909587, time: 10.172532320022583


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2069565000803095, Training Loss Force: 4.366731071971861, time: 0.6811792850494385
Validation Loss Energy: 1.7657261354265177, Validation Loss Force: 4.4667951718915715, time: 0.05884432792663574
Test Loss Energy: 8.329536096118025, Test Loss Force: 9.770751091284827, time: 10.144853115081787


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2028340715503965, Training Loss Force: 4.393930776154378, time: 0.6801700592041016
Validation Loss Energy: 1.9582693705905783, Validation Loss Force: 4.445290676454449, time: 0.05353403091430664
Test Loss Energy: 8.181907326723186, Test Loss Force: 9.741552068820393, time: 9.459180116653442


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.20926777488877, Training Loss Force: 4.356116056484987, time: 0.6088013648986816
Validation Loss Energy: 1.7275114339332447, Validation Loss Force: 4.502220051655515, time: 0.05018305778503418
Test Loss Energy: 8.325387350238852, Test Loss Force: 9.778011401819509, time: 9.679712533950806


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2335544316180753, Training Loss Force: 4.381104340600483, time: 0.5774128437042236
Validation Loss Energy: 1.9853855738433726, Validation Loss Force: 4.455193664050442, time: 0.04887819290161133
Test Loss Energy: 8.211195244306547, Test Loss Force: 9.76123957003706, time: 8.942485332489014


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.202920204305719, Training Loss Force: 4.37030721267851, time: 0.5708985328674316
Validation Loss Energy: 1.637829431388515, Validation Loss Force: 4.489586249653864, time: 0.050282955169677734
Test Loss Energy: 8.318295442863688, Test Loss Force: 9.814320826022099, time: 8.974791765213013


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.193535018345447, Training Loss Force: 4.358378628603028, time: 0.6064431667327881
Validation Loss Energy: 1.7917462498084822, Validation Loss Force: 4.460208618555027, time: 0.051512956619262695
Test Loss Energy: 8.139312789580517, Test Loss Force: 9.789643316240033, time: 9.164320468902588


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1903690744097486, Training Loss Force: 4.362604963215786, time: 0.6146771907806396
Validation Loss Energy: 1.7781066512746755, Validation Loss Force: 4.502612394690639, time: 0.048686981201171875
Test Loss Energy: 8.369138708387549, Test Loss Force: 9.820908302677823, time: 8.95707082748413


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.251228059030861, Training Loss Force: 4.5281998876630825, time: 0.5960783958435059
Validation Loss Energy: 1.6870966499436324, Validation Loss Force: 4.593402621574652, time: 0.048941612243652344
Test Loss Energy: 8.577846925551043, Test Loss Force: 9.843916484023204, time: 8.966458320617676


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2313500070733903, Training Loss Force: 4.499842217328184, time: 0.599365234375
Validation Loss Energy: 1.7959678341461272, Validation Loss Force: 4.487032234550072, time: 0.049805641174316406
Test Loss Energy: 8.220532939060417, Test Loss Force: 9.860106951147584, time: 9.165898561477661


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.166650839435337, Training Loss Force: 4.357396533964406, time: 0.6161320209503174
Validation Loss Energy: 1.817593127594915, Validation Loss Force: 4.496706763602343, time: 0.05573105812072754
Test Loss Energy: 8.210470895745809, Test Loss Force: 9.773049661743379, time: 8.879938125610352

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–ƒâ–ˆâ–„â–â–‚â–‚â–ƒâ–â–„â–‚â–„â–‚â–„â–‚â–„â–†â–‚â–‚
wandb:   test_error_force â–ˆâ–…â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–„â–„â–„â–ƒâ–…â–„â–†â–…â–†â–‡â–ˆâ–„
wandb:          test_loss â–â–„â–„â–…â–…â–…â–…â–…â–…â–…â–…â–†â–…â–…â–†â–†â–†â–ˆâ–†â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–ƒâ–ƒâ–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–‚â–‡â–„â–‚â–‡â–…â–ˆâ–ƒâ–„â–‡â–„â–ˆâ–‚â–…â–„â–ƒâ–…â–…
wandb:  valid_error_force â–ˆâ–†â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–ƒâ–‚â–„â–‡â–ƒâ–ƒ
wandb:         valid_loss â–ˆâ–…â–‚â–„â–‚â–â–„â–ƒâ–…â–â–‚â–„â–‚â–…â–â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1134
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.21047
wandb:   test_error_force 9.77305
wandb:          test_loss 8.62075
wandb: train_error_energy 2.16665
wandb:  train_error_force 4.3574
wandb:         train_loss 1.07733
wandb: valid_error_energy 1.81759
wandb:  valid_error_force 4.49671
wandb:         valid_loss 1.05362
wandb: 
wandb: ğŸš€ View run al_73_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vvkcjwmv
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_011426-vvkcjwmv/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0299954414367676, Uncertainty Bias: 0.0825190395116806
9.1552734e-05 0.0033855438
3.2131782 9.270836
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2716 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 781 steps.
Found uncertainty sample 11 after 1416 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3687 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2698 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1876 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3448 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1815 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3057 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2684 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2754 steps.
Found uncertainty sample 68 after 3012 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 627 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_015524-1q8n0n8l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1q8n0n8l
Training model 23. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 10.461494054635066, Training Loss Force: 6.0279535424176665, time: 0.6604280471801758
Validation Loss Energy: 4.96243575982711, Validation Loss Force: 5.152320882061657, time: 0.054465532302856445
Test Loss Energy: 8.47433020101548, Test Loss Force: 10.231452103945454, time: 9.750779151916504


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.444795181937474, Training Loss Force: 4.700751231268818, time: 0.6049652099609375
Validation Loss Energy: 5.909666743897584, Validation Loss Force: 4.6252296132786945, time: 0.05675196647644043
Test Loss Energy: 10.81272017256949, Test Loss Force: 9.834906385712697, time: 9.591127872467041


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.425770899152777, Training Loss Force: 4.500989062393777, time: 0.6072380542755127
Validation Loss Energy: 5.350486179156676, Validation Loss Force: 4.618833219392773, time: 0.053412675857543945
Test Loss Energy: 8.826893999439907, Test Loss Force: 9.827365633298077, time: 9.993579149246216


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.330617532206849, Training Loss Force: 4.473720899819395, time: 0.5907790660858154
Validation Loss Energy: 5.737115078658639, Validation Loss Force: 4.600093829409782, time: 0.05697226524353027
Test Loss Energy: 10.89971157988587, Test Loss Force: 9.812500712101986, time: 9.794819593429565


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.481969236084627, Training Loss Force: 4.473418242968047, time: 0.6724715232849121
Validation Loss Energy: 5.4723926378309296, Validation Loss Force: 4.633838002460263, time: 0.05286526679992676
Test Loss Energy: 8.955905112423576, Test Loss Force: 9.79548514737189, time: 9.72775673866272


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.493315364063765, Training Loss Force: 4.46135788824021, time: 0.5741448402404785
Validation Loss Energy: 5.824469965959278, Validation Loss Force: 4.58266462468143, time: 0.056276559829711914
Test Loss Energy: 11.09409597120433, Test Loss Force: 9.716536017998411, time: 9.932010650634766


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.364398359072852, Training Loss Force: 4.461303321928949, time: 0.6105062961578369
Validation Loss Energy: 5.569833546765513, Validation Loss Force: 4.548305884788189, time: 0.05413317680358887
Test Loss Energy: 8.88231147212465, Test Loss Force: 9.605766194610556, time: 9.643134117126465


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.540912124871387, Training Loss Force: 4.468968094937362, time: 0.5972335338592529
Validation Loss Energy: 5.793202764488098, Validation Loss Force: 4.561571176487691, time: 0.05715775489807129
Test Loss Energy: 10.67314722546382, Test Loss Force: 9.693338649485485, time: 9.739957809448242


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.5624414850298045, Training Loss Force: 4.439720211912807, time: 0.5700681209564209
Validation Loss Energy: 5.553367608762445, Validation Loss Force: 4.525679136855591, time: 0.052491188049316406
Test Loss Energy: 8.835130687365922, Test Loss Force: 9.654878343924254, time: 9.813922882080078


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.455868172190235, Training Loss Force: 4.422185276451664, time: 0.6300601959228516
Validation Loss Energy: 6.028578302559109, Validation Loss Force: 4.601570125847283, time: 0.06031346321105957
Test Loss Energy: 11.165662324344481, Test Loss Force: 9.751760075840483, time: 8.94255805015564


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.364487952477817, Training Loss Force: 4.443670010002084, time: 0.6259438991546631
Validation Loss Energy: 5.477167109657913, Validation Loss Force: 4.5201400191814916, time: 0.0511319637298584
Test Loss Energy: 8.81874436465769, Test Loss Force: 9.668407450763592, time: 10.80099892616272


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.407222284053187, Training Loss Force: 4.421721815365431, time: 0.6248500347137451
Validation Loss Energy: 6.12816885942848, Validation Loss Force: 4.540063118344234, time: 0.05602860450744629
Test Loss Energy: 11.596921117864268, Test Loss Force: 9.722796280595484, time: 9.83641791343689


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.471163458084858, Training Loss Force: 4.463115582810876, time: 0.569180965423584
Validation Loss Energy: 5.806524614150666, Validation Loss Force: 4.529899607847506, time: 0.049040794372558594
Test Loss Energy: 8.818501643630558, Test Loss Force: 9.65718186673114, time: 8.522205352783203


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.506788430817434, Training Loss Force: 4.430475656981321, time: 0.5838029384613037
Validation Loss Energy: 6.124379475903081, Validation Loss Force: 4.533066408440892, time: 0.04845595359802246
Test Loss Energy: 10.633749326580089, Test Loss Force: 9.742165329959263, time: 8.410260438919067


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.35648946955008, Training Loss Force: 4.40644510378873, time: 0.5717291831970215
Validation Loss Energy: 5.1428151362220005, Validation Loss Force: 4.5302451903619865, time: 0.04947495460510254
Test Loss Energy: 8.639117022409284, Test Loss Force: 9.698719156779262, time: 8.650242567062378


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.342063134534304, Training Loss Force: 4.410432601001464, time: 0.5579688549041748
Validation Loss Energy: 6.1130816887769965, Validation Loss Force: 4.616120218518788, time: 0.048909664154052734
Test Loss Energy: 11.269468936128675, Test Loss Force: 9.860848441735136, time: 8.566829919815063


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.302013515573507, Training Loss Force: 4.410029953333087, time: 0.563119649887085
Validation Loss Energy: 5.567573900272638, Validation Loss Force: 4.523018685900046, time: 0.05330228805541992
Test Loss Energy: 8.842841223255599, Test Loss Force: 9.681031877344973, time: 8.465291976928711


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.558747038968872, Training Loss Force: 4.391587777177878, time: 0.5904123783111572
Validation Loss Energy: 5.927470032791095, Validation Loss Force: 4.538069784149888, time: 0.048597097396850586
Test Loss Energy: 11.009532594887435, Test Loss Force: 9.79526559326239, time: 8.662940263748169


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.47030687462149, Training Loss Force: 4.4112234042879725, time: 0.6151115894317627
Validation Loss Energy: 5.39243437421972, Validation Loss Force: 4.549469999083099, time: 0.049005985260009766
Test Loss Energy: 8.787437052429258, Test Loss Force: 9.740899589932473, time: 8.546862125396729


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.427660661267996, Training Loss Force: 4.4403758859540075, time: 0.5887935161590576
Validation Loss Energy: 6.266007740832158, Validation Loss Force: 4.517808673223628, time: 0.048999786376953125
Test Loss Energy: 11.273871499186448, Test Loss Force: 9.74450560833072, time: 8.500857591629028

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–‚â–†â–‚â–‡â–‚â–†â–‚â–‡â–‚â–ˆâ–‚â–†â–â–‡â–‚â–‡â–‚â–‡
wandb:   test_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–â–‡â–„â–ˆâ–„â–‡â–„â–†â–ƒâ–‡â–„â–ˆâ–„â–†â–ƒâ–‡â–„â–†â–ƒâ–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–†â–ƒâ–…â–„â–†â–„â–…â–„â–‡â–„â–‡â–†â–‡â–‚â–‡â–„â–†â–ƒâ–ˆ
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–
wandb:         valid_loss â–â–‡â–‡â–†â–†â–…â–†â–„â–„â–†â–„â–…â–‡â–ˆâ–â–†â–‡â–ƒâ–ƒâ–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1145
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 11.27387
wandb:   test_error_force 9.74451
wandb:          test_loss 6.82054
wandb: train_error_energy 4.42766
wandb:  train_error_force 4.44038
wandb:         train_loss 1.8492
wandb: valid_error_energy 6.26601
wandb:  valid_error_force 4.51781
wandb:         valid_loss 2.32263
wandb: 
wandb: ğŸš€ View run al_73_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1q8n0n8l
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_015524-1q8n0n8l/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.443688154220581, Uncertainty Bias: -0.17401716113090515
0.00025177002 0.3337078
1.8983252 8.545511
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 24.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 649 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2464 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 819 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1722 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3116 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_031439-g9piwgjg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g9piwgjg
Training model 25. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.335567553256669, Training Loss Force: 4.800759985535256, time: 0.6315171718597412
Validation Loss Energy: 3.403405265141531, Validation Loss Force: 4.600800581278957, time: 0.05875849723815918
Test Loss Energy: 9.568477879536644, Test Loss Force: 9.681405210730393, time: 9.592955589294434


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.928778777539251, Training Loss Force: 4.83945450192648, time: 0.5919437408447266
Validation Loss Energy: 10.844160197940507, Validation Loss Force: 4.722796552949873, time: 0.05254793167114258
Test Loss Energy: 11.629198878189388, Test Loss Force: 9.825947554932878, time: 9.268208026885986


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.6456722741107916, Training Loss Force: 4.6158034098061655, time: 0.5889041423797607
Validation Loss Energy: 2.7052902867989794, Validation Loss Force: 5.051369816710668, time: 0.0529940128326416
Test Loss Energy: 9.024875045394417, Test Loss Force: 9.996233413554513, time: 9.181219577789307


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0016590635229634, Training Loss Force: 5.285490577032852, time: 0.5868096351623535
Validation Loss Energy: 5.324962060297265, Validation Loss Force: 5.451078747182722, time: 0.0506289005279541
Test Loss Energy: 8.828019949875337, Test Loss Force: 10.151263996811752, time: 8.967117547988892


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.261324105646206, Training Loss Force: 4.749521427549209, time: 0.6041297912597656
Validation Loss Energy: 7.637055598465996, Validation Loss Force: 4.872966406316741, time: 0.050310373306274414
Test Loss Energy: 13.184377896134649, Test Loss Force: 10.00622591414717, time: 8.993132591247559


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.13027351582528, Training Loss Force: 4.566768707321429, time: 0.5968978404998779
Validation Loss Energy: 8.658990299642076, Validation Loss Force: 4.642660154021922, time: 0.054561614990234375
Test Loss Energy: 10.097545128310253, Test Loss Force: 9.674470789897558, time: 9.242964744567871


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.171735549919716, Training Loss Force: 4.481346229462709, time: 0.617753267288208
Validation Loss Energy: 6.629225206331274, Validation Loss Force: 4.5657511216950475, time: 0.062094688415527344
Test Loss Energy: 11.719637954664465, Test Loss Force: 9.685071790473105, time: 9.060952186584473


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.2093419564178385, Training Loss Force: 4.476877890599852, time: 0.5925469398498535
Validation Loss Energy: 2.1125076119226924, Validation Loss Force: 4.530315999150392, time: 0.051513671875
Test Loss Energy: 8.053227246982054, Test Loss Force: 9.667851794482516, time: 9.061136245727539


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.035542382154693, Training Loss Force: 4.471817573442038, time: 0.5856759548187256
Validation Loss Energy: 4.258812392152596, Validation Loss Force: 4.633526265655964, time: 0.0511324405670166
Test Loss Energy: 8.373037530883654, Test Loss Force: 9.597184665623345, time: 9.783597230911255


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.133066516775193, Training Loss Force: 4.487641420221806, time: 0.5792036056518555
Validation Loss Energy: 8.510421882772722, Validation Loss Force: 4.55384767449204, time: 0.05005383491516113
Test Loss Energy: 12.61777053661794, Test Loss Force: 9.629971370672793, time: 9.014791488647461


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.223607131546622, Training Loss Force: 4.611205304313265, time: 0.5727777481079102
Validation Loss Energy: 8.543481125530327, Validation Loss Force: 4.745948800066861, time: 0.05142068862915039
Test Loss Energy: 10.370610951724895, Test Loss Force: 9.653264195466704, time: 9.011724948883057


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 6.131183824405358, Training Loss Force: 4.507526108956877, time: 0.5835938453674316
Validation Loss Energy: 6.3196665516178365, Validation Loss Force: 4.660031464772332, time: 0.04976177215576172
Test Loss Energy: 11.10451203281321, Test Loss Force: 9.686419011086002, time: 8.954283475875854


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.181540024974398, Training Loss Force: 4.445018587128633, time: 0.675788402557373
Validation Loss Energy: 2.2668046379093316, Validation Loss Force: 4.587509459958527, time: 0.07480645179748535
Test Loss Energy: 7.777038550583551, Test Loss Force: 9.622668316988548, time: 9.108915567398071


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 5.3917784187494595, Training Loss Force: 4.797331672400488, time: 0.5681486129760742
Validation Loss Energy: 2.5653810276764646, Validation Loss Force: 6.535986509518639, time: 0.049965858459472656
Test Loss Energy: 8.054219204218757, Test Loss Force: 10.705808997966908, time: 8.98145079612732


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.384612233213905, Training Loss Force: 4.880799708942351, time: 0.5582940578460693
Validation Loss Energy: 2.271693339008176, Validation Loss Force: 4.516872572134147, time: 0.056420326232910156
Test Loss Energy: 8.560499544156077, Test Loss Force: 9.599673551750662, time: 9.057519435882568


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.28105231120406, Training Loss Force: 4.433171128845318, time: 0.5813677310943604
Validation Loss Energy: 1.986506490323973, Validation Loss Force: 4.509069354584254, time: 0.04924464225769043
Test Loss Energy: 7.779559295885842, Test Loss Force: 9.53073451732979, time: 9.185898303985596


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.389768022860663, Training Loss Force: 4.405479944375707, time: 0.5892062187194824
Validation Loss Energy: 2.3636632670273143, Validation Loss Force: 4.506317163940586, time: 0.05212116241455078
Test Loss Energy: 8.598086399098518, Test Loss Force: 9.615604193126922, time: 8.983108758926392


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.42486578000085, Training Loss Force: 4.416702722925883, time: 0.5702741146087646
Validation Loss Energy: 2.257474800694957, Validation Loss Force: 4.546055145061151, time: 0.054091691970825195
Test Loss Energy: 8.123569579666391, Test Loss Force: 9.626601824575909, time: 8.99834418296814


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.402982691348364, Training Loss Force: 4.379967391941377, time: 0.6168978214263916
Validation Loss Energy: 2.163861797048018, Validation Loss Force: 4.458889526534551, time: 0.04910850524902344
Test Loss Energy: 8.438057732896272, Test Loss Force: 9.535603128075797, time: 9.215914249420166


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.349744743804251, Training Loss Force: 4.3704373504237966, time: 0.6404280662536621
Validation Loss Energy: 2.0190629461500746, Validation Loss Force: 4.47849732618666, time: 0.04955458641052246
Test Loss Energy: 7.85056844455316, Test Loss Force: 9.589848689548102, time: 8.99209713935852

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–ƒâ–‚â–ˆâ–„â–†â–â–‚â–‡â–„â–…â–â–â–‚â–â–‚â–â–‚â–
wandb:   test_error_force â–‚â–ƒâ–„â–…â–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ˆâ–â–â–‚â–‚â–â–
wandb:          test_loss â–‚â–ˆâ–„â–…â–„â–‚â–ƒâ–â–â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–ˆâ–ˆâ–ˆâ–ˆâ–†â–„â–„â–„â–„â–„â–„
wandb:  train_error_force â–„â–…â–ƒâ–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–…â–â–â–â–â–
wandb:         train_loss â–†â–ƒâ–‚â–â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–‚â–„â–…â–†â–…â–â–ƒâ–†â–†â–„â–â–â–â–â–â–â–â–
wandb:  valid_error_force â–â–‚â–ƒâ–„â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–ˆâ–â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–â–ƒâ–‚â–ƒâ–‚â–â–â–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1149
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.85057
wandb:   test_error_force 9.58985
wandb:          test_loss 5.53455
wandb: train_error_energy 4.34974
wandb:  train_error_force 4.37044
wandb:         train_loss 1.81211
wandb: valid_error_energy 2.01906
wandb:  valid_error_force 4.4785
wandb:         valid_loss 1.32519
wandb: 
wandb: ğŸš€ View run al_73_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g9piwgjg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_031439-g9piwgjg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.241054058074951, Uncertainty Bias: -0.10564270615577698
0.0002593994 0.0014638901
2.2077076 8.289687
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3340 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1186 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 518 steps.
Found uncertainty sample 27 after 2258 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3401 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3859 steps.
Found uncertainty sample 47 after 3381 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3933 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1823 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_035628-1ln3a45y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1ln3a45y
Training model 26. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.794420894105151, Training Loss Force: 4.828363188610846, time: 0.6207525730133057
Validation Loss Energy: 2.0329011655620493, Validation Loss Force: 4.675962551486882, time: 0.06398391723632812
Test Loss Energy: 8.052752523357778, Test Loss Force: 9.655773539176078, time: 10.345093488693237


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.406276887613461, Training Loss Force: 4.43689674173275, time: 0.6164748668670654
Validation Loss Energy: 3.0193332754422566, Validation Loss Force: 4.48070041471647, time: 0.056153297424316406
Test Loss Energy: 7.935626652334276, Test Loss Force: 9.513306438771044, time: 10.27489972114563


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.346107543941277, Training Loss Force: 4.382105556032584, time: 0.6001970767974854
Validation Loss Energy: 5.531592347643874, Validation Loss Force: 4.501831271326725, time: 0.05294680595397949
Test Loss Energy: 10.122352896045268, Test Loss Force: 9.577196404841532, time: 10.326282262802124


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.465934001978738, Training Loss Force: 4.3763491192901425, time: 0.6179025173187256
Validation Loss Energy: 4.951443474769238, Validation Loss Force: 4.5092844529792195, time: 0.054859161376953125
Test Loss Energy: 8.436924922852182, Test Loss Force: 9.487610274770905, time: 10.33979058265686


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.355491393468751, Training Loss Force: 4.413280891435855, time: 0.5746650695800781
Validation Loss Energy: 2.3998234003111114, Validation Loss Force: 4.4729341602448, time: 0.05326104164123535
Test Loss Energy: 7.9995968445824905, Test Loss Force: 9.517348706829408, time: 10.330382823944092


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.271889949689742, Training Loss Force: 4.405908400267377, time: 0.64247727394104
Validation Loss Energy: 4.164590833729837, Validation Loss Force: 4.572070472056478, time: 0.05489993095397949
Test Loss Energy: 9.662239972417755, Test Loss Force: 9.585538808150543, time: 10.546225786209106


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.345893474638849, Training Loss Force: 4.396393874041668, time: 0.6028378009796143
Validation Loss Energy: 5.659315369748054, Validation Loss Force: 4.485938483705275, time: 0.05989575386047363
Test Loss Energy: 8.650223544899664, Test Loss Force: 9.510017482583688, time: 10.992435455322266


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.505065913792597, Training Loss Force: 4.376601565920775, time: 0.6010527610778809
Validation Loss Energy: 5.871860194948797, Validation Loss Force: 4.475244575302947, time: 0.05559563636779785
Test Loss Energy: 10.645143728799367, Test Loss Force: 9.51502304767832, time: 9.61362075805664


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.502801946314675, Training Loss Force: 4.425052723119364, time: 0.6949934959411621
Validation Loss Energy: 2.453262659318905, Validation Loss Force: 4.557985757899962, time: 0.052352190017700195
Test Loss Energy: 7.757454862152781, Test Loss Force: 9.520317924112899, time: 10.395466804504395


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.37704343177757, Training Loss Force: 4.419747095108067, time: 0.6485319137573242
Validation Loss Energy: 3.466648646644525, Validation Loss Force: 4.516143553350379, time: 0.05625653266906738
Test Loss Energy: 8.018431294472073, Test Loss Force: 9.476446282656346, time: 9.782830476760864


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.423319508614058, Training Loss Force: 4.412756222747198, time: 0.6005218029022217
Validation Loss Energy: 6.424310362084892, Validation Loss Force: 4.511870977778317, time: 0.055083274841308594
Test Loss Energy: 10.515018132258378, Test Loss Force: 9.516830272435723, time: 8.949487209320068


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.53475913327015, Training Loss Force: 4.432460696917151, time: 0.6060645580291748
Validation Loss Energy: 5.044351285231024, Validation Loss Force: 4.531362989474544, time: 0.05235004425048828
Test Loss Energy: 8.526985223954544, Test Loss Force: 9.44776337696119, time: 8.878498315811157


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.500153703044603, Training Loss Force: 4.4051788037474475, time: 0.6031198501586914
Validation Loss Energy: 2.413012761831852, Validation Loss Force: 4.520759484745462, time: 0.05436897277832031
Test Loss Energy: 8.229849504727373, Test Loss Force: 9.542587585347079, time: 8.77932596206665


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.313441510823038, Training Loss Force: 4.428341907489819, time: 0.6058783531188965
Validation Loss Energy: 3.2798960339548895, Validation Loss Force: 4.683014038000123, time: 0.05104398727416992
Test Loss Energy: 8.855869965710474, Test Loss Force: 9.463973252441283, time: 8.87912917137146


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.043142766573857, Training Loss Force: 5.020172340772589, time: 0.6297943592071533
Validation Loss Energy: 4.923562625669328, Validation Loss Force: 5.365545738834064, time: 0.051152706146240234
Test Loss Energy: 9.332083253567335, Test Loss Force: 10.02054761589176, time: 8.98423457145691


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.382667579053092, Training Loss Force: 5.353970361518113, time: 0.6038093566894531
Validation Loss Energy: 1.7426546058749288, Validation Loss Force: 4.957040486421279, time: 0.05053544044494629
Test Loss Energy: 7.931754650395089, Test Loss Force: 9.545470985242243, time: 8.790048360824585


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9583735104647926, Training Loss Force: 4.830603914244401, time: 0.5951857566833496
Validation Loss Energy: 2.4117622519083213, Validation Loss Force: 4.744776669682697, time: 0.050629377365112305
Test Loss Energy: 8.024459827270851, Test Loss Force: 9.68481294866613, time: 8.788015842437744


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0088452788281046, Training Loss Force: 4.431751200801204, time: 0.6020970344543457
Validation Loss Energy: 3.571518243625552, Validation Loss Force: 4.46265486179219, time: 0.052118539810180664
Test Loss Energy: 8.865186279563106, Test Loss Force: 9.425878655887388, time: 8.905847072601318


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.023974792725824, Training Loss Force: 4.369921593850385, time: 0.5958676338195801
Validation Loss Energy: 2.460693796725953, Validation Loss Force: 4.4601823435958075, time: 0.05127406120300293
Test Loss Energy: 8.252536308044174, Test Loss Force: 9.462522867231202, time: 8.824958324432373


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9614214418427625, Training Loss Force: 4.334932916925231, time: 0.633704423904419
Validation Loss Energy: 2.2434695794235373, Validation Loss Force: 4.452268236811243, time: 0.05399346351623535
Test Loss Energy: 7.565134089203898, Test Loss Force: 9.412197919520322, time: 9.37079405784607

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‡â–ƒâ–‚â–†â–ƒâ–ˆâ–â–‚â–ˆâ–ƒâ–ƒâ–„â–…â–‚â–‚â–„â–ƒâ–
wandb:   test_error_force â–„â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ˆâ–ƒâ–„â–â–‚â–
wandb:          test_loss â–â–â–ƒâ–‚â–â–ƒâ–‚â–„â–â–â–ƒâ–‚â–â–‚â–ˆâ–…â–†â–…â–„â–ƒ
wandb: train_error_energy â–ˆâ–…â–„â–…â–„â–„â–„â–…â–…â–…â–…â–…â–…â–„â–„â–‚â–â–â–â–
wandb:  train_error_force â–„â–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–‚â–†â–ˆâ–„â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–†â–…â–‚â–â–â–
wandb: valid_error_energy â–â–ƒâ–‡â–†â–‚â–…â–‡â–‡â–‚â–„â–ˆâ–†â–‚â–ƒâ–†â–â–‚â–„â–‚â–‚
wandb:  valid_error_force â–ƒâ–â–â–â–â–‚â–â–â–‚â–â–â–‚â–‚â–ƒâ–ˆâ–…â–ƒâ–â–â–
wandb:         valid_loss â–‚â–‚â–…â–…â–‚â–ƒâ–…â–…â–‚â–ƒâ–†â–…â–‚â–ƒâ–ˆâ–â–‚â–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1157
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.56513
wandb:   test_error_force 9.4122
wandb:          test_loss 6.44676
wandb: train_error_energy 2.96142
wandb:  train_error_force 4.33493
wandb:         train_loss 1.42512
wandb: valid_error_energy 2.24347
wandb:  valid_error_force 4.45227
wandb:         valid_loss 1.2329
wandb: 
wandb: ğŸš€ View run al_73_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1ln3a45y
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_035628-1ln3a45y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.059617042541504, Uncertainty Bias: 0.015889763832092285
0.0002861023 0.055813313
2.7038221 8.513924
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3830 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3182 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 713 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_043928-2himph2b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2himph2b
Training model 27. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.984143470950315, Training Loss Force: 4.687727305902402, time: 0.59737229347229
Validation Loss Energy: 1.84636554395512, Validation Loss Force: 4.572334557663549, time: 0.05152535438537598
Test Loss Energy: 7.98614849319728, Test Loss Force: 9.409662494375697, time: 8.912248849868774


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.624433733726502, Training Loss Force: 4.66928081611758, time: 0.6187024116516113
Validation Loss Energy: 4.47061083037619, Validation Loss Force: 5.657794539481367, time: 0.05387473106384277
Test Loss Energy: 9.594499037898817, Test Loss Force: 10.245770490134806, time: 8.921007633209229


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1282447627601644, Training Loss Force: 4.927607139891282, time: 0.5782878398895264
Validation Loss Energy: 2.087036042981721, Validation Loss Force: 4.54529896064158, time: 0.05045628547668457
Test Loss Energy: 8.296462667820274, Test Loss Force: 9.461059154514965, time: 9.131070852279663


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.019711728737143, Training Loss Force: 4.414576958263025, time: 0.6129443645477295
Validation Loss Energy: 2.209452636669295, Validation Loss Force: 4.519583346316672, time: 0.05123639106750488
Test Loss Energy: 7.6220210640026735, Test Loss Force: 9.41515569790507, time: 8.93222427368164


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.074458218119829, Training Loss Force: 4.452485537825326, time: 0.5711088180541992
Validation Loss Energy: 3.3870190426927054, Validation Loss Force: 4.502496606734757, time: 0.05166339874267578
Test Loss Energy: 7.8175202839573394, Test Loss Force: 9.407369846216945, time: 8.885892391204834


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9539455659916385, Training Loss Force: 4.386262229305147, time: 0.5832016468048096
Validation Loss Energy: 2.0960663901948227, Validation Loss Force: 4.503417120984023, time: 0.04961252212524414
Test Loss Energy: 7.567922305616923, Test Loss Force: 9.425171952982106, time: 9.656115770339966


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0418827722264306, Training Loss Force: 4.391604687996797, time: 0.5950396060943604
Validation Loss Energy: 2.910813463152036, Validation Loss Force: 4.511174023351563, time: 0.051384925842285156
Test Loss Energy: 8.702308297000515, Test Loss Force: 9.467428350122486, time: 8.95193099975586


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.076895055090098, Training Loss Force: 4.438503191295089, time: 0.5727083683013916
Validation Loss Energy: 3.5131542111172736, Validation Loss Force: 4.557198399799961, time: 0.05615234375
Test Loss Energy: 8.747332380691825, Test Loss Force: 9.450423869885789, time: 8.97171926498413


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1222355905190113, Training Loss Force: 4.40721986135604, time: 0.6115367412567139
Validation Loss Energy: 2.19548705050585, Validation Loss Force: 4.508579927801504, time: 0.04971122741699219
Test Loss Energy: 8.028751132698927, Test Loss Force: 9.46201928988252, time: 8.931072235107422


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.039874708768986, Training Loss Force: 4.384759627818002, time: 0.6047892570495605
Validation Loss Energy: 2.332605819891598, Validation Loss Force: 4.487429476306407, time: 0.050054073333740234
Test Loss Energy: 7.445367184907019, Test Loss Force: 9.437229414954063, time: 9.073920965194702


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1175753238915482, Training Loss Force: 4.4085417517860535, time: 0.6035828590393066
Validation Loss Energy: 3.3391674432328236, Validation Loss Force: 4.4891248791835014, time: 0.05167675018310547
Test Loss Energy: 7.634914129833448, Test Loss Force: 9.427412685421457, time: 8.967149496078491


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.083577642018429, Training Loss Force: 4.401547888436928, time: 0.5933279991149902
Validation Loss Energy: 1.9164109111933432, Validation Loss Force: 4.483188965091359, time: 0.05235648155212402
Test Loss Energy: 7.327164276048541, Test Loss Force: 9.416389993784193, time: 8.894289016723633


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.042634370865212, Training Loss Force: 4.392906790963249, time: 0.6008148193359375
Validation Loss Energy: 2.7252187300212247, Validation Loss Force: 4.4798364584302695, time: 0.0507051944732666
Test Loss Energy: 8.320966437378164, Test Loss Force: 9.396582041383457, time: 9.095617771148682


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.156331502584952, Training Loss Force: 4.42097407431915, time: 0.6149194240570068
Validation Loss Energy: 3.2658625337019367, Validation Loss Force: 4.557325766551432, time: 0.055297136306762695
Test Loss Energy: 8.852634174987676, Test Loss Force: 9.5186348624692, time: 8.9978768825531


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.06738695016111, Training Loss Force: 4.380455944764444, time: 0.6056756973266602
Validation Loss Energy: 2.0983010977433536, Validation Loss Force: 4.520603616343313, time: 0.05124402046203613
Test Loss Energy: 7.999617145946402, Test Loss Force: 9.487026937567311, time: 8.968839168548584


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.079250678002952, Training Loss Force: 4.374129125959498, time: 0.5978758335113525
Validation Loss Energy: 2.5999626593847798, Validation Loss Force: 4.5120522304631026, time: 0.04978013038635254
Test Loss Energy: 7.647234056940677, Test Loss Force: 9.47473770849124, time: 9.193351030349731


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0275993559475993, Training Loss Force: 4.371010102943127, time: 0.5967681407928467
Validation Loss Energy: 3.418872309355967, Validation Loss Force: 4.518622751621139, time: 0.05332446098327637
Test Loss Energy: 7.80233533473723, Test Loss Force: 9.41245037270468, time: 8.981825351715088


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.2260578902535486, Training Loss Force: 4.37946961071926, time: 0.6364281177520752
Validation Loss Energy: 1.9166375883838978, Validation Loss Force: 4.534389508505994, time: 0.05267333984375
Test Loss Energy: 7.620238227928688, Test Loss Force: 9.490238922510214, time: 9.011785507202148


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0523637667986563, Training Loss Force: 4.39162685862203, time: 0.5682926177978516
Validation Loss Energy: 2.8357394472567528, Validation Loss Force: 4.502469886437246, time: 0.0500483512878418
Test Loss Energy: 8.246248959086179, Test Loss Force: 9.490456569359385, time: 9.692937135696411


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.133442080286222, Training Loss Force: 4.36690204977948, time: 0.5872759819030762
Validation Loss Energy: 3.8558498201202465, Validation Loss Force: 4.498527306539448, time: 0.05098414421081543
Test Loss Energy: 9.607611004987147, Test Loss Force: 9.48186388593035, time: 8.954627752304077

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–„â–‚â–ƒâ–‚â–…â–…â–ƒâ–â–‚â–â–„â–†â–ƒâ–‚â–‚â–‚â–„â–ˆ
wandb:   test_error_force â–â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:          test_loss â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–ƒ
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒ
wandb:  train_error_force â–…â–…â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–…â–‚â–„â–…â–‚â–‚â–…â–â–ƒâ–…â–‚â–ƒâ–…â–â–„â–†
wandb:  valid_error_force â–‚â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         valid_loss â–â–ˆâ–â–â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒâ–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1159
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.60761
wandb:   test_error_force 9.48186
wandb:          test_loss 7.01697
wandb: train_error_energy 3.13344
wandb:  train_error_force 4.3669
wandb:         train_loss 1.47028
wandb: valid_error_energy 3.85585
wandb:  valid_error_force 4.49853
wandb:         valid_loss 1.71213
wandb: 
wandb: ğŸš€ View run al_73_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2himph2b
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_043928-2himph2b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.157670259475708, Uncertainty Bias: -0.02488306164741516
0.0006866455 0.11022568
2.5419164 8.713923
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1973 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_052215-v5dev2zq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v5dev2zq
Training model 28. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.788040493280183, Training Loss Force: 5.1689205659863235, time: 0.6126151084899902
Validation Loss Energy: 1.743328848048798, Validation Loss Force: 4.679340442430607, time: 0.051702260971069336
Test Loss Energy: 8.171022328556212, Test Loss Force: 9.634519668937866, time: 8.803137063980103


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.240297907190324, Training Loss Force: 4.613866168844987, time: 0.5810070037841797
Validation Loss Energy: 2.138431867237335, Validation Loss Force: 4.523221760161132, time: 0.05441093444824219
Test Loss Energy: 8.194651635574798, Test Loss Force: 9.522440145271103, time: 9.022028923034668


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.26433458712781, Training Loss Force: 4.4194813003648505, time: 0.6035451889038086
Validation Loss Energy: 2.222412871638876, Validation Loss Force: 4.50842539541423, time: 0.04934263229370117
Test Loss Energy: 8.036034367663376, Test Loss Force: 9.490486656507647, time: 8.951033115386963


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.185927969387658, Training Loss Force: 4.371358303324592, time: 0.5933094024658203
Validation Loss Energy: 1.882461659859463, Validation Loss Force: 4.49561880215534, time: 0.04934549331665039
Test Loss Energy: 7.589914075756987, Test Loss Force: 9.430390282525998, time: 8.830012321472168


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2721447254754814, Training Loss Force: 4.394431924160728, time: 0.604604959487915
Validation Loss Energy: 1.8162660194851854, Validation Loss Force: 4.465730368035745, time: 0.049928903579711914
Test Loss Energy: 7.509548497816558, Test Loss Force: 9.484811540446703, time: 9.430387258529663


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.254924197845375, Training Loss Force: 4.370592134901965, time: 0.6188266277313232
Validation Loss Energy: 1.9613110311239519, Validation Loss Force: 4.466661125065722, time: 0.04915046691894531
Test Loss Energy: 7.910405214290025, Test Loss Force: 9.444625639937481, time: 8.990703582763672


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1710665371054656, Training Loss Force: 4.3683275595974544, time: 0.6331503391265869
Validation Loss Energy: 1.8837551449281575, Validation Loss Force: 4.462611218639588, time: 0.04872584342956543
Test Loss Energy: 8.068465755709504, Test Loss Force: 9.440159740914472, time: 8.809141874313354


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.170463558085421, Training Loss Force: 4.354159789849507, time: 0.5712916851043701
Validation Loss Energy: 1.685500446171049, Validation Loss Force: 4.505928828950088, time: 0.049509286880493164
Test Loss Energy: 7.551304299742678, Test Loss Force: 9.488826607895053, time: 8.810092210769653


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2631473904677852, Training Loss Force: 4.367193686179795, time: 0.6195685863494873
Validation Loss Energy: 1.6907057827954028, Validation Loss Force: 4.471655594008883, time: 0.056803226470947266
Test Loss Energy: 7.531324943395088, Test Loss Force: 9.464640527752243, time: 8.880054473876953


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.150420073149836, Training Loss Force: 4.36179007170812, time: 0.5825984477996826
Validation Loss Energy: 2.1812270957314888, Validation Loss Force: 4.49199953785743, time: 0.052880048751831055
Test Loss Energy: 8.265593221060529, Test Loss Force: 9.49709479126424, time: 9.005045175552368


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2124450030682286, Training Loss Force: 4.39392131371869, time: 0.6025357246398926
Validation Loss Energy: 2.2051923079002584, Validation Loss Force: 4.528918972928841, time: 0.04957294464111328
Test Loss Energy: 8.309873032548671, Test Loss Force: 9.544416321576108, time: 9.169348001480103


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.192586517075357, Training Loss Force: 4.368576160671756, time: 0.6031439304351807
Validation Loss Energy: 2.015137957114806, Validation Loss Force: 4.479322538041469, time: 0.05058717727661133
Test Loss Energy: 7.448081901848977, Test Loss Force: 9.482081542105977, time: 10.038005590438843


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2537868429655283, Training Loss Force: 4.385478602417863, time: 0.6637589931488037
Validation Loss Energy: 1.8225418380285872, Validation Loss Force: 4.484526761320093, time: 0.0559687614440918
Test Loss Energy: 7.545530108735673, Test Loss Force: 9.484234755078713, time: 9.78188443183899


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1537752097140817, Training Loss Force: 4.370306185591999, time: 0.6096911430358887
Validation Loss Energy: 2.2521078062706597, Validation Loss Force: 4.509881206290307, time: 0.05972790718078613
Test Loss Energy: 8.54394777011177, Test Loss Force: 9.48759053532599, time: 9.921058893203735


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2293976205982315, Training Loss Force: 4.413794980331036, time: 0.6013879776000977
Validation Loss Energy: 1.735931779021077, Validation Loss Force: 4.52263079624784, time: 0.051039934158325195
Test Loss Energy: 7.66094729833982, Test Loss Force: 9.556304904739271, time: 9.820307731628418


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.174100022070333, Training Loss Force: 4.4022263191979745, time: 0.6617121696472168
Validation Loss Energy: 1.6102074351707458, Validation Loss Force: 4.481436558912907, time: 0.05591297149658203
Test Loss Energy: 7.728250954956821, Test Loss Force: 9.492021586044755, time: 9.824153900146484


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.251887869335334, Training Loss Force: 4.392958299752977, time: 0.6322760581970215
Validation Loss Energy: 1.6873836704727332, Validation Loss Force: 4.511980530998113, time: 0.055541276931762695
Test Loss Energy: 7.709565749353748, Test Loss Force: 9.540483466840696, time: 9.910634994506836


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.196450810714106, Training Loss Force: 4.39122034299667, time: 0.6306338310241699
Validation Loss Energy: 2.2020361954258783, Validation Loss Force: 4.49117655269408, time: 0.0552217960357666
Test Loss Energy: 8.395088743193417, Test Loss Force: 9.521416049065735, time: 10.34446907043457


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2031761049828176, Training Loss Force: 4.375285880136422, time: 0.6043186187744141
Validation Loss Energy: 1.9938648149203027, Validation Loss Force: 4.480826445453065, time: 0.05788826942443848
Test Loss Energy: 8.365830138662437, Test Loss Force: 9.483445923398603, time: 9.6061429977417


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.21396897778434, Training Loss Force: 4.36263756251369, time: 0.6169941425323486
Validation Loss Energy: 1.881123640961583, Validation Loss Force: 4.517459082664521, time: 0.05563664436340332
Test Loss Energy: 7.440201727044314, Test Loss Force: 9.480663822809348, time: 10.010610580444336

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–…â–‚â–â–„â–…â–‚â–‚â–†â–‡â–â–‚â–ˆâ–‚â–ƒâ–ƒâ–‡â–‡â–
wandb:   test_error_force â–ˆâ–„â–ƒâ–â–ƒâ–â–â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–„â–ƒâ–ƒ
wandb:          test_loss â–â–†â–†â–‡â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–†â–†â–ˆâ–†â–‡â–‡â–ˆâ–ˆâ–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‡â–ˆâ–„â–ƒâ–…â–„â–‚â–‚â–‡â–‡â–…â–ƒâ–ˆâ–‚â–â–‚â–‡â–…â–„
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒ
wandb:         valid_loss â–ˆâ–„â–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–…â–…â–…â–ƒâ–…â–‚â–â–‚â–…â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1160
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.4402
wandb:   test_error_force 9.48066
wandb:          test_loss 7.66286
wandb: train_error_energy 2.21397
wandb:  train_error_force 4.36264
wandb:         train_loss 1.09756
wandb: valid_error_energy 1.88112
wandb:  valid_error_force 4.51746
wandb:         valid_loss 1.108
wandb: 
wandb: ğŸš€ View run al_73_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v5dev2zq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_052215-v5dev2zq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.029219627380371, Uncertainty Bias: 0.08888626098632812
4.386902e-05 0.00064373016
3.2248342 13.304432
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3742 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2872 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2529 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2709 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1215 steps.
Found uncertainty sample 49 after 1028 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3740 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 918 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2101 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_060405-v2avamh6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v2avamh6
Training model 29. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 10.119911757593586, Training Loss Force: 5.735007412884987, time: 0.6913406848907471
Validation Loss Energy: 6.329453305919655, Validation Loss Force: 5.018938500944578, time: 0.05803561210632324
Test Loss Energy: 8.813333453116133, Test Loss Force: 9.92741523601856, time: 10.343337059020996


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.532005570503096, Training Loss Force: 4.673051290819833, time: 0.6790075302124023
Validation Loss Energy: 2.628240304902733, Validation Loss Force: 4.593428896533871, time: 0.05852365493774414
Test Loss Energy: 8.497882051813878, Test Loss Force: 9.552538681136662, time: 10.382060766220093


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.524267576958704, Training Loss Force: 4.472292812923677, time: 0.6623854637145996
Validation Loss Energy: 4.000990022818897, Validation Loss Force: 4.605449467707637, time: 0.05909085273742676
Test Loss Energy: 9.071230965708839, Test Loss Force: 9.596237531335973, time: 10.50508165359497


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.416918823833512, Training Loss Force: 4.484627419810223, time: 0.615455150604248
Validation Loss Energy: 5.873160137422723, Validation Loss Force: 4.685953716064661, time: 0.0580592155456543
Test Loss Energy: 8.420975880377497, Test Loss Force: 9.539776209011261, time: 10.759445190429688


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.5163127758832, Training Loss Force: 4.475284824255595, time: 0.6301655769348145
Validation Loss Energy: 4.721432481761919, Validation Loss Force: 4.549393400896901, time: 0.06284928321838379
Test Loss Energy: 9.41207786004742, Test Loss Force: 9.48245702990282, time: 10.515079736709595


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.526691697715315, Training Loss Force: 4.480736180195774, time: 0.6553082466125488
Validation Loss Energy: 1.8951687200101242, Validation Loss Force: 4.607360859656281, time: 0.060643672943115234
Test Loss Energy: 7.494993737253638, Test Loss Force: 9.404901324407119, time: 10.693900108337402


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.3927171520769805, Training Loss Force: 4.4504772366535255, time: 0.6053545475006104
Validation Loss Energy: 3.4639835196369155, Validation Loss Force: 4.523934746766392, time: 0.052278995513916016
Test Loss Energy: 7.658143073064428, Test Loss Force: 9.41840737158307, time: 10.391148805618286


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.363107833731806, Training Loss Force: 4.443993436100699, time: 0.661334753036499
Validation Loss Energy: 6.24087551966958, Validation Loss Force: 4.53618377648388, time: 0.058130502700805664
Test Loss Energy: 10.562923335526271, Test Loss Force: 9.46476679398186, time: 10.656185388565063


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.522178476977355, Training Loss Force: 4.44317421224049, time: 0.6920342445373535
Validation Loss Energy: 5.289379530778005, Validation Loss Force: 4.531353637370414, time: 0.058264732360839844
Test Loss Energy: 8.278883612585748, Test Loss Force: 9.384856862399195, time: 10.434196949005127


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.409480380471246, Training Loss Force: 4.445602575747045, time: 0.6679654121398926
Validation Loss Energy: 2.37932715076675, Validation Loss Force: 4.582614301454451, time: 0.05823397636413574
Test Loss Energy: 8.105561132048795, Test Loss Force: 9.349988590214876, time: 10.375236511230469


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.367071705614422, Training Loss Force: 4.480392589667437, time: 0.6451046466827393
Validation Loss Energy: 3.689888716262472, Validation Loss Force: 4.527900038917075, time: 0.06079459190368652
Test Loss Energy: 9.160866908382959, Test Loss Force: 9.395101032753873, time: 10.556822061538696


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.519302265637491, Training Loss Force: 4.420169685038528, time: 0.6633203029632568
Validation Loss Energy: 5.919143097409979, Validation Loss Force: 4.515292511874644, time: 0.05864143371582031
Test Loss Energy: 8.451208206591357, Test Loss Force: 9.385731073124179, time: 10.486915826797485


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.385874023703477, Training Loss Force: 4.42296747471243, time: 0.5937108993530273
Validation Loss Energy: 5.315967562816659, Validation Loss Force: 4.542752070950458, time: 0.0587460994720459
Test Loss Energy: 9.306432290238012, Test Loss Force: 9.372941447021045, time: 10.438898086547852


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.549671099412298, Training Loss Force: 4.42150478516517, time: 0.6039078235626221
Validation Loss Energy: 2.176408535413611, Validation Loss Force: 4.515674166790764, time: 0.051459312438964844
Test Loss Energy: 7.535226713051407, Test Loss Force: 9.400493864959747, time: 10.84726619720459


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.462982263671809, Training Loss Force: 4.4171600166451475, time: 0.5872600078582764
Validation Loss Energy: 3.401057218997723, Validation Loss Force: 4.51165098066214, time: 0.054776668548583984
Test Loss Energy: 7.583608582178114, Test Loss Force: 9.425399215407799, time: 10.44463324546814


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.445593253733339, Training Loss Force: 4.417834054204127, time: 0.6023910045623779
Validation Loss Energy: 6.351621355411641, Validation Loss Force: 4.498958394005965, time: 0.0562891960144043
Test Loss Energy: 10.602007217287118, Test Loss Force: 9.413960293349025, time: 10.518171787261963


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.507734802103348, Training Loss Force: 4.509902269587895, time: 0.6847560405731201
Validation Loss Energy: 5.200068272361245, Validation Loss Force: 4.6371303884519515, time: 0.08166217803955078
Test Loss Energy: 8.20082981369771, Test Loss Force: 9.475908197419079, time: 10.518933534622192


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.560960184387436, Training Loss Force: 4.471385508371043, time: 0.6529462337493896
Validation Loss Energy: 2.42675345215791, Validation Loss Force: 4.5442858160276085, time: 0.05812788009643555
Test Loss Energy: 8.172905545280152, Test Loss Force: 9.431876192208408, time: 11.074156999588013


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.44994442549583, Training Loss Force: 4.426278703328332, time: 0.6277754306793213
Validation Loss Energy: 4.51405090871695, Validation Loss Force: 4.5431493127067935, time: 0.05855202674865723
Test Loss Energy: 9.741510580079215, Test Loss Force: 9.4773270731963, time: 9.73858094215393


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.606811402475406, Training Loss Force: 4.443789669759836, time: 0.5866978168487549
Validation Loss Energy: 5.339011147390433, Validation Loss Force: 4.567180657611904, time: 0.04889392852783203
Test Loss Energy: 8.114358006582066, Test Loss Force: 9.420019239722038, time: 10.551507472991943

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–…â–ƒâ–…â–â–â–ˆâ–ƒâ–‚â–…â–ƒâ–…â–â–â–ˆâ–ƒâ–ƒâ–†â–‚
wandb:   test_error_force â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–ƒâ–„â–„â–†â–…â–â–ƒâ–ˆâ–„â–‚â–…â–„â–†â–â–‚â–ˆâ–„â–‚â–†â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–„â–‡â–…â–â–ƒâ–ˆâ–†â–‚â–„â–‡â–†â–â–ƒâ–ˆâ–†â–‚â–…â–†
wandb:  valid_error_force â–ˆâ–‚â–‚â–„â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–ƒâ–‚â–‚â–‚
wandb:         valid_loss â–ˆâ–‚â–ƒâ–ˆâ–…â–â–ƒâ–‡â–†â–â–ƒâ–‡â–†â–â–ƒâ–‡â–†â–â–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1168
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.11436
wandb:   test_error_force 9.42002
wandb:          test_loss 5.33009
wandb: train_error_energy 4.60681
wandb:  train_error_force 4.44379
wandb:         train_loss 1.88654
wandb: valid_error_energy 5.33901
wandb:  valid_error_force 4.56718
wandb:         valid_loss 2.16666
wandb: 
wandb: ğŸš€ View run al_73_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v2avamh6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_060405-v2avamh6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3306852579116821, Uncertainty Bias: 0.06496819853782654
0.0011482239 0.042524815
3.2443233 19.340221
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2840 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2895 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_064745-oolms7fw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oolms7fw
Training model 30. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.163657317329772, Training Loss Force: 4.7659064791461585, time: 0.6394481658935547
Validation Loss Energy: 4.163142148266431, Validation Loss Force: 5.084853021522122, time: 0.05079984664916992
Test Loss Energy: 7.804077941141647, Test Loss Force: 9.616903382489495, time: 8.738757610321045


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1717284180545913, Training Loss Force: 4.635725249851786, time: 0.6148862838745117
Validation Loss Energy: 3.0079597808065572, Validation Loss Force: 4.506666754499693, time: 0.0510101318359375
Test Loss Energy: 7.43447713646392, Test Loss Force: 9.349701423959894, time: 8.7477445602417


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.970616106849388, Training Loss Force: 4.413365228879397, time: 0.6370844841003418
Validation Loss Energy: 2.4520520071724956, Validation Loss Force: 4.495787140029661, time: 0.05085253715515137
Test Loss Energy: 7.938732516193327, Test Loss Force: 9.334415114811915, time: 9.00577425956726


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9688656445124004, Training Loss Force: 4.404258963523704, time: 0.6045951843261719
Validation Loss Energy: 3.757553416327008, Validation Loss Force: 4.522527477764129, time: 0.05111861228942871
Test Loss Energy: 8.780508369698707, Test Loss Force: 9.458880951302374, time: 8.720137596130371


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1025252908427547, Training Loss Force: 4.38449284610884, time: 0.6472835540771484
Validation Loss Energy: 2.3158762416197516, Validation Loss Force: 4.453128630391107, time: 0.060485124588012695
Test Loss Energy: 7.918491876838807, Test Loss Force: 9.364340542320717, time: 9.515063524246216


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.990908872902881, Training Loss Force: 4.367390206746288, time: 0.6084380149841309
Validation Loss Energy: 2.4904419492836136, Validation Loss Force: 4.478485747391072, time: 0.053177833557128906
Test Loss Energy: 7.624325449506774, Test Loss Force: 9.36340744435019, time: 8.936049461364746


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0163981951946774, Training Loss Force: 4.392065143718236, time: 0.6643667221069336
Validation Loss Energy: 3.0742339120547744, Validation Loss Force: 4.523562443954401, time: 0.053055524826049805
Test Loss Energy: 7.532291052357952, Test Loss Force: 9.38993685261569, time: 8.730678796768188


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.047856293331895, Training Loss Force: 4.384486442866373, time: 0.619281530380249
Validation Loss Energy: 2.0432768797548464, Validation Loss Force: 4.47783243611692, time: 0.0495302677154541
Test Loss Energy: 7.418522978427916, Test Loss Force: 9.340925797425859, time: 8.761252880096436


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.026963900331716, Training Loss Force: 4.415464938744646, time: 0.6178324222564697
Validation Loss Energy: 2.828794173926119, Validation Loss Force: 4.49292628684278, time: 0.052236080169677734
Test Loss Energy: 8.133518252908932, Test Loss Force: 9.425751144575845, time: 8.808319330215454


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0086795227122587, Training Loss Force: 4.376161655941612, time: 0.6056728363037109
Validation Loss Energy: 3.969201775546246, Validation Loss Force: 4.488491162794191, time: 0.05229330062866211
Test Loss Energy: 9.072550673275435, Test Loss Force: 9.400501694519873, time: 9.139623165130615


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.1076136780208166, Training Loss Force: 4.386177530776504, time: 0.6442668437957764
Validation Loss Energy: 2.4115119717882987, Validation Loss Force: 4.50365404095529, time: 0.05380392074584961
Test Loss Energy: 8.497407675600105, Test Loss Force: 9.377948835437898, time: 8.802916288375854


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.1568098380369998, Training Loss Force: 4.3969189218696805, time: 0.5875515937805176
Validation Loss Energy: 2.4937851038405734, Validation Loss Force: 4.479086063408493, time: 0.05058789253234863
Test Loss Energy: 7.396258143634907, Test Loss Force: 9.32605119070482, time: 8.791438341140747


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0963627958494175, Training Loss Force: 4.383308240234418, time: 0.6223688125610352
Validation Loss Energy: 3.380362125906048, Validation Loss Force: 4.526058565080252, time: 0.0513463020324707
Test Loss Energy: 7.719327152015529, Test Loss Force: 9.409414158821829, time: 9.074542045593262


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0769966102748953, Training Loss Force: 4.378474773119936, time: 0.5932066440582275
Validation Loss Energy: 1.9377056522950011, Validation Loss Force: 4.50367808922305, time: 0.0610349178314209
Test Loss Energy: 7.57248647984236, Test Loss Force: 9.394856679596874, time: 8.790494203567505


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.120283462152832, Training Loss Force: 4.3900608927176545, time: 0.6085784435272217
Validation Loss Energy: 3.3187119421421674, Validation Loss Force: 4.504703703309193, time: 0.05229759216308594
Test Loss Energy: 8.885345820716227, Test Loss Force: 9.384133413841495, time: 8.875526905059814


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0832044124213445, Training Loss Force: 4.3952684740877235, time: 0.5941359996795654
Validation Loss Energy: 4.011396688022978, Validation Loss Force: 4.530047905498694, time: 0.05182194709777832
Test Loss Energy: 9.31586111846034, Test Loss Force: 9.479491449937317, time: 8.991684198379517


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.13268967823309, Training Loss Force: 4.376988011232575, time: 0.6068699359893799
Validation Loss Energy: 2.165225200228534, Validation Loss Force: 4.5151633637700055, time: 0.05230522155761719
Test Loss Energy: 8.140075362622703, Test Loss Force: 9.405831741021437, time: 8.859693765640259


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1771223614636313, Training Loss Force: 4.415340773614407, time: 0.5796074867248535
Validation Loss Energy: 2.5736204540832306, Validation Loss Force: 4.468628629639141, time: 0.05379128456115723
Test Loss Energy: 7.304227787173309, Test Loss Force: 9.36628987429389, time: 9.718624830245972


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.040670335717811, Training Loss Force: 4.392908626479181, time: 0.6318137645721436
Validation Loss Energy: 3.135233233905108, Validation Loss Force: 4.55736139361478, time: 0.05227160453796387
Test Loss Energy: 7.595386609527419, Test Loss Force: 9.425971472781221, time: 9.1135892868042


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0974152806851976, Training Loss Force: 4.38705833168269, time: 0.6348419189453125
Validation Loss Energy: 1.9073019617717293, Validation Loss Force: 4.516682858021817, time: 0.05650162696838379
Test Loss Energy: 7.330896817153958, Test Loss Force: 9.355482628462092, time: 8.93347978591919

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–ƒâ–†â–ƒâ–‚â–‚â–â–„â–‡â–…â–â–‚â–‚â–‡â–ˆâ–„â–â–‚â–
wandb:   test_error_force â–ˆâ–‚â–â–„â–‚â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–…â–ƒâ–‚â–ƒâ–‚
wandb:          test_loss â–„â–ƒâ–„â–†â–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–…â–â–„â–ƒâ–†â–ˆâ–ƒâ–â–…â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–†â–‚â–‚â–â–â–â–â–‚â–â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–ƒâ–‡â–‚â–ƒâ–…â–â–„â–‡â–ƒâ–ƒâ–†â–â–…â–ˆâ–‚â–ƒâ–…â–
wandb:  valid_error_force â–ˆâ–‚â–â–‚â–â–â–‚â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–ˆâ–„â–‚â–…â–â–‚â–„â–â–ƒâ–†â–‚â–‚â–…â–â–„â–†â–â–‚â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1169
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.3309
wandb:   test_error_force 9.35548
wandb:          test_loss 5.86327
wandb: train_error_energy 3.09742
wandb:  train_error_force 4.38706
wandb:         train_loss 1.46484
wandb: valid_error_energy 1.9073
wandb:  valid_error_force 4.51668
wandb:         valid_loss 1.17838
wandb: 
wandb: ğŸš€ View run al_73_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oolms7fw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_064745-oolms7fw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.982464075088501, Uncertainty Bias: 0.02591472864151001
0.0003633499 0.0048675537
2.8154302 13.945004
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2045 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2450 steps.
Found uncertainty sample 50 after 3357 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2561 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3451 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2104 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1999 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_072950-oqjgierw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oqjgierw
Training model 31. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.341077724766679, Training Loss Force: 4.854089274403695, time: 0.6094796657562256
Validation Loss Energy: 1.676598133716856, Validation Loss Force: 5.246643086938376, time: 0.04900765419006348
Test Loss Energy: 6.7635990457196415, Test Loss Force: 9.747667542845491, time: 8.319283485412598


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.264636258684904, Training Loss Force: 4.771514540002305, time: 0.6098761558532715
Validation Loss Energy: 1.9436838735248705, Validation Loss Force: 4.5597185691935715, time: 0.04892420768737793
Test Loss Energy: 7.727668862835156, Test Loss Force: 9.318392757063675, time: 8.349639177322388


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2033272010435425, Training Loss Force: 4.446138359838741, time: 0.6169788837432861
Validation Loss Energy: 2.161096691593887, Validation Loss Force: 4.558034745112066, time: 0.05515170097351074
Test Loss Energy: 8.086701258239136, Test Loss Force: 9.314996481342824, time: 8.48180890083313


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1504161282951015, Training Loss Force: 4.419979862600668, time: 0.7131597995758057
Validation Loss Energy: 1.7745643191666833, Validation Loss Force: 4.525467155828668, time: 0.05539989471435547
Test Loss Energy: 7.110792201909523, Test Loss Force: 9.307527915700541, time: 8.33921217918396


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.165414475020658, Training Loss Force: 4.404618237181616, time: 0.58461594581604
Validation Loss Energy: 1.7886760876244299, Validation Loss Force: 4.507311159008008, time: 0.05112791061401367
Test Loss Energy: 7.218135965538095, Test Loss Force: 9.297395238468585, time: 8.922558546066284


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.175441362951146, Training Loss Force: 4.414996430825444, time: 0.60591721534729
Validation Loss Energy: 2.156991563219562, Validation Loss Force: 4.5361134130337675, time: 0.05083274841308594
Test Loss Energy: 7.85520321072689, Test Loss Force: 9.333031726201197, time: 8.334946155548096


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.200007092743186, Training Loss Force: 4.424912688298916, time: 0.59316086769104
Validation Loss Energy: 1.8949832366115662, Validation Loss Force: 4.541114562051305, time: 0.051837921142578125
Test Loss Energy: 7.59006303092335, Test Loss Force: 9.371067472815374, time: 8.554143190383911


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.228293933895058, Training Loss Force: 4.4121080509176585, time: 0.5946767330169678
Validation Loss Energy: 1.7584169093768651, Validation Loss Force: 4.502401749678592, time: 0.051218509674072266
Test Loss Energy: 7.23117619119238, Test Loss Force: 9.292882408717103, time: 8.432387828826904


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.195608014014854, Training Loss Force: 4.438991558894873, time: 0.6180515289306641
Validation Loss Energy: 1.7432535858774745, Validation Loss Force: 4.5607539807221364, time: 0.05389142036437988
Test Loss Energy: 7.428538753192452, Test Loss Force: 9.383454205329608, time: 10.477621078491211


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2694573827070017, Training Loss Force: 4.417308302260166, time: 0.6499676704406738
Validation Loss Energy: 1.967545989879076, Validation Loss Force: 4.536940406241743, time: 0.05864834785461426
Test Loss Energy: 7.921581431057275, Test Loss Force: 9.39407591996476, time: 10.575831174850464


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2331817804258285, Training Loss Force: 4.404795993359001, time: 0.6160821914672852
Validation Loss Energy: 2.0103536878454014, Validation Loss Force: 4.56044046256467, time: 0.05752897262573242
Test Loss Energy: 7.996252797017334, Test Loss Force: 9.402270802050076, time: 9.629266500473022


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.148195512092657, Training Loss Force: 4.416224132206727, time: 0.6140260696411133
Validation Loss Energy: 1.8155875465975435, Validation Loss Force: 4.537043279387161, time: 0.055811166763305664
Test Loss Energy: 7.448641664102471, Test Loss Force: 9.384242967061294, time: 9.226309776306152


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1835601959611375, Training Loss Force: 4.409246042258452, time: 0.6164138317108154
Validation Loss Energy: 1.7013969078334068, Validation Loss Force: 4.569179335865751, time: 0.0504152774810791
Test Loss Energy: 7.226756066417255, Test Loss Force: 9.398966788298905, time: 9.185546875


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.186849612027866, Training Loss Force: 4.417265333133088, time: 0.5961132049560547
Validation Loss Energy: 2.4488538102295347, Validation Loss Force: 4.527590974142527, time: 0.05391359329223633
Test Loss Energy: 8.377457793224012, Test Loss Force: 9.373269495797542, time: 8.97397232055664


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2427837494269527, Training Loss Force: 4.425708628188162, time: 0.5801050662994385
Validation Loss Energy: 1.7989055081883525, Validation Loss Force: 4.536305799175849, time: 0.05065155029296875
Test Loss Energy: 7.6351543933393256, Test Loss Force: 9.301179835190249, time: 8.922226190567017


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2443722109331508, Training Loss Force: 4.4226100847151315, time: 0.6222453117370605
Validation Loss Energy: 1.8586087842748136, Validation Loss Force: 4.550116630282874, time: 0.054392337799072266
Test Loss Energy: 7.244070695629053, Test Loss Force: 9.442959230681637, time: 9.146366119384766


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2339885077324833, Training Loss Force: 4.4148582134666725, time: 0.6166958808898926
Validation Loss Energy: 1.683172774254093, Validation Loss Force: 4.489481595155278, time: 0.05206918716430664
Test Loss Energy: 7.175270441210635, Test Loss Force: 9.347297749001237, time: 8.928271293640137


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.121496831542733, Training Loss Force: 4.419685421772731, time: 0.622298002243042
Validation Loss Energy: 2.157699651103613, Validation Loss Force: 4.501436701600141, time: 0.05065464973449707
Test Loss Energy: 7.783064145548571, Test Loss Force: 9.390956010462407, time: 9.586003065109253


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1775476535923697, Training Loss Force: 4.433085855589556, time: 0.582674503326416
Validation Loss Energy: 1.977027687450973, Validation Loss Force: 4.53884066473309, time: 0.05441737174987793
Test Loss Energy: 7.901472315722154, Test Loss Force: 9.383968396185644, time: 9.148614883422852


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.179606368262428, Training Loss Force: 4.389739262181575, time: 0.6002545356750488
Validation Loss Energy: 1.7422208463786615, Validation Loss Force: 4.523309046466336, time: 0.05131840705871582
Test Loss Energy: 7.210511750665388, Test Loss Force: 9.386555611142514, time: 9.009719371795654

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–‡â–ƒâ–ƒâ–†â–…â–ƒâ–„â–†â–†â–„â–ƒâ–ˆâ–…â–ƒâ–ƒâ–…â–†â–ƒ
wandb:   test_error_force â–ˆâ–â–â–â–â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–‚â–‚
wandb:          test_loss â–â–…â–‡â–„â–…â–‡â–…â–…â–‡â–†â–‡â–†â–…â–ˆâ–…â–…â–…â–†â–‡â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‡â–‚â–â–â–â–‚â–â–‚â–â–â–â–â–â–‚â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ƒâ–…â–‚â–‚â–…â–ƒâ–‚â–‚â–„â–„â–‚â–â–ˆâ–‚â–ƒâ–â–…â–„â–‚
wandb:  valid_error_force â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–â–‚â–â–‚â–â–â–‚â–â–â–â–
wandb:         valid_loss â–‡â–ƒâ–…â–‚â–‚â–…â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–â–„â–â–†â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1175
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.21051
wandb:   test_error_force 9.38656
wandb:          test_loss 7.26955
wandb: train_error_energy 2.17961
wandb:  train_error_force 4.38974
wandb:         train_loss 1.08919
wandb: valid_error_energy 1.74222
wandb:  valid_error_force 4.52331
wandb:         valid_loss 1.04625
wandb: 
wandb: ğŸš€ View run al_73_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oqjgierw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_072950-oqjgierw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1463818550109863, Uncertainty Bias: 0.08174565434455872
0.0008058548 0.0035276413
3.1125844 12.804333
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1294 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3645 steps.
Found uncertainty sample 77 after 2377 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 782 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_081209-hrjruiui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hrjruiui
Training model 32. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 10.154533860923694, Training Loss Force: 5.909707727056605, time: 0.6154134273529053
Validation Loss Energy: 3.383114427884289, Validation Loss Force: 5.682160556112807, time: 0.17815876007080078
Test Loss Energy: 7.396001903909263, Test Loss Force: 9.719215396997166, time: 9.199153184890747


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2724947613728803, Training Loss Force: 4.7780447399906745, time: 0.5952920913696289
Validation Loss Energy: 1.6243119668812496, Validation Loss Force: 3.82593655839088, time: 0.05652141571044922
Test Loss Energy: 7.380598608355757, Test Loss Force: 9.390180492298775, time: 9.118756294250488


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.642762046297584, Training Loss Force: 4.658775394138239, time: 0.6207990646362305
Validation Loss Energy: 6.141260469194158, Validation Loss Force: 3.856578950238587, time: 0.05861353874206543
Test Loss Energy: 9.711206060098181, Test Loss Force: 9.475736073003471, time: 9.266479730606079


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.329123376678631, Training Loss Force: 4.902444166314225, time: 0.5941004753112793
Validation Loss Energy: 2.4627154655691177, Validation Loss Force: 5.6684416873630505, time: 0.055986642837524414
Test Loss Energy: 7.681426869848569, Test Loss Force: 9.703708675705702, time: 9.083323955535889


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.324435080820164, Training Loss Force: 4.929371943324884, time: 0.6053810119628906
Validation Loss Energy: 3.9301004055138886, Validation Loss Force: 6.222687235822761, time: 0.058123111724853516
Test Loss Energy: 7.985788951309224, Test Loss Force: 9.335171583688405, time: 9.103569746017456


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2119443314936094, Training Loss Force: 4.950564978789619, time: 0.5867800712585449
Validation Loss Energy: 3.37637968823113, Validation Loss Force: 5.558620819253173, time: 0.05779123306274414
Test Loss Energy: 8.945704757760943, Test Loss Force: 9.58800614550041, time: 9.867481708526611


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.3223411995483634, Training Loss Force: 5.0878666859239585, time: 0.5950074195861816
Validation Loss Energy: 1.5450121359345488, Validation Loss Force: 4.245684932654424, time: 0.062320709228515625
Test Loss Energy: 7.48938640121439, Test Loss Force: 9.603820695810953, time: 9.162569999694824


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1649406832228033, Training Loss Force: 4.489871615209583, time: 0.6008563041687012
Validation Loss Energy: 2.080357638622482, Validation Loss Force: 4.20467172533513, time: 0.059824228286743164
Test Loss Energy: 7.241623424150073, Test Loss Force: 9.310360985373883, time: 9.195311546325684


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.132999760142109, Training Loss Force: 4.411043993304375, time: 0.5802900791168213
Validation Loss Energy: 2.451997675900889, Validation Loss Force: 4.48426712909594, time: 0.058876752853393555
Test Loss Energy: 7.1849790094970585, Test Loss Force: 9.299855529680663, time: 9.30278205871582


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0983590157936347, Training Loss Force: 4.403205630137935, time: 0.6159789562225342
Validation Loss Energy: 3.019511633428145, Validation Loss Force: 5.6637936916109535, time: 0.05860567092895508
Test Loss Energy: 8.165063809465433, Test Loss Force: 9.310700570976914, time: 9.046224355697632


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.109688313612911, Training Loss Force: 4.392804670078457, time: 0.6262831687927246
Validation Loss Energy: 2.067298427217536, Validation Loss Force: 6.801033601961112, time: 0.058338165283203125
Test Loss Energy: 7.960859396375267, Test Loss Force: 9.401075705267093, time: 9.06588363647461


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2092230045989933, Training Loss Force: 4.414495034071578, time: 0.626399040222168
Validation Loss Energy: 1.1708644544019893, Validation Loss Force: 4.151551551213451, time: 0.05672049522399902
Test Loss Energy: 7.095088412594876, Test Loss Force: 9.325292474152343, time: 9.212967157363892


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.169276860926453, Training Loss Force: 4.407420323768227, time: 0.696697473526001
Validation Loss Energy: 3.956223782712277, Validation Loss Force: 4.076751752371378, time: 0.06230521202087402
Test Loss Energy: 7.408085099905965, Test Loss Force: 9.310168258816143, time: 9.14347243309021


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.08802944827681, Training Loss Force: 4.404103708966227, time: 0.6097226142883301
Validation Loss Energy: 1.3398378821331614, Validation Loss Force: 4.60762717195481, time: 0.05822300910949707
Test Loss Energy: 8.038391125883244, Test Loss Force: 9.369642199089078, time: 9.113373041152954


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1259725957194964, Training Loss Force: 4.418453598003203, time: 0.6126973628997803
Validation Loss Energy: 2.462292895197433, Validation Loss Force: 3.5507467750168242, time: 0.059244394302368164
Test Loss Energy: 7.829906002219443, Test Loss Force: 9.331573730602717, time: 9.21692705154419


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1614072819529886, Training Loss Force: 4.403696808183427, time: 0.5914416313171387
Validation Loss Energy: 1.7766664272388146, Validation Loss Force: 4.941917243368156, time: 0.058702707290649414
Test Loss Energy: 7.247796085674042, Test Loss Force: 9.363283285899712, time: 9.331066846847534


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1382795434872652, Training Loss Force: 4.4054613708936285, time: 0.6232764720916748
Validation Loss Energy: 1.1363749520528017, Validation Loss Force: 4.085604743609748, time: 0.06350994110107422
Test Loss Energy: 7.18850067476063, Test Loss Force: 9.353672423901878, time: 9.089934349060059


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1057687468722492, Training Loss Force: 4.412130474302461, time: 0.5943119525909424
Validation Loss Energy: 2.1544475682273374, Validation Loss Force: 3.7093316294120218, time: 0.06099867820739746
Test Loss Energy: 7.873009442117385, Test Loss Force: 9.401349590648197, time: 9.09225583076477


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.263031199300207, Training Loss Force: 4.397852615725151, time: 0.584425687789917
Validation Loss Energy: 1.917324300029939, Validation Loss Force: 6.868330675265721, time: 0.05738186836242676
Test Loss Energy: 7.902400475334032, Test Loss Force: 9.46367672708733, time: 9.41275668144226


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1792097433598085, Training Loss Force: 4.413999998433587, time: 0.6085195541381836
Validation Loss Energy: 2.628972218385398, Validation Loss Force: 5.699984330567743, time: 0.056238651275634766
Test Loss Energy: 7.117976618405462, Test Loss Force: 9.37618652689439, time: 9.729598999023438

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ˆâ–ƒâ–ƒâ–†â–‚â–â–â–„â–ƒâ–â–‚â–„â–ƒâ–â–â–ƒâ–ƒâ–
wandb:   test_error_force â–ˆâ–ƒâ–„â–ˆâ–‚â–†â–†â–â–â–â–ƒâ–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‚
wandb:          test_loss â–â–†â–‡â–„â–…â–ˆâ–…â–…â–…â–†â–†â–…â–…â–†â–†â–†â–…â–†â–…â–…
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–„â–„â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–‚â–ˆâ–ƒâ–…â–„â–‚â–‚â–ƒâ–„â–‚â–â–…â–â–ƒâ–‚â–â–‚â–‚â–ƒ
wandb:  valid_error_force â–…â–‚â–‚â–…â–‡â–…â–‚â–‚â–ƒâ–…â–ˆâ–‚â–‚â–ƒâ–â–„â–‚â–â–ˆâ–†
wandb:         valid_loss â–ƒâ–â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–â–…â–â–‚â–‚â–â–â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1178
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.11798
wandb:   test_error_force 9.37619
wandb:          test_loss 7.23753
wandb: train_error_energy 2.17921
wandb:  train_error_force 4.414
wandb:         train_loss 1.11123
wandb: valid_error_energy 2.62897
wandb:  valid_error_force 5.69998
wandb:         valid_loss 1.70872
wandb: 
wandb: ğŸš€ View run al_73_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hrjruiui
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_081209-hrjruiui/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1887094974517822, Uncertainty Bias: 0.08145458996295929
0.00010681152 0.011133194
3.0851738 12.403704
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 879 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1615 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2026 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1573 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 520 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1235 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1386 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2228 steps.
Found uncertainty sample 61 after 2202 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1208 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1270 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2040 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2139 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2401 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_085209-dkwzqq91
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dkwzqq91
Training model 33. Added 14 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 9.643745318252586, Training Loss Force: 5.936361692284569, time: 0.7557694911956787
Validation Loss Energy: 3.857140410490044, Validation Loss Force: 4.838178137641005, time: 0.06971859931945801
Test Loss Energy: 8.94084344030382, Test Loss Force: 9.756156870484988, time: 10.45777678489685


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.524983243037138, Training Loss Force: 4.791763047158074, time: 0.6966369152069092
Validation Loss Energy: 3.760402245380008, Validation Loss Force: 4.569581699012444, time: 0.06369328498840332
Test Loss Energy: 7.781841535719281, Test Loss Force: 9.361549609577274, time: 10.649515867233276


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.343942152537694, Training Loss Force: 4.54483830505637, time: 0.5987892150878906
Validation Loss Energy: 2.9043251069088463, Validation Loss Force: 4.088261297855239, time: 0.06101655960083008
Test Loss Energy: 7.280006154578802, Test Loss Force: 9.308008960330623, time: 10.870543003082275


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.44307224426257, Training Loss Force: 4.617188198339802, time: 0.679718017578125
Validation Loss Energy: 2.748673807176674, Validation Loss Force: 5.982870784305366, time: 0.06546664237976074
Test Loss Energy: 9.46543830816724, Test Loss Force: 9.465834579972112, time: 10.57762885093689


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.347983105320275, Training Loss Force: 4.525772071925445, time: 0.783522367477417
Validation Loss Energy: 4.360748768474316, Validation Loss Force: 4.137473851135032, time: 0.06335902214050293
Test Loss Energy: 8.924472557544114, Test Loss Force: 9.303614996265626, time: 10.547746896743774


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.428700875809102, Training Loss Force: 4.486394861698997, time: 0.6751153469085693
Validation Loss Energy: 4.059242386750492, Validation Loss Force: 4.536216508848332, time: 0.07056736946105957
Test Loss Energy: 7.781596021418466, Test Loss Force: 9.319320557606984, time: 10.70691704750061


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.45373202275857, Training Loss Force: 4.472622739865077, time: 0.6992824077606201
Validation Loss Energy: 3.6773679188523793, Validation Loss Force: 4.1196639935017165, time: 0.07128453254699707
Test Loss Energy: 7.569428260185694, Test Loss Force: 9.33686856506824, time: 10.609133243560791


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.471787789164993, Training Loss Force: 4.4652543131211795, time: 0.6896836757659912
Validation Loss Energy: 5.028239836508273, Validation Loss Force: 4.191684992737184, time: 0.06542038917541504
Test Loss Energy: 9.904406406484464, Test Loss Force: 9.342038984605738, time: 11.508591890335083


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.528382141056865, Training Loss Force: 4.49587640691832, time: 0.6729366779327393
Validation Loss Energy: 5.051543609979065, Validation Loss Force: 6.25495511243574, time: 0.06427812576293945
Test Loss Energy: 8.393715364202002, Test Loss Force: 9.266491806101813, time: 10.824496030807495


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.397120460885603, Training Loss Force: 4.490065293022755, time: 0.729071855545044
Validation Loss Energy: 4.916298935460018, Validation Loss Force: 4.439355875708037, time: 0.06380939483642578
Test Loss Energy: 7.892589607479259, Test Loss Force: 9.273667376453881, time: 10.584073781967163


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.488281103753581, Training Loss Force: 4.511898096536406, time: 0.6786701679229736
Validation Loss Energy: 3.2426219982685884, Validation Loss Force: 4.362003063773328, time: 0.06451725959777832
Test Loss Energy: 7.152403182621068, Test Loss Force: 9.356766004817885, time: 10.75334644317627


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4425761637741585, Training Loss Force: 4.501955661343298, time: 0.618340253829956
Validation Loss Energy: 5.541731809872843, Validation Loss Force: 4.376039681394324, time: 0.06169605255126953
Test Loss Energy: 10.093743268317843, Test Loss Force: 9.337142455112573, time: 10.241734266281128


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.423448974964534, Training Loss Force: 4.474524797288735, time: 0.753058910369873
Validation Loss Energy: 4.096870243709673, Validation Loss Force: 4.590430211145662, time: 0.06630611419677734
Test Loss Energy: 8.060169310845888, Test Loss Force: 9.23055246035137, time: 10.85788345336914


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.614419448143335, Training Loss Force: 4.539876697391375, time: 0.7417654991149902
Validation Loss Energy: 6.355898384366622, Validation Loss Force: 5.2050916882933755, time: 0.08734130859375
Test Loss Energy: 7.918148136299462, Test Loss Force: 9.27984354705706, time: 9.456790685653687


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.508791492788707, Training Loss Force: 4.516165609315254, time: 0.6431071758270264
Validation Loss Energy: 3.6375412040771624, Validation Loss Force: 4.984954958562225, time: 0.06209301948547363
Test Loss Energy: 7.380423112426168, Test Loss Force: 9.263243816374079, time: 9.818632364273071


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.435299125135522, Training Loss Force: 4.47541784119705, time: 0.6282253265380859
Validation Loss Energy: 5.914712204075162, Validation Loss Force: 4.364521229144625, time: 0.058992624282836914
Test Loss Energy: 9.713544459188677, Test Loss Force: 9.290735589030211, time: 9.845280885696411


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.428313824096049, Training Loss Force: 4.479506931533154, time: 0.7486767768859863
Validation Loss Energy: 4.24585193451387, Validation Loss Force: 4.395712055098752, time: 0.06275725364685059
Test Loss Energy: 8.679991861256005, Test Loss Force: 9.2407929001235, time: 9.696838855743408


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.417839356137033, Training Loss Force: 4.486526892783104, time: 0.6268713474273682
Validation Loss Energy: 5.674345314429034, Validation Loss Force: 4.6581002552697, time: 0.058470726013183594
Test Loss Energy: 7.851569711924937, Test Loss Force: 9.243335026327028, time: 9.50337529182434


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.41208886098659, Training Loss Force: 4.488137716543033, time: 0.6841740608215332
Validation Loss Energy: 1.964172941989275, Validation Loss Force: 4.9946330503208305, time: 0.06108975410461426
Test Loss Energy: 7.6245716446389045, Test Loss Force: 9.25478021110126, time: 9.685166358947754


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.093450769143492, Training Loss Force: 4.716953263362723, time: 0.6613495349884033
Validation Loss Energy: 3.5489788933327304, Validation Loss Force: 4.741892658904641, time: 0.06376791000366211
Test Loss Energy: 7.150341674362243, Test Loss Force: 9.255583452156465, time: 8.265173435211182

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–â–‡â–…â–ƒâ–‚â–ˆâ–„â–ƒâ–â–ˆâ–ƒâ–ƒâ–‚â–‡â–…â–ƒâ–‚â–
wandb:   test_error_force â–ˆâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–â–â–
wandb:          test_loss â–„â–†â–‚â–ˆâ–…â–ƒâ–‚â–‡â–ƒâ–ƒâ–â–ˆâ–ƒâ–ƒâ–â–‡â–„â–‚â–‚â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–„â–‚â–‚â–…â–„â–„â–†â–†â–†â–ƒâ–‡â–„â–ˆâ–„â–‡â–…â–‡â–â–„
wandb:  valid_error_force â–ƒâ–ƒâ–â–‡â–â–‚â–â–â–ˆâ–‚â–‚â–‚â–ƒâ–…â–„â–‚â–‚â–ƒâ–„â–ƒ
wandb:         valid_loss â–„â–„â–â–…â–„â–ƒâ–‚â–„â–ˆâ–…â–‚â–…â–ƒâ–ˆâ–„â–†â–ƒâ–†â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1190
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.15034
wandb:   test_error_force 9.25558
wandb:          test_loss 5.85176
wandb: train_error_energy 3.09345
wandb:  train_error_force 4.71695
wandb:         train_loss 1.59978
wandb: valid_error_energy 3.54898
wandb:  valid_error_force 4.74189
wandb:         valid_loss 1.70761
wandb: 
wandb: ğŸš€ View run al_73_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dkwzqq91
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_085209-dkwzqq91/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1944799423217773, Uncertainty Bias: 0.013253599405288696
0.0007019043 0.017028809
2.7757854 10.96062
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1411 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1856 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1356 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 459 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2329 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3322 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1485 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3412 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1598 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 920 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 188 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 545 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2112 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2488 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3270 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_093225-53mkc4y3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/53mkc4y3
Training model 34. Added 15 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.467637842765335, Training Loss Force: 4.858240908955388, time: 0.6222677230834961
Validation Loss Energy: 1.9365812844426389, Validation Loss Force: 4.94207667447664, time: 0.06100916862487793
Test Loss Energy: 6.7664536012168535, Test Loss Force: 9.244560126320168, time: 8.42642879486084


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1698431914726712, Training Loss Force: 4.624118365326798, time: 0.6519050598144531
Validation Loss Energy: 3.430677225461902, Validation Loss Force: 4.825296504879937, time: 0.05553841590881348
Test Loss Energy: 7.2377707373020375, Test Loss Force: 9.158942645924517, time: 8.726681470870972


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.148714403341587, Training Loss Force: 4.509012128613749, time: 0.6533975601196289
Validation Loss Energy: 2.5330594877993162, Validation Loss Force: 4.297292737936961, time: 0.06473445892333984
Test Loss Energy: 7.964677181291938, Test Loss Force: 9.156041446487363, time: 10.835036039352417


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.04460172031457, Training Loss Force: 4.497116474830849, time: 0.6597976684570312
Validation Loss Energy: 2.1132517722083834, Validation Loss Force: 4.108720472986803, time: 0.06287002563476562
Test Loss Energy: 7.93247425645276, Test Loss Force: 9.216084902155547, time: 10.585702419281006


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0260737283169235, Training Loss Force: 4.485650314672158, time: 0.682422399520874
Validation Loss Energy: 3.7354335747051146, Validation Loss Force: 4.302005307741377, time: 0.05718660354614258
Test Loss Energy: 7.312663776808805, Test Loss Force: 9.221272654912214, time: 9.169574737548828


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0266684717459817, Training Loss Force: 4.49457586675353, time: 0.6024539470672607
Validation Loss Energy: 2.8419351049076202, Validation Loss Force: 4.770258481404381, time: 0.05693316459655762
Test Loss Energy: 7.856191656552769, Test Loss Force: 9.202810654726314, time: 9.162968873977661


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0862046492877098, Training Loss Force: 4.4877550654754685, time: 0.6243319511413574
Validation Loss Energy: 2.9268282734654543, Validation Loss Force: 4.427979263704294, time: 0.05713796615600586
Test Loss Energy: 7.7460860377401115, Test Loss Force: 9.237723642605717, time: 9.013220310211182


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.990720372226537, Training Loss Force: 4.497082968984101, time: 0.6324288845062256
Validation Loss Energy: 2.9601300029229765, Validation Loss Force: 4.569679005429213, time: 0.056082963943481445
Test Loss Energy: 7.352140351346893, Test Loss Force: 9.257827495487827, time: 8.989752769470215


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.101744893054012, Training Loss Force: 4.473977927726051, time: 0.6151633262634277
Validation Loss Energy: 2.9077153559901694, Validation Loss Force: 4.494398575235655, time: 0.058199405670166016
Test Loss Energy: 8.199316785011781, Test Loss Force: 9.285816079148539, time: 9.10411810874939


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.113534190091304, Training Loss Force: 4.484410727256207, time: 0.6401448249816895
Validation Loss Energy: 2.706509511707507, Validation Loss Force: 6.2148677634252145, time: 0.05787253379821777
Test Loss Energy: 8.19071783886729, Test Loss Force: 9.170071943621364, time: 8.938903093338013


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0075975449838475, Training Loss Force: 4.486071053883103, time: 0.63409423828125
Validation Loss Energy: 3.565042468189107, Validation Loss Force: 4.171020293983928, time: 0.06426811218261719
Test Loss Energy: 6.9903624337155525, Test Loss Force: 9.136684381620025, time: 8.997384786605835


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.020594338711361, Training Loss Force: 4.502310431889905, time: 0.601945161819458
Validation Loss Energy: 3.550037128448752, Validation Loss Force: 5.370430877226574, time: 0.05672478675842285
Test Loss Energy: 8.390638139558861, Test Loss Force: 9.291035947557733, time: 9.7853364944458


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0828879044634, Training Loss Force: 4.490232939450784, time: 0.6176514625549316
Validation Loss Energy: 2.7337024244810735, Validation Loss Force: 4.159399413927104, time: 0.05917549133300781
Test Loss Energy: 7.631022164614392, Test Loss Force: 9.172541971653894, time: 8.860433340072632


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9755982161504284, Training Loss Force: 4.4916394818484635, time: 0.594773530960083
Validation Loss Energy: 3.5355467111083554, Validation Loss Force: 5.3510920619027456, time: 0.05563807487487793
Test Loss Energy: 7.2191962623838775, Test Loss Force: 9.200227543410247, time: 8.97040343284607


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0600804282904526, Training Loss Force: 4.484539336267125, time: 0.6225831508636475
Validation Loss Energy: 3.0854327227454936, Validation Loss Force: 4.288380628040348, time: 0.05686640739440918
Test Loss Energy: 8.002169920631497, Test Loss Force: 9.22280702952517, time: 9.124140501022339


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.026260330920925, Training Loss Force: 4.486212085488478, time: 0.6159439086914062
Validation Loss Energy: 2.546753528939303, Validation Loss Force: 4.878140346591518, time: 0.058977365493774414
Test Loss Energy: 7.982395855909996, Test Loss Force: 9.253776241388747, time: 8.93114972114563


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0511912064381543, Training Loss Force: 4.47055587797486, time: 0.6191473007202148
Validation Loss Energy: 3.6908149085749584, Validation Loss Force: 4.08728578432693, time: 0.06367897987365723
Test Loss Energy: 7.3167701922341095, Test Loss Force: 9.205109402387533, time: 8.980057001113892


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1081571052388663, Training Loss Force: 4.4813453700379355, time: 0.6091079711914062
Validation Loss Energy: 2.6312065919302103, Validation Loss Force: 4.7904229539213095, time: 0.059056997299194336
Test Loss Energy: 7.9008199977156055, Test Loss Force: 9.249822653940814, time: 8.963134288787842


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1096932645183357, Training Loss Force: 4.489405313393654, time: 0.6180670261383057
Validation Loss Energy: 2.3867988139583574, Validation Loss Force: 4.464699187220953, time: 0.05780649185180664
Test Loss Energy: 8.165170706976776, Test Loss Force: 9.19107976328752, time: 9.285582542419434


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0895992140486648, Training Loss Force: 4.463776094697367, time: 0.6494836807250977
Validation Loss Energy: 3.2147254509938907, Validation Loss Force: 4.495321538845526, time: 0.058194637298583984
Test Loss Energy: 7.040268105916914, Test Loss Force: 9.201831432765786, time: 8.984482526779175

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–†â–†â–ƒâ–†â–…â–„â–‡â–‡â–‚â–ˆâ–…â–ƒâ–†â–†â–ƒâ–†â–‡â–‚
wandb:   test_error_force â–†â–‚â–‚â–…â–…â–„â–†â–†â–ˆâ–ƒâ–â–ˆâ–ƒâ–„â–…â–†â–„â–†â–ƒâ–„
wandb:          test_loss â–‚â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–…â–†â–â–ˆâ–â–„â–„â–…â–…â–†â–…â–
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–ƒâ–‚â–ˆâ–…â–…â–…â–…â–„â–‡â–‡â–„â–‡â–…â–ƒâ–ˆâ–„â–ƒâ–†
wandb:  valid_error_force â–„â–ƒâ–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–ˆâ–â–…â–â–…â–‚â–„â–â–ƒâ–‚â–‚
wandb:         valid_loss â–‚â–…â–ƒâ–â–…â–„â–ƒâ–„â–„â–†â–„â–†â–‚â–ˆâ–ƒâ–„â–†â–„â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1203
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.04027
wandb:   test_error_force 9.20183
wandb:          test_loss 5.67299
wandb: train_error_energy 3.0896
wandb:  train_error_force 4.46378
wandb:         train_loss 1.47502
wandb: valid_error_energy 3.21473
wandb:  valid_error_force 4.49532
wandb:         valid_loss 1.70168
wandb: 
wandb: ğŸš€ View run al_73_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/53mkc4y3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_093225-53mkc4y3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.148885488510132, Uncertainty Bias: 0.020214200019836426
0.00019073486 0.13843203
2.8195238 8.57383
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2559 steps.
Found uncertainty sample 13 after 3805 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3076 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2353 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3442 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3094 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2523 steps.
Found uncertainty sample 63 after 2783 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2813 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3003 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3713 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1934 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_101410-o58bjhyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o58bjhyb
Training model 35. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.629424242930254, Training Loss Force: 5.043420680553619, time: 0.6289846897125244
Validation Loss Energy: 2.5551493804210827, Validation Loss Force: 5.240301915000645, time: 0.05828595161437988
Test Loss Energy: 7.344870028861294, Test Loss Force: 9.636435574891394, time: 9.216992139816284


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0603456536119666, Training Loss Force: 4.836385275994567, time: 0.5946357250213623
Validation Loss Energy: 3.7124907479198717, Validation Loss Force: 4.6419360339593645, time: 0.05793881416320801
Test Loss Energy: 7.244595735485465, Test Loss Force: 9.14619594017362, time: 9.188243627548218


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0665560337951803, Training Loss Force: 4.5389344787600985, time: 0.6027097702026367
Validation Loss Energy: 2.974325160975873, Validation Loss Force: 4.587188148380953, time: 0.05758404731750488
Test Loss Energy: 8.193808987909797, Test Loss Force: 9.188900086494824, time: 9.523014307022095


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.991587064999347, Training Loss Force: 4.52756578909018, time: 0.6191756725311279
Validation Loss Energy: 2.4734053102595324, Validation Loss Force: 4.642529892571554, time: 0.05733847618103027
Test Loss Energy: 7.900948635196759, Test Loss Force: 9.169540573432688, time: 9.282814025878906


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.061575176968494, Training Loss Force: 4.528448355829209, time: 0.6142764091491699
Validation Loss Energy: 3.4866720582575086, Validation Loss Force: 4.837710087096265, time: 0.0586094856262207
Test Loss Energy: 7.303708970394911, Test Loss Force: 9.203374373728924, time: 9.266067504882812


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0961228721410556, Training Loss Force: 4.524648506853951, time: 0.6264290809631348
Validation Loss Energy: 2.724086902752474, Validation Loss Force: 4.573827331617848, time: 0.060527801513671875
Test Loss Energy: 8.233768924702378, Test Loss Force: 9.203763179705467, time: 9.467950820922852


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0977466868877337, Training Loss Force: 4.548924963611012, time: 0.6422970294952393
Validation Loss Energy: 2.856828998740438, Validation Loss Force: 4.472158603609534, time: 0.05862689018249512
Test Loss Energy: 8.289842077581193, Test Loss Force: 9.249396052499813, time: 9.236079454421997


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0084661275145397, Training Loss Force: 4.52546032926143, time: 0.611947774887085
Validation Loss Energy: 3.727674445646115, Validation Loss Force: 4.999179286273238, time: 0.057839393615722656
Test Loss Energy: 7.1029561598964195, Test Loss Force: 9.221071972887188, time: 9.278725624084473


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.167805007024563, Training Loss Force: 4.528316102075955, time: 0.6324338912963867
Validation Loss Energy: 2.982142072678241, Validation Loss Force: 4.954984804866074, time: 0.056813955307006836
Test Loss Energy: 8.527355127535634, Test Loss Force: 9.203138899358393, time: 9.384001970291138


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.1123501908556896, Training Loss Force: 4.534884935636254, time: 0.6315765380859375
Validation Loss Energy: 2.8048581314154655, Validation Loss Force: 4.9467496091730805, time: 0.05700206756591797
Test Loss Energy: 8.083328067829425, Test Loss Force: 9.20456555340023, time: 9.241289615631104


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0006437897166682, Training Loss Force: 4.5237113510158835, time: 0.6552677154541016
Validation Loss Energy: 3.874903618937287, Validation Loss Force: 4.086684243629206, time: 0.05759859085083008
Test Loss Energy: 7.086063706722073, Test Loss Force: 9.22768211749513, time: 9.207048416137695


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.077391700407463, Training Loss Force: 4.529730918390324, time: 0.6131863594055176
Validation Loss Energy: 2.4508794314500397, Validation Loss Force: 4.445303368595767, time: 0.0596623420715332
Test Loss Energy: 7.942839689393213, Test Loss Force: 9.299309866697591, time: 9.381459474563599


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0870422690876884, Training Loss Force: 4.550840926136861, time: 0.5976238250732422
Validation Loss Energy: 2.5938724355745086, Validation Loss Force: 4.4711093865939215, time: 0.05814957618713379
Test Loss Energy: 8.132398434618567, Test Loss Force: 9.148906777309723, time: 9.265754222869873


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.049441516237312, Training Loss Force: 4.525488004692384, time: 0.6055889129638672
Validation Loss Energy: 3.2556292164279603, Validation Loss Force: 4.684015603818506, time: 0.06217837333679199
Test Loss Energy: 7.32023337128976, Test Loss Force: 9.252517589468802, time: 9.250699758529663


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.073824417635699, Training Loss Force: 4.534113258131899, time: 0.681523323059082
Validation Loss Energy: 2.6617446632830495, Validation Loss Force: 5.086259622516947, time: 0.06098198890686035
Test Loss Energy: 7.9272051886545825, Test Loss Force: 9.172407414204558, time: 10.245341777801514


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0257116917245015, Training Loss Force: 4.51485399429031, time: 0.6386916637420654
Validation Loss Energy: 2.3709864098985873, Validation Loss Force: 4.7753921185637465, time: 0.0662984848022461
Test Loss Energy: 8.08043521790234, Test Loss Force: 9.17452095243188, time: 10.420414209365845


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1241436482901803, Training Loss Force: 4.513813684040535, time: 0.6620869636535645
Validation Loss Energy: 4.5647526732447075, Validation Loss Force: 5.718110267053703, time: 0.06091046333312988
Test Loss Energy: 7.369352699643253, Test Loss Force: 9.19288681550548, time: 9.889774799346924


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.1203668983089554, Training Loss Force: 4.509089031505096, time: 0.6666274070739746
Validation Loss Energy: 3.2975005906356594, Validation Loss Force: 4.4229433782999905, time: 0.06353187561035156
Test Loss Energy: 8.359352982327547, Test Loss Force: 9.20603484333738, time: 10.234326362609863


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.143618039825307, Training Loss Force: 4.526720712803669, time: 0.613755464553833
Validation Loss Energy: 2.7807874854060985, Validation Loss Force: 5.262527635801427, time: 0.0589447021484375
Test Loss Energy: 8.029024108750535, Test Loss Force: 9.204857131069078, time: 10.237839221954346


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.042796837464109, Training Loss Force: 4.5123352253684335, time: 0.6581213474273682
Validation Loss Energy: 3.2572832028439116, Validation Loss Force: 4.312304423747975, time: 0.060118675231933594
Test Loss Energy: 7.34094036843719, Test Loss Force: 9.222256125073617, time: 10.024784564971924

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–†â–…â–‚â–‡â–‡â–â–ˆâ–†â–â–…â–†â–‚â–…â–†â–‚â–‡â–†â–‚
wandb:   test_error_force â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–â–â–‚â–‚â–‚â–‚
wandb:          test_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–„â–ƒâ–â–„â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–…â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–…â–ƒâ–â–…â–‚â–ƒâ–…â–ƒâ–‚â–†â–â–‚â–„â–‚â–â–ˆâ–„â–‚â–„
wandb:  valid_error_force â–†â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–…â–…â–â–ƒâ–ƒâ–„â–…â–„â–ˆâ–‚â–†â–‚
wandb:         valid_loss â–‚â–…â–‚â–â–…â–‚â–‚â–…â–ƒâ–‚â–„â–â–â–„â–ƒâ–â–ˆâ–‚â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1213
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.34094
wandb:   test_error_force 9.22226
wandb:          test_loss 5.78898
wandb: train_error_energy 3.0428
wandb:  train_error_force 4.51234
wandb:         train_loss 1.49016
wandb: valid_error_energy 3.25728
wandb:  valid_error_force 4.3123
wandb:         valid_loss 1.61361
wandb: 
wandb: ğŸš€ View run al_73_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o58bjhyb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_101410-o58bjhyb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3328328132629395, Uncertainty Bias: -0.004857510328292847
0.0 0.005346298
2.6881795 9.980293
(48745, 22, 3)
Found uncertainty sample 0 after 3417 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2755 steps.
Found uncertainty sample 4 after 2445 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 423 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3444 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1091 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2511 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1079 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2436 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2912 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3350 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3846 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 829 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_105519-uux2p6oa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_36
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uux2p6oa
Training model 36. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.728754679716689, Training Loss Force: 4.942931746834864, time: 0.6324808597564697
Validation Loss Energy: 2.214746372944582, Validation Loss Force: 4.5676600642830865, time: 0.06439518928527832
Test Loss Energy: 7.229770500692859, Test Loss Force: 9.303449017984768, time: 9.277299880981445


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.21261302553317, Training Loss Force: 4.653220666477443, time: 0.6027922630310059
Validation Loss Energy: 2.1508262999071137, Validation Loss Force: 4.560691633361277, time: 0.058118581771850586
Test Loss Energy: 6.857838182181052, Test Loss Force: 9.151734027274289, time: 9.29190444946289


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.232454199578608, Training Loss Force: 4.582605406107545, time: 0.6326148509979248
Validation Loss Energy: 1.8276828789370545, Validation Loss Force: 4.5349161210361135, time: 0.06417727470397949
Test Loss Energy: 7.174966986299597, Test Loss Force: 9.292094192583114, time: 9.487928867340088


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.080780941617916, Training Loss Force: 4.996566041176629, time: 0.6188173294067383
Validation Loss Energy: 7.942085608089554, Validation Loss Force: 4.925091694694414, time: 0.05951738357543945
Test Loss Energy: 8.764267161988425, Test Loss Force: 9.54278848654383, time: 9.213134527206421


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.718728412576711, Training Loss Force: 4.955143813474128, time: 0.6223647594451904
Validation Loss Energy: 2.490159270802858, Validation Loss Force: 5.58735159648309, time: 0.05884552001953125
Test Loss Energy: 7.81532443508929, Test Loss Force: 10.39724176188732, time: 9.825071096420288


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.4945767558432927, Training Loss Force: 5.755576474777137, time: 0.6079633235931396
Validation Loss Energy: 5.812698561559805, Validation Loss Force: 4.943006095491743, time: 0.05850839614868164
Test Loss Energy: 9.886734161297849, Test Loss Force: 9.44434960480818, time: 9.459247589111328


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.236914600199649, Training Loss Force: 5.028674749316527, time: 0.6533606052398682
Validation Loss Energy: 1.9411235123504198, Validation Loss Force: 4.902001572269141, time: 0.0596766471862793
Test Loss Energy: 7.693270110112456, Test Loss Force: 9.376722233885282, time: 9.283263444900513


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.218384195859385, Training Loss Force: 4.715899164904544, time: 0.6276788711547852
Validation Loss Energy: 1.6930283889892892, Validation Loss Force: 4.294436560802145, time: 0.06392455101013184
Test Loss Energy: 7.598641694356838, Test Loss Force: 9.230646969997037, time: 9.26840853691101


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.191505631970484, Training Loss Force: 4.562564926048106, time: 0.6495780944824219
Validation Loss Energy: 2.331230726580921, Validation Loss Force: 5.028891589098404, time: 0.05843210220336914
Test Loss Energy: 7.509658295855833, Test Loss Force: 9.21172087601551, time: 9.439378261566162


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.190054457180216, Training Loss Force: 4.517690858407571, time: 0.66023850440979
Validation Loss Energy: 1.7456968787484537, Validation Loss Force: 4.751905645058722, time: 0.05909848213195801
Test Loss Energy: 6.87274149107158, Test Loss Force: 9.16342710459571, time: 9.265705347061157


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1837257290220626, Training Loss Force: 4.521850312344037, time: 0.6359195709228516
Validation Loss Energy: 2.125361299705947, Validation Loss Force: 4.266229278734305, time: 0.06096529960632324
Test Loss Energy: 7.697160305636415, Test Loss Force: 9.173598705793344, time: 9.284568548202515


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1681965601159123, Training Loss Force: 4.544000456952905, time: 0.6123101711273193
Validation Loss Energy: 2.0912812302488346, Validation Loss Force: 4.057457470876735, time: 0.06168317794799805
Test Loss Energy: 7.88826945065839, Test Loss Force: 9.20658878821371, time: 9.473891973495483


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1922923563198387, Training Loss Force: 4.5476573923027335, time: 0.6136133670806885
Validation Loss Energy: 1.9447804077339919, Validation Loss Force: 4.9505897612637515, time: 0.06468415260314941
Test Loss Energy: 7.229057334553313, Test Loss Force: 9.190011627555153, time: 9.241563320159912


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1339802856550754, Training Loss Force: 4.522784278093502, time: 0.6478958129882812
Validation Loss Energy: 1.667704004353776, Validation Loss Force: 4.544951819443079, time: 0.05923199653625488
Test Loss Energy: 7.129188324670827, Test Loss Force: 9.172043999505492, time: 9.253279685974121


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1285006092240084, Training Loss Force: 4.5631355813933965, time: 0.6360220909118652
Validation Loss Energy: 3.300461533603634, Validation Loss Force: 5.648579376877146, time: 0.058999061584472656
Test Loss Energy: 8.009198340486511, Test Loss Force: 9.156207261555236, time: 9.436887264251709


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.149362832638097, Training Loss Force: 4.569962868624014, time: 0.6137959957122803
Validation Loss Energy: 2.9632656298359317, Validation Loss Force: 4.833472247910967, time: 0.061981916427612305
Test Loss Energy: 7.770492571995462, Test Loss Force: 9.227360336097316, time: 9.253401279449463


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1475234969960213, Training Loss Force: 4.554322564976183, time: 0.6267831325531006
Validation Loss Energy: 1.657482377209961, Validation Loss Force: 4.412202709377018, time: 0.0597689151763916
Test Loss Energy: 7.171985504725977, Test Loss Force: 9.233594745757323, time: 9.190351724624634


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1437429774154704, Training Loss Force: 4.550192292116766, time: 0.6315057277679443
Validation Loss Energy: 2.0891962677009395, Validation Loss Force: 4.612724514043389, time: 0.06005406379699707
Test Loss Energy: 6.993340499474526, Test Loss Force: 9.255574065078125, time: 9.63048243522644


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.188628072888194, Training Loss Force: 4.541286885132392, time: 0.6532261371612549
Validation Loss Energy: 1.7016612717769095, Validation Loss Force: 4.2819731006971296, time: 0.05848503112792969
Test Loss Energy: 7.9325245680216705, Test Loss Force: 9.162510859531851, time: 9.304548501968384


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.254337846331325, Training Loss Force: 4.560582548317632, time: 0.6858956813812256
Validation Loss Energy: 2.4943271918763346, Validation Loss Force: 4.742040288548391, time: 0.061034202575683594
Test Loss Energy: 8.240454713866354, Test Loss Force: 9.219979229299678, time: 9.890352487564087

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–…â–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–‚â–â–ƒâ–„
wandb:   test_error_force â–‚â–â–‚â–ƒâ–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb:          test_loss â–â–‚â–ƒâ–ˆâ–ˆâ–†â–‚â–ƒâ–„â–ƒâ–„â–„â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–„
wandb: train_error_energy â–ˆâ–â–â–„â–ƒâ–…â–‡â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ƒâ–‚â–â–„â–ƒâ–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–‡â–â–â–„â–ƒâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–â–ˆâ–‚â–†â–â–â–‚â–â–‚â–â–â–â–ƒâ–‚â–â–â–â–‚
wandb:  valid_error_force â–ƒâ–ƒâ–ƒâ–…â–ˆâ–…â–…â–‚â–…â–„â–‚â–â–…â–ƒâ–ˆâ–„â–ƒâ–ƒâ–‚â–„
wandb:         valid_loss â–â–â–â–ˆâ–‚â–„â–â–â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1224
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.24045
wandb:   test_error_force 9.21998
wandb:          test_loss 7.14364
wandb: train_error_energy 2.25434
wandb:  train_error_force 4.56058
wandb:         train_loss 1.18599
wandb: valid_error_energy 2.49433
wandb:  valid_error_force 4.74204
wandb:         valid_loss 1.24889
wandb: 
wandb: ğŸš€ View run al_73_36 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/uux2p6oa
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_105519-uux2p6oa/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.306990623474121, Uncertainty Bias: 0.06390385329723358
6.0081482e-05 0.0030765533
3.027276 9.41583
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 574 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2474 steps.
Found uncertainty sample 14 after 3923 steps.
Found uncertainty sample 15 after 970 steps.
Found uncertainty sample 16 after 3116 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 670 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3511 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2705 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2006 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3428 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1724 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1328 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2337 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 557 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1890 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1751 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1922 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3214 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3872 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2187 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1783 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_113452-oaky9z4x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_37
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oaky9z4x
Training model 37. Added 21 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.027236806212046, Training Loss Force: 5.517904315716096, time: 0.6192817687988281
Validation Loss Energy: 7.843503742451237, Validation Loss Force: 5.534202252703294, time: 0.06916284561157227
Test Loss Energy: 12.381915861177173, Test Loss Force: 9.751382219123721, time: 9.53589129447937


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.538568580165164, Training Loss Force: 4.915827933121728, time: 0.606149435043335
Validation Loss Energy: 4.010423401186127, Validation Loss Force: 4.284079773486752, time: 0.05978798866271973
Test Loss Energy: 9.406938278437924, Test Loss Force: 9.317792231200986, time: 9.504536390304565


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.442249141529312, Training Loss Force: 4.712680750745026, time: 0.6288919448852539
Validation Loss Energy: 2.076419066769311, Validation Loss Force: 4.707968791853396, time: 0.06207537651062012
Test Loss Energy: 7.0184879507403615, Test Loss Force: 9.192519987323381, time: 9.74064040184021


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.4123798255542095, Training Loss Force: 4.666317289153637, time: 0.6171619892120361
Validation Loss Energy: 5.399726343410563, Validation Loss Force: 4.869662664198611, time: 0.06468558311462402
Test Loss Energy: 7.547582484062094, Test Loss Force: 9.156900977370013, time: 9.545503377914429


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.437298629759344, Training Loss Force: 4.671544030563328, time: 0.6054501533508301
Validation Loss Energy: 5.700259326962964, Validation Loss Force: 4.433767770821833, time: 0.06463217735290527
Test Loss Energy: 7.901094209522684, Test Loss Force: 9.136179852972791, time: 9.58259391784668


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.560009215233126, Training Loss Force: 4.641594716415448, time: 0.634082555770874
Validation Loss Energy: 3.4792621857538966, Validation Loss Force: 4.788763178107564, time: 0.06002378463745117
Test Loss Energy: 6.979057341642512, Test Loss Force: 9.111430296315238, time: 9.667445182800293


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.4551686794303755, Training Loss Force: 4.645347702099686, time: 0.6040606498718262
Validation Loss Energy: 2.4507454959587642, Validation Loss Force: 4.525381650876632, time: 0.06006026268005371
Test Loss Energy: 7.957012918615559, Test Loss Force: 9.12658444491317, time: 9.547947645187378


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.387037007910037, Training Loss Force: 4.6613072105324, time: 0.6053156852722168
Validation Loss Energy: 5.881282662527877, Validation Loss Force: 4.861704691592297, time: 0.05883908271789551
Test Loss Energy: 9.923709191375705, Test Loss Force: 9.21133532497224, time: 9.526525497436523


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.37190403021861, Training Loss Force: 4.618892415128798, time: 0.6159882545471191
Validation Loss Energy: 6.027972865151332, Validation Loss Force: 4.769341307192304, time: 0.059464454650878906
Test Loss Energy: 10.324720402930621, Test Loss Force: 9.10509712414546, time: 9.736970901489258


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.465232531210638, Training Loss Force: 4.641792241076282, time: 0.6350138187408447
Validation Loss Energy: 4.833247574742726, Validation Loss Force: 5.33499998539569, time: 0.05939888954162598
Test Loss Energy: 8.649743537837852, Test Loss Force: 9.088721177119947, time: 10.16667103767395


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.474455370190929, Training Loss Force: 4.6267489134086865, time: 0.6094729900360107
Validation Loss Energy: 1.9013297526087998, Validation Loss Force: 4.186644876619109, time: 0.0588381290435791
Test Loss Energy: 7.342012871282752, Test Loss Force: 9.133604463962605, time: 9.542948484420776


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4932070497979355, Training Loss Force: 4.632819228313525, time: 0.6218914985656738
Validation Loss Energy: 4.716856408143958, Validation Loss Force: 5.019030908640138, time: 0.05992841720581055
Test Loss Energy: 7.7041833417944865, Test Loss Force: 9.108039019575001, time: 9.731490135192871


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.479014184095347, Training Loss Force: 4.612569296520282, time: 0.6378772258758545
Validation Loss Energy: 6.5346794416320435, Validation Loss Force: 4.872456939310858, time: 0.059332847595214844
Test Loss Energy: 7.898041616050826, Test Loss Force: 9.04208164393042, time: 9.493386030197144


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.476998580131678, Training Loss Force: 4.618127814957405, time: 0.6401023864746094
Validation Loss Energy: 2.8904360075970272, Validation Loss Force: 5.332709610560677, time: 0.06003856658935547
Test Loss Energy: 7.149747541785397, Test Loss Force: 9.041580850528966, time: 9.54452109336853


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.526503161141621, Training Loss Force: 4.600104860096702, time: 0.6383845806121826
Validation Loss Energy: 2.4465413911490743, Validation Loss Force: 4.642195888852662, time: 0.06244826316833496
Test Loss Energy: 7.644309916752459, Test Loss Force: 9.035970539350135, time: 9.73967432975769


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.396684999367685, Training Loss Force: 4.64896520788229, time: 0.6222686767578125
Validation Loss Energy: 4.877668288002152, Validation Loss Force: 4.742298807426812, time: 0.06184053421020508
Test Loss Energy: 9.92451399927558, Test Loss Force: 9.040215079594336, time: 9.548657417297363


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.453610603466934, Training Loss Force: 4.623013552843768, time: 0.6531949043273926
Validation Loss Energy: 5.977934209340147, Validation Loss Force: 4.941218062249943, time: 0.06260538101196289
Test Loss Energy: 10.30909023666259, Test Loss Force: 9.087614621050546, time: 9.499843835830688


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.50526438707337, Training Loss Force: 4.6142902092882485, time: 0.6375207901000977
Validation Loss Energy: 4.29253786099482, Validation Loss Force: 4.533609943826101, time: 0.06723785400390625
Test Loss Energy: 9.12935365633972, Test Loss Force: 9.041423387302777, time: 9.734054803848267


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.5852050341294595, Training Loss Force: 4.621139877622765, time: 0.6697533130645752
Validation Loss Energy: 2.23737312087718, Validation Loss Force: 4.508318959562477, time: 0.059556007385253906
Test Loss Energy: 6.886167654817075, Test Loss Force: 9.080180493348424, time: 9.496007680892944


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.467865776564124, Training Loss Force: 4.602189728438422, time: 0.6241703033447266
Validation Loss Energy: 5.081089690286795, Validation Loss Force: 5.302090153635001, time: 0.06827473640441895
Test Loss Energy: 7.510983261212211, Test Loss Force: 9.088403895737333, time: 9.489918947219849

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–â–‚â–‚â–â–‚â–…â–…â–ƒâ–‚â–‚â–‚â–â–‚â–…â–…â–„â–â–‚
wandb:   test_error_force â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–â–‚
wandb:          test_loss â–ˆâ–ƒâ–â–â–‚â–â–â–‚â–ƒâ–‚â–â–â–‚â–â–â–‚â–ƒâ–‚â–â–
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–‚â–ƒâ–‚â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–â–…â–…â–ƒâ–‚â–†â–†â–„â–â–„â–†â–‚â–‚â–…â–†â–„â–â–…
wandb:  valid_error_force â–ˆâ–‚â–„â–…â–‚â–„â–ƒâ–…â–„â–‡â–â–…â–…â–‡â–ƒâ–„â–…â–ƒâ–ƒâ–‡
wandb:         valid_loss â–ˆâ–‚â–â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1242
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.51098
wandb:   test_error_force 9.0884
wandb:          test_loss 4.85161
wandb: train_error_energy 4.46787
wandb:  train_error_force 4.60219
wandb:         train_loss 1.90213
wandb: valid_error_energy 5.08109
wandb:  valid_error_force 5.30209
wandb:         valid_loss 2.30232
wandb: 
wandb: ğŸš€ View run al_73_37 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/oaky9z4x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_113452-oaky9z4x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.572937488555908, Uncertainty Bias: -0.13864758610725403
9.1552734e-05 0.08711815
2.3567066 8.962043
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2219 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3109 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1522 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2994 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3911 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2191 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2634 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2932 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3632 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3013 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 675 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_121647-f8h53hwi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_38
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/f8h53hwi
Training model 38. Added 11 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.776195809445601, Training Loss Force: 4.910532428054097, time: 0.6383183002471924
Validation Loss Energy: 1.67297358102673, Validation Loss Force: 4.64888175262829, time: 0.0670773983001709
Test Loss Energy: 6.843690945792618, Test Loss Force: 9.231575442045203, time: 9.487625360488892


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7447846873574497, Training Loss Force: 5.251095022507483, time: 0.6304755210876465
Validation Loss Energy: 3.013069703701881, Validation Loss Force: 5.212939885010746, time: 0.06079673767089844
Test Loss Energy: 8.630125800846479, Test Loss Force: 9.383829604525117, time: 10.139797449111938


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3434806247080777, Training Loss Force: 5.127743318608129, time: 0.678642749786377
Validation Loss Energy: 1.728670760841518, Validation Loss Force: 4.687039450820205, time: 0.0616607666015625
Test Loss Energy: 6.984298434734797, Test Loss Force: 9.133849740438786, time: 9.70375108718872


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.416707998657921, Training Loss Force: 5.240472590900998, time: 0.6535282135009766
Validation Loss Energy: 2.584359898325901, Validation Loss Force: 5.050918243682727, time: 0.06039547920227051
Test Loss Energy: 7.173749988665433, Test Loss Force: 9.205082206440748, time: 9.49792766571045


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.47963020835049, Training Loss Force: 4.837904538494675, time: 0.6416912078857422
Validation Loss Energy: 2.2678618710141967, Validation Loss Force: 4.556239809126742, time: 0.059845685958862305
Test Loss Energy: 7.522197438988518, Test Loss Force: 9.072842013119644, time: 9.503997325897217


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.4765677839192595, Training Loss Force: 4.668010401678734, time: 0.6269879341125488
Validation Loss Energy: 2.8372610568654504, Validation Loss Force: 4.532936814997962, time: 0.060463666915893555
Test Loss Energy: 7.875351310649653, Test Loss Force: 8.999336894881392, time: 9.709058284759521


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.439369864897129, Training Loss Force: 4.618789643040914, time: 0.6500186920166016
Validation Loss Energy: 3.06238279210106, Validation Loss Force: 4.675439056324805, time: 0.06071305274963379
Test Loss Energy: 8.273333296169156, Test Loss Force: 9.016484746068695, time: 9.478854417800903


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.339487288576331, Training Loss Force: 4.648639254794918, time: 0.6258459091186523
Validation Loss Energy: 2.468344040572594, Validation Loss Force: 4.408386605554107, time: 0.05959630012512207
Test Loss Energy: 8.053046567874334, Test Loss Force: 9.029719649841718, time: 9.50166654586792


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.381836549738291, Training Loss Force: 4.630614231965891, time: 0.6336555480957031
Validation Loss Energy: 2.8800943617835575, Validation Loss Force: 4.705871693837048, time: 0.0616452693939209
Test Loss Energy: 8.150134668622364, Test Loss Force: 9.010796885405117, time: 9.65639877319336


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.379188824324436, Training Loss Force: 4.6051191491631105, time: 0.6838724613189697
Validation Loss Energy: 2.3933197912314252, Validation Loss Force: 4.800358005874316, time: 0.06099820137023926
Test Loss Energy: 7.966100608379869, Test Loss Force: 9.043330829497148, time: 9.518923997879028


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.4088655112197115, Training Loss Force: 4.660853815328616, time: 0.6220223903656006
Validation Loss Energy: 3.135714978602323, Validation Loss Force: 4.675190334888804, time: 0.06130671501159668
Test Loss Energy: 8.170197174991756, Test Loss Force: 9.032923212994515, time: 9.517369270324707


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.4529404248622395, Training Loss Force: 4.782182581170673, time: 0.650766134262085
Validation Loss Energy: 3.133911358520308, Validation Loss Force: 4.352960247088054, time: 0.060318946838378906
Test Loss Energy: 8.562905049431796, Test Loss Force: 9.101306222739288, time: 9.694952249526978


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.513986454349297, Training Loss Force: 4.653125648414357, time: 0.6853883266448975
Validation Loss Energy: 2.4813594974903648, Validation Loss Force: 4.855206983244978, time: 0.06089901924133301
Test Loss Energy: 7.598316870202634, Test Loss Force: 9.007762079817178, time: 9.54796576499939


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.446461262071414, Training Loss Force: 4.666065564824372, time: 0.6763150691986084
Validation Loss Energy: 2.418983634979906, Validation Loss Force: 5.030258554985254, time: 0.06369233131408691
Test Loss Energy: 7.993265549362059, Test Loss Force: 8.985709552477068, time: 9.521167516708374


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.411876159507786, Training Loss Force: 4.5719864701211765, time: 0.6397101879119873
Validation Loss Energy: 2.8992361149132395, Validation Loss Force: 4.520552402439749, time: 0.06580185890197754
Test Loss Energy: 8.160464542116276, Test Loss Force: 9.048584035324646, time: 9.658243417739868


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4025447023753745, Training Loss Force: 4.627085371341228, time: 0.6707484722137451
Validation Loss Energy: 2.5061425734321277, Validation Loss Force: 5.0666803245155165, time: 0.060021400451660156
Test Loss Energy: 7.89644890445325, Test Loss Force: 9.064241975779758, time: 10.166017532348633


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.308703295852, Training Loss Force: 4.637687217185173, time: 0.654991865158081
Validation Loss Energy: 2.842477749616246, Validation Loss Force: 5.095884496349676, time: 0.06048727035522461
Test Loss Energy: 7.863059155397892, Test Loss Force: 8.963036037028981, time: 9.515436172485352


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.24823427727288, Training Loss Force: 4.627122323285995, time: 0.6483573913574219
Validation Loss Energy: 2.611489684396596, Validation Loss Force: 4.794984331375641, time: 0.06169271469116211
Test Loss Energy: 7.597449407168838, Test Loss Force: 8.93314991120734, time: 9.75106430053711


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.501279085245196, Training Loss Force: 4.659607246648968, time: 0.6254329681396484
Validation Loss Energy: 2.318817255699166, Validation Loss Force: 4.526365403163341, time: 0.06000375747680664
Test Loss Energy: 7.9778588846261895, Test Loss Force: 8.991505231639557, time: 9.527429580688477


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.525666082876911, Training Loss Force: 4.6309287298676, time: 0.6548583507537842
Validation Loss Energy: 2.4525635895352647, Validation Loss Force: 4.77086770418764, time: 0.060547590255737305
Test Loss Energy: 8.080283586042999, Test Loss Force: 9.036474354523456, time: 9.52079725265503

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–‚â–‚â–„â–…â–‡â–†â–†â–…â–†â–ˆâ–„â–†â–†â–…â–…â–„â–…â–†
wandb:   test_error_force â–†â–ˆâ–„â–…â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–â–â–‚â–ƒ
wandb:          test_loss â–ƒâ–ˆâ–…â–…â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚
wandb: train_error_energy â–ˆâ–‚â–â–„â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–‡â–‡
wandb:  train_error_force â–„â–ˆâ–‡â–ˆâ–„â–‚â–â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–‡â–ƒâ–â–ˆâ–‡â–…â–…â–„â–…â–„â–…â–…â–…â–…â–„â–„â–„â–„â–…â–…
wandb: valid_error_energy â–â–‡â–â–…â–„â–‡â–ˆâ–…â–‡â–„â–ˆâ–ˆâ–…â–…â–‡â–…â–‡â–…â–„â–…
wandb:  valid_error_force â–ƒâ–ˆâ–„â–‡â–ƒâ–‚â–„â–â–„â–…â–„â–â–…â–‡â–‚â–‡â–‡â–…â–‚â–„
wandb:         valid_loss â–‚â–ˆâ–â–†â–„â–…â–†â–„â–†â–…â–†â–…â–†â–†â–…â–‡â–‡â–†â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1251
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.08028
wandb:   test_error_force 9.03647
wandb:          test_loss 5.06528
wandb: train_error_energy 4.52567
wandb:  train_error_force 4.63093
wandb:         train_loss 1.93879
wandb: valid_error_energy 2.45256
wandb:  valid_error_force 4.77087
wandb:         valid_loss 1.52892
wandb: 
wandb: ğŸš€ View run al_73_38 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/f8h53hwi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_121647-f8h53hwi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.512568473815918, Uncertainty Bias: -0.1394382119178772
0.00039672852 0.02152729
2.4144466 8.726939
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1933 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2283 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_125941-wdsgp62d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_39
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wdsgp62d
Training model 39. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.274984176462733, Training Loss Force: 5.4878858568034685, time: 0.6666252613067627
Validation Loss Energy: 4.307782013394181, Validation Loss Force: 5.01742101071508, time: 0.06268596649169922
Test Loss Energy: 7.097059857596111, Test Loss Force: 9.025295458731613, time: 9.331418991088867


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0307642966518067, Training Loss Force: 4.690464525355952, time: 0.6705062389373779
Validation Loss Energy: 2.746082272321794, Validation Loss Force: 4.917654990558718, time: 0.06091427803039551
Test Loss Energy: 7.810725386911858, Test Loss Force: 9.038834153168102, time: 9.35592794418335


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9889511671259537, Training Loss Force: 4.604040372818377, time: 0.6728975772857666
Validation Loss Energy: 2.774533154435279, Validation Loss Force: 4.555942100478637, time: 0.06008577346801758
Test Loss Energy: 8.012680102506486, Test Loss Force: 8.993242228180467, time: 9.49075984954834


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0447947853045614, Training Loss Force: 4.556411219835278, time: 0.6301991939544678
Validation Loss Energy: 3.752160146943491, Validation Loss Force: 4.601057096135065, time: 0.05831003189086914
Test Loss Energy: 7.192743892979641, Test Loss Force: 8.988387509191226, time: 9.583138227462769


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.076213426845251, Training Loss Force: 4.598705676553696, time: 0.6379351615905762
Validation Loss Energy: 2.254140330234689, Validation Loss Force: 4.899164990019166, time: 0.06184649467468262
Test Loss Energy: 7.639698839777917, Test Loss Force: 9.040623503771865, time: 10.010772705078125


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0512678553108827, Training Loss Force: 4.586318079826698, time: 0.7100841999053955
Validation Loss Energy: 2.8626374347465378, Validation Loss Force: 4.740141588741064, time: 0.05971050262451172
Test Loss Energy: 8.25012844783822, Test Loss Force: 8.980095300870417, time: 10.387575626373291


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1067794682261827, Training Loss Force: 4.598047589026364, time: 0.6429681777954102
Validation Loss Energy: 3.504117629168086, Validation Loss Force: 4.710714970430123, time: 0.059545278549194336
Test Loss Energy: 6.840053683765521, Test Loss Force: 9.010441309592633, time: 10.98859167098999


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1518662628352803, Training Loss Force: 4.582704293189778, time: 0.6692371368408203
Validation Loss Energy: 2.4045094724871614, Validation Loss Force: 4.696475278548041, time: 0.06596136093139648
Test Loss Energy: 7.771612621115619, Test Loss Force: 9.014010012838925, time: 10.035869121551514


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1054961090369, Training Loss Force: 4.606950224350818, time: 0.6771101951599121
Validation Loss Energy: 3.117138805103297, Validation Loss Force: 5.050210601136968, time: 0.06125998497009277
Test Loss Energy: 8.253432160811174, Test Loss Force: 9.026630340442729, time: 10.4102783203125


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.06472840001772, Training Loss Force: 4.60136815379847, time: 0.6610195636749268
Validation Loss Energy: 3.5289051584927673, Validation Loss Force: 4.762594432070692, time: 0.06615829467773438
Test Loss Energy: 7.057702300299426, Test Loss Force: 9.00377432023309, time: 10.418612718582153


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.981529532124708, Training Loss Force: 4.5967153261259055, time: 0.6600615978240967
Validation Loss Energy: 2.288242777940967, Validation Loss Force: 4.796030876361501, time: 0.07003426551818848
Test Loss Energy: 7.977930605075703, Test Loss Force: 9.03513273444761, time: 10.267168283462524


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0144423727022316, Training Loss Force: 4.566250100984157, time: 0.8412063121795654
Validation Loss Energy: 2.632600723452864, Validation Loss Force: 4.99056755705448, time: 0.06954145431518555
Test Loss Energy: 8.265742094620398, Test Loss Force: 9.017225989505157, time: 10.379648208618164


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0794035492483074, Training Loss Force: 4.558747130510633, time: 0.624401330947876
Validation Loss Energy: 3.0146906237496625, Validation Loss Force: 4.743248268665049, time: 0.061419010162353516
Test Loss Energy: 6.986833097441612, Test Loss Force: 9.05380868354273, time: 10.319868087768555


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1252003912299395, Training Loss Force: 4.576420536491324, time: 0.6876826286315918
Validation Loss Energy: 2.656282366464295, Validation Loss Force: 4.858382022596762, time: 0.06770133972167969
Test Loss Energy: 8.325024651345311, Test Loss Force: 8.995443677585566, time: 10.28168535232544


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0764881142870317, Training Loss Force: 4.5580791008059345, time: 0.6980926990509033
Validation Loss Energy: 3.0354104331165352, Validation Loss Force: 4.558475407351857, time: 0.06575751304626465
Test Loss Energy: 8.155163512552104, Test Loss Force: 9.016372320300336, time: 10.450774669647217


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.10313151300882, Training Loss Force: 4.655138711095032, time: 0.6276094913482666
Validation Loss Energy: 3.9502512952129156, Validation Loss Force: 4.903540884074939, time: 0.06058549880981445
Test Loss Energy: 7.214714342840433, Test Loss Force: 9.015770530702806, time: 10.099459171295166


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.1486996403772123, Training Loss Force: 4.663383904632677, time: 0.690192699432373
Validation Loss Energy: 2.2377645732357214, Validation Loss Force: 4.573267541384986, time: 0.06435680389404297
Test Loss Energy: 7.552391724918439, Test Loss Force: 9.044889919219493, time: 10.23174524307251


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.038382854678982, Training Loss Force: 4.553519760774289, time: 0.8047034740447998
Validation Loss Energy: 2.9316063079987726, Validation Loss Force: 4.455050710458756, time: 0.06265974044799805
Test Loss Energy: 7.8924717677029745, Test Loss Force: 9.017536984856173, time: 10.571792125701904


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.159135761925935, Training Loss Force: 4.645434277576463, time: 0.6903998851776123
Validation Loss Energy: 3.1090696092585928, Validation Loss Force: 4.498933455061621, time: 0.06650209426879883
Test Loss Energy: 7.110851380606828, Test Loss Force: 9.08908585555385, time: 10.114166975021362


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.102830954195647, Training Loss Force: 4.648594386962013, time: 0.6745541095733643
Validation Loss Energy: 2.6268692196366827, Validation Loss Force: 4.92088703321186, time: 0.06676125526428223
Test Loss Energy: 8.017136155123179, Test Loss Force: 8.994668593102155, time: 10.35309648513794

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‡â–ƒâ–…â–ˆâ–â–…â–ˆâ–‚â–†â–ˆâ–‚â–ˆâ–‡â–ƒâ–„â–†â–‚â–‡
wandb:   test_error_force â–„â–…â–‚â–‚â–…â–â–ƒâ–ƒâ–„â–ƒâ–…â–ƒâ–†â–‚â–ƒâ–ƒâ–…â–ƒâ–ˆâ–‚
wandb:          test_loss â–â–†â–†â–…â–†â–‡â–„â–…â–‡â–…â–†â–ˆâ–„â–‡â–‡â–…â–…â–†â–…â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–‚â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–ƒâ–†â–â–ƒâ–…â–‚â–„â–…â–â–‚â–„â–‚â–„â–‡â–â–ƒâ–„â–‚
wandb:  valid_error_force â–ˆâ–†â–‚â–ƒâ–†â–„â–„â–„â–ˆâ–…â–…â–‡â–„â–†â–‚â–†â–‚â–â–‚â–†
wandb:         valid_loss â–‡â–ƒâ–‚â–‡â–‚â–ƒâ–…â–‚â–„â–†â–‚â–ƒâ–„â–ƒâ–ƒâ–ˆâ–â–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1252
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.01714
wandb:   test_error_force 8.99467
wandb:          test_loss 5.70414
wandb: train_error_energy 3.10283
wandb:  train_error_force 4.64859
wandb:         train_loss 1.55868
wandb: valid_error_energy 2.62687
wandb:  valid_error_force 4.92089
wandb:         valid_loss 1.48171
wandb: 
wandb: ğŸš€ View run al_73_39 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wdsgp62d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_125941-wdsgp62d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5445618629455566, Uncertainty Bias: -0.05416470766067505
0.00012207031 0.01550293
2.4107282 9.280437
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1070 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1819 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1695 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3093 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 565 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 661 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 758 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3269 steps.
Found uncertainty sample 90 after 3127 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3847 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_134115-5ss2gai3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_40
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5ss2gai3
Training model 40. Added 10 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.32454529383913, Training Loss Force: 5.117224517222158, time: 0.6340000629425049
Validation Loss Energy: 4.215658443664354, Validation Loss Force: 5.161636468450693, time: 0.0581812858581543
Test Loss Energy: 7.41730097948152, Test Loss Force: 9.07634964206637, time: 8.65636420249939


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.454949691033977, Training Loss Force: 4.659835437989715, time: 0.6391911506652832
Validation Loss Energy: 3.127834940197084, Validation Loss Force: 4.826396045122528, time: 0.06411433219909668
Test Loss Energy: 7.180035689172267, Test Loss Force: 9.00499257927048, time: 8.720319271087646


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.465727105932757, Training Loss Force: 4.637041287393208, time: 0.6370961666107178
Validation Loss Energy: 3.065526991776133, Validation Loss Force: 5.06160970272445, time: 0.058231353759765625
Test Loss Energy: 7.306865528207585, Test Loss Force: 9.006709379370111, time: 8.853108406066895


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.40580172850669, Training Loss Force: 4.6699276275590025, time: 0.6503257751464844
Validation Loss Energy: 2.808432750549617, Validation Loss Force: 4.208877834167133, time: 0.056891441345214844
Test Loss Energy: 7.0026749229738225, Test Loss Force: 8.955728091618372, time: 8.652782201766968


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.515282099308708, Training Loss Force: 4.781610967206163, time: 0.6471595764160156
Validation Loss Energy: 3.562599008316268, Validation Loss Force: 4.810448035552888, time: 0.05854463577270508
Test Loss Energy: 7.078343909661216, Test Loss Force: 9.00297899267612, time: 8.646960258483887


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.478781635718909, Training Loss Force: 4.643652980076327, time: 0.6367754936218262
Validation Loss Energy: 3.3739745274513906, Validation Loss Force: 4.50389897701581, time: 0.05973005294799805
Test Loss Energy: 6.971320509809089, Test Loss Force: 9.004964665186554, time: 8.612759113311768


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.432819681782208, Training Loss Force: 4.647533268280552, time: 0.6580259799957275
Validation Loss Energy: 3.545301289718587, Validation Loss Force: 4.681863283853968, time: 0.06318378448486328
Test Loss Energy: 7.078658055022873, Test Loss Force: 9.010524576195138, time: 8.890375137329102


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.295639029857442, Training Loss Force: 4.6395278003454115, time: 0.7028200626373291
Validation Loss Energy: 3.861222381273192, Validation Loss Force: 4.848407335535782, time: 0.06359601020812988
Test Loss Energy: 7.003763786755479, Test Loss Force: 8.965964987337076, time: 8.709332704544067


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.415574326617556, Training Loss Force: 4.625255854837542, time: 0.6343748569488525
Validation Loss Energy: 3.6377772333718457, Validation Loss Force: 4.650694724814434, time: 0.05632758140563965
Test Loss Energy: 7.024766831275971, Test Loss Force: 8.934881479750638, time: 8.701980590820312


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.4774639075469524, Training Loss Force: 4.591681767614178, time: 0.6841611862182617
Validation Loss Energy: 3.5559988721618225, Validation Loss Force: 4.811077075890134, time: 0.06135153770446777
Test Loss Energy: 7.0302605221126875, Test Loss Force: 8.974712447972864, time: 8.893255233764648


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.514517489645327, Training Loss Force: 4.626576628010071, time: 0.6556744575500488
Validation Loss Energy: 3.153001229738989, Validation Loss Force: 4.674990377995761, time: 0.05705714225769043
Test Loss Energy: 7.110606484183748, Test Loss Force: 8.947353470065815, time: 9.28534460067749


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.504578535415539, Training Loss Force: 4.630706249990447, time: 0.678166389465332
Validation Loss Energy: 3.1971721082166837, Validation Loss Force: 4.686271910274192, time: 0.06711959838867188
Test Loss Energy: 7.03961896823199, Test Loss Force: 8.92338445853188, time: 11.305601596832275


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.50648511771063, Training Loss Force: 4.6141040830039, time: 0.6661262512207031
Validation Loss Energy: 3.354996213474819, Validation Loss Force: 4.84627928650815, time: 0.06508612632751465
Test Loss Energy: 7.027798957839318, Test Loss Force: 8.902260552463238, time: 10.110008239746094


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.601255243841298, Training Loss Force: 4.669167145624914, time: 0.6782684326171875
Validation Loss Energy: 3.657244862796593, Validation Loss Force: 4.8421374177247465, time: 0.06362748146057129
Test Loss Energy: 7.133243684742327, Test Loss Force: 8.939398543713315, time: 9.542119264602661


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.338745652802082, Training Loss Force: 4.619048829926775, time: 0.6286787986755371
Validation Loss Energy: 3.712308604558503, Validation Loss Force: 4.471019650928113, time: 0.06206560134887695
Test Loss Energy: 6.866202199552711, Test Loss Force: 8.900131401747947, time: 9.439285278320312


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.523053656089414, Training Loss Force: 4.633360148906373, time: 0.638979434967041
Validation Loss Energy: 3.916303157224765, Validation Loss Force: 4.879045274000569, time: 0.0603940486907959
Test Loss Energy: 6.967263729784607, Test Loss Force: 8.892023903895623, time: 9.435366868972778


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.584139306767623, Training Loss Force: 4.581048191416939, time: 0.630481481552124
Validation Loss Energy: 3.348436380435787, Validation Loss Force: 4.644301893634847, time: 0.05772757530212402
Test Loss Energy: 7.296294300012398, Test Loss Force: 8.919367866207912, time: 9.21248173713684


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.373760612585195, Training Loss Force: 4.629978979159475, time: 0.6331615447998047
Validation Loss Energy: 3.5242936804806027, Validation Loss Force: 4.672735630224096, time: 0.05788230895996094
Test Loss Energy: 7.223320675538371, Test Loss Force: 8.95352578884251, time: 9.248526334762573


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.407206013742398, Training Loss Force: 4.582766807552496, time: 0.6346597671508789
Validation Loss Energy: 3.418461930120022, Validation Loss Force: 5.04439470571448, time: 0.05859231948852539
Test Loss Energy: 6.943184766324864, Test Loss Force: 8.887707195532, time: 9.414668083190918


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.524798769853336, Training Loss Force: 4.713448267596759, time: 0.6393721103668213
Validation Loss Energy: 3.1756347690805375, Validation Loss Force: 4.688045915359799, time: 0.06001639366149902
Test Loss Energy: 7.242767780347156, Test Loss Force: 8.982620951888764, time: 9.204533338546753

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–‡â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–â–‚â–†â–†â–‚â–†
wandb:   test_error_force â–ˆâ–…â–…â–„â–…â–…â–†â–„â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–â–â–‚â–ƒâ–â–…
wandb:          test_loss â–ˆâ–‡â–‡â–ƒâ–„â–„â–†â–„â–ƒâ–„â–…â–…â–ƒâ–„â–â–â–„â–…â–‚â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–ƒ
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–â–…â–„â–…â–†â–…â–…â–ƒâ–ƒâ–„â–…â–…â–‡â–„â–…â–„â–ƒ
wandb:  valid_error_force â–ˆâ–†â–‡â–â–…â–ƒâ–„â–†â–„â–…â–„â–…â–†â–†â–ƒâ–†â–„â–„â–‡â–…
wandb:         valid_loss â–ˆâ–„â–…â–â–…â–ƒâ–…â–†â–…â–…â–„â–„â–…â–†â–„â–†â–„â–„â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1261
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.24277
wandb:   test_error_force 8.98262
wandb:          test_loss 4.6582
wandb: train_error_energy 4.5248
wandb:  train_error_force 4.71345
wandb:         train_loss 1.96466
wandb: valid_error_energy 3.17563
wandb:  valid_error_force 4.68805
wandb:         valid_loss 1.64159
wandb: 
wandb: ğŸš€ View run al_73_40 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/5ss2gai3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_134115-5ss2gai3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.887625217437744, Uncertainty Bias: -0.20762324333190918
0.00037002563 0.01613617
2.2066388 9.765151
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2525 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3802 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3675 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3921 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3122 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_142356-gi8a1e5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_41
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/gi8a1e5t
Training model 41. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.575867390149102, Training Loss Force: 4.931674139785216, time: 0.6997137069702148
Validation Loss Energy: 7.100158425834665, Validation Loss Force: 4.91450310879811, time: 0.0664358139038086
Test Loss Energy: 8.23419107742369, Test Loss Force: 9.163910546125084, time: 9.426333665847778


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.380787288188851, Training Loss Force: 4.995658898209577, time: 0.6385664939880371
Validation Loss Energy: 5.328393391836013, Validation Loss Force: 5.0034373883508145, time: 0.05962800979614258
Test Loss Energy: 7.434237509488691, Test Loss Force: 8.953172423400186, time: 9.46657133102417


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.443956145112066, Training Loss Force: 4.610886914649706, time: 0.6372551918029785
Validation Loss Energy: 5.199067819888592, Validation Loss Force: 4.810639531018386, time: 0.06304645538330078
Test Loss Energy: 7.538352036561683, Test Loss Force: 8.912160362069221, time: 9.570298671722412


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.413356358222069, Training Loss Force: 4.574738504896442, time: 0.6955657005310059
Validation Loss Energy: 5.306956810488399, Validation Loss Force: 4.950734050870313, time: 0.05987834930419922
Test Loss Energy: 7.588473520631925, Test Loss Force: 8.901326568479353, time: 10.121233701705933


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.402560264165311, Training Loss Force: 4.577151982368781, time: 0.685797929763794
Validation Loss Energy: 5.985917120890804, Validation Loss Force: 4.908352764318439, time: 0.05878138542175293
Test Loss Energy: 7.583616281167851, Test Loss Force: 8.88580124557065, time: 9.518285512924194


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.30907441295079, Training Loss Force: 4.582933263872535, time: 0.6267869472503662
Validation Loss Energy: 5.5184896044209, Validation Loss Force: 5.223119427685981, time: 0.059613943099975586
Test Loss Energy: 7.679558062499728, Test Loss Force: 8.892160293993635, time: 9.600340127944946


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.397999062062932, Training Loss Force: 4.561849401585528, time: 0.6644196510314941
Validation Loss Energy: 5.694561223518671, Validation Loss Force: 4.958939631566897, time: 0.06052446365356445
Test Loss Energy: 7.603975991390896, Test Loss Force: 8.889972866915693, time: 9.522537469863892


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.3927925118917335, Training Loss Force: 4.576388911905873, time: 0.67649245262146
Validation Loss Energy: 5.659737327779586, Validation Loss Force: 4.814124971159593, time: 0.06157493591308594
Test Loss Energy: 7.607075149527814, Test Loss Force: 8.879191296818295, time: 9.430694818496704


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.337051026483635, Training Loss Force: 4.591665646368012, time: 0.6303718090057373
Validation Loss Energy: 5.598089148038019, Validation Loss Force: 4.742255386943357, time: 0.06536698341369629
Test Loss Energy: 7.787529251822788, Test Loss Force: 8.872022548769062, time: 9.607759952545166


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.368807799472508, Training Loss Force: 4.588610035612648, time: 0.6409139633178711
Validation Loss Energy: 5.415209865141797, Validation Loss Force: 4.596535576457857, time: 0.06409835815429688
Test Loss Energy: 7.550045281759321, Test Loss Force: 8.941145305054047, time: 9.368425130844116


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.412602367093586, Training Loss Force: 4.577721414175663, time: 0.6516497135162354
Validation Loss Energy: 5.977064686325299, Validation Loss Force: 4.737965665847058, time: 0.05985069274902344
Test Loss Energy: 7.777423653956915, Test Loss Force: 8.884338353582573, time: 9.378998517990112


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.416370936620569, Training Loss Force: 4.599237187805026, time: 0.6701920032501221
Validation Loss Energy: 5.957089705251555, Validation Loss Force: 5.141537015324374, time: 0.05912446975708008
Test Loss Energy: 7.693795467068386, Test Loss Force: 8.930728851734003, time: 9.6294686794281


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.501288064378505, Training Loss Force: 4.580969644875713, time: 0.6594874858856201
Validation Loss Energy: 5.66661758171961, Validation Loss Force: 4.333113300773219, time: 0.05944085121154785
Test Loss Energy: 7.592819469767894, Test Loss Force: 8.874284410295326, time: 9.46501350402832


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.450217364909589, Training Loss Force: 4.557139732046738, time: 0.6415624618530273
Validation Loss Energy: 5.477938212910261, Validation Loss Force: 4.613587134314715, time: 0.06197333335876465
Test Loss Energy: 7.5775282572354765, Test Loss Force: 8.93482555831822, time: 9.430806636810303


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.5241533076665785, Training Loss Force: 4.577902065653754, time: 0.6475462913513184
Validation Loss Energy: 5.710357150061643, Validation Loss Force: 4.664837110279746, time: 0.05936145782470703
Test Loss Energy: 7.625152885721429, Test Loss Force: 8.883530952927826, time: 9.599757432937622


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.400064059538531, Training Loss Force: 4.567575438874177, time: 0.6900174617767334
Validation Loss Energy: 4.893396300455615, Validation Loss Force: 4.781635538746416, time: 0.06627702713012695
Test Loss Energy: 7.519793199779249, Test Loss Force: 8.923861987087909, time: 9.440516233444214


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.478651468902929, Training Loss Force: 4.5783799804416585, time: 0.6276578903198242
Validation Loss Energy: 5.48588928277305, Validation Loss Force: 4.877715271191943, time: 0.05939769744873047
Test Loss Energy: 7.605882731769425, Test Loss Force: 8.911313132782528, time: 9.372660398483276


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.408428422819712, Training Loss Force: 4.5897211880511986, time: 0.637345552444458
Validation Loss Energy: 5.597789880705893, Validation Loss Force: 4.881319839326222, time: 0.059250831604003906
Test Loss Energy: 7.520993838808934, Test Loss Force: 8.879406201689289, time: 9.614344120025635


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.425177579276214, Training Loss Force: 4.566323425933911, time: 0.6496219635009766
Validation Loss Energy: 5.291585514006711, Validation Loss Force: 4.226172769400491, time: 0.06017160415649414
Test Loss Energy: 7.627451815248549, Test Loss Force: 8.893118009145763, time: 10.161581754684448


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.452785564037976, Training Loss Force: 4.575915823471706, time: 0.6441669464111328
Validation Loss Energy: 5.474690138078612, Validation Loss Force: 4.787506878786239, time: 0.05977463722229004
Test Loss Energy: 7.506687290224336, Test Loss Force: 8.921004151009667, time: 9.57167911529541

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–„â–‚â–„â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚
wandb:   test_error_force â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–ƒâ–â–‚â–â–ƒâ–â–‚â–‚â–â–‚â–‚
wandb:          test_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: train_error_energy â–ˆâ–ƒâ–…â–„â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–„â–„â–†â–…â–‡â–ƒâ–…â–„â–„â–…
wandb:  train_error_force â–‡â–ˆâ–‚â–â–â–â–â–â–‚â–‚â–â–‚â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–‚â–‚â–„â–ƒâ–„â–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–„â–â–ƒâ–ƒâ–‚â–ƒ
wandb:  valid_error_force â–†â–†â–…â–†â–†â–ˆâ–†â–…â–…â–„â–…â–‡â–‚â–„â–„â–…â–†â–†â–â–…
wandb:         valid_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1265
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.50669
wandb:   test_error_force 8.921
wandb:          test_loss 4.85679
wandb: train_error_energy 4.45279
wandb:  train_error_force 4.57592
wandb:         train_loss 1.88728
wandb: valid_error_energy 5.47469
wandb:  valid_error_force 4.78751
wandb:         valid_loss 2.23892
wandb: 
wandb: ğŸš€ View run al_73_41 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/gi8a1e5t
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_142356-gi8a1e5t/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.8664391040802, Uncertainty Bias: -0.18247869610786438
4.7683716e-06 0.012765884
2.2194712 9.274131
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3660 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3281 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2706 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3344 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1323 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1282 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1653 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1912 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1557 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_150558-v9ezlhpk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_42
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v9ezlhpk
Training model 42. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.260956975562179, Training Loss Force: 4.962144942789071, time: 0.7064599990844727
Validation Loss Energy: 3.3421286088699445, Validation Loss Force: 4.481886127918536, time: 0.06705212593078613
Test Loss Energy: 8.507833189572516, Test Loss Force: 9.016137848523869, time: 10.366524696350098


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.398716073413006, Training Loss Force: 4.6674982626431, time: 0.6787009239196777
Validation Loss Energy: 3.423410640553694, Validation Loss Force: 4.6652232185787845, time: 0.07101750373840332
Test Loss Energy: 8.596542348287075, Test Loss Force: 8.904614204973134, time: 10.477572441101074


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.37166350343539, Training Loss Force: 4.573444463154883, time: 0.7061061859130859
Validation Loss Energy: 3.8381471776806952, Validation Loss Force: 4.628814363858986, time: 0.07055068016052246
Test Loss Energy: 9.059497346281557, Test Loss Force: 8.869436858687811, time: 10.65578579902649


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.4398633999256205, Training Loss Force: 4.570576362087302, time: 0.6729145050048828
Validation Loss Energy: 4.4009234037900455, Validation Loss Force: 4.606375326016405, time: 0.07021546363830566
Test Loss Energy: 8.948004992991956, Test Loss Force: 8.896036560455, time: 10.590150833129883


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.476226078631282, Training Loss Force: 4.579393225256746, time: 0.6691873073577881
Validation Loss Energy: 3.9813979213415758, Validation Loss Force: 4.48649426589351, time: 0.06289958953857422
Test Loss Energy: 9.488472011360486, Test Loss Force: 8.923997141430453, time: 10.417287826538086


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.442057832192382, Training Loss Force: 4.6343990507737995, time: 0.6586763858795166
Validation Loss Energy: 3.7039231071920087, Validation Loss Force: 4.68343688670824, time: 0.0626213550567627
Test Loss Energy: 8.90678158949633, Test Loss Force: 8.857071917438892, time: 10.864604711532593


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.487119181284828, Training Loss Force: 4.585198777697405, time: 0.7049851417541504
Validation Loss Energy: 3.643036789933233, Validation Loss Force: 4.596666505915662, time: 0.06936836242675781
Test Loss Energy: 8.35082133589225, Test Loss Force: 8.818157562675554, time: 10.558047771453857


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.480233627819132, Training Loss Force: 4.568231644847225, time: 0.6762077808380127
Validation Loss Energy: 3.947136153861386, Validation Loss Force: 4.677428827812816, time: 0.06555986404418945
Test Loss Energy: 8.624930043658626, Test Loss Force: 8.861103105667086, time: 9.765461206436157


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.5035992977457635, Training Loss Force: 4.564043505415299, time: 0.6616389751434326
Validation Loss Energy: 4.08085899610259, Validation Loss Force: 4.340366080194379, time: 0.06830954551696777
Test Loss Energy: 8.926803080442202, Test Loss Force: 8.873037831473157, time: 10.987915992736816


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.468107483636554, Training Loss Force: 4.570583877170978, time: 0.7103662490844727
Validation Loss Energy: 3.9221085871973944, Validation Loss Force: 4.8486598423472635, time: 0.06857967376708984
Test Loss Energy: 8.606314441399471, Test Loss Force: 8.839274758358835, time: 9.411602973937988


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.563348972515508, Training Loss Force: 4.573317831211594, time: 0.6528546810150146
Validation Loss Energy: 3.816775393054546, Validation Loss Force: 4.661291772138283, time: 0.059037208557128906
Test Loss Energy: 8.745580221664468, Test Loss Force: 8.825752776932166, time: 9.133527040481567


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.414193900380834, Training Loss Force: 4.60475717819949, time: 0.6386163234710693
Validation Loss Energy: 4.303087925128878, Validation Loss Force: 4.407796309648253, time: 0.05990481376647949
Test Loss Energy: 8.38230309715554, Test Loss Force: 8.811813240727181, time: 9.68800163269043


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.385639802768117, Training Loss Force: 4.568431913477073, time: 0.683570384979248
Validation Loss Energy: 3.9935920631145922, Validation Loss Force: 4.836516357804946, time: 0.06266069412231445
Test Loss Energy: 9.509313050670537, Test Loss Force: 8.957440424345398, time: 8.988852262496948


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.4645638377806005, Training Loss Force: 4.600153894411896, time: 0.6290755271911621
Validation Loss Energy: 3.7962552065769977, Validation Loss Force: 4.866763957256922, time: 0.05843830108642578
Test Loss Energy: 8.34270949191126, Test Loss Force: 8.808730044820345, time: 9.140301704406738


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.405211705370539, Training Loss Force: 4.564548563572092, time: 0.672154426574707
Validation Loss Energy: 4.10767192397863, Validation Loss Force: 5.150126254959393, time: 0.06246018409729004
Test Loss Energy: 8.716035453472568, Test Loss Force: 8.824138847646342, time: 9.055760145187378


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.544947967266855, Training Loss Force: 4.551458022618315, time: 0.6595597267150879
Validation Loss Energy: 3.768998944431415, Validation Loss Force: 4.600929061376157, time: 0.060302734375
Test Loss Energy: 8.892847070924873, Test Loss Force: 8.861939390357223, time: 8.896732330322266


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.508833698260389, Training Loss Force: 4.589564885444214, time: 0.6297662258148193
Validation Loss Energy: 4.031986903946921, Validation Loss Force: 4.933016712267131, time: 0.059212446212768555
Test Loss Energy: 8.652379949852094, Test Loss Force: 8.86068897369826, time: 9.187901020050049


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.520047806321434, Training Loss Force: 4.56495539123516, time: 0.6609129905700684
Validation Loss Energy: 3.935935895821218, Validation Loss Force: 4.880046839818952, time: 0.0603635311126709
Test Loss Energy: 8.73631209294869, Test Loss Force: 8.847489100095375, time: 8.906551122665405


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.519726923381966, Training Loss Force: 4.56228643431824, time: 0.639981746673584
Validation Loss Energy: 3.728540183285482, Validation Loss Force: 4.765532996789501, time: 0.0589146614074707
Test Loss Energy: 8.461286303068995, Test Loss Force: 8.891062868525028, time: 8.944065570831299


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.517685203182211, Training Loss Force: 4.578621598731905, time: 0.6535491943359375
Validation Loss Energy: 3.961518353996862, Validation Loss Force: 4.680876636868362, time: 0.0597231388092041
Test Loss Energy: 8.66520416311869, Test Loss Force: 8.854310125208388, time: 8.965110301971436

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–…â–…â–ˆâ–„â–â–ƒâ–…â–ƒâ–ƒâ–â–ˆâ–â–ƒâ–„â–ƒâ–ƒâ–‚â–ƒ
wandb:   test_error_force â–ˆâ–„â–ƒâ–„â–…â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–â–†â–â–‚â–ƒâ–ƒâ–‚â–„â–ƒ
wandb:          test_loss â–â–„â–…â–…â–‡â–„â–‚â–‚â–…â–‚â–ƒâ–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–„â–ˆâ–…â–ƒâ–ƒâ–…â–†â–…â–„â–‡â–…â–„â–†â–„â–†â–…â–„â–…
wandb:  valid_error_force â–‚â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–â–…â–„â–‚â–…â–†â–ˆâ–ƒâ–†â–†â–…â–„
wandb:         valid_loss â–â–‚â–ƒâ–…â–ƒâ–„â–ƒâ–„â–‚â–…â–„â–„â–…â–…â–ˆâ–„â–†â–…â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1273
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.6652
wandb:   test_error_force 8.85431
wandb:          test_loss 5.07853
wandb: train_error_energy 4.51769
wandb:  train_error_force 4.57862
wandb:         train_loss 1.90508
wandb: valid_error_energy 3.96152
wandb:  valid_error_force 4.68088
wandb:         valid_loss 1.7939
wandb: 
wandb: ğŸš€ View run al_73_42 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/v9ezlhpk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_150558-v9ezlhpk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6375443935394287, Uncertainty Bias: -0.19069066643714905
0.00040245056 0.1693039
2.3963249 8.769502
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3028 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3763 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_154906-svy01004
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_43
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svy01004
Training model 43. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.476967879222959, Training Loss Force: 5.0311960477568975, time: 0.6437749862670898
Validation Loss Energy: 6.427483620083509, Validation Loss Force: 4.391614052137097, time: 0.0635371208190918
Test Loss Energy: 9.933681532832907, Test Loss Force: 8.887903330909545, time: 10.130818605422974


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.402427723139562, Training Loss Force: 4.57670069881073, time: 0.6927070617675781
Validation Loss Energy: 5.998254772928371, Validation Loss Force: 4.741985066600201, time: 0.06598877906799316
Test Loss Energy: 9.833844689898456, Test Loss Force: 8.849462032666404, time: 10.040964126586914


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.374137112710587, Training Loss Force: 4.5542600800172135, time: 0.6654832363128662
Validation Loss Energy: 6.064872705337901, Validation Loss Force: 4.479846701210983, time: 0.07148623466491699
Test Loss Energy: 10.519512005987282, Test Loss Force: 8.950499498309242, time: 10.362935781478882


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.360296794641912, Training Loss Force: 4.546157283398388, time: 0.6802752017974854
Validation Loss Energy: 6.552603862540938, Validation Loss Force: 4.848287762204418, time: 0.06072282791137695
Test Loss Energy: 10.217785208039649, Test Loss Force: 8.835151378109385, time: 10.197885274887085


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.405026689577188, Training Loss Force: 4.591367169511354, time: 0.6944308280944824
Validation Loss Energy: 6.1442092766936796, Validation Loss Force: 4.784646248268505, time: 0.06979894638061523
Test Loss Energy: 10.07820906662267, Test Loss Force: 8.908819438866947, time: 10.686914443969727


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.488625248587139, Training Loss Force: 4.556973593030233, time: 0.6342113018035889
Validation Loss Energy: 6.07642500329778, Validation Loss Force: 4.468343167794061, time: 0.057851552963256836
Test Loss Energy: 10.531358372945668, Test Loss Force: 8.901331483521862, time: 10.076335906982422


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.380757979362518, Training Loss Force: 4.551730185548654, time: 0.663017749786377
Validation Loss Energy: 6.092815679129524, Validation Loss Force: 4.752352096696306, time: 0.06712937355041504
Test Loss Energy: 10.177944447038229, Test Loss Force: 8.870591478650132, time: 10.970616102218628


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.532171548460601, Training Loss Force: 4.581303726528807, time: 0.6567196846008301
Validation Loss Energy: 6.149426414782768, Validation Loss Force: 4.496993116124006, time: 0.05794548988342285
Test Loss Energy: 10.19870605758257, Test Loss Force: 8.867613541129932, time: 8.768532514572144


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.491738959289408, Training Loss Force: 4.565303278375301, time: 0.6575808525085449
Validation Loss Energy: 6.4466759191093175, Validation Loss Force: 5.098993625634265, time: 0.062381744384765625
Test Loss Energy: 10.458778947471583, Test Loss Force: 8.853550704508455, time: 8.970155715942383


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.387965406645381, Training Loss Force: 4.5529498836291165, time: 0.6554663181304932
Validation Loss Energy: 6.1295095503561114, Validation Loss Force: 5.094525323882933, time: 0.06327128410339355
Test Loss Energy: 10.442549164670359, Test Loss Force: 8.857960495569921, time: 8.78027606010437


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.547539780458168, Training Loss Force: 4.54342263908342, time: 0.6637873649597168
Validation Loss Energy: 5.7844088919079715, Validation Loss Force: 4.802076566342587, time: 0.05857491493225098
Test Loss Energy: 10.20063767861509, Test Loss Force: 8.8582106031505, time: 8.806766271591187


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.454370723420921, Training Loss Force: 4.560268829186988, time: 0.6433711051940918
Validation Loss Energy: 6.205631669921276, Validation Loss Force: 4.528307300784977, time: 0.05752730369567871
Test Loss Energy: 9.886529776669642, Test Loss Force: 8.843195992329605, time: 8.937861442565918


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.52923190101307, Training Loss Force: 4.555580463518735, time: 0.6464383602142334
Validation Loss Energy: 6.144686456673403, Validation Loss Force: 4.801700255485969, time: 0.06173563003540039
Test Loss Energy: 10.565596726940033, Test Loss Force: 8.879223295890112, time: 9.02547550201416


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.450395233023356, Training Loss Force: 4.567296935439908, time: 0.6749222278594971
Validation Loss Energy: 6.214825233618343, Validation Loss Force: 5.069925281979122, time: 0.05975079536437988
Test Loss Energy: 10.24765790842734, Test Loss Force: 8.882183755631067, time: 8.856651306152344


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.439792435268814, Training Loss Force: 4.5626720527451585, time: 0.6677894592285156
Validation Loss Energy: 6.515493822680613, Validation Loss Force: 4.853310955467403, time: 0.06066441535949707
Test Loss Energy: 10.264102899209393, Test Loss Force: 8.836212826772533, time: 9.042688608169556


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.388213872011865, Training Loss Force: 4.595129498735522, time: 0.699800968170166
Validation Loss Energy: 5.799382501295032, Validation Loss Force: 4.703654799820191, time: 0.061615943908691406
Test Loss Energy: 10.248889993936306, Test Loss Force: 8.86511798192308, time: 8.872473239898682


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.5514438497271765, Training Loss Force: 4.5657583695757475, time: 0.6649227142333984
Validation Loss Energy: 5.7198125726743205, Validation Loss Force: 4.811887368912165, time: 0.058982133865356445
Test Loss Energy: 9.663678676241227, Test Loss Force: 8.87886329001085, time: 8.822917222976685


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.380520725387532, Training Loss Force: 4.544486006723256, time: 0.6250977516174316
Validation Loss Energy: 5.590174150576871, Validation Loss Force: 4.525199730184409, time: 0.05977773666381836
Test Loss Energy: 10.045084506027848, Test Loss Force: 8.906180228915794, time: 9.044050931930542


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.553982684361944, Training Loss Force: 4.542445388735771, time: 0.6756980419158936
Validation Loss Energy: 6.184706782271004, Validation Loss Force: 4.762875440532854, time: 0.05780196189880371
Test Loss Energy: 10.279388900584314, Test Loss Force: 8.882894039895593, time: 8.836073160171509


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.525296140357867, Training Loss Force: 4.557149017350122, time: 0.660024881362915
Validation Loss Energy: 6.251584569573831, Validation Loss Force: 4.619676022110109, time: 0.05748248100280762
Test Loss Energy: 10.173826406185055, Test Loss Force: 8.8035784274189, time: 10.779566049575806

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–ˆâ–…â–„â–ˆâ–…â–…â–‡â–‡â–…â–ƒâ–ˆâ–†â–†â–†â–â–„â–†â–…
wandb:   test_error_force â–…â–ƒâ–ˆâ–ƒâ–†â–†â–„â–„â–ƒâ–„â–„â–ƒâ–…â–…â–ƒâ–„â–…â–†â–…â–
wandb:          test_loss â–„â–‚â–ˆâ–†â–„â–‡â–„â–…â–†â–‡â–ƒâ–‚â–‡â–†â–†â–†â–â–…â–„â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–„â–„â–ˆâ–…â–…â–…â–…â–‡â–…â–‚â–…â–…â–†â–ˆâ–ƒâ–‚â–â–…â–†
wandb:  valid_error_force â–â–„â–‚â–†â–…â–‚â–…â–‚â–ˆâ–ˆâ–…â–‚â–…â–ˆâ–†â–„â–…â–‚â–…â–ƒ
wandb:         valid_loss â–„â–…â–‚â–‡â–…â–‚â–…â–…â–ˆâ–‡â–ƒâ–„â–†â–‡â–ˆâ–ƒâ–ƒâ–â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1274
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 10.17383
wandb:   test_error_force 8.80358
wandb:          test_loss 5.6733
wandb: train_error_energy 4.5253
wandb:  train_error_force 4.55715
wandb:         train_loss 1.90431
wandb: valid_error_energy 6.25158
wandb:  valid_error_force 4.61968
wandb:         valid_loss 2.347
wandb: 
wandb: ğŸš€ View run al_73_43 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svy01004
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_154906-svy01004/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6835432052612305, Uncertainty Bias: -0.20429280400276184
0.00010681152 0.23382568
2.4488306 8.730128
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3340 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2961 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2531 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2509 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_163158-6zcmjoyi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_44
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6zcmjoyi
Training model 44. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.432737915487392, Training Loss Force: 4.867135391659245, time: 0.6571457386016846
Validation Loss Energy: 1.6284669174769757, Validation Loss Force: 4.729283127839896, time: 0.05894184112548828
Test Loss Energy: 6.534897470865924, Test Loss Force: 8.980107238734579, time: 9.285882472991943


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.1965191114627003, Training Loss Force: 4.7602810555129045, time: 0.6488316059112549
Validation Loss Energy: 6.35762696494646, Validation Loss Force: 5.106213004683536, time: 0.06083822250366211
Test Loss Energy: 7.916669941928086, Test Loss Force: 9.066380373676544, time: 9.241744756698608


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.755873920377026, Training Loss Force: 5.057149584064229, time: 0.6756742000579834
Validation Loss Energy: 2.2170281750174774, Validation Loss Force: 5.430481405846109, time: 0.05878281593322754
Test Loss Energy: 7.355909403197397, Test Loss Force: 9.388689364464025, time: 9.506455659866333


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.36602610795037, Training Loss Force: 4.893801090695997, time: 0.6385998725891113
Validation Loss Energy: 2.3734087162025626, Validation Loss Force: 5.195748936268538, time: 0.06250286102294922
Test Loss Energy: 7.692244484368242, Test Loss Force: 8.883805952820465, time: 9.275370597839355


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9663864130669464, Training Loss Force: 4.742041023356572, time: 0.6421489715576172
Validation Loss Energy: 3.3283027475955693, Validation Loss Force: 4.597894971593745, time: 0.060384273529052734
Test Loss Energy: 8.682249288052263, Test Loss Force: 8.870840704880584, time: 9.55450701713562


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.085199560316064, Training Loss Force: 4.557259700615835, time: 0.6370179653167725
Validation Loss Energy: 2.4101816349759533, Validation Loss Force: 4.463813409358452, time: 0.06343197822570801
Test Loss Energy: 6.737676810748612, Test Loss Force: 8.801519243779325, time: 9.535232305526733


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.056453510766101, Training Loss Force: 4.5018946819327565, time: 0.6631104946136475
Validation Loss Energy: 2.680799352776674, Validation Loss Force: 4.5831453673674885, time: 0.06444931030273438
Test Loss Energy: 6.912852985111852, Test Loss Force: 8.855065092525402, time: 9.417311906814575


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.981486337093762, Training Loss Force: 4.507597812133018, time: 0.6414620876312256
Validation Loss Energy: 3.800686433915534, Validation Loss Force: 5.042047772916401, time: 0.05974888801574707
Test Loss Energy: 9.148435502142693, Test Loss Force: 8.862782795796804, time: 9.429985284805298


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0726545977369097, Training Loss Force: 4.5029251780399235, time: 0.6466019153594971
Validation Loss Energy: 2.3285592535026525, Validation Loss Force: 4.524097740581212, time: 0.058945655822753906
Test Loss Energy: 6.9568992364846345, Test Loss Force: 8.883711667009754, time: 9.574905633926392


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.945519096524354, Training Loss Force: 4.516062190044457, time: 0.6827535629272461
Validation Loss Energy: 2.540213958792549, Validation Loss Force: 4.565949074565777, time: 0.06121349334716797
Test Loss Energy: 6.766780756985154, Test Loss Force: 8.831771899336465, time: 9.384284019470215


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9883975698787126, Training Loss Force: 4.51935784927259, time: 0.655461311340332
Validation Loss Energy: 3.2353915970965943, Validation Loss Force: 4.795327909867807, time: 0.06112980842590332
Test Loss Energy: 8.77741674267531, Test Loss Force: 8.85051555850486, time: 9.443481206893921


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.052070160077304, Training Loss Force: 4.49791606860042, time: 0.6257574558258057
Validation Loss Energy: 2.2118691535754764, Validation Loss Force: 4.675884839954953, time: 0.0657358169555664
Test Loss Energy: 6.83871148078615, Test Loss Force: 8.86178334941563, time: 9.629729270935059


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9863745093533853, Training Loss Force: 4.516758732533291, time: 0.6175618171691895
Validation Loss Energy: 2.4864174271401147, Validation Loss Force: 4.539375516021609, time: 0.06161952018737793
Test Loss Energy: 6.727498326626174, Test Loss Force: 8.823965482812035, time: 9.44118070602417


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0324700369440007, Training Loss Force: 4.539404841548128, time: 0.751558780670166
Validation Loss Energy: 3.5353644564124136, Validation Loss Force: 4.724832639620237, time: 0.061527252197265625
Test Loss Energy: 8.421397314961668, Test Loss Force: 8.859217319504417, time: 10.154902458190918


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.1242259131131584, Training Loss Force: 4.513666047365129, time: 0.6691734790802002
Validation Loss Energy: 2.313654226212538, Validation Loss Force: 4.567955100901441, time: 0.06066489219665527
Test Loss Energy: 6.8984036717963075, Test Loss Force: 8.85860999465503, time: 9.635142087936401


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0514142769745165, Training Loss Force: 4.504902825192939, time: 0.6319451332092285
Validation Loss Energy: 2.193769714717882, Validation Loss Force: 4.512754974287651, time: 0.06103157997131348
Test Loss Energy: 6.824631926491622, Test Loss Force: 8.839459683335818, time: 9.447023153305054


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0501731191551147, Training Loss Force: 4.531747127151641, time: 0.6582565307617188
Validation Loss Energy: 3.9622778784536212, Validation Loss Force: 4.672375574215131, time: 0.059265851974487305
Test Loss Energy: 8.710660705265601, Test Loss Force: 8.856211122821405, time: 9.449537754058838


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0712414057353645, Training Loss Force: 4.526264934844699, time: 0.6942470073699951
Validation Loss Energy: 2.160881259195202, Validation Loss Force: 4.615151385064857, time: 0.05957341194152832
Test Loss Energy: 6.940411043225045, Test Loss Force: 8.851190108451789, time: 9.56287956237793


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0335962028497163, Training Loss Force: 4.509393605394554, time: 0.6745476722717285
Validation Loss Energy: 2.713711522563395, Validation Loss Force: 4.768137557789419, time: 0.05933523178100586
Test Loss Energy: 6.868828434071434, Test Loss Force: 8.84590043151664, time: 9.406074523925781


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.022535491563301, Training Loss Force: 4.507276055217152, time: 0.681002140045166
Validation Loss Energy: 4.25302433037335, Validation Loss Force: 5.074739388914081, time: 0.05971670150756836
Test Loss Energy: 9.151175927461644, Test Loss Force: 8.830915716651653, time: 9.413270235061646

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–ƒâ–„â–‡â–‚â–‚â–ˆâ–‚â–‚â–‡â–‚â–‚â–†â–‚â–‚â–‡â–‚â–‚â–ˆ
wandb:   test_error_force â–ƒâ–„â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–
wandb:          test_loss â–â–ˆâ–†â–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–‚â–„â–ƒâ–‚â–…â–ƒâ–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–…â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:  train_error_force â–†â–„â–ˆâ–†â–„â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–…â–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–„â–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–„â–‚â–ƒâ–…
wandb:  valid_error_force â–ƒâ–†â–ˆâ–†â–‚â–â–‚â–…â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–…
wandb:         valid_loss â–â–ˆâ–‚â–‚â–‚â–â–â–ƒâ–â–â–‚â–â–â–‚â–â–â–‚â–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1277
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.15118
wandb:   test_error_force 8.83092
wandb:          test_loss 6.45955
wandb: train_error_energy 3.02254
wandb:  train_error_force 4.50728
wandb:         train_loss 1.48307
wandb: valid_error_energy 4.25302
wandb:  valid_error_force 5.07474
wandb:         valid_loss 2.22891
wandb: 
wandb: ğŸš€ View run al_73_44 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/6zcmjoyi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_163158-6zcmjoyi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.399686813354492, Uncertainty Bias: -0.03245404362678528
0.00022888184 0.10889053
2.62622 8.836787
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1824 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1483 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2161 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3077 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3691 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_171437-3hvdnjqq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_45
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3hvdnjqq
Training model 45. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.419411579528791, Training Loss Force: 4.8847897252129435, time: 0.7886378765106201
Validation Loss Energy: 3.169825219728709, Validation Loss Force: 5.077157353169712, time: 0.07856154441833496
Test Loss Energy: 8.019656788507993, Test Loss Force: 9.091113921471733, time: 9.413946151733398


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.135157206771755, Training Loss Force: 4.982482853118406, time: 0.6567935943603516
Validation Loss Energy: 4.79075539895618, Validation Loss Force: 5.010067807509106, time: 0.06423306465148926
Test Loss Energy: 8.986640407434837, Test Loss Force: 9.092266592204671, time: 9.31846284866333


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1062044900567343, Training Loss Force: 5.088071861524196, time: 0.6765122413635254
Validation Loss Energy: 3.948857943032272, Validation Loss Force: 4.4461532967257735, time: 0.06291055679321289
Test Loss Energy: 9.398267014950711, Test Loss Force: 8.96967430556612, time: 9.541955709457397


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.402182352614709, Training Loss Force: 4.871458556031975, time: 0.6707837581634521
Validation Loss Energy: 2.37352205479784, Validation Loss Force: 4.548671062187511, time: 0.06676697731018066
Test Loss Energy: 7.282328789626413, Test Loss Force: 8.934995910707118, time: 9.245082139968872


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9654658345287537, Training Loss Force: 4.946045681400391, time: 0.674067497253418
Validation Loss Energy: 5.521601183066095, Validation Loss Force: 5.062080202629795, time: 0.06070303916931152
Test Loss Energy: 7.477922281402106, Test Loss Force: 9.047183285515388, time: 9.306438684463501


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.453177221143513, Training Loss Force: 4.708561499103173, time: 0.6928629875183105
Validation Loss Energy: 2.4884930375838805, Validation Loss Force: 4.9523869239405345, time: 0.06207394599914551
Test Loss Energy: 7.0059733618356965, Test Loss Force: 8.882214495631274, time: 9.492799758911133


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.299611440632101, Training Loss Force: 4.568798718261994, time: 0.6965718269348145
Validation Loss Energy: 3.971709252798539, Validation Loss Force: 4.8919560764197545, time: 0.06227564811706543
Test Loss Energy: 9.353775667773936, Test Loss Force: 8.873595273770627, time: 9.316978454589844


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.339573378034875, Training Loss Force: 4.518608549674393, time: 0.6584477424621582
Validation Loss Energy: 6.437916782915956, Validation Loss Force: 4.732358411414305, time: 0.0605311393737793
Test Loss Energy: 11.227411178519377, Test Loss Force: 8.821990283912108, time: 10.1061851978302


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.473054939248125, Training Loss Force: 4.514913827690787, time: 0.6728782653808594
Validation Loss Energy: 5.411587483475845, Validation Loss Force: 4.581047824012849, time: 0.06193208694458008
Test Loss Energy: 10.02055772577047, Test Loss Force: 8.860649527451024, time: 9.594634294509888


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.44738575415562, Training Loss Force: 4.592023734742063, time: 0.6746599674224854
Validation Loss Energy: 2.9577461070466735, Validation Loss Force: 4.398634364969908, time: 0.06378316879272461
Test Loss Energy: 8.286935333565724, Test Loss Force: 8.802310355778017, time: 9.358916521072388


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.396158843455533, Training Loss Force: 4.5223895260817955, time: 0.6627776622772217
Validation Loss Energy: 3.136753173495211, Validation Loss Force: 4.699956042637185, time: 0.0594632625579834
Test Loss Energy: 6.905956543940983, Test Loss Force: 8.827143118416112, time: 9.376704931259155


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.546072621873629, Training Loss Force: 4.564568971199317, time: 0.6645846366882324
Validation Loss Energy: 5.520116425201049, Validation Loss Force: 4.659536471260934, time: 0.06058907508850098
Test Loss Energy: 7.638468799094514, Test Loss Force: 8.847148050238692, time: 9.583094596862793


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.499386146866247, Training Loss Force: 4.5412872446894506, time: 0.651298999786377
Validation Loss Energy: 5.140177842857631, Validation Loss Force: 4.445659193890959, time: 0.05982565879821777
Test Loss Energy: 7.321492848601093, Test Loss Force: 8.78065414687506, time: 9.319396734237671


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.361267620170056, Training Loss Force: 4.520741052084944, time: 0.6645667552947998
Validation Loss Energy: 2.292148951433405, Validation Loss Force: 4.888013051183665, time: 0.06262373924255371
Test Loss Energy: 6.7983127831850725, Test Loss Force: 8.805703264648118, time: 9.31683349609375


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.322120947828412, Training Loss Force: 4.505631674259369, time: 0.6529839038848877
Validation Loss Energy: 4.105523166720427, Validation Loss Force: 4.273302364154701, time: 0.06106925010681152
Test Loss Energy: 9.028413153200574, Test Loss Force: 8.78924270334715, time: 9.508482694625854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.594072345194146, Training Loss Force: 4.60183700296511, time: 0.6492011547088623
Validation Loss Energy: 5.958610312849096, Validation Loss Force: 4.748999367366071, time: 0.06650829315185547
Test Loss Energy: 10.383333268792375, Test Loss Force: 8.880645813648547, time: 9.416707754135132


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.3960956542966825, Training Loss Force: 4.67823807809153, time: 0.6918251514434814
Validation Loss Energy: 5.297575536701315, Validation Loss Force: 4.880393535679162, time: 0.06473183631896973
Test Loss Energy: 9.635778591325046, Test Loss Force: 8.910404400179274, time: 9.40950632095337


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.473001148356519, Training Loss Force: 4.570116615472419, time: 0.6549110412597656
Validation Loss Energy: 2.8447863833212255, Validation Loss Force: 4.536971134583881, time: 0.05953574180603027
Test Loss Energy: 8.402716956784296, Test Loss Force: 8.912671526490163, time: 9.60335111618042


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.430656154159954, Training Loss Force: 4.632290821200989, time: 0.6518793106079102
Validation Loss Energy: 3.3897238048082903, Validation Loss Force: 4.9785396377988995, time: 0.06042957305908203
Test Loss Energy: 6.935941504552434, Test Loss Force: 8.829227539446634, time: 9.36109733581543


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.4952896808647935, Training Loss Force: 4.608529497936522, time: 0.6783552169799805
Validation Loss Energy: 4.876530225997316, Validation Loss Force: 4.448673243450238, time: 0.06488752365112305
Test Loss Energy: 7.293312939682712, Test Loss Force: 8.838018969660997, time: 9.368351459503174

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–…â–‚â–‚â–â–…â–ˆâ–†â–ƒâ–â–‚â–‚â–â–…â–‡â–…â–„â–â–‚
wandb:   test_error_force â–ˆâ–ˆâ–…â–„â–‡â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–â–‚â–â–ƒâ–„â–„â–‚â–‚
wandb:          test_loss â–…â–…â–ˆâ–„â–†â–‚â–„â–…â–„â–‚â–â–‚â–â–â–ƒâ–„â–ƒâ–ƒâ–â–
wandb: train_error_energy â–‡â–†â–‚â–ƒâ–â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–‡â–‡â–ˆâ–‡â–‡â–‡â–ˆ
wandb:  train_error_force â–†â–‡â–ˆâ–…â–†â–ƒâ–‚â–â–â–‚â–â–‚â–â–â–â–‚â–ƒâ–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–…â–â–‚â–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–…â–„â–â–†â–â–„â–ˆâ–†â–‚â–‚â–†â–†â–â–„â–‡â–†â–‚â–ƒâ–…
wandb:  valid_error_force â–ˆâ–‡â–ƒâ–ƒâ–ˆâ–‡â–†â–…â–„â–‚â–…â–„â–ƒâ–†â–â–…â–†â–ƒâ–‡â–ƒ
wandb:         valid_loss â–‚â–„â–ƒâ–â–ˆâ–‚â–‚â–„â–ƒâ–â–‚â–„â–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1281
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.29331
wandb:   test_error_force 8.83802
wandb:          test_loss 4.67781
wandb: train_error_energy 4.49529
wandb:  train_error_force 4.60853
wandb:         train_loss 1.90698
wandb: valid_error_energy 4.87653
wandb:  valid_error_force 4.44867
wandb:         valid_loss 1.99173
wandb: 
wandb: ğŸš€ View run al_73_45 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3hvdnjqq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_171437-3hvdnjqq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8079447746276855, Uncertainty Bias: -0.008988380432128906
0.00062561035 0.10303497
3.0136163 18.561825
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2547 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1350 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1746 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2794 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_175650-g23huq6d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_46
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g23huq6d
Training model 46. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.386323382438375, Training Loss Force: 4.837747397755595, time: 0.6815104484558105
Validation Loss Energy: 4.170413854564995, Validation Loss Force: 4.729087401660625, time: 0.06146574020385742
Test Loss Energy: 8.909743047168115, Test Loss Force: 8.860114599219239, time: 10.12933611869812


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9630081129686663, Training Loss Force: 4.597337185383197, time: 0.6844320297241211
Validation Loss Energy: 2.359613471935752, Validation Loss Force: 4.649928074945004, time: 0.06360507011413574
Test Loss Energy: 7.536946793732067, Test Loss Force: 8.840600122421222, time: 9.355521440505981


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.13356990704953, Training Loss Force: 4.896579415637156, time: 0.6494238376617432
Validation Loss Energy: 4.9808215512063665, Validation Loss Force: 5.054233787265591, time: 0.06379175186157227
Test Loss Energy: 10.414773410744099, Test Loss Force: 9.27142261498538, time: 9.57082986831665


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.295533086864834, Training Loss Force: 4.861695448107263, time: 0.6641280651092529
Validation Loss Energy: 2.5503274800660165, Validation Loss Force: 4.833366034728359, time: 0.06386446952819824
Test Loss Energy: 6.690290794985758, Test Loss Force: 8.853657613677871, time: 9.42908525466919


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0621084691442313, Training Loss Force: 4.595117662784226, time: 0.6748647689819336
Validation Loss Energy: 3.3918659933266886, Validation Loss Force: 4.9392946461674185, time: 0.06300854682922363
Test Loss Energy: 7.070584008837953, Test Loss Force: 8.91657000857061, time: 9.59281325340271


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.238718898696555, Training Loss Force: 5.266572996518412, time: 0.6859641075134277
Validation Loss Energy: 4.305802039348592, Validation Loss Force: 4.766499380882828, time: 0.06951785087585449
Test Loss Energy: 9.070535883568201, Test Loss Force: 9.046015608514143, time: 10.270296096801758


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9395435832364245, Training Loss Force: 4.672894605132378, time: 0.7092790603637695
Validation Loss Energy: 3.3758098778867005, Validation Loss Force: 4.8977091791430905, time: 0.06802821159362793
Test Loss Energy: 8.162223849872444, Test Loss Force: 8.86888255007968, time: 10.229782104492188


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1082348470698062, Training Loss Force: 4.734041366543046, time: 0.6363828182220459
Validation Loss Energy: 2.4506115604674887, Validation Loss Force: 4.8399937818569, time: 0.06428146362304688
Test Loss Energy: 6.7925950452184995, Test Loss Force: 8.984769510959769, time: 10.369446992874146


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.747189180457136, Training Loss Force: 5.173213699923961, time: 0.6595938205718994
Validation Loss Energy: 4.830926026227283, Validation Loss Force: 5.117957243447206, time: 0.06655573844909668
Test Loss Energy: 10.162730902902878, Test Loss Force: 9.090185925072841, time: 10.269824981689453


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.403772922574302, Training Loss Force: 4.662226787036808, time: 0.6474854946136475
Validation Loss Energy: 2.92489773197026, Validation Loss Force: 5.031808109571767, time: 0.06436944007873535
Test Loss Energy: 8.17331930185911, Test Loss Force: 8.869166596635006, time: 10.342333555221558


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.361841267484038, Training Loss Force: 4.5612617424082185, time: 0.6446373462677002
Validation Loss Energy: 3.2743482321840984, Validation Loss Force: 4.9523450621411005, time: 0.062072038650512695
Test Loss Energy: 6.990386437682643, Test Loss Force: 8.767764415252438, time: 10.28488802909851


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.292053055954586, Training Loss Force: 4.559716907321409, time: 0.796621561050415
Validation Loss Energy: 5.257568125914178, Validation Loss Force: 4.723585247064749, time: 0.09469723701477051
Test Loss Energy: 7.375483061024337, Test Loss Force: 8.754495679758922, time: 10.267006397247314


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.307682455846656, Training Loss Force: 4.511922528401077, time: 0.6889915466308594
Validation Loss Energy: 5.014242853995253, Validation Loss Force: 4.882157520653202, time: 0.06355643272399902
Test Loss Energy: 7.321481593899864, Test Loss Force: 8.725540926513377, time: 10.356464385986328


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.411818138038182, Training Loss Force: 4.535620206306491, time: 0.7404499053955078
Validation Loss Energy: 1.7483646221185278, Validation Loss Force: 4.5998938725167395, time: 0.06709909439086914
Test Loss Energy: 6.783315932268729, Test Loss Force: 8.789422298254314, time: 10.430262804031372


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.29459437891706, Training Loss Force: 4.533270558031024, time: 0.7140648365020752
Validation Loss Energy: 3.923906751885334, Validation Loss Force: 4.98634085132648, time: 0.06443047523498535
Test Loss Energy: 8.895689317831286, Test Loss Force: 8.761197969755836, time: 10.211437225341797


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.333455858245886, Training Loss Force: 4.530367929939986, time: 0.7123098373413086
Validation Loss Energy: 6.665580843125196, Validation Loss Force: 4.811618607253029, time: 0.06623077392578125
Test Loss Energy: 10.428738729937729, Test Loss Force: 8.79317574927492, time: 10.244734048843384


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.454588709997639, Training Loss Force: 4.486243225439819, time: 0.6787052154541016
Validation Loss Energy: 5.428527484090593, Validation Loss Force: 4.941949975732607, time: 0.06731557846069336
Test Loss Energy: 9.917994251346043, Test Loss Force: 8.780257026362658, time: 11.22132134437561


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.488628489916725, Training Loss Force: 4.516964768022471, time: 0.6658601760864258
Validation Loss Energy: 2.9152685160891862, Validation Loss Force: 4.903243175426834, time: 0.06135749816894531
Test Loss Energy: 8.130759883487917, Test Loss Force: 8.74328850615135, time: 10.245429277420044


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.396476983355516, Training Loss Force: 4.549135984502298, time: 0.6540937423706055
Validation Loss Energy: 3.2631239258761706, Validation Loss Force: 5.140797531090749, time: 0.06429553031921387
Test Loss Energy: 6.893135042341579, Test Loss Force: 8.75046790501376, time: 10.377723455429077


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.261026562545632, Training Loss Force: 4.53632147291134, time: 0.7059540748596191
Validation Loss Energy: 5.685654903019852, Validation Loss Force: 4.819315166282024, time: 0.06674766540527344
Test Loss Energy: 7.530814760583678, Test Loss Force: 8.794608488829539, time: 10.361132144927979

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ƒâ–ˆâ–â–‚â–…â–„â–â–ˆâ–„â–‚â–‚â–‚â–â–…â–ˆâ–‡â–„â–â–ƒ
wandb:   test_error_force â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–…â–ƒâ–„â–†â–ƒâ–‚â–â–â–‚â–â–‚â–‚â–â–â–‚
wandb:          test_loss â–ƒâ–„â–ˆâ–ƒâ–„â–†â–…â–„â–‡â–ƒâ–â–‚â–‚â–â–ƒâ–…â–„â–‚â–â–‚
wandb: train_error_energy â–ˆâ–â–„â–…â–â–‚â–â–â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–„â–‚â–…â–„â–‚â–ˆâ–ƒâ–ƒâ–‡â–ƒâ–‚â–‚â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–â–ˆâ–‡â–â–„â–â–‚â–†â–…â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–„â–‚â–†â–‚â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–ƒâ–†â–†â–â–„â–ˆâ–†â–ƒâ–ƒâ–‡
wandb:  valid_error_force â–ƒâ–‚â–‡â–„â–…â–ƒâ–…â–„â–ˆâ–‡â–†â–ƒâ–…â–â–†â–„â–…â–…â–ˆâ–„
wandb:         valid_loss â–„â–â–‡â–‚â–„â–…â–ƒâ–‚â–‡â–ƒâ–ƒâ–†â–†â–â–„â–ˆâ–†â–ƒâ–„â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1284
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.53081
wandb:   test_error_force 8.79461
wandb:          test_loss 4.76974
wandb: train_error_energy 4.26103
wandb:  train_error_force 4.53632
wandb:         train_loss 1.84704
wandb: valid_error_energy 5.68565
wandb:  valid_error_force 4.81932
wandb:         valid_loss 2.36709
wandb: 
wandb: ğŸš€ View run al_73_46 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g23huq6d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_175650-g23huq6d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0817859172821045, Uncertainty Bias: -0.050750017166137695
1.1444092e-05 0.073369026
2.878483 16.71957
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2632 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3166 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3760 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3353 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 887 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3917 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2928 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3353 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_183923-q1raoo8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_47
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q1raoo8q
Training model 47. Added 8 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.166365774544853, Training Loss Force: 4.897334426970494, time: 0.7474148273468018
Validation Loss Energy: 6.204711378341156, Validation Loss Force: 5.164082489018709, time: 0.07018542289733887
Test Loss Energy: 10.60429779963579, Test Loss Force: 8.899266839242081, time: 10.907039880752563


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.47068654331676, Training Loss Force: 4.586924035619109, time: 0.7029626369476318
Validation Loss Energy: 5.451335484707977, Validation Loss Force: 4.693679667420918, time: 0.0681304931640625
Test Loss Energy: 10.096108387705849, Test Loss Force: 8.791751496795598, time: 9.255018711090088


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.409935904885744, Training Loss Force: 4.549121994362788, time: 0.6705193519592285
Validation Loss Energy: 2.6525768178723377, Validation Loss Force: 4.480438778470004, time: 0.05835556983947754
Test Loss Energy: 8.122099268482268, Test Loss Force: 8.762876927758729, time: 9.030318021774292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.29794093596719, Training Loss Force: 4.542545303640122, time: 0.6499922275543213
Validation Loss Energy: 3.383267178918395, Validation Loss Force: 4.801129777134102, time: 0.06061434745788574
Test Loss Energy: 6.975764939329524, Test Loss Force: 8.686946259358393, time: 8.939175367355347


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.493634086886228, Training Loss Force: 4.549758285024664, time: 0.6827812194824219
Validation Loss Energy: 5.610753455712663, Validation Loss Force: 4.36810085833456, time: 0.06640434265136719
Test Loss Energy: 7.7197173569605315, Test Loss Force: 8.789651673122375, time: 8.886195182800293


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.647723107304841, Training Loss Force: 4.556859508221769, time: 0.6421713829040527
Validation Loss Energy: 5.2778160993608285, Validation Loss Force: 4.596635554904378, time: 0.058564186096191406
Test Loss Energy: 7.542870595088993, Test Loss Force: 8.787257436537567, time: 9.061777353286743


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.435360045298633, Training Loss Force: 4.5413176526052546, time: 0.6548211574554443
Validation Loss Energy: 2.0353771351301932, Validation Loss Force: 4.511510476431059, time: 0.06084394454956055
Test Loss Energy: 6.623126195833293, Test Loss Force: 8.770922451308445, time: 8.857561588287354


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.445185256191238, Training Loss Force: 4.527152370234597, time: 0.679114818572998
Validation Loss Energy: 4.1490042161840375, Validation Loss Force: 4.809540436114086, time: 0.06399250030517578
Test Loss Energy: 9.099649741496256, Test Loss Force: 8.804963266293585, time: 8.835441827774048


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.379568585466625, Training Loss Force: 4.564779969223425, time: 0.6646218299865723
Validation Loss Energy: 6.90397399346182, Validation Loss Force: 4.719817685115651, time: 0.06150364875793457
Test Loss Energy: 11.362765447644371, Test Loss Force: 8.861361583742262, time: 9.065033674240112


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.388685279429753, Training Loss Force: 4.555131150311078, time: 0.6863813400268555
Validation Loss Energy: 5.152786037907501, Validation Loss Force: 4.5506833232592605, time: 0.06099748611450195
Test Loss Energy: 9.408022427695885, Test Loss Force: 8.773523548695625, time: 8.957981824874878


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.529638688487072, Training Loss Force: 4.5622520444263905, time: 0.6582167148590088
Validation Loss Energy: 2.9444818173583283, Validation Loss Force: 4.878429371142934, time: 0.05931496620178223
Test Loss Energy: 8.340217122352486, Test Loss Force: 8.851340180461303, time: 8.89463210105896


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.438089849546702, Training Loss Force: 4.58460460517603, time: 0.6784176826477051
Validation Loss Energy: 3.5679938363838066, Validation Loss Force: 4.996261875123292, time: 0.059841156005859375
Test Loss Energy: 7.147704215453273, Test Loss Force: 8.783858092412567, time: 9.954588413238525


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.524495031216141, Training Loss Force: 4.538788983767416, time: 0.6737511157989502
Validation Loss Energy: 5.591180615116464, Validation Loss Force: 5.328547033546704, time: 0.0646204948425293
Test Loss Energy: 7.662050025898877, Test Loss Force: 8.739857680572863, time: 8.922354221343994


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.536373447148573, Training Loss Force: 4.54703152211127, time: 0.6781346797943115
Validation Loss Energy: 5.521581365512107, Validation Loss Force: 4.819639595227641, time: 0.058367252349853516
Test Loss Energy: 7.401607171806809, Test Loss Force: 8.719987096354346, time: 10.2533597946167


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4584565328029075, Training Loss Force: 4.526714868810488, time: 0.6927914619445801
Validation Loss Energy: 2.269304321741517, Validation Loss Force: 5.234542577541223, time: 0.06649422645568848
Test Loss Energy: 6.736873322542312, Test Loss Force: 8.80650535854919, time: 10.986794233322144


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.440761754385877, Training Loss Force: 4.568055540979119, time: 0.6839425563812256
Validation Loss Energy: 3.407804984795918, Validation Loss Force: 4.619292363171676, time: 0.0687413215637207
Test Loss Energy: 8.74404446207274, Test Loss Force: 8.829929131453818, time: 10.21739149093628


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.499424809833317, Training Loss Force: 4.771550755370161, time: 0.678152322769165
Validation Loss Energy: 5.828907316699327, Validation Loss Force: 4.961420833859971, time: 0.06375789642333984
Test Loss Energy: 10.21448088185219, Test Loss Force: 9.03658810464862, time: 9.603386640548706


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.576421057862983, Training Loss Force: 4.617810755260401, time: 0.672243595123291
Validation Loss Energy: 5.33830595420528, Validation Loss Force: 4.601530268070162, time: 0.06143021583557129
Test Loss Energy: 9.999093833061172, Test Loss Force: 8.782335301258428, time: 9.78425121307373


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4490400094038325, Training Loss Force: 4.587055529896212, time: 0.6549699306488037
Validation Loss Energy: 2.863943389287404, Validation Loss Force: 4.528396368443348, time: 0.061972856521606445
Test Loss Energy: 8.34397401949872, Test Loss Force: 8.710933821214056, time: 9.44177770614624


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.2981353940185185, Training Loss Force: 4.545161057837838, time: 0.6655945777893066
Validation Loss Energy: 3.706952632256929, Validation Loss Force: 4.4991127037240926, time: 0.06072092056274414
Test Loss Energy: 6.902783030630624, Test Loss Force: 8.773666770422931, time: 9.45262861251831

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–ƒâ–‚â–ƒâ–‚â–â–…â–ˆâ–…â–„â–‚â–ƒâ–‚â–â–„â–†â–†â–„â–
wandb:   test_error_force â–…â–ƒâ–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–„â–ˆâ–ƒâ–â–ƒ
wandb:          test_loss â–†â–…â–ƒâ–â–ƒâ–‚â–â–„â–ˆâ–…â–ƒâ–‚â–‚â–‚â–â–„â–†â–…â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–â–â–‚â–†â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–‚â–‚â–â–
wandb: valid_error_energy â–‡â–†â–‚â–ƒâ–†â–†â–â–„â–ˆâ–…â–‚â–ƒâ–†â–†â–â–ƒâ–†â–†â–‚â–ƒ
wandb:  valid_error_force â–‡â–ƒâ–‚â–„â–â–ƒâ–‚â–„â–„â–‚â–…â–†â–ˆâ–„â–‡â–ƒâ–…â–ƒâ–‚â–‚
wandb:         valid_loss â–‡â–…â–â–ƒâ–†â–…â–â–„â–ˆâ–…â–ƒâ–„â–‡â–†â–ƒâ–ƒâ–†â–…â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1291
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.90278
wandb:   test_error_force 8.77367
wandb:          test_loss 4.60277
wandb: train_error_energy 4.29814
wandb:  train_error_force 4.54516
wandb:         train_loss 1.85165
wandb: valid_error_energy 3.70695
wandb:  valid_error_force 4.49911
wandb:         valid_loss 1.62927
wandb: 
wandb: ğŸš€ View run al_73_47 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q1raoo8q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_183923-q1raoo8q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1345367431640625, Uncertainty Bias: -0.059880614280700684
7.1525574e-05 0.16837692
2.8821323 17.474655
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3709 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3649 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2242 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_192228-jsxualur
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_48
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jsxualur
Training model 48. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.627762250231593, Training Loss Force: 4.888652839380418, time: 0.7100906372070312
Validation Loss Energy: 1.660712137504357, Validation Loss Force: 4.812130523619518, time: 0.07006621360778809
Test Loss Energy: 6.8165814669148705, Test Loss Force: 8.8245271266781, time: 10.752680540084839


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.333478806745304, Training Loss Force: 4.796297215814805, time: 0.7426497936248779
Validation Loss Energy: 4.2261677593447065, Validation Loss Force: 4.742277876527096, time: 0.06585192680358887
Test Loss Energy: 9.365433621660655, Test Loss Force: 8.899542757790677, time: 10.793711423873901


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.406483664171099, Training Loss Force: 4.52383294895002, time: 0.7239241600036621
Validation Loss Energy: 6.0873809932848655, Validation Loss Force: 4.800248897992811, time: 0.06863617897033691
Test Loss Energy: 10.339689015668677, Test Loss Force: 8.745488155550373, time: 10.990556001663208


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.346557976909062, Training Loss Force: 4.532664458046764, time: 0.7293932437896729
Validation Loss Energy: 5.325939577847889, Validation Loss Force: 4.819861596366131, time: 0.06898641586303711
Test Loss Energy: 9.872583879821411, Test Loss Force: 8.806182089581583, time: 10.85523247718811


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.4897804062872035, Training Loss Force: 4.539572431579976, time: 0.6678965091705322
Validation Loss Energy: 2.5237636076296965, Validation Loss Force: 4.822089401171139, time: 0.07152438163757324
Test Loss Energy: 7.443810361513571, Test Loss Force: 8.736660086352144, time: 11.139700651168823


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.472407015481113, Training Loss Force: 4.535968612917457, time: 0.7127230167388916
Validation Loss Energy: 3.087700942000487, Validation Loss Force: 4.530644436140635, time: 0.06611037254333496
Test Loss Energy: 6.9477347969792085, Test Loss Force: 8.695717413856599, time: 11.061410427093506


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.4230855715580075, Training Loss Force: 4.515353001848969, time: 0.7434921264648438
Validation Loss Energy: 5.744575385723804, Validation Loss Force: 4.561398162561305, time: 0.07074618339538574
Test Loss Energy: 7.515570826190235, Test Loss Force: 8.721463227247245, time: 11.7647385597229


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.433603951501887, Training Loss Force: 4.514995101929051, time: 0.7394685745239258
Validation Loss Energy: 5.198738492221764, Validation Loss Force: 4.613195459287027, time: 0.06786155700683594
Test Loss Energy: 7.307646723851535, Test Loss Force: 8.693341079404803, time: 11.021158218383789


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.410842920496907, Training Loss Force: 4.506333130947636, time: 0.7177445888519287
Validation Loss Energy: 2.318535913233286, Validation Loss Force: 4.557939442717609, time: 0.07401394844055176
Test Loss Energy: 6.972544511611991, Test Loss Force: 8.74763747472757, time: 10.875746488571167


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.292117722333137, Training Loss Force: 4.5120732591200055, time: 0.7481420040130615
Validation Loss Energy: 4.095752444597116, Validation Loss Force: 4.877155480959081, time: 0.06698012351989746
Test Loss Energy: 8.618825001274985, Test Loss Force: 8.72748650458786, time: 11.118587017059326


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.403604093198575, Training Loss Force: 4.517628436127386, time: 0.7460834980010986
Validation Loss Energy: 6.217589893734182, Validation Loss Force: 4.704486023741939, time: 0.08051800727844238
Test Loss Energy: 10.655769514432723, Test Loss Force: 8.711010549970645, time: 11.05903959274292


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.392037308166822, Training Loss Force: 4.53198650653078, time: 0.7320356369018555
Validation Loss Energy: 5.4059405939351155, Validation Loss Force: 4.960038058463759, time: 0.06679058074951172
Test Loss Energy: 10.048884337515998, Test Loss Force: 8.828055390409556, time: 10.868205547332764


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.340267454055597, Training Loss Force: 4.52077843877764, time: 0.7438533306121826
Validation Loss Energy: 2.5870486282629788, Validation Loss Force: 4.559004691911728, time: 0.06847119331359863
Test Loss Energy: 7.986592761278267, Test Loss Force: 8.691487035836401, time: 11.13700795173645


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.269689399764334, Training Loss Force: 4.540176967449261, time: 0.7648670673370361
Validation Loss Energy: 3.4920863698753157, Validation Loss Force: 5.00350597044776, time: 0.07303023338317871
Test Loss Energy: 7.014554480458825, Test Loss Force: 8.710153928942384, time: 10.867633581161499


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.450637858755713, Training Loss Force: 4.523251929114927, time: 0.7304034233093262
Validation Loss Energy: 5.56966854892838, Validation Loss Force: 4.8713988155294095, time: 0.07427406311035156
Test Loss Energy: 7.681278178154601, Test Loss Force: 8.672441824354069, time: 11.098108530044556


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.524970674235661, Training Loss Force: 4.52225868895022, time: 0.6509950160980225
Validation Loss Energy: 4.919365089599443, Validation Loss Force: 4.6933579105050525, time: 0.06475710868835449
Test Loss Energy: 7.436713919148994, Test Loss Force: 8.700170558950518, time: 11.197176694869995


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.390940404652776, Training Loss Force: 4.508736730327875, time: 0.7065103054046631
Validation Loss Energy: 2.2802797952788705, Validation Loss Force: 4.551999965919132, time: 0.06955361366271973
Test Loss Energy: 7.081098753681722, Test Loss Force: 8.703711949669321, time: 11.023948192596436


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.412854736230365, Training Loss Force: 4.538683970825815, time: 0.7439248561859131
Validation Loss Energy: 4.240486944111885, Validation Loss Force: 4.4985201811267785, time: 0.0714116096496582
Test Loss Energy: 8.962865679976856, Test Loss Force: 8.77764231234917, time: 11.037369966506958


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.462566255764975, Training Loss Force: 4.603009654720933, time: 0.7065157890319824
Validation Loss Energy: 5.711823203718431, Validation Loss Force: 5.165895906543145, time: 0.07046365737915039
Test Loss Energy: 10.05099579594355, Test Loss Force: 8.78614377370841, time: 10.930447340011597


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.509304449754715, Training Loss Force: 4.516945955195117, time: 0.7302134037017822
Validation Loss Energy: 5.443863598847224, Validation Loss Force: 4.56559681197692, time: 0.06893181800842285
Test Loss Energy: 9.73766523082073, Test Loss Force: 8.728147815629965, time: 9.941998481750488

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–‡â–‡â–‚â–â–‚â–‚â–â–„â–ˆâ–‡â–ƒâ–â–ƒâ–‚â–â–…â–‡â–†
wandb:   test_error_force â–†â–ˆâ–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–†â–‚â–‚â–â–‚â–‚â–„â–…â–ƒ
wandb:          test_loss â–‚â–‡â–‡â–†â–‚â–â–‚â–‚â–â–„â–ˆâ–‡â–ƒâ–â–ƒâ–‚â–â–…â–‡â–†
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–†â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–ƒâ–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–
wandb: valid_error_energy â–â–…â–ˆâ–‡â–‚â–ƒâ–‡â–†â–‚â–…â–ˆâ–‡â–‚â–„â–‡â–†â–‚â–…â–‡â–‡
wandb:  valid_error_force â–„â–„â–„â–„â–„â–â–‚â–‚â–‚â–…â–ƒâ–†â–‚â–†â–…â–ƒâ–‚â–â–ˆâ–‚
wandb:         valid_loss â–â–„â–ˆâ–†â–‚â–‚â–‡â–†â–â–…â–ˆâ–‡â–â–„â–ˆâ–†â–â–„â–ˆâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1293
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.73767
wandb:   test_error_force 8.72815
wandb:          test_loss 5.55412
wandb: train_error_energy 4.5093
wandb:  train_error_force 4.51695
wandb:         train_loss 1.88618
wandb: valid_error_energy 5.44386
wandb:  valid_error_force 4.5656
wandb:         valid_loss 2.13151
wandb: 
wandb: ğŸš€ View run al_73_48 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/jsxualur
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_192228-jsxualur/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.6638622283935547, Uncertainty Bias: -0.19063565135002136
0.0004749298 0.048521042
2.4925396 11.323727
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3630 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1639 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3838 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3831 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_200557-g01k1t8a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_49
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g01k1t8a
Training model 49. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.309050394677005, Training Loss Force: 4.880030557816526, time: 0.6674284934997559
Validation Loss Energy: 4.9843700067158725, Validation Loss Force: 5.263243517105585, time: 0.06406116485595703
Test Loss Energy: 7.354884651808468, Test Loss Force: 9.020337206750167, time: 9.632196187973022


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0653761795928824, Training Loss Force: 4.7565202621627485, time: 0.6981887817382812
Validation Loss Energy: 2.6015076492538, Validation Loss Force: 4.474576122526872, time: 0.06087160110473633
Test Loss Energy: 7.699871986816822, Test Loss Force: 8.724042095025661, time: 10.234779119491577


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.910822847841894, Training Loss Force: 4.514971086247019, time: 0.6804258823394775
Validation Loss Energy: 3.5173724554177292, Validation Loss Force: 4.559633286910682, time: 0.06462407112121582
Test Loss Energy: 8.507569395417208, Test Loss Force: 8.78689780837979, time: 9.630930423736572


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.996750697464874, Training Loss Force: 4.481140713082291, time: 0.6432540416717529
Validation Loss Energy: 2.9060113803509573, Validation Loss Force: 4.922000378941499, time: 0.0603940486907959
Test Loss Energy: 8.425548702559606, Test Loss Force: 8.758313352758115, time: 9.459156036376953


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.014237847765237, Training Loss Force: 4.499572797920082, time: 0.6588413715362549
Validation Loss Energy: 2.4006857979132894, Validation Loss Force: 4.958668643216303, time: 0.0605311393737793
Test Loss Energy: 6.848577612558167, Test Loss Force: 8.762942222279802, time: 9.503715991973877


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0197703260971203, Training Loss Force: 4.492538858821731, time: 0.6496944427490234
Validation Loss Energy: 3.095440142170926, Validation Loss Force: 4.728862728492384, time: 0.06490635871887207
Test Loss Energy: 6.9319158935451535, Test Loss Force: 8.713367149640755, time: 9.684466123580933


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.994929117215406, Training Loss Force: 4.494321944463727, time: 0.7053656578063965
Validation Loss Energy: 2.469824233720149, Validation Loss Force: 4.555605870068286, time: 0.06794476509094238
Test Loss Energy: 6.8584534135338275, Test Loss Force: 8.76318838010611, time: 9.46465015411377


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.083223456504623, Training Loss Force: 4.496565721706739, time: 0.6742074489593506
Validation Loss Energy: 2.834455314292187, Validation Loss Force: 4.8065337346366235, time: 0.060384511947631836
Test Loss Energy: 7.826513049048674, Test Loss Force: 8.722470176762572, time: 9.434777975082397


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9755428163384696, Training Loss Force: 4.492391848306825, time: 0.6487338542938232
Validation Loss Energy: 4.162253921043325, Validation Loss Force: 5.0917054418189025, time: 0.06037497520446777
Test Loss Energy: 9.082757631069182, Test Loss Force: 8.80157537972024, time: 9.67882490158081


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0507709572994184, Training Loss Force: 4.501248638498063, time: 0.6679763793945312
Validation Loss Energy: 3.1063453635927396, Validation Loss Force: 4.778212000627776, time: 0.06347870826721191
Test Loss Energy: 8.503684098614459, Test Loss Force: 8.811989725261146, time: 9.470683574676514


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0171041536307155, Training Loss Force: 4.49117041571518, time: 0.685232400894165
Validation Loss Energy: 2.4288874019179088, Validation Loss Force: 4.930024484284153, time: 0.05962634086608887
Test Loss Energy: 6.916324107976718, Test Loss Force: 8.743226904907, time: 9.473572731018066


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.973620516317152, Training Loss Force: 4.518001265741991, time: 0.6533615589141846
Validation Loss Energy: 3.2320989884357605, Validation Loss Force: 4.548846525474501, time: 0.060167551040649414
Test Loss Energy: 6.821244779039947, Test Loss Force: 8.781511043033786, time: 9.684220552444458


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0638843967878295, Training Loss Force: 4.5017486665045405, time: 0.6657848358154297
Validation Loss Energy: 2.4195106928483163, Validation Loss Force: 4.890256442828887, time: 0.0625619888305664
Test Loss Energy: 6.778676146129856, Test Loss Force: 8.68637465017369, time: 9.501933097839355


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.091937244225582, Training Loss Force: 4.482860631289256, time: 0.6842243671417236
Validation Loss Energy: 2.714989866130167, Validation Loss Force: 4.818353458240762, time: 0.06821608543395996
Test Loss Energy: 7.914495681474929, Test Loss Force: 8.741608270423933, time: 9.450012922286987


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.032895423129964, Training Loss Force: 4.48470426664608, time: 0.7069292068481445
Validation Loss Energy: 4.228258622624969, Validation Loss Force: 4.597253461784327, time: 0.06047940254211426
Test Loss Energy: 9.140338566502214, Test Loss Force: 8.797964199128392, time: 9.688498973846436


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.072999961112364, Training Loss Force: 4.505292570873942, time: 0.6871840953826904
Validation Loss Energy: 3.222111720568034, Validation Loss Force: 4.766106369840266, time: 0.06176257133483887
Test Loss Energy: 8.817591414131059, Test Loss Force: 8.826285331580802, time: 9.479770421981812


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.997190268082755, Training Loss Force: 4.506205449200787, time: 0.6550962924957275
Validation Loss Energy: 2.0729026756168194, Validation Loss Force: 4.664756949387211, time: 0.061231136322021484
Test Loss Energy: 6.661010403852691, Test Loss Force: 8.74769876819886, time: 9.550565481185913


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.8985520427112204, Training Loss Force: 4.519210934885585, time: 0.6686182022094727
Validation Loss Energy: 3.423110037206692, Validation Loss Force: 4.867661759253303, time: 0.06216835975646973
Test Loss Energy: 6.831296304443378, Test Loss Force: 8.777621323159101, time: 10.429278135299683


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.073617906008997, Training Loss Force: 4.52850370040264, time: 0.6515331268310547
Validation Loss Energy: 3.1462403264611836, Validation Loss Force: 4.818679000532109, time: 0.0601954460144043
Test Loss Energy: 6.839735793831629, Test Loss Force: 8.683750278614628, time: 9.478529214859009


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0361927784452742, Training Loss Force: 4.499420090333613, time: 0.6996691226959229
Validation Loss Energy: 2.4661849291991054, Validation Loss Force: 4.573176915042593, time: 0.060274600982666016
Test Loss Energy: 7.907573566901279, Test Loss Force: 8.843534346840398, time: 9.459991693496704

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–†â–†â–‚â–‚â–‚â–„â–ˆâ–†â–‚â–â–â–…â–ˆâ–‡â–â–â–‚â–…
wandb:   test_error_force â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–â–‚â–ƒâ–„â–‚â–ƒâ–â–„
wandb:          test_loss â–â–„â–†â–‡â–ƒâ–ƒâ–‚â–…â–ˆâ–†â–ƒâ–ƒâ–‚â–„â–ˆâ–‡â–‚â–ƒâ–‚â–„
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–
wandb:  train_error_force â–ˆâ–†â–‚â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–„â–‚â–ƒâ–†â–„â–â–„â–„â–‚
wandb:  valid_error_force â–ˆâ–â–‚â–…â–…â–ƒâ–‚â–„â–†â–„â–…â–‚â–…â–„â–‚â–„â–ƒâ–„â–„â–‚
wandb:         valid_loss â–ˆâ–â–„â–ƒâ–‚â–ƒâ–â–‚â–†â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–â–„â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1296
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.90757
wandb:   test_error_force 8.84353
wandb:          test_loss 5.73192
wandb: train_error_energy 3.03619
wandb:  train_error_force 4.49942
wandb:         train_loss 1.47975
wandb: valid_error_energy 2.46618
wandb:  valid_error_force 4.57318
wandb:         valid_loss 1.34022
wandb: 
wandb: ğŸš€ View run al_73_49 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/g01k1t8a
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_200557-g01k1t8a/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.7692890167236328, Uncertainty Bias: 0.06264173984527588
0.00023913383 0.02768135
3.234486 19.297434
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2624 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2732 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_204848-svxcn0t6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_50
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svxcn0t6
Training model 50. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.119498422698856, Training Loss Force: 4.92267972621286, time: 0.6824967861175537
Validation Loss Energy: 2.911412109150863, Validation Loss Force: 5.631876296233664, time: 0.06441926956176758
Test Loss Energy: 7.63899870502954, Test Loss Force: 9.252493172806016, time: 9.682177782058716


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9212535993304183, Training Loss Force: 5.063462098211332, time: 0.6632239818572998
Validation Loss Energy: 2.484331907919355, Validation Loss Force: 4.94829270635436, time: 0.07416272163391113
Test Loss Energy: 7.622414955229557, Test Loss Force: 8.808234511540286, time: 9.692562103271484


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2002739592192775, Training Loss Force: 4.663322862330251, time: 0.6864488124847412
Validation Loss Energy: 2.075018143837706, Validation Loss Force: 4.718460294002076, time: 0.0642251968383789
Test Loss Energy: 7.53147231539548, Test Loss Force: 8.87651545720973, time: 9.917613506317139


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.097460127973255, Training Loss Force: 4.52793441142987, time: 0.6892123222351074
Validation Loss Energy: 2.0223345125766192, Validation Loss Force: 4.934436896079857, time: 0.06245899200439453
Test Loss Energy: 6.849625073868366, Test Loss Force: 8.806069276765285, time: 9.707239389419556


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1385579305596587, Training Loss Force: 4.504570503712291, time: 0.6963510513305664
Validation Loss Energy: 1.9657725414663343, Validation Loss Force: 5.325416973362396, time: 0.0621485710144043
Test Loss Energy: 6.9268292232542805, Test Loss Force: 8.842243817092564, time: 9.786550760269165


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.140554471732801, Training Loss Force: 4.493811700831311, time: 0.6628425121307373
Validation Loss Energy: 1.7937222158094455, Validation Loss Force: 4.4295388384023715, time: 0.06159329414367676
Test Loss Energy: 7.42657586521494, Test Loss Force: 8.831210586559598, time: 9.932670831680298


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.155337913522807, Training Loss Force: 4.499892746328006, time: 0.6715435981750488
Validation Loss Energy: 2.134908128003028, Validation Loss Force: 4.427895540105425, time: 0.06241416931152344
Test Loss Energy: 8.003119374874892, Test Loss Force: 8.83765405806568, time: 9.73749589920044


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1503083307415247, Training Loss Force: 4.4954015531022815, time: 0.6558587551116943
Validation Loss Energy: 1.9160555312364425, Validation Loss Force: 4.638071833600934, time: 0.06314945220947266
Test Loss Energy: 6.739368058689391, Test Loss Force: 8.74802861231821, time: 9.708925247192383


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.091276402130036, Training Loss Force: 4.490743216812286, time: 0.6996119022369385
Validation Loss Energy: 1.8244977081391305, Validation Loss Force: 4.608137306968132, time: 0.06186556816101074
Test Loss Energy: 6.906287365006637, Test Loss Force: 8.83089632694885, time: 9.88900089263916


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1311768312544648, Training Loss Force: 4.506516903595438, time: 0.6549625396728516
Validation Loss Energy: 2.3990232387352197, Validation Loss Force: 4.849714626091524, time: 0.06258487701416016
Test Loss Energy: 7.826333885490116, Test Loss Force: 8.830424151778779, time: 9.749868392944336


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.163797117092081, Training Loss Force: 4.496451237180004, time: 0.6627895832061768
Validation Loss Energy: 1.8432134395253663, Validation Loss Force: 5.010896359401103, time: 0.060886383056640625
Test Loss Energy: 7.556648370903016, Test Loss Force: 8.822515694495163, time: 9.721438646316528


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1059026259256295, Training Loss Force: 4.49061770744735, time: 0.6474330425262451
Validation Loss Energy: 1.801597633829906, Validation Loss Force: 4.717901171776651, time: 0.0668342113494873
Test Loss Energy: 6.952790960431285, Test Loss Force: 8.810440003964226, time: 9.941160917282104


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.168194387385863, Training Loss Force: 4.496702733833897, time: 0.6538329124450684
Validation Loss Energy: 1.8603347484921864, Validation Loss Force: 4.653241614505556, time: 0.06448149681091309
Test Loss Energy: 6.730037407741698, Test Loss Force: 8.852114047842159, time: 9.805103063583374


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1934063295336372, Training Loss Force: 4.493958450660387, time: 0.6877901554107666
Validation Loss Energy: 2.1755541539006864, Validation Loss Force: 4.974329632256842, time: 0.06397652626037598
Test Loss Energy: 7.871231073416004, Test Loss Force: 8.809888110908298, time: 10.569986581802368


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.110587734107207, Training Loss Force: 4.4996865329750575, time: 0.6576836109161377
Validation Loss Energy: 2.27006885625406, Validation Loss Force: 4.888388026025408, time: 0.06192803382873535
Test Loss Energy: 7.797283207309154, Test Loss Force: 8.786038487342406, time: 9.917893171310425


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0965923102782074, Training Loss Force: 4.492637772801116, time: 0.6500892639160156
Validation Loss Energy: 1.9478652660816755, Validation Loss Force: 4.617467812189943, time: 0.06263041496276855
Test Loss Energy: 6.755607249553482, Test Loss Force: 8.784936524552771, time: 9.768849611282349


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.211680403457619, Training Loss Force: 4.492515380804222, time: 0.6363658905029297
Validation Loss Energy: 1.8817261836704635, Validation Loss Force: 4.787525360325352, time: 0.061786651611328125
Test Loss Energy: 7.067932499622455, Test Loss Force: 8.788797612206388, time: 9.801483154296875


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0786845596850054, Training Loss Force: 4.511708983259177, time: 0.7765512466430664
Validation Loss Energy: 1.922557358962961, Validation Loss Force: 4.798313457776407, time: 0.0629270076751709
Test Loss Energy: 7.103229245533892, Test Loss Force: 8.98199731506718, time: 9.77874755859375


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.118928219720495, Training Loss Force: 4.558182086915213, time: 0.6780130863189697
Validation Loss Energy: 2.0689474035777042, Validation Loss Force: 4.751153023345485, time: 0.0681772232055664
Test Loss Energy: 7.542406596889549, Test Loss Force: 8.85421184767435, time: 9.754904747009277


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.08827764070846, Training Loss Force: 4.511414104138511, time: 0.6811292171478271
Validation Loss Energy: 1.8110079102732466, Validation Loss Force: 4.733219250332461, time: 0.06315302848815918
Test Loss Energy: 6.726668437553495, Test Loss Force: 8.866093193507364, time: 10.002055883407593

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–…â–‚â–‚â–…â–ˆâ–â–‚â–‡â–†â–‚â–â–‡â–‡â–â–ƒâ–ƒâ–…â–
wandb:   test_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–‚â–ƒ
wandb:          test_loss â–â–ƒâ–…â–‚â–ƒâ–…â–ˆâ–â–ƒâ–‡â–„â–…â–â–…â–…â–‚â–‚â–ˆâ–…â–ƒ
wandb: train_error_energy â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–†â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–ƒâ–‚â–‚â–â–ƒâ–‚â–â–…â–â–â–â–ƒâ–„â–‚â–‚â–‚â–ƒâ–
wandb:  valid_error_force â–ˆâ–„â–ƒâ–„â–†â–â–â–‚â–‚â–ƒâ–„â–ƒâ–‚â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb:         valid_loss â–ˆâ–…â–ƒâ–„â–†â–â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1297
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.72667
wandb:   test_error_force 8.86609
wandb:          test_loss 6.50565
wandb: train_error_energy 2.08828
wandb:  train_error_force 4.51141
wandb:         train_loss 1.10673
wandb: valid_error_energy 1.81101
wandb:  valid_error_force 4.73322
wandb:         valid_loss 1.09009
wandb: 
wandb: ğŸš€ View run al_73_50 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/svxcn0t6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_204848-svxcn0t6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0729002952575684, Uncertainty Bias: 0.10535556077957153
0.00039291382 2.3841858e-06
3.313065 18.563992
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 835 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2687 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1414 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_213130-ymsj3j12
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_51
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ymsj3j12
Training model 51. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.69420759473699, Training Loss Force: 5.860456916957091, time: 0.7181668281555176
Validation Loss Energy: 1.9488298688218344, Validation Loss Force: 5.048767037063918, time: 0.07178950309753418
Test Loss Energy: 6.767079842451381, Test Loss Force: 8.892374615961112, time: 10.429824113845825


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3864044486951705, Training Loss Force: 5.225090712203926, time: 0.7663054466247559
Validation Loss Energy: 1.9738365045861088, Validation Loss Force: 5.5446970948891625, time: 0.06604218482971191
Test Loss Energy: 6.633386433340688, Test Loss Force: 8.859147287143506, time: 10.75584077835083


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.794958568036461, Training Loss Force: 4.850559470847857, time: 0.6619281768798828
Validation Loss Energy: 3.77000618831302, Validation Loss Force: 6.268610075140616, time: 0.06431174278259277
Test Loss Energy: 8.508800508643095, Test Loss Force: 9.342972012627841, time: 11.034398555755615


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.5525586167617806, Training Loss Force: 5.721748898136354, time: 0.6862733364105225
Validation Loss Energy: 2.428951085293644, Validation Loss Force: 6.0009141105381865, time: 0.0672905445098877
Test Loss Energy: 7.004655225776999, Test Loss Force: 9.730697029562908, time: 9.724236011505127


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.103699746487579, Training Loss Force: 4.721609085549414, time: 0.7109830379486084
Validation Loss Energy: 1.931314268464863, Validation Loss Force: 4.5639588577394745, time: 0.05928206443786621
Test Loss Energy: 6.579471149667954, Test Loss Force: 8.768002799477355, time: 10.946807384490967


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.063710396340558, Training Loss Force: 4.4891500679517655, time: 0.8860466480255127
Validation Loss Energy: 2.007085350121473, Validation Loss Force: 4.717414639692798, time: 0.09522294998168945
Test Loss Energy: 7.601845266836093, Test Loss Force: 8.75046409515633, time: 10.077221155166626


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.085729944520553, Training Loss Force: 4.48680012640474, time: 0.7106418609619141
Validation Loss Energy: 2.26205276700066, Validation Loss Force: 4.688326923821959, time: 0.06554508209228516
Test Loss Energy: 7.865000809365857, Test Loss Force: 8.831259154081165, time: 9.101710557937622


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.052598317997655, Training Loss Force: 4.484944423466396, time: 0.6782257556915283
Validation Loss Energy: 1.8249371456986188, Validation Loss Force: 4.652770446592773, time: 0.06108546257019043
Test Loss Energy: 7.0001190355839125, Test Loss Force: 8.776115893203501, time: 9.0296311378479


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1200339322431927, Training Loss Force: 4.4942604008841744, time: 0.7913572788238525
Validation Loss Energy: 2.081813115494839, Validation Loss Force: 4.760464379020748, time: 0.08939003944396973
Test Loss Energy: 6.977139742937152, Test Loss Force: 8.793569465630744, time: 9.039900779724121


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.056205175279373, Training Loss Force: 4.5043829945675995, time: 0.6694374084472656
Validation Loss Energy: 1.857374195195217, Validation Loss Force: 4.526561352011758, time: 0.06720256805419922
Test Loss Energy: 7.542221445745998, Test Loss Force: 8.805849778614524, time: 9.029790878295898


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0761673528772264, Training Loss Force: 4.482969603396891, time: 0.680840253829956
Validation Loss Energy: 2.1978941039733293, Validation Loss Force: 4.513533648290959, time: 0.06716299057006836
Test Loss Energy: 7.947810347893249, Test Loss Force: 8.79119206796292, time: 9.815176725387573


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0652576074700826, Training Loss Force: 4.499519574563251, time: 0.6698064804077148
Validation Loss Energy: 2.120010894133021, Validation Loss Force: 4.870091524973667, time: 0.08606958389282227
Test Loss Energy: 7.088473688696855, Test Loss Force: 8.77479344365873, time: 9.208276748657227


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.104761978786318, Training Loss Force: 4.49682122640526, time: 0.6607887744903564
Validation Loss Energy: 1.6469150562170929, Validation Loss Force: 4.9088613406477375, time: 0.07029438018798828
Test Loss Energy: 6.857928807357636, Test Loss Force: 8.842279215657731, time: 9.025674819946289


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0758081956912773, Training Loss Force: 4.515130821488971, time: 0.67327880859375
Validation Loss Energy: 2.6907063484172933, Validation Loss Force: 4.808586744162078, time: 0.06690382957458496
Test Loss Energy: 8.107860763391757, Test Loss Force: 8.83313049822614, time: 9.113297700881958


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.147354874344712, Training Loss Force: 4.486695580525248, time: 0.7006332874298096
Validation Loss Energy: 1.9547941732300833, Validation Loss Force: 4.626663157240177, time: 0.06458425521850586
Test Loss Energy: 7.509453678066219, Test Loss Force: 8.803369337593452, time: 9.227588653564453


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1558560917801546, Training Loss Force: 4.493542015909865, time: 0.6505913734436035
Validation Loss Energy: 2.026358144043534, Validation Loss Force: 4.997445584303044, time: 0.06096243858337402
Test Loss Energy: 6.784899373368667, Test Loss Force: 8.819774490417101, time: 9.003384590148926


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.141497766121886, Training Loss Force: 4.528465873802606, time: 0.650597333908081
Validation Loss Energy: 1.6221973893369463, Validation Loss Force: 4.505499300167593, time: 0.059763193130493164
Test Loss Energy: 6.969558709557454, Test Loss Force: 8.806457784295226, time: 8.962957620620728


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.069871803675114, Training Loss Force: 4.498920529389247, time: 0.7019009590148926
Validation Loss Energy: 2.080640205768664, Validation Loss Force: 4.584916032415906, time: 0.0638115406036377
Test Loss Energy: 7.864211026387197, Test Loss Force: 8.84966291987347, time: 10.607207536697388


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1537267067376473, Training Loss Force: 4.486960556808904, time: 0.7118988037109375
Validation Loss Energy: 2.1326028343352377, Validation Loss Force: 4.822061344858751, time: 0.06649041175842285
Test Loss Energy: 7.551314360657492, Test Loss Force: 8.811150908438101, time: 11.166550874710083


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.092903874624758, Training Loss Force: 4.488509562868981, time: 0.6991884708404541
Validation Loss Energy: 1.9711035748235641, Validation Loss Force: 4.871530858332944, time: 0.06995820999145508
Test Loss Energy: 6.85775603475331, Test Loss Force: 8.758127597726515, time: 10.89609694480896

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–ƒâ–â–…â–†â–ƒâ–‚â–„â–†â–ƒâ–‚â–‡â–„â–‚â–‚â–†â–…â–‚
wandb:   test_error_force â–‚â–‚â–…â–ˆâ–â–â–‚â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–
wandb:          test_loss â–â–„â–ˆâ–†â–„â–†â–†â–…â–…â–†â–†â–…â–…â–‡â–†â–…â–…â–‡â–†â–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–ƒâ–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–ˆâ–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–â–„â–‚â–‚â–â–‚â–ƒâ–‚
wandb:  valid_error_force â–ƒâ–…â–ˆâ–‡â–â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–â–ƒâ–â–â–‚â–‚
wandb:         valid_loss â–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1299
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.85776
wandb:   test_error_force 8.75813
wandb:          test_loss 6.50068
wandb: train_error_energy 2.0929
wandb:  train_error_force 4.48851
wandb:         train_loss 1.09279
wandb: valid_error_energy 1.9711
wandb:  valid_error_force 4.87153
wandb:         valid_loss 1.5428
wandb: 
wandb: ğŸš€ View run al_73_51 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ymsj3j12
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_213130-ymsj3j12/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0578339099884033, Uncertainty Bias: 0.10118599236011505
1.9073486e-05 0.0005311966
3.213802 16.475449
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1993 steps.
Found uncertainty sample 8 after 1375 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2177 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2038 steps.
Found uncertainty sample 85 after 1783 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_221354-c38hssta
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_52
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/c38hssta
Training model 52. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.863746633326809, Training Loss Force: 6.233449547100527, time: 1.0964696407318115
Validation Loss Energy: 3.7317549690798146, Validation Loss Force: 4.97679858774689, time: 0.1148984432220459
Test Loss Energy: 7.099138148813181, Test Loss Force: 8.894445271142025, time: 9.829506874084473


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.076990170483571, Training Loss Force: 4.916253440351837, time: 0.7131788730621338
Validation Loss Energy: 2.815657918996682, Validation Loss Force: 4.952120166303713, time: 0.07140660285949707
Test Loss Energy: 8.288370001365202, Test Loss Force: 8.88185078714883, time: 9.96554446220398


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.971884348693489, Training Loss Force: 4.5498826864748265, time: 0.6543705463409424
Validation Loss Energy: 4.051731756458349, Validation Loss Force: 4.784357891724529, time: 0.06478357315063477
Test Loss Energy: 8.692299370186571, Test Loss Force: 8.774545220022338, time: 10.163887739181519


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9598913151759287, Training Loss Force: 4.512630149223017, time: 0.6860973834991455
Validation Loss Energy: 2.984373774193302, Validation Loss Force: 4.9079163327924205, time: 0.06306886672973633
Test Loss Energy: 8.396078075032653, Test Loss Force: 8.742748112616132, time: 9.81762981414795


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.042124719793997, Training Loss Force: 4.519757777722255, time: 0.6907520294189453
Validation Loss Energy: 2.1905307693212164, Validation Loss Force: 4.612649474541213, time: 0.06476855278015137
Test Loss Energy: 6.817135803502368, Test Loss Force: 8.753097485398706, time: 9.84804391860962


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0043242019204914, Training Loss Force: 4.499511591059725, time: 0.6590278148651123
Validation Loss Energy: 3.264775685600663, Validation Loss Force: 4.559175479146654, time: 0.06216001510620117
Test Loss Energy: 6.9121772390468905, Test Loss Force: 8.747300808305386, time: 10.031033992767334


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9705725042821647, Training Loss Force: 4.513536857985234, time: 0.6808860301971436
Validation Loss Energy: 2.5202099193952616, Validation Loss Force: 4.725031260498405, time: 0.0669565200805664
Test Loss Energy: 6.918492809861876, Test Loss Force: 8.735925217548614, time: 9.797621011734009


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0119777858043215, Training Loss Force: 4.4917592506942, time: 0.6692750453948975
Validation Loss Energy: 2.786541033467727, Validation Loss Force: 5.036285318088936, time: 0.06199216842651367
Test Loss Energy: 8.093860201851106, Test Loss Force: 8.730168998623043, time: 10.65309453010559


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0774930253020103, Training Loss Force: 4.498814886456891, time: 0.7003190517425537
Validation Loss Energy: 3.947823756184011, Validation Loss Force: 4.822909268966445, time: 0.0920877456665039
Test Loss Energy: 8.6964068814705, Test Loss Force: 8.770695958315406, time: 10.026926755905151


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9227566785214103, Training Loss Force: 4.4936173432526445, time: 0.7089228630065918
Validation Loss Energy: 3.038847220049357, Validation Loss Force: 4.691488157686697, time: 0.06177330017089844
Test Loss Energy: 8.48172886953047, Test Loss Force: 8.77413301862998, time: 9.853669881820679


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.105958307592092, Training Loss Force: 4.51174720631891, time: 0.680124044418335
Validation Loss Energy: 2.0252995749237934, Validation Loss Force: 4.369446447983401, time: 0.06282496452331543
Test Loss Energy: 6.8874340127216005, Test Loss Force: 8.785209281432657, time: 10.009225368499756


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.982837541738863, Training Loss Force: 4.522119819436529, time: 0.6777660846710205
Validation Loss Energy: 3.232291597246988, Validation Loss Force: 4.62848436818472, time: 0.06290912628173828
Test Loss Energy: 6.9070396906048845, Test Loss Force: 8.772501341097675, time: 9.88993525505066


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9417990397476874, Training Loss Force: 4.517632417017239, time: 0.6698756217956543
Validation Loss Energy: 2.4102756013555346, Validation Loss Force: 4.741867719960297, time: 0.06236147880554199
Test Loss Energy: 6.933289356474677, Test Loss Force: 8.764884862520526, time: 9.853034019470215


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.026152903634084, Training Loss Force: 4.505382366280252, time: 0.6950075626373291
Validation Loss Energy: 2.32884427000944, Validation Loss Force: 4.591833694772445, time: 0.062380075454711914
Test Loss Energy: 7.6742555756767485, Test Loss Force: 8.733770918043712, time: 10.076021909713745


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.032435861167543, Training Loss Force: 4.5060907365739515, time: 0.6599247455596924
Validation Loss Energy: 3.6428258109174667, Validation Loss Force: 4.810981996164823, time: 0.06773877143859863
Test Loss Energy: 8.996181815312054, Test Loss Force: 8.741087014777195, time: 9.820373296737671


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0302981667642244, Training Loss Force: 4.507989908874343, time: 0.6646711826324463
Validation Loss Energy: 3.1071348370496263, Validation Loss Force: 4.648448215801169, time: 0.06847715377807617
Test Loss Energy: 8.327337267447163, Test Loss Force: 8.749485955064745, time: 9.820714235305786


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0599065102530156, Training Loss Force: 4.507630814144374, time: 0.6561055183410645
Validation Loss Energy: 2.132135785801654, Validation Loss Force: 4.803278979730597, time: 0.06367254257202148
Test Loss Energy: 6.7335741981858925, Test Loss Force: 8.754874553059429, time: 10.038854122161865


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.08117980722973, Training Loss Force: 4.506306367202486, time: 0.6834208965301514
Validation Loss Energy: 3.76659356098253, Validation Loss Force: 4.737220837553929, time: 0.06908869743347168
Test Loss Energy: 6.893118389953722, Test Loss Force: 8.714638951864186, time: 9.804537773132324


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9884355907032667, Training Loss Force: 4.5071439724961, time: 0.6664941310882568
Validation Loss Energy: 2.7000364083008135, Validation Loss Force: 4.894092809544077, time: 0.062150001525878906
Test Loss Energy: 6.609146504570389, Test Loss Force: 8.732891801602678, time: 9.813927412033081


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.069819186672334, Training Loss Force: 4.507507162165972, time: 0.6700270175933838
Validation Loss Energy: 2.652524490623045, Validation Loss Force: 4.635872530446605, time: 0.06258273124694824
Test Loss Energy: 8.189120335802754, Test Loss Force: 8.758268553124923, time: 9.96061086654663

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.050 MB of 0.058 MB uploadedwandb: - 0.050 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‡â–†â–‚â–‚â–‚â–…â–‡â–†â–‚â–‚â–‚â–„â–ˆâ–†â–â–‚â–â–†
wandb:   test_error_force â–ˆâ–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–ƒ
wandb:          test_loss â–â–ˆâ–†â–‡â–‚â–‚â–ƒâ–…â–‡â–‡â–‚â–ƒâ–ƒâ–…â–ˆâ–‡â–‚â–ƒâ–‚â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–„â–ˆâ–„â–‚â–…â–ƒâ–„â–ˆâ–…â–â–…â–‚â–‚â–‡â–…â–â–‡â–ƒâ–ƒ
wandb:  valid_error_force â–‡â–‡â–…â–‡â–„â–ƒâ–…â–ˆâ–†â–„â–â–„â–…â–ƒâ–†â–„â–†â–…â–‡â–„
wandb:         valid_loss â–‡â–„â–‡â–…â–‚â–„â–ƒâ–…â–ˆâ–„â–â–…â–ƒâ–‚â–†â–…â–ƒâ–†â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1303
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.18912
wandb:   test_error_force 8.75827
wandb:          test_loss 5.92018
wandb: train_error_energy 3.06982
wandb:  train_error_force 4.50751
wandb:         train_loss 1.49247
wandb: valid_error_energy 2.65252
wandb:  valid_error_force 4.63587
wandb:         valid_loss 1.4248
wandb: 
wandb: ğŸš€ View run al_73_52 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/c38hssta
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_221354-c38hssta/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.2464747428894043, Uncertainty Bias: -0.002562969923019409
0.00013542175 0.0078372955
2.8326302 12.907632
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 416 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 661 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_225635-hto1k212
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_53
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hto1k212
Training model 53. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.475435257730414, Training Loss Force: 5.030640872477858, time: 0.6847467422485352
Validation Loss Energy: 4.456272718731608, Validation Loss Force: 5.065042370278071, time: 0.06450843811035156
Test Loss Energy: 7.116373785271106, Test Loss Force: 8.789391586233476, time: 9.688693046569824


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.422177347559406, Training Loss Force: 4.540927096354253, time: 0.6435091495513916
Validation Loss Energy: 5.605722023691278, Validation Loss Force: 4.769185438790155, time: 0.06332254409790039
Test Loss Energy: 7.5363421992027835, Test Loss Force: 8.700376631667329, time: 10.531757593154907


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.3938227942908314, Training Loss Force: 4.513840676457466, time: 0.6489269733428955
Validation Loss Energy: 4.920990797033863, Validation Loss Force: 5.049851435804587, time: 0.06374192237854004
Test Loss Energy: 7.349178660513697, Test Loss Force: 8.695551734022345, time: 9.965161800384521


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.354777048097318, Training Loss Force: 4.5167626061617865, time: 0.6416611671447754
Validation Loss Energy: 2.125679382580905, Validation Loss Force: 4.581001063492204, time: 0.06346321105957031
Test Loss Energy: 6.89359085890717, Test Loss Force: 8.682623824550557, time: 9.824584245681763


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.376217990501619, Training Loss Force: 4.510055322700512, time: 0.6527743339538574
Validation Loss Energy: 4.271244233238891, Validation Loss Force: 4.687575192785308, time: 0.06253838539123535
Test Loss Energy: 8.967194997709495, Test Loss Force: 8.717449558767354, time: 9.847507953643799


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.4156038230833765, Training Loss Force: 4.523701747944476, time: 0.6857538223266602
Validation Loss Energy: 6.540503575812931, Validation Loss Force: 4.860221937749564, time: 0.06548905372619629
Test Loss Energy: 10.741443009525357, Test Loss Force: 8.75642096812756, time: 9.96074652671814


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.446380278049795, Training Loss Force: 4.5328637686561875, time: 0.6367442607879639
Validation Loss Energy: 5.217498145097034, Validation Loss Force: 4.884697730269947, time: 0.062137603759765625
Test Loss Energy: 9.588947371477667, Test Loss Force: 8.737417935544176, time: 9.771414041519165


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.467993332841989, Training Loss Force: 4.497885769575256, time: 0.662442684173584
Validation Loss Energy: 3.077571165879367, Validation Loss Force: 4.727269976091563, time: 0.06201338768005371
Test Loss Energy: 8.01320678848245, Test Loss Force: 8.630827740264163, time: 9.837412118911743


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.2897985607223195, Training Loss Force: 4.529605228374681, time: 0.7140676975250244
Validation Loss Energy: 3.9773058191122876, Validation Loss Force: 4.935710118256273, time: 0.06691956520080566
Test Loss Energy: 7.008086869752034, Test Loss Force: 8.737836231775777, time: 10.054619073867798


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.570631247316297, Training Loss Force: 4.533846434751941, time: 0.6538896560668945
Validation Loss Energy: 5.770928501813504, Validation Loss Force: 4.882917267779108, time: 0.06375908851623535
Test Loss Energy: 7.691126787846704, Test Loss Force: 8.696906947408358, time: 9.78125286102295


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.425639445456975, Training Loss Force: 4.515398502388105, time: 0.6757416725158691
Validation Loss Energy: 5.221270605767343, Validation Loss Force: 4.700794614640749, time: 0.06451559066772461
Test Loss Energy: 7.4069431149604155, Test Loss Force: 8.701198292473872, time: 9.787763118743896


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.493443552699726, Training Loss Force: 4.50732363934209, time: 0.6670920848846436
Validation Loss Energy: 2.223945169366578, Validation Loss Force: 4.595245654095496, time: 0.06386685371398926
Test Loss Energy: 6.946755845485918, Test Loss Force: 8.684439265916025, time: 9.967557191848755


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.404428406230366, Training Loss Force: 4.515819998788482, time: 0.6721484661102295
Validation Loss Energy: 4.321070240015715, Validation Loss Force: 4.754132559187145, time: 0.06581377983093262
Test Loss Energy: 9.2768342819699, Test Loss Force: 8.72383314509706, time: 9.80218768119812


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.513597195892825, Training Loss Force: 4.535750951111835, time: 0.682450532913208
Validation Loss Energy: 6.011505591133387, Validation Loss Force: 4.728020816451631, time: 0.0632925033569336
Test Loss Energy: 10.192693020691056, Test Loss Force: 8.739106303941552, time: 9.819931030273438


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4261272348068585, Training Loss Force: 4.505737235727405, time: 0.868605375289917
Validation Loss Energy: 5.611993054848043, Validation Loss Force: 4.633781667166343, time: 0.06213831901550293
Test Loss Energy: 10.003387048081187, Test Loss Force: 8.725831730086345, time: 9.767715692520142


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.397448847282215, Training Loss Force: 4.522591334930417, time: 0.6929306983947754
Validation Loss Energy: 2.8684957486413247, Validation Loss Force: 4.678932067216975, time: 0.06106114387512207
Test Loss Energy: 7.980252913697342, Test Loss Force: 8.642833510351661, time: 9.798311948776245


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.424766587835893, Training Loss Force: 4.506862366628913, time: 0.6683480739593506
Validation Loss Energy: 3.8267988446584855, Validation Loss Force: 4.938047476281077, time: 0.062192678451538086
Test Loss Energy: 6.911963812419229, Test Loss Force: 8.653581006240701, time: 9.983060359954834


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.363452091386884, Training Loss Force: 4.5083266715182635, time: 0.6895921230316162
Validation Loss Energy: 5.6410464796704085, Validation Loss Force: 4.889904625578321, time: 0.06952071189880371
Test Loss Energy: 7.523495502181485, Test Loss Force: 8.623351704130323, time: 9.779983043670654


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.533628713205816, Training Loss Force: 4.495010763320224, time: 0.665886402130127
Validation Loss Energy: 4.809204651042027, Validation Loss Force: 4.7688928515324065, time: 0.06242799758911133
Test Loss Energy: 7.503592914227921, Test Loss Force: 8.672718437723661, time: 10.593291997909546


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.455115702694593, Training Loss Force: 4.515946192453721, time: 0.6837329864501953
Validation Loss Energy: 2.2375626123203647, Validation Loss Force: 5.073405155391682, time: 0.06343436241149902
Test Loss Energy: 7.0512187623367595, Test Loss Force: 8.673832482937527, time: 9.974096298217773

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.051 MB of 0.058 MB uploadedwandb: | 0.051 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‚â–â–…â–ˆâ–†â–ƒâ–â–‚â–‚â–â–…â–‡â–‡â–ƒâ–â–‚â–‚â–
wandb:   test_error_force â–ˆâ–„â–„â–ƒâ–…â–‡â–†â–â–†â–„â–„â–„â–…â–†â–…â–‚â–‚â–â–ƒâ–ƒ
wandb:          test_loss â–‚â–‚â–‚â–â–…â–ˆâ–†â–ƒâ–â–ƒâ–‚â–â–…â–†â–‡â–ƒâ–â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‡â–…â–â–„â–ˆâ–†â–ƒâ–„â–‡â–†â–â–„â–‡â–‡â–‚â–„â–‡â–…â–
wandb:  valid_error_force â–ˆâ–„â–ˆâ–â–ƒâ–…â–…â–ƒâ–†â–…â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–†â–…â–„â–ˆ
wandb:         valid_loss â–…â–†â–…â–â–„â–ˆâ–…â–‚â–„â–‡â–…â–â–„â–‡â–†â–‚â–„â–†â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1304
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.05122
wandb:   test_error_force 8.67383
wandb:          test_loss 4.61082
wandb: train_error_energy 4.45512
wandb:  train_error_force 4.51595
wandb:         train_loss 1.87751
wandb: valid_error_energy 2.23756
wandb:  valid_error_force 5.07341
wandb:         valid_loss 1.60262
wandb: 
wandb: ğŸš€ View run al_73_53 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hto1k212
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_225635-hto1k212/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1974916458129883, Uncertainty Bias: -0.07758495211601257
0.00032043457 0.002175331
2.9425888 13.795419
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2498 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3221 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241204_233941-7hzfmk4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_54
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/7hzfmk4g
Training model 54. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8655152197375333, Training Loss Force: 5.111607599220019, time: 0.6736495494842529
Validation Loss Energy: 1.514690053653259, Validation Loss Force: 5.08797862832351, time: 0.06186318397521973
Test Loss Energy: 6.71921527921714, Test Loss Force: 8.772595468358627, time: 9.64001727104187


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1756623032186724, Training Loss Force: 4.6103445067307085, time: 0.6769759654998779
Validation Loss Energy: 1.699315563659133, Validation Loss Force: 4.4992654547581985, time: 0.06629061698913574
Test Loss Energy: 6.793162746617981, Test Loss Force: 8.704891513239213, time: 9.652651071548462


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.168686611110323, Training Loss Force: 4.5977980236199905, time: 0.6849346160888672
Validation Loss Energy: 2.040348947487755, Validation Loss Force: 4.713522605691127, time: 0.061730146408081055
Test Loss Energy: 7.073032481098188, Test Loss Force: 8.772828993499775, time: 9.823811769485474


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0872290536836022, Training Loss Force: 4.548636325800746, time: 0.6635160446166992
Validation Loss Energy: 1.9709570585255438, Validation Loss Force: 4.619752620296309, time: 0.0645296573638916
Test Loss Energy: 7.509373915879695, Test Loss Force: 8.69203350089472, time: 9.639755964279175


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.113362145502351, Training Loss Force: 4.479483337750557, time: 0.6852848529815674
Validation Loss Energy: 1.777770921869903, Validation Loss Force: 4.488688447657483, time: 0.06788945198059082
Test Loss Energy: 6.66447239844838, Test Loss Force: 8.682626972229583, time: 9.73705506324768


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.078878667439752, Training Loss Force: 4.489454929167315, time: 0.7091083526611328
Validation Loss Energy: 1.8875815471990671, Validation Loss Force: 4.821029273367376, time: 0.0714406967163086
Test Loss Energy: 6.811639109546698, Test Loss Force: 8.675924831455967, time: 9.895208597183228


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1035924878461767, Training Loss Force: 4.468611326617215, time: 0.6682703495025635
Validation Loss Energy: 2.3366926893959565, Validation Loss Force: 4.787473033076058, time: 0.06532907485961914
Test Loss Energy: 7.45131219928897, Test Loss Force: 8.660192479868677, time: 9.69191312789917


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.103435831955584, Training Loss Force: 4.474057422897865, time: 0.6649131774902344
Validation Loss Energy: 2.194519219063075, Validation Loss Force: 4.716891144530722, time: 0.06229376792907715
Test Loss Energy: 7.7198972573091424, Test Loss Force: 8.689900530995542, time: 9.671130895614624


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.135108209808031, Training Loss Force: 4.476589355739527, time: 0.6326065063476562
Validation Loss Energy: 2.2194170809495635, Validation Loss Force: 4.5457247040485935, time: 0.06913113594055176
Test Loss Energy: 6.740485815832892, Test Loss Force: 8.74454014923933, time: 9.844716787338257


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1201186062591475, Training Loss Force: 4.484026125046681, time: 0.6674253940582275
Validation Loss Energy: 2.0274636963530654, Validation Loss Force: 4.739218402462048, time: 0.06362509727478027
Test Loss Energy: 6.606131501380944, Test Loss Force: 8.688322317374402, time: 9.641666889190674


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0736061995859716, Training Loss Force: 4.784144585544639, time: 0.6755423545837402
Validation Loss Energy: 1.8023834889131716, Validation Loss Force: 4.810705663754726, time: 0.06104421615600586
Test Loss Energy: 7.887894813900692, Test Loss Force: 8.888305142629502, time: 9.642983436584473


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.821874540935589, Training Loss Force: 5.559933958947212, time: 0.6674773693084717
Validation Loss Energy: 2.819195352383464, Validation Loss Force: 5.144743228356589, time: 0.06190037727355957
Test Loss Energy: 7.139221980583846, Test Loss Force: 8.74082454497869, time: 9.83076810836792


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.193202229624691, Training Loss Force: 4.882699111756601, time: 0.7290685176849365
Validation Loss Energy: 2.1793777171399853, Validation Loss Force: 4.7952804813397245, time: 0.061484575271606445
Test Loss Energy: 7.882422128575344, Test Loss Force: 8.756126769724473, time: 9.693522214889526


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.167483089807538, Training Loss Force: 4.576822340249673, time: 0.6788654327392578
Validation Loss Energy: 1.950250497972854, Validation Loss Force: 4.581917792365989, time: 0.06360459327697754
Test Loss Energy: 7.586228719525983, Test Loss Force: 8.696338467249769, time: 9.724624633789062


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1106491554902767, Training Loss Force: 4.485328391969252, time: 0.6861295700073242
Validation Loss Energy: 2.268173273814777, Validation Loss Force: 4.87973309899234, time: 0.06262493133544922
Test Loss Energy: 6.632704193730477, Test Loss Force: 8.696573922967385, time: 9.850284576416016


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0716715732101907, Training Loss Force: 4.459580897939792, time: 0.6523575782775879
Validation Loss Energy: 1.92000412320118, Validation Loss Force: 4.704335276730147, time: 0.07086610794067383
Test Loss Energy: 6.814316506673475, Test Loss Force: 8.668429261059252, time: 9.67870020866394


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.090360968538966, Training Loss Force: 4.46442401703518, time: 0.6687772274017334
Validation Loss Energy: 2.4107439859039936, Validation Loss Force: 4.841853514563689, time: 0.06245541572570801
Test Loss Energy: 7.910300872227727, Test Loss Force: 8.72844904618116, time: 10.48266887664795


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.091693923071515, Training Loss Force: 4.460998844199151, time: 0.7229132652282715
Validation Loss Energy: 1.9580885075767984, Validation Loss Force: 4.824064031157226, time: 0.09262824058532715
Test Loss Energy: 7.585462474191598, Test Loss Force: 8.671344757954028, time: 9.824181318283081


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.080390001682008, Training Loss Force: 4.475457957516203, time: 0.6506326198577881
Validation Loss Energy: 2.414184558212297, Validation Loss Force: 4.903192184192417, time: 0.061537742614746094
Test Loss Energy: 6.87639620756178, Test Loss Force: 8.74637197718865, time: 9.669735431671143


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.011202404872492, Training Loss Force: 4.4684892278918795, time: 0.6802787780761719
Validation Loss Energy: 1.699132139950175, Validation Loss Force: 4.78542625828669, time: 0.06287240982055664
Test Loss Energy: 6.810669249016759, Test Loss Force: 8.714643596439462, time: 9.865590810775757

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–„â–†â–â–‚â–†â–‡â–‚â–â–ˆâ–„â–ˆâ–†â–â–‚â–ˆâ–†â–‚â–‚
wandb:   test_error_force â–„â–‚â–„â–‚â–‚â–â–â–‚â–„â–‚â–ˆâ–ƒâ–„â–‚â–‚â–â–ƒâ–â–„â–ƒ
wandb:          test_loss â–ƒâ–„â–‡â–‡â–„â–†â–‡â–ˆâ–…â–„â–„â–â–ƒâ–†â–„â–…â–ˆâ–‡â–…â–†
wandb: train_error_energy â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–…â–ˆâ–…â–‚â–â–â–â–â–â–
wandb:  train_error_force â–…â–‚â–‚â–‚â–â–â–â–â–â–â–ƒâ–ˆâ–„â–‚â–â–â–â–â–â–
wandb:         train_loss â–†â–‚â–‚â–â–â–â–â–â–â–â–…â–ˆâ–†â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–„â–ƒâ–‚â–ƒâ–…â–…â–…â–„â–ƒâ–ˆâ–…â–ƒâ–…â–ƒâ–†â–ƒâ–†â–‚
wandb:  valid_error_force â–‡â–â–ƒâ–‚â–â–…â–„â–ƒâ–‚â–„â–„â–ˆâ–„â–‚â–…â–ƒâ–…â–…â–…â–„
wandb:         valid_loss â–ƒâ–â–ƒâ–‚â–â–ƒâ–„â–…â–„â–ƒâ–‚â–ˆâ–ƒâ–‚â–‡â–ƒâ–„â–„â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1305
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.81067
wandb:   test_error_force 8.71464
wandb:          test_loss 6.60309
wandb: train_error_energy 2.0112
wandb:  train_error_force 4.46849
wandb:         train_loss 1.0624
wandb: valid_error_energy 1.69913
wandb:  valid_error_force 4.78543
wandb:         valid_loss 1.10415
wandb: 
wandb: ğŸš€ View run al_73_54 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/7hzfmk4g
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241204_233941-7hzfmk4g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.5670504570007324, Uncertainty Bias: 0.06208565831184387
4.196167e-05 0.0022115707
3.0421984 10.473232
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1945 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2537 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3693 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2247 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2597 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_002214-tz6u62bc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tz6u62bc
Training model 55. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.861887302510674, Training Loss Force: 5.957782624478908, time: 0.7435140609741211
Validation Loss Energy: 1.957755227532631, Validation Loss Force: 5.143459763399461, time: 0.07062339782714844
Test Loss Energy: 6.801341554555736, Test Loss Force: 8.904255024485261, time: 10.344903469085693


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1353146675539443, Training Loss Force: 4.762689739896105, time: 0.6626906394958496
Validation Loss Energy: 2.2021098989131804, Validation Loss Force: 4.862902428928242, time: 0.06232285499572754
Test Loss Energy: 7.57646067409565, Test Loss Force: 8.748129380016103, time: 10.515189409255981


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1215771000268844, Training Loss Force: 4.514369086633617, time: 0.7412402629852295
Validation Loss Energy: 2.1268509562922038, Validation Loss Force: 4.7548021253089505, time: 0.06960225105285645
Test Loss Energy: 7.813027536398042, Test Loss Force: 8.806662094311783, time: 10.335585594177246


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.036911176194379, Training Loss Force: 4.489427459398044, time: 0.8237671852111816
Validation Loss Energy: 2.155987325371428, Validation Loss Force: 4.714994894084001, time: 0.06837773323059082
Test Loss Energy: 7.044110316822829, Test Loss Force: 8.760646375146512, time: 10.46406626701355


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.106690106222113, Training Loss Force: 4.491291819278304, time: 0.6826596260070801
Validation Loss Energy: 2.1113359268768206, Validation Loss Force: 4.64764326683864, time: 0.06769967079162598
Test Loss Energy: 6.736911850133591, Test Loss Force: 8.699201805937273, time: 10.559977293014526


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0974452906047993, Training Loss Force: 4.472915836203376, time: 0.7173349857330322
Validation Loss Energy: 2.5302760121406465, Validation Loss Force: 4.724156393424055, time: 0.06651115417480469
Test Loss Energy: 8.076676919456036, Test Loss Force: 8.757856006653679, time: 10.525807619094849


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.140194874639515, Training Loss Force: 4.4802573031160735, time: 0.7247433662414551
Validation Loss Energy: 2.2368806880609613, Validation Loss Force: 4.8685128007290395, time: 0.06990885734558105
Test Loss Energy: 7.909027533470609, Test Loss Force: 8.801929001640117, time: 10.57420563697815


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0868578343470894, Training Loss Force: 4.498288616076923, time: 0.6763291358947754
Validation Loss Energy: 1.7534752130212896, Validation Loss Force: 4.669388022284218, time: 0.06474876403808594
Test Loss Energy: 6.766064643685395, Test Loss Force: 8.738122428079295, time: 10.6038076877594


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.040692543630525, Training Loss Force: 4.487181911663774, time: 0.7319900989532471
Validation Loss Energy: 1.7482734947705572, Validation Loss Force: 4.763633406305592, time: 0.06975817680358887
Test Loss Energy: 6.815925280760541, Test Loss Force: 8.69251370614373, time: 10.228507995605469


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0343745021291957, Training Loss Force: 4.48846294355316, time: 0.701894998550415
Validation Loss Energy: 2.4350281716243054, Validation Loss Force: 4.647886866884285, time: 0.0680701732635498
Test Loss Energy: 7.963909168594071, Test Loss Force: 8.75151402098263, time: 10.520503282546997


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0933614923053683, Training Loss Force: 4.490448315967801, time: 0.7106521129608154
Validation Loss Energy: 2.3064330658100998, Validation Loss Force: 4.655343388573969, time: 0.0637209415435791
Test Loss Energy: 7.9595107254984, Test Loss Force: 8.746500714929207, time: 10.639502763748169


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0273917524951117, Training Loss Force: 4.503916736237937, time: 0.719810962677002
Validation Loss Energy: 2.266794283794046, Validation Loss Force: 5.008002996518918, time: 0.0707404613494873
Test Loss Energy: 6.9142223630534785, Test Loss Force: 8.82215555804551, time: 10.252424478530884


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0419810485136876, Training Loss Force: 4.492660930392292, time: 0.7047810554504395
Validation Loss Energy: 1.809107095109034, Validation Loss Force: 4.674625645934731, time: 0.07956957817077637
Test Loss Energy: 6.758041538605187, Test Loss Force: 8.78683141800009, time: 10.702965259552002


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.065401476177648, Training Loss Force: 4.532471327863876, time: 0.7193586826324463
Validation Loss Energy: 2.2013141907202076, Validation Loss Force: 4.871705876281643, time: 0.06771206855773926
Test Loss Energy: 7.862944248792138, Test Loss Force: 8.893294810779244, time: 11.431556701660156


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1067328804219496, Training Loss Force: 4.511109394989696, time: 0.6994848251342773
Validation Loss Energy: 2.1876339550672688, Validation Loss Force: 4.85012277863601, time: 0.06376981735229492
Test Loss Energy: 7.982504007829721, Test Loss Force: 8.692735908966839, time: 10.452771186828613


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1195310882866627, Training Loss Force: 4.51035752274822, time: 0.709665060043335
Validation Loss Energy: 1.5612427683176575, Validation Loss Force: 4.723988055549732, time: 0.0695950984954834
Test Loss Energy: 6.8003055018332965, Test Loss Force: 8.70292155580777, time: 10.99556040763855


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.07220935721429, Training Loss Force: 4.48637426351672, time: 0.6742260456085205
Validation Loss Energy: 1.7897764628763184, Validation Loss Force: 5.114477815372938, time: 0.06466007232666016
Test Loss Energy: 6.921246786521939, Test Loss Force: 8.769973689554439, time: 10.50215220451355


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.075825789269283, Training Loss Force: 4.502354489510107, time: 0.7361679077148438
Validation Loss Energy: 2.516412519780609, Validation Loss Force: 5.081018658829245, time: 0.06762146949768066
Test Loss Energy: 8.160555176619319, Test Loss Force: 8.728542338724269, time: 10.425552606582642


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0621755922272254, Training Loss Force: 4.501631216676497, time: 0.669701337814331
Validation Loss Energy: 2.2767739809108107, Validation Loss Force: 4.6854320022557525, time: 0.06848311424255371
Test Loss Energy: 7.797087132553577, Test Loss Force: 8.778824739141172, time: 10.963866233825684


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1441970918517375, Training Loss Force: 4.480180645189372, time: 0.7253358364105225
Validation Loss Energy: 1.9027062932689256, Validation Loss Force: 4.63432921059618, time: 0.06794571876525879
Test Loss Energy: 6.743932074365068, Test Loss Force: 8.781836886103347, time: 10.20836353302002

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–†â–ƒâ–â–ˆâ–‡â–â–â–‡â–‡â–‚â–â–‡â–‡â–â–‚â–ˆâ–†â–
wandb:   test_error_force â–ˆâ–ƒâ–…â–ƒâ–â–ƒâ–…â–ƒâ–â–ƒâ–ƒâ–…â–„â–ˆâ–â–â–„â–‚â–„â–„
wandb:          test_loss â–â–†â–‡â–†â–…â–ˆâ–ˆâ–…â–†â–ˆâ–ˆâ–‡â–†â–ˆâ–ˆâ–…â–†â–ˆâ–ˆâ–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–†â–…â–…â–…â–ˆâ–†â–‚â–‚â–‡â–†â–†â–ƒâ–†â–†â–â–ƒâ–ˆâ–†â–ƒ
wandb:  valid_error_force â–ˆâ–„â–ƒâ–‚â–â–‚â–„â–â–ƒâ–â–â–†â–‚â–„â–„â–‚â–ˆâ–‡â–‚â–
wandb:         valid_loss â–…â–„â–ƒâ–†â–ƒâ–…â–„â–â–‚â–…â–ƒâ–†â–‚â–„â–„â–â–†â–ˆâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1309
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.74393
wandb:   test_error_force 8.78184
wandb:          test_loss 6.48373
wandb: train_error_energy 2.1442
wandb:  train_error_force 4.48018
wandb:         train_loss 1.10752
wandb: valid_error_energy 1.90271
wandb:  valid_error_force 4.63433
wandb:         valid_loss 1.2207
wandb: 
wandb: ğŸš€ View run al_73_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tz6u62bc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_002214-tz6u62bc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9781653881072998, Uncertainty Bias: 0.11529923975467682
0.00017642975 0.032642365
3.3553658 14.660092
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3883 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_010554-j5a66dpu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_56
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/j5a66dpu
Training model 56. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.795981593657258, Training Loss Force: 5.867397850954856, time: 0.7643206119537354
Validation Loss Energy: 2.3155764176147597, Validation Loss Force: 5.017383379629418, time: 0.07094192504882812
Test Loss Energy: 7.617419206230259, Test Loss Force: 8.961187813169358, time: 10.70774245262146


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.155643035424186, Training Loss Force: 4.728884316537629, time: 0.6697196960449219
Validation Loss Energy: 1.709624588442725, Validation Loss Force: 4.710587381009507, time: 0.06660962104797363
Test Loss Energy: 6.727627619290885, Test Loss Force: 8.700676090191811, time: 9.455862045288086


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0689865363223627, Training Loss Force: 4.502959628215372, time: 0.6508979797363281
Validation Loss Energy: 1.8530551931062287, Validation Loss Force: 4.797039344923409, time: 0.07047128677368164
Test Loss Energy: 6.977655481984946, Test Loss Force: 8.701891775127242, time: 9.895025968551636


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0895073908073485, Training Loss Force: 4.497581484040914, time: 0.7079389095306396
Validation Loss Energy: 2.167329089653833, Validation Loss Force: 4.588546430171113, time: 0.0652167797088623
Test Loss Energy: 7.807084168135641, Test Loss Force: 8.74310257391708, time: 9.415620565414429


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.093530441162102, Training Loss Force: 4.482737956882714, time: 0.6814098358154297
Validation Loss Energy: 1.9885454716932336, Validation Loss Force: 4.681676241771389, time: 0.060518741607666016
Test Loss Energy: 7.536021529984891, Test Loss Force: 8.755792784658494, time: 9.460951566696167


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.096321650500377, Training Loss Force: 4.496581417166049, time: 0.6613101959228516
Validation Loss Energy: 2.0742592873883847, Validation Loss Force: 5.012807751349747, time: 0.06286263465881348
Test Loss Energy: 6.593169855784839, Test Loss Force: 8.782536510228239, time: 9.618682146072388


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0746820926488634, Training Loss Force: 4.498738418613608, time: 0.7374176979064941
Validation Loss Energy: 1.817080042215411, Validation Loss Force: 4.869172346739277, time: 0.0690453052520752
Test Loss Energy: 7.130319726420007, Test Loss Force: 8.721132641674618, time: 10.068056106567383


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.047832712204348, Training Loss Force: 4.484282075083493, time: 0.7126970291137695
Validation Loss Energy: 2.2653568431225093, Validation Loss Force: 4.5401933797946015, time: 0.07041525840759277
Test Loss Energy: 8.124238617677602, Test Loss Force: 8.88509557790203, time: 10.778427362442017


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.072841172769428, Training Loss Force: 4.50727970291793, time: 0.6972675323486328
Validation Loss Energy: 2.475355446639568, Validation Loss Force: 4.827341498316137, time: 0.06932425498962402
Test Loss Energy: 7.945942692361771, Test Loss Force: 8.779209711944146, time: 10.891356229782104


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.033216815369266, Training Loss Force: 4.489152240333676, time: 0.7409970760345459
Validation Loss Energy: 1.686596702043738, Validation Loss Force: 4.666286241081444, time: 0.06935381889343262
Test Loss Energy: 6.9422816878857905, Test Loss Force: 8.75815400092451, time: 10.798256397247314


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0925635981530966, Training Loss Force: 4.4787786930918365, time: 0.6631741523742676
Validation Loss Energy: 1.6183221111885056, Validation Loss Force: 4.764005263779291, time: 0.0708155632019043
Test Loss Energy: 6.914640934415543, Test Loss Force: 8.743888066725805, time: 11.04622197151184


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.015942623667686, Training Loss Force: 4.506800725292175, time: 0.7754278182983398
Validation Loss Energy: 1.9862899445795583, Validation Loss Force: 4.751876252731458, time: 0.07598376274108887
Test Loss Energy: 7.940721047262641, Test Loss Force: 8.832202464521423, time: 11.619158506393433


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.014824566584777, Training Loss Force: 4.499950010315193, time: 0.7141022682189941
Validation Loss Energy: 2.116087241112628, Validation Loss Force: 4.858021075911214, time: 0.06476116180419922
Test Loss Energy: 7.920423912898635, Test Loss Force: 8.79937508679573, time: 10.68415904045105


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0809589973832208, Training Loss Force: 4.507885645404502, time: 0.7351720333099365
Validation Loss Energy: 1.9151714790598227, Validation Loss Force: 4.7884434252140124, time: 0.07199478149414062
Test Loss Energy: 6.810559315743866, Test Loss Force: 8.768144207208897, time: 11.056575059890747


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0946615026662294, Training Loss Force: 4.492022695448606, time: 0.7138841152191162
Validation Loss Energy: 1.7958229321994148, Validation Loss Force: 4.764542119090123, time: 0.07541584968566895
Test Loss Energy: 7.289774999752767, Test Loss Force: 8.708874283169141, time: 10.644168615341187


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0742259223177015, Training Loss Force: 4.510564952635038, time: 0.7106006145477295
Validation Loss Energy: 2.7887771883657066, Validation Loss Force: 4.954289186454195, time: 0.07377314567565918
Test Loss Energy: 8.11862921582827, Test Loss Force: 8.717925105451403, time: 10.85914921760559


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0975046455095763, Training Loss Force: 4.495704502621748, time: 0.9105088710784912
Validation Loss Energy: 1.845577573514968, Validation Loss Force: 4.630057525700701, time: 0.06808662414550781
Test Loss Energy: 7.813272733599342, Test Loss Force: 8.845811401164093, time: 10.769145011901855


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0932459949055664, Training Loss Force: 4.486588319168368, time: 0.774000883102417
Validation Loss Energy: 1.7170217131377326, Validation Loss Force: 4.6604545361495955, time: 0.06907224655151367
Test Loss Energy: 6.809771500647503, Test Loss Force: 8.734797998715122, time: 10.898963212966919


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.034994103467037, Training Loss Force: 4.523817438143173, time: 0.6675257682800293
Validation Loss Energy: 1.7935499255577838, Validation Loss Force: 4.743279887683771, time: 0.06836819648742676
Test Loss Energy: 6.996203050076466, Test Loss Force: 8.737549732362424, time: 10.97963261604309


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.020230055616546, Training Loss Force: 4.502594255301679, time: 0.7000372409820557
Validation Loss Energy: 2.3671902349642373, Validation Loss Force: 5.068163746365688, time: 0.07812881469726562
Test Loss Energy: 7.6560913575847955, Test Loss Force: 8.782542171387258, time: 10.585234880447388

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–ƒâ–‡â–…â–â–ƒâ–ˆâ–‡â–ƒâ–‚â–‡â–‡â–‚â–„â–ˆâ–‡â–‚â–ƒâ–†
wandb:   test_error_force â–ˆâ–â–â–‚â–‚â–ƒâ–‚â–†â–ƒâ–ƒâ–‚â–…â–„â–ƒâ–â–â–…â–‚â–‚â–ƒ
wandb:          test_loss â–â–„â–…â–‡â–†â–…â–†â–ˆâ–‡â–…â–…â–‡â–‡â–…â–†â–‡â–‡â–…â–†â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–‚â–„â–ƒâ–„â–‚â–…â–†â–â–â–ƒâ–„â–ƒâ–‚â–ˆâ–‚â–‚â–‚â–…
wandb:  valid_error_force â–‡â–ƒâ–„â–‚â–ƒâ–‡â–…â–â–…â–ƒâ–„â–„â–…â–„â–„â–†â–‚â–ƒâ–„â–ˆ
wandb:         valid_loss â–…â–â–‚â–‚â–‚â–„â–ƒâ–ƒâ–‡â–â–â–ƒâ–ƒâ–‚â–‚â–ˆâ–â–â–‚â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1310
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.65609
wandb:   test_error_force 8.78254
wandb:          test_loss 7.20283
wandb: train_error_energy 2.02023
wandb:  train_error_force 4.50259
wandb:         train_loss 1.08524
wandb: valid_error_energy 2.36719
wandb:  valid_error_force 5.06816
wandb:         valid_loss 1.59895
wandb: 
wandb: ğŸš€ View run al_73_56 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/j5a66dpu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_010554-j5a66dpu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.613210678100586, Uncertainty Bias: 0.0531136691570282
0.0007133484 0.031562805
2.9588327 9.313924
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1825 steps.
Found uncertainty sample 9 after 1928 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3391 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 401 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3870 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2676 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2405 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3630 steps.
Found uncertainty sample 59 after 2956 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3892 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2230 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3257 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 935 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_014800-dlz9r7yr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_57
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dlz9r7yr
Training model 57. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.915647902897233, Training Loss Force: 4.873661473357401, time: 0.7806382179260254
Validation Loss Energy: 2.9626477229559818, Validation Loss Force: 5.610590016559552, time: 0.07140159606933594
Test Loss Energy: 7.4805025994444865, Test Loss Force: 8.933513731607258, time: 9.565646648406982


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.6527278458713868, Training Loss Force: 5.041081367616489, time: 0.6928908824920654
Validation Loss Energy: 2.4628854177947472, Validation Loss Force: 6.409893870900944, time: 0.06024599075317383
Test Loss Energy: 7.740115137778495, Test Loss Force: 9.605680489139706, time: 9.428381204605103


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.537193535996669, Training Loss Force: 5.384367272525317, time: 0.6988365650177002
Validation Loss Energy: 5.467042566261722, Validation Loss Force: 4.9883457643164135, time: 0.06305098533630371
Test Loss Energy: 7.384210334545302, Test Loss Force: 9.143732706464556, time: 9.498037815093994


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.657134708836494, Training Loss Force: 4.812780855368432, time: 0.7232954502105713
Validation Loss Energy: 4.995609454525724, Validation Loss Force: 4.887836029212652, time: 0.06577396392822266
Test Loss Energy: 7.302976622066217, Test Loss Force: 8.76860706524905, time: 9.52736210823059


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.4127113917392435, Training Loss Force: 4.572745763956322, time: 0.725553035736084
Validation Loss Energy: 4.261306954594426, Validation Loss Force: 4.758861161170067, time: 0.06365418434143066
Test Loss Energy: 9.441517057416394, Test Loss Force: 8.741977868563577, time: 9.293291330337524


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.557744395149068, Training Loss Force: 4.585975863327474, time: 0.7259273529052734
Validation Loss Energy: 5.814725964133478, Validation Loss Force: 4.739261377607212, time: 0.06172537803649902
Test Loss Energy: 10.561409516423163, Test Loss Force: 8.751890017071345, time: 9.588952779769897


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.508021462980224, Training Loss Force: 4.545517208214468, time: 0.6932809352874756
Validation Loss Energy: 3.1216612154570904, Validation Loss Force: 4.780089769535385, time: 0.06076622009277344
Test Loss Energy: 7.04604059950886, Test Loss Force: 8.72049902554471, time: 9.426335334777832


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.478317717012238, Training Loss Force: 4.5523319125992465, time: 0.6923131942749023
Validation Loss Energy: 4.478721999354901, Validation Loss Force: 4.674299880974239, time: 0.06253337860107422
Test Loss Energy: 7.371598365778023, Test Loss Force: 8.686908328660321, time: 9.719830751419067


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.3820252029911915, Training Loss Force: 4.543820511735668, time: 0.7270777225494385
Validation Loss Energy: 3.9748716000090054, Validation Loss Force: 4.546080974682079, time: 0.06104326248168945
Test Loss Energy: 9.113118655386154, Test Loss Force: 8.725998575727646, time: 9.725106477737427


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.360911571429868, Training Loss Force: 4.539750353020547, time: 0.7360131740570068
Validation Loss Energy: 5.023549978956742, Validation Loss Force: 4.860618956836753, time: 0.06372380256652832
Test Loss Energy: 10.02231050267556, Test Loss Force: 8.691320143562818, time: 10.23384952545166


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.354849483456678, Training Loss Force: 4.519790174143361, time: 0.7249274253845215
Validation Loss Energy: 3.3538544774290746, Validation Loss Force: 4.7320827470116456, time: 0.06168532371520996
Test Loss Energy: 6.971292159713326, Test Loss Force: 8.663638591509162, time: 9.44095253944397


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.449383876124528, Training Loss Force: 4.535937631647996, time: 0.7238562107086182
Validation Loss Energy: 5.194864939759205, Validation Loss Force: 4.564652249459893, time: 0.06151270866394043
Test Loss Energy: 7.4104594711386955, Test Loss Force: 8.61956707942929, time: 9.738152265548706


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.447044821572898, Training Loss Force: 4.502475580405406, time: 0.6937997341156006
Validation Loss Energy: 4.232902164994147, Validation Loss Force: 4.785120310880185, time: 0.06914019584655762
Test Loss Energy: 9.019328900235438, Test Loss Force: 8.719736653021338, time: 9.546263456344604


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.511442488118503, Training Loss Force: 4.503777442075305, time: 0.6949462890625
Validation Loss Energy: 5.739927612640853, Validation Loss Force: 4.6102134740847625, time: 0.0605776309967041
Test Loss Energy: 10.201933627034073, Test Loss Force: 8.69128873672098, time: 9.424055814743042


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.516029403603213, Training Loss Force: 4.546653329816747, time: 0.724895715713501
Validation Loss Energy: 3.5229402974116537, Validation Loss Force: 4.848955992311348, time: 0.06412076950073242
Test Loss Energy: 6.738336034996103, Test Loss Force: 8.666101284283753, time: 9.701253652572632


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4048165829473245, Training Loss Force: 4.521598979235488, time: 0.7011969089508057
Validation Loss Energy: 5.362526567884429, Validation Loss Force: 4.602626913613857, time: 0.06810331344604492
Test Loss Energy: 7.2885994302378165, Test Loss Force: 8.697960272728002, time: 8.794664859771729


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.478353190327843, Training Loss Force: 4.520952793374006, time: 0.6563265323638916
Validation Loss Energy: 3.7310016793591405, Validation Loss Force: 4.790852037365513, time: 0.06068015098571777
Test Loss Energy: 8.676554283323101, Test Loss Force: 8.749722362080913, time: 9.231889247894287


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.404369288347973, Training Loss Force: 4.5131700931954155, time: 0.7031650543212891
Validation Loss Energy: 5.670548582821819, Validation Loss Force: 4.6672837988552, time: 0.06519103050231934
Test Loss Energy: 9.869802851774633, Test Loss Force: 8.621788809213776, time: 9.85714602470398


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.444700733108077, Training Loss Force: 4.513326963608723, time: 0.7348556518554688
Validation Loss Energy: 2.9513320109636507, Validation Loss Force: 4.735873689221066, time: 0.056944847106933594
Test Loss Energy: 6.861265200233726, Test Loss Force: 8.635048740532477, time: 7.732193470001221


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.510761443932391, Training Loss Force: 4.519781458236792, time: 0.7053492069244385
Validation Loss Energy: 5.229187161912513, Validation Loss Force: 4.772630353146804, time: 0.06254243850708008
Test Loss Energy: 7.3047477044735585, Test Loss Force: 8.69105585510532, time: 7.703311920166016

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.057 MB of 0.058 MB uploadedwandb: - 0.057 MB of 0.058 MB uploadedwandb: \ 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–‚â–†â–ˆâ–‚â–‚â–…â–‡â–â–‚â–…â–‡â–â–‚â–…â–‡â–â–‚
wandb:   test_error_force â–ƒâ–ˆâ–…â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–‚
wandb:          test_loss â–†â–ˆâ–…â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–
wandb: train_error_energy â–…â–â–ˆâ–ˆâ–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡
wandb:  train_error_force â–„â–…â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–â–‡â–†â–…â–ˆâ–‚â–…â–„â–†â–ƒâ–‡â–…â–ˆâ–ƒâ–‡â–„â–ˆâ–‚â–‡
wandb:  valid_error_force â–…â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–‚â–‚
wandb:         valid_loss â–ƒâ–ƒâ–ˆâ–„â–‚â–„â–â–‚â–â–ƒâ–â–ƒâ–‚â–„â–‚â–ƒâ–‚â–„â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1321
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.30475
wandb:   test_error_force 8.69106
wandb:          test_loss 4.59868
wandb: train_error_energy 4.51076
wandb:  train_error_force 4.51978
wandb:         train_loss 1.88362
wandb: valid_error_energy 5.22919
wandb:  valid_error_force 4.77263
wandb:         valid_loss 2.2115
wandb: 
wandb: ğŸš€ View run al_73_57 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dlz9r7yr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_014800-dlz9r7yr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1015655994415283, Uncertainty Bias: -0.064891517162323
0.00025558472 0.18164301
2.869285 13.111611
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2255 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1329 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3542 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_023132-rq6vr5bl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_58
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rq6vr5bl
Training model 58. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.3157786068397535, Training Loss Force: 4.88187459299507, time: 0.6995401382446289
Validation Loss Energy: 2.1068177472368, Validation Loss Force: 4.98007338287605, time: 0.06102561950683594
Test Loss Energy: 7.023339571014471, Test Loss Force: 8.811620985155487, time: 8.456898212432861


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.268575342720097, Training Loss Force: 4.831241590820234, time: 0.7134013175964355
Validation Loss Energy: 2.0327142348140423, Validation Loss Force: 4.922156470012794, time: 0.0591278076171875
Test Loss Energy: 6.481239012153974, Test Loss Force: 8.733281703437845, time: 8.43655276298523


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.1978947441571135, Training Loss Force: 5.0356364177845325, time: 0.7042176723480225
Validation Loss Energy: 9.922960127705576, Validation Loss Force: 5.847039487921373, time: 0.06003880500793457
Test Loss Energy: 14.013137143236507, Test Loss Force: 9.587422882908468, time: 8.637638807296753


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.6924539629040174, Training Loss Force: 4.819271841228202, time: 0.6671280860900879
Validation Loss Energy: 2.323274757996921, Validation Loss Force: 4.8630028527130555, time: 0.06112957000732422
Test Loss Energy: 6.681724255945554, Test Loss Force: 8.714940131119873, time: 8.451975584030151


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.161161674869529, Training Loss Force: 4.7925810844902275, time: 0.6661732196807861
Validation Loss Energy: 5.553038058426472, Validation Loss Force: 5.877564533129176, time: 0.05852866172790527
Test Loss Energy: 7.5239532166809475, Test Loss Force: 9.30909075932158, time: 8.456918954849243


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.465293361281099, Training Loss Force: 5.029088534656331, time: 0.6897156238555908
Validation Loss Energy: 3.8886834990330286, Validation Loss Force: 5.118472499850883, time: 0.05850672721862793
Test Loss Energy: 9.0402441408324, Test Loss Force: 8.652966607274156, time: 8.726656913757324


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.320769239045237, Training Loss Force: 4.534048220325043, time: 0.7136051654815674
Validation Loss Energy: 5.3145153146469175, Validation Loss Force: 4.680255389951224, time: 0.05967068672180176
Test Loss Energy: 9.905703949727487, Test Loss Force: 8.651294811989757, time: 8.731491565704346


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.329304767701269, Training Loss Force: 4.502498112402315, time: 0.6938731670379639
Validation Loss Energy: 3.3775549359833366, Validation Loss Force: 4.753498397459543, time: 0.05861544609069824
Test Loss Energy: 6.842835942904538, Test Loss Force: 8.60992611629351, time: 9.4030122756958


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.350482376879701, Training Loss Force: 4.555128403799661, time: 0.6529049873352051
Validation Loss Energy: 5.112104384946494, Validation Loss Force: 4.72772778385559, time: 0.06296849250793457
Test Loss Energy: 7.3233343504172845, Test Loss Force: 8.606164285451854, time: 8.602814674377441


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.263646608232091, Training Loss Force: 4.476703673199748, time: 0.691697359085083
Validation Loss Energy: 3.9811548779687955, Validation Loss Force: 4.580864344636605, time: 0.059034109115600586
Test Loss Energy: 8.753658247914649, Test Loss Force: 8.613570699588859, time: 8.793460607528687


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.365587766638802, Training Loss Force: 4.48931995856192, time: 0.720285177230835
Validation Loss Energy: 5.473628674259975, Validation Loss Force: 4.780691866905974, time: 0.061092376708984375
Test Loss Energy: 9.72055602846864, Test Loss Force: 8.643596503084387, time: 8.576213598251343


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.299977989994046, Training Loss Force: 4.505501622288686, time: 0.7118191719055176
Validation Loss Energy: 3.6539902192251397, Validation Loss Force: 4.861344635583332, time: 0.06190061569213867
Test Loss Energy: 6.836180017053871, Test Loss Force: 8.580006396576007, time: 8.594561576843262


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.3232017775266325, Training Loss Force: 4.483195443703176, time: 0.6780755519866943
Validation Loss Energy: 4.865048959494986, Validation Loss Force: 4.9815496793135505, time: 0.05953693389892578
Test Loss Energy: 7.213987049451093, Test Loss Force: 8.572632904829998, time: 8.779408931732178


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.402766468120767, Training Loss Force: 4.496775419922337, time: 0.6719670295715332
Validation Loss Energy: 4.319793455132964, Validation Loss Force: 4.6538352504486, time: 0.06213212013244629
Test Loss Energy: 9.529734749185872, Test Loss Force: 8.725845356039107, time: 8.642245292663574


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.421924804800176, Training Loss Force: 4.501319482199749, time: 0.6837215423583984
Validation Loss Energy: 5.310381239283622, Validation Loss Force: 4.760402031659888, time: 0.06494021415710449
Test Loss Energy: 9.879365831745444, Test Loss Force: 8.659357780676123, time: 8.590293169021606


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.469447463613412, Training Loss Force: 4.484637141596717, time: 0.6872076988220215
Validation Loss Energy: 3.492720197599199, Validation Loss Force: 4.691851108394559, time: 0.0591127872467041
Test Loss Energy: 6.951882104252486, Test Loss Force: 8.642729315181054, time: 8.79589319229126


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.334886717376082, Training Loss Force: 4.477930718036616, time: 0.7039749622344971
Validation Loss Energy: 5.386981874843386, Validation Loss Force: 4.882082703820171, time: 0.06180930137634277
Test Loss Energy: 7.343968633847596, Test Loss Force: 8.652347442488402, time: 8.615492105484009


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.3770908653207234, Training Loss Force: 4.477144070357222, time: 0.6677238941192627
Validation Loss Energy: 3.9454180387314075, Validation Loss Force: 4.695961803497532, time: 0.05873513221740723
Test Loss Energy: 9.073102603637187, Test Loss Force: 8.635872369221316, time: 8.649780750274658


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.368901380422402, Training Loss Force: 4.496280691493257, time: 0.6889908313751221
Validation Loss Energy: 5.485394734599945, Validation Loss Force: 4.923708028621619, time: 0.060768842697143555
Test Loss Energy: 10.011735331720944, Test Loss Force: 8.6685693957295, time: 8.570842266082764


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.493330092037275, Training Loss Force: 4.471417422849082, time: 0.6497297286987305
Validation Loss Energy: 3.3612576698583085, Validation Loss Force: 4.771315269170954, time: 0.06093859672546387
Test Loss Energy: 6.601725732353792, Test Loss Force: 8.564907451273351, time: 8.802207946777344

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–â–‚â–ƒâ–„â–â–‚â–ƒâ–„â–â–‚â–„â–„â–â–‚â–ƒâ–„â–
wandb:   test_error_force â–ƒâ–‚â–ˆâ–‚â–†â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–
wandb:          test_loss â–‚â–†â–ˆâ–‚â–ˆâ–„â–„â–â–‚â–‚â–ƒâ–â–â–ƒâ–ƒâ–â–‚â–ƒâ–„â–
wandb: train_error_energy â–†â–â–ˆâ–„â–ƒâ–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…â–…
wandb:  train_error_force â–†â–…â–ˆâ–…â–…â–ˆâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–„â–â–ˆâ–‚â–‚â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–â–ˆâ–â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–„â–‚
wandb:  valid_error_force â–ƒâ–ƒâ–ˆâ–ƒâ–ˆâ–„â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒâ–‚
wandb:         valid_loss â–â–â–ˆâ–â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1323
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.60173
wandb:   test_error_force 8.56491
wandb:          test_loss 4.399
wandb: train_error_energy 4.49333
wandb:  train_error_force 4.47142
wandb:         train_loss 1.86968
wandb: valid_error_energy 3.36126
wandb:  valid_error_force 4.77132
wandb:         valid_loss 1.66776
wandb: 
wandb: ğŸš€ View run al_73_58 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rq6vr5bl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_023132-rq6vr5bl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4201605319976807, Uncertainty Bias: -0.11225754022598267
4.9591064e-05 0.008005142
2.6921773 10.588612
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1748 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2072 steps.
Found uncertainty sample 33 after 3120 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3443 steps.
Found uncertainty sample 37 after 3758 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2861 steps.
Found uncertainty sample 48 after 1918 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3614 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1318 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_031415-bexqnqjl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_59
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bexqnqjl
Training model 59. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.804818185503469, Training Loss Force: 4.816241282342247, time: 0.719353199005127
Validation Loss Energy: 3.8716982965816564, Validation Loss Force: 4.659935271701292, time: 0.06155753135681152
Test Loss Energy: 6.779343677918363, Test Loss Force: 8.634854139357007, time: 8.725672245025635


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9902630072894953, Training Loss Force: 4.533188325099933, time: 0.6838939189910889
Validation Loss Energy: 3.43104340487238, Validation Loss Force: 4.7791443163417755, time: 0.05959343910217285
Test Loss Energy: 6.803549173411729, Test Loss Force: 8.681556598147687, time: 8.768318891525269


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0104592631761817, Training Loss Force: 4.486521739024801, time: 0.7001562118530273
Validation Loss Energy: 3.588573475523318, Validation Loss Force: 4.756095165039353, time: 0.06746482849121094
Test Loss Energy: 6.714088551796141, Test Loss Force: 8.600211716640239, time: 8.91142725944519


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0034510805101777, Training Loss Force: 4.482059141844921, time: 0.6897904872894287
Validation Loss Energy: 3.404120701107397, Validation Loss Force: 4.7991279815122105, time: 0.05992460250854492
Test Loss Energy: 6.803985863746913, Test Loss Force: 8.603265482913987, time: 8.701122283935547


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.003061939669437, Training Loss Force: 4.487671104139618, time: 0.6977968215942383
Validation Loss Energy: 3.864624209150104, Validation Loss Force: 4.711734795118472, time: 0.06557536125183105
Test Loss Energy: 6.726092458923981, Test Loss Force: 8.699876057437598, time: 8.765135765075684


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0813580099161735, Training Loss Force: 4.53333494743088, time: 0.6886091232299805
Validation Loss Energy: 3.2412811960063843, Validation Loss Force: 4.899925182483364, time: 0.06031608581542969
Test Loss Energy: 6.5178421241361635, Test Loss Force: 8.621704661261141, time: 8.74739956855774


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.043603149368296, Training Loss Force: 4.486908494124692, time: 0.8097641468048096
Validation Loss Energy: 3.8582853752384043, Validation Loss Force: 4.8609509565333315, time: 0.09056806564331055
Test Loss Energy: 6.650742406733592, Test Loss Force: 8.59934868833645, time: 8.779270648956299


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9834392450419593, Training Loss Force: 4.508614102213758, time: 0.6743333339691162
Validation Loss Energy: 3.496917510999938, Validation Loss Force: 4.87656496238408, time: 0.060227155685424805
Test Loss Energy: 6.612627175394966, Test Loss Force: 8.616216783138363, time: 9.52958345413208


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9454852573086896, Training Loss Force: 4.4966549983275605, time: 0.6614270210266113
Validation Loss Energy: 3.566086897818081, Validation Loss Force: 4.762365305519533, time: 0.06312131881713867
Test Loss Energy: 6.67924703721516, Test Loss Force: 8.561936517921891, time: 8.755844116210938


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.972777387742529, Training Loss Force: 4.487463141760613, time: 0.7024779319763184
Validation Loss Energy: 3.8177119394823187, Validation Loss Force: 4.9644685064602845, time: 0.0599818229675293
Test Loss Energy: 6.702807617576725, Test Loss Force: 8.618976975881596, time: 8.950042009353638


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0303143130574353, Training Loss Force: 4.505463821550342, time: 0.7021806240081787
Validation Loss Energy: 3.569836868904651, Validation Loss Force: 4.879553627660723, time: 0.06902885437011719
Test Loss Energy: 6.690907371679868, Test Loss Force: 8.615593743209985, time: 8.68800663948059


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.081205640600603, Training Loss Force: 4.4755510210642075, time: 0.7427809238433838
Validation Loss Energy: 3.3411070028284278, Validation Loss Force: 4.7094965248636065, time: 0.06334137916564941
Test Loss Energy: 6.772134968335184, Test Loss Force: 8.601223348036664, time: 8.749485731124878


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0524455876796432, Training Loss Force: 4.476010520053414, time: 0.692368745803833
Validation Loss Energy: 3.529397034636122, Validation Loss Force: 4.837805389490722, time: 0.06295418739318848
Test Loss Energy: 6.733196765822896, Test Loss Force: 8.613181338688161, time: 8.9676194190979


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0215724893901696, Training Loss Force: 4.5197202348249546, time: 0.6769063472747803
Validation Loss Energy: 3.156034206175671, Validation Loss Force: 4.594698333334806, time: 0.06047320365905762
Test Loss Energy: 6.670964323226939, Test Loss Force: 8.59390239221941, time: 8.75587248802185


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.974951614109709, Training Loss Force: 4.474019895000344, time: 0.7073228359222412
Validation Loss Energy: 3.361359540992571, Validation Loss Force: 4.579411205790279, time: 0.060602664947509766
Test Loss Energy: 6.680032439090936, Test Loss Force: 8.645217347937614, time: 8.740337133407593


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.965508745795545, Training Loss Force: 4.481735513447901, time: 0.729339599609375
Validation Loss Energy: 3.5244116951279443, Validation Loss Force: 4.707170300296099, time: 0.06488466262817383
Test Loss Energy: 6.7392199055982775, Test Loss Force: 8.631353565874523, time: 8.941435098648071


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.035920687416898, Training Loss Force: 4.482424319244243, time: 0.6680097579956055
Validation Loss Energy: 3.380525676393732, Validation Loss Force: 4.712104203231567, time: 0.060770273208618164
Test Loss Energy: 6.8454162889262875, Test Loss Force: 8.658591784824447, time: 8.766356229782104


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9916566351557474, Training Loss Force: 4.486212345548181, time: 0.7061202526092529
Validation Loss Energy: 3.5271714565225736, Validation Loss Force: 4.671202107816091, time: 0.06178402900695801
Test Loss Energy: 6.763130897247111, Test Loss Force: 8.586961060482402, time: 8.753162384033203


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0976213402030326, Training Loss Force: 4.475505310269536, time: 0.7443313598632812
Validation Loss Energy: 3.430840330611294, Validation Loss Force: 4.954280502357504, time: 0.06212329864501953
Test Loss Energy: 6.900631349528347, Test Loss Force: 8.609301607448254, time: 8.998027324676514


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0216235442443438, Training Loss Force: 4.473141613665757, time: 0.6699349880218506
Validation Loss Energy: 3.7092937756572137, Validation Loss Force: 4.634393784648498, time: 0.06072545051574707
Test Loss Energy: 6.675891394533115, Test Loss Force: 8.594881586200566, time: 8.771087169647217

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–†â–…â–†â–…â–â–ƒâ–ƒâ–„â–„â–„â–†â–…â–„â–„â–…â–‡â–…â–ˆâ–„
wandb:   test_error_force â–…â–‡â–ƒâ–ƒâ–ˆâ–„â–ƒâ–„â–â–„â–„â–ƒâ–„â–ƒâ–…â–…â–†â–‚â–ƒâ–ƒ
wandb:          test_loss â–â–ˆâ–†â–†â–†â–„â–…â–†â–†â–†â–†â–…â–†â–…â–‡â–†â–ˆâ–†â–…â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–…â–ƒâ–ˆâ–‚â–ˆâ–„â–…â–‡â–…â–ƒâ–…â–â–ƒâ–…â–ƒâ–…â–„â–†
wandb:  valid_error_force â–‚â–…â–„â–…â–ƒâ–‡â–†â–†â–„â–ˆâ–†â–ƒâ–†â–â–â–ƒâ–ƒâ–ƒâ–ˆâ–‚
wandb:         valid_loss â–„â–„â–‡â–…â–†â–ƒâ–ˆâ–ˆâ–…â–ˆâ–†â–‚â–†â–â–ƒâ–„â–ƒâ–…â–…â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1331
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.67589
wandb:   test_error_force 8.59488
wandb:          test_loss 5.23921
wandb: train_error_energy 3.02162
wandb:  train_error_force 4.47314
wandb:         train_loss 1.46276
wandb: valid_error_energy 3.70929
wandb:  valid_error_force 4.63439
wandb:         valid_loss 1.83006
wandb: 
wandb: ğŸš€ View run al_73_59 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bexqnqjl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_031415-bexqnqjl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.402326822280884, Uncertainty Bias: -0.004715025424957275
3.3108518e-05 0.01338768
2.7652543 9.225626
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 891 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1946 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3051 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1947 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_035714-pla2u8dg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_60
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/pla2u8dg
Training model 60. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.480090727381446, Training Loss Force: 5.0845584620519375, time: 0.743910551071167
Validation Loss Energy: 5.3082756798397295, Validation Loss Force: 4.712853484907614, time: 0.06715583801269531
Test Loss Energy: 9.906102319985044, Test Loss Force: 8.592910323065231, time: 8.855933427810669


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.459880316756765, Training Loss Force: 4.563328046652354, time: 0.6662538051605225
Validation Loss Energy: 3.132446418209249, Validation Loss Force: 4.696528719143064, time: 0.061751365661621094
Test Loss Energy: 8.398873862196638, Test Loss Force: 8.550258875885767, time: 8.864843368530273


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.364222115560241, Training Loss Force: 4.493829464708542, time: 0.6672422885894775
Validation Loss Energy: 5.840721028236526, Validation Loss Force: 4.69288340255508, time: 0.07015776634216309
Test Loss Energy: 7.554563245725039, Test Loss Force: 8.62036110128237, time: 9.013921976089478


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.514633207089313, Training Loss Force: 4.504628971302503, time: 0.7034530639648438
Validation Loss Energy: 2.449016581375208, Validation Loss Force: 4.902666239669735, time: 0.06066417694091797
Test Loss Energy: 6.482388465259465, Test Loss Force: 8.61774842043637, time: 8.870843648910522


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.445810147666959, Training Loss Force: 4.5231653612474565, time: 0.6840200424194336
Validation Loss Energy: 5.761361521958716, Validation Loss Force: 4.9849420437517615, time: 0.062429189682006836
Test Loss Energy: 10.05780481790721, Test Loss Force: 8.669366430027988, time: 8.85736083984375


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.500668959591567, Training Loss Force: 4.505584995978897, time: 0.67421555519104
Validation Loss Energy: 2.7166518686353722, Validation Loss Force: 4.7653477360600895, time: 0.0648965835571289
Test Loss Energy: 7.69326685517918, Test Loss Force: 8.612036973164622, time: 9.008346557617188


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.380469408366948, Training Loss Force: 4.497771949176705, time: 0.7276067733764648
Validation Loss Energy: 5.7680213334442705, Validation Loss Force: 4.781876244093164, time: 0.0655817985534668
Test Loss Energy: 7.469104823379618, Test Loss Force: 8.550706881544144, time: 8.852249383926392


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.465256490981686, Training Loss Force: 4.4947756654342825, time: 0.6810340881347656
Validation Loss Energy: 2.1582596640056213, Validation Loss Force: 4.839950138704298, time: 0.06005215644836426
Test Loss Energy: 6.508161933924875, Test Loss Force: 8.569263382049256, time: 9.729047536849976


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.40254158818832, Training Loss Force: 4.494869637115512, time: 0.6753189563751221
Validation Loss Energy: 6.3569658602522, Validation Loss Force: 4.717479436414264, time: 0.060991764068603516
Test Loss Energy: 10.785963576489946, Test Loss Force: 8.671845975709248, time: 8.851760387420654


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.502502836169197, Training Loss Force: 4.502438161385598, time: 0.8977096080780029
Validation Loss Energy: 2.5183293671233287, Validation Loss Force: 4.662825517215434, time: 0.06098318099975586
Test Loss Energy: 7.894913732428274, Test Loss Force: 8.617459510134047, time: 8.872791051864624


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.330798845860567, Training Loss Force: 4.514409437851772, time: 0.7111308574676514
Validation Loss Energy: 5.769296782312145, Validation Loss Force: 4.708090369207072, time: 0.060706377029418945
Test Loss Energy: 7.423775787881019, Test Loss Force: 8.572703748592616, time: 8.834364652633667


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.50831749630809, Training Loss Force: 4.492682495937868, time: 0.6659517288208008
Validation Loss Energy: 2.2401663939782717, Validation Loss Force: 4.8522254433810055, time: 0.06604886054992676
Test Loss Energy: 6.525939915479015, Test Loss Force: 8.56038682460434, time: 8.894333600997925


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.346015816719187, Training Loss Force: 4.492171894379671, time: 0.7206876277923584
Validation Loss Energy: 6.355603347748268, Validation Loss Force: 4.837963929922623, time: 0.06255459785461426
Test Loss Energy: 11.283356272157336, Test Loss Force: 8.665848411408861, time: 9.123713493347168


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.5181624308767505, Training Loss Force: 4.501992144483011, time: 0.6490001678466797
Validation Loss Energy: 2.818426698491721, Validation Loss Force: 4.588467605293454, time: 0.060080766677856445
Test Loss Energy: 7.80552992817061, Test Loss Force: 8.54894822430831, time: 8.889812231063843


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.521280466927179, Training Loss Force: 4.4915427374062045, time: 0.693596601486206
Validation Loss Energy: 5.39841036875813, Validation Loss Force: 5.061743972219444, time: 0.061096906661987305
Test Loss Energy: 7.368138068597393, Test Loss Force: 8.586778896136506, time: 8.907601118087769


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.4945919792938325, Training Loss Force: 4.484276454691838, time: 0.6570501327514648
Validation Loss Energy: 2.2547042398467507, Validation Loss Force: 4.631369492308507, time: 0.060549259185791016
Test Loss Energy: 6.61348873011865, Test Loss Force: 8.615058451246401, time: 9.08907413482666


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.447563847447117, Training Loss Force: 4.504106016908353, time: 0.7034540176391602
Validation Loss Energy: 5.736695569987711, Validation Loss Force: 4.703642553017165, time: 0.06231188774108887
Test Loss Energy: 10.226207021461455, Test Loss Force: 8.626328928176608, time: 8.831594944000244


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.4636346060342715, Training Loss Force: 4.5571265306822895, time: 0.7320504188537598
Validation Loss Energy: 1.924026028982214, Validation Loss Force: 4.872734385066684, time: 0.06284141540527344
Test Loss Energy: 7.08111699623039, Test Loss Force: 8.635137467775191, time: 8.831860780715942


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.44025162066564, Training Loss Force: 4.557791399545445, time: 0.6941537857055664
Validation Loss Energy: 5.644127775311757, Validation Loss Force: 4.793853840121765, time: 0.06460404396057129
Test Loss Energy: 7.358098418104539, Test Loss Force: 8.636182110163952, time: 9.012798547744751


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.431794665059066, Training Loss Force: 4.509259598861218, time: 0.7005515098571777
Validation Loss Energy: 2.2358788995734318, Validation Loss Force: 4.536274180157127, time: 0.06019735336303711
Test Loss Energy: 6.538800562547435, Test Loss Force: 8.54518724683741, time: 8.857033491134644

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–„â–ƒâ–â–†â–ƒâ–‚â–â–‡â–ƒâ–‚â–â–ˆâ–ƒâ–‚â–â–†â–‚â–‚â–
wandb:   test_error_force â–„â–â–…â–…â–ˆâ–…â–â–‚â–ˆâ–…â–ƒâ–‚â–ˆâ–â–ƒâ–…â–…â–†â–†â–
wandb:          test_loss â–…â–„â–ƒâ–â–†â–ƒâ–‚â–â–‡â–ƒâ–‚â–â–ˆâ–ƒâ–‚â–â–†â–‚â–‚â–
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–ƒâ–‡â–‚â–‡â–‚â–‡â–â–ˆâ–‚â–‡â–â–ˆâ–‚â–†â–‚â–‡â–â–‡â–
wandb:  valid_error_force â–ƒâ–ƒâ–ƒâ–†â–‡â–„â–„â–…â–ƒâ–ƒâ–ƒâ–…â–…â–‚â–ˆâ–‚â–ƒâ–…â–„â–
wandb:         valid_loss â–†â–‚â–‡â–‚â–‡â–‚â–‡â–‚â–ˆâ–â–‡â–‚â–ˆâ–‚â–‡â–â–†â–â–‡â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1334
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.5388
wandb:   test_error_force 8.54519
wandb:          test_loss 4.38729
wandb: train_error_energy 4.43179
wandb:  train_error_force 4.50926
wandb:         train_loss 1.87258
wandb: valid_error_energy 2.23588
wandb:  valid_error_force 4.53627
wandb:         valid_loss 1.3999
wandb: 
wandb: ğŸš€ View run al_73_60 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/pla2u8dg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_035714-pla2u8dg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.4204928874969482, Uncertainty Bias: -0.12711045145988464
2.2888184e-05 0.01859665
2.6279652 9.28681
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2640 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3202 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2828 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_044035-ufdhlayi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_61
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ufdhlayi
Training model 61. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.192743035339671, Training Loss Force: 4.907253425538408, time: 0.6995728015899658
Validation Loss Energy: 2.6438507480471465, Validation Loss Force: 4.876403972591573, time: 0.06121540069580078
Test Loss Energy: 7.563404332324751, Test Loss Force: 8.61499039609424, time: 8.697410106658936


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9432153282727547, Training Loss Force: 4.554789040116327, time: 0.6975088119506836
Validation Loss Energy: 2.213819623959231, Validation Loss Force: 4.8801029524437265, time: 0.05969405174255371
Test Loss Energy: 7.127219323201161, Test Loss Force: 8.570648626624793, time: 8.739986181259155


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0222179065129344, Training Loss Force: 4.484376947398054, time: 0.6906263828277588
Validation Loss Energy: 2.0910898461179093, Validation Loss Force: 4.539566120810523, time: 0.0606076717376709
Test Loss Energy: 7.344488623427881, Test Loss Force: 8.604992322943902, time: 8.839237689971924


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.979312700667278, Training Loss Force: 4.4814055283769285, time: 0.7019233703613281
Validation Loss Energy: 2.3844197054686918, Validation Loss Force: 4.649913601450519, time: 0.06516218185424805
Test Loss Energy: 7.355542768539268, Test Loss Force: 8.6005471379805, time: 8.74513840675354


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0298439695506567, Training Loss Force: 4.467578193244873, time: 0.717923641204834
Validation Loss Energy: 2.810675140183683, Validation Loss Force: 4.830280953711529, time: 0.06191682815551758
Test Loss Energy: 7.621105247955806, Test Loss Force: 8.567583188290893, time: 8.707765102386475


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.994417578817508, Training Loss Force: 4.472259186443738, time: 0.6745495796203613
Validation Loss Energy: 2.526273979580886, Validation Loss Force: 4.9261431384014855, time: 0.0636897087097168
Test Loss Energy: 7.396720554005156, Test Loss Force: 8.590717915659583, time: 8.656371593475342


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0117679268583237, Training Loss Force: 4.461142609589268, time: 0.693488359451294
Validation Loss Energy: 2.5721526190732744, Validation Loss Force: 4.72285689628842, time: 0.0911414623260498
Test Loss Energy: 7.7196162908160355, Test Loss Force: 8.597258083865352, time: 8.756816387176514


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.021257330373164, Training Loss Force: 4.465096725869483, time: 0.6810507774353027
Validation Loss Energy: 2.6149828066233387, Validation Loss Force: 4.836067456806755, time: 0.06053876876831055
Test Loss Energy: 7.7500213989606745, Test Loss Force: 8.579223543154434, time: 8.696585893630981


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.011326063795639, Training Loss Force: 4.541282762082822, time: 0.6996181011199951
Validation Loss Energy: 3.032795406666759, Validation Loss Force: 4.636463494359898, time: 0.07722806930541992
Test Loss Energy: 8.103342099941814, Test Loss Force: 8.689626701573177, time: 9.52773666381836


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.013783705572414, Training Loss Force: 4.476172639096588, time: 0.7043192386627197
Validation Loss Energy: 2.6643806206325427, Validation Loss Force: 4.785034137920712, time: 0.05915999412536621
Test Loss Energy: 7.5138907746603305, Test Loss Force: 8.64802797815692, time: 8.882800817489624


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9895653636487185, Training Loss Force: 4.471038927714176, time: 0.6792941093444824
Validation Loss Energy: 2.9655682514739707, Validation Loss Force: 4.973409118007577, time: 0.06197714805603027
Test Loss Energy: 8.224794134024089, Test Loss Force: 8.56510211307079, time: 8.716762065887451


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0480756606268162, Training Loss Force: 4.466286118414102, time: 0.680556058883667
Validation Loss Energy: 2.6321245454842974, Validation Loss Force: 4.715715896778516, time: 0.06064891815185547
Test Loss Energy: 7.995582441644157, Test Loss Force: 8.566622460693358, time: 8.734539031982422


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.015234482535298, Training Loss Force: 4.481352670963002, time: 0.7205996513366699
Validation Loss Energy: 2.6360410730920214, Validation Loss Force: 4.760083392112065, time: 0.06012988090515137
Test Loss Energy: 7.744123119451614, Test Loss Force: 8.630144577334772, time: 8.927048683166504


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.004702550031694, Training Loss Force: 4.4638783757326, time: 0.6697304248809814
Validation Loss Energy: 2.7989401421895694, Validation Loss Force: 4.80242793825486, time: 0.05954766273498535
Test Loss Energy: 7.878687817774832, Test Loss Force: 8.582173109594343, time: 8.757009267807007


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9648804476887856, Training Loss Force: 4.472500559797924, time: 0.7026357650756836
Validation Loss Energy: 2.400974488460985, Validation Loss Force: 4.880477481947176, time: 0.06162905693054199
Test Loss Energy: 7.618284242053784, Test Loss Force: 8.614671981547179, time: 8.756609439849854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0047759804842102, Training Loss Force: 4.479922175448159, time: 0.712587833404541
Validation Loss Energy: 2.555255704938263, Validation Loss Force: 5.057421073420402, time: 0.0672454833984375
Test Loss Energy: 7.748201630119448, Test Loss Force: 8.62557980854774, time: 8.927761316299438


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0212801857704994, Training Loss Force: 4.477994348395887, time: 0.7267541885375977
Validation Loss Energy: 2.7586916920519653, Validation Loss Force: 4.867502550813965, time: 0.059679269790649414
Test Loss Energy: 7.9747088273536075, Test Loss Force: 8.610799599554893, time: 8.727688312530518


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.999581106658891, Training Loss Force: 4.470913607398189, time: 0.6464006900787354
Validation Loss Energy: 2.342432877308829, Validation Loss Force: 4.8688661766636265, time: 0.05988883972167969
Test Loss Energy: 7.517285096488573, Test Loss Force: 8.618363365000615, time: 8.720554828643799


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9614396951245063, Training Loss Force: 4.476087229574186, time: 0.6895978450775146
Validation Loss Energy: 2.536394180928731, Validation Loss Force: 4.635777896059586, time: 0.059569358825683594
Test Loss Energy: 7.632266141355234, Test Loss Force: 8.572857593153733, time: 8.852763652801514


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0101451830442043, Training Loss Force: 4.4696434813832315, time: 0.6912648677825928
Validation Loss Energy: 2.852643152800715, Validation Loss Force: 4.915809286008123, time: 0.06075930595397949
Test Loss Energy: 7.555701162003994, Test Loss Force: 8.539400031434079, time: 8.727451086044312

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–‚â–‚â–„â–ƒâ–…â–…â–‡â–ƒâ–ˆâ–‡â–…â–†â–„â–…â–†â–ƒâ–„â–„
wandb:   test_error_force â–…â–‚â–„â–„â–‚â–ƒâ–„â–ƒâ–ˆâ–†â–‚â–‚â–…â–ƒâ–…â–…â–„â–…â–ƒâ–
wandb:          test_loss â–â–ƒâ–„â–†â–…â–„â–†â–†â–ˆâ–†â–ˆâ–†â–†â–†â–…â–‡â–†â–†â–†â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–â–ƒâ–†â–„â–…â–…â–ˆâ–…â–ˆâ–…â–…â–†â–ƒâ–„â–†â–ƒâ–„â–‡
wandb:  valid_error_force â–†â–†â–â–‚â–…â–†â–ƒâ–…â–‚â–„â–‡â–ƒâ–„â–…â–†â–ˆâ–…â–…â–‚â–†
wandb:         valid_loss â–†â–ƒâ–â–‚â–…â–…â–„â–„â–…â–„â–ˆâ–„â–„â–…â–„â–…â–…â–„â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1336
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.5557
wandb:   test_error_force 8.5394
wandb:          test_loss 5.54258
wandb: train_error_energy 3.01015
wandb:  train_error_force 4.46964
wandb:         train_loss 1.46538
wandb: valid_error_energy 2.85264
wandb:  valid_error_force 4.91581
wandb:         valid_loss 1.53873
wandb: 
wandb: ğŸš€ View run al_73_61 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ufdhlayi
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_044035-ufdhlayi/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.348393678665161, Uncertainty Bias: -0.025432825088500977
4.196167e-05 0.0013370514
2.7051022 9.337119
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1256 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 615 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3814 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1612 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3490 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2164 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_052312-541yw0lg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_62
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/541yw0lg
Training model 62. Added 6 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.29196915538594, Training Loss Force: 5.006122226879486, time: 0.6820869445800781
Validation Loss Energy: 4.846807680391436, Validation Loss Force: 4.764134189214784, time: 0.06110858917236328
Test Loss Energy: 7.051520655066358, Test Loss Force: 8.566147515565744, time: 8.78572678565979


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.5295879399646095, Training Loss Force: 4.561665280710077, time: 0.708928108215332
Validation Loss Energy: 3.775224662416983, Validation Loss Force: 4.995081505980728, time: 0.06574249267578125
Test Loss Energy: 8.492994790486737, Test Loss Force: 8.679249531287377, time: 8.779927730560303


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.4217753354851475, Training Loss Force: 4.55430848298789, time: 0.6649062633514404
Validation Loss Energy: 5.6254674328755705, Validation Loss Force: 4.775553331025398, time: 0.0603787899017334
Test Loss Energy: 9.436699840108234, Test Loss Force: 8.578226470356409, time: 8.937784671783447


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.410986047814491, Training Loss Force: 4.492834059403196, time: 0.6789565086364746
Validation Loss Energy: 3.5987524615256876, Validation Loss Force: 4.727209187414724, time: 0.059418678283691406
Test Loss Energy: 6.597285693262694, Test Loss Force: 8.54406744719996, time: 8.771390438079834


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.526031733448169, Training Loss Force: 4.532126771153307, time: 0.7160124778747559
Validation Loss Energy: 5.428435521733324, Validation Loss Force: 4.707091698087586, time: 0.06486248970031738
Test Loss Energy: 7.289025159655145, Test Loss Force: 8.553956288893247, time: 8.802924871444702


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.415151739545685, Training Loss Force: 4.517394635851713, time: 0.7086701393127441
Validation Loss Energy: 4.215808077330417, Validation Loss Force: 4.659029676284803, time: 0.06626129150390625
Test Loss Energy: 8.54727691399964, Test Loss Force: 8.600132003417611, time: 8.774580955505371


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.553778429689302, Training Loss Force: 4.51533470237615, time: 0.889277458190918
Validation Loss Energy: 5.720302444795362, Validation Loss Force: 4.662484388083873, time: 0.05943012237548828
Test Loss Energy: 9.632901486787935, Test Loss Force: 8.600225151400647, time: 8.85893440246582


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.382550280694697, Training Loss Force: 4.556936196277339, time: 0.738283634185791
Validation Loss Energy: 4.31099668785394, Validation Loss Force: 4.695749822470608, time: 0.05901145935058594
Test Loss Energy: 6.885753965854924, Test Loss Force: 8.594912125681963, time: 8.7746422290802


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.451448151648437, Training Loss Force: 4.52570425605591, time: 0.6517374515533447
Validation Loss Energy: 4.869685153782349, Validation Loss Force: 4.634312065071943, time: 0.059139251708984375
Test Loss Energy: 7.198223237394839, Test Loss Force: 8.542507345557096, time: 8.803443908691406


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.416270932991228, Training Loss Force: 4.511476980629537, time: 0.7079100608825684
Validation Loss Energy: 3.9558447441586218, Validation Loss Force: 4.877084449501529, time: 0.06089186668395996
Test Loss Energy: 8.343378098573865, Test Loss Force: 8.533229489347322, time: 9.89424991607666


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.379081808472574, Training Loss Force: 4.517182999431802, time: 0.6662626266479492
Validation Loss Energy: 5.598816830806912, Validation Loss Force: 4.95504514820462, time: 0.061690568923950195
Test Loss Energy: 9.976983248530134, Test Loss Force: 8.689340379362497, time: 8.885299444198608


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.372419571483824, Training Loss Force: 4.517707835910401, time: 0.6575267314910889
Validation Loss Energy: 3.4235852131641016, Validation Loss Force: 4.796589107910343, time: 0.06513667106628418
Test Loss Energy: 6.738117739958215, Test Loss Force: 8.612008928510306, time: 8.905442237854004


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.4310899622761974, Training Loss Force: 4.509146016390209, time: 0.6943299770355225
Validation Loss Energy: 5.309640196365974, Validation Loss Force: 4.603364839163461, time: 0.06397390365600586
Test Loss Energy: 7.27990072132111, Test Loss Force: 8.599553739806286, time: 9.053023338317871


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.580910818868348, Training Loss Force: 4.487333707367073, time: 0.686211109161377
Validation Loss Energy: 3.7544427283583968, Validation Loss Force: 4.647744803969183, time: 0.0599057674407959
Test Loss Energy: 8.329214860317908, Test Loss Force: 8.560823032295405, time: 8.870228290557861


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.407964398345197, Training Loss Force: 4.501062320542788, time: 0.6937072277069092
Validation Loss Energy: 6.036855137382391, Validation Loss Force: 4.630681444647591, time: 0.0694420337677002
Test Loss Energy: 10.057008954078997, Test Loss Force: 8.560948142044433, time: 8.9375


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.397181936544191, Training Loss Force: 4.50430316392884, time: 0.6745095252990723
Validation Loss Energy: 3.38149473251681, Validation Loss Force: 4.857429443990483, time: 0.05986618995666504
Test Loss Energy: 6.92411477677956, Test Loss Force: 8.499837114894495, time: 9.060779571533203


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.4067010186751965, Training Loss Force: 4.507199129919375, time: 0.6561181545257568
Validation Loss Energy: 4.83001686810446, Validation Loss Force: 4.837011573985489, time: 0.06281256675720215
Test Loss Energy: 7.244942490801833, Test Loss Force: 8.477773139329186, time: 8.871851921081543


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.3194063501244155, Training Loss Force: 4.533902032729094, time: 0.6980926990509033
Validation Loss Energy: 3.583302674170061, Validation Loss Force: 4.94551936214183, time: 0.06003236770629883
Test Loss Energy: 8.096796349851907, Test Loss Force: 8.492415372726436, time: 8.860469102859497


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.494857263072975, Training Loss Force: 4.502249306139973, time: 0.6930599212646484
Validation Loss Energy: 5.485629873218045, Validation Loss Force: 4.618713868730556, time: 0.06067705154418945
Test Loss Energy: 9.774096052842712, Test Loss Force: 8.633241730283569, time: 9.068222045898438


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.358681174119804, Training Loss Force: 4.503817840620351, time: 0.6914746761322021
Validation Loss Energy: 3.867036050004221, Validation Loss Force: 4.816477248017175, time: 0.0599825382232666
Test Loss Energy: 6.798861488924534, Test Loss Force: 8.472267027984195, time: 8.86328125

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‡â–â–‚â–…â–‡â–‚â–‚â–…â–ˆâ–â–‚â–…â–ˆâ–‚â–‚â–„â–‡â–
wandb:   test_error_force â–„â–ˆâ–„â–ƒâ–„â–…â–…â–…â–ƒâ–ƒâ–ˆâ–†â–…â–„â–„â–‚â–â–‚â–†â–
wandb:          test_loss â–â–…â–‡â–â–ƒâ–…â–‡â–‚â–‚â–„â–ˆâ–‚â–‚â–„â–ˆâ–‚â–‚â–„â–‡â–
wandb: train_error_energy â–ˆâ–‚â–â–â–‚â–â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–‚â–‡â–‚â–†â–ƒâ–‡â–ƒâ–…â–ƒâ–‡â–â–†â–‚â–ˆâ–â–…â–‚â–‡â–‚
wandb:  valid_error_force â–„â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–†â–‡â–„â–â–‚â–â–†â–…â–‡â–â–…
wandb:         valid_loss â–„â–‚â–ˆâ–â–‡â–‚â–‡â–„â–„â–ƒâ–ˆâ–â–†â–â–ˆâ–â–†â–‚â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1341
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.79886
wandb:   test_error_force 8.47227
wandb:          test_loss 4.44143
wandb: train_error_energy 4.35868
wandb:  train_error_force 4.50382
wandb:         train_loss 1.84263
wandb: valid_error_energy 3.86704
wandb:  valid_error_force 4.81648
wandb:         valid_loss 1.85539
wandb: 
wandb: ğŸš€ View run al_73_62 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/541yw0lg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_052312-541yw0lg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.3664917945861816, Uncertainty Bias: -0.11263874173164368
0.0004196167 0.07728052
2.7061658 9.217311
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2179 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3628 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2770 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2348 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3378 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3280 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1106 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_060612-a7q5tuzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_63
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a7q5tuzc
Training model 63. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.313489321359564, Training Loss Force: 4.815783084722273, time: 0.6977732181549072
Validation Loss Energy: 1.7013632291250853, Validation Loss Force: 4.814558953325006, time: 0.06043386459350586
Test Loss Energy: 6.622259819331662, Test Loss Force: 8.667504985916455, time: 8.67726469039917


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7025603682482573, Training Loss Force: 5.122070470764419, time: 0.7104842662811279
Validation Loss Energy: 4.4306472854108, Validation Loss Force: 4.808566035931506, time: 0.060103654861450195
Test Loss Energy: 10.018244596713517, Test Loss Force: 8.628322905896445, time: 8.715213775634766


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.370447889521331, Training Loss Force: 4.853729873806176, time: 0.7341229915618896
Validation Loss Energy: 3.8358485640872826, Validation Loss Force: 5.023305933572805, time: 0.059613704681396484
Test Loss Energy: 6.8083940879637055, Test Loss Force: 8.484056969881516, time: 8.879974126815796


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.472168175793633, Training Loss Force: 4.535779160753969, time: 0.7068259716033936
Validation Loss Energy: 2.169854157768654, Validation Loss Force: 4.59913212136852, time: 0.06345486640930176
Test Loss Energy: 6.61344545769269, Test Loss Force: 8.454245740167783, time: 8.67142128944397


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.4108512681901555, Training Loss Force: 4.504496051384735, time: 0.722327470779419
Validation Loss Energy: 5.7863450001318135, Validation Loss Force: 4.676090808914936, time: 0.06133627891540527
Test Loss Energy: 10.251323075211909, Test Loss Force: 8.53276727016943, time: 8.726048707962036


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.321321845793908, Training Loss Force: 4.479866140745258, time: 0.781287670135498
Validation Loss Energy: 5.523106426492566, Validation Loss Force: 4.65951977107499, time: 0.06397032737731934
Test Loss Energy: 7.192933292324068, Test Loss Force: 8.501550235707084, time: 8.716422319412231


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.348802190775578, Training Loss Force: 4.477889667265775, time: 0.8521385192871094
Validation Loss Energy: 3.886320534056442, Validation Loss Force: 4.853236583972663, time: 0.08330059051513672
Test Loss Energy: 8.470606100353082, Test Loss Force: 8.506979128656528, time: 8.674328327178955


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.411535784214851, Training Loss Force: 4.476794337023547, time: 0.6966423988342285
Validation Loss Energy: 2.760673447450723, Validation Loss Force: 4.558877770498548, time: 0.0607457160949707
Test Loss Energy: 7.968237264560927, Test Loss Force: 8.502330958033376, time: 8.70530104637146


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.337163326301455, Training Loss Force: 4.478673970137959, time: 0.7184278964996338
Validation Loss Energy: 4.672467313903253, Validation Loss Force: 4.808022723215442, time: 0.06372594833374023
Test Loss Energy: 7.107008113479728, Test Loss Force: 8.481377721453148, time: 8.677009105682373


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.410888653304085, Training Loss Force: 4.492883544723466, time: 0.7016708850860596
Validation Loss Energy: 5.7265378488887775, Validation Loss Force: 4.7098654876384085, time: 0.06008410453796387
Test Loss Energy: 9.824911977859713, Test Loss Force: 8.497132848246904, time: 8.856300354003906


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.40671579985011, Training Loss Force: 4.519658442780724, time: 0.7690863609313965
Validation Loss Energy: 3.8807740683005276, Validation Loss Force: 4.729793930860653, time: 0.06184220314025879
Test Loss Energy: 6.68593027093009, Test Loss Force: 8.548526570552413, time: 9.54370641708374


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.499583043100519, Training Loss Force: 4.52038634304041, time: 0.6988029479980469
Validation Loss Energy: 2.303715834222343, Validation Loss Force: 4.787265950770346, time: 0.060263872146606445
Test Loss Energy: 6.459918140653169, Test Loss Force: 8.533698092484602, time: 8.716926574707031


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.447629132289927, Training Loss Force: 4.488306057415346, time: 0.7428333759307861
Validation Loss Energy: 5.821647411865497, Validation Loss Force: 4.5867799958364674, time: 0.06588077545166016
Test Loss Energy: 9.928448649353847, Test Loss Force: 8.612576093638545, time: 8.922365427017212


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.3738561152524245, Training Loss Force: 4.489439867993001, time: 0.6841647624969482
Validation Loss Energy: 5.815284641020611, Validation Loss Force: 4.702062715426807, time: 0.06013083457946777
Test Loss Energy: 7.561579737042351, Test Loss Force: 8.520688441285923, time: 8.694925785064697


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.496610870875731, Training Loss Force: 4.505064385898779, time: 0.7027297019958496
Validation Loss Energy: 3.705324364127332, Validation Loss Force: 4.858591108924789, time: 0.06273102760314941
Test Loss Energy: 8.131790678420574, Test Loss Force: 8.566175933278315, time: 8.720398187637329


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.475432508062111, Training Loss Force: 4.512444873842656, time: 0.7357816696166992
Validation Loss Energy: 2.5275323942590973, Validation Loss Force: 4.800349544446771, time: 0.06099414825439453
Test Loss Energy: 7.439268678037682, Test Loss Force: 8.534860406773433, time: 8.924334049224854


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.464978947700226, Training Loss Force: 4.507618835984157, time: 0.7095646858215332
Validation Loss Energy: 5.361030899231233, Validation Loss Force: 4.702382245651213, time: 0.05996823310852051
Test Loss Energy: 7.236609975868193, Test Loss Force: 8.556834148873326, time: 8.736643314361572


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.374202236315536, Training Loss Force: 4.5112499379952675, time: 0.6906108856201172
Validation Loss Energy: 6.616706078939776, Validation Loss Force: 4.576031756162534, time: 0.06011390686035156
Test Loss Energy: 10.369380251194702, Test Loss Force: 8.561334816925697, time: 8.749497890472412


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.600048482579296, Training Loss Force: 4.480190678436271, time: 0.7079184055328369
Validation Loss Energy: 3.5102335712647115, Validation Loss Force: 4.761401148117665, time: 0.05981779098510742
Test Loss Energy: 6.675150402910977, Test Loss Force: 8.499839273969146, time: 8.942100763320923


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.451410481601839, Training Loss Force: 4.493834844276745, time: 0.6993818283081055
Validation Loss Energy: 2.6208631647635725, Validation Loss Force: 4.790769204443228, time: 0.060990095138549805
Test Loss Energy: 6.41095717086568, Test Loss Force: 8.47552813070959, time: 8.712177515029907

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–‚â–â–ˆâ–‚â–…â–„â–‚â–‡â–â–â–‡â–ƒâ–„â–ƒâ–‚â–ˆâ–â–
wandb:   test_error_force â–ˆâ–‡â–‚â–â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–„â–†â–ƒâ–…â–„â–„â–…â–‚â–‚
wandb:          test_loss â–„â–ˆâ–‚â–â–„â–‚â–‚â–‚â–â–ƒâ–â–â–ƒâ–‚â–‚â–â–â–„â–â–
wandb: train_error_energy â–‡â–â–‡â–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–‡â–‡â–ˆâ–ˆâ–ˆâ–‡â–ˆâ–‡
wandb:  train_error_force â–…â–ˆâ–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–†â–â–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–â–…â–„â–‚â–‡â–†â–„â–ƒâ–…â–‡â–„â–‚â–‡â–‡â–„â–‚â–†â–ˆâ–„â–‚
wandb:  valid_error_force â–…â–…â–ˆâ–‚â–ƒâ–ƒâ–…â–â–…â–ƒâ–„â–„â–â–ƒâ–†â–…â–ƒâ–â–„â–„
wandb:         valid_loss â–â–ˆâ–†â–‚â–‡â–‡â–„â–ƒâ–†â–‡â–„â–ƒâ–‡â–‡â–„â–ƒâ–†â–ˆâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1347
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.41096
wandb:   test_error_force 8.47553
wandb:          test_loss 4.30444
wandb: train_error_energy 4.45141
wandb:  train_error_force 4.49383
wandb:         train_loss 1.86113
wandb: valid_error_energy 2.62086
wandb:  valid_error_force 4.79077
wandb:         valid_loss 1.56972
wandb: 
wandb: ğŸš€ View run al_73_63 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/a7q5tuzc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_060612-a7q5tuzc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.279831647872925, Uncertainty Bias: -0.11071869730949402
7.1525574e-06 0.009983063
2.7043185 9.234198
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3245 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2220 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1620 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_064913-tq50gys2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_64
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tq50gys2
Training model 64. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.865798199744215, Training Loss Force: 4.914203535943202, time: 0.7449054718017578
Validation Loss Energy: 3.8949033162862294, Validation Loss Force: 4.728703074714754, time: 0.06090974807739258
Test Loss Energy: 6.682911287675388, Test Loss Force: 8.560691645841237, time: 8.721495866775513


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.950470159677633, Training Loss Force: 4.49576427242621, time: 0.709181547164917
Validation Loss Energy: 2.1680584424413194, Validation Loss Force: 4.796884367197842, time: 0.05999159812927246
Test Loss Energy: 6.334453009336454, Test Loss Force: 8.506053454545276, time: 8.74777865409851


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.925456763574521, Training Loss Force: 4.469780279640231, time: 0.6888227462768555
Validation Loss Energy: 3.2382952027594927, Validation Loss Force: 4.678939415298791, time: 0.060520172119140625
Test Loss Energy: 8.288502161915249, Test Loss Force: 8.548619965686543, time: 8.918160438537598


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9942877036475584, Training Loss Force: 4.499900833398576, time: 0.753753662109375
Validation Loss Energy: 3.9329681614442924, Validation Loss Force: 4.968055706401181, time: 0.062059640884399414
Test Loss Energy: 8.537765215549204, Test Loss Force: 8.539413335624095, time: 8.772193431854248


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.1166794205310158, Training Loss Force: 4.546357819749047, time: 0.7067544460296631
Validation Loss Energy: 2.3505778919977214, Validation Loss Force: 4.764011275846231, time: 0.060347795486450195
Test Loss Energy: 7.379802189603387, Test Loss Force: 8.574053244860872, time: 8.765831708908081


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9498352134296675, Training Loss Force: 4.452238207546656, time: 0.7035415172576904
Validation Loss Energy: 2.5192053475434086, Validation Loss Force: 4.752234304718111, time: 0.06067657470703125
Test Loss Energy: 6.522325221144728, Test Loss Force: 8.470783030225341, time: 8.79421067237854


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.930366965191828, Training Loss Force: 4.48926189838353, time: 0.9104666709899902
Validation Loss Energy: 3.6611839913226287, Validation Loss Force: 4.902819881380426, time: 0.06440591812133789
Test Loss Energy: 6.486513752769242, Test Loss Force: 8.50094944404039, time: 8.76251220703125


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0775805930696034, Training Loss Force: 4.46982827778706, time: 0.7391407489776611
Validation Loss Energy: 2.240956869446315, Validation Loss Force: 4.549839184527048, time: 0.06330490112304688
Test Loss Energy: 6.355877714607684, Test Loss Force: 8.509730703754075, time: 8.820229530334473


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0441732304049234, Training Loss Force: 4.465987628574575, time: 0.7119500637054443
Validation Loss Energy: 2.81266702702858, Validation Loss Force: 4.442660285833604, time: 0.06264925003051758
Test Loss Energy: 8.021982023305318, Test Loss Force: 8.495146746719477, time: 8.720433235168457


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9374414668915594, Training Loss Force: 4.492821766981352, time: 0.7080516815185547
Validation Loss Energy: 3.9812902608095198, Validation Loss Force: 4.861584004915205, time: 0.07031488418579102
Test Loss Energy: 8.481772293511346, Test Loss Force: 8.5936833324121, time: 8.995190858840942


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.015956337315343, Training Loss Force: 4.484043351782637, time: 0.7071499824523926
Validation Loss Energy: 2.5122776650753034, Validation Loss Force: 4.777890689050202, time: 0.061530351638793945
Test Loss Energy: 7.553494569058201, Test Loss Force: 8.553311728166788, time: 8.800307750701904


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.051565928903362, Training Loss Force: 4.463308628761339, time: 0.7296850681304932
Validation Loss Energy: 2.8267672166907385, Validation Loss Force: 4.967079302196288, time: 0.06385922431945801
Test Loss Energy: 6.533990479978401, Test Loss Force: 8.557018155194354, time: 8.785704612731934


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0270850849003783, Training Loss Force: 4.469008202857664, time: 0.7093648910522461
Validation Loss Energy: 3.5867544912702334, Validation Loss Force: 4.641815347282272, time: 0.06847262382507324
Test Loss Energy: 6.616866928835435, Test Loss Force: 8.533893122677068, time: 9.80550765991211


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9776687608711243, Training Loss Force: 4.46077899333985, time: 0.749631404876709
Validation Loss Energy: 2.0440182566762126, Validation Loss Force: 4.665713090699826, time: 0.06298708915710449
Test Loss Energy: 6.61288128868856, Test Loss Force: 8.568170489238444, time: 8.782772779464722


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9269857989403176, Training Loss Force: 4.470612187104474, time: 0.7000596523284912
Validation Loss Energy: 2.6293110094909267, Validation Loss Force: 4.929755722625018, time: 0.06137990951538086
Test Loss Energy: 7.4007644495301586, Test Loss Force: 8.59032979984081, time: 8.856760740280151


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.499326299215415, Training Loss Force: 5.621022884225922, time: 0.7569153308868408
Validation Loss Energy: 3.931007782283544, Validation Loss Force: 4.8199851777421205, time: 0.06164813041687012
Test Loss Energy: 6.842591748297299, Test Loss Force: 8.604495898987258, time: 8.991128921508789


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0550952296879648, Training Loss Force: 4.552032952022842, time: 0.6877381801605225
Validation Loss Energy: 1.9922087131474646, Validation Loss Force: 4.874794297335662, time: 0.06565523147583008
Test Loss Energy: 6.397089003036482, Test Loss Force: 8.451989502494712, time: 8.854050397872925


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.963242977134098, Training Loss Force: 4.468169661924214, time: 0.7226531505584717
Validation Loss Energy: 3.131603949495631, Validation Loss Force: 4.715545332212735, time: 0.060654401779174805
Test Loss Energy: 7.9480614720575735, Test Loss Force: 8.563854363778345, time: 8.782361268997192


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0608571071291566, Training Loss Force: 4.487787849350896, time: 0.7124927043914795
Validation Loss Energy: 3.958301230176497, Validation Loss Force: 4.86740324037488, time: 0.06046628952026367
Test Loss Energy: 8.292699286455244, Test Loss Force: 8.505419134267916, time: 8.946157217025757


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.03709832997207, Training Loss Force: 4.473043485617098, time: 0.7222464084625244
Validation Loss Energy: 2.5277607414682457, Validation Loss Force: 4.704325924626017, time: 0.0606379508972168
Test Loss Energy: 7.702769842719366, Test Loss Force: 8.54242757637573, time: 8.833425521850586

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‡â–ˆâ–„â–‚â–â–â–†â–ˆâ–…â–‚â–‚â–‚â–„â–ƒâ–â–†â–‡â–…
wandb:   test_error_force â–†â–ƒâ–…â–…â–‡â–‚â–ƒâ–„â–ƒâ–ˆâ–†â–†â–…â–†â–‡â–ˆâ–â–†â–ƒâ–…
wandb:          test_loss â–â–‚â–ˆâ–ˆâ–†â–ƒâ–‚â–‚â–†â–ˆâ–†â–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–ˆâ–†â–…
wandb: train_error_energy â–ˆâ–â–â–â–‚â–â–â–‚â–â–â–â–â–â–â–â–ƒâ–â–â–â–
wandb:  train_error_force â–„â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–ˆâ–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–‡â–‚â–â–â–
wandb: valid_error_energy â–ˆâ–‚â–…â–ˆâ–‚â–ƒâ–‡â–‚â–„â–ˆâ–ƒâ–„â–‡â–â–ƒâ–ˆâ–â–…â–ˆâ–ƒ
wandb:  valid_error_force â–…â–†â–„â–ˆâ–…â–…â–‡â–‚â–â–‡â–…â–ˆâ–„â–„â–‡â–†â–‡â–…â–‡â–„
wandb:         valid_loss â–†â–‚â–„â–ˆâ–‚â–ƒâ–‡â–â–‚â–‡â–‚â–„â–†â–â–ƒâ–ˆâ–‚â–„â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1349
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.70277
wandb:   test_error_force 8.54243
wandb:          test_loss 5.61198
wandb: train_error_energy 3.0371
wandb:  train_error_force 4.47304
wandb:         train_loss 1.46811
wandb: valid_error_energy 2.52776
wandb:  valid_error_force 4.70433
wandb:         valid_loss 1.37726
wandb: 
wandb: ğŸš€ View run al_73_64 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/tq50gys2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_064913-tq50gys2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1262173652648926, Uncertainty Bias: -0.00011032819747924805
0.0001296997 0.0030293465
2.8059607 9.308057
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 3358 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3355 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1056 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_073233-w26exn28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_65
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w26exn28
Training model 65. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.765460138781292, Training Loss Force: 4.938716762771862, time: 0.7147164344787598
Validation Loss Energy: 1.921704925805063, Validation Loss Force: 4.73731213190376, time: 0.06388425827026367
Test Loss Energy: 7.118654726395498, Test Loss Force: 8.609183138136162, time: 8.611545085906982


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.126733998028717, Training Loss Force: 4.477773755029439, time: 0.6956648826599121
Validation Loss Energy: 1.6778109568874382, Validation Loss Force: 4.683459598961124, time: 0.0640115737915039
Test Loss Energy: 6.544488413884559, Test Loss Force: 8.513356466260465, time: 8.619431495666504


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.127369951466192, Training Loss Force: 4.491504684161542, time: 0.6931731700897217
Validation Loss Energy: 1.8426356130916837, Validation Loss Force: 4.785592592138698, time: 0.060781002044677734
Test Loss Energy: 6.826176077562474, Test Loss Force: 8.490287658285427, time: 8.833304166793823


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1512607843726936, Training Loss Force: 4.489807002809466, time: 0.7159521579742432
Validation Loss Energy: 2.279958149697578, Validation Loss Force: 4.973009426890636, time: 0.0634608268737793
Test Loss Energy: 7.544591524477184, Test Loss Force: 8.568463139449776, time: 8.623525381088257


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0809455939131283, Training Loss Force: 4.46161052278438, time: 0.7092564105987549
Validation Loss Energy: 2.4952277772370395, Validation Loss Force: 4.99955426111498, time: 0.06034660339355469
Test Loss Energy: 7.396445080794853, Test Loss Force: 8.565312410672336, time: 8.641340970993042


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.060970276246489, Training Loss Force: 4.4671913883341645, time: 0.7216107845306396
Validation Loss Energy: 1.8346613856377179, Validation Loss Force: 4.781058602989317, time: 0.06429767608642578
Test Loss Energy: 6.689273301911502, Test Loss Force: 8.60037831046722, time: 8.611890316009521


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.078714974673683, Training Loss Force: 4.469344174350403, time: 0.7120883464813232
Validation Loss Energy: 2.140044882530436, Validation Loss Force: 4.685375221623541, time: 0.06159210205078125
Test Loss Energy: 6.583238016796053, Test Loss Force: 8.568973935475691, time: 8.813104629516602


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0952544892944234, Training Loss Force: 4.527418545369944, time: 0.7044758796691895
Validation Loss Energy: 2.298858640807647, Validation Loss Force: 4.623311095917381, time: 0.06292557716369629
Test Loss Energy: 7.658854394897225, Test Loss Force: 8.55447565593257, time: 8.665346384048462


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.055706175681019, Training Loss Force: 4.46842651855157, time: 0.696260929107666
Validation Loss Energy: 2.182923277950594, Validation Loss Force: 4.774179017056732, time: 0.0598599910736084
Test Loss Energy: 7.503504061078048, Test Loss Force: 8.59857701267284, time: 8.583138704299927


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0919223309684263, Training Loss Force: 4.5033288507918945, time: 0.7328999042510986
Validation Loss Energy: 1.7702196544586268, Validation Loss Force: 4.878998736149071, time: 0.061606407165527344
Test Loss Energy: 6.644128242422952, Test Loss Force: 8.611268403210987, time: 8.822652578353882


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0958993610359373, Training Loss Force: 5.04651662357307, time: 0.6753954887390137
Validation Loss Energy: 3.636888226806729, Validation Loss Force: 5.142779286489506, time: 0.06301140785217285
Test Loss Energy: 8.887881912702483, Test Loss Force: 8.824967554590675, time: 8.617609977722168


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.531701078913346, Training Loss Force: 5.391812164129067, time: 0.721177339553833
Validation Loss Energy: 6.071579500013246, Validation Loss Force: 4.872774465512951, time: 0.060251712799072266
Test Loss Energy: 7.566968845660518, Test Loss Force: 8.587397487345193, time: 8.850964069366455


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.473344570550858, Training Loss Force: 4.642175398112886, time: 0.7378566265106201
Validation Loss Energy: 4.061552245135775, Validation Loss Force: 4.711680463846866, time: 0.06041765213012695
Test Loss Energy: 8.638560724934333, Test Loss Force: 8.535611811384113, time: 8.847151756286621


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.458154933254607, Training Loss Force: 4.548503117867959, time: 0.7029838562011719
Validation Loss Energy: 2.4934105743371227, Validation Loss Force: 4.920357748651989, time: 0.061280012130737305
Test Loss Energy: 7.522661488483474, Test Loss Force: 8.556119257339349, time: 8.66136360168457


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.474144781321097, Training Loss Force: 4.5110514258624965, time: 0.6784460544586182
Validation Loss Energy: 5.5793468633561325, Validation Loss Force: 4.95253477625343, time: 0.06098818778991699
Test Loss Energy: 7.214477865875844, Test Loss Force: 8.448601858409237, time: 9.564531564712524


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.423386500257091, Training Loss Force: 4.496271605950973, time: 0.7414753437042236
Validation Loss Energy: 6.225040626026072, Validation Loss Force: 4.886281353235784, time: 0.06081056594848633
Test Loss Energy: 10.150320429893943, Test Loss Force: 8.609322391456283, time: 8.839843511581421


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.512023076340042, Training Loss Force: 4.485717295568086, time: 0.7443451881408691
Validation Loss Energy: 3.3702815596661786, Validation Loss Force: 4.743813848295705, time: 0.059348106384277344
Test Loss Energy: 6.685733529332881, Test Loss Force: 8.451022409590701, time: 8.6539785861969


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.554798230951772, Training Loss Force: 4.532078109560924, time: 0.7092320919036865
Validation Loss Energy: 2.408146661651319, Validation Loss Force: 4.58959097113466, time: 0.06053972244262695
Test Loss Energy: 6.354439679957457, Test Loss Force: 8.546634363124532, time: 8.648912191390991


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.408396211397495, Training Loss Force: 4.491059946558545, time: 0.7029237747192383
Validation Loss Energy: 5.725075357938324, Validation Loss Force: 4.663507775478557, time: 0.06059980392456055
Test Loss Energy: 9.699660107626059, Test Loss Force: 8.566664835447892, time: 8.869117498397827


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.394357763228986, Training Loss Force: 4.4878629561716545, time: 0.7353808879852295
Validation Loss Energy: 5.935985346269665, Validation Loss Force: 4.721921017868086, time: 0.06044602394104004
Test Loss Energy: 7.4401933845290875, Test Loss Force: 8.513026379653251, time: 8.686302661895752

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–†â–ƒâ–…â–ƒâ–ƒâ–ˆâ–‚â–â–‡â–ƒ
wandb:   test_error_force â–„â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–ˆâ–„â–ƒâ–ƒâ–â–„â–â–ƒâ–ƒâ–‚
wandb:          test_loss â–†â–…â–†â–‡â–‡â–†â–†â–ˆâ–ˆâ–†â–‡â–‚â–ƒâ–‚â–‚â–…â–â–â–„â–‚
wandb: train_error_energy â–†â–â–â–â–â–â–â–â–â–â–„â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–…â–â–â–â–â–â–â–â–â–â–…â–ˆâ–‚â–‚â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–…â–†â–„â–„â–„â–„â–„â–„â–„â–„
wandb: valid_error_energy â–â–â–â–‚â–‚â–â–‚â–‚â–‚â–â–„â–ˆâ–…â–‚â–‡â–ˆâ–„â–‚â–‡â–ˆ
wandb:  valid_error_force â–ƒâ–‚â–ƒâ–†â–†â–ƒâ–‚â–â–ƒâ–…â–ˆâ–…â–ƒâ–…â–†â–…â–ƒâ–â–‚â–ƒ
wandb:         valid_loss â–â–â–â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–…â–ˆâ–„â–ƒâ–‡â–‡â–„â–ƒâ–†â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1351
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.44019
wandb:   test_error_force 8.51303
wandb:          test_loss 4.67667
wandb: train_error_energy 4.39436
wandb:  train_error_force 4.48786
wandb:         train_loss 1.84432
wandb: valid_error_energy 5.93599
wandb:  valid_error_force 4.72192
wandb:         valid_loss 2.40146
wandb: 
wandb: ğŸš€ View run al_73_65 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/w26exn28
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_073233-w26exn28/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5925066471099854, Uncertainty Bias: 0.0272161066532135
9.536743e-05 0.14774704
3.252818 13.98726
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2507 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2135 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2952 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3514 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2625 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_081559-i0s6nwi6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_66
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/i0s6nwi6
Training model 66. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.042766937295874, Training Loss Force: 4.941143918602701, time: 0.7132618427276611
Validation Loss Energy: 2.0809969217404403, Validation Loss Force: 5.074522509165948, time: 0.061158180236816406
Test Loss Energy: 7.1587737748654305, Test Loss Force: 8.745562487407673, time: 8.67612075805664


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.840765458724848, Training Loss Force: 4.784417929540293, time: 0.7309648990631104
Validation Loss Energy: 2.625918645052717, Validation Loss Force: 5.038661643214278, time: 0.06059885025024414
Test Loss Energy: 8.03852948386355, Test Loss Force: 8.601791776899743, time: 8.664112567901611


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.904380660271579, Training Loss Force: 5.100689178683575, time: 0.6916708946228027
Validation Loss Energy: 6.380715528687712, Validation Loss Force: 5.249545356586399, time: 0.06151461601257324
Test Loss Energy: 10.367276580358224, Test Loss Force: 8.766608895287076, time: 8.84480595588684


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.660538991303808, Training Loss Force: 4.697030107919466, time: 0.7275185585021973
Validation Loss Energy: 3.684726577452428, Validation Loss Force: 5.234182298863112, time: 0.060329437255859375
Test Loss Energy: 8.77243365434054, Test Loss Force: 9.078273699342773, time: 8.722543478012085


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0751259816152356, Training Loss Force: 5.258078090041875, time: 0.7293736934661865
Validation Loss Energy: 2.540134688576599, Validation Loss Force: 5.80481451510994, time: 0.06111741065979004
Test Loss Energy: 8.054730949211612, Test Loss Force: 9.223185879509536, time: 9.021360397338867


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0021706238058137, Training Loss Force: 4.968675249640436, time: 0.7609095573425293
Validation Loss Energy: 3.057188700268575, Validation Loss Force: 5.094627974359206, time: 0.06659770011901855
Test Loss Energy: 7.8570167005313625, Test Loss Force: 8.6586483078133, time: 10.640049934387207


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.5107855473640575, Training Loss Force: 5.085056737898884, time: 0.7161509990692139
Validation Loss Energy: 2.1541321573821306, Validation Loss Force: 5.72636327627837, time: 0.06199812889099121
Test Loss Energy: 6.791803846950086, Test Loss Force: 9.29938833950152, time: 10.51462435722351


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.8212790307000057, Training Loss Force: 4.730771163601903, time: 0.739722490310669
Validation Loss Energy: 3.592332019372006, Validation Loss Force: 4.734456622776381, time: 0.06744861602783203
Test Loss Energy: 6.484453883635126, Test Loss Force: 8.518160640519387, time: 10.25390887260437


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9716541565384813, Training Loss Force: 4.44929862787081, time: 0.7443315982818604
Validation Loss Energy: 1.9384898930269587, Validation Loss Force: 4.625632421763678, time: 0.06879782676696777
Test Loss Energy: 6.44587387067472, Test Loss Force: 8.505568744617836, time: 10.549778461456299


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.933567060000882, Training Loss Force: 4.451105499958024, time: 0.7504878044128418
Validation Loss Energy: 2.9145303678704355, Validation Loss Force: 4.808740608541914, time: 0.06739425659179688
Test Loss Energy: 7.962063304327908, Test Loss Force: 8.536737477362621, time: 10.323323965072632


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.914269329723653, Training Loss Force: 4.459910034765395, time: 0.7389299869537354
Validation Loss Energy: 4.019000616687267, Validation Loss Force: 4.568049289950168, time: 0.0699758529663086
Test Loss Energy: 8.922451267296788, Test Loss Force: 8.491621388179183, time: 10.391732692718506


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9692446485320447, Training Loss Force: 4.446873056615752, time: 0.74249267578125
Validation Loss Energy: 2.216797378447723, Validation Loss Force: 4.723393306260959, time: 0.061962127685546875
Test Loss Energy: 7.198256458232444, Test Loss Force: 8.427845666536047, time: 10.807826280593872


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9058505951033644, Training Loss Force: 4.442475227059929, time: 0.667043924331665
Validation Loss Energy: 2.659054931334815, Validation Loss Force: 4.786426488090198, time: 0.06199169158935547
Test Loss Energy: 6.523431254932569, Test Loss Force: 8.46198945492601, time: 10.464153051376343


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.987635602728476, Training Loss Force: 4.466730680692888, time: 0.738006591796875
Validation Loss Energy: 3.4240232033741416, Validation Loss Force: 4.7511715048845975, time: 0.07349896430969238
Test Loss Energy: 6.5850280155885335, Test Loss Force: 8.48911846573502, time: 10.479624032974243


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.98127419120105, Training Loss Force: 4.449463076802606, time: 0.725947380065918
Validation Loss Energy: 1.9801767858472568, Validation Loss Force: 4.692884961239102, time: 0.0695946216583252
Test Loss Energy: 6.4863285153559715, Test Loss Force: 8.478113741515962, time: 10.330324172973633


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.969422079592883, Training Loss Force: 4.448915756041914, time: 0.7556843757629395
Validation Loss Energy: 3.0882149737238613, Validation Loss Force: 4.643049379689003, time: 0.06861042976379395
Test Loss Energy: 8.156232503986843, Test Loss Force: 8.49668869441501, time: 10.371044635772705


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9156463985757064, Training Loss Force: 4.465646126601653, time: 0.774346113204956
Validation Loss Energy: 4.069724202791324, Validation Loss Force: 4.920294955952839, time: 0.07017993927001953
Test Loss Energy: 8.886988377559891, Test Loss Force: 8.477589319537282, time: 11.26840591430664


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.999542679956397, Training Loss Force: 4.435891542530522, time: 0.7097368240356445
Validation Loss Energy: 2.7017350398805235, Validation Loss Force: 4.586037616903944, time: 0.06852126121520996
Test Loss Energy: 7.818111574296602, Test Loss Force: 8.526922212083669, time: 10.441227197647095


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9161588742042355, Training Loss Force: 4.438799694786678, time: 0.7057461738586426
Validation Loss Energy: 2.444526458047574, Validation Loss Force: 4.87826659999726, time: 0.06223344802856445
Test Loss Energy: 6.611120686886569, Test Loss Force: 8.450099001808347, time: 10.500269412994385


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9257401152410663, Training Loss Force: 4.443115789230888, time: 0.7360556125640869
Validation Loss Energy: 3.711882304478624, Validation Loss Force: 4.708526132725654, time: 0.07003617286682129
Test Loss Energy: 6.570400611256915, Test Loss Force: 8.504651086595835, time: 10.511942148208618

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ˆâ–…â–„â–„â–‚â–â–â–„â–…â–‚â–â–â–â–„â–…â–ƒâ–â–
wandb:   test_error_force â–„â–‚â–„â–†â–‡â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–â–‚
wandb:          test_loss â–â–‚â–ˆâ–†â–„â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–â–â–â–‚â–ƒâ–‚â–â–‚
wandb: train_error_energy â–ˆâ–„â–â–„â–‚â–‚â–ƒâ–â–â–â–â–â–â–‚â–‚â–â–â–‚â–â–
wandb:  train_error_force â–…â–„â–‡â–ƒâ–ˆâ–†â–‡â–„â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–‡â–ˆâ–ƒâ–…â–…â–ƒâ–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‚â–ˆâ–„â–‚â–ƒâ–â–„â–â–ƒâ–„â–â–‚â–ƒâ–â–ƒâ–„â–‚â–‚â–„
wandb:  valid_error_force â–„â–„â–…â–…â–ˆâ–„â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–â–ƒâ–‚
wandb:         valid_loss â–‚â–‚â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–â–‚â–‚â–â–‚â–ƒâ–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1355
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.5704
wandb:   test_error_force 8.50465
wandb:          test_loss 5.33721
wandb: train_error_energy 2.92574
wandb:  train_error_force 4.44312
wandb:         train_loss 1.426
wandb: valid_error_energy 3.71188
wandb:  valid_error_force 4.70853
wandb:         valid_loss 1.92744
wandb: 
wandb: ğŸš€ View run al_73_66 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/i0s6nwi6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_081559-i0s6nwi6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8515669107437134, Uncertainty Bias: 0.06665179133415222
0.00016498566 0.019039154
3.162777 14.234683
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3338 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_090008-o6dks5v8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_67
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o6dks5v8
Training model 67. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.450453391243087, Training Loss Force: 4.856000809106916, time: 0.7606792449951172
Validation Loss Energy: 1.8388035884248395, Validation Loss Force: 5.022979277935729, time: 0.07424736022949219
Test Loss Energy: 6.233032163383068, Test Loss Force: 8.680249248135786, time: 10.797006130218506


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.578089027245693, Training Loss Force: 4.910489409410775, time: 0.7563998699188232
Validation Loss Energy: 7.719818157301019, Validation Loss Force: 4.879581238634818, time: 0.06993412971496582
Test Loss Energy: 11.988505319855852, Test Loss Force: 8.66221647945158, time: 11.693646669387817


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.368849904169398, Training Loss Force: 4.634498843058558, time: 0.7308785915374756
Validation Loss Energy: 3.14291242474072, Validation Loss Force: 5.093082873155613, time: 0.07062292098999023
Test Loss Energy: 8.012908920118779, Test Loss Force: 8.454852486776874, time: 10.923628568649292


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.352042060281934, Training Loss Force: 4.6787817085815995, time: 0.7875821590423584
Validation Loss Energy: 8.317244374546485, Validation Loss Force: 5.064107605203468, time: 0.06851458549499512
Test Loss Energy: 8.504706243258832, Test Loss Force: 8.50284260276682, time: 10.74021863937378


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.2361334953976755, Training Loss Force: 4.677752531789121, time: 0.7723443508148193
Validation Loss Energy: 5.507318070700557, Validation Loss Force: 4.935796513884893, time: 0.07403874397277832
Test Loss Energy: 9.565934498924731, Test Loss Force: 8.482624388876651, time: 11.114915370941162


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.30944405192167, Training Loss Force: 4.890509213736334, time: 0.7103128433227539
Validation Loss Energy: 6.221541825736108, Validation Loss Force: 5.1118897318898195, time: 0.06423115730285645
Test Loss Energy: 10.062460356430899, Test Loss Force: 8.48833025892749, time: 11.125730276107788


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.095762575817073, Training Loss Force: 4.6066134473653895, time: 0.7112076282501221
Validation Loss Energy: 8.378733568517859, Validation Loss Force: 4.654015835125947, time: 0.06486320495605469
Test Loss Energy: 8.823730852485808, Test Loss Force: 8.392293904996365, time: 10.852848291397095


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.380248643272223, Training Loss Force: 4.742255133204098, time: 0.723067045211792
Validation Loss Energy: 1.8970461549140143, Validation Loss Force: 4.679438416854815, time: 0.07125091552734375
Test Loss Energy: 6.312908564023456, Test Loss Force: 8.504307546575301, time: 9.337524890899658


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.046602639774299, Training Loss Force: 4.637531389692007, time: 0.7242300510406494
Validation Loss Energy: 2.542934753086641, Validation Loss Force: 5.082799121320083, time: 0.07522249221801758
Test Loss Energy: 7.178637548439178, Test Loss Force: 8.560622494830454, time: 10.970225811004639


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.962071711534756, Training Loss Force: 4.572653885932218, time: 0.7153916358947754
Validation Loss Energy: 2.3104119407786836, Validation Loss Force: 4.871909841219313, time: 0.06809258460998535
Test Loss Energy: 6.599583885999762, Test Loss Force: 8.515193503035668, time: 8.138889074325562


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.971977000908315, Training Loss Force: 4.472123520273169, time: 0.6659801006317139
Validation Loss Energy: 3.6640363830819638, Validation Loss Force: 4.771418142316373, time: 0.06017422676086426
Test Loss Energy: 6.556732519233082, Test Loss Force: 8.475143120600787, time: 8.24729609489441


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0388707064659, Training Loss Force: 4.461663393760658, time: 0.6950345039367676
Validation Loss Energy: 2.152937426079655, Validation Loss Force: 4.671764792747851, time: 0.06701374053955078
Test Loss Energy: 6.427686821417563, Test Loss Force: 8.432677647624649, time: 7.971681356430054


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.97869154757695, Training Loss Force: 4.439030866786969, time: 0.6901462078094482
Validation Loss Energy: 2.9360728283969384, Validation Loss Force: 4.81358655716474, time: 0.05738377571105957
Test Loss Energy: 8.119109055013865, Test Loss Force: 8.494291249529208, time: 7.96668004989624


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9771322784016534, Training Loss Force: 4.458394817832526, time: 0.7039415836334229
Validation Loss Energy: 3.890981889957295, Validation Loss Force: 4.822182031535844, time: 0.06198000907897949
Test Loss Energy: 8.477791673329614, Test Loss Force: 8.463777299307072, time: 8.047059059143066


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9576337212682065, Training Loss Force: 4.4586347619614966, time: 0.8669590950012207
Validation Loss Energy: 2.740756137685774, Validation Loss Force: 4.792726243566787, time: 0.05898594856262207
Test Loss Energy: 7.712644839288165, Test Loss Force: 8.461478215893418, time: 8.033634185791016


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.906021718931186, Training Loss Force: 4.446070960925303, time: 0.6896748542785645
Validation Loss Energy: 2.721728168489661, Validation Loss Force: 4.639284935107948, time: 0.05913901329040527
Test Loss Energy: 6.499675040490491, Test Loss Force: 8.474635999198682, time: 7.974959373474121


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0045449371413135, Training Loss Force: 4.444521411517144, time: 0.7402441501617432
Validation Loss Energy: 3.4240766439691646, Validation Loss Force: 4.712836562052523, time: 0.06014442443847656
Test Loss Energy: 6.4434800980811175, Test Loss Force: 8.387412829441413, time: 7.9711833000183105


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9776800211980508, Training Loss Force: 4.436286547238692, time: 0.7003076076507568
Validation Loss Energy: 2.24767268222207, Validation Loss Force: 4.661456769975416, time: 0.05836820602416992
Test Loss Energy: 6.325157941151442, Test Loss Force: 8.418666008585436, time: 8.204689502716064


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.069839054873132, Training Loss Force: 4.440548672895954, time: 0.7248208522796631
Validation Loss Energy: 3.0351712864538083, Validation Loss Force: 4.611044698006511, time: 0.06149029731750488
Test Loss Energy: 7.972289152859041, Test Loss Force: 8.447203995138226, time: 8.062148809432983


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0837810873014546, Training Loss Force: 4.451185148193689, time: 0.6878314018249512
Validation Loss Energy: 3.8303473001679906, Validation Loss Force: 4.577098786709819, time: 0.05931258201599121
Test Loss Energy: 8.642631266145195, Test Loss Force: 8.480884683000168, time: 8.88265085220337

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–ƒâ–„â–…â–†â–„â–â–‚â–â–â–â–ƒâ–„â–ƒâ–â–â–â–ƒâ–„
wandb:   test_error_force â–ˆâ–ˆâ–ƒâ–„â–ƒâ–ƒâ–â–„â–…â–„â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–ƒ
wandb:          test_loss â–„â–‡â–ƒâ–ƒâ–„â–„â–ƒâ–â–‚â–„â–„â–„â–‡â–ˆâ–†â–…â–„â–„â–†â–‡
wandb: train_error_energy â–†â–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–‡â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–‡â–ˆâ–„â–…â–…â–ˆâ–„â–†â–„â–ƒâ–‚â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ˆâ–…â–…â–…â–…â–…â–…â–…â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–‚â–ˆâ–…â–†â–ˆâ–â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚â–ƒ
wandb:  valid_error_force â–‡â–…â–ˆâ–‡â–†â–ˆâ–‚â–‚â–ˆâ–…â–„â–‚â–„â–„â–„â–‚â–ƒâ–‚â–â–
wandb:         valid_loss â–â–‡â–ƒâ–ˆâ–„â–…â–‡â–‚â–ƒâ–â–ƒâ–â–‚â–„â–‚â–‚â–ƒâ–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1356
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.64263
wandb:   test_error_force 8.48088
wandb:          test_loss 6.04009
wandb: train_error_energy 3.08378
wandb:  train_error_force 4.45119
wandb:         train_loss 1.46968
wandb: valid_error_energy 3.83035
wandb:  valid_error_force 4.5771
wandb:         valid_loss 1.77843
wandb: 
wandb: ğŸš€ View run al_73_67 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/o6dks5v8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_090008-o6dks5v8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9797080755233765, Uncertainty Bias: 0.0023628175258636475
0.0002784729 0.023781657
2.8372178 9.710177
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2287 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3758 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2211 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2641 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 216 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2674 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3203 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_094257-vj9l5eq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_68
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vj9l5eq1
Training model 68. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.769846441325049, Training Loss Force: 4.777072001919205, time: 0.7196683883666992
Validation Loss Energy: 2.3914841067923964, Validation Loss Force: 4.829050038672841, time: 0.07595324516296387
Test Loss Energy: 6.24224799632634, Test Loss Force: 8.52173486969108, time: 9.60729455947876


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.16197223703238, Training Loss Force: 4.542735821281158, time: 0.6998984813690186
Validation Loss Energy: 2.115610395136623, Validation Loss Force: 5.017692889742258, time: 0.06511664390563965
Test Loss Energy: 7.262924992217797, Test Loss Force: 8.515094236897252, time: 9.631293296813965


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0868481671844323, Training Loss Force: 4.4968379934045775, time: 0.7168657779693604
Validation Loss Energy: 3.2617683161157625, Validation Loss Force: 4.6882835033385035, time: 0.06409883499145508
Test Loss Energy: 6.469221667934114, Test Loss Force: 8.497677177546713, time: 9.795339584350586


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.2027598687424645, Training Loss Force: 5.1496282010418275, time: 0.7099742889404297
Validation Loss Energy: 1.9118857174752257, Validation Loss Force: 5.607499146144928, time: 0.07149410247802734
Test Loss Energy: 7.536852055588221, Test Loss Force: 9.103089525136092, time: 9.642662286758423


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.056104088033968, Training Loss Force: 4.715536078497298, time: 0.6828596591949463
Validation Loss Energy: 1.9608236640308023, Validation Loss Force: 4.765359314855678, time: 0.06697916984558105
Test Loss Energy: 7.488820642049449, Test Loss Force: 8.471851049377003, time: 10.53609561920166


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1156764657327374, Training Loss Force: 4.482232352548692, time: 0.7348685264587402
Validation Loss Energy: 1.7394970460511, Validation Loss Force: 4.818871386674189, time: 0.06505513191223145
Test Loss Energy: 6.393899049515149, Test Loss Force: 8.556706091964083, time: 11.140806913375854


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.124993768745537, Training Loss Force: 4.4727281032528285, time: 0.7211415767669678
Validation Loss Energy: 2.0699670055969075, Validation Loss Force: 4.666944896415098, time: 0.06926846504211426
Test Loss Energy: 6.6057299694546785, Test Loss Force: 8.507246434222662, time: 11.615487575531006


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1185690182027983, Training Loss Force: 4.465644780230073, time: 0.741593599319458
Validation Loss Energy: 2.232606331135731, Validation Loss Force: 4.727821527566025, time: 0.07180023193359375
Test Loss Energy: 7.235229681309378, Test Loss Force: 8.51193600498566, time: 10.969005107879639


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.122977843989584, Training Loss Force: 4.467997895980715, time: 0.7420272827148438
Validation Loss Energy: 2.481596751465351, Validation Loss Force: 4.7349696524886, time: 0.07323884963989258
Test Loss Energy: 7.401306444884257, Test Loss Force: 8.511926146921274, time: 10.420491695404053


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.077835353871985, Training Loss Force: 4.477660721956943, time: 0.711057186126709
Validation Loss Energy: 2.0603156341358133, Validation Loss Force: 4.899357376161248, time: 0.06737136840820312
Test Loss Energy: 6.427907954029804, Test Loss Force: 8.526338963481411, time: 10.244966983795166


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0746348939890993, Training Loss Force: 4.483190984648729, time: 0.7161293029785156
Validation Loss Energy: 1.897768382288831, Validation Loss Force: 4.868405474200702, time: 0.06723809242248535
Test Loss Energy: 6.4967039276047425, Test Loss Force: 8.534675491122908, time: 10.446773767471313


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0760046846670916, Training Loss Force: 4.466344872738278, time: 0.6996059417724609
Validation Loss Energy: 2.2817444015862103, Validation Loss Force: 4.590197521888168, time: 0.06598162651062012
Test Loss Energy: 7.165479366427903, Test Loss Force: 8.555072413906883, time: 10.304145574569702


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1107159408884497, Training Loss Force: 4.475790104353766, time: 0.7384030818939209
Validation Loss Energy: 2.2322390383795234, Validation Loss Force: 5.108452610953278, time: 0.06761717796325684
Test Loss Energy: 6.928189165153676, Test Loss Force: 8.514628823408051, time: 10.260649681091309


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.123269307544899, Training Loss Force: 4.477935278192225, time: 0.740220308303833
Validation Loss Energy: 2.045467610147057, Validation Loss Force: 4.744057893679642, time: 0.0679774284362793
Test Loss Energy: 6.514869180933354, Test Loss Force: 8.492179366747894, time: 10.423587560653687


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.055854698590529, Training Loss Force: 4.470285660926204, time: 0.6960949897766113
Validation Loss Energy: 2.2695063939914464, Validation Loss Force: 4.780957956535357, time: 0.06883406639099121
Test Loss Energy: 6.458332612758619, Test Loss Force: 8.590625830892574, time: 10.289124250411987


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1531747525515725, Training Loss Force: 4.497779417840151, time: 0.7029476165771484
Validation Loss Energy: 2.160020197607899, Validation Loss Force: 4.883980512950913, time: 0.06612539291381836
Test Loss Energy: 7.356872679249136, Test Loss Force: 8.566637163851832, time: 10.285446643829346


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.121129894623296, Training Loss Force: 4.48563543617602, time: 0.7347650527954102
Validation Loss Energy: 2.4947786535697034, Validation Loss Force: 4.702968978850733, time: 0.06652045249938965
Test Loss Energy: 7.756376341411244, Test Loss Force: 8.694187418014911, time: 10.441627979278564


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.060235185844731, Training Loss Force: 4.528549549280689, time: 0.733844518661499
Validation Loss Energy: 1.8864093611476167, Validation Loss Force: 4.834371608591369, time: 0.06591510772705078
Test Loss Energy: 6.312113318072977, Test Loss Force: 8.548621010249656, time: 10.34950041770935


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1262846672272913, Training Loss Force: 4.516781888829879, time: 0.7216091156005859
Validation Loss Energy: 2.6165341425630175, Validation Loss Force: 4.976229000071607, time: 0.07262873649597168
Test Loss Energy: 6.346669739203905, Test Loss Force: 8.481237316315667, time: 10.444891691207886


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0843102463993746, Training Loss Force: 4.475878270978849, time: 0.7077980041503906
Validation Loss Energy: 2.168097075538138, Validation Loss Force: 4.725007434899791, time: 0.07207846641540527
Test Loss Energy: 7.282863456717416, Test Loss Force: 8.572345766554387, time: 10.268408298492432

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–‚â–‡â–‡â–‚â–ƒâ–†â–†â–‚â–‚â–…â–„â–‚â–‚â–†â–ˆâ–â–â–†
wandb:   test_error_force â–‚â–â–â–ˆâ–â–‚â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–ƒâ–‚â–â–‚
wandb:          test_loss â–â–…â–„â–ƒâ–ˆâ–„â–„â–†â–†â–ƒâ–„â–†â–…â–ƒâ–ƒâ–†â–‡â–ƒâ–„â–…
wandb: train_error_energy â–ˆâ–â–â–†â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–„â–‚â–â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–…â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–ƒâ–ˆâ–‚â–‚â–â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–‚â–…â–ƒ
wandb:  valid_error_force â–ƒâ–„â–‚â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–â–…â–‚â–‚â–ƒâ–‚â–ƒâ–„â–‚
wandb:         valid_loss â–„â–ƒâ–ˆâ–…â–‚â–â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1362
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.28286
wandb:   test_error_force 8.57235
wandb:          test_loss 6.6142
wandb: train_error_energy 2.08431
wandb:  train_error_force 4.47588
wandb:         train_loss 1.10022
wandb: valid_error_energy 2.1681
wandb:  valid_error_force 4.72501
wandb:         valid_loss 1.25171
wandb: 
wandb: ğŸš€ View run al_73_68 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vj9l5eq1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_094257-vj9l5eq1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.1124534606933594, Uncertainty Bias: 0.07423612475395203
3.8146973e-05 0.0063257217
2.9899108 10.113901
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1403 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3764 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3748 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3512 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_102602-pq9kd031
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_69
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/pq9kd031
Training model 69. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7926493775139503, Training Loss Force: 4.948387376989846, time: 0.7379744052886963
Validation Loss Energy: 2.168275767527745, Validation Loss Force: 4.939066632961989, time: 0.06876778602600098
Test Loss Energy: 7.164853293069592, Test Loss Force: 8.834576672541166, time: 10.096141338348389


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.971997419151162, Training Loss Force: 4.870513949056901, time: 0.7232751846313477
Validation Loss Energy: 4.031218027386032, Validation Loss Force: 5.905857542818198, time: 0.06507277488708496
Test Loss Energy: 6.825444328458602, Test Loss Force: 9.254593430159462, time: 10.029956579208374


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.200054633989148, Training Loss Force: 4.961392611840313, time: 0.6986064910888672
Validation Loss Energy: 2.383737447205569, Validation Loss Force: 5.464975305910929, time: 0.06691384315490723
Test Loss Energy: 7.406632418056002, Test Loss Force: 8.886993637681286, time: 10.23026990890503


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7561825758511915, Training Loss Force: 5.187351140315495, time: 0.6972291469573975
Validation Loss Energy: 4.997939909807004, Validation Loss Force: 5.668553912612598, time: 0.06807732582092285
Test Loss Energy: 7.058533725905792, Test Loss Force: 9.210974307172462, time: 10.050865173339844


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.5959637778523517, Training Loss Force: 5.032655790296904, time: 0.6958024501800537
Validation Loss Energy: 2.1295721959245872, Validation Loss Force: 4.9460058942256815, time: 0.06531643867492676
Test Loss Energy: 6.557748051419884, Test Loss Force: 8.623943910793928, time: 9.99974012374878


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.7269500836086817, Training Loss Force: 4.801495089170581, time: 0.6813099384307861
Validation Loss Energy: 1.793639939560025, Validation Loss Force: 4.743563790844828, time: 0.06802654266357422
Test Loss Energy: 6.161575661909317, Test Loss Force: 8.639993776925241, time: 10.231165170669556


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.656785549539746, Training Loss Force: 4.883291719607275, time: 0.6720635890960693
Validation Loss Energy: 1.88551434251556, Validation Loss Force: 4.915251277128428, time: 0.06655263900756836
Test Loss Energy: 7.011710226032679, Test Loss Force: 8.522806763985365, time: 10.046318054199219


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.891243418866042, Training Loss Force: 4.502243219603396, time: 0.699190616607666
Validation Loss Energy: 3.474227191026177, Validation Loss Force: 4.927187456695886, time: 0.0662987232208252
Test Loss Energy: 8.01796215506355, Test Loss Force: 8.460669630778709, time: 10.00557017326355


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.939161850139816, Training Loss Force: 4.466000885156285, time: 0.7202835083007812
Validation Loss Energy: 4.233265561040302, Validation Loss Force: 4.935274354737692, time: 0.06801652908325195
Test Loss Energy: 8.737597898846369, Test Loss Force: 8.523366113543165, time: 11.147579908370972


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9441920108757267, Training Loss Force: 4.463035418897637, time: 0.7187845706939697
Validation Loss Energy: 2.6451457917998624, Validation Loss Force: 4.850389981611123, time: 0.06729578971862793
Test Loss Energy: 7.492796505738432, Test Loss Force: 8.479560181634996, time: 10.022217750549316


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.92132447215357, Training Loss Force: 4.448462230775182, time: 0.7053098678588867
Validation Loss Energy: 2.648980822500177, Validation Loss Force: 4.661608407663793, time: 0.06619477272033691
Test Loss Energy: 6.372527614631113, Test Loss Force: 8.423766507679499, time: 10.288143396377563


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.896432826878934, Training Loss Force: 4.452168159976028, time: 0.6999242305755615
Validation Loss Energy: 3.4962225605954975, Validation Loss Force: 4.565338961105935, time: 0.06750106811523438
Test Loss Energy: 6.544680860648605, Test Loss Force: 8.47153280736938, time: 10.035821914672852


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9802929970203427, Training Loss Force: 4.455932552773562, time: 0.7078561782836914
Validation Loss Energy: 2.114458304975593, Validation Loss Force: 4.786077788207675, time: 0.06669306755065918
Test Loss Energy: 6.279378619675884, Test Loss Force: 8.482280331237789, time: 10.075944423675537


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9750619395204585, Training Loss Force: 4.456849431819561, time: 0.6909825801849365
Validation Loss Energy: 3.30164502011424, Validation Loss Force: 4.952180509642259, time: 0.06877803802490234
Test Loss Energy: 8.052344912913568, Test Loss Force: 8.468416828968392, time: 10.199894905090332


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9498179462141536, Training Loss Force: 4.457825302654174, time: 0.703188419342041
Validation Loss Energy: 4.130182215947908, Validation Loss Force: 4.94178030184341, time: 0.0679481029510498
Test Loss Energy: 8.672890137785506, Test Loss Force: 8.477788383422126, time: 10.05558156967163


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.037784127638943, Training Loss Force: 4.438569423819676, time: 0.7365071773529053
Validation Loss Energy: 2.9591442466139544, Validation Loss Force: 4.705276499209983, time: 0.0657951831817627
Test Loss Energy: 7.742077114094897, Test Loss Force: 8.460228937062128, time: 10.065122842788696


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0013304879398754, Training Loss Force: 4.454680116503001, time: 0.7050118446350098
Validation Loss Energy: 2.5338767948994443, Validation Loss Force: 4.7589773944642415, time: 0.06786370277404785
Test Loss Energy: 6.402906725278612, Test Loss Force: 8.447409941947875, time: 10.205940961837769


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0177783923313, Training Loss Force: 4.441893465078551, time: 0.7138614654541016
Validation Loss Energy: 3.5836952398743316, Validation Loss Force: 4.906206901759132, time: 0.07064557075500488
Test Loss Energy: 6.6171939960024, Test Loss Force: 8.44438044777684, time: 10.018763065338135


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0370824091281365, Training Loss Force: 4.446243669328907, time: 0.7110617160797119
Validation Loss Energy: 2.1650671051349253, Validation Loss Force: 4.838776672305259, time: 0.07082176208496094
Test Loss Energy: 6.395064739981185, Test Loss Force: 8.467690097498052, time: 10.04323410987854


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9572205871488753, Training Loss Force: 4.454372263462876, time: 0.7103457450866699
Validation Loss Energy: 3.148153277093849, Validation Loss Force: 4.6371936264893945, time: 0.06947135925292969
Test Loss Energy: 7.964353177865892, Test Loss Force: 8.467111600725316, time: 10.21638560295105

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–„â–ƒâ–‚â–â–ƒâ–†â–ˆâ–…â–‚â–‚â–â–†â–ˆâ–…â–‚â–‚â–‚â–†
wandb:   test_error_force â–„â–ˆâ–…â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:          test_loss â–‡â–…â–‚â–ˆâ–ƒâ–‚â–„â–ƒâ–…â–‚â–â–‚â–â–ƒâ–„â–ƒâ–â–â–â–ƒ
wandb: train_error_energy â–†â–ƒâ–ˆâ–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–†â–…â–†â–ˆâ–‡â–„â–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–…â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–†â–‚â–ˆâ–‚â–â–â–…â–†â–ƒâ–ƒâ–…â–‚â–„â–†â–„â–ƒâ–…â–‚â–„
wandb:  valid_error_force â–ƒâ–ˆâ–†â–‡â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–
wandb:         valid_loss â–‚â–…â–‚â–ˆâ–â–â–â–ƒâ–„â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1365
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.96435
wandb:   test_error_force 8.46711
wandb:          test_loss 5.7021
wandb: train_error_energy 2.95722
wandb:  train_error_force 4.45437
wandb:         train_loss 1.4311
wandb: valid_error_energy 3.14815
wandb:  valid_error_force 4.63719
wandb:         valid_loss 1.53285
wandb: 
wandb: ğŸš€ View run al_73_69 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/pq9kd031
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_102602-pq9kd031/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8011106252670288, Uncertainty Bias: 0.03582221269607544
5.4359436e-05 0.0730896
2.9078524 10.732944
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1491 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2135 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3080 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2207 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_110849-hh7szo30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_70
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hh7szo30
Training model 70. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.894068923212915, Training Loss Force: 4.819235751072211, time: 0.7042596340179443
Validation Loss Energy: 2.0722023811528762, Validation Loss Force: 4.739046947219683, time: 0.06664800643920898
Test Loss Energy: 6.3288183537748735, Test Loss Force: 8.533829119870202, time: 10.33438491821289


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0865954377038047, Training Loss Force: 4.525224953938126, time: 0.7220091819763184
Validation Loss Energy: 2.160908758834724, Validation Loss Force: 4.770141580102769, time: 0.0697319507598877
Test Loss Energy: 6.938845802704717, Test Loss Force: 8.524755820828076, time: 10.383668899536133


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0988818525352224, Training Loss Force: 4.485812038700502, time: 0.7006113529205322
Validation Loss Energy: 2.349642792919398, Validation Loss Force: 4.674059398296636, time: 0.06737589836120605
Test Loss Energy: 7.092232777560338, Test Loss Force: 8.481424386377615, time: 10.51468014717102


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1091553952493287, Training Loss Force: 4.4782429551683745, time: 0.6794557571411133
Validation Loss Energy: 2.287469225328014, Validation Loss Force: 4.863915350873068, time: 0.06757688522338867
Test Loss Energy: 6.32597832190185, Test Loss Force: 8.543235937655487, time: 10.359473466873169


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0618266928518403, Training Loss Force: 4.477157717534646, time: 0.6872444152832031
Validation Loss Energy: 1.9539121807430635, Validation Loss Force: 4.784765598930722, time: 0.0671231746673584
Test Loss Energy: 6.438064562948815, Test Loss Force: 8.517325101945756, time: 10.315587997436523


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.104992844127115, Training Loss Force: 4.482178761781454, time: 0.7033147811889648
Validation Loss Energy: 2.2591615194753603, Validation Loss Force: 4.6463201667735365, time: 0.06832623481750488
Test Loss Energy: 7.4638174920482445, Test Loss Force: 8.494804773543615, time: 10.54499888420105


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.086454213681764, Training Loss Force: 4.534900819005271, time: 0.6915683746337891
Validation Loss Energy: 2.6075567906066466, Validation Loss Force: 4.853601761371985, time: 0.07437515258789062
Test Loss Energy: 7.316881799605922, Test Loss Force: 8.570368287335876, time: 10.421141862869263


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.08256819951456, Training Loss Force: 4.537058027334315, time: 0.7002251148223877
Validation Loss Energy: 2.4246971025952666, Validation Loss Force: 4.988507644785503, time: 0.06633663177490234
Test Loss Energy: 6.382414544400844, Test Loss Force: 8.53308491994707, time: 10.540187358856201


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.084677867980949, Training Loss Force: 4.483825063522695, time: 0.7124700546264648
Validation Loss Energy: 2.077980311485984, Validation Loss Force: 4.6850835250423755, time: 0.06676912307739258
Test Loss Energy: 6.527056229353394, Test Loss Force: 8.548199114005897, time: 10.327441930770874


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.08616236951756, Training Loss Force: 4.4806818244319615, time: 0.7023649215698242
Validation Loss Energy: 2.10039363104221, Validation Loss Force: 4.760852491342099, time: 0.06647300720214844
Test Loss Energy: 7.278326175328935, Test Loss Force: 8.546916371849138, time: 10.365156888961792


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0721519698939095, Training Loss Force: 4.476068067944815, time: 0.7146689891815186
Validation Loss Energy: 2.169504567209547, Validation Loss Force: 4.627135661167836, time: 0.0673530101776123
Test Loss Energy: 7.154160016534682, Test Loss Force: 8.476252339373481, time: 10.515311002731323


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0824341682237684, Training Loss Force: 4.4771649465143595, time: 0.7152009010314941
Validation Loss Energy: 2.0339759895294427, Validation Loss Force: 4.788715972248628, time: 0.06640982627868652
Test Loss Energy: 6.414065412971106, Test Loss Force: 8.484655056875864, time: 10.358235120773315


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0709419287930624, Training Loss Force: 4.479050747046279, time: 0.7014224529266357
Validation Loss Energy: 1.9998319026928755, Validation Loss Force: 4.657088224001459, time: 0.06818270683288574
Test Loss Energy: 6.537985369638386, Test Loss Force: 8.511344600397305, time: 11.345103025436401


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1198427892845504, Training Loss Force: 4.490882194439868, time: 0.6850783824920654
Validation Loss Energy: 2.234222463796875, Validation Loss Force: 4.821137935910588, time: 0.07148146629333496
Test Loss Energy: 7.303771079931136, Test Loss Force: 8.53070509273736, time: 10.560513019561768


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.114121476465559, Training Loss Force: 4.491349633939046, time: 0.7212796211242676
Validation Loss Energy: 2.4594311513339693, Validation Loss Force: 4.604442557829752, time: 0.06777644157409668
Test Loss Energy: 7.74390346508271, Test Loss Force: 8.544195476129833, time: 10.386550903320312


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0097127787248423, Training Loss Force: 4.48263851660592, time: 0.7339687347412109
Validation Loss Energy: 2.0180455708223306, Validation Loss Force: 4.764112367638482, time: 0.06998276710510254
Test Loss Energy: 6.344082300412083, Test Loss Force: 8.490054855944647, time: 10.490921020507812


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.10849494302745, Training Loss Force: 4.501107720882913, time: 0.744086742401123
Validation Loss Energy: 1.8086948788526351, Validation Loss Force: 4.68087129280886, time: 0.06817483901977539
Test Loss Energy: 6.463420022171158, Test Loss Force: 8.529690635424654, time: 10.429487466812134


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.047306885773357, Training Loss Force: 4.514663373148705, time: 0.7585968971252441
Validation Loss Energy: 2.1904931382355546, Validation Loss Force: 4.744678472589343, time: 0.06818056106567383
Test Loss Energy: 7.7558229211480825, Test Loss Force: 8.633027883965372, time: 10.351947784423828


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.026378958430326, Training Loss Force: 4.507356107105371, time: 0.703632116317749
Validation Loss Energy: 2.5181973243197935, Validation Loss Force: 4.8688414603884285, time: 0.06701540946960449
Test Loss Energy: 7.577022649050918, Test Loss Force: 8.499933205374516, time: 10.580777883529663


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.035085324625279, Training Loss Force: 4.495396288359979, time: 0.6936383247375488
Validation Loss Energy: 2.044307615231346, Validation Loss Force: 4.678380515742512, time: 0.06661438941955566
Test Loss Energy: 6.912095993953803, Test Loss Force: 8.507585782001058, time: 10.35822057723999

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–…â–â–‚â–‡â–†â–â–‚â–†â–…â–â–‚â–†â–ˆâ–â–‚â–ˆâ–‡â–„
wandb:   test_error_force â–„â–ƒâ–â–„â–ƒâ–‚â–…â–„â–„â–„â–â–â–ƒâ–ƒâ–„â–‚â–ƒâ–ˆâ–‚â–‚
wandb:          test_loss â–â–ƒâ–„â–ƒâ–ƒâ–…â–„â–ƒâ–ƒâ–…â–†â–ƒâ–ƒâ–…â–†â–„â–„â–ˆâ–‡â–…
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ƒâ–„â–†â–…â–‚â–…â–ˆâ–†â–ƒâ–„â–„â–ƒâ–ƒâ–…â–‡â–ƒâ–â–„â–‡â–ƒ
wandb:  valid_error_force â–ƒâ–„â–‚â–†â–„â–‚â–†â–ˆâ–‚â–„â–â–„â–‚â–…â–â–„â–‚â–„â–†â–‚
wandb:         valid_loss â–„â–„â–„â–…â–ƒâ–„â–ˆâ–‡â–„â–„â–„â–†â–ƒâ–†â–…â–ƒâ–â–ƒâ–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1368
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.9121
wandb:   test_error_force 8.50759
wandb:          test_loss 6.63758
wandb: train_error_energy 2.03509
wandb:  train_error_force 4.4954
wandb:         train_loss 1.08411
wandb: valid_error_energy 2.04431
wandb:  valid_error_force 4.67838
wandb:         valid_loss 1.26498
wandb: 
wandb: ğŸš€ View run al_73_70 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/hh7szo30
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_110849-hh7szo30/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9860152006149292, Uncertainty Bias: 0.09740863740444183
5.340576e-05 0.004425049
3.168152 9.952263
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3834 steps.
Found uncertainty sample 20 after 1150 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_115206-q0pv9t0k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_71
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q0pv9t0k
Training model 71. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.873146105043492, Training Loss Force: 5.7692731327775055, time: 0.713139533996582
Validation Loss Energy: 5.075581300954834, Validation Loss Force: 5.135716889188114, time: 0.06636428833007812
Test Loss Energy: 9.066359281895453, Test Loss Force: 8.65502012975471, time: 10.099016904830933


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.178825812129891, Training Loss Force: 4.987599165026822, time: 0.7163937091827393
Validation Loss Energy: 5.025931425472439, Validation Loss Force: 5.4978724455303, time: 0.06732726097106934
Test Loss Energy: 6.831201575625989, Test Loss Force: 8.765026610667727, time: 10.103359460830688


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.441801267106256, Training Loss Force: 4.862262327630631, time: 0.6993048191070557
Validation Loss Energy: 6.667746077900198, Validation Loss Force: 4.88548219367105, time: 0.06683468818664551
Test Loss Energy: 11.270812752585, Test Loss Force: 8.564461669974818, time: 10.314598083496094


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.484442859068071, Training Loss Force: 4.5456619527762605, time: 0.6817448139190674
Validation Loss Energy: 3.5825973696503346, Validation Loss Force: 4.957210828317914, time: 0.06679558753967285
Test Loss Energy: 6.508120111762881, Test Loss Force: 8.412762240456798, time: 10.119377374649048


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.428826835684035, Training Loss Force: 4.530110542847279, time: 0.7452213764190674
Validation Loss Energy: 1.8433105789402773, Validation Loss Force: 4.679924503600375, time: 0.06646370887756348
Test Loss Energy: 6.5215713869921625, Test Loss Force: 8.4319539425894, time: 10.137308835983276


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.327831262395621, Training Loss Force: 4.496114857228945, time: 0.7129402160644531
Validation Loss Energy: 5.758552996021129, Validation Loss Force: 4.709696927094942, time: 0.06664538383483887
Test Loss Energy: 9.993617524407522, Test Loss Force: 8.491377324142332, time: 10.280147790908813


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.392245505586483, Training Loss Force: 4.503750244383036, time: 0.7211029529571533
Validation Loss Energy: 5.579781068190691, Validation Loss Force: 4.827887483061952, time: 0.0656285285949707
Test Loss Energy: 7.2052666821710725, Test Loss Force: 8.45825302002506, time: 10.097391366958618


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.469921457057102, Training Loss Force: 4.488929209966106, time: 0.7233006954193115
Validation Loss Energy: 4.19329333197822, Validation Loss Force: 4.806462480509927, time: 0.06704425811767578
Test Loss Energy: 8.771271456632416, Test Loss Force: 8.48406783520319, time: 10.181187629699707


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.531070987370596, Training Loss Force: 4.503028558146028, time: 0.8642704486846924
Validation Loss Energy: 2.9296637423696987, Validation Loss Force: 4.930462697163339, time: 0.0980978012084961
Test Loss Energy: 7.7026121276788535, Test Loss Force: 8.479142221155826, time: 10.164522886276245


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.3879080038341485, Training Loss Force: 4.491145420440469, time: 0.7191691398620605
Validation Loss Energy: 4.979367744352604, Validation Loss Force: 4.7274997706501605, time: 0.0677943229675293
Test Loss Energy: 6.9380217776414845, Test Loss Force: 8.39905098792448, time: 10.075055599212646


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.425791259714532, Training Loss Force: 4.485990640068944, time: 0.6831839084625244
Validation Loss Energy: 6.382893455604032, Validation Loss Force: 4.807468499711228, time: 0.06731152534484863
Test Loss Energy: 10.456021422094869, Test Loss Force: 8.505737087155387, time: 10.251792907714844


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.494704760846363, Training Loss Force: 4.476240838488646, time: 0.7366917133331299
Validation Loss Energy: 3.7839555196288117, Validation Loss Force: 4.791141061916927, time: 0.06580471992492676
Test Loss Energy: 6.451723053385814, Test Loss Force: 8.33675341635205, time: 10.141994714736938


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.501139122410841, Training Loss Force: 4.483277054041158, time: 0.7113232612609863
Validation Loss Energy: 1.8235727961742327, Validation Loss Force: 4.805914046403506, time: 0.0684959888458252
Test Loss Energy: 6.311372121268798, Test Loss Force: 8.456289651735046, time: 10.139141321182251


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.494937817766865, Training Loss Force: 4.488272491336186, time: 0.7075817584991455
Validation Loss Energy: 5.011013483371862, Validation Loss Force: 5.020086805730127, time: 0.07199645042419434
Test Loss Energy: 9.47506751996799, Test Loss Force: 8.477066487719416, time: 10.308303356170654


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4189520390375865, Training Loss Force: 4.470305576868884, time: 0.7193799018859863
Validation Loss Energy: 5.935530878542826, Validation Loss Force: 4.954729626024841, time: 0.07529330253601074
Test Loss Energy: 7.298984672571605, Test Loss Force: 8.418069800872045, time: 10.176396369934082


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.447536408714881, Training Loss Force: 4.4965888007385235, time: 0.70574951171875
Validation Loss Energy: 3.98954638740223, Validation Loss Force: 5.000255668924653, time: 0.06746482849121094
Test Loss Energy: 8.817456558235119, Test Loss Force: 8.487292284955037, time: 10.142551898956299


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.451548021226268, Training Loss Force: 4.491880601463391, time: 0.7028179168701172
Validation Loss Energy: 3.0144472463731633, Validation Loss Force: 4.8266737135475, time: 0.0675511360168457
Test Loss Energy: 7.890266708959255, Test Loss Force: 8.539391856795067, time: 11.266485929489136


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.404677771297659, Training Loss Force: 4.478189473146535, time: 0.7281029224395752
Validation Loss Energy: 5.411871609306049, Validation Loss Force: 4.707136677255064, time: 0.06920433044433594
Test Loss Energy: 7.071191301044742, Test Loss Force: 8.378931186801967, time: 10.136061429977417


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.440366208476745, Training Loss Force: 4.489501645735116, time: 0.7177929878234863
Validation Loss Energy: 6.293862760311141, Validation Loss Force: 4.68248653479342, time: 0.06594634056091309
Test Loss Energy: 10.31192618821095, Test Loss Force: 8.49343443730859, time: 10.123732089996338


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.397510206840811, Training Loss Force: 4.472331332726546, time: 0.68625807762146
Validation Loss Energy: 3.3097115439291933, Validation Loss Force: 4.7632152336495395, time: 0.06946277618408203
Test Loss Energy: 6.663130214121923, Test Loss Force: 8.399723532683288, time: 10.304579734802246

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–ˆâ–â–â–†â–‚â–„â–ƒâ–‚â–‡â–â–â–…â–‚â–…â–ƒâ–‚â–‡â–
wandb:   test_error_force â–†â–ˆâ–…â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–„â–â–ƒâ–ƒâ–‚â–ƒâ–„â–‚â–„â–‚
wandb:          test_loss â–…â–ˆâ–ˆâ–‚â–‚â–…â–‚â–„â–ƒâ–‚â–…â–â–â–„â–‚â–„â–ƒâ–‚â–…â–
wandb: train_error_energy â–ˆâ–â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:  train_error_force â–ˆâ–„â–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–†â–ˆâ–„â–â–‡â–†â–„â–ƒâ–†â–ˆâ–„â–â–†â–‡â–„â–ƒâ–†â–‡â–ƒ
wandb:  valid_error_force â–…â–ˆâ–ƒâ–ƒâ–â–â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–„â–ƒâ–„â–‚â–â–â–‚
wandb:         valid_loss â–„â–ˆâ–†â–‚â–â–„â–„â–ƒâ–‚â–ƒâ–…â–‚â–â–„â–…â–ƒâ–‚â–„â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1369
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.66313
wandb:   test_error_force 8.39972
wandb:          test_loss 4.34926
wandb: train_error_energy 4.39751
wandb:  train_error_force 4.47233
wandb:         train_loss 1.83962
wandb: valid_error_energy 3.30971
wandb:  valid_error_force 4.76322
wandb:         valid_loss 1.66589
wandb: 
wandb: ğŸš€ View run al_73_71 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q0pv9t0k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_115206-q0pv9t0k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.530537724494934, Uncertainty Bias: 0.018187791109085083
0.0002670288 0.07133484
3.1684504 12.701383
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 72.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3958 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3795 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2899 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 350 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_131152-faep0z38
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_73
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/faep0z38
Training model 73. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.213965199933958, Training Loss Force: 4.817543237715663, time: 0.7324349880218506
Validation Loss Energy: 2.2230282178236473, Validation Loss Force: 4.731276016695949, time: 0.0703270435333252
Test Loss Energy: 7.274299634007632, Test Loss Force: 8.483322096414758, time: 10.130545377731323


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.436471828681514, Training Loss Force: 4.517132349352162, time: 0.7455651760101318
Validation Loss Energy: 5.6422840747834755, Validation Loss Force: 4.756715298610761, time: 0.06868982315063477
Test Loss Energy: 7.043319090575048, Test Loss Force: 8.333085973912127, time: 10.196048021316528


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.406423507758437, Training Loss Force: 4.478275951628791, time: 0.688225269317627
Validation Loss Energy: 6.2912777941960645, Validation Loss Force: 4.854269768809768, time: 0.0734250545501709
Test Loss Energy: 10.031870540149386, Test Loss Force: 8.410236850579233, time: 11.319191217422485


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.388339500390492, Training Loss Force: 4.493796374298022, time: 0.6877832412719727
Validation Loss Energy: 3.676520440082978, Validation Loss Force: 4.984251324061093, time: 0.0706338882446289
Test Loss Energy: 6.560889365139613, Test Loss Force: 8.369900752153338, time: 10.198485851287842


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.475221863050063, Training Loss Force: 4.488509545944611, time: 0.7203516960144043
Validation Loss Energy: 2.271446287590769, Validation Loss Force: 4.6969477824757, time: 0.06910252571105957
Test Loss Energy: 6.35354587901086, Test Loss Force: 8.398264888896088, time: 10.159512281417847


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.471421786227305, Training Loss Force: 4.471317592602068, time: 0.6892476081848145
Validation Loss Energy: 5.983516747497703, Validation Loss Force: 4.712458247173592, time: 0.06643247604370117
Test Loss Energy: 10.38765694401891, Test Loss Force: 8.425357465903273, time: 10.435762166976929


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.344938446112142, Training Loss Force: 4.479482321277904, time: 0.7257184982299805
Validation Loss Energy: 6.158216724656559, Validation Loss Force: 4.873533989969711, time: 0.06842899322509766
Test Loss Energy: 7.244767102126494, Test Loss Force: 8.316230684334815, time: 10.228169202804565


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.527880951510752, Training Loss Force: 4.482032628681499, time: 0.6805267333984375
Validation Loss Energy: 4.03610761916146, Validation Loss Force: 4.7272786601882535, time: 0.06725621223449707
Test Loss Energy: 8.668028671105079, Test Loss Force: 8.431762260594775, time: 10.393117427825928


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.49933451326355, Training Loss Force: 4.479585049429461, time: 0.6615021228790283
Validation Loss Energy: 2.6444561854549242, Validation Loss Force: 4.6892795024282385, time: 0.0686490535736084
Test Loss Energy: 7.281346946931646, Test Loss Force: 8.43484794666546, time: 10.201875925064087


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.474228774194281, Training Loss Force: 4.484018775322949, time: 0.7087366580963135
Validation Loss Energy: 4.857030420880982, Validation Loss Force: 4.857992574260535, time: 0.07318615913391113
Test Loss Energy: 6.851250316145774, Test Loss Force: 8.370113819712428, time: 10.216248989105225


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.455751595254853, Training Loss Force: 4.476137789279251, time: 0.7157459259033203
Validation Loss Energy: 6.0092501753542855, Validation Loss Force: 4.64848696023256, time: 0.07231521606445312
Test Loss Energy: 10.112619493737135, Test Loss Force: 8.496640122230215, time: 10.36862587928772


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.43032398534597, Training Loss Force: 4.527075054909764, time: 0.7006950378417969
Validation Loss Energy: 3.6620252353559444, Validation Loss Force: 4.982831808255803, time: 0.06787252426147461
Test Loss Energy: 6.375627068883022, Test Loss Force: 8.409496264657948, time: 10.199610471725464


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.103253347354594, Training Loss Force: 4.733107718982112, time: 0.7268469333648682
Validation Loss Energy: 2.4459681294328837, Validation Loss Force: 5.112490715914679, time: 0.06822896003723145
Test Loss Energy: 7.187756358256794, Test Loss Force: 8.755689316951482, time: 10.21116018295288


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.736151501458403, Training Loss Force: 5.570129033900512, time: 0.7271263599395752
Validation Loss Energy: 7.404898297561079, Validation Loss Force: 5.947417180221597, time: 0.07491922378540039
Test Loss Energy: 7.838643754014146, Test Loss Force: 8.975551689149674, time: 10.401346683502197


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.521826811866504, Training Loss Force: 5.807410692357596, time: 0.6958775520324707
Validation Loss Energy: 5.275046763192925, Validation Loss Force: 5.392589797283578, time: 0.06722569465637207
Test Loss Energy: 6.878565114628981, Test Loss Force: 8.743157082391358, time: 10.279477596282959


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.085509471103907, Training Loss Force: 4.719957158854637, time: 0.7058005332946777
Validation Loss Energy: 2.1359522236282835, Validation Loss Force: 4.865699376070241, time: 0.06901669502258301
Test Loss Energy: 6.211825781129098, Test Loss Force: 8.330657630476358, time: 10.19782304763794


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9251743543680817, Training Loss Force: 4.444167885410341, time: 0.7019827365875244
Validation Loss Energy: 3.051090683038197, Validation Loss Force: 4.7422224319097595, time: 0.0664072036743164
Test Loss Energy: 7.677232494281588, Test Loss Force: 8.491177831240494, time: 10.396710395812988


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9466398697587857, Training Loss Force: 4.449197955525088, time: 0.7038946151733398
Validation Loss Energy: 4.13161420122537, Validation Loss Force: 4.754682329308441, time: 0.07046270370483398
Test Loss Energy: 8.459768009598443, Test Loss Force: 8.413675626961782, time: 10.213963985443115


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0469690926821302, Training Loss Force: 4.430044442357491, time: 0.690047025680542
Validation Loss Energy: 2.5769637199747635, Validation Loss Force: 4.474695250519943, time: 0.0675656795501709
Test Loss Energy: 7.640281773612272, Test Loss Force: 8.384134160335437, time: 10.371164083480835


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.933339196967666, Training Loss Force: 4.4249363551880325, time: 0.7790958881378174
Validation Loss Energy: 2.4222773569864695, Validation Loss Force: 4.9086673958216345, time: 0.06741929054260254
Test Loss Energy: 6.496827379576151, Test Loss Force: 8.352415894128187, time: 10.262624263763428

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‡â–‚â–â–ˆâ–ƒâ–…â–ƒâ–‚â–ˆâ–â–ƒâ–„â–‚â–â–ƒâ–…â–ƒâ–
wandb:   test_error_force â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–†â–ˆâ–†â–â–ƒâ–‚â–‚â–
wandb:          test_loss â–‚â–‚â–…â–â–â–…â–‚â–„â–‚â–â–…â–â–…â–…â–ˆâ–ƒâ–…â–‡â–…â–ƒ
wandb: train_error_energy â–ˆâ–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–„â–ƒâ–‚â–â–â–â–â–
wandb:  train_error_force â–ƒâ–â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–‡â–ˆâ–‚â–â–â–â–
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–„â–„â–ƒâ–„â–„â–„â–„â–„â–„â–†â–…â–‚â–â–â–â–
wandb: valid_error_energy â–â–†â–‡â–ƒâ–â–†â–†â–„â–‚â–…â–†â–ƒâ–â–ˆâ–…â–â–‚â–„â–‚â–
wandb:  valid_error_force â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–„â–ˆâ–…â–ƒâ–‚â–‚â–â–ƒ
wandb:         valid_loss â–â–„â–„â–‚â–â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ˆâ–‡â–â–‚â–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1372
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.49683
wandb:   test_error_force 8.35242
wandb:          test_loss 5.02404
wandb: train_error_energy 2.93334
wandb:  train_error_force 4.42494
wandb:         train_loss 1.41074
wandb: valid_error_energy 2.42228
wandb:  valid_error_force 4.90867
wandb:         valid_loss 1.44884
wandb: 
wandb: ğŸš€ View run al_73_73 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/faep0z38
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_131152-faep0z38/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9038900136947632, Uncertainty Bias: 0.03251364827156067
0.00016403198 0.011706591
3.024569 10.412127
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1957 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2031 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_135513-d2ykr5tr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_74
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/d2ykr5tr
Training model 74. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.339141394713423, Training Loss Force: 5.11217635886415, time: 0.732527494430542
Validation Loss Energy: 2.561593091500514, Validation Loss Force: 5.224595501454337, time: 0.07002735137939453
Test Loss Energy: 7.107874060964364, Test Loss Force: 8.679957045594362, time: 9.05624794960022


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.13053252888715, Training Loss Force: 4.732327600218531, time: 0.6795594692230225
Validation Loss Energy: 4.441701695160385, Validation Loss Force: 4.861820034209888, time: 0.06703472137451172
Test Loss Energy: 8.961632652495798, Test Loss Force: 8.379462379787974, time: 9.7821683883667


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.419829389131832, Training Loss Force: 4.492866880785988, time: 0.6970760822296143
Validation Loss Energy: 5.650167453225903, Validation Loss Force: 4.782774714096982, time: 0.0663001537322998
Test Loss Energy: 6.994700485674587, Test Loss Force: 8.32902482910606, time: 9.342161417007446


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.465358878225053, Training Loss Force: 4.456679633649911, time: 0.7003138065338135
Validation Loss Energy: 3.8730958794760726, Validation Loss Force: 4.722312470226626, time: 0.06490635871887207
Test Loss Energy: 8.472068570319012, Test Loss Force: 8.426557855450252, time: 10.08217716217041


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.399768522497163, Training Loss Force: 4.4802879796746895, time: 0.7120566368103027
Validation Loss Energy: 2.479652070479391, Validation Loss Force: 4.74176417880744, time: 0.07834577560424805
Test Loss Energy: 7.078227417557877, Test Loss Force: 8.318288366414913, time: 10.77893328666687


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.316179164642371, Training Loss Force: 4.474444903081341, time: 0.7085001468658447
Validation Loss Energy: 4.945121452378057, Validation Loss Force: 4.600322955960942, time: 0.07395148277282715
Test Loss Energy: 6.814295501162109, Test Loss Force: 8.302621808314113, time: 11.142910242080688


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.397553539292279, Training Loss Force: 4.459213908874997, time: 0.7290441989898682
Validation Loss Energy: 5.968711921323257, Validation Loss Force: 4.7914617054870625, time: 0.07064270973205566
Test Loss Energy: 9.926571891200947, Test Loss Force: 8.44076667443012, time: 10.435922384262085


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.492040949140221, Training Loss Force: 4.449254042258101, time: 0.6976561546325684
Validation Loss Energy: 3.4161801280471273, Validation Loss Force: 4.47932298337976, time: 0.06582951545715332
Test Loss Energy: 6.340193872251607, Test Loss Force: 8.356569576034396, time: 10.7120840549469


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.5009918707868035, Training Loss Force: 4.453061798577216, time: 0.7948529720306396
Validation Loss Energy: 2.0768055090720687, Validation Loss Force: 4.771548181097595, time: 0.09391164779663086
Test Loss Energy: 6.195348994125652, Test Loss Force: 8.324858822287757, time: 9.237163782119751


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.415716242079077, Training Loss Force: 4.454289668744792, time: 0.6872828006744385
Validation Loss Energy: 5.609948061411842, Validation Loss Force: 4.68432867663768, time: 0.06693005561828613
Test Loss Energy: 9.8300220598877, Test Loss Force: 8.371787620184945, time: 9.498746633529663


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.324067392611664, Training Loss Force: 4.438641941464317, time: 0.6906824111938477
Validation Loss Energy: 5.502890740072075, Validation Loss Force: 4.792845816898151, time: 0.06786036491394043
Test Loss Energy: 7.218240715632859, Test Loss Force: 8.400104406508687, time: 9.341448068618774


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.481698195159372, Training Loss Force: 4.4631825048144025, time: 0.7620217800140381
Validation Loss Energy: 4.165536064254301, Validation Loss Force: 4.6304247071223354, time: 0.09565901756286621
Test Loss Energy: 8.498585912481579, Test Loss Force: 8.399216000917104, time: 9.483718156814575


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.516891196077946, Training Loss Force: 4.45471312332012, time: 0.7093796730041504
Validation Loss Energy: 2.9466686510404854, Validation Loss Force: 4.649101749744467, time: 0.07594108581542969
Test Loss Energy: 7.636603890204437, Test Loss Force: 8.346094753087135, time: 10.639593124389648


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.501047936806407, Training Loss Force: 4.45276051686607, time: 0.7045693397521973
Validation Loss Energy: 4.945650068930489, Validation Loss Force: 4.584716966199446, time: 0.07134366035461426
Test Loss Energy: 6.864760445978005, Test Loss Force: 8.296129214362308, time: 11.110276460647583


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4535326091836955, Training Loss Force: 4.451438778707604, time: 0.6867434978485107
Validation Loss Energy: 6.432156109441658, Validation Loss Force: 4.665268643084554, time: 0.07236051559448242
Test Loss Energy: 10.498207399826395, Test Loss Force: 8.430943957312524, time: 10.731959104537964


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.322185967787379, Training Loss Force: 4.469722763682002, time: 0.7178478240966797
Validation Loss Energy: 3.3207498101656983, Validation Loss Force: 4.735572863204918, time: 0.06852221488952637
Test Loss Energy: 6.473022138284529, Test Loss Force: 8.371966501618198, time: 9.716639995574951


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.456357452109161, Training Loss Force: 4.451828791484225, time: 0.7002687454223633
Validation Loss Energy: 2.4397918439977113, Validation Loss Force: 4.841754872132043, time: 0.071929931640625
Test Loss Energy: 6.5013551199997615, Test Loss Force: 8.366502648447037, time: 9.501651763916016


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.5242652758109365, Training Loss Force: 4.444039141217178, time: 0.7276821136474609
Validation Loss Energy: 5.709335321350981, Validation Loss Force: 4.827003931890911, time: 0.07234764099121094
Test Loss Energy: 9.78521870543939, Test Loss Force: 8.412047959805715, time: 9.162873983383179


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4944803724874935, Training Loss Force: 4.455802037583934, time: 0.713592529296875
Validation Loss Energy: 5.768619422770232, Validation Loss Force: 4.579363331923905, time: 0.06698131561279297
Test Loss Energy: 7.203510601368809, Test Loss Force: 8.33451001654618, time: 9.7050940990448


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.4148321678944615, Training Loss Force: 4.448322047601939, time: 0.685868501663208
Validation Loss Energy: 4.523357588340147, Validation Loss Force: 4.922014184428546, time: 0.06642937660217285
Test Loss Energy: 9.060106401188602, Test Loss Force: 8.470016358205577, time: 9.245184659957886

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‚â–…â–‚â–‚â–‡â–â–â–‡â–ƒâ–…â–ƒâ–‚â–ˆâ–â–â–‡â–ƒâ–†
wandb:   test_error_force â–ˆâ–ƒâ–‚â–ƒâ–â–â–„â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–„
wandb:          test_loss â–ˆâ–‡â–‚â–„â–‚â–‚â–…â–â–â–…â–‚â–„â–‚â–â–…â–â–â–…â–‚â–„
wandb: train_error_energy â–…â–â–†â–‡â–†â–„â–†â–‡â–ˆâ–†â–„â–‡â–ˆâ–ˆâ–‡â–„â–‡â–ˆâ–‡â–†
wandb:  train_error_force â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–…â–‡â–„â–‚â–†â–‡â–ƒâ–â–‡â–‡â–„â–‚â–†â–ˆâ–ƒâ–‚â–‡â–‡â–…
wandb:  valid_error_force â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–„â–â–„â–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–‚â–…
wandb:         valid_loss â–‚â–†â–ˆâ–ƒâ–â–…â–‡â–‚â–â–†â–‡â–ƒâ–‚â–…â–‡â–‚â–â–†â–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1373
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.06011
wandb:   test_error_force 8.47002
wandb:          test_loss 5.22334
wandb: train_error_energy 4.41483
wandb:  train_error_force 4.44832
wandb:         train_loss 1.83073
wandb: valid_error_energy 4.52336
wandb:  valid_error_force 4.92201
wandb:         valid_loss 1.97197
wandb: 
wandb: ğŸš€ View run al_73_74 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/d2ykr5tr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_135513-d2ykr5tr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.7440475225448608, Uncertainty Bias: -0.040218204259872437
0.00011444092 0.047372818
3.0047977 10.564668
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3311 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 897 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_143826-yxxoekts
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_75
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yxxoekts
Training model 75. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.18995239611901, Training Loss Force: 4.8087946601825, time: 0.6835603713989258
Validation Loss Energy: 2.316597355648839, Validation Loss Force: 4.755067546930896, time: 0.06258583068847656
Test Loss Energy: 6.2360076363871695, Test Loss Force: 8.377716905498222, time: 9.077012062072754


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.419517535814608, Training Loss Force: 4.511787927365238, time: 0.7341725826263428
Validation Loss Energy: 5.858551705434985, Validation Loss Force: 4.727156637496286, time: 0.06597471237182617
Test Loss Energy: 10.11635282759134, Test Loss Force: 8.386027692120127, time: 9.067898750305176


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.40147955364129, Training Loss Force: 4.452838621952769, time: 0.7028956413269043
Validation Loss Energy: 5.83436916817979, Validation Loss Force: 4.640352410993526, time: 0.06324982643127441
Test Loss Energy: 7.099321446323526, Test Loss Force: 8.302976027127194, time: 9.217797994613647


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.505851187325915, Training Loss Force: 4.462494912848483, time: 0.6908152103424072
Validation Loss Energy: 3.524808268876842, Validation Loss Force: 4.767855435981529, time: 0.06558418273925781
Test Loss Energy: 7.637282371252726, Test Loss Force: 8.293222885374147, time: 9.060934782028198


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.48068265814667, Training Loss Force: 4.442617466039007, time: 0.7223410606384277
Validation Loss Energy: 2.657815443534008, Validation Loss Force: 4.906802096386198, time: 0.06293487548828125
Test Loss Energy: 7.427492411057018, Test Loss Force: 8.309863717750368, time: 9.068851232528687


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.487709925506528, Training Loss Force: 4.446037508769892, time: 0.7458157539367676
Validation Loss Energy: 4.823809742992577, Validation Loss Force: 4.656961747926571, time: 0.06863617897033691
Test Loss Energy: 6.898474960897216, Test Loss Force: 8.368337549463728, time: 9.27117371559143


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.415012711144991, Training Loss Force: 4.451657512305837, time: 0.7400050163269043
Validation Loss Energy: 6.162945549308628, Validation Loss Force: 4.651582506699248, time: 0.06850552558898926
Test Loss Energy: 10.329846297965391, Test Loss Force: 8.386980044559836, time: 9.060863733291626


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.535838230217866, Training Loss Force: 4.448933616178759, time: 0.7150866985321045
Validation Loss Energy: 3.761414387982823, Validation Loss Force: 4.770600946550818, time: 0.06286001205444336
Test Loss Energy: 6.313757208599902, Test Loss Force: 8.317440600856978, time: 8.996520280838013


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.483298621878199, Training Loss Force: 4.506843046323042, time: 0.7118628025054932
Validation Loss Energy: 2.243374611032799, Validation Loss Force: 4.897301694606043, time: 0.06641602516174316
Test Loss Energy: 6.398992355579731, Test Loss Force: 8.38701758820997, time: 9.180031299591064


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.39243700105198, Training Loss Force: 4.452945710276904, time: 0.7152819633483887
Validation Loss Energy: 5.474239455727254, Validation Loss Force: 4.705418784794231, time: 0.0640864372253418
Test Loss Energy: 9.746263570745556, Test Loss Force: 8.363295681137663, time: 9.038185358047485


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.391380736298982, Training Loss Force: 4.4469865246698355, time: 0.6867995262145996
Validation Loss Energy: 5.491176338973959, Validation Loss Force: 4.774034282111879, time: 0.06942510604858398
Test Loss Energy: 7.125669492318381, Test Loss Force: 8.34627447390146, time: 9.024044513702393


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.495329412530093, Training Loss Force: 4.450919348552031, time: 0.700066328048706
Validation Loss Energy: 4.241709620392175, Validation Loss Force: 4.582283860441894, time: 0.06490588188171387
Test Loss Energy: 8.923275315676163, Test Loss Force: 8.425221239018246, time: 9.02142071723938


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.525465509112658, Training Loss Force: 4.456697245225848, time: 0.9285521507263184
Validation Loss Energy: 2.841723680553562, Validation Loss Force: 4.570391769365329, time: 0.06487274169921875
Test Loss Energy: 7.760435711858982, Test Loss Force: 8.355754681571952, time: 9.032305002212524


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.455982321916853, Training Loss Force: 4.458814616491178, time: 0.7409369945526123
Validation Loss Energy: 4.608038664536485, Validation Loss Force: 4.8407773545814194, time: 0.06318497657775879
Test Loss Energy: 6.782042054908753, Test Loss Force: 8.275038664364885, time: 10.101109027862549


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4484547817154985, Training Loss Force: 4.491239293609709, time: 0.7023727893829346
Validation Loss Energy: 6.428388992830852, Validation Loss Force: 4.772858143683088, time: 0.06414985656738281
Test Loss Energy: 10.48872455276875, Test Loss Force: 8.3214707351956, time: 9.06821870803833


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.612197031550096, Training Loss Force: 4.444073732610079, time: 0.8342037200927734
Validation Loss Energy: 3.7287408081859628, Validation Loss Force: 4.859054483417465, time: 0.06601142883300781
Test Loss Energy: 6.2808719299014255, Test Loss Force: 8.30735597819149, time: 9.071807622909546


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.4935764134303104, Training Loss Force: 4.482843993622442, time: 0.7322344779968262
Validation Loss Energy: 2.4347921423296217, Validation Loss Force: 4.95205692826627, time: 0.06331181526184082
Test Loss Energy: 6.379761855388615, Test Loss Force: 8.324489755756126, time: 9.029805421829224


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.353194311198066, Training Loss Force: 4.476602038913454, time: 0.7508683204650879
Validation Loss Energy: 6.028769352686315, Validation Loss Force: 4.928385862039271, time: 0.06341934204101562
Test Loss Energy: 10.251380647427107, Test Loss Force: 8.437254494172683, time: 9.032747507095337


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.437274918615591, Training Loss Force: 4.459265744180828, time: 0.6986057758331299
Validation Loss Energy: 5.689246333674522, Validation Loss Force: 4.78786938415581, time: 0.062189579010009766
Test Loss Energy: 7.101717765039719, Test Loss Force: 8.346728098749805, time: 9.218363285064697


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.485711009048477, Training Loss Force: 4.447298644672199, time: 0.6962015628814697
Validation Loss Energy: 3.7789061627411806, Validation Loss Force: 4.588723229472979, time: 0.06940412521362305
Test Loss Energy: 8.36789940886458, Test Loss Force: 8.327852423591434, time: 9.033930540084839

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–‚â–ƒâ–ƒâ–‚â–ˆâ–â–â–‡â–‚â–…â–„â–‚â–ˆâ–â–â–ˆâ–‚â–…
wandb:   test_error_force â–…â–†â–‚â–‚â–ƒâ–…â–†â–ƒâ–†â–…â–„â–‡â–„â–â–ƒâ–‚â–ƒâ–ˆâ–„â–ƒ
wandb:          test_loss â–â–‡â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–â–‚â–‡â–ƒâ–†â–„â–‚â–ˆâ–â–‚â–ˆâ–‚â–„
wandb: train_error_energy â–ˆâ–â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–‚â–â–â–‚â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–â–â–â–â–‚â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–‡â–ƒâ–‚â–…â–ˆâ–„â–â–†â–†â–„â–‚â–…â–ˆâ–ƒâ–â–‡â–‡â–„
wandb:  valid_error_force â–„â–„â–‚â–…â–‡â–ƒâ–‚â–…â–‡â–ƒâ–…â–â–â–†â–…â–†â–ˆâ–ˆâ–…â–
wandb:         valid_loss â–â–†â–‡â–ƒâ–‚â–…â–‡â–ƒâ–â–†â–†â–ƒâ–â–„â–ˆâ–ƒâ–‚â–‡â–‡â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1374
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.3679
wandb:   test_error_force 8.32785
wandb:          test_loss 4.85222
wandb: train_error_energy 4.48571
wandb:  train_error_force 4.4473
wandb:         train_loss 1.84884
wandb: valid_error_energy 3.77891
wandb:  valid_error_force 4.58872
wandb:         valid_loss 1.69722
wandb: 
wandb: ğŸš€ View run al_73_75 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yxxoekts
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_143826-yxxoekts/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.7998117208480835, Uncertainty Bias: -0.06426757574081421
0.0003643036 0.0059108734
2.947637 10.075614
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1867 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3917 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 534 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1981 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2240 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2107 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3552 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3143 steps.
Found uncertainty sample 61 after 2614 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3193 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2585 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2304 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2179 steps.
Found uncertainty sample 78 after 3935 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2564 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1004 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_151955-b8mdebxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_76
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/b8mdebxs
Training model 76. Added 16 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.185110284066738, Training Loss Force: 4.896491361098712, time: 0.7414817810058594
Validation Loss Energy: 3.7472832473093804, Validation Loss Force: 4.618088613768791, time: 0.06568551063537598
Test Loss Energy: 8.477677526830053, Test Loss Force: 8.42778141191486, time: 10.242021799087524


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.3915670815989625, Training Loss Force: 4.5117340463748965, time: 0.7886450290679932
Validation Loss Energy: 3.5275938598923986, Validation Loss Force: 4.7823952858723215, time: 0.0670926570892334
Test Loss Energy: 6.24113141431634, Test Loss Force: 8.31704184821471, time: 9.312701940536499


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.464053740216182, Training Loss Force: 4.521781632277857, time: 0.6845340728759766
Validation Loss Energy: 3.723333065307961, Validation Loss Force: 4.627114062260682, time: 0.07293367385864258
Test Loss Energy: 7.913236421003708, Test Loss Force: 8.272801424683449, time: 10.013281106948853


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.377324758172428, Training Loss Force: 4.479063563703429, time: 0.7093722820281982
Validation Loss Energy: 4.044348826921393, Validation Loss Force: 4.770435726044539, time: 0.06455683708190918
Test Loss Energy: 6.4529581513401855, Test Loss Force: 8.257798080221855, time: 9.62362289428711


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.512737752853477, Training Loss Force: 4.493057509819005, time: 0.6986479759216309
Validation Loss Energy: 4.043845149313305, Validation Loss Force: 4.6198289958133625, time: 0.06757521629333496
Test Loss Energy: 8.628074649617455, Test Loss Force: 8.30317045576322, time: 9.69405221939087


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.637311727167997, Training Loss Force: 4.467805593869167, time: 0.7218472957611084
Validation Loss Energy: 3.221147229162448, Validation Loss Force: 4.642952295941379, time: 0.06577920913696289
Test Loss Energy: 6.423230458696196, Test Loss Force: 8.277605202567974, time: 10.155271053314209


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.407991975099574, Training Loss Force: 4.468909855709785, time: 0.753692626953125
Validation Loss Energy: 4.362269376071858, Validation Loss Force: 4.897726101998181, time: 0.08296442031860352
Test Loss Energy: 8.735790571497946, Test Loss Force: 8.26110370278675, time: 10.540194034576416


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.602625309383874, Training Loss Force: 4.470164560922452, time: 0.7124111652374268
Validation Loss Energy: 3.726720642359533, Validation Loss Force: 4.881291783013835, time: 0.06649613380432129
Test Loss Energy: 6.604703854071505, Test Loss Force: 8.344169357464244, time: 10.188720941543579


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.431670657623497, Training Loss Force: 4.469767167346243, time: 0.7565360069274902
Validation Loss Energy: 4.291885663066397, Validation Loss Force: 4.954079209449586, time: 0.06783866882324219
Test Loss Energy: 8.694051372995785, Test Loss Force: 8.3261774293325, time: 10.21717119216919


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.52126271701526, Training Loss Force: 4.489881822702433, time: 0.7328176498413086
Validation Loss Energy: 3.672077411279708, Validation Loss Force: 4.599748469564448, time: 0.06806373596191406
Test Loss Energy: 6.383280753026258, Test Loss Force: 8.29064377044464, time: 10.254782915115356


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.484880468728068, Training Loss Force: 4.494489464732493, time: 0.7168049812316895
Validation Loss Energy: 4.339454027372659, Validation Loss Force: 4.697950906978105, time: 0.07046341896057129
Test Loss Energy: 8.804712692390185, Test Loss Force: 8.437595408795747, time: 10.074601411819458


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.531933675313569, Training Loss Force: 4.471502984673323, time: 0.6991524696350098
Validation Loss Energy: 2.9778726144742214, Validation Loss Force: 4.7182302767743325, time: 0.06849360466003418
Test Loss Energy: 6.1549736033390525, Test Loss Force: 8.297384592696066, time: 10.32017207145691


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.392973877429291, Training Loss Force: 4.503002875401999, time: 0.7419109344482422
Validation Loss Energy: 4.059071488180993, Validation Loss Force: 4.622345602500637, time: 0.06622624397277832
Test Loss Energy: 8.574879683144692, Test Loss Force: 8.289858478154727, time: 10.162920236587524


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.499689664784504, Training Loss Force: 4.459546456182324, time: 0.7076094150543213
Validation Loss Energy: 3.4451857903376917, Validation Loss Force: 4.78921341512063, time: 0.06963562965393066
Test Loss Energy: 6.551172382057928, Test Loss Force: 8.327477476729062, time: 9.808917045593262


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.461729529792311, Training Loss Force: 4.481247993570943, time: 0.7124001979827881
Validation Loss Energy: 4.289242580304235, Validation Loss Force: 4.544856739717767, time: 0.06422662734985352
Test Loss Energy: 8.95382059812849, Test Loss Force: 8.346133891561307, time: 9.727805137634277


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.538122030428582, Training Loss Force: 4.496408285733551, time: 0.7050693035125732
Validation Loss Energy: 4.348939510320037, Validation Loss Force: 4.763288937136842, time: 0.06555557250976562
Test Loss Energy: 6.389587636247131, Test Loss Force: 8.284339379719231, time: 10.02765679359436


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.610559264086401, Training Loss Force: 4.469514579564162, time: 0.7036261558532715
Validation Loss Energy: 4.2805324313229764, Validation Loss Force: 4.604355271524549, time: 0.06903553009033203
Test Loss Energy: 8.697443069426557, Test Loss Force: 8.362269383888592, time: 10.155517101287842


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.559337177431897, Training Loss Force: 4.500483829475442, time: 0.7286553382873535
Validation Loss Energy: 3.3492429994169104, Validation Loss Force: 4.698514259917302, time: 0.0666191577911377
Test Loss Energy: 6.322145269576094, Test Loss Force: 8.28213075826918, time: 10.330092906951904


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.530195755281259, Training Loss Force: 4.541395945002484, time: 0.7103312015533447
Validation Loss Energy: 3.9570197692416826, Validation Loss Force: 5.198546996756266, time: 0.06914925575256348
Test Loss Energy: 8.134889444846326, Test Loss Force: 8.779401319327121, time: 10.187819719314575


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.493742804479573, Training Loss Force: 4.567910668285503, time: 0.7138433456420898
Validation Loss Energy: 2.8882114314946357, Validation Loss Force: 4.813450728985724, time: 0.06840181350708008
Test Loss Energy: 6.527402000728616, Test Loss Force: 8.27815928267792, time: 11.095144987106323

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–â–…â–‚â–‡â–‚â–‡â–‚â–‡â–‚â–ˆâ–â–‡â–‚â–ˆâ–‚â–‡â–â–†â–‚
wandb:   test_error_force â–ƒâ–‚â–â–â–‚â–â–â–‚â–‚â–â–ƒâ–‚â–â–‚â–‚â–â–‚â–â–ˆâ–
wandb:          test_loss â–…â–â–…â–‚â–‡â–â–ˆâ–‚â–‡â–â–ˆâ–â–‡â–‚â–ˆâ–â–‡â–â–‡â–‚
wandb: train_error_energy â–ˆâ–â–â–â–‚â–‚â–â–‚â–â–‚â–â–‚â–â–â–â–‚â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–â–â–â–â–â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–ƒ
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–„â–…â–†â–†â–ƒâ–ˆâ–…â–ˆâ–…â–ˆâ–â–‡â–„â–ˆâ–ˆâ–ˆâ–ƒâ–†â–
wandb:  valid_error_force â–‚â–„â–‚â–ƒâ–‚â–‚â–…â–…â–…â–‚â–ƒâ–ƒâ–‚â–„â–â–ƒâ–‚â–ƒâ–ˆâ–„
wandb:         valid_loss â–„â–„â–ƒâ–†â–…â–‚â–ˆâ–…â–ˆâ–ƒâ–†â–â–„â–„â–…â–‡â–…â–ƒâ–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1388
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.5274
wandb:   test_error_force 8.27816
wandb:          test_loss 4.19868
wandb: train_error_energy 4.49374
wandb:  train_error_force 4.56791
wandb:         train_loss 1.8887
wandb: valid_error_energy 2.88821
wandb:  valid_error_force 4.81345
wandb:         valid_loss 1.61369
wandb: 
wandb: ğŸš€ View run al_73_76 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/b8mdebxs
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_151955-b8mdebxs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4883804321289062, Uncertainty Bias: 0.022717922925949097
4.863739e-05 0.008812904
3.39715 13.043825
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1308 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3858 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_160303-0g0ors0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_77
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0g0ors0u
Training model 77. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.81617792248743, Training Loss Force: 4.828696409705132, time: 0.7098324298858643
Validation Loss Energy: 3.1008750506847313, Validation Loss Force: 4.818218520738331, time: 0.07352280616760254
Test Loss Energy: 7.558467563835561, Test Loss Force: 8.390946740342205, time: 10.416358470916748


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.142857870799968, Training Loss Force: 4.452278469470631, time: 0.7233400344848633
Validation Loss Energy: 2.568425248905016, Validation Loss Force: 4.611770376753089, time: 0.06986212730407715
Test Loss Energy: 7.133433991084638, Test Loss Force: 8.263005982787517, time: 10.462204456329346


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.901686194132507, Training Loss Force: 4.437769681925694, time: 0.7708277702331543
Validation Loss Energy: 3.625767795655377, Validation Loss Force: 4.857621384794273, time: 0.07201266288757324
Test Loss Energy: 6.297522030443668, Test Loss Force: 8.309584287790948, time: 10.638290882110596


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0894691576882987, Training Loss Force: 4.448023079908104, time: 0.7105538845062256
Validation Loss Energy: 3.189969540687931, Validation Loss Force: 4.808315755811483, time: 0.07037949562072754
Test Loss Energy: 7.736741644258951, Test Loss Force: 8.354991301791289, time: 10.52820086479187


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0971639556067756, Training Loss Force: 4.443798292171156, time: 0.7080299854278564
Validation Loss Energy: 2.8139074055059705, Validation Loss Force: 4.635466159255287, time: 0.06817221641540527
Test Loss Energy: 7.5876968250031736, Test Loss Force: 8.335991230357802, time: 10.462854146957397


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.016601944849033, Training Loss Force: 4.44109691563872, time: 0.697798490524292
Validation Loss Energy: 3.4396576947863156, Validation Loss Force: 4.736893513909416, time: 0.0684359073638916
Test Loss Energy: 6.16504214019891, Test Loss Force: 8.32629263438486, time: 10.626228094100952


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1198250249518207, Training Loss Force: 4.451729261082861, time: 0.7080273628234863
Validation Loss Energy: 3.085163515748067, Validation Loss Force: 4.7686298792710655, time: 0.06850481033325195
Test Loss Energy: 7.841196342170113, Test Loss Force: 8.423984233803546, time: 10.43443512916565


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1279093521771233, Training Loss Force: 4.4294767541959565, time: 0.7376208305358887
Validation Loss Energy: 2.6845258322683483, Validation Loss Force: 4.74355933746191, time: 0.06720280647277832
Test Loss Energy: 7.373565306100829, Test Loss Force: 8.36363288383109, time: 11.637779474258423


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.995829514714447, Training Loss Force: 4.434504309749937, time: 0.7326910495758057
Validation Loss Energy: 3.76920235269622, Validation Loss Force: 4.685470524017998, time: 0.06849551200866699
Test Loss Energy: 6.35847811484225, Test Loss Force: 8.311704736922444, time: 10.455724716186523


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.00237105851954, Training Loss Force: 4.42964621047667, time: 0.713559627532959
Validation Loss Energy: 2.9891048255368298, Validation Loss Force: 4.75454405176882, time: 0.06898093223571777
Test Loss Energy: 7.7834194695467325, Test Loss Force: 8.382537559605556, time: 10.441272020339966


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.072796638385097, Training Loss Force: 4.445519296939368, time: 0.7058613300323486
Validation Loss Energy: 2.5556830070292986, Validation Loss Force: 4.601467030032719, time: 0.07267260551452637
Test Loss Energy: 7.162606043768851, Test Loss Force: 8.31772825675092, time: 10.642608404159546


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0190825069683114, Training Loss Force: 4.4601801675109725, time: 0.755178689956665
Validation Loss Energy: 3.5326439961220406, Validation Loss Force: 4.74669140166853, time: 0.07230377197265625
Test Loss Energy: 6.330382587037912, Test Loss Force: 8.330993173060554, time: 10.409462213516235


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0145553977894735, Training Loss Force: 4.4634449526498905, time: 0.7349669933319092
Validation Loss Energy: 2.670684718157477, Validation Loss Force: 4.699462607809808, time: 0.07809829711914062
Test Loss Energy: 7.089280658002997, Test Loss Force: 8.349794152629821, time: 9.857091665267944


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.03703087746205, Training Loss Force: 4.433053680992166, time: 0.6982259750366211
Validation Loss Energy: 2.885470596977411, Validation Loss Force: 4.743602757945366, time: 0.06653499603271484
Test Loss Energy: 7.66457060099334, Test Loss Force: 8.3247097855149, time: 9.666817665100098


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9670539430312317, Training Loss Force: 4.438435386762082, time: 0.753631591796875
Validation Loss Energy: 3.415354693523173, Validation Loss Force: 4.74190468303852, time: 0.0659341812133789
Test Loss Energy: 6.44157070898898, Test Loss Force: 8.299206100921404, time: 9.481498956680298


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0434929891099944, Training Loss Force: 4.448323571920533, time: 0.782771110534668
Validation Loss Energy: 3.1682775578299376, Validation Loss Force: 4.696394226978924, time: 0.07356810569763184
Test Loss Energy: 7.6826417107396985, Test Loss Force: 8.314362730356734, time: 9.470382452011108


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.029643152947464, Training Loss Force: 4.444141374718407, time: 0.7077357769012451
Validation Loss Energy: 2.91309448588292, Validation Loss Force: 4.681336671323849, time: 0.06473255157470703
Test Loss Energy: 7.253987623945711, Test Loss Force: 8.384889757188258, time: 9.65807318687439


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0570768950540073, Training Loss Force: 4.432773117868297, time: 0.7089464664459229
Validation Loss Energy: 3.4375659408294696, Validation Loss Force: 4.865681339869422, time: 0.07065129280090332
Test Loss Energy: 6.5069768817354054, Test Loss Force: 8.376446688772374, time: 9.534822702407837


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0261255295236764, Training Loss Force: 4.440133046694609, time: 0.7184419631958008
Validation Loss Energy: 3.239567979597616, Validation Loss Force: 4.774287234261653, time: 0.0659933090209961
Test Loss Energy: 7.61240949086254, Test Loss Force: 8.335736720689816, time: 9.486895561218262


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0348459921349193, Training Loss Force: 4.440592357475373, time: 0.7481844425201416
Validation Loss Energy: 2.9149130247977126, Validation Loss Force: 4.891250437896309, time: 0.06547188758850098
Test Loss Energy: 7.615993060480293, Test Loss Force: 8.38798813190284, time: 9.632214784622192

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–…â–‚â–ˆâ–‡â–â–ˆâ–†â–‚â–ˆâ–…â–‚â–…â–‡â–‚â–‡â–†â–‚â–‡â–‡
wandb:   test_error_force â–‡â–â–ƒâ–…â–„â–„â–ˆâ–…â–ƒâ–†â–ƒâ–„â–…â–„â–ƒâ–ƒâ–†â–†â–„â–†
wandb:          test_loss â–ƒâ–„â–ƒâ–‡â–‡â–â–ˆâ–†â–‚â–ˆâ–„â–‚â–†â–‡â–„â–ˆâ–†â–ƒâ–†â–ˆ
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–‚â–â–
wandb:  train_error_force â–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–â–‡â–…â–‚â–†â–„â–‚â–ˆâ–„â–â–‡â–‚â–ƒâ–†â–…â–ƒâ–†â–…â–ƒ
wandb:  valid_error_force â–†â–â–‡â–†â–‚â–„â–…â–„â–ƒâ–…â–â–…â–ƒâ–„â–„â–ƒâ–ƒâ–‡â–…â–ˆ
wandb:         valid_loss â–„â–â–‡â–…â–‚â–…â–ƒâ–‚â–‡â–ƒâ–â–†â–‚â–ƒâ–†â–„â–‚â–ˆâ–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1389
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.61599
wandb:   test_error_force 8.38799
wandb:          test_loss 5.63407
wandb: train_error_energy 3.03485
wandb:  train_error_force 4.44059
wandb:         train_loss 1.46421
wandb: valid_error_energy 2.91491
wandb:  valid_error_force 4.89125
wandb:         valid_loss 1.59227
wandb: 
wandb: ğŸš€ View run al_73_77 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/0g0ors0u
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_160303-0g0ors0u/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.815041184425354, Uncertainty Bias: 0.032744407653808594
0.00039672852 0.08324623
3.024426 9.96223
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2633 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2702 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3441 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1580 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_164706-rgf6ra2q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_78
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rgf6ra2q
Training model 78. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.570136636070057, Training Loss Force: 4.758711851386398, time: 0.7514281272888184
Validation Loss Energy: 3.302386063031888, Validation Loss Force: 4.819872729823427, time: 0.06702780723571777
Test Loss Energy: 7.837403967183831, Test Loss Force: 8.351227447108599, time: 9.519320487976074


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.0000131668570167, Training Loss Force: 4.435659507157685, time: 0.7286171913146973
Validation Loss Energy: 2.674742640672865, Validation Loss Force: 4.613427925875376, time: 0.06630825996398926
Test Loss Energy: 7.527346430992495, Test Loss Force: 8.324385560585515, time: 9.516361236572266


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1034274514372155, Training Loss Force: 4.440930875305131, time: 0.700671911239624
Validation Loss Energy: 3.6930339179487017, Validation Loss Force: 4.748279032678996, time: 0.0658566951751709
Test Loss Energy: 6.375843815729152, Test Loss Force: 8.368418559063795, time: 9.705565452575684


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9912325835763736, Training Loss Force: 4.429647227669815, time: 0.6769325733184814
Validation Loss Energy: 3.1886415419016174, Validation Loss Force: 4.701001474277316, time: 0.06667208671569824
Test Loss Energy: 8.027292845648685, Test Loss Force: 8.399899289753654, time: 9.537624835968018


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0889580535581276, Training Loss Force: 4.541742650984019, time: 0.7060666084289551
Validation Loss Energy: 2.7519207686625933, Validation Loss Force: 4.843122283357186, time: 0.06623291969299316
Test Loss Energy: 8.055463404794551, Test Loss Force: 8.542786472406686, time: 9.500105857849121


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9862547591518718, Training Loss Force: 4.541108661318938, time: 0.7229809761047363
Validation Loss Energy: 3.3919340187507694, Validation Loss Force: 4.692571443081635, time: 0.0659637451171875
Test Loss Energy: 6.359496169835504, Test Loss Force: 8.415290274384747, time: 9.685375690460205


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.04580085865495, Training Loss Force: 4.459221445260531, time: 0.7165930271148682
Validation Loss Energy: 2.895722729794218, Validation Loss Force: 4.6609270400772544, time: 0.06680750846862793
Test Loss Energy: 7.823421948970061, Test Loss Force: 8.370398010827826, time: 9.55042576789856


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0618590540271877, Training Loss Force: 4.4544011845600835, time: 0.7180013656616211
Validation Loss Energy: 2.5982953128200723, Validation Loss Force: 4.877987818226558, time: 0.06562447547912598
Test Loss Energy: 7.568186836562286, Test Loss Force: 8.420212288419952, time: 9.484285354614258


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.953949967536961, Training Loss Force: 4.463875655506064, time: 0.71543288230896
Validation Loss Energy: 3.853060221060063, Validation Loss Force: 4.701191633727937, time: 0.06528949737548828
Test Loss Energy: 6.36367993189513, Test Loss Force: 8.335972423558523, time: 9.724245309829712


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.116143064107345, Training Loss Force: 4.440654249376616, time: 0.7070112228393555
Validation Loss Energy: 3.321534050897656, Validation Loss Force: 4.622531531237488, time: 0.06830644607543945
Test Loss Energy: 8.084521049838425, Test Loss Force: 8.27005476929164, time: 9.55666184425354


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0725880555929805, Training Loss Force: 4.442480627257478, time: 0.7627320289611816
Validation Loss Energy: 2.701387564678303, Validation Loss Force: 4.908084447997596, time: 0.06611990928649902
Test Loss Energy: 7.3582347639018835, Test Loss Force: 8.325877649045273, time: 9.516552209854126


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9457972378682276, Training Loss Force: 4.437924234555617, time: 0.7855803966522217
Validation Loss Energy: 3.306824972455958, Validation Loss Force: 4.80088706776504, time: 0.06630373001098633
Test Loss Energy: 6.383095571571725, Test Loss Force: 8.392738893546108, time: 9.702638626098633


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.957710442028357, Training Loss Force: 4.4606546552182955, time: 0.7817142009735107
Validation Loss Energy: 3.1546672402888207, Validation Loss Force: 4.843459181774975, time: 0.0659797191619873
Test Loss Energy: 8.093492014337988, Test Loss Force: 8.393425101563503, time: 9.528327226638794


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.09709169440826, Training Loss Force: 4.514588259972698, time: 0.702021598815918
Validation Loss Energy: 2.797617042124467, Validation Loss Force: 4.726993866350612, time: 0.06558346748352051
Test Loss Energy: 8.060245188563332, Test Loss Force: 8.465126427180298, time: 9.549539804458618


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0660963669035954, Training Loss Force: 4.454924264747842, time: 0.714322566986084
Validation Loss Energy: 3.344768240260345, Validation Loss Force: 4.605113682635578, time: 0.06605410575866699
Test Loss Energy: 6.3729266960309685, Test Loss Force: 8.27997601109437, time: 10.734942436218262


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.007162291260417, Training Loss Force: 4.458375353112629, time: 0.7574830055236816
Validation Loss Energy: 3.0181060344444757, Validation Loss Force: 4.6459561027199445, time: 0.06604552268981934
Test Loss Energy: 7.895298586318932, Test Loss Force: 8.310951019350584, time: 9.54783821105957


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0948943902155817, Training Loss Force: 4.460317331704864, time: 0.7867023944854736
Validation Loss Energy: 2.837731445436223, Validation Loss Force: 4.756511779011383, time: 0.06987953186035156
Test Loss Energy: 7.987722248772275, Test Loss Force: 8.433485738437168, time: 9.566758871078491


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9711925198537386, Training Loss Force: 4.457487925474184, time: 0.7352766990661621
Validation Loss Energy: 3.3955179899890497, Validation Loss Force: 4.754282860860647, time: 0.06579256057739258
Test Loss Energy: 6.109476050431848, Test Loss Force: 8.302820018828198, time: 9.726801633834839


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0867683378287296, Training Loss Force: 4.4520197481657116, time: 0.7587556838989258
Validation Loss Energy: 2.984584530539923, Validation Loss Force: 4.68003249813615, time: 0.07007646560668945
Test Loss Energy: 7.930431804475921, Test Loss Force: 8.373619084402465, time: 9.576350450515747


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0511777820988915, Training Loss Force: 4.43697981373714, time: 0.7124607563018799
Validation Loss Energy: 3.073899017659299, Validation Loss Force: 4.610078313913184, time: 0.06650948524475098
Test Loss Energy: 7.933638170228859, Test Loss Force: 8.314900796941087, time: 9.540417194366455

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–†â–‚â–ˆâ–ˆâ–‚â–‡â–†â–‚â–ˆâ–…â–‚â–ˆâ–ˆâ–‚â–‡â–ˆâ–â–‡â–‡
wandb:   test_error_force â–ƒâ–‚â–„â–„â–ˆâ–…â–„â–…â–ƒâ–â–‚â–„â–„â–†â–â–‚â–…â–‚â–„â–‚
wandb:          test_loss â–†â–†â–‚â–‡â–ˆâ–ƒâ–†â–†â–‚â–‡â–„â–‚â–ˆâ–‡â–‚â–†â–†â–â–†â–†
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–
wandb:  train_error_force â–ˆâ–â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–â–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–â–‡â–„â–‚â–…â–ƒâ–â–ˆâ–…â–‚â–…â–„â–‚â–…â–ƒâ–‚â–…â–ƒâ–„
wandb:  valid_error_force â–†â–â–„â–ƒâ–†â–ƒâ–‚â–‡â–ƒâ–â–ˆâ–†â–‡â–„â–â–‚â–„â–„â–ƒâ–
wandb:         valid_loss â–„â–â–†â–„â–‚â–†â–‚â–‚â–ˆâ–„â–ƒâ–…â–…â–‚â–…â–ƒâ–‚â–…â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1392
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.93364
wandb:   test_error_force 8.3149
wandb:          test_loss 5.53017
wandb: train_error_energy 3.05118
wandb:  train_error_force 4.43698
wandb:         train_loss 1.45577
wandb: valid_error_energy 3.0739
wandb:  valid_error_force 4.61008
wandb:         valid_loss 1.49034
wandb: 
wandb: ğŸš€ View run al_73_78 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rgf6ra2q
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_164706-rgf6ra2q/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.6123689413070679, Uncertainty Bias: 0.05081760883331299
0.0002937317 7.247925e-05
3.1196885 9.810401
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3523 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2196 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3735 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3259 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_173102-j6kbw4qm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_79
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/j6kbw4qm
Training model 79. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7032481919500384, Training Loss Force: 4.705918444236368, time: 0.728501558303833
Validation Loss Energy: 2.1951612855453577, Validation Loss Force: 4.774912043885126, time: 0.071502685546875
Test Loss Energy: 6.380177771042225, Test Loss Force: 8.405984331551602, time: 9.496680736541748


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.26408461555199, Training Loss Force: 4.795285683700679, time: 0.7485184669494629
Validation Loss Energy: 2.524091265277929, Validation Loss Force: 5.4328167598486, time: 0.06803417205810547
Test Loss Energy: 7.554012014847513, Test Loss Force: 8.932966235975512, time: 9.538524627685547


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0861347555469725, Training Loss Force: 4.620172250423134, time: 0.7686316967010498
Validation Loss Energy: 4.703942265687584, Validation Loss Force: 4.68219728757286, time: 0.06629204750061035
Test Loss Energy: 9.382196416106876, Test Loss Force: 8.369169786471803, time: 9.66864275932312


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.0466612294618343, Training Loss Force: 4.442194674528144, time: 0.7126109600067139
Validation Loss Energy: 2.322893882422812, Validation Loss Force: 4.90108684741767, time: 0.06588912010192871
Test Loss Energy: 6.4157553179021685, Test Loss Force: 8.281023903753177, time: 10.499157667160034


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9601119667221565, Training Loss Force: 4.4347805713107595, time: 0.717512845993042
Validation Loss Energy: 2.0891218962061995, Validation Loss Force: 4.6376957454134615, time: 0.06598544120788574
Test Loss Energy: 6.355603323266321, Test Loss Force: 8.317543672189593, time: 9.526905536651611


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9938346977460166, Training Loss Force: 4.425780780377274, time: 0.7455472946166992
Validation Loss Energy: 3.8354229320148416, Validation Loss Force: 4.932632162652113, time: 0.06626486778259277
Test Loss Energy: 8.709976110725158, Test Loss Force: 8.34240910540437, time: 9.698648691177368


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9686203116685914, Training Loss Force: 4.435526411736369, time: 0.7477612495422363
Validation Loss Energy: 2.4146879018166665, Validation Loss Force: 4.668403156651779, time: 0.07228398323059082
Test Loss Energy: 6.342599358874416, Test Loss Force: 8.29719887497029, time: 9.500286102294922


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9957946897660905, Training Loss Force: 4.434725192482035, time: 0.6965396404266357
Validation Loss Energy: 2.1735312047099327, Validation Loss Force: 4.7154469124502345, time: 0.06641507148742676
Test Loss Energy: 6.243712252308664, Test Loss Force: 8.300697858291961, time: 9.535051107406616


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.968593090365502, Training Loss Force: 4.459707714189938, time: 0.7649071216583252
Validation Loss Energy: 3.7662508731669475, Validation Loss Force: 4.6550826430040875, time: 0.06639838218688965
Test Loss Energy: 8.284366246908434, Test Loss Force: 8.280809861579394, time: 9.69243860244751


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0481220807576688, Training Loss Force: 4.434464613914013, time: 0.7037191390991211
Validation Loss Energy: 2.5749238479289187, Validation Loss Force: 4.643847871246301, time: 0.06627488136291504
Test Loss Energy: 6.209701988462992, Test Loss Force: 8.375249847942046, time: 9.531914710998535


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0403785208265646, Training Loss Force: 4.433701111776601, time: 0.7532322406768799
Validation Loss Energy: 1.9192274532201838, Validation Loss Force: 4.754718624379227, time: 0.06659936904907227
Test Loss Energy: 6.295242285437307, Test Loss Force: 8.347652649023066, time: 9.544864892959595


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0499602322696204, Training Loss Force: 4.437763133428539, time: 0.6991968154907227
Validation Loss Energy: 4.164071569281533, Validation Loss Force: 4.6976812546423865, time: 0.06741094589233398
Test Loss Energy: 8.891027358042384, Test Loss Force: 8.399431106306912, time: 9.742744207382202


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0131230380229925, Training Loss Force: 4.4508331392264, time: 0.7628252506256104
Validation Loss Energy: 2.1620189315290332, Validation Loss Force: 4.584820062014011, time: 0.06588125228881836
Test Loss Energy: 6.121242058310502, Test Loss Force: 8.315578727728452, time: 9.52013349533081


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.011620638688794, Training Loss Force: 4.441445266335537, time: 0.7105550765991211
Validation Loss Energy: 2.589471713908965, Validation Loss Force: 4.8856022123407055, time: 0.06816458702087402
Test Loss Energy: 6.182158572886307, Test Loss Force: 8.330519874052488, time: 9.53053593635559


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9427392718805776, Training Loss Force: 4.445443093484837, time: 0.7394497394561768
Validation Loss Energy: 4.556509906800753, Validation Loss Force: 4.719604145404706, time: 0.0700681209564209
Test Loss Energy: 9.362039724186179, Test Loss Force: 8.36981005702833, time: 9.69042181968689


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.980736003052968, Training Loss Force: 4.467710392687958, time: 0.7159113883972168
Validation Loss Energy: 2.8290055982801774, Validation Loss Force: 4.752312016250039, time: 0.06639695167541504
Test Loss Energy: 6.168132554782979, Test Loss Force: 8.325317609329703, time: 9.524352312088013


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0548653982336074, Training Loss Force: 4.439847038297992, time: 0.6991946697235107
Validation Loss Energy: 2.2737210755855677, Validation Loss Force: 4.581673301643759, time: 0.0661771297454834
Test Loss Energy: 6.253050306131103, Test Loss Force: 8.336839816643897, time: 9.515220880508423


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0077837962713385, Training Loss Force: 4.457739055785491, time: 0.7101397514343262
Validation Loss Energy: 4.028124707610803, Validation Loss Force: 4.6694922314445115, time: 0.06576180458068848
Test Loss Energy: 8.582348358372839, Test Loss Force: 8.397138127058957, time: 9.745240449905396


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0878702920072887, Training Loss Force: 4.433993253696059, time: 0.7475967407226562
Validation Loss Energy: 2.8309139841953517, Validation Loss Force: 4.876155696493864, time: 0.06550741195678711
Test Loss Energy: 6.1956080434462795, Test Loss Force: 8.325027943584413, time: 9.555793285369873


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.009646777923393, Training Loss Force: 4.443591214926104, time: 0.7109065055847168
Validation Loss Energy: 2.113069517512441, Validation Loss Force: 4.674359333636201, time: 0.06663346290588379
Test Loss Energy: 6.04641806955511, Test Loss Force: 8.270531542404704, time: 9.532095670700073

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ˆâ–‚â–‚â–‡â–‚â–â–†â–â–‚â–‡â–â–â–ˆâ–â–â–†â–â–
wandb:   test_error_force â–‚â–ˆâ–‚â–â–â–‚â–â–â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:          test_loss â–…â–…â–ˆâ–‚â–‚â–†â–‚â–â–…â–â–‚â–†â–â–‚â–ˆâ–â–‚â–†â–â–
wandb: train_error_energy â–…â–ˆâ–‚â–‚â–â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–
wandb:  train_error_force â–†â–ˆâ–…â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–ˆâ–‚â–â–†â–‚â–‚â–†â–ƒâ–â–‡â–‚â–ƒâ–ˆâ–ƒâ–‚â–†â–ƒâ–
wandb:  valid_error_force â–ƒâ–ˆâ–‚â–„â–â–„â–‚â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚
wandb:         valid_loss â–â–ƒâ–ˆâ–ƒâ–â–†â–‚â–‚â–…â–‚â–â–†â–â–ƒâ–‡â–ƒâ–â–†â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1395
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.04642
wandb:   test_error_force 8.27053
wandb:          test_loss 4.78903
wandb: train_error_energy 3.00965
wandb:  train_error_force 4.44359
wandb:         train_loss 1.44639
wandb: valid_error_energy 2.11307
wandb:  valid_error_force 4.67436
wandb:         valid_loss 1.28409
wandb: 
wandb: ğŸš€ View run al_73_79 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/j6kbw4qm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_173102-j6kbw4qm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.6463637351989746, Uncertainty Bias: 0.06878851354122162
4.9591064e-05 0.006379068
3.2469552 10.335852
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 982 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1951 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 827 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_181443-1k6iden9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_80
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1k6iden9
Training model 80. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.257463204744248, Training Loss Force: 5.256229196097064, time: 0.7306487560272217
Validation Loss Energy: 1.6807681144799322, Validation Loss Force: 5.040609107564562, time: 0.06733322143554688
Test Loss Energy: 6.5393567830791195, Test Loss Force: 8.613891096007901, time: 9.64971113204956


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.986240536160175, Training Loss Force: 4.7214471981682005, time: 0.7307033538818359
Validation Loss Energy: 3.8075417489112127, Validation Loss Force: 4.702374006892814, time: 0.06936979293823242
Test Loss Energy: 8.211674796703612, Test Loss Force: 8.343019162905472, time: 9.710566282272339


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9627367501290536, Training Loss Force: 4.44231004750971, time: 0.7459299564361572
Validation Loss Energy: 2.8036342304548736, Validation Loss Force: 4.873000252026921, time: 0.0664834976196289
Test Loss Energy: 6.421481568591798, Test Loss Force: 8.277830483121686, time: 9.815608024597168


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.00692781052843, Training Loss Force: 4.430815896560892, time: 0.7488193511962891
Validation Loss Energy: 2.110101449131797, Validation Loss Force: 4.721939054068905, time: 0.0666205883026123
Test Loss Energy: 6.177989096626229, Test Loss Force: 8.245265617163549, time: 9.716907739639282


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0839140888062917, Training Loss Force: 4.41593958852994, time: 0.6999790668487549
Validation Loss Energy: 3.8675510837387517, Validation Loss Force: 4.829466875314018, time: 0.06651520729064941
Test Loss Energy: 8.47723957742326, Test Loss Force: 8.33404982120932, time: 9.688584566116333


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.97473590204918, Training Loss Force: 4.417513368507397, time: 0.7036581039428711
Validation Loss Energy: 2.117682776877773, Validation Loss Force: 4.612037357059057, time: 0.0686802864074707
Test Loss Energy: 6.328406989431975, Test Loss Force: 8.303695353391175, time: 9.847384214401245


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9608847349324354, Training Loss Force: 4.432671464342519, time: 0.734947919845581
Validation Loss Energy: 2.220646882642523, Validation Loss Force: 4.5540837037867234, time: 0.06810665130615234
Test Loss Energy: 6.200074052055152, Test Loss Force: 8.30413285279645, time: 9.64914321899414


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.995705670184012, Training Loss Force: 4.44860095694841, time: 0.8052322864532471
Validation Loss Energy: 3.9533735619771146, Validation Loss Force: 4.717389478079308, time: 0.06628131866455078
Test Loss Energy: 8.737316892715823, Test Loss Force: 8.305520736759139, time: 9.679686307907104


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.937484619101063, Training Loss Force: 4.448876176012778, time: 0.7588491439819336
Validation Loss Energy: 2.5096495011459172, Validation Loss Force: 4.680999995575206, time: 0.06912112236022949
Test Loss Energy: 6.277195377845238, Test Loss Force: 8.295614212104567, time: 9.830788850784302


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0483570827378825, Training Loss Force: 4.451584799413779, time: 0.728705644607544
Validation Loss Energy: 2.1639584354573507, Validation Loss Force: 4.687250986508836, time: 0.07208061218261719
Test Loss Energy: 6.23694155508586, Test Loss Force: 8.258285247670548, time: 9.68030595779419


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.978901480035962, Training Loss Force: 4.456742935239859, time: 0.7149398326873779
Validation Loss Energy: 4.153238715332146, Validation Loss Force: 4.749985569013386, time: 0.0664985179901123
Test Loss Energy: 8.450078313396494, Test Loss Force: 8.29961193234406, time: 9.68653655052185


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0031280602360892, Training Loss Force: 4.4598220345537225, time: 0.7263655662536621
Validation Loss Energy: 2.5321057958473077, Validation Loss Force: 4.603102757578704, time: 0.06676197052001953
Test Loss Energy: 6.181712481483097, Test Loss Force: 8.29194613546561, time: 10.8542959690094


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.086905461537322, Training Loss Force: 4.44684821676624, time: 0.7107505798339844
Validation Loss Energy: 2.165909239844824, Validation Loss Force: 4.690799219349196, time: 0.06741571426391602
Test Loss Energy: 6.272772863165665, Test Loss Force: 8.398291119554639, time: 9.672143459320068


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.947958315309062, Training Loss Force: 4.449952290449084, time: 0.7349612712860107
Validation Loss Energy: 4.050099925622416, Validation Loss Force: 4.59868433371606, time: 0.06682348251342773
Test Loss Energy: 8.788265066884206, Test Loss Force: 8.382652247039585, time: 9.678201913833618


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9817769762495177, Training Loss Force: 4.462072091091335, time: 0.8464756011962891
Validation Loss Energy: 2.70536243160226, Validation Loss Force: 4.680357149750913, time: 0.09978723526000977
Test Loss Energy: 6.002835839697914, Test Loss Force: 8.322308941135752, time: 9.729355096817017


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.050047303496672, Training Loss Force: 4.434084998444843, time: 0.7121636867523193
Validation Loss Energy: 2.0652764800379386, Validation Loss Force: 4.652861072935165, time: 0.06652212142944336
Test Loss Energy: 6.2016793730217445, Test Loss Force: 8.276415030153952, time: 9.688728332519531


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9554028128648655, Training Loss Force: 4.440797592639307, time: 0.7382845878601074
Validation Loss Energy: 4.056808946989221, Validation Loss Force: 4.6966523005190535, time: 0.06746315956115723
Test Loss Energy: 8.557305661864994, Test Loss Force: 8.37577577614343, time: 9.8646821975708


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.017693499366345, Training Loss Force: 4.443750919310359, time: 0.7162847518920898
Validation Loss Energy: 2.445821724469436, Validation Loss Force: 4.79579417905938, time: 0.06736922264099121
Test Loss Energy: 6.041786073338925, Test Loss Force: 8.282201275605823, time: 9.730438947677612


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9563591161186764, Training Loss Force: 4.462158005957027, time: 0.7070150375366211
Validation Loss Energy: 2.0886151012300678, Validation Loss Force: 4.647755714757333, time: 0.06698775291442871
Test Loss Energy: 6.113306223214198, Test Loss Force: 8.247373121173597, time: 9.674497604370117


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9383408249827854, Training Loss Force: 4.440837111352047, time: 0.6880416870117188
Validation Loss Energy: 3.8953617920576944, Validation Loss Force: 4.784269046735304, time: 0.06759214401245117
Test Loss Energy: 8.364526460942734, Test Loss Force: 8.338857530195206, time: 9.859272241592407

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‡â–‚â–â–‡â–‚â–â–ˆâ–‚â–‚â–‡â–â–‚â–ˆâ–â–â–‡â–â–â–‡
wandb:   test_error_force â–ˆâ–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–„â–„â–‚â–‚â–ƒâ–‚â–â–ƒ
wandb:          test_loss â–â–ˆâ–‚â–‚â–†â–‚â–‚â–‡â–‚â–‚â–‡â–‚â–‚â–ˆâ–â–‚â–ˆâ–â–â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–‡â–„â–‚â–‡â–‚â–ƒâ–‡â–ƒâ–‚â–ˆâ–ƒâ–‚â–ˆâ–„â–‚â–ˆâ–ƒâ–‚â–‡
wandb:  valid_error_force â–ˆâ–ƒâ–†â–ƒâ–…â–‚â–â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–‚â–„
wandb:         valid_loss â–‚â–‡â–„â–â–‡â–â–â–‡â–‚â–â–ˆâ–‚â–‚â–‡â–ƒâ–â–ˆâ–ƒâ–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1397
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.36453
wandb:   test_error_force 8.33886
wandb:          test_loss 5.94991
wandb: train_error_energy 2.93834
wandb:  train_error_force 4.44084
wandb:         train_loss 1.42157
wandb: valid_error_energy 3.89536
wandb:  valid_error_force 4.78427
wandb:         valid_loss 1.89502
wandb: 
wandb: ğŸš€ View run al_73_80 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/1k6iden9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_181443-1k6iden9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5689830780029297, Uncertainty Bias: 0.061180949211120605
0.0001487732 0.0073509216
3.1833265 9.641619
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3047 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 811 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1233 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3705 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_185837-vn7icizw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_81
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vn7icizw
Training model 81. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.713162381508003, Training Loss Force: 4.942019084138443, time: 0.7043652534484863
Validation Loss Energy: 2.202476857665669, Validation Loss Force: 4.830641900397079, time: 0.0675208568572998
Test Loss Energy: 7.227791988569305, Test Loss Force: 8.4435921896738, time: 9.396525382995605


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.358621883399039, Training Loss Force: 4.5161688870263905, time: 0.6961462497711182
Validation Loss Energy: 2.253613161031705, Validation Loss Force: 4.704306775079468, time: 0.07021832466125488
Test Loss Energy: 6.118359374220865, Test Loss Force: 8.27171606298616, time: 10.453558683395386


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.454044486300626, Training Loss Force: 4.448704963682208, time: 0.7454578876495361
Validation Loss Energy: 2.593092425556324, Validation Loss Force: 4.54697766333273, time: 0.06587958335876465
Test Loss Energy: 7.23039539425444, Test Loss Force: 8.272657769275922, time: 9.63211178779602


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.446838368717194, Training Loss Force: 4.4757929790453925, time: 0.7417259216308594
Validation Loss Energy: 2.1974393022427723, Validation Loss Force: 4.7507836152323915, time: 0.06553530693054199
Test Loss Energy: 5.9674864575983175, Test Loss Force: 8.268144254029894, time: 9.43680715560913


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.439950351721039, Training Loss Force: 4.451938428381488, time: 0.7112569808959961
Validation Loss Energy: 2.909342956112329, Validation Loss Force: 4.673431693974266, time: 0.06598091125488281
Test Loss Energy: 7.839322743354309, Test Loss Force: 8.270547173545586, time: 9.406764507293701


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.44173559147719, Training Loss Force: 4.490203286099879, time: 0.7149300575256348
Validation Loss Energy: 2.317502394392462, Validation Loss Force: 4.819303587486436, time: 0.06641125679016113
Test Loss Energy: 6.07668250442665, Test Loss Force: 8.304158300032663, time: 9.623507022857666


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.571319621575085, Training Loss Force: 4.462461979705193, time: 0.7305901050567627
Validation Loss Energy: 3.0773713203208968, Validation Loss Force: 4.68632178816288, time: 0.0654442310333252
Test Loss Energy: 7.742745158838506, Test Loss Force: 8.261395504290551, time: 9.431354284286499


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.425113744586673, Training Loss Force: 4.483275532782501, time: 0.7178802490234375
Validation Loss Energy: 1.978830973529269, Validation Loss Force: 4.7167034344407055, time: 0.06548190116882324
Test Loss Energy: 6.195067691880115, Test Loss Force: 8.26304944407422, time: 9.459964275360107


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.443114034946381, Training Loss Force: 4.468732292247895, time: 0.7565827369689941
Validation Loss Energy: 2.5964407015036395, Validation Loss Force: 4.693317830058785, time: 0.0701131820678711
Test Loss Energy: 7.422058432857236, Test Loss Force: 8.27636395381562, time: 9.578328847885132


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.441759007162148, Training Loss Force: 4.4645666889578015, time: 0.744208812713623
Validation Loss Energy: 2.455007606080968, Validation Loss Force: 4.714113792273565, time: 0.0657188892364502
Test Loss Energy: 6.149241903667287, Test Loss Force: 8.219902766724529, time: 9.482867002487183


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.47180681166228, Training Loss Force: 4.465634144600728, time: 0.7812697887420654
Validation Loss Energy: 2.9175235978645695, Validation Loss Force: 4.9106199815622755, time: 0.06576752662658691
Test Loss Energy: 7.628880110746709, Test Loss Force: 8.264287377271332, time: 9.447056293487549


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.479000649548381, Training Loss Force: 4.522389655684125, time: 0.7283680438995361
Validation Loss Energy: 2.406386128049041, Validation Loss Force: 4.724333415395067, time: 0.06654000282287598
Test Loss Energy: 5.916894281264568, Test Loss Force: 8.271775780286323, time: 9.586917161941528


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.470342989757613, Training Loss Force: 4.447385001227799, time: 0.7125022411346436
Validation Loss Energy: 2.983563258502125, Validation Loss Force: 4.800217724312381, time: 0.06435489654541016
Test Loss Energy: 7.553374476942702, Test Loss Force: 8.260297397990627, time: 9.451996326446533


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.37431621714418, Training Loss Force: 4.466955331735441, time: 0.7327580451965332
Validation Loss Energy: 2.2917728632459333, Validation Loss Force: 4.448486869375097, time: 0.06742262840270996
Test Loss Energy: 5.892835395333786, Test Loss Force: 8.259226072610181, time: 9.42019248008728


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4502397968017755, Training Loss Force: 4.46897145915327, time: 0.7508089542388916
Validation Loss Energy: 2.6838897778530058, Validation Loss Force: 4.599435396745274, time: 0.06873583793640137
Test Loss Energy: 7.154212704018353, Test Loss Force: 8.277973900704575, time: 9.658088207244873


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.513668838826513, Training Loss Force: 4.454145125163593, time: 0.6828532218933105
Validation Loss Energy: 2.2421252144549983, Validation Loss Force: 4.652059018671533, time: 0.06901669502258301
Test Loss Energy: 6.553588661722376, Test Loss Force: 8.292996420360476, time: 9.469761848449707


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.49144852281318, Training Loss Force: 4.450028175081884, time: 0.7407448291778564
Validation Loss Energy: 2.976757376056842, Validation Loss Force: 4.890081870218481, time: 0.07312321662902832
Test Loss Energy: 7.758623038119442, Test Loss Force: 8.276723521351435, time: 9.449931859970093


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.439128459660771, Training Loss Force: 4.480444598231772, time: 0.7062993049621582
Validation Loss Energy: 2.150085590993185, Validation Loss Force: 4.61606432856316, time: 0.06946754455566406
Test Loss Energy: 6.230051945544284, Test Loss Force: 8.233553159465782, time: 9.60676908493042


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.578929486396377, Training Loss Force: 4.472323176351024, time: 0.765453577041626
Validation Loss Energy: 2.839410482131091, Validation Loss Force: 4.68851663793429, time: 0.06644153594970703
Test Loss Energy: 7.651368181267869, Test Loss Force: 8.262706109235728, time: 9.482564926147461


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.516798015925229, Training Loss Force: 4.51395030274829, time: 0.7063438892364502
Validation Loss Energy: 2.428941955858661, Validation Loss Force: 4.783777393261095, time: 0.06634378433227539
Test Loss Energy: 6.212616958412982, Test Loss Force: 8.287998488970388, time: 10.52537226676941

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–†â–â–ˆâ–‚â–ˆâ–‚â–†â–‚â–‡â–â–‡â–â–†â–ƒâ–ˆâ–‚â–‡â–‚
wandb:   test_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–ƒ
wandb:          test_loss â–ˆâ–ƒâ–†â–â–‡â–‚â–‡â–‚â–†â–‚â–†â–â–‡â–â–†â–„â–ˆâ–‚â–‡â–ƒ
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–…â–‚â–‡â–ƒâ–ˆâ–â–…â–„â–‡â–„â–‡â–ƒâ–…â–ƒâ–‡â–‚â–†â–„
wandb:  valid_error_force â–‡â–…â–‚â–†â–„â–‡â–…â–…â–…â–…â–ˆâ–…â–†â–â–ƒâ–„â–ˆâ–„â–…â–†
wandb:         valid_loss â–ƒâ–‚â–‚â–„â–†â–…â–†â–ƒâ–„â–„â–ˆâ–„â–‡â–â–„â–ƒâ–ˆâ–‚â–†â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1400
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.21262
wandb:   test_error_force 8.288
wandb:          test_loss 4.18097
wandb: train_error_energy 4.5168
wandb:  train_error_force 4.51395
wandb:         train_loss 1.88505
wandb: valid_error_energy 2.42894
wandb:  valid_error_force 4.78378
wandb:         valid_loss 1.52102
wandb: 
wandb: ğŸš€ View run al_73_81 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vn7icizw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_185837-vn7icizw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5363117456436157, Uncertainty Bias: 0.005287081003189087
2.4795532e-05 0.0028848648
3.2800915 9.266186
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1704 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1774 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 310 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3565 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1725 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_194157-vv1b3559
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_82
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vv1b3559
Training model 82. Added 5 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.631896669102485, Training Loss Force: 4.805504557844146, time: 0.7475430965423584
Validation Loss Energy: 4.265864324004129, Validation Loss Force: 4.731575952035514, time: 0.06838417053222656
Test Loss Energy: 8.366843022135631, Test Loss Force: 8.334764311705671, time: 9.697319746017456


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.876592894524505, Training Loss Force: 4.492328652976435, time: 0.7173540592193604
Validation Loss Energy: 2.7878236077482708, Validation Loss Force: 4.737967447200226, time: 0.07025408744812012
Test Loss Energy: 5.997165911478327, Test Loss Force: 8.290709102271538, time: 9.69476866722107


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9523292625673316, Training Loss Force: 4.428981259678981, time: 0.7321901321411133
Validation Loss Energy: 2.094923429468775, Validation Loss Force: 4.783518651713527, time: 0.06918001174926758
Test Loss Energy: 5.868816669124149, Test Loss Force: 8.239417924353862, time: 9.860414981842041


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.040040716550205, Training Loss Force: 4.425865050527683, time: 0.7525861263275146
Validation Loss Energy: 3.8894929013784756, Validation Loss Force: 4.680186362515986, time: 0.06641149520874023
Test Loss Energy: 8.504890303206986, Test Loss Force: 8.27479600862295, time: 9.720409154891968


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0435420117467356, Training Loss Force: 4.414290880384879, time: 0.7327196598052979
Validation Loss Energy: 2.6172155101495562, Validation Loss Force: 4.835510115934499, time: 0.06751108169555664
Test Loss Energy: 6.314999396992734, Test Loss Force: 8.263193160103716, time: 9.667274713516235


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0039434670574834, Training Loss Force: 4.418680448350476, time: 0.735884428024292
Validation Loss Energy: 2.0437354668608845, Validation Loss Force: 4.767223500945386, time: 0.06593894958496094
Test Loss Energy: 6.350116116648399, Test Loss Force: 8.324348376003954, time: 9.881353378295898


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9596658086029906, Training Loss Force: 4.420869255690972, time: 0.7522478103637695
Validation Loss Energy: 3.6379276463799197, Validation Loss Force: 4.791436989211865, time: 0.06613659858703613
Test Loss Energy: 8.179119469378731, Test Loss Force: 8.307468744375507, time: 9.713191747665405


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0613651409672142, Training Loss Force: 4.423994194484922, time: 0.6759562492370605
Validation Loss Energy: 2.5931679103967933, Validation Loss Force: 4.871183049127005, time: 0.0662987232208252
Test Loss Energy: 6.080023115192635, Test Loss Force: 8.23753309415297, time: 9.737808465957642


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.031166141586668, Training Loss Force: 4.426287605717381, time: 0.7131447792053223
Validation Loss Energy: 2.299831148302487, Validation Loss Force: 4.88165785108974, time: 0.06668448448181152
Test Loss Energy: 6.391125214497851, Test Loss Force: 8.302894481255889, time: 9.873360633850098


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9340636796325694, Training Loss Force: 4.439425925397079, time: 0.6981298923492432
Validation Loss Energy: 3.7889132481628938, Validation Loss Force: 4.531144773711535, time: 0.06675052642822266
Test Loss Energy: 8.780802922507139, Test Loss Force: 8.30204759704808, time: 10.756068468093872


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0901238758266008, Training Loss Force: 4.4168954413847965, time: 0.7053964138031006
Validation Loss Energy: 2.577260426611712, Validation Loss Force: 4.654923434564749, time: 0.06676268577575684
Test Loss Energy: 5.94608498686153, Test Loss Force: 8.305035980199419, time: 9.716423273086548


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.014105732631258, Training Loss Force: 4.42096994263023, time: 0.7058837413787842
Validation Loss Energy: 2.0972582824656874, Validation Loss Force: 4.668728921612272, time: 0.06636238098144531
Test Loss Energy: 6.144981701971219, Test Loss Force: 8.273182536333485, time: 9.888071060180664


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.943579809951487, Training Loss Force: 4.4259352419152735, time: 0.754230260848999
Validation Loss Energy: 3.7075938080626285, Validation Loss Force: 4.704176958967391, time: 0.0672919750213623
Test Loss Energy: 8.198733611021174, Test Loss Force: 8.355547545639112, time: 9.654113531112671


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.022613589223772, Training Loss Force: 4.444006978706851, time: 0.7046606540679932
Validation Loss Energy: 2.3569366547979813, Validation Loss Force: 4.77996485214452, time: 0.0668797492980957
Test Loss Energy: 6.356485121063564, Test Loss Force: 8.308358959299628, time: 9.722871780395508


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0761591702184146, Training Loss Force: 4.500432544722606, time: 0.9356558322906494
Validation Loss Energy: 2.287709262667324, Validation Loss Force: 4.604996558664821, time: 0.06665587425231934
Test Loss Energy: 5.96980919057372, Test Loss Force: 8.319771072459558, time: 9.67626142501831


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9942070612859566, Training Loss Force: 4.4508774554471024, time: 0.7020297050476074
Validation Loss Energy: 4.386181147645605, Validation Loss Force: 4.7696069514833965, time: 0.0682370662689209
Test Loss Energy: 9.2573991686524, Test Loss Force: 8.349213361548822, time: 9.73278260231018


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0502813363600363, Training Loss Force: 4.445313783439001, time: 0.7180013656616211
Validation Loss Energy: 2.435999677107988, Validation Loss Force: 4.777141630043301, time: 0.06616997718811035
Test Loss Energy: 6.147570563047637, Test Loss Force: 8.267245477418824, time: 9.843830108642578


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0010750431196414, Training Loss Force: 4.4497276122201805, time: 0.7151520252227783
Validation Loss Energy: 2.1461496911697653, Validation Loss Force: 4.722676088941926, time: 0.06603550910949707
Test Loss Energy: 6.275512577342319, Test Loss Force: 8.332911779023203, time: 9.748857498168945


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.8728705015177245, Training Loss Force: 4.437259921401392, time: 0.744206428527832
Validation Loss Energy: 3.7742022770334556, Validation Loss Force: 5.029003591678805, time: 0.0662984848022461
Test Loss Energy: 8.503590990268865, Test Loss Force: 8.367745478033743, time: 9.67259430885315


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9397337470071236, Training Loss Force: 4.432040247920438, time: 0.7045059204101562
Validation Loss Energy: 2.6785618618638187, Validation Loss Force: 4.971078885395443, time: 0.066741943359375
Test Loss Energy: 5.996175215644848, Test Loss Force: 8.325243356747281, time: 9.819870948791504

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–â–†â–‚â–‚â–†â–â–‚â–‡â–â–‚â–†â–‚â–â–ˆâ–‚â–‚â–†â–
wandb:   test_error_force â–†â–„â–â–ƒâ–‚â–†â–…â–â–…â–„â–…â–ƒâ–‡â–…â–…â–‡â–ƒâ–†â–ˆâ–†
wandb:          test_loss â–„â–‚â–â–†â–‚â–‚â–†â–‚â–‚â–‡â–â–‚â–†â–‚â–‚â–ˆâ–‚â–‚â–‡â–‚
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–â–‡â–ƒâ–â–†â–ƒâ–‚â–†â–ƒâ–â–†â–‚â–‚â–ˆâ–‚â–â–†â–ƒ
wandb:  valid_error_force â–„â–„â–…â–ƒâ–…â–„â–…â–†â–†â–â–ƒâ–ƒâ–ƒâ–„â–‚â–„â–„â–„â–ˆâ–‡
wandb:         valid_loss â–‡â–ƒâ–‚â–†â–ƒâ–â–†â–ƒâ–ƒâ–…â–‚â–â–†â–‚â–â–ˆâ–ƒâ–â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1404
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 5.99618
wandb:   test_error_force 8.32524
wandb:          test_loss 4.79211
wandb: train_error_energy 2.93973
wandb:  train_error_force 4.43204
wandb:         train_loss 1.43106
wandb: valid_error_energy 2.67856
wandb:  valid_error_force 4.97108
wandb:         valid_loss 1.61413
wandb: 
wandb: ğŸš€ View run al_73_82 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/vv1b3559
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_194157-vv1b3559/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.756210207939148, Uncertainty Bias: 0.04929855465888977
8.392334e-05 0.046260834
3.1926618 9.059031
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2273 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1176 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1513 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_202644-l5w1oi4j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_83
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/l5w1oi4j
Training model 83. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.603306163313178, Training Loss Force: 4.7475911975658995, time: 0.701331377029419
Validation Loss Energy: 4.20835934906084, Validation Loss Force: 4.748700100033945, time: 0.06067967414855957
Test Loss Energy: 8.697548700871447, Test Loss Force: 8.291385289011563, time: 7.661936044692993


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9211984130537263, Training Loss Force: 4.43668390668485, time: 0.7526788711547852
Validation Loss Energy: 2.514017713116156, Validation Loss Force: 4.683937892286577, time: 0.05920767784118652
Test Loss Energy: 6.178325128849383, Test Loss Force: 8.303227104659237, time: 7.627742528915405


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.94015110742686, Training Loss Force: 4.428055031941858, time: 0.7016439437866211
Validation Loss Energy: 2.212118988357207, Validation Loss Force: 4.675771278690529, time: 0.05883646011352539
Test Loss Energy: 6.0021525368716775, Test Loss Force: 8.24325706685563, time: 7.6782450675964355


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.984288871460093, Training Loss Force: 4.427323310764364, time: 0.7295198440551758
Validation Loss Energy: 3.884872516600474, Validation Loss Force: 4.637304961062359, time: 0.07261347770690918
Test Loss Energy: 8.685018606733061, Test Loss Force: 8.299230657481038, time: 7.900824069976807


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.986282711720679, Training Loss Force: 4.40891850141578, time: 0.7256367206573486
Validation Loss Energy: 2.813329022399423, Validation Loss Force: 4.696033502962521, time: 0.05870676040649414
Test Loss Energy: 6.07862496513309, Test Loss Force: 8.287595702635736, time: 7.692985534667969


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0222836745201054, Training Loss Force: 4.422393183083051, time: 0.7255988121032715
Validation Loss Energy: 2.15228890219214, Validation Loss Force: 4.677099277476843, time: 0.06114387512207031
Test Loss Energy: 6.344712430778918, Test Loss Force: 8.288038611385707, time: 7.696670055389404


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9753818880144975, Training Loss Force: 4.4236584903834615, time: 0.7530643939971924
Validation Loss Energy: 4.0476757266307, Validation Loss Force: 4.868950122931642, time: 0.05906105041503906
Test Loss Energy: 8.81789372655119, Test Loss Force: 8.34685817483685, time: 7.926882028579712


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.1079839959589464, Training Loss Force: 4.442223662002415, time: 0.7270689010620117
Validation Loss Energy: 2.6151985730257428, Validation Loss Force: 4.831283187537351, time: 0.06412768363952637
Test Loss Energy: 6.018898930744365, Test Loss Force: 8.239227086403538, time: 7.68748140335083


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.040015066582794, Training Loss Force: 4.425916638920265, time: 0.7197375297546387
Validation Loss Energy: 2.151000649848375, Validation Loss Force: 4.733680843471969, time: 0.05869936943054199
Test Loss Energy: 5.930843090298803, Test Loss Force: 8.22461578419885, time: 7.681271553039551


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.976597833613785, Training Loss Force: 4.45400692859457, time: 0.75826096534729
Validation Loss Energy: 3.6873067561808663, Validation Loss Force: 4.957616976840086, time: 0.06167912483215332
Test Loss Energy: 8.330091407320213, Test Loss Force: 8.287032519904368, time: 7.666449546813965


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.987923626445632, Training Loss Force: 4.433447375224154, time: 0.7139291763305664
Validation Loss Energy: 2.5291029910798986, Validation Loss Force: 4.859903075532595, time: 0.05940437316894531
Test Loss Energy: 6.0586882260279005, Test Loss Force: 8.262837052683217, time: 7.913503646850586


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0662171218996304, Training Loss Force: 4.445527839337512, time: 0.694746732711792
Validation Loss Energy: 1.9575114048178404, Validation Loss Force: 4.881518460204389, time: 0.06217169761657715
Test Loss Energy: 6.33500256611506, Test Loss Force: 8.281843722584586, time: 7.690118312835693


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0363690743963785, Training Loss Force: 4.446428202029072, time: 0.7114050388336182
Validation Loss Energy: 4.263987891111396, Validation Loss Force: 4.861240649092183, time: 0.05921173095703125
Test Loss Energy: 9.017547351212432, Test Loss Force: 8.342164402505256, time: 7.744204759597778


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0362870967260394, Training Loss Force: 4.434918130236318, time: 0.7243087291717529
Validation Loss Energy: 2.7463670661594355, Validation Loss Force: 4.802920927743944, time: 0.06014108657836914
Test Loss Energy: 6.1634820059134485, Test Loss Force: 8.32609990782712, time: 7.931070327758789


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9833462421161063, Training Loss Force: 4.46317022953044, time: 0.7447383403778076
Validation Loss Energy: 2.085364688372387, Validation Loss Force: 4.69740113685681, time: 0.05953526496887207
Test Loss Energy: 5.841993974116671, Test Loss Force: 8.294704826649369, time: 7.724176406860352


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.960613635247269, Training Loss Force: 4.455315590589824, time: 0.7082905769348145
Validation Loss Energy: 3.93200155468182, Validation Loss Force: 4.657373463177392, time: 0.059322357177734375
Test Loss Energy: 8.053985033220506, Test Loss Force: 8.246665285103868, time: 7.786550045013428


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0179362239173937, Training Loss Force: 4.435348590180697, time: 0.7632970809936523
Validation Loss Energy: 2.5446791431758395, Validation Loss Force: 4.598898541434442, time: 0.0605168342590332
Test Loss Energy: 6.225077787291495, Test Loss Force: 8.295219968803956, time: 7.759005784988403


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0633979230250263, Training Loss Force: 4.438564863809777, time: 0.7334854602813721
Validation Loss Energy: 2.001853849872473, Validation Loss Force: 4.726232337871539, time: 0.058934688568115234
Test Loss Energy: 6.20724306124516, Test Loss Force: 8.349928644793964, time: 7.876173973083496


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0304337473410743, Training Loss Force: 4.4367486730423416, time: 0.704289436340332
Validation Loss Energy: 4.29031562291846, Validation Loss Force: 4.756962906701033, time: 0.05952191352844238
Test Loss Energy: 8.969748772657036, Test Loss Force: 8.316644681070025, time: 7.724907875061035


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.983461901025098, Training Loss Force: 4.453142810367174, time: 0.7028567790985107
Validation Loss Energy: 3.122141290135711, Validation Loss Force: 4.7480628209383, time: 0.062270402908325195
Test Loss Energy: 6.081829477252823, Test Loss Force: 8.327823786707137, time: 8.76888918876648

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‚â–â–‡â–‚â–‚â–ˆâ–â–â–†â–â–‚â–ˆâ–‚â–â–†â–‚â–‚â–ˆâ–‚
wandb:   test_error_force â–…â–…â–‚â–…â–…â–…â–ˆâ–‚â–â–„â–ƒâ–„â–ˆâ–‡â–…â–‚â–…â–ˆâ–†â–‡
wandb:          test_loss â–†â–‚â–â–‡â–‚â–‚â–‡â–â–â–†â–‚â–‚â–ˆâ–‚â–â–…â–‚â–‚â–‡â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–‚â–‡â–„â–‚â–‡â–ƒâ–‚â–†â–ƒâ–â–ˆâ–ƒâ–â–‡â–ƒâ–â–ˆâ–„
wandb:  valid_error_force â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–†â–†â–„â–ˆâ–†â–‡â–†â–…â–ƒâ–‚â–â–ƒâ–„â–„
wandb:         valid_loss â–‡â–‚â–â–†â–ƒâ–â–‡â–ƒâ–‚â–†â–ƒâ–‚â–ˆâ–ƒâ–â–†â–ƒâ–â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1406
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.08183
wandb:   test_error_force 8.32782
wandb:          test_loss 4.84852
wandb: train_error_energy 2.98346
wandb:  train_error_force 4.45314
wandb:         train_loss 1.43766
wandb: valid_error_energy 3.12214
wandb:  valid_error_force 4.74806
wandb:         valid_loss 1.61185
wandb: 
wandb: ğŸš€ View run al_73_83 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/l5w1oi4j
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_202644-l5w1oi4j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.6568702459335327, Uncertainty Bias: 0.06535306572914124
0.00031661987 0.03720522
3.2641168 9.79468
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1933 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2803 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2873 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2247 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_211059-trm184j3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_84
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/trm184j3
Training model 84. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.177115813530348, Training Loss Force: 5.213649383132721, time: 0.7453887462615967
Validation Loss Energy: 8.729667713251015, Validation Loss Force: 4.846724179461713, time: 0.06354546546936035
Test Loss Energy: 8.4133508564347, Test Loss Force: 8.278687859592914, time: 7.8891191482543945


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.518895430362482, Training Loss Force: 4.6121742392053635, time: 0.7149167060852051
Validation Loss Energy: 8.904016318497597, Validation Loss Force: 5.112901095150624, time: 0.060460805892944336
Test Loss Energy: 12.505850024369122, Test Loss Force: 8.298490626483906, time: 7.9306323528289795


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 5.660073050999106, Training Loss Force: 4.814620454543112, time: 0.7492091655731201
Validation Loss Energy: 3.459804242436997, Validation Loss Force: 5.054729226115281, time: 0.0622100830078125
Test Loss Energy: 7.6009205300337035, Test Loss Force: 8.465726906410707, time: 7.919814825057983


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.379984928373669, Training Loss Force: 4.602901113348355, time: 0.7285218238830566
Validation Loss Energy: 6.536209401333712, Validation Loss Force: 4.79623929468209, time: 0.06144523620605469
Test Loss Energy: 7.261221832060614, Test Loss Force: 8.254759725917266, time: 8.082591772079468


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.589113400246881, Training Loss Force: 4.456740596089235, time: 0.7311794757843018
Validation Loss Energy: 6.044087876580417, Validation Loss Force: 4.734968093804578, time: 0.0601191520690918
Test Loss Energy: 10.217140791873263, Test Loss Force: 8.242484687044566, time: 7.901881217956543


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.418477441789807, Training Loss Force: 4.565666022495677, time: 0.7117624282836914
Validation Loss Energy: 2.7555291221723532, Validation Loss Force: 4.726705509806635, time: 0.06426095962524414
Test Loss Energy: 6.028524523880043, Test Loss Force: 8.225655380974711, time: 7.915942907333374


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.450461281640242, Training Loss Force: 4.504298821527052, time: 0.7529399394989014
Validation Loss Energy: 3.6492802101159025, Validation Loss Force: 4.731027517929094, time: 0.06734490394592285
Test Loss Energy: 6.138955141717963, Test Loss Force: 8.262995290005286, time: 8.086078405380249


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.5086459566255765, Training Loss Force: 4.5435100664124155, time: 0.7075514793395996
Validation Loss Energy: 5.950058704299739, Validation Loss Force: 4.746656665281765, time: 0.06001758575439453
Test Loss Energy: 9.96886356566256, Test Loss Force: 8.264747045663405, time: 7.867566823959351


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.552544065399512, Training Loss Force: 4.526902980911846, time: 0.7154912948608398
Validation Loss Energy: 5.649586509424177, Validation Loss Force: 4.942105621465611, time: 0.06152510643005371
Test Loss Energy: 6.930103730429101, Test Loss Force: 8.352828128163143, time: 7.873330116271973


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9461597431815694, Training Loss Force: 4.711398723050626, time: 0.7452449798583984
Validation Loss Energy: 6.439168628854362, Validation Loss Force: 4.756845337391983, time: 0.060242652893066406
Test Loss Energy: 10.425311131313144, Test Loss Force: 8.396717032890445, time: 7.931590795516968


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.420465687336458, Training Loss Force: 5.440320264728076, time: 0.7972791194915771
Validation Loss Energy: 8.92467378050361, Validation Loss Force: 4.889053806771732, time: 0.09211325645446777
Test Loss Energy: 8.646675250271532, Test Loss Force: 8.195170417378984, time: 7.969255685806274


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.984323221454211, Training Loss Force: 4.789276381006895, time: 0.7264087200164795
Validation Loss Energy: 1.9576238527365337, Validation Loss Force: 4.893634556441758, time: 0.06300759315490723
Test Loss Energy: 6.10612082744034, Test Loss Force: 8.246387799710604, time: 8.919390439987183


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3727622600454783, Training Loss Force: 4.876036711998687, time: 0.7374889850616455
Validation Loss Energy: 2.1210188060220636, Validation Loss Force: 4.9911594116443565, time: 0.06141829490661621
Test Loss Energy: 6.916426883194342, Test Loss Force: 8.347026997686903, time: 7.920192003250122


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.3804181015078525, Training Loss Force: 4.737676354299856, time: 0.7497704029083252
Validation Loss Energy: 4.175221726763867, Validation Loss Force: 4.84678340945453, time: 0.06384801864624023
Test Loss Energy: 8.595631918268763, Test Loss Force: 8.22375010251822, time: 8.108559608459473


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.4140708243401, Training Loss Force: 4.492221553840531, time: 0.7662441730499268
Validation Loss Energy: 5.467246531199392, Validation Loss Force: 4.72635146586461, time: 0.05989956855773926
Test Loss Energy: 6.873415185316136, Test Loss Force: 8.221847071737717, time: 7.926061391830444


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.437680394297197, Training Loss Force: 4.44097147396323, time: 0.7260887622833252
Validation Loss Energy: 5.564031234160927, Validation Loss Force: 4.944556540754839, time: 0.060724735260009766
Test Loss Energy: 9.629349048881558, Test Loss Force: 8.308346410552575, time: 7.907480478286743


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.334605218688358, Training Loss Force: 4.404754213672994, time: 0.7442123889923096
Validation Loss Energy: 2.5232541406238136, Validation Loss Force: 4.774082601316545, time: 0.059326171875
Test Loss Energy: 5.9366111957930245, Test Loss Force: 8.150510032843657, time: 7.99338436126709


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.368580675706612, Training Loss Force: 4.3949132419082435, time: 0.7322201728820801
Validation Loss Energy: 3.5901149026860026, Validation Loss Force: 4.630147038697364, time: 0.06041407585144043
Test Loss Energy: 6.097752363680606, Test Loss Force: 8.173078345863848, time: 7.877961874008179


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.422167881043163, Training Loss Force: 4.479864554328283, time: 0.7521369457244873
Validation Loss Energy: 5.88274470814004, Validation Loss Force: 4.726026146242409, time: 0.061072587966918945
Test Loss Energy: 9.719321466785507, Test Loss Force: 8.308197746837976, time: 7.877909421920776


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.45035239147968, Training Loss Force: 4.429656303799153, time: 0.7187826633453369
Validation Loss Energy: 4.820620230146307, Validation Loss Force: 4.735383371761733, time: 0.06256461143493652
Test Loss Energy: 6.479037858863863, Test Loss Force: 8.215950769437406, time: 7.811678886413574

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–ƒâ–‚â–†â–â–â–…â–‚â–†â–„â–â–‚â–„â–‚â–…â–â–â–…â–‚
wandb:   test_error_force â–„â–„â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–†â–‚â–ƒâ–…â–ƒâ–ƒâ–…â–â–‚â–…â–‚
wandb:          test_loss â–‚â–…â–‚â–‚â–„â–â–â–„â–‚â–ˆâ–‚â–â–†â–„â–‚â–„â–â–â–„â–
wandb: train_error_energy â–ˆâ–†â–…â–ƒâ–„â–ƒâ–„â–„â–„â–‚â–†â–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„
wandb:  train_error_force â–†â–‚â–„â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–ˆâ–„â–„â–ƒâ–‚â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–†â–ƒâ–â–„â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ˆâ–ˆâ–ƒâ–†â–…â–‚â–ƒâ–…â–…â–†â–ˆâ–â–â–ƒâ–…â–…â–‚â–ƒâ–…â–„
wandb:  valid_error_force â–„â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–ƒâ–…â–…â–†â–„â–‚â–†â–ƒâ–â–‚â–ƒ
wandb:         valid_loss â–ˆâ–‡â–ƒâ–†â–…â–‚â–‚â–…â–…â–‡â–ˆâ–â–â–ƒâ–„â–„â–‚â–‚â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1409
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.47904
wandb:   test_error_force 8.21595
wandb:          test_loss 4.16934
wandb: train_error_energy 4.45035
wandb:  train_error_force 4.42966
wandb:         train_loss 1.84926
wandb: valid_error_energy 4.82062
wandb:  valid_error_force 4.73538
wandb:         valid_loss 2.05444
wandb: 
wandb: ğŸš€ View run al_73_84 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/trm184j3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_211059-trm184j3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4403605461120605, Uncertainty Bias: 0.02933385968208313
0.0001411438 0.10681534
3.361234 10.902945
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3982 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_215552-9yj8tp2g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_85
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9yj8tp2g
Training model 85. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.958308258151823, Training Loss Force: 4.840168225814024, time: 0.7552752494812012
Validation Loss Energy: 1.8870389581577276, Validation Loss Force: 4.862429034324, time: 0.06862044334411621
Test Loss Energy: 6.547606905765539, Test Loss Force: 8.362607281403017, time: 7.889965057373047


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.446628583438417, Training Loss Force: 4.674211144845485, time: 0.7558555603027344
Validation Loss Energy: 3.5536652995124998, Validation Loss Force: 5.039362160347366, time: 0.06096816062927246
Test Loss Energy: 8.114009572503548, Test Loss Force: 8.47287044038513, time: 8.996052026748657


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.466598507448446, Training Loss Force: 4.905596095550837, time: 0.7710070610046387
Validation Loss Energy: 3.1433501922816136, Validation Loss Force: 5.308796057633762, time: 0.06293869018554688
Test Loss Energy: 7.914653872164718, Test Loss Force: 8.806682971584374, time: 8.110847234725952


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7680248693035283, Training Loss Force: 5.212422253469512, time: 0.7061009407043457
Validation Loss Energy: 2.1996142231256215, Validation Loss Force: 5.073797275757661, time: 0.06010317802429199
Test Loss Energy: 6.140771135675971, Test Loss Force: 8.548419959829603, time: 7.920695781707764


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.8714818111630613, Training Loss Force: 4.835108707791032, time: 0.7258143424987793
Validation Loss Energy: 2.8842833250913236, Validation Loss Force: 4.806493654190356, time: 0.06049323081970215
Test Loss Energy: 6.1727203715753225, Test Loss Force: 8.279798118265493, time: 7.951340913772583


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.895674549139242, Training Loss Force: 4.500992476654015, time: 0.7324047088623047
Validation Loss Energy: 3.2219886958649093, Validation Loss Force: 4.555124682043935, time: 0.06238245964050293
Test Loss Energy: 7.713982875673151, Test Loss Force: 8.20004659654434, time: 7.931488275527954


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.895554134613328, Training Loss Force: 4.413490019088065, time: 0.7088344097137451
Validation Loss Energy: 2.848233635703907, Validation Loss Force: 4.7519488428730305, time: 0.0603785514831543
Test Loss Energy: 6.177977767313349, Test Loss Force: 8.272003196598545, time: 8.12269926071167


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0343483705653043, Training Loss Force: 4.4335389362146636, time: 0.7290549278259277
Validation Loss Energy: 2.086336861863508, Validation Loss Force: 4.693848005295239, time: 0.06133246421813965
Test Loss Energy: 6.914219635064991, Test Loss Force: 8.209439681122612, time: 7.936730146408081


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9683890365850925, Training Loss Force: 4.459636289575148, time: 0.7319419384002686
Validation Loss Energy: 2.248976410071477, Validation Loss Force: 4.616898001845515, time: 0.06022286415100098
Test Loss Energy: 6.039099522295217, Test Loss Force: 8.237611781465398, time: 7.935827255249023


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9371791427297693, Training Loss Force: 4.409542876946877, time: 0.7671186923980713
Validation Loss Energy: 3.0287968254787607, Validation Loss Force: 4.552394312976569, time: 0.06362676620483398
Test Loss Energy: 7.637558203531602, Test Loss Force: 8.2390131841266, time: 8.099398136138916


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9735426620114564, Training Loss Force: 4.3920585195451824, time: 0.7440133094787598
Validation Loss Energy: 2.6249174132380526, Validation Loss Force: 4.600445423991202, time: 0.06531548500061035
Test Loss Energy: 6.125107116702919, Test Loss Force: 8.235993128329419, time: 7.893445014953613


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.8851634001495867, Training Loss Force: 4.411426212583136, time: 0.7195560932159424
Validation Loss Energy: 3.1333535723097583, Validation Loss Force: 4.819734897622098, time: 0.060952186584472656
Test Loss Energy: 7.8197054890070525, Test Loss Force: 8.266176894016551, time: 7.903024196624756


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9754405206242325, Training Loss Force: 4.473026810402319, time: 0.7200920581817627
Validation Loss Energy: 2.7593144976531256, Validation Loss Force: 4.884444110112735, time: 0.06039619445800781
Test Loss Energy: 7.660398326796352, Test Loss Force: 8.328357633069983, time: 7.907894849777222


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.074695292421543, Training Loss Force: 4.607539351243656, time: 0.723360538482666
Validation Loss Energy: 3.0327745871016147, Validation Loss Force: 4.620847484486836, time: 0.06038498878479004
Test Loss Energy: 6.312712556884687, Test Loss Force: 8.26632890592899, time: 8.16944670677185


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9405094146395867, Training Loss Force: 4.45545823458143, time: 0.759974479675293
Validation Loss Energy: 4.193834863341117, Validation Loss Force: 4.766612274139813, time: 0.06517958641052246
Test Loss Energy: 8.880110046035691, Test Loss Force: 8.339001997004438, time: 7.93396520614624


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.973299467718478, Training Loss Force: 4.431896889813136, time: 0.7288434505462646
Validation Loss Energy: 3.3906864035261357, Validation Loss Force: 4.62923520854479, time: 0.06029987335205078
Test Loss Energy: 6.343406197610168, Test Loss Force: 8.24342692494234, time: 7.9407641887664795


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0034729999902146, Training Loss Force: 4.469535719413009, time: 0.7094156742095947
Validation Loss Energy: 8.680686735882986, Validation Loss Force: 4.885940224104224, time: 0.060494422912597656
Test Loss Energy: 12.888647804453417, Test Loss Force: 8.486160146415806, time: 8.07281231880188


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 5.804064857370445, Training Loss Force: 4.879848743450329, time: 0.747067928314209
Validation Loss Energy: 3.4464317355437304, Validation Loss Force: 4.885833120245032, time: 0.059883832931518555
Test Loss Energy: 8.4572910310243, Test Loss Force: 8.35416350417645, time: 7.919372081756592


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.4376693325888485, Training Loss Force: 4.504651717485924, time: 0.7233736515045166
Validation Loss Energy: 6.2724455511792225, Validation Loss Force: 4.669980544881532, time: 0.06649541854858398
Test Loss Energy: 7.181735298281185, Test Loss Force: 8.254331580947737, time: 7.889224052429199


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.4599426056227935, Training Loss Force: 4.457801866927945, time: 0.736534833908081
Validation Loss Energy: 5.5708012668737155, Validation Loss Force: 4.700073611946234, time: 0.06056785583496094
Test Loss Energy: 9.906636833189518, Test Loss Force: 8.295324429778573, time: 7.907352685928345

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–ƒâ–â–â–ƒâ–â–‚â–â–ƒâ–â–ƒâ–ƒâ–â–„â–â–ˆâ–ƒâ–‚â–…
wandb:   test_error_force â–ƒâ–„â–ˆâ–…â–‚â–â–‚â–â–â–â–â–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–‚â–‚
wandb:          test_loss â–â–†â–…â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–‚â–„â–‚â–ˆâ–‚â–â–ƒ
wandb: train_error_energy â–†â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–…â–…
wandb:  train_error_force â–…â–ƒâ–…â–ˆâ–…â–‚â–â–â–‚â–â–â–â–‚â–ƒâ–‚â–â–‚â–…â–‚â–‚
wandb:         train_loss â–†â–â–â–ƒâ–‚â–â–â–‚â–â–â–â–â–â–‚â–â–â–â–ˆâ–„â–ƒ
wandb: valid_error_energy â–â–ƒâ–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–†â–…
wandb:  valid_error_force â–„â–†â–ˆâ–†â–ƒâ–â–ƒâ–‚â–‚â–â–â–ƒâ–„â–‚â–ƒâ–‚â–„â–„â–‚â–‚
wandb:         valid_loss â–â–ƒâ–‚â–â–‚â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ˆâ–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1410
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 9.90664
wandb:   test_error_force 8.29532
wandb:          test_loss 5.58859
wandb: train_error_energy 4.45994
wandb:  train_error_force 4.4578
wandb:         train_loss 1.85634
wandb: valid_error_energy 5.5708
wandb:  valid_error_force 4.70007
wandb:         valid_loss 2.22262
wandb: 
wandb: ğŸš€ View run al_73_85 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/9yj8tp2g
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_215552-9yj8tp2g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3706638813018799, Uncertainty Bias: 0.024001896381378174
7.6293945e-06 0.091091156
3.1953683 10.194745
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3876 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2020 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2514 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_224031-gcf6tils
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_86
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/gcf6tils
Training model 86. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.502983009217944, Training Loss Force: 4.909731031901496, time: 0.7376835346221924
Validation Loss Energy: 2.7492519676140756, Validation Loss Force: 5.052724535794493, time: 0.061806678771972656
Test Loss Energy: 6.042899458706003, Test Loss Force: 8.325626991203766, time: 8.246068000793457


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9352795992537897, Training Loss Force: 4.555180087075646, time: 0.7485508918762207
Validation Loss Energy: 2.675700563338647, Validation Loss Force: 4.618874635853915, time: 0.06886124610900879
Test Loss Energy: 7.341710505235495, Test Loss Force: 8.291018013159556, time: 8.269171476364136


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.999493033942816, Training Loss Force: 4.4503280512679275, time: 0.7122163772583008
Validation Loss Energy: 2.0475802393363334, Validation Loss Force: 4.5902422783865, time: 0.06140542030334473
Test Loss Energy: 6.234373613251087, Test Loss Force: 8.312755959126173, time: 8.38623332977295


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9734799979655895, Training Loss Force: 4.405591786139503, time: 0.822746753692627
Validation Loss Energy: 2.6671446127409446, Validation Loss Force: 4.668556353024178, time: 0.06127357482910156
Test Loss Energy: 7.251657907786098, Test Loss Force: 8.263406470150674, time: 8.223694086074829


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.010626394749241, Training Loss Force: 4.415577423574259, time: 0.7658348083496094
Validation Loss Energy: 2.211009316668476, Validation Loss Force: 4.701923324541457, time: 0.06822609901428223
Test Loss Energy: 6.062096099197255, Test Loss Force: 8.232660580284971, time: 8.144205570220947


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0274800220022837, Training Loss Force: 4.440225477894136, time: 0.769554853439331
Validation Loss Energy: 2.6221280368470152, Validation Loss Force: 4.803928728298414, time: 0.06547188758850098
Test Loss Energy: 7.548753959262697, Test Loss Force: 8.288775144961697, time: 8.141796112060547


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.016293925719798, Training Loss Force: 4.42912428288289, time: 0.7123875617980957
Validation Loss Energy: 2.1857748903679175, Validation Loss Force: 4.633182464494651, time: 0.06349349021911621
Test Loss Energy: 5.9553604345139455, Test Loss Force: 8.205803491638, time: 8.303279399871826


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.0255303853907756, Training Loss Force: 4.430270920123946, time: 0.7053899765014648
Validation Loss Energy: 2.8100943077165303, Validation Loss Force: 4.798208580608675, time: 0.06099987030029297
Test Loss Energy: 7.547074870689416, Test Loss Force: 8.25318908071547, time: 8.086944103240967


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9395935690200803, Training Loss Force: 4.440307143040456, time: 0.7452020645141602
Validation Loss Energy: 2.335371816022313, Validation Loss Force: 4.866294570697306, time: 0.06293272972106934
Test Loss Energy: 6.2478163757573135, Test Loss Force: 8.203429306934394, time: 8.081631183624268


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9407334024816785, Training Loss Force: 4.4197101678708846, time: 0.7361834049224854
Validation Loss Energy: 2.6023378711643916, Validation Loss Force: 4.859262011061469, time: 0.06371784210205078
Test Loss Energy: 7.248521718954145, Test Loss Force: 8.389080581706974, time: 8.261764764785767


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.039891634833722, Training Loss Force: 4.437420014894356, time: 0.742499828338623
Validation Loss Energy: 2.2355937717320713, Validation Loss Force: 4.791643848848432, time: 0.06468343734741211
Test Loss Energy: 6.181359988064445, Test Loss Force: 8.207232356049996, time: 8.127110958099365


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9575360681895235, Training Loss Force: 4.475462523862982, time: 0.7463939189910889
Validation Loss Energy: 3.1474352804328047, Validation Loss Force: 4.912511778626078, time: 0.061781883239746094
Test Loss Energy: 7.097380251683539, Test Loss Force: 8.211738993034446, time: 9.172216176986694


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0321970130262974, Training Loss Force: 4.451567833486828, time: 0.7203676700592041
Validation Loss Energy: 2.3731776969636624, Validation Loss Force: 4.68495860765151, time: 0.06472301483154297
Test Loss Energy: 5.995216637795507, Test Loss Force: 8.196681769634381, time: 8.07401967048645


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.8774679445699167, Training Loss Force: 4.437273953831034, time: 0.9208290576934814
Validation Loss Energy: 2.7113986581446436, Validation Loss Force: 4.7352506609507605, time: 0.09465289115905762
Test Loss Energy: 7.444359426321607, Test Loss Force: 8.217739588433158, time: 8.091418027877808


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0193761714161687, Training Loss Force: 4.406614738092301, time: 0.7183322906494141
Validation Loss Energy: 2.2968513897916814, Validation Loss Force: 4.748692751952129, time: 0.06552648544311523
Test Loss Energy: 6.324229872472514, Test Loss Force: 8.277975686720973, time: 8.118669271469116


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0177803412329305, Training Loss Force: 4.407180614615154, time: 0.7498049736022949
Validation Loss Energy: 2.6239312115907385, Validation Loss Force: 4.788452554648995, time: 0.06103682518005371
Test Loss Energy: 7.358186713998644, Test Loss Force: 8.324209630975705, time: 8.086799621582031


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.952245976265924, Training Loss Force: 4.4591366200116855, time: 0.749962568283081
Validation Loss Energy: 2.088731445858815, Validation Loss Force: 4.8150307892452275, time: 0.06171011924743652
Test Loss Energy: 6.371041579041545, Test Loss Force: 8.210900232170141, time: 8.27592396736145


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.096681109484503, Training Loss Force: 4.4400275893500485, time: 0.7526297569274902
Validation Loss Energy: 2.64066134653545, Validation Loss Force: 4.7252775325738, time: 0.06191396713256836
Test Loss Energy: 7.4935127006446836, Test Loss Force: 8.267652306772309, time: 8.120460510253906


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.031460816873726, Training Loss Force: 4.421008784226341, time: 0.7206623554229736
Validation Loss Energy: 1.9876061975684238, Validation Loss Force: 4.7306808220688845, time: 0.06156110763549805
Test Loss Energy: 6.054340103827594, Test Loss Force: 8.234946648628753, time: 8.139593362808228


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0413162250214367, Training Loss Force: 4.4200852713659105, time: 0.7490975856781006
Validation Loss Energy: 2.4563864847671257, Validation Loss Force: 4.887061140584824, time: 0.06143021583557129
Test Loss Energy: 7.101865395849277, Test Loss Force: 8.2613164159405, time: 8.299568176269531

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–‚â–‡â–â–ˆâ–â–ˆâ–‚â–‡â–‚â–†â–â–ˆâ–ƒâ–‡â–ƒâ–ˆâ–â–†
wandb:   test_error_force â–†â–„â–…â–ƒâ–‚â–„â–â–ƒâ–â–ˆâ–â–‚â–â–‚â–„â–†â–‚â–„â–‚â–ƒ
wandb:          test_loss â–â–†â–„â–‡â–ƒâ–‡â–ƒâ–‡â–„â–ˆâ–ƒâ–†â–ƒâ–‡â–…â–‡â–…â–‡â–ƒâ–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–…â–â–…â–‚â–…â–‚â–†â–ƒâ–…â–‚â–ˆâ–ƒâ–…â–ƒâ–…â–‚â–…â–â–„
wandb:  valid_error_force â–ˆâ–â–â–‚â–ƒâ–„â–‚â–„â–…â–…â–„â–†â–‚â–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–…
wandb:         valid_loss â–‡â–ƒâ–â–„â–‚â–„â–‚â–…â–„â–„â–„â–ˆâ–ƒâ–…â–ƒâ–„â–ƒâ–„â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1412
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.10187
wandb:   test_error_force 8.26132
wandb:          test_loss 5.20857
wandb: train_error_energy 3.04132
wandb:  train_error_force 4.42009
wandb:         train_loss 1.45636
wandb: valid_error_energy 2.45639
wandb:  valid_error_force 4.88706
wandb:         valid_loss 1.43296
wandb: 
wandb: ğŸš€ View run al_73_86 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/gcf6tils
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_224031-gcf6tils/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.643886685371399, Uncertainty Bias: 0.04942375421524048
9.441376e-05 0.036464214
3.173609 9.599495
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1465 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2768 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2100 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3124 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241205_232457-wdyyoaob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_87
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wdyyoaob
Training model 87. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.46125862975726, Training Loss Force: 4.962336488973651, time: 0.7520740032196045
Validation Loss Energy: 2.903824880672519, Validation Loss Force: 4.889067389589633, time: 0.07037711143493652
Test Loss Energy: 6.0774901918699324, Test Loss Force: 8.393963872295313, time: 7.975323677062988


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9719607437016355, Training Loss Force: 4.45302966632625, time: 0.7337784767150879
Validation Loss Energy: 2.692023102411737, Validation Loss Force: 4.515559046842319, time: 0.06371951103210449
Test Loss Energy: 7.532418691908271, Test Loss Force: 8.292549174808293, time: 7.996078252792358


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.8898056485636174, Training Loss Force: 4.3980458553654245, time: 0.7409079074859619
Validation Loss Energy: 2.215686816082408, Validation Loss Force: 4.704659483006617, time: 0.06086421012878418
Test Loss Energy: 5.9758519625397675, Test Loss Force: 8.213882842244983, time: 8.02737832069397


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.001109750491942, Training Loss Force: 4.40608513189922, time: 0.9248166084289551
Validation Loss Energy: 2.7119445315558854, Validation Loss Force: 4.774363164440414, time: 0.07784414291381836
Test Loss Energy: 7.2116845688757065, Test Loss Force: 8.212037957256744, time: 9.10185432434082


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.889477879580811, Training Loss Force: 4.415317989278238, time: 0.7627058029174805
Validation Loss Energy: 2.1378305492087573, Validation Loss Force: 4.726790346751233, time: 0.06827974319458008
Test Loss Energy: 5.969989226155947, Test Loss Force: 8.22864134391062, time: 7.9841485023498535


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.979617457324017, Training Loss Force: 4.419111286832402, time: 0.7568860054016113
Validation Loss Energy: 2.433642167525478, Validation Loss Force: 4.594469874791084, time: 0.06176877021789551
Test Loss Energy: 7.200103318097822, Test Loss Force: 8.217135989503094, time: 8.009373903274536


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.979447503861337, Training Loss Force: 4.421184702748031, time: 0.7343072891235352
Validation Loss Energy: 2.574806946627307, Validation Loss Force: 4.625138764267156, time: 0.06589579582214355
Test Loss Energy: 6.30689177323325, Test Loss Force: 8.208190434933922, time: 8.195091962814331


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9804589091818676, Training Loss Force: 4.413402554647545, time: 0.6939280033111572
Validation Loss Energy: 2.5520428118316714, Validation Loss Force: 4.740507211478677, time: 0.06379961967468262
Test Loss Energy: 7.176124868190038, Test Loss Force: 8.23459561480052, time: 8.020373821258545


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.1213833565262936, Training Loss Force: 4.425455749325291, time: 0.721203088760376
Validation Loss Energy: 2.097456291003704, Validation Loss Force: 4.70586991248388, time: 0.06073784828186035
Test Loss Energy: 5.825375313058864, Test Loss Force: 8.187202881657466, time: 8.019085884094238


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.090471730466042, Training Loss Force: 4.3934180235415425, time: 0.7437450885772705
Validation Loss Energy: 2.7077482201663035, Validation Loss Force: 4.916688829134538, time: 0.06095528602600098
Test Loss Energy: 7.295867871110842, Test Loss Force: 8.20144875931174, time: 8.151201248168945


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9933118497864326, Training Loss Force: 4.412297492210135, time: 0.7079081535339355
Validation Loss Energy: 2.3796874294448616, Validation Loss Force: 4.647990630706287, time: 0.06132197380065918
Test Loss Energy: 6.046447046855067, Test Loss Force: 8.137312518834243, time: 7.976853609085083


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.978935968506498, Training Loss Force: 4.425771518915233, time: 0.7101843357086182
Validation Loss Energy: 2.6692634209990205, Validation Loss Force: 4.6157532597663, time: 0.061219215393066406
Test Loss Energy: 7.606836119445793, Test Loss Force: 8.27148923424069, time: 7.9687817096710205


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.931919774200105, Training Loss Force: 4.4409291173434715, time: 0.7168447971343994
Validation Loss Energy: 2.085877050077167, Validation Loss Force: 4.66567345559185, time: 0.063507080078125
Test Loss Energy: 6.014358653231774, Test Loss Force: 8.265046247710337, time: 7.983215093612671


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9962128700131365, Training Loss Force: 4.423053475822143, time: 0.7342243194580078
Validation Loss Energy: 2.4558924932668846, Validation Loss Force: 4.765158244616906, time: 0.06092214584350586
Test Loss Energy: 7.484048329297116, Test Loss Force: 8.2804131887369, time: 8.195379257202148


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.969405325782224, Training Loss Force: 4.432730167239232, time: 0.7057061195373535
Validation Loss Energy: 2.1399717357159984, Validation Loss Force: 4.688829710753465, time: 0.06066131591796875
Test Loss Energy: 6.298376618304439, Test Loss Force: 8.315546005856262, time: 8.017979145050049


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9529040477115958, Training Loss Force: 4.424822681150605, time: 0.7657938003540039
Validation Loss Energy: 2.9326342601109485, Validation Loss Force: 4.685512163148287, time: 0.06679391860961914
Test Loss Energy: 7.845709451715287, Test Loss Force: 8.2277817850486, time: 8.003395557403564


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9546616024955226, Training Loss Force: 4.4602935693083, time: 0.769521951675415
Validation Loss Energy: 1.9861131452776917, Validation Loss Force: 4.7193799175747575, time: 0.06321883201599121
Test Loss Energy: 6.17659851964926, Test Loss Force: 8.240999355602451, time: 8.164857864379883


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0385521982756125, Training Loss Force: 4.397932452443505, time: 0.7192885875701904
Validation Loss Energy: 2.7703200315251792, Validation Loss Force: 4.928494524582483, time: 0.061483144760131836
Test Loss Energy: 7.124974235306686, Test Loss Force: 8.180096868017035, time: 7.978992462158203


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0224667820501225, Training Loss Force: 4.40893672204963, time: 0.7525169849395752
Validation Loss Energy: 2.1585480205495973, Validation Loss Force: 4.728563015821965, time: 0.06433248519897461
Test Loss Energy: 5.985232799149208, Test Loss Force: 8.22856562241132, time: 7.937799453735352


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.994108765340997, Training Loss Force: 4.421548930092328, time: 0.72275710105896
Validation Loss Energy: 2.6725740658606743, Validation Loss Force: 4.737232193680372, time: 0.06146550178527832
Test Loss Energy: 7.749260008046835, Test Loss Force: 8.32073134306073, time: 7.959033250808716

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‡â–‚â–†â–‚â–†â–ƒâ–†â–â–†â–‚â–‡â–‚â–‡â–ƒâ–ˆâ–‚â–†â–‚â–ˆ
wandb:   test_error_force â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–â–…â–„â–…â–†â–ƒâ–„â–‚â–ƒâ–†
wandb:          test_loss â–ƒâ–†â–ƒâ–…â–‚â–†â–ƒâ–…â–â–…â–‚â–‡â–ƒâ–†â–„â–ˆâ–„â–…â–‚â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–‚â–‚â–â–â–â–â–â–â–â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–†â–ƒâ–†â–‚â–„â–…â–…â–‚â–†â–„â–†â–‚â–„â–‚â–ˆâ–â–‡â–‚â–†
wandb:  valid_error_force â–‡â–â–„â–…â–…â–‚â–ƒâ–…â–„â–ˆâ–ƒâ–ƒâ–„â–…â–„â–„â–„â–ˆâ–…â–…
wandb:         valid_loss â–ˆâ–ƒâ–‚â–…â–‚â–ƒâ–ƒâ–…â–‚â–†â–„â–„â–â–„â–‚â–†â–â–‡â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1415
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.74926
wandb:   test_error_force 8.32073
wandb:          test_loss 5.6171
wandb: train_error_energy 2.99411
wandb:  train_error_force 4.42155
wandb:         train_loss 1.43822
wandb: valid_error_energy 2.67257
wandb:  valid_error_force 4.73723
wandb:         valid_loss 1.43444
wandb: 
wandb: ğŸš€ View run al_73_87 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/wdyyoaob
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241205_232457-wdyyoaob/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4372199773788452, Uncertainty Bias: 0.07825607061386108
0.0004069805 0.0020873547
3.3996053 10.175477
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3052 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_000946-yjpo77s8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_88
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yjpo77s8
Training model 88. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.4391218281687514, Training Loss Force: 5.102353945508275, time: 0.7687878608703613
Validation Loss Energy: 7.153470986098426, Validation Loss Force: 5.470134772691222, time: 0.06177568435668945
Test Loss Energy: 11.199546995797006, Test Loss Force: 8.666775624385416, time: 8.087679862976074


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.4251443474720915, Training Loss Force: 4.833921312199865, time: 0.716912031173706
Validation Loss Energy: 6.041819100652559, Validation Loss Force: 5.038534276462807, time: 0.06107640266418457
Test Loss Energy: 9.875805825419718, Test Loss Force: 8.477514549336533, time: 8.053337812423706


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.166762080571779, Training Loss Force: 4.73705622567665, time: 0.7447047233581543
Validation Loss Energy: 2.0619053805031653, Validation Loss Force: 4.773373400086765, time: 0.06739211082458496
Test Loss Energy: 5.911867363248068, Test Loss Force: 8.307407716708223, time: 8.1096830368042


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.980448280441302, Training Loss Force: 4.620369616706861, time: 0.9388995170593262
Validation Loss Energy: 3.8607443106168855, Validation Loss Force: 4.853802386272466, time: 0.06104850769042969
Test Loss Energy: 8.47987824877156, Test Loss Force: 8.310775644664927, time: 8.120386838912964


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9872890526676503, Training Loss Force: 4.407617056037578, time: 0.730853796005249
Validation Loss Energy: 3.269081550210042, Validation Loss Force: 4.629585467111333, time: 0.06121253967285156
Test Loss Energy: 6.22946704615925, Test Loss Force: 8.174006589413832, time: 8.11999773979187


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.8880432123771924, Training Loss Force: 4.44537557772569, time: 0.7117772102355957
Validation Loss Energy: 4.205435257836517, Validation Loss Force: 4.733330362236279, time: 0.06383275985717773
Test Loss Energy: 8.325821009475714, Test Loss Force: 8.234346407222981, time: 8.0950345993042


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.920113319202962, Training Loss Force: 4.403891801226205, time: 0.7329075336456299
Validation Loss Energy: 3.0589512378931665, Validation Loss Force: 4.753687666233581, time: 0.060964345932006836
Test Loss Energy: 6.166162422480477, Test Loss Force: 8.238563415767967, time: 8.269117832183838


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.928517119973252, Training Loss Force: 4.4212814896034605, time: 0.7102861404418945
Validation Loss Energy: 3.933642848956454, Validation Loss Force: 4.7999981725344965, time: 0.0606997013092041
Test Loss Energy: 8.604087488799415, Test Loss Force: 8.320864855946953, time: 8.106801748275757


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.984269067738582, Training Loss Force: 4.384019985241872, time: 0.7131602764129639
Validation Loss Energy: 3.676016539805744, Validation Loss Force: 4.691469008140147, time: 0.06118583679199219
Test Loss Energy: 6.1644387324612, Test Loss Force: 8.145472543288859, time: 8.059706211090088


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.97169141794733, Training Loss Force: 4.398789431763132, time: 0.7525923252105713
Validation Loss Energy: 3.7803325812899935, Validation Loss Force: 4.6614233696035265, time: 0.06312990188598633
Test Loss Energy: 7.991817868824326, Test Loss Force: 8.209147543866383, time: 8.312568187713623


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9590178348657097, Training Loss Force: 4.395992875529189, time: 0.751183032989502
Validation Loss Energy: 3.7418720530596166, Validation Loss Force: 4.749012282176535, time: 0.06175541877746582
Test Loss Energy: 6.037655940735062, Test Loss Force: 8.135877867356065, time: 8.114474773406982


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9406610968617923, Training Loss Force: 4.410783045125631, time: 0.7360513210296631
Validation Loss Energy: 4.086851468157798, Validation Loss Force: 4.898251378513425, time: 0.061661720275878906
Test Loss Energy: 8.55965620400169, Test Loss Force: 8.208301079349113, time: 8.12171745300293


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.036947500912163, Training Loss Force: 4.4409271380621735, time: 0.7035045623779297
Validation Loss Energy: 3.5256097664676087, Validation Loss Force: 4.560639528781129, time: 0.06209874153137207
Test Loss Energy: 6.137446491803302, Test Loss Force: 8.189626235439071, time: 8.109960317611694


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9707908771204554, Training Loss Force: 4.420493399169379, time: 0.7407569885253906
Validation Loss Energy: 3.864465334714484, Validation Loss Force: 4.689578324422074, time: 0.06374001502990723
Test Loss Energy: 8.150135379764661, Test Loss Force: 8.22769302982652, time: 8.29724669456482


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0094118706337945, Training Loss Force: 4.410797177194093, time: 0.7401299476623535
Validation Loss Energy: 4.1247252631886555, Validation Loss Force: 4.724717742340938, time: 0.06192445755004883
Test Loss Energy: 6.2752002389815855, Test Loss Force: 8.172424509976524, time: 8.114029169082642


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.891929452032867, Training Loss Force: 4.389968339116967, time: 0.7125651836395264
Validation Loss Energy: 4.165822194106818, Validation Loss Force: 4.56895577604324, time: 0.06291890144348145
Test Loss Energy: 8.645994778024804, Test Loss Force: 8.1915245050636, time: 8.121843099594116


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.030898438730568, Training Loss Force: 4.458962482843163, time: 0.7267343997955322
Validation Loss Energy: 3.9161789078413376, Validation Loss Force: 4.776593195936881, time: 0.06093454360961914
Test Loss Energy: 6.425124734265781, Test Loss Force: 8.191530147569706, time: 9.460423469543457


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0187522796843975, Training Loss Force: 4.487767022938821, time: 0.7288188934326172
Validation Loss Energy: 4.089141620323665, Validation Loss Force: 4.616943649020429, time: 0.06304407119750977
Test Loss Energy: 8.666702421029335, Test Loss Force: 8.245392172513316, time: 8.074859142303467


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.997793229638937, Training Loss Force: 4.409547399604641, time: 0.73720383644104
Validation Loss Energy: 3.661634673673987, Validation Loss Force: 4.83529345885551, time: 0.06406021118164062
Test Loss Energy: 6.119617471216654, Test Loss Force: 8.194490201609808, time: 8.091404676437378


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.005174659870309, Training Loss Force: 4.395151225743207, time: 0.697394609451294
Validation Loss Energy: 4.344485014055751, Validation Loss Force: 4.723146588847272, time: 0.06103348731994629
Test Loss Energy: 8.468166712061358, Test Loss Force: 8.189686768804169, time: 8.30691385269165

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–â–„â–â–„â–â–…â–â–„â–â–…â–â–„â–â–…â–‚â–…â–â–„
wandb:   test_error_force â–ˆâ–†â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb:          test_loss â–ˆâ–‡â–‚â–„â–â–ƒâ–â–„â–â–ƒâ–â–ƒâ–â–ƒâ–â–„â–‚â–„â–â–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–‡â–â–â–â–â–â–â–â–â–â–‚â–â–‚â–â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–…â–„â–ƒâ–â–‚â–â–â–â–â–â–â–‚â–â–â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–„â–…â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–†â–â–ƒâ–ƒâ–„â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–„â–„â–ƒâ–„
wandb:  valid_error_force â–ˆâ–…â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–„â–â–‚â–‚â–â–ƒâ–â–ƒâ–‚
wandb:         valid_loss â–ˆâ–†â–â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1416
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.46817
wandb:   test_error_force 8.18969
wandb:          test_loss 5.98308
wandb: train_error_energy 3.00517
wandb:  train_error_force 4.39515
wandb:         train_loss 1.41711
wandb: valid_error_energy 4.34449
wandb:  valid_error_force 4.72315
wandb:         valid_loss 2.06449
wandb: 
wandb: ğŸš€ View run al_73_88 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/yjpo77s8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_000946-yjpo77s8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4408204555511475, Uncertainty Bias: 0.07415245473384857
4.9591064e-05 0.0040664673
3.2900786 9.785785
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 975 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1934 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 253 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_005349-izb9p7my
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_89
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/izb9p7my
Training model 89. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7205779898618028, Training Loss Force: 4.903241270368585, time: 0.7616806030273438
Validation Loss Energy: 2.5071620641167582, Validation Loss Force: 4.787161518940906, time: 0.06116962432861328
Test Loss Energy: 7.034760898713298, Test Loss Force: 8.380966629946842, time: 7.947283029556274


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.115186922954898, Training Loss Force: 4.476096606419332, time: 0.7561445236206055
Validation Loss Energy: 2.1437381843193672, Validation Loss Force: 4.675603831492792, time: 0.06121635437011719
Test Loss Energy: 7.105602313394345, Test Loss Force: 8.27959424192916, time: 7.977041721343994


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0489714303892104, Training Loss Force: 4.408228317480572, time: 0.7229533195495605
Validation Loss Energy: 1.9959595749106183, Validation Loss Force: 4.687535557677332, time: 0.061432600021362305
Test Loss Energy: 6.137823672351977, Test Loss Force: 8.237920016185328, time: 7.934455156326294


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.114816121922591, Training Loss Force: 4.395908706592028, time: 0.7722988128662109
Validation Loss Energy: 1.6950774461374032, Validation Loss Force: 4.721779622960421, time: 0.09386563301086426
Test Loss Energy: 5.968242896163825, Test Loss Force: 8.24812160660343, time: 8.147315740585327


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0727677678036067, Training Loss Force: 4.412246550457748, time: 0.7755117416381836
Validation Loss Energy: 2.294395683115817, Validation Loss Force: 4.678565999141069, time: 0.07097864151000977
Test Loss Energy: 7.148903779608862, Test Loss Force: 8.264872663704306, time: 7.9920313358306885


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0817029734388566, Training Loss Force: 4.426119189571481, time: 0.7460246086120605
Validation Loss Energy: 2.2955197169644603, Validation Loss Force: 4.802517673920669, time: 0.06082725524902344
Test Loss Energy: 7.1416661766638345, Test Loss Force: 8.268738447228706, time: 7.967013359069824


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.049032783161218, Training Loss Force: 4.416511728465964, time: 0.733069896697998
Validation Loss Energy: 1.9661714532412637, Validation Loss Force: 4.671860985818892, time: 0.06252264976501465
Test Loss Energy: 5.926348395841738, Test Loss Force: 8.223943034258, time: 8.132259130477905


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0923742042257225, Training Loss Force: 4.419560509463803, time: 0.7245416641235352
Validation Loss Energy: 1.9756111776791534, Validation Loss Force: 4.734962749745076, time: 0.06062483787536621
Test Loss Energy: 6.212534402952774, Test Loss Force: 8.270613274805138, time: 7.963933944702148


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.064532040178765, Training Loss Force: 4.410549707653511, time: 0.7406723499298096
Validation Loss Energy: 2.4481569671373533, Validation Loss Force: 4.8688817635038415, time: 0.0634927749633789
Test Loss Energy: 7.091426220949889, Test Loss Force: 8.279115291088532, time: 7.937975883483887


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.066060186363946, Training Loss Force: 4.416398998499685, time: 0.7163009643554688
Validation Loss Energy: 2.1981036356396473, Validation Loss Force: 4.6104797863832925, time: 0.06349539756774902
Test Loss Energy: 7.104311988828554, Test Loss Force: 8.295070969336924, time: 9.22877049446106


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0777553810111744, Training Loss Force: 4.405235109753352, time: 0.7341940402984619
Validation Loss Energy: 1.9871121504008964, Validation Loss Force: 4.699725357402004, time: 0.061652421951293945
Test Loss Energy: 6.131309434026542, Test Loss Force: 8.262290802133395, time: 7.933392286300659


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.068192668981683, Training Loss Force: 4.471958513115004, time: 0.7164394855499268
Validation Loss Energy: 1.937062249797843, Validation Loss Force: 4.722079780969132, time: 0.0612637996673584
Test Loss Energy: 6.467361154136604, Test Loss Force: 8.254239272345776, time: 7.922861337661743


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0500206622494317, Training Loss Force: 4.4314960061792155, time: 0.768841028213501
Validation Loss Energy: 2.27702526304199, Validation Loss Force: 4.5277864776526515, time: 0.06515097618103027
Test Loss Energy: 7.2381798679586336, Test Loss Force: 8.299387393243629, time: 7.93128514289856


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9983246948297162, Training Loss Force: 4.410435102318204, time: 0.7361795902252197
Validation Loss Energy: 2.4076128123739573, Validation Loss Force: 4.609508058230463, time: 0.06404733657836914
Test Loss Energy: 6.945467614709584, Test Loss Force: 8.316654921519126, time: 8.133630990982056


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.064251561174351, Training Loss Force: 4.471953980560833, time: 0.7153544425964355
Validation Loss Energy: 1.9089757100743818, Validation Loss Force: 4.898707850262577, time: 0.06079864501953125
Test Loss Energy: 5.84914956486757, Test Loss Force: 8.293843565709063, time: 7.940875291824341


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.045570728228536, Training Loss Force: 4.471016142652014, time: 0.7614438533782959
Validation Loss Energy: 1.9025023283312557, Validation Loss Force: 4.73977218062797, time: 0.06104135513305664
Test Loss Energy: 5.750660744621269, Test Loss Force: 8.21860837582376, time: 7.924928188323975


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.063988831374969, Training Loss Force: 4.414687612926117, time: 0.7354328632354736
Validation Loss Energy: 2.478395882492639, Validation Loss Force: 4.683638402285304, time: 0.06074047088623047
Test Loss Energy: 7.179951508577036, Test Loss Force: 8.168239710348624, time: 8.111670732498169


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.032237312140888, Training Loss Force: 4.4097509488932385, time: 0.7430481910705566
Validation Loss Energy: 2.229568789981557, Validation Loss Force: 4.721994498686241, time: 0.06111574172973633
Test Loss Energy: 6.788778920411061, Test Loss Force: 8.33790960782227, time: 7.970114469528198


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0755818258324195, Training Loss Force: 4.430837756598227, time: 0.7373671531677246
Validation Loss Energy: 2.141200980736093, Validation Loss Force: 4.6631334686442525, time: 0.06107592582702637
Test Loss Energy: 5.963248494837472, Test Loss Force: 8.258647641122641, time: 7.941072225570679


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0792607135053043, Training Loss Force: 4.4338344726015455, time: 0.7770931720733643
Validation Loss Energy: 1.9836154654678195, Validation Loss Force: 4.761848713100981, time: 0.0635066032409668
Test Loss Energy: 6.125472039956304, Test Loss Force: 8.309608214814775, time: 7.9723851680755615

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.040 MB of 0.058 MB uploadedwandb: / 0.040 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–‡â–ƒâ–‚â–ˆâ–ˆâ–‚â–ƒâ–‡â–‡â–ƒâ–„â–ˆâ–‡â–â–â–ˆâ–†â–‚â–ƒ
wandb:   test_error_force â–ˆâ–…â–ƒâ–„â–„â–„â–ƒâ–„â–…â–…â–„â–„â–…â–†â–…â–ƒâ–â–‡â–„â–†
wandb:          test_loss â–„â–†â–‚â–â–‡â–‡â–‚â–ƒâ–‡â–‡â–ƒâ–…â–ˆâ–‡â–‚â–â–†â–‡â–‚â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–…â–„â–â–†â–†â–ƒâ–ƒâ–‡â–…â–„â–ƒâ–†â–‡â–ƒâ–ƒâ–ˆâ–†â–…â–ƒ
wandb:  valid_error_force â–†â–„â–„â–…â–„â–†â–„â–…â–‡â–ƒâ–„â–…â–â–ƒâ–ˆâ–…â–„â–…â–„â–…
wandb:         valid_loss â–†â–ƒâ–ƒâ–â–„â–…â–ƒâ–…â–ˆâ–ƒâ–„â–ƒâ–„â–†â–„â–ƒâ–†â–„â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1418
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.12547
wandb:   test_error_force 8.30961
wandb:          test_loss 5.8401
wandb: train_error_energy 2.07926
wandb:  train_error_force 4.43383
wandb:         train_loss 1.07495
wandb: valid_error_energy 1.98362
wandb:  valid_error_force 4.76185
wandb:         valid_loss 1.29521
wandb: 
wandb: ğŸš€ View run al_73_89 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/izb9p7my
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_005349-izb9p7my/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.7979307174682617, Uncertainty Bias: 0.10304589569568634
0.00031280518 0.0071189404
3.2518642 9.652381
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 822 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3994 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3989 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3699 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_013832-3qa0y85b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_90
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3qa0y85b
Training model 90. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.670878971510199, Training Loss Force: 5.811576323908939, time: 0.7802512645721436
Validation Loss Energy: 2.2222799381587572, Validation Loss Force: 5.514858761327401, time: 0.06194949150085449
Test Loss Energy: 6.641034724460525, Test Loss Force: 8.789399233927702, time: 7.9804182052612305


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.05805942322271, Training Loss Force: 4.686658033417841, time: 0.746384859085083
Validation Loss Energy: 2.909425900369187, Validation Loss Force: 4.664306712374145, time: 0.06239628791809082
Test Loss Energy: 6.168478090665176, Test Loss Force: 8.206594855451012, time: 7.995701313018799


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.967613227591461, Training Loss Force: 4.44496308560696, time: 0.7790701389312744
Validation Loss Energy: 3.162552400084415, Validation Loss Force: 4.760393792901489, time: 0.06379008293151855
Test Loss Energy: 7.106102908608602, Test Loss Force: 8.123215631320544, time: 9.32227611541748


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.010802318219134, Training Loss Force: 4.419348533385083, time: 0.7562098503112793
Validation Loss Energy: 2.6614274710846755, Validation Loss Force: 4.784361231761718, time: 0.06564116477966309
Test Loss Energy: 5.9741961224906115, Test Loss Force: 8.169211956119783, time: 8.084178924560547


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0003067709143028, Training Loss Force: 4.421929951638434, time: 0.7615056037902832
Validation Loss Energy: 3.409603483487577, Validation Loss Force: 4.737823157593665, time: 0.06350493431091309
Test Loss Energy: 7.963441290588773, Test Loss Force: 8.20269818736633, time: 8.027015209197998


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9895788287700706, Training Loss Force: 4.4052005811911235, time: 0.7318332195281982
Validation Loss Energy: 2.401826086609586, Validation Loss Force: 4.656330703567012, time: 0.061661481857299805
Test Loss Energy: 6.031978770522099, Test Loss Force: 8.171264704504457, time: 8.00314736366272


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.061619648033627, Training Loss Force: 4.430549395106046, time: 0.7345740795135498
Validation Loss Energy: 2.737887936417078, Validation Loss Force: 4.752533572050238, time: 0.06522655487060547
Test Loss Energy: 7.332850698106226, Test Loss Force: 8.227123784898506, time: 8.257197618484497


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9973373887856978, Training Loss Force: 4.419718362095453, time: 0.7343535423278809
Validation Loss Energy: 2.8884775211240195, Validation Loss Force: 4.7106256801026065, time: 0.06647419929504395
Test Loss Energy: 5.835963862815151, Test Loss Force: 8.140778355929958, time: 8.022685050964355


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.98981802491483, Training Loss Force: 4.414161153790298, time: 0.7799344062805176
Validation Loss Energy: 3.0476143723319717, Validation Loss Force: 4.740647270371467, time: 0.0639810562133789
Test Loss Energy: 7.499779755233613, Test Loss Force: 8.288602614845237, time: 8.025381565093994


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9914306369293664, Training Loss Force: 4.4368715263577, time: 0.6897730827331543
Validation Loss Energy: 2.675431245006647, Validation Loss Force: 4.747616146631568, time: 0.06672501564025879
Test Loss Energy: 5.856892493871852, Test Loss Force: 8.203245337919192, time: 8.198520183563232


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.949726749505031, Training Loss Force: 4.420199584757226, time: 0.747800350189209
Validation Loss Energy: 3.4399142096424242, Validation Loss Force: 4.6974158330204405, time: 0.0636293888092041
Test Loss Energy: 8.02455909574088, Test Loss Force: 8.235107217564913, time: 8.044609069824219


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.030214653946744, Training Loss Force: 4.464486755907535, time: 0.7162051200866699
Validation Loss Energy: 2.87300056813259, Validation Loss Force: 4.60618583457322, time: 0.06595087051391602
Test Loss Energy: 6.078744949994342, Test Loss Force: 8.202542309637725, time: 8.014457702636719


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.03773442604438, Training Loss Force: 4.432003226700825, time: 0.7566869258880615
Validation Loss Energy: 2.9430624128876115, Validation Loss Force: 4.759149072375752, time: 0.06465339660644531
Test Loss Energy: 7.219926575213468, Test Loss Force: 8.22312007707402, time: 8.035850524902344


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.956206325161567, Training Loss Force: 4.431338217874208, time: 0.7329709529876709
Validation Loss Energy: 2.503114161712937, Validation Loss Force: 4.648075022312594, time: 0.06107735633850098
Test Loss Energy: 6.1496478516706485, Test Loss Force: 8.151374562706925, time: 8.247637033462524


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.037122991414272, Training Loss Force: 4.411419344477033, time: 0.7173247337341309
Validation Loss Energy: 3.244855369802244, Validation Loss Force: 4.633035502858339, time: 0.06329488754272461
Test Loss Energy: 7.667933896032839, Test Loss Force: 8.210060156275485, time: 8.043917655944824


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0338411104580687, Training Loss Force: 4.416384094511518, time: 0.760716438293457
Validation Loss Energy: 2.8969134530520666, Validation Loss Force: 4.791121689701232, time: 0.0694277286529541
Test Loss Energy: 5.812279807166036, Test Loss Force: 8.115924846589659, time: 7.975998163223267


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.948648004086568, Training Loss Force: 4.421318912864585, time: 0.7705347537994385
Validation Loss Energy: 3.3869752882055306, Validation Loss Force: 4.943548962869515, time: 0.06177544593811035
Test Loss Energy: 7.500094530131075, Test Loss Force: 8.184890554675762, time: 8.201727867126465


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.984283387838767, Training Loss Force: 4.452954631772276, time: 0.7635807991027832
Validation Loss Energy: 2.5359294704211797, Validation Loss Force: 4.740808928171409, time: 0.06449031829833984
Test Loss Energy: 5.852108497401294, Test Loss Force: 8.100240862005123, time: 8.091324090957642


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9965264599195507, Training Loss Force: 4.447384365158763, time: 0.7686645984649658
Validation Loss Energy: 3.0873835271329666, Validation Loss Force: 4.646094825597858, time: 0.06243252754211426
Test Loss Energy: 7.645661313286199, Test Loss Force: 8.145148187789088, time: 8.013861179351807


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.949842643847283, Training Loss Force: 4.431144446235217, time: 0.7395291328430176
Validation Loss Energy: 2.667900685825942, Validation Loss Force: 4.690691670151713, time: 0.07005643844604492
Test Loss Energy: 5.91056318189972, Test Loss Force: 8.140088533910715, time: 8.057479858398438

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–…â–‚â–ˆâ–‚â–†â–â–†â–â–ˆâ–‚â–…â–‚â–‡â–â–†â–â–‡â–
wandb:   test_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–
wandb:          test_loss â–„â–‚â–…â–‚â–‡â–‚â–…â–â–†â–‚â–ˆâ–‚â–…â–‚â–†â–â–‡â–‚â–†â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–…â–†â–„â–ˆâ–‚â–„â–…â–†â–„â–ˆâ–…â–…â–ƒâ–‡â–…â–ˆâ–ƒâ–†â–„
wandb:  valid_error_force â–ˆâ–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–„â–‚â–â–‚
wandb:         valid_loss â–…â–ƒâ–†â–ƒâ–†â–â–ƒâ–ƒâ–„â–ƒâ–†â–„â–„â–‚â–…â–…â–ˆâ–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1421
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 5.91056
wandb:   test_error_force 8.14009
wandb:          test_loss 4.65845
wandb: train_error_energy 2.94984
wandb:  train_error_force 4.43114
wandb:         train_loss 1.42048
wandb: valid_error_energy 2.6679
wandb:  valid_error_force 4.69069
wandb:         valid_loss 1.48754
wandb: 
wandb: ğŸš€ View run al_73_90 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/3qa0y85b
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_013832-3qa0y85b/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.567296028137207, Uncertainty Bias: 0.0734701007604599
0.00020599365 0.0042352676
3.320175 10.332304
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 91.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3739 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2699 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_030228-7tyzwbh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_92
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/7tyzwbh0
Training model 92. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.956764151537082, Training Loss Force: 5.091507662135287, time: 0.718498945236206
Validation Loss Energy: 2.601337084688019, Validation Loss Force: 5.107188963550138, time: 0.06636285781860352
Test Loss Energy: 6.794063596033982, Test Loss Force: 8.348482400530514, time: 8.240978240966797


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.001575388787601, Training Loss Force: 4.472667590639703, time: 0.7661619186401367
Validation Loss Energy: 2.618682231813783, Validation Loss Force: 4.70974947701338, time: 0.0640256404876709
Test Loss Energy: 5.871395800374956, Test Loss Force: 8.127514726671304, time: 8.27029275894165


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.916074194911693, Training Loss Force: 4.409672381322149, time: 0.740044355392456
Validation Loss Energy: 3.3069567925903476, Validation Loss Force: 4.761654322936586, time: 0.06158638000488281
Test Loss Energy: 7.422715822124436, Test Loss Force: 8.132141106029142, time: 8.348617792129517


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9459786463651856, Training Loss Force: 4.411503266004033, time: 0.828040361404419
Validation Loss Energy: 2.5343999560578014, Validation Loss Force: 4.633448554124035, time: 0.06200218200683594
Test Loss Energy: 5.940292096309496, Test Loss Force: 8.15731125788979, time: 8.294128894805908


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.99248336469518, Training Loss Force: 4.400142592162935, time: 0.7245063781738281
Validation Loss Energy: 3.252808777691066, Validation Loss Force: 4.559671363334635, time: 0.06593203544616699
Test Loss Energy: 7.618793732375807, Test Loss Force: 8.144898364665426, time: 8.26282000541687


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9439135236381935, Training Loss Force: 4.390972191005249, time: 0.7685611248016357
Validation Loss Energy: 2.860921546308018, Validation Loss Force: 4.661476142191112, time: 0.06603813171386719
Test Loss Energy: 5.987200245432275, Test Loss Force: 8.184313834592968, time: 8.287237644195557


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.012217882884134, Training Loss Force: 4.407222268590051, time: 0.7254512310028076
Validation Loss Energy: 2.8778946132909367, Validation Loss Force: 4.717612592563529, time: 0.06157708168029785
Test Loss Energy: 7.529201652026012, Test Loss Force: 8.196074360846888, time: 8.422525882720947


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.072252473341024, Training Loss Force: 4.412438248799581, time: 0.7633507251739502
Validation Loss Energy: 2.724337739545361, Validation Loss Force: 4.690705920977052, time: 0.06168651580810547
Test Loss Energy: 5.767280820968828, Test Loss Force: 8.139061262046953, time: 8.209618091583252


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.025262677698932, Training Loss Force: 4.406870629474801, time: 0.7266824245452881
Validation Loss Energy: 3.0600320739275, Validation Loss Force: 4.651828778774645, time: 0.06350088119506836
Test Loss Energy: 7.441315898165343, Test Loss Force: 8.127882259000861, time: 8.267939805984497


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.994430358966156, Training Loss Force: 4.410827321648247, time: 0.746668815612793
Validation Loss Energy: 2.4239765452390447, Validation Loss Force: 4.672671501510068, time: 0.06259775161743164
Test Loss Energy: 5.811155299999731, Test Loss Force: 8.162730176194144, time: 8.464245080947876


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0243727680867236, Training Loss Force: 4.426283509504769, time: 0.7170631885528564
Validation Loss Energy: 2.965780789173759, Validation Loss Force: 4.725620888396822, time: 0.06202125549316406
Test Loss Energy: 7.464140422931805, Test Loss Force: 8.137339211152383, time: 8.278993129730225


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9563381180808386, Training Loss Force: 4.424266047871411, time: 0.7098004817962646
Validation Loss Energy: 2.6650760163752754, Validation Loss Force: 4.67316026028538, time: 0.06721878051757812
Test Loss Energy: 5.780491995905221, Test Loss Force: 8.172031120046672, time: 8.273141860961914


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9542617753029927, Training Loss Force: 4.405679725607534, time: 0.7185361385345459
Validation Loss Energy: 3.0235129979804674, Validation Loss Force: 4.568608634844739, time: 0.06173110008239746
Test Loss Energy: 7.798385620100309, Test Loss Force: 8.184859110528096, time: 8.242050886154175


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9456729389465384, Training Loss Force: 4.442033036745933, time: 0.9360103607177734
Validation Loss Energy: 2.875055247676638, Validation Loss Force: 4.740770851747456, time: 0.06439352035522461
Test Loss Energy: 6.121320234999443, Test Loss Force: 8.12926080718072, time: 8.279441118240356


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.0081071036617066, Training Loss Force: 4.416504751499391, time: 0.7464432716369629
Validation Loss Energy: 3.216706761054356, Validation Loss Force: 4.753572768954283, time: 0.06224942207336426
Test Loss Energy: 7.73093130857027, Test Loss Force: 8.124629955787054, time: 8.257493734359741


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9941936097079007, Training Loss Force: 4.419612084586204, time: 0.7191572189331055
Validation Loss Energy: 2.4556029120426057, Validation Loss Force: 4.696189816702962, time: 0.0627908706665039
Test Loss Energy: 5.988781562431774, Test Loss Force: 8.122577482532842, time: 8.223927974700928


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.999252197468682, Training Loss Force: 4.395703662946052, time: 0.7123825550079346
Validation Loss Energy: 3.0283069533577196, Validation Loss Force: 4.580506292649952, time: 0.06164741516113281
Test Loss Energy: 7.698865440670733, Test Loss Force: 8.189575993818588, time: 8.411004543304443


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.001860627963535, Training Loss Force: 4.412104423216006, time: 0.7249774932861328
Validation Loss Energy: 2.7670609345708073, Validation Loss Force: 4.684429100422494, time: 0.06277656555175781
Test Loss Energy: 5.855783557224462, Test Loss Force: 8.105646900473223, time: 8.240840673446655


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.022469429338858, Training Loss Force: 4.411463640792464, time: 0.7278163433074951
Validation Loss Energy: 3.3086351612777785, Validation Loss Force: 4.721186655024815, time: 0.06180310249328613
Test Loss Energy: 7.970303697188717, Test Loss Force: 8.21185120429431, time: 9.40327525138855


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0941102160594496, Training Loss Force: 4.407691239500594, time: 0.7454142570495605
Validation Loss Energy: 2.469845498623585, Validation Loss Force: 4.591476533462377, time: 0.06192135810852051
Test Loss Energy: 6.038418446160439, Test Loss Force: 8.137083335158536, time: 8.425659418106079

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–†â–‚â–‡â–‚â–‡â–â–†â–â–†â–â–‡â–‚â–‡â–‚â–‡â–â–ˆâ–‚
wandb:   test_error_force â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–â–ƒâ–â–„â–‚
wandb:          test_loss â–ƒâ–â–‡â–‚â–‡â–‚â–‡â–â–†â–â–…â–‚â–ˆâ–ƒâ–‡â–‚â–‡â–‚â–ˆâ–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–ˆâ–‚â–ˆâ–„â–…â–ƒâ–†â–â–…â–ƒâ–†â–…â–‡â–â–†â–„â–ˆâ–
wandb:  valid_error_force â–ˆâ–ƒâ–„â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–
wandb:         valid_loss â–…â–ƒâ–ˆâ–‚â–†â–ƒâ–„â–ƒâ–…â–â–„â–„â–„â–…â–‡â–ƒâ–„â–…â–‡â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1422
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.03842
wandb:   test_error_force 8.13708
wandb:          test_loss 4.67733
wandb: train_error_energy 3.09411
wandb:  train_error_force 4.40769
wandb:         train_loss 1.45496
wandb: valid_error_energy 2.46985
wandb:  valid_error_force 4.59148
wandb:         valid_loss 1.37633
wandb: 
wandb: ğŸš€ View run al_73_92 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/7tyzwbh0
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_030228-7tyzwbh0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3495962619781494, Uncertainty Bias: 0.10054340958595276
0.00037956238 0.009628296
3.4778311 11.242779
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 914 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_034717-rbjymtc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_93
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rbjymtc7
Training model 93. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.7451768992064105, Training Loss Force: 5.105080217463357, time: 0.7409298419952393
Validation Loss Energy: 1.8554462143952013, Validation Loss Force: 4.968952395051833, time: 0.06399655342102051
Test Loss Energy: 5.807313660339269, Test Loss Force: 8.354360087223899, time: 7.973759889602661


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2578349729866987, Training Loss Force: 4.69068399054028, time: 0.7251148223876953
Validation Loss Energy: 1.912594250697568, Validation Loss Force: 4.942240113629751, time: 0.06461358070373535
Test Loss Energy: 5.741087533527816, Test Loss Force: 8.385914767386351, time: 7.9913904666900635


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.6405957110935363, Training Loss Force: 5.103962428247205, time: 0.7443861961364746
Validation Loss Energy: 3.084699584582526, Validation Loss Force: 5.0951552548967625, time: 0.06118130683898926
Test Loss Energy: 5.726235475846679, Test Loss Force: 8.328216593733467, time: 7.95667576789856


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.005777785519792, Training Loss Force: 4.970681435814572, time: 0.9481706619262695
Validation Loss Energy: 3.6876684822084256, Validation Loss Force: 4.9105903665658674, time: 0.06367874145507812
Test Loss Energy: 5.979942014697364, Test Loss Force: 8.170221633623598, time: 7.9581732749938965


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.3627359718448435, Training Loss Force: 4.487208341103485, time: 0.7603123188018799
Validation Loss Energy: 6.442807933375406, Validation Loss Force: 4.853467714546136, time: 0.06745433807373047
Test Loss Energy: 10.299088017902394, Test Loss Force: 8.215906077058465, time: 7.9551520347595215


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.491483539223266, Training Loss Force: 4.425135605523682, time: 0.7094688415527344
Validation Loss Energy: 5.077488016851413, Validation Loss Force: 4.563984019352965, time: 0.061151742935180664
Test Loss Energy: 6.399642106479162, Test Loss Force: 8.10148718901297, time: 7.975509166717529


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.387395441669601, Training Loss Force: 4.410517534436027, time: 0.7461545467376709
Validation Loss Energy: 2.6037744211593443, Validation Loss Force: 4.667102546170415, time: 0.06516075134277344
Test Loss Energy: 7.1833773328432935, Test Loss Force: 8.201021257867698, time: 8.194186449050903


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.373259691744837, Training Loss Force: 4.42782888285954, time: 0.7197515964508057
Validation Loss Energy: 3.927902438374436, Validation Loss Force: 4.786836421987851, time: 0.06347918510437012
Test Loss Energy: 7.917891385950329, Test Loss Force: 8.155910536059903, time: 7.983361005783081


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.405722463238943, Training Loss Force: 4.4124721934738265, time: 0.7569262981414795
Validation Loss Energy: 6.135443015087649, Validation Loss Force: 4.595006284763624, time: 0.06337690353393555
Test Loss Energy: 6.941778672456104, Test Loss Force: 8.127492996027954, time: 8.000520944595337


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.556915214128374, Training Loss Force: 4.421639412936828, time: 0.7217903137207031
Validation Loss Energy: 5.758272432897259, Validation Loss Force: 4.7612989429796855, time: 0.061322689056396484
Test Loss Energy: 9.798783299445232, Test Loss Force: 8.139625773798354, time: 8.177530765533447


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.553431416790643, Training Loss Force: 4.430507226518012, time: 0.7337288856506348
Validation Loss Energy: 2.1089525876733823, Validation Loss Force: 4.675531909358657, time: 0.061257362365722656
Test Loss Energy: 5.696905316410784, Test Loss Force: 8.07431239462962, time: 7.953404426574707


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.399592557312766, Training Loss Force: 4.409654919112905, time: 0.7611346244812012
Validation Loss Energy: 3.421399158823956, Validation Loss Force: 4.6054078285773485, time: 0.06352877616882324
Test Loss Energy: 6.018746249658683, Test Loss Force: 8.124981064226937, time: 9.130929231643677


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.438692598752552, Training Loss Force: 4.4123956991998945, time: 0.7527651786804199
Validation Loss Energy: 5.644924262846741, Validation Loss Force: 4.823366854061327, time: 0.06409215927124023
Test Loss Energy: 9.558957945825227, Test Loss Force: 8.160236598859269, time: 8.006967544555664


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.472496664855084, Training Loss Force: 4.410529330952557, time: 0.726083517074585
Validation Loss Energy: 5.281275041873672, Validation Loss Force: 4.741589160858741, time: 0.0646369457244873
Test Loss Energy: 6.559992547084378, Test Loss Force: 8.131525070269502, time: 8.1518874168396


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.459573160398175, Training Loss Force: 4.412024786833015, time: 0.7311692237854004
Validation Loss Energy: 2.9642940272863987, Validation Loss Force: 4.721694563346677, time: 0.06154584884643555
Test Loss Energy: 7.293811305873894, Test Loss Force: 8.148853229837881, time: 7.935803413391113


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.3760356337640705, Training Loss Force: 4.403580767066766, time: 0.7596187591552734
Validation Loss Energy: 3.9373801279017058, Validation Loss Force: 4.66518024343362, time: 0.06635522842407227
Test Loss Energy: 8.238188594812756, Test Loss Force: 8.121673310566756, time: 7.974818468093872


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.434193491961931, Training Loss Force: 4.417256086679784, time: 0.7258176803588867
Validation Loss Energy: 5.867425293569353, Validation Loss Force: 4.75351220294659, time: 0.06128692626953125
Test Loss Energy: 6.729353181596278, Test Loss Force: 8.085293210477765, time: 8.200097560882568


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.486895174268449, Training Loss Force: 4.4261807749090405, time: 0.7514894008636475
Validation Loss Energy: 5.073091859903362, Validation Loss Force: 4.834903119842699, time: 0.06119489669799805
Test Loss Energy: 9.0218884855653, Test Loss Force: 8.14625447805448, time: 7.96302056312561


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.511888276696855, Training Loss Force: 4.407519393350174, time: 0.7350952625274658
Validation Loss Energy: 2.3097808964191247, Validation Loss Force: 4.682801388965762, time: 0.061379432678222656
Test Loss Energy: 5.995435042419258, Test Loss Force: 8.024793401972751, time: 7.977203845977783


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.470780373138, Training Loss Force: 4.421404680071394, time: 0.7211298942565918
Validation Loss Energy: 3.6006439245857713, Validation Loss Force: 4.630744237346741, time: 0.06171607971191406
Test Loss Energy: 6.181512729772094, Test Loss Force: 8.097817377653127, time: 7.962785243988037

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–ˆâ–‚â–ƒâ–„â–ƒâ–‡â–â–â–‡â–‚â–ƒâ–…â–ƒâ–†â–â–‚
wandb:   test_error_force â–‡â–ˆâ–‡â–„â–…â–‚â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚
wandb:          test_loss â–ƒâ–†â–‡â–ƒâ–ˆâ–‚â–ƒâ–„â–ƒâ–†â–â–‚â–†â–‚â–ƒâ–„â–‚â–…â–â–‚
wandb: train_error_energy â–ˆâ–â–‚â–…â–…â–…â–…â–…â–…â–†â–†â–…â–…â–…â–…â–…â–…â–…â–†â–…
wandb:  train_error_force â–ˆâ–„â–ˆâ–‡â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–‚â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–â–â–ƒâ–„â–ˆâ–†â–‚â–„â–ˆâ–‡â–â–ƒâ–‡â–†â–ƒâ–„â–‡â–†â–‚â–„
wandb:  valid_error_force â–†â–†â–ˆâ–†â–…â–â–‚â–„â–â–„â–‚â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–…â–ƒâ–‚
wandb:         valid_loss â–‚â–â–„â–„â–ˆâ–…â–‚â–„â–‡â–†â–‚â–ƒâ–†â–…â–ƒâ–ƒâ–†â–…â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1423
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.18151
wandb:   test_error_force 8.09782
wandb:          test_loss 4.06985
wandb: train_error_energy 4.47078
wandb:  train_error_force 4.4214
wandb:         train_loss 1.82832
wandb: valid_error_energy 3.60064
wandb:  valid_error_force 4.63074
wandb:         valid_loss 1.69826
wandb: 
wandb: ğŸš€ View run al_73_93 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/rbjymtc7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_034717-rbjymtc7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3472988605499268, Uncertainty Bias: 0.03876471519470215
7.05719e-05 0.00016403198
3.344499 9.446416
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1867 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_043158-zr971dyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_94
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zr971dyh
Training model 94. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.56510360229279, Training Loss Force: 4.896299203473653, time: 0.7406313419342041
Validation Loss Energy: 2.0559302766413388, Validation Loss Force: 4.760681036099735, time: 0.06753921508789062
Test Loss Energy: 6.5785286296448735, Test Loss Force: 8.229403194152438, time: 8.419680118560791


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.2207628255194267, Training Loss Force: 4.757941829541377, time: 0.7485179901123047
Validation Loss Energy: 7.942438316016704, Validation Loss Force: 4.789648955970065, time: 0.0678708553314209
Test Loss Energy: 11.41746432619196, Test Loss Force: 8.191111002630576, time: 8.404547452926636


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 6.4451869008412785, Training Loss Force: 4.746449756163165, time: 0.729719877243042
Validation Loss Energy: 6.910542065259252, Validation Loss Force: 4.898353806320552, time: 0.06282830238342285
Test Loss Energy: 7.050870048464552, Test Loss Force: 8.113649205224103, time: 8.58873987197876


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.311736189985618, Training Loss Force: 4.524192290848776, time: 0.7537150382995605
Validation Loss Energy: 6.925441525820718, Validation Loss Force: 4.69655900214691, time: 0.06971073150634766
Test Loss Energy: 10.204497008231678, Test Loss Force: 8.175497339527098, time: 8.451892852783203


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.3705475301706445, Training Loss Force: 4.48820272213076, time: 0.7252466678619385
Validation Loss Energy: 6.831591379533366, Validation Loss Force: 4.673729402622372, time: 0.0628056526184082
Test Loss Energy: 7.4814984831193225, Test Loss Force: 8.08765556457146, time: 8.452061653137207


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.378288259335884, Training Loss Force: 4.517969173144013, time: 0.7526006698608398
Validation Loss Energy: 6.5953592332579705, Validation Loss Force: 4.874138314031759, time: 0.06296992301940918
Test Loss Energy: 10.452228995813078, Test Loss Force: 8.300433359989196, time: 8.453913927078247


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.297489201977855, Training Loss Force: 4.554870482946945, time: 0.7334494590759277
Validation Loss Energy: 6.733791082597255, Validation Loss Force: 4.8267852707896095, time: 0.0631248950958252
Test Loss Energy: 7.142665569417883, Test Loss Force: 8.069105578596124, time: 9.751434564590454


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 5.240073119979102, Training Loss Force: 4.6580798637241365, time: 0.7335333824157715
Validation Loss Energy: 2.5357858488220564, Validation Loss Force: 5.198785920749847, time: 0.06521224975585938
Test Loss Energy: 6.79241562518239, Test Loss Force: 8.36368901044555, time: 8.462881326675415


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.991222973209773, Training Loss Force: 4.51363698161928, time: 0.7164602279663086
Validation Loss Energy: 3.2099766974532615, Validation Loss Force: 4.643551943951363, time: 0.0649716854095459
Test Loss Energy: 5.849219158885034, Test Loss Force: 8.110117966353064, time: 8.457276344299316


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.0907266000445732, Training Loss Force: 4.408760046452844, time: 0.7341208457946777
Validation Loss Energy: 3.1457779539796644, Validation Loss Force: 4.767962317171574, time: 0.0629122257232666
Test Loss Energy: 7.478225176725762, Test Loss Force: 8.096629756024926, time: 8.627086877822876


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.080317846698723, Training Loss Force: 4.382311806104004, time: 0.733910322189331
Validation Loss Energy: 3.0870753530350026, Validation Loss Force: 4.578991474450206, time: 0.06299996376037598
Test Loss Energy: 5.682669024022051, Test Loss Force: 8.066513961551847, time: 8.427679061889648


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.09290556113537, Training Loss Force: 4.379439384017942, time: 0.7682530879974365
Validation Loss Energy: 3.371969503126884, Validation Loss Force: 4.545512945690817, time: 0.06646370887756348
Test Loss Energy: 7.97530340760036, Test Loss Force: 8.148009959631922, time: 8.43865156173706


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.0077597496904653, Training Loss Force: 4.381251703041258, time: 0.7368566989898682
Validation Loss Energy: 2.6007598149272013, Validation Loss Force: 4.7086739850385495, time: 0.062361955642700195
Test Loss Energy: 5.906493347167928, Test Loss Force: 8.098542476993604, time: 8.619471073150635


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.988469674168578, Training Loss Force: 4.38168922317199, time: 0.7142598628997803
Validation Loss Energy: 3.478206288663907, Validation Loss Force: 4.718178394863331, time: 0.06246137619018555
Test Loss Energy: 7.536637640356182, Test Loss Force: 8.089721481912534, time: 8.439382791519165


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9645156300945286, Training Loss Force: 4.367747452710755, time: 0.7532527446746826
Validation Loss Energy: 3.279231589223441, Validation Loss Force: 4.632173105256161, time: 0.06289339065551758
Test Loss Energy: 5.841768800817206, Test Loss Force: 8.110862889076563, time: 8.434462785720825


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0756110984554224, Training Loss Force: 4.376861216734122, time: 0.7145507335662842
Validation Loss Energy: 3.102590493784959, Validation Loss Force: 4.70714402533688, time: 0.06587648391723633
Test Loss Energy: 7.486548423493382, Test Loss Force: 8.097145117351236, time: 8.55787992477417


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0342626503664274, Training Loss Force: 4.388310512895298, time: 0.7294900417327881
Validation Loss Energy: 2.7208853657723244, Validation Loss Force: 4.622870879015881, time: 0.06478452682495117
Test Loss Energy: 5.910267428310033, Test Loss Force: 8.049177025788016, time: 8.418251037597656


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.0033807184738364, Training Loss Force: 4.381712628173329, time: 0.7256381511688232
Validation Loss Energy: 3.2004780770262737, Validation Loss Force: 4.706826721803932, time: 0.0630941390991211
Test Loss Energy: 7.606642830969058, Test Loss Force: 8.174854769999076, time: 8.370961666107178


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.895504543720428, Training Loss Force: 4.387565432243805, time: 0.750889778137207
Validation Loss Energy: 2.7415958230350674, Validation Loss Force: 4.745664451567512, time: 0.06332778930664062
Test Loss Energy: 5.88040349945456, Test Loss Force: 8.169626927469686, time: 8.419897079467773


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9420204647825634, Training Loss Force: 4.377682722384702, time: 0.7487668991088867
Validation Loss Energy: 2.8721514193445943, Validation Loss Force: 4.65721937612841, time: 0.06292939186096191
Test Loss Energy: 7.404770029640761, Test Loss Force: 8.175025490783, time: 8.595057010650635

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–ƒâ–‡â–ƒâ–‡â–ƒâ–‚â–â–ƒâ–â–„â–â–ƒâ–â–ƒâ–â–ƒâ–â–ƒ
wandb:   test_error_force â–…â–„â–‚â–„â–‚â–‡â–â–ˆâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–â–„â–„â–„
wandb:          test_loss â–‚â–ˆâ–â–‚â–â–‚â–â–â–‚â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒ
wandb: train_error_energy â–„â–‚â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–†â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–†â–†â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–…â–„â–ˆâ–…â–…â–…â–…â–„â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–‡â–‡â–‡â–†â–‡â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚
wandb:  valid_error_force â–ƒâ–„â–…â–ƒâ–‚â–…â–„â–ˆâ–‚â–ƒâ–â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚
wandb:         valid_loss â–â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–â–â–â–‚â–â–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1424
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.40477
wandb:   test_error_force 8.17503
wandb:          test_loss 5.43861
wandb: train_error_energy 2.94202
wandb:  train_error_force 4.37768
wandb:         train_loss 1.40288
wandb: valid_error_energy 2.87215
wandb:  valid_error_force 4.65722
wandb:         valid_loss 1.46666
wandb: 
wandb: ğŸš€ View run al_73_94 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/zr971dyh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_043158-zr971dyh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.5582410097122192, Uncertainty Bias: 0.06540603935718536
0.0001077652 0.006095886
3.3137195 9.662359
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3680 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_051706-grluiiv2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_95
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/grluiiv2
Training model 95. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.7847476626413474, Training Loss Force: 4.726896940945491, time: 0.7396078109741211
Validation Loss Energy: 2.024545060522817, Validation Loss Force: 4.771687794652092, time: 0.06184101104736328
Test Loss Energy: 6.144644424666139, Test Loss Force: 8.169805305274293, time: 7.936640739440918


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.073643941203613, Training Loss Force: 4.42572849923624, time: 0.7278327941894531
Validation Loss Energy: 2.088391096069264, Validation Loss Force: 4.600054194301807, time: 0.061920166015625
Test Loss Energy: 6.688735202684551, Test Loss Force: 8.121799651408027, time: 7.996567964553833


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.086840002591545, Training Loss Force: 4.405742359964182, time: 0.7430722713470459
Validation Loss Energy: 2.120874627750075, Validation Loss Force: 4.753200020804, time: 0.06179046630859375
Test Loss Energy: 6.651648028963641, Test Loss Force: 8.155982760138063, time: 7.951800584793091


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.064167755930128, Training Loss Force: 4.3990511224398325, time: 0.7828464508056641
Validation Loss Energy: 1.9155960534538203, Validation Loss Force: 4.6827521790845115, time: 0.09390139579772949
Test Loss Energy: 5.940176942552647, Test Loss Force: 8.14213838176746, time: 8.123545408248901


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0502898593504515, Training Loss Force: 4.440593931004004, time: 0.7250473499298096
Validation Loss Energy: 1.8397524929902107, Validation Loss Force: 4.582850776087426, time: 0.06568264961242676
Test Loss Energy: 6.090853455662028, Test Loss Force: 8.186030443500242, time: 7.9502434730529785


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0515565449503828, Training Loss Force: 4.3855526021286835, time: 0.712592363357544
Validation Loss Energy: 2.162645800842107, Validation Loss Force: 4.706936052354583, time: 0.06159353256225586
Test Loss Energy: 6.900963788734183, Test Loss Force: 8.188981693365527, time: 7.987536191940308


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.022403596916194, Training Loss Force: 4.376167221332908, time: 0.7617771625518799
Validation Loss Energy: 2.4298904150857403, Validation Loss Force: 4.609272028935779, time: 0.061859130859375
Test Loss Energy: 7.467649014835154, Test Loss Force: 8.169293982303591, time: 8.173437595367432


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1075191847356916, Training Loss Force: 4.394381725708711, time: 0.7171778678894043
Validation Loss Energy: 2.105389101996527, Validation Loss Force: 4.753018322780923, time: 0.06219172477722168
Test Loss Energy: 5.907094327695367, Test Loss Force: 8.176981971484985, time: 7.944187641143799


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.077651674093509, Training Loss Force: 4.4218408443944375, time: 0.7417652606964111
Validation Loss Energy: 2.1710736053463275, Validation Loss Force: 4.725451437176771, time: 0.06225895881652832
Test Loss Energy: 5.9243134493306675, Test Loss Force: 8.19728558773617, time: 8.01491117477417


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0187542821799895, Training Loss Force: 4.423166695660543, time: 0.689579963684082
Validation Loss Energy: 2.2776215710147847, Validation Loss Force: 4.69073286394371, time: 0.06291937828063965
Test Loss Energy: 7.13131915647988, Test Loss Force: 8.163589697750336, time: 7.983100652694702


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0835359017286788, Training Loss Force: 4.408479023146073, time: 0.9203031063079834
Validation Loss Energy: 2.7779042539700525, Validation Loss Force: 4.8804670164973185, time: 0.06199908256530762
Test Loss Energy: 7.316870768739646, Test Loss Force: 8.155979976190833, time: 8.003335952758789


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.183544111692761, Training Loss Force: 5.049356501671629, time: 0.7327547073364258
Validation Loss Energy: 2.3545416254643823, Validation Loss Force: 5.126645793521308, time: 0.061725616455078125
Test Loss Energy: 6.83359862180578, Test Loss Force: 8.449085668333634, time: 7.969161748886108


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.00723050376884, Training Loss Force: 5.216010829010911, time: 0.7036857604980469
Validation Loss Energy: 6.070862505363358, Validation Loss Force: 4.786200701576227, time: 0.06216001510620117
Test Loss Energy: 10.08608906888789, Test Loss Force: 8.211372887652717, time: 7.990263223648071


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.509220888360362, Training Loss Force: 4.52412230346211, time: 0.7114861011505127
Validation Loss Energy: 2.3301350830483836, Validation Loss Force: 4.7823311571582945, time: 0.06402707099914551
Test Loss Energy: 6.032148297519609, Test Loss Force: 8.140869825150848, time: 8.166622877120972


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.509913624443851, Training Loss Force: 4.450292636977319, time: 0.7544436454772949
Validation Loss Energy: 3.0826512511091364, Validation Loss Force: 4.676510317585864, time: 0.06572604179382324
Test Loss Energy: 5.940538016311165, Test Loss Force: 8.135724750258545, time: 7.973236322402954


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.534356016592346, Training Loss Force: 4.438047100691321, time: 0.7401139736175537
Validation Loss Energy: 6.014323914513396, Validation Loss Force: 4.778114248872713, time: 0.06281590461730957
Test Loss Energy: 9.94142294861964, Test Loss Force: 8.154206839631478, time: 8.016858100891113


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.58171686562511, Training Loss Force: 4.414425645150033, time: 0.7160284519195557
Validation Loss Energy: 5.352690158363069, Validation Loss Force: 4.72892641186812, time: 0.06345129013061523
Test Loss Energy: 6.543569769589795, Test Loss Force: 8.06196860578376, time: 8.1978120803833


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.418980966003596, Training Loss Force: 4.438675067268464, time: 0.7059855461120605
Validation Loss Energy: 2.6728686571407367, Validation Loss Force: 4.840519726379581, time: 0.06332707405090332
Test Loss Energy: 6.917416951823631, Test Loss Force: 8.101699356569021, time: 7.95999813079834


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.546792996387707, Training Loss Force: 4.437899154362564, time: 0.7450118064880371
Validation Loss Energy: 3.473002733392721, Validation Loss Force: 4.73377325116753, time: 0.0621490478515625
Test Loss Energy: 8.091618443501554, Test Loss Force: 8.145007279022963, time: 7.982051134109497


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.460577462572952, Training Loss Force: 4.402416910078426, time: 0.7365996837615967
Validation Loss Energy: 6.202752335195284, Validation Loss Force: 4.599941078375675, time: 0.06180262565612793
Test Loss Energy: 6.988512330574968, Test Loss Force: 8.130857552470678, time: 7.930364370346069

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‚â–â–â–ƒâ–„â–â–â–ƒâ–ƒâ–ƒâ–ˆâ–â–â–ˆâ–‚â–ƒâ–…â–ƒ
wandb:   test_error_force â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–„â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚
wandb:          test_loss â–„â–†â–†â–…â–…â–†â–‡â–…â–…â–‡â–‡â–ˆâ–†â–â–â–„â–â–‚â–ƒâ–‚
wandb: train_error_energy â–†â–â–â–â–â–â–â–â–â–â–â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
wandb:  train_error_force â–„â–â–â–â–‚â–â–â–â–â–â–â–‡â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–ƒâ–ˆâ–…â–…â–…â–…â–„â–…â–„
wandb: valid_error_energy â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–ˆâ–‚â–ƒâ–ˆâ–‡â–‚â–„â–ˆ
wandb:  valid_error_force â–ƒâ–â–ƒâ–‚â–â–ƒâ–â–ƒâ–ƒâ–‚â–…â–ˆâ–„â–„â–‚â–„â–ƒâ–„â–ƒâ–
wandb:         valid_loss â–‚â–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–†â–…â–ƒâ–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1425
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 6.98851
wandb:   test_error_force 8.13086
wandb:          test_loss 4.26603
wandb: train_error_energy 4.46058
wandb:  train_error_force 4.40242
wandb:         train_loss 1.83032
wandb: valid_error_energy 6.20275
wandb:  valid_error_force 4.59994
wandb:         valid_loss 2.37178
wandb: 
wandb: ğŸš€ View run al_73_95 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/grluiiv2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_051706-grluiiv2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.1712677478790283, Uncertainty Bias: 0.0756053626537323
0.00018882751 0.03633976
3.5111172 12.032389
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 96.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 97.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2450 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_072007-dkqm8tpm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_98
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dkqm8tpm
Training model 98. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.1271181267359545, Training Loss Force: 4.7558152253890915, time: 0.7166926860809326
Validation Loss Energy: 1.9572069047607838, Validation Loss Force: 4.914587723073563, time: 0.06457233428955078
Test Loss Energy: 5.655439623236633, Test Loss Force: 8.192332344061796, time: 9.389242172241211


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.950741418165601, Training Loss Force: 4.420312186070221, time: 0.8096895217895508
Validation Loss Energy: 2.533653569080652, Validation Loss Force: 4.730545884566451, time: 0.06192660331726074
Test Loss Energy: 6.957267111561462, Test Loss Force: 8.071620131131384, time: 8.306440353393555


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0053964531842614, Training Loss Force: 4.364014483650525, time: 0.7411859035491943
Validation Loss Energy: 2.3058494499786235, Validation Loss Force: 4.7113101650571885, time: 0.0643460750579834
Test Loss Energy: 5.71460593967253, Test Loss Force: 8.09026538685858, time: 8.500759840011597


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.8468276235452667, Training Loss Force: 4.383681914099914, time: 0.7307760715484619
Validation Loss Energy: 2.4765822422990573, Validation Loss Force: 4.509006116546811, time: 0.06240200996398926
Test Loss Energy: 6.867161672741864, Test Loss Force: 8.063380444749647, time: 8.362177610397339


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.0022231654964266, Training Loss Force: 4.35977594676857, time: 0.7219500541687012
Validation Loss Energy: 2.11268407722084, Validation Loss Force: 4.582374932122578, time: 0.07142996788024902
Test Loss Energy: 5.792489787209293, Test Loss Force: 8.071191468543525, time: 8.339758396148682


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.039016065114511, Training Loss Force: 4.358388995088823, time: 0.756706714630127
Validation Loss Energy: 2.4444658920398816, Validation Loss Force: 4.657898071685198, time: 0.06240344047546387
Test Loss Energy: 6.56937535390773, Test Loss Force: 8.129979140177099, time: 8.352429628372192


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0583671915680073, Training Loss Force: 4.362472277145829, time: 0.7254910469055176
Validation Loss Energy: 2.3769646311284562, Validation Loss Force: 4.861995052158587, time: 0.062273263931274414
Test Loss Energy: 5.932100028482389, Test Loss Force: 8.14604891362954, time: 8.540724754333496


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.998414751181355, Training Loss Force: 4.36498489063309, time: 0.700681209564209
Validation Loss Energy: 2.570186339180159, Validation Loss Force: 4.525258514838933, time: 0.06295657157897949
Test Loss Energy: 7.0221910272384775, Test Loss Force: 8.138115503411896, time: 8.288673400878906


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.976486330801911, Training Loss Force: 4.370274747517034, time: 0.7616181373596191
Validation Loss Energy: 2.457202344517805, Validation Loss Force: 4.6863614232708555, time: 0.06249690055847168
Test Loss Energy: 5.84988609144872, Test Loss Force: 8.137522886384211, time: 8.345179557800293


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9712976547778758, Training Loss Force: 4.3966319755636265, time: 0.7057492733001709
Validation Loss Energy: 2.4904180123504265, Validation Loss Force: 4.822399133953124, time: 0.06286811828613281
Test Loss Energy: 6.924766311363773, Test Loss Force: 8.06819760143584, time: 8.465751886367798


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9459401122324325, Training Loss Force: 4.401312560182282, time: 0.7067403793334961
Validation Loss Energy: 2.25935346027915, Validation Loss Force: 4.659190888746455, time: 0.06401729583740234
Test Loss Energy: 5.841906811387014, Test Loss Force: 8.121201680994384, time: 8.320943593978882


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.947892260057086, Training Loss Force: 4.388873346273156, time: 0.7370786666870117
Validation Loss Energy: 2.4243384939357497, Validation Loss Force: 4.888849619164915, time: 0.06768465042114258
Test Loss Energy: 6.694457715796789, Test Loss Force: 8.104782473200977, time: 8.302232503890991


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.025005875847036, Training Loss Force: 4.385571553747103, time: 0.7885088920593262
Validation Loss Energy: 2.1136545806933666, Validation Loss Force: 4.6431999040316505, time: 0.06737637519836426
Test Loss Energy: 5.960259754949179, Test Loss Force: 8.142298213913568, time: 8.499901294708252


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.019420950181415, Training Loss Force: 4.36139025849092, time: 0.7103631496429443
Validation Loss Energy: 2.7708411886612234, Validation Loss Force: 4.7275852756021965, time: 0.06518101692199707
Test Loss Energy: 7.1331948094477, Test Loss Force: 8.053548867498495, time: 8.325494527816772


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9057134168703844, Training Loss Force: 4.38980675059187, time: 0.7209711074829102
Validation Loss Energy: 2.188860528057612, Validation Loss Force: 4.659947741173463, time: 0.06223607063293457
Test Loss Energy: 5.827908816953477, Test Loss Force: 8.11097946045478, time: 8.323181867599487


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.0437847821811235, Training Loss Force: 4.392846273501442, time: 0.7304661273956299
Validation Loss Energy: 2.7244429507168126, Validation Loss Force: 4.67320457144542, time: 0.06248211860656738
Test Loss Energy: 7.324387701384686, Test Loss Force: 8.14966744813224, time: 8.309287309646606


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.023921662663988, Training Loss Force: 4.362476557341634, time: 0.7419154644012451
Validation Loss Energy: 2.5327860500881174, Validation Loss Force: 4.661954880854856, time: 0.062070608139038086
Test Loss Energy: 5.737568852730285, Test Loss Force: 8.076791655853963, time: 8.517990112304688


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.936506835303368, Training Loss Force: 4.37668130996062, time: 0.7010273933410645
Validation Loss Energy: 2.6387722215013985, Validation Loss Force: 4.796319455574624, time: 0.062408447265625
Test Loss Energy: 7.331821057322543, Test Loss Force: 8.158749206270295, time: 8.333288431167603


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.985694372941666, Training Loss Force: 4.373257049404306, time: 0.7305891513824463
Validation Loss Energy: 2.2818653109324494, Validation Loss Force: 4.527414620178952, time: 0.06683182716369629
Test Loss Energy: 5.716826118933646, Test Loss Force: 8.057632265229469, time: 8.292563199996948


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9879572283443445, Training Loss Force: 4.3923647935331, time: 0.7247762680053711
Validation Loss Energy: 2.8130229636583453, Validation Loss Force: 4.7713967660783645, time: 0.06307530403137207
Test Loss Energy: 7.455600007295905, Test Loss Force: 8.143933384203786, time: 8.506797075271606

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–â–†â–‚â–…â–‚â–†â–‚â–†â–‚â–…â–‚â–‡â–‚â–‡â–â–ˆâ–â–ˆ
wandb:   test_error_force â–ˆâ–‚â–ƒâ–â–‚â–…â–†â–…â–…â–‚â–„â–„â–…â–â–„â–†â–‚â–†â–â–†
wandb:          test_loss â–â–†â–ƒâ–‡â–„â–…â–„â–‡â–…â–†â–…â–†â–„â–‡â–„â–ˆâ–ƒâ–ˆâ–„â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–‚â–‚â–â–â–â–â–â–‚â–‚â–â–‚â–‚â–â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–
wandb: valid_error_energy â–â–†â–„â–…â–‚â–…â–„â–†â–…â–…â–ƒâ–…â–‚â–ˆâ–ƒâ–‡â–†â–‡â–„â–ˆ
wandb:  valid_error_force â–ˆâ–…â–„â–â–‚â–„â–‡â–â–„â–†â–„â–ˆâ–ƒâ–…â–„â–„â–„â–†â–â–†
wandb:         valid_loss â–†â–…â–„â–‚â–‚â–„â–‡â–ƒâ–„â–†â–‚â–†â–â–ˆâ–â–†â–„â–‡â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1426
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.4556
wandb:   test_error_force 8.14393
wandb:          test_loss 5.24877
wandb: train_error_energy 2.98796
wandb:  train_error_force 4.39236
wandb:         train_loss 1.42279
wandb: valid_error_energy 2.81302
wandb:  valid_error_force 4.7714
wandb:         valid_loss 1.50573
wandb: 
wandb: ğŸš€ View run al_73_98 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/dkqm8tpm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_072007-dkqm8tpm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3976242542266846, Uncertainty Bias: 0.0773199051618576
7.6293945e-05 0.0042333603
3.3627696 9.516431
(48745, 22, 3)
Found uncertainty sample 0 after 2786 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2911 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3822 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_080456-922gmlxo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_99
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/922gmlxo
Training model 99. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.481010511191394, Training Loss Force: 5.0618108224452545, time: 0.7750496864318848
Validation Loss Energy: 2.4287666039062428, Validation Loss Force: 5.601659647792972, time: 0.0683138370513916
Test Loss Energy: 6.384754829767141, Test Loss Force: 8.81330187839808, time: 8.030436038970947


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9378258902123195, Training Loss Force: 4.55449961016569, time: 0.7400550842285156
Validation Loss Energy: 3.4211354072206044, Validation Loss Force: 4.650759744205045, time: 0.06949162483215332
Test Loss Energy: 5.872989997210708, Test Loss Force: 8.046389347977847, time: 8.031921148300171


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9690980448349458, Training Loss Force: 4.355132641913148, time: 0.726632833480835
Validation Loss Energy: 2.71051276894757, Validation Loss Force: 4.5491282019441, time: 0.062306880950927734
Test Loss Energy: 7.221997465887405, Test Loss Force: 8.122152387314545, time: 8.084553003311157


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.9322771705498276, Training Loss Force: 4.357561655506619, time: 0.9482431411743164
Validation Loss Energy: 2.608438449089948, Validation Loss Force: 4.652392354382988, time: 0.0735316276550293
Test Loss Energy: 5.810054904054768, Test Loss Force: 8.109432275953996, time: 8.064540147781372


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.938556603755697, Training Loss Force: 4.352023517576762, time: 0.7437117099761963
Validation Loss Energy: 2.8731702420217866, Validation Loss Force: 4.6352296846223116, time: 0.06436800956726074
Test Loss Energy: 7.131134100932507, Test Loss Force: 8.097606044814922, time: 8.066817045211792


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9393482494738077, Training Loss Force: 4.348948709029865, time: 0.7381155490875244
Validation Loss Energy: 2.2329044851221287, Validation Loss Force: 4.500089775936424, time: 0.06160283088684082
Test Loss Energy: 5.820969681596944, Test Loss Force: 8.106159268007039, time: 8.088014602661133


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.9521968826674505, Training Loss Force: 4.36489283425996, time: 0.7048509120941162
Validation Loss Energy: 3.000103122661641, Validation Loss Force: 4.608241516128426, time: 0.0622866153717041
Test Loss Energy: 7.47968350574506, Test Loss Force: 8.093043523703876, time: 8.254381895065308


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.8951494111736893, Training Loss Force: 4.362535638888355, time: 0.7397823333740234
Validation Loss Energy: 2.369486287862472, Validation Loss Force: 4.796399839136304, time: 0.06445789337158203
Test Loss Energy: 5.859117555532875, Test Loss Force: 8.05954174059133, time: 8.082754611968994


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.914500921112937, Training Loss Force: 4.377473829036603, time: 0.7148106098175049
Validation Loss Energy: 2.8941484589325084, Validation Loss Force: 4.741542177668951, time: 0.06226372718811035
Test Loss Energy: 7.541128795423052, Test Loss Force: 8.1612401582077, time: 8.071328401565552


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9454017427714074, Training Loss Force: 4.350215513386673, time: 0.7518665790557861
Validation Loss Energy: 3.021749681013865, Validation Loss Force: 4.793878779066109, time: 0.06444978713989258
Test Loss Energy: 5.948416398104588, Test Loss Force: 8.072239370528788, time: 8.259811162948608


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9560020039532637, Training Loss Force: 4.368030202940456, time: 0.732457160949707
Validation Loss Energy: 3.2395444880027204, Validation Loss Force: 4.901128263878812, time: 0.06588220596313477
Test Loss Energy: 7.501623779856252, Test Loss Force: 8.151189786953246, time: 8.059255361557007


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0433682622249543, Training Loss Force: 4.373832421529181, time: 0.7157082557678223
Validation Loss Energy: 2.3670604188521613, Validation Loss Force: 4.651629044550747, time: 0.06268930435180664
Test Loss Energy: 5.899709520626164, Test Loss Force: 8.117905123745082, time: 8.08410096168518


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9212004369813127, Training Loss Force: 4.3582228542167405, time: 0.7131800651550293
Validation Loss Energy: 2.9771017338910193, Validation Loss Force: 4.481856067583835, time: 0.062100887298583984
Test Loss Energy: 7.397292431325479, Test Loss Force: 8.138896356308576, time: 8.054140567779541


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.913158043079473, Training Loss Force: 4.386070194084291, time: 0.7365186214447021
Validation Loss Energy: 2.7975408892765596, Validation Loss Force: 4.617496091171477, time: 0.06982994079589844
Test Loss Energy: 5.7655897642204055, Test Loss Force: 8.141629922018867, time: 8.294927597045898


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9554213916811554, Training Loss Force: 4.37647746872803, time: 0.7116186618804932
Validation Loss Energy: 2.8640962516560835, Validation Loss Force: 4.740181669187331, time: 0.0636601448059082
Test Loss Energy: 7.300616429378789, Test Loss Force: 8.057261944289458, time: 8.098726511001587


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9502030808678987, Training Loss Force: 4.359423877159639, time: 0.746727466583252
Validation Loss Energy: 2.5907712110445997, Validation Loss Force: 4.7168521774301855, time: 0.069091796875
Test Loss Energy: 5.708349731752367, Test Loss Force: 8.150112581242055, time: 9.2073974609375


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9348351887500423, Training Loss Force: 4.357208358743284, time: 0.7454104423522949
Validation Loss Energy: 2.91959486625999, Validation Loss Force: 4.552826291119669, time: 0.0616755485534668
Test Loss Energy: 7.6035560210603785, Test Loss Force: 8.193540423272053, time: 8.298901081085205


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.918463630301526, Training Loss Force: 4.3732479743995585, time: 0.7164559364318848
Validation Loss Energy: 2.7886759852388825, Validation Loss Force: 4.714735929867287, time: 0.06200051307678223
Test Loss Energy: 5.778529406374313, Test Loss Force: 8.134572308023786, time: 8.078904390335083


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.0242193069854517, Training Loss Force: 4.366422625722719, time: 0.7462778091430664
Validation Loss Energy: 2.9918343039276127, Validation Loss Force: 4.674953414917537, time: 0.06708693504333496
Test Loss Energy: 7.2738240150435445, Test Loss Force: 8.182636858462054, time: 8.07025146484375


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.052014839165049, Training Loss Force: 4.386951963902164, time: 0.75626540184021
Validation Loss Energy: 2.2979126309411733, Validation Loss Force: 4.628134109618177, time: 0.062497615814208984
Test Loss Energy: 5.982665845918812, Test Loss Force: 8.058391676602945, time: 8.107259035110474

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‡â–â–†â–â–ˆâ–‚â–ˆâ–‚â–ˆâ–‚â–‡â–â–‡â–â–ˆâ–â–‡â–‚
wandb:   test_error_force â–ˆâ–â–‚â–‚â–â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–
wandb:          test_loss â–ˆâ–ƒâ–‡â–‚â–†â–‚â–‡â–‚â–‡â–‚â–‡â–â–†â–â–†â–â–ˆâ–‚â–†â–‚
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–â–â–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–ˆâ–„â–ƒâ–…â–â–†â–‚â–…â–†â–‡â–‚â–…â–„â–…â–ƒâ–…â–„â–…â–
wandb:  valid_error_force â–ˆâ–‚â–â–‚â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–â–‚â–ƒâ–‚â–â–‚â–‚â–‚
wandb:         valid_loss â–†â–ˆâ–‚â–ƒâ–„â–â–„â–„â–„â–†â–†â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–„â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1428
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 5.98267
wandb:   test_error_force 8.05839
wandb:          test_loss 4.6206
wandb: train_error_energy 3.05201
wandb:  train_error_force 4.38695
wandb:         train_loss 1.44104
wandb: valid_error_energy 2.29791
wandb:  valid_error_force 4.62813
wandb:         valid_loss 1.3227
wandb: 
wandb: ğŸš€ View run al_73_99 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/922gmlxo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_080456-922gmlxo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.6228851079940796, Uncertainty Bias: 0.05627760291099548
0.00016021729 0.003534317
3.2706075 8.955005
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2491 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_084947-ofyeaf5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_100
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ofyeaf5n
Training model 100. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.8317510382592, Training Loss Force: 5.119382345773957, time: 0.7679648399353027
Validation Loss Energy: 1.8110907431955319, Validation Loss Force: 4.949531860151449, time: 0.06370115280151367
Test Loss Energy: 5.844241109168321, Test Loss Force: 8.16105860008147, time: 8.186629295349121


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.5892042873173255, Training Loss Force: 4.766137014062949, time: 0.7581720352172852
Validation Loss Energy: 4.2236967998323465, Validation Loss Force: 4.993040520589155, time: 0.06388211250305176
Test Loss Energy: 6.42692750797188, Test Loss Force: 8.564452749219297, time: 8.228508710861206


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.737499942852604, Training Loss Force: 4.98315571764008, time: 0.7349531650543213
Validation Loss Energy: 2.480390664036433, Validation Loss Force: 5.004024344219481, time: 0.06185483932495117
Test Loss Energy: 6.08317414474829, Test Loss Force: 8.331890336194672, time: 8.211870431900024


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1968908186543197, Training Loss Force: 4.924308250623179, time: 0.8814947605133057
Validation Loss Energy: 2.2021454146419557, Validation Loss Force: 4.880059309291124, time: 0.06138110160827637
Test Loss Energy: 6.831026930735544, Test Loss Force: 8.350408337087872, time: 8.173895359039307


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.003604796330968, Training Loss Force: 4.441362753134657, time: 0.742016077041626
Validation Loss Energy: 2.121664546545254, Validation Loss Force: 4.715853283641553, time: 0.06443309783935547
Test Loss Energy: 6.595766683986614, Test Loss Force: 8.111706131303157, time: 8.129979372024536


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9871483192924997, Training Loss Force: 4.360879277334846, time: 0.7585234642028809
Validation Loss Energy: 1.8073699974343649, Validation Loss Force: 4.630014995893829, time: 0.06479930877685547
Test Loss Energy: 5.962377926093704, Test Loss Force: 8.113175743003053, time: 8.200665950775146


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.002727269597375, Training Loss Force: 4.375012859946589, time: 0.7252459526062012
Validation Loss Energy: 1.855844124158974, Validation Loss Force: 4.6641285770574035, time: 0.06651473045349121
Test Loss Energy: 5.9550374546664875, Test Loss Force: 8.159640988039088, time: 8.257493019104004


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9836612635629334, Training Loss Force: 4.380545109514587, time: 0.6972939968109131
Validation Loss Energy: 2.392790061333263, Validation Loss Force: 4.8421612433233605, time: 0.06136894226074219
Test Loss Energy: 6.538690927721145, Test Loss Force: 8.136837844173863, time: 8.14130187034607


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0089046659041743, Training Loss Force: 4.35346677486121, time: 0.7051141262054443
Validation Loss Energy: 2.0529367126434854, Validation Loss Force: 4.755308474946789, time: 0.06114053726196289
Test Loss Energy: 6.653208769468767, Test Loss Force: 8.126081581415832, time: 8.191321611404419


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0193526906650607, Training Loss Force: 4.358786964231034, time: 0.7659106254577637
Validation Loss Energy: 1.8201840501096442, Validation Loss Force: 4.562889155162438, time: 0.06681394577026367
Test Loss Energy: 6.035180603617241, Test Loss Force: 8.124311387353462, time: 8.344069719314575


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0463676561536084, Training Loss Force: 4.378449624612497, time: 0.7811005115509033
Validation Loss Energy: 2.1062641917400233, Validation Loss Force: 4.656319124771423, time: 0.06172800064086914
Test Loss Energy: 5.982161053799186, Test Loss Force: 8.130587598190933, time: 9.292123556137085


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.94410130889864, Training Loss Force: 4.3475747760728485, time: 0.7102229595184326
Validation Loss Energy: 2.0562139571332505, Validation Loss Force: 4.70628719446335, time: 0.06237173080444336
Test Loss Energy: 6.441664915524812, Test Loss Force: 8.14237874320113, time: 8.044000148773193


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.015497817669743, Training Loss Force: 4.3778798637501, time: 0.7233021259307861
Validation Loss Energy: 2.230310723575789, Validation Loss Force: 4.809871099795789, time: 0.06150317192077637
Test Loss Energy: 7.122840514627772, Test Loss Force: 8.21808001808049, time: 8.157470226287842


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9671989476446394, Training Loss Force: 4.36544544959812, time: 0.893047571182251
Validation Loss Energy: 2.129765584077826, Validation Loss Force: 4.5572277921272235, time: 0.08643817901611328
Test Loss Energy: 6.022935089973806, Test Loss Force: 8.140146539806134, time: 8.144252300262451


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9993684836663708, Training Loss Force: 4.343000894508922, time: 0.7418427467346191
Validation Loss Energy: 1.736529033337742, Validation Loss Force: 4.607652778906592, time: 0.06207752227783203
Test Loss Energy: 5.874930287184427, Test Loss Force: 8.15123026843714, time: 8.148443698883057


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0090701659839363, Training Loss Force: 4.383565972749732, time: 0.7143750190734863
Validation Loss Energy: 2.096258887671477, Validation Loss Force: 4.553638365494868, time: 0.06495094299316406
Test Loss Energy: 6.98749183438176, Test Loss Force: 8.199170128816913, time: 8.199689149856567


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9459196523594038, Training Loss Force: 4.380971654530526, time: 0.7459168434143066
Validation Loss Energy: 2.3182826270797934, Validation Loss Force: 4.805769756796945, time: 0.061537742614746094
Test Loss Energy: 7.064049541428642, Test Loss Force: 8.200425707669483, time: 8.362873077392578


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0074769509261117, Training Loss Force: 4.366737108779818, time: 0.7269539833068848
Validation Loss Energy: 2.0361055972410957, Validation Loss Force: 4.5945409062486355, time: 0.0627589225769043
Test Loss Energy: 5.7862095030419995, Test Loss Force: 8.198764712421568, time: 8.191830396652222


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.969562046222713, Training Loss Force: 4.367228772150432, time: 0.7359180450439453
Validation Loss Energy: 1.8989654516173387, Validation Loss Force: 4.646781759913045, time: 0.06285905838012695
Test Loss Energy: 5.77020300260121, Test Loss Force: 8.165972975748906, time: 8.197790145874023


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9562705216237184, Training Loss Force: 4.3777895738855275, time: 0.6990032196044922
Validation Loss Energy: 2.3958126836546603, Validation Loss Force: 4.577916650482813, time: 0.062211036682128906
Test Loss Energy: 7.250977785281485, Test Loss Force: 8.169087615803404, time: 8.33787989616394

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–‚â–†â–…â–‚â–‚â–…â–…â–‚â–‚â–„â–‡â–‚â–â–‡â–‡â–â–â–ˆ
wandb:   test_error_force â–‚â–ˆâ–„â–…â–â–â–‚â–â–â–â–â–â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚
wandb:          test_loss â–â–„â–…â–‡â–†â–…â–…â–†â–†â–…â–…â–†â–‡â–†â–…â–‡â–‡â–…â–…â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–…â–‡â–†â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–„â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–â–ˆâ–ƒâ–‚â–‚â–â–â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–â–ƒ
wandb:  valid_error_force â–‡â–ˆâ–ˆâ–†â–„â–‚â–ƒâ–…â–„â–â–ƒâ–ƒâ–…â–â–‚â–â–…â–‚â–‚â–
wandb:         valid_loss â–ƒâ–ˆâ–„â–ƒâ–‚â–â–â–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–â–â–ƒâ–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1429
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.25098
wandb:   test_error_force 8.16909
wandb:          test_loss 7.00933
wandb: train_error_energy 1.95627
wandb:  train_error_force 4.37779
wandb:         train_loss 0.99477
wandb: valid_error_energy 2.39581
wandb:  valid_error_force 4.57792
wandb:         valid_loss 1.38117
wandb: 
wandb: ğŸš€ View run al_73_100 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/ofyeaf5n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_084947-ofyeaf5n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8600777387619019, Uncertainty Bias: 0.10144658386707306
0.00039672852 0.009220123
3.2726521 9.433007
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3909 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1051 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1961 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 133 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_093352-auikk0bw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_101
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/auikk0bw
Training model 101. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.721160658112358, Training Loss Force: 4.677786884747672, time: 0.7340466976165771
Validation Loss Energy: 2.45863744716331, Validation Loss Force: 4.750706349038754, time: 0.06293559074401855
Test Loss Energy: 7.13561462850234, Test Loss Force: 8.249867300064908, time: 7.969701051712036


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0907108236459147, Training Loss Force: 4.4473117997582055, time: 0.7708451747894287
Validation Loss Energy: 2.6058319954022906, Validation Loss Force: 4.780678061418926, time: 0.06264925003051758
Test Loss Energy: 6.998441110486063, Test Loss Force: 8.300215946301433, time: 8.067821502685547


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0410094472641687, Training Loss Force: 4.37915011700457, time: 0.7307398319244385
Validation Loss Energy: 1.912282847896988, Validation Loss Force: 4.863722074054403, time: 0.061502933502197266
Test Loss Energy: 5.978263252550055, Test Loss Force: 8.196908934132281, time: 8.078519582748413


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0395218862419853, Training Loss Force: 4.388298132490785, time: 0.8706874847412109
Validation Loss Energy: 1.9607228505749836, Validation Loss Force: 4.7210341266598554, time: 0.09530520439147949
Test Loss Energy: 5.865180451660164, Test Loss Force: 8.159376471083412, time: 8.044159650802612


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0048265844087756, Training Loss Force: 4.4055858977776445, time: 0.7404248714447021
Validation Loss Energy: 2.574785904393017, Validation Loss Force: 4.788552087757225, time: 0.0682070255279541
Test Loss Energy: 7.091202495582778, Test Loss Force: 8.223508169576652, time: 8.012516498565674


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0208508358939805, Training Loss Force: 4.401032991647265, time: 0.7316880226135254
Validation Loss Energy: 2.015123093949315, Validation Loss Force: 4.60686007674709, time: 0.06610822677612305
Test Loss Energy: 6.778384395921567, Test Loss Force: 8.298251295623666, time: 8.036279678344727


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0181963005154127, Training Loss Force: 4.394353901961876, time: 0.7193572521209717
Validation Loss Energy: 2.1123997287214906, Validation Loss Force: 4.748942364064714, time: 0.06166696548461914
Test Loss Energy: 5.6525651557550605, Test Loss Force: 8.243007094508666, time: 9.408624172210693


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.118693432545513, Training Loss Force: 4.421763588097207, time: 0.7126989364624023
Validation Loss Energy: 1.825467320935073, Validation Loss Force: 4.786942412501313, time: 0.06706118583679199
Test Loss Energy: 5.909607259758831, Test Loss Force: 8.335975477972989, time: 8.029532670974731


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0137650929696895, Training Loss Force: 4.422274297102103, time: 0.7282865047454834
Validation Loss Energy: 2.144662372609541, Validation Loss Force: 4.833913132819903, time: 0.06208181381225586
Test Loss Energy: 6.9248553720273005, Test Loss Force: 8.254781736354309, time: 8.030861854553223


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.071213509949913, Training Loss Force: 4.401097372719657, time: 0.6989657878875732
Validation Loss Energy: 2.336418472342747, Validation Loss Force: 4.876695223834448, time: 0.06487894058227539
Test Loss Energy: 7.002633037858246, Test Loss Force: 8.259514413998668, time: 8.236244201660156


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0664285405097496, Training Loss Force: 4.397871322340643, time: 0.7219929695129395
Validation Loss Energy: 2.1506830123117093, Validation Loss Force: 4.73651920707511, time: 0.06241583824157715
Test Loss Energy: 5.612107445001277, Test Loss Force: 8.133925583559448, time: 8.037922620773315


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0481204235508965, Training Loss Force: 4.426496212969365, time: 0.702439546585083
Validation Loss Energy: 2.0397936663050977, Validation Loss Force: 4.619178356568961, time: 0.06434035301208496
Test Loss Energy: 5.895803486447669, Test Loss Force: 8.166597447288336, time: 8.052507400512695


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9900601117576637, Training Loss Force: 4.419009230140518, time: 0.7372281551361084
Validation Loss Energy: 2.432112875831246, Validation Loss Force: 4.721155926682678, time: 0.06229567527770996
Test Loss Energy: 7.037161015628849, Test Loss Force: 8.249787847983058, time: 8.061568975448608


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.02481128622779, Training Loss Force: 4.427182390209457, time: 0.7418386936187744
Validation Loss Energy: 2.238187421943838, Validation Loss Force: 4.669013492780767, time: 0.06270289421081543
Test Loss Energy: 6.730643088803148, Test Loss Force: 8.186600732991367, time: 8.28018856048584


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.071206988218039, Training Loss Force: 4.417547793157357, time: 0.7392399311065674
Validation Loss Energy: 2.118284651579216, Validation Loss Force: 4.606820664308261, time: 0.06267380714416504
Test Loss Energy: 5.942344240806122, Test Loss Force: 8.240109956743263, time: 8.014744281768799


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0764788311680777, Training Loss Force: 4.389124106368893, time: 0.7223250865936279
Validation Loss Energy: 2.1615511593207257, Validation Loss Force: 4.9024631654086495, time: 0.06348252296447754
Test Loss Energy: 5.543338373589747, Test Loss Force: 8.129758424923782, time: 8.038987874984741


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0684119609788985, Training Loss Force: 4.401659003684126, time: 0.7725028991699219
Validation Loss Energy: 2.4674872096990637, Validation Loss Force: 4.683538201169637, time: 0.06160402297973633
Test Loss Energy: 7.060388329061575, Test Loss Force: 8.225644758140902, time: 8.232879161834717


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.019893991936506, Training Loss Force: 4.407158535732283, time: 0.7603394985198975
Validation Loss Energy: 2.048335644413893, Validation Loss Force: 4.697222333532629, time: 0.06167960166931152
Test Loss Energy: 6.877975535694458, Test Loss Force: 8.238029163704272, time: 8.084129810333252


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.040180608376383, Training Loss Force: 4.388075309950557, time: 0.7318525314331055
Validation Loss Energy: 2.0154103928148484, Validation Loss Force: 4.646364032595285, time: 0.0622861385345459
Test Loss Energy: 6.009532848588908, Test Loss Force: 8.169355476293694, time: 8.01536226272583


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0097620237613496, Training Loss Force: 4.402831871350573, time: 0.7624626159667969
Validation Loss Energy: 1.994643711592758, Validation Loss Force: 4.956758364613389, time: 0.06266355514526367
Test Loss Energy: 5.907754626816958, Test Loss Force: 8.265135357337762, time: 8.067042112350464

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‡â–ƒâ–‚â–ˆâ–†â–â–ƒâ–‡â–‡â–â–ƒâ–ˆâ–†â–ƒâ–â–ˆâ–‡â–ƒâ–ƒ
wandb:   test_error_force â–…â–‡â–ƒâ–‚â–„â–‡â–…â–ˆâ–…â–…â–â–‚â–…â–ƒâ–…â–â–„â–…â–‚â–†
wandb:          test_loss â–‡â–‡â–ƒâ–ƒâ–‡â–†â–‚â–‚â–†â–‡â–‚â–ƒâ–ˆâ–„â–‚â–â–‡â–‡â–ƒâ–„
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–â–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‡â–ˆâ–‚â–‚â–ˆâ–ƒâ–„â–â–„â–†â–„â–ƒâ–†â–…â–„â–„â–‡â–ƒâ–ƒâ–ƒ
wandb:  valid_error_force â–„â–„â–†â–ƒâ–…â–â–„â–…â–†â–†â–„â–â–ƒâ–‚â–â–‡â–ƒâ–ƒâ–‚â–ˆ
wandb:         valid_loss â–„â–‡â–‚â–‚â–ˆâ–â–ƒâ–â–ƒâ–„â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–…â–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1432
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 5.90775
wandb:   test_error_force 8.26514
wandb:          test_loss 6.03632
wandb: train_error_energy 2.00976
wandb:  train_error_force 4.40283
wandb:         train_loss 1.02842
wandb: valid_error_energy 1.99464
wandb:  valid_error_force 4.95676
wandb:         valid_loss 1.35116
wandb: 
wandb: ğŸš€ View run al_73_101 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/auikk0bw
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_093352-auikk0bw/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.585762619972229, Uncertainty Bias: 0.1459822952747345
7.6293945e-06 0.0051056147
3.6341949 11.779862
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1001 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1887 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_101818-q9xrfegu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_102
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q9xrfegu
Training model 102. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 8.338925226421283, Training Loss Force: 5.868764638585704, time: 0.7356774806976318
Validation Loss Energy: 3.682114891039841, Validation Loss Force: 5.169270012111388, time: 0.06926083564758301
Test Loss Energy: 7.586159395975755, Test Loss Force: 8.497258125872149, time: 9.40815281867981


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.024547458506627, Training Loss Force: 4.979837650473561, time: 0.7332546710968018
Validation Loss Energy: 2.1611633810030924, Validation Loss Force: 4.904112698441683, time: 0.06556487083435059
Test Loss Energy: 5.897536577534969, Test Loss Force: 8.255225685004163, time: 8.31169319152832


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.017357636022708, Training Loss Force: 4.496133563738692, time: 0.7307476997375488
Validation Loss Energy: 3.8094413393951227, Validation Loss Force: 4.76219051023998, time: 0.06909799575805664
Test Loss Energy: 8.295371728902072, Test Loss Force: 8.193287545733929, time: 8.438560485839844


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.943711060480207, Training Loss Force: 4.380526781369777, time: 0.7312726974487305
Validation Loss Energy: 3.41399741374417, Validation Loss Force: 4.688390829866842, time: 0.06534337997436523
Test Loss Energy: 5.927190609826518, Test Loss Force: 8.101996940475773, time: 8.299967527389526


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.969111427250616, Training Loss Force: 4.388269957421521, time: 0.6917829513549805
Validation Loss Energy: 3.8088225418385893, Validation Loss Force: 4.668110792063176, time: 0.06539630889892578
Test Loss Energy: 7.746848144459479, Test Loss Force: 8.10990030551421, time: 8.316073179244995


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.9325139544455054, Training Loss Force: 4.37367730030572, time: 0.7507894039154053
Validation Loss Energy: 3.2372840621678347, Validation Loss Force: 4.689313793476712, time: 0.06318092346191406
Test Loss Energy: 6.014075497353033, Test Loss Force: 8.11791711290475, time: 8.287944078445435


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.971627034400837, Training Loss Force: 4.3740311166303965, time: 0.7010242938995361
Validation Loss Energy: 4.079953178016955, Validation Loss Force: 4.7210488228234855, time: 0.06317257881164551
Test Loss Energy: 8.404317458304558, Test Loss Force: 8.137470942685438, time: 8.454658508300781


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9784593773629613, Training Loss Force: 4.369005592763684, time: 0.7306256294250488
Validation Loss Energy: 3.406923214978044, Validation Loss Force: 4.887106787759739, time: 0.06760907173156738
Test Loss Energy: 5.948385842301894, Test Loss Force: 8.137379874502173, time: 8.27074909210205


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.951748934198384, Training Loss Force: 4.385829310602226, time: 0.7037720680236816
Validation Loss Energy: 3.575168681603892, Validation Loss Force: 4.778788491046583, time: 0.06723546981811523
Test Loss Energy: 8.046246895683192, Test Loss Force: 8.16127475469762, time: 8.28368353843689


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.991676490881589, Training Loss Force: 4.3715600235165475, time: 0.7426726818084717
Validation Loss Energy: 3.986842515963229, Validation Loss Force: 4.585225765197892, time: 0.06312441825866699
Test Loss Energy: 6.0870573011293025, Test Loss Force: 8.079835442819387, time: 8.45431661605835


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.0161694660377316, Training Loss Force: 4.37199807805323, time: 0.7379393577575684
Validation Loss Energy: 4.133953563272486, Validation Loss Force: 4.60911014846669, time: 0.06648993492126465
Test Loss Energy: 8.404405698239925, Test Loss Force: 8.143897034340068, time: 8.26109790802002


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.971280343488831, Training Loss Force: 4.372043284838057, time: 0.7307004928588867
Validation Loss Energy: 3.7696198573448347, Validation Loss Force: 4.702746755043098, time: 0.0663919448852539
Test Loss Energy: 5.907017125621119, Test Loss Force: 8.089683276084, time: 8.267903566360474


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.909887565257642, Training Loss Force: 4.359103738306234, time: 0.7185118198394775
Validation Loss Energy: 4.002673178892965, Validation Loss Force: 4.731261320532319, time: 0.06731057167053223
Test Loss Energy: 8.212972428547971, Test Loss Force: 8.121862819497048, time: 8.442212581634521


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9728017526952972, Training Loss Force: 4.37304901704357, time: 0.7268157005310059
Validation Loss Energy: 3.4474398701019187, Validation Loss Force: 4.70791824595727, time: 0.06591320037841797
Test Loss Energy: 5.9467829089081325, Test Loss Force: 8.150258666191469, time: 8.286730527877808


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.994017569955231, Training Loss Force: 4.3886314434612235, time: 0.7537586688995361
Validation Loss Energy: 3.7561609548229486, Validation Loss Force: 4.873428667463687, time: 0.06338906288146973
Test Loss Energy: 8.012450872198501, Test Loss Force: 8.22191390978732, time: 8.322697639465332


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.953026864590185, Training Loss Force: 4.396128575054921, time: 0.7200279235839844
Validation Loss Energy: 3.4793823157581247, Validation Loss Force: 4.662903451416509, time: 0.0635061264038086
Test Loss Energy: 5.975639242391178, Test Loss Force: 8.143442019849724, time: 8.305569410324097


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.001173127079076, Training Loss Force: 4.377193503426489, time: 0.7315726280212402
Validation Loss Energy: 4.015567281126206, Validation Loss Force: 4.678082361756114, time: 0.06341361999511719
Test Loss Energy: 7.973609765091907, Test Loss Force: 8.097926021543426, time: 8.467854738235474


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.907826519850121, Training Loss Force: 4.368688571278322, time: 0.7403271198272705
Validation Loss Energy: 3.245465928600378, Validation Loss Force: 4.757999208906181, time: 0.06400275230407715
Test Loss Energy: 5.905571739391654, Test Loss Force: 8.113800764803408, time: 8.28572392463684


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.934778959842492, Training Loss Force: 4.3576257050493945, time: 0.7437076568603516
Validation Loss Energy: 4.283604374860197, Validation Loss Force: 4.825492676397499, time: 0.064605712890625
Test Loss Energy: 8.563614167889275, Test Loss Force: 8.162016487773041, time: 8.283477783203125


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0250573421089637, Training Loss Force: 4.368647738705162, time: 0.7138514518737793
Validation Loss Energy: 3.4906704167763607, Validation Loss Force: 4.595739534261164, time: 0.07647371292114258
Test Loss Energy: 5.935813249833425, Test Loss Force: 8.087258057011116, time: 8.441577434539795

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‡â–â–†â–â–ˆâ–â–‡â–â–ˆâ–â–‡â–â–‡â–â–†â–â–ˆâ–
wandb:   test_error_force â–ˆâ–„â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–
wandb:          test_loss â–ˆâ–â–‡â–â–…â–‚â–‡â–‚â–†â–â–‡â–â–‡â–â–†â–‚â–†â–‚â–‡â–
wandb: train_error_energy â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–â–†â–…â–†â–…â–‡â–…â–†â–‡â–ˆâ–†â–‡â–…â–†â–…â–‡â–…â–ˆâ–…
wandb:  valid_error_force â–ˆâ–…â–ƒâ–‚â–‚â–‚â–ƒâ–…â–ƒâ–â–â–‚â–ƒâ–‚â–„â–‚â–‚â–ƒâ–„â–
wandb:         valid_loss â–ˆâ–â–…â–„â–…â–„â–†â–„â–„â–†â–†â–…â–†â–„â–…â–„â–†â–„â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1433
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 5.93581
wandb:   test_error_force 8.08726
wandb:          test_loss 4.72273
wandb: train_error_energy 3.02506
wandb:  train_error_force 4.36865
wandb:         train_loss 1.41278
wandb: valid_error_energy 3.49067
wandb:  valid_error_force 4.59574
wandb:         valid_loss 1.70695
wandb: 
wandb: ğŸš€ View run al_73_102 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/q9xrfegu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_101818-q9xrfegu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.209272861480713, Uncertainty Bias: 0.1289079487323761
0.00017547607 0.0011558533
3.6349597 11.362509
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2562 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_110306-bjxwx2ua
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_103
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bjxwx2ua
Training model 103. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.0662022860225315, Training Loss Force: 5.105138131234111, time: 0.7528400421142578
Validation Loss Energy: 2.528682146394095, Validation Loss Force: 4.963269210440318, time: 0.06600785255432129
Test Loss Energy: 5.813968972975432, Test Loss Force: 8.255564804284377, time: 8.160866260528564


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.9319575388872545, Training Loss Force: 4.673159433935439, time: 0.7589354515075684
Validation Loss Energy: 2.8526784458603442, Validation Loss Force: 4.646263386141325, time: 0.06426310539245605
Test Loss Energy: 7.230742842060194, Test Loss Force: 8.090548584706372, time: 8.173969745635986


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.8949080402936054, Training Loss Force: 4.348892848763456, time: 0.7742562294006348
Validation Loss Energy: 1.9438841644216325, Validation Loss Force: 4.673505842799861, time: 0.0637826919555664
Test Loss Energy: 5.839967447064092, Test Loss Force: 8.082005070355342, time: 8.115868330001831


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.8906925447200504, Training Loss Force: 4.343323735081299, time: 0.929762601852417
Validation Loss Energy: 2.5656485646552967, Validation Loss Force: 4.743388327557837, time: 0.06679201126098633
Test Loss Energy: 6.985254093403293, Test Loss Force: 8.061499802127667, time: 8.200582265853882


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.9359814301348397, Training Loss Force: 4.390555799702363, time: 0.7285807132720947
Validation Loss Energy: 2.077029736902018, Validation Loss Force: 4.736949626534189, time: 0.07488465309143066
Test Loss Energy: 5.777103773579448, Test Loss Force: 8.048583177668093, time: 8.15793776512146


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.0028562757308395, Training Loss Force: 4.357218339269225, time: 0.7387838363647461
Validation Loss Energy: 2.816688765807755, Validation Loss Force: 4.620828112271139, time: 0.06609511375427246
Test Loss Energy: 7.397805489017066, Test Loss Force: 8.13858384074517, time: 8.21220874786377


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.900078301579272, Training Loss Force: 4.36349117157197, time: 0.7548427581787109
Validation Loss Energy: 2.150020126264282, Validation Loss Force: 4.686676500112343, time: 0.0671529769897461
Test Loss Energy: 5.974573734387894, Test Loss Force: 8.108072483277905, time: 8.357299089431763


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.9836073445189175, Training Loss Force: 4.366420285222584, time: 0.7592275142669678
Validation Loss Energy: 2.8572175564000823, Validation Loss Force: 4.705223949291544, time: 0.06328701972961426
Test Loss Energy: 7.087182785890767, Test Loss Force: 8.140053270579166, time: 8.1816246509552


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.0105405607416893, Training Loss Force: 4.3785610878387455, time: 0.732330322265625
Validation Loss Energy: 2.634543511751084, Validation Loss Force: 4.726702169769447, time: 0.0681006908416748
Test Loss Energy: 5.963138162858569, Test Loss Force: 8.089080651768626, time: 8.21043610572815


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9775136767591897, Training Loss Force: 4.370747676990171, time: 0.7273805141448975
Validation Loss Energy: 2.5010237437709666, Validation Loss Force: 4.785367696301312, time: 0.0637814998626709
Test Loss Energy: 6.923469346361042, Test Loss Force: 8.225765400517327, time: 8.363834381103516


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.958688618533455, Training Loss Force: 4.357823984501538, time: 0.7343337535858154
Validation Loss Energy: 2.323893221549736, Validation Loss Force: 4.564494154366285, time: 0.06709671020507812
Test Loss Energy: 5.74829000837491, Test Loss Force: 8.138274109128991, time: 8.187529563903809


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.0321792019687246, Training Loss Force: 4.3442758386600655, time: 0.7781345844268799
Validation Loss Energy: 2.6022113950895043, Validation Loss Force: 4.595695000431979, time: 0.06241178512573242
Test Loss Energy: 7.274436574366568, Test Loss Force: 8.11318438862811, time: 8.182875871658325


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.023587211132704, Training Loss Force: 4.3591974176900266, time: 0.7209343910217285
Validation Loss Energy: 2.2609454333379606, Validation Loss Force: 4.721384830564691, time: 0.06850218772888184
Test Loss Energy: 5.923527438903613, Test Loss Force: 8.114419971558213, time: 8.214276552200317


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.0086393225060992, Training Loss Force: 4.36703933018928, time: 0.7415812015533447
Validation Loss Energy: 2.7066562506746736, Validation Loss Force: 4.642347749210185, time: 0.06248116493225098
Test Loss Energy: 7.125196111703823, Test Loss Force: 8.057041905204228, time: 8.368772029876709


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.9654684363181567, Training Loss Force: 4.361987773825307, time: 0.7328763008117676
Validation Loss Energy: 2.238680634102068, Validation Loss Force: 4.66976299712596, time: 0.07009458541870117
Test Loss Energy: 5.833153113683526, Test Loss Force: 8.050116307199122, time: 8.193958520889282


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.94794953303552, Training Loss Force: 4.376545902378878, time: 0.7021095752716064
Validation Loss Energy: 2.558937984604471, Validation Loss Force: 4.609657691896526, time: 0.06501340866088867
Test Loss Energy: 6.975906841363255, Test Loss Force: 8.080095408464354, time: 8.279921293258667


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.030719170275283, Training Loss Force: 4.379495175009506, time: 0.7240970134735107
Validation Loss Energy: 2.072893880185555, Validation Loss Force: 4.605224126531958, time: 0.06496214866638184
Test Loss Energy: 5.834855324873772, Test Loss Force: 8.094761820699755, time: 8.327401876449585


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9314751286567033, Training Loss Force: 4.378167972883915, time: 0.7076513767242432
Validation Loss Energy: 2.65269260582822, Validation Loss Force: 4.662879403148748, time: 0.06782841682434082
Test Loss Energy: 7.152134958398983, Test Loss Force: 8.055457615396756, time: 9.3501615524292


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9393896807795605, Training Loss Force: 4.386496551068506, time: 0.762296199798584
Validation Loss Energy: 1.8596873379504013, Validation Loss Force: 4.578872346457134, time: 0.06948113441467285
Test Loss Energy: 5.77875388718439, Test Loss Force: 8.032345947691455, time: 8.164106369018555


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.001906569556543, Training Loss Force: 4.358729411679117, time: 0.7162127494812012
Validation Loss Energy: 2.901963811950855, Validation Loss Force: 4.653800291392689, time: 0.06506657600402832
Test Loss Energy: 7.173033168886604, Test Loss Force: 8.09656809415861, time: 8.349623680114746

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‡â–â–†â–â–ˆâ–‚â–‡â–‚â–†â–â–‡â–‚â–‡â–â–†â–â–‡â–â–‡
wandb:   test_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–„â–ƒâ–‡â–„â–„â–„â–‚â–‚â–‚â–ƒâ–‚â–â–ƒ
wandb:          test_loss â–â–ˆâ–ƒâ–‡â–‚â–ˆâ–ƒâ–ˆâ–‚â–†â–‚â–‡â–ƒâ–ˆâ–‚â–†â–‚â–ˆâ–‚â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–…â–ˆâ–‚â–†â–‚â–‡â–ƒâ–ˆâ–†â–…â–„â–†â–„â–‡â–„â–†â–‚â–†â–â–ˆ
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–„â–„â–‚â–ƒâ–ƒâ–„â–…â–â–‚â–„â–‚â–ƒâ–‚â–‚â–ƒâ–â–ƒ
wandb:         valid_loss â–ˆâ–‡â–‚â–†â–…â–‡â–ƒâ–‡â–ˆâ–†â–„â–…â–„â–†â–„â–…â–‚â–†â–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 1434
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 7.17303
wandb:   test_error_force 8.09657
wandb:          test_loss 5.32898
wandb: train_error_energy 3.00191
wandb:  train_error_force 4.35873
wandb:         train_loss 1.41142
wandb: valid_error_energy 2.90196
wandb:  valid_error_force 4.6538
wandb:         valid_loss 1.50282
wandb: 
wandb: ğŸš€ View run al_73_103 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/bjxwx2ua
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_110306-bjxwx2ua/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3165346384048462, Uncertainty Bias: 0.09662425518035889
7.1525574e-05 0.003733635
3.4269567 9.388055
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 838 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3317 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_114656-2btjpzxl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_104
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2btjpzxl
Training model 104. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.714086266945646, Training Loss Force: 4.811385809135064, time: 0.7376570701599121
Validation Loss Energy: 4.053913357415576, Validation Loss Force: 5.042739383283653, time: 0.0652015209197998
Test Loss Energy: 8.010633754402498, Test Loss Force: 8.314826567674807, time: 8.116227865219116


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7784928848055155, Training Loss Force: 4.828644558158106, time: 0.7360312938690186
Validation Loss Energy: 3.5224700201754544, Validation Loss Force: 5.49783525978293, time: 0.06547117233276367
Test Loss Energy: 5.652486955749978, Test Loss Force: 8.582745795984756, time: 8.153606414794922


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.913136699004785, Training Loss Force: 4.579139613758889, time: 0.758671760559082
Validation Loss Energy: 2.712464130007908, Validation Loss Force: 4.719825923874051, time: 0.06249189376831055
Test Loss Energy: 7.326533035833399, Test Loss Force: 8.10353982548017, time: 8.20331859588623


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.870752082312129, Training Loss Force: 4.353782979893038, time: 0.9379026889801025
Validation Loss Energy: 2.0788427090881623, Validation Loss Force: 4.512732707373058, time: 0.06339883804321289
Test Loss Energy: 5.729233665766893, Test Loss Force: 8.025014383030074, time: 8.18115520477295


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.847051972606196, Training Loss Force: 4.330934681108444, time: 0.7424075603485107
Validation Loss Energy: 2.7605505340821708, Validation Loss Force: 4.684231147551764, time: 0.06252670288085938
Test Loss Energy: 7.014057408313466, Test Loss Force: 8.083121591743376, time: 8.130205631256104


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.952920215965692, Training Loss Force: 4.332478560105837, time: 0.7591996192932129
Validation Loss Energy: 2.235388470779526, Validation Loss Force: 4.695861379712719, time: 0.06263089179992676
Test Loss Energy: 5.752654633739769, Test Loss Force: 8.014459119396587, time: 8.098844289779663


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.990437584494663, Training Loss Force: 4.343652266087403, time: 0.7453610897064209
Validation Loss Energy: 2.6250465613426908, Validation Loss Force: 4.685760884584288, time: 0.06378936767578125
Test Loss Energy: 7.433084528651076, Test Loss Force: 8.119842872259436, time: 8.312898874282837


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.904152137516289, Training Loss Force: 4.344331995818669, time: 0.7185318470001221
Validation Loss Energy: 2.1594260049919907, Validation Loss Force: 4.614430605039489, time: 0.06305480003356934
Test Loss Energy: 5.73315281294305, Test Loss Force: 8.008086706161617, time: 8.108692646026611


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.903366699319147, Training Loss Force: 4.333991681071871, time: 0.7480883598327637
Validation Loss Energy: 2.5116102143103847, Validation Loss Force: 4.770908897979636, time: 0.06510114669799805
Test Loss Energy: 6.733166513130032, Test Loss Force: 8.052932789769804, time: 8.137245416641235


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.8856770978692428, Training Loss Force: 4.352480207046856, time: 0.7467086315155029
Validation Loss Energy: 2.162321037892771, Validation Loss Force: 4.619065017973684, time: 0.06739544868469238
Test Loss Energy: 5.801649530843934, Test Loss Force: 8.163299831486235, time: 8.308078289031982


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9350307838019276, Training Loss Force: 4.354849248417025, time: 0.7376387119293213
Validation Loss Energy: 2.626137528823164, Validation Loss Force: 4.797495594003415, time: 0.0627591609954834
Test Loss Energy: 7.074591582478606, Test Loss Force: 8.136986083534696, time: 8.115700006484985


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9655374785980038, Training Loss Force: 4.361389625120906, time: 0.7525348663330078
Validation Loss Energy: 2.1930749869825874, Validation Loss Force: 4.567970465072509, time: 0.06518435478210449
Test Loss Energy: 5.7718638276412975, Test Loss Force: 8.087723022830412, time: 8.176956176757812


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9304570061502697, Training Loss Force: 4.335128847451921, time: 0.7623748779296875
Validation Loss Energy: 2.6145263348741867, Validation Loss Force: 4.739445524990893, time: 0.0626823902130127
Test Loss Energy: 6.814537161304829, Test Loss Force: 8.154339340597183, time: 8.150142192840576


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.9224916335060067, Training Loss Force: 4.347962640984038, time: 0.7325468063354492
Validation Loss Energy: 2.265218454248315, Validation Loss Force: 4.729878545136106, time: 0.06255626678466797
Test Loss Energy: 5.805846268335991, Test Loss Force: 8.141615358757237, time: 8.327558517456055


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.917252809916207, Training Loss Force: 4.35754766198785, time: 0.7190220355987549
Validation Loss Energy: 2.681341886150727, Validation Loss Force: 4.819964024173258, time: 0.06441330909729004
Test Loss Energy: 7.315951180141176, Test Loss Force: 8.131602097472694, time: 8.094174146652222


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.947703921545257, Training Loss Force: 4.354914460787562, time: 0.6987767219543457
Validation Loss Energy: 2.2296980494207683, Validation Loss Force: 4.67481380136304, time: 0.06252217292785645
Test Loss Energy: 5.902401215210562, Test Loss Force: 8.096488049846782, time: 8.141428232192993


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.065045044202585, Training Loss Force: 4.363526971822431, time: 0.7587313652038574
Validation Loss Energy: 2.7995453569282014, Validation Loss Force: 4.536003637144825, time: 0.06641864776611328
Test Loss Energy: 7.083808334077832, Test Loss Force: 8.085990554284072, time: 9.522439002990723


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.9090189180747683, Training Loss Force: 4.361038629272078, time: 0.7254197597503662
Validation Loss Energy: 1.945846547604694, Validation Loss Force: 4.56283816392802, time: 0.06426501274108887
Test Loss Energy: 5.627990549429397, Test Loss Force: 8.138782270430982, time: 8.140448808670044


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.9613936503261167, Training Loss Force: 4.3466625748050305, time: 0.7306301593780518
Validation Loss Energy: 2.538004969530373, Validation Loss Force: 4.609589332468726, time: 0.06324195861816406
Test Loss Energy: 7.156219265459452, Test Loss Force: 8.073536051074596, time: 8.133797407150269


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.0031309257518335, Training Loss Force: 4.361788672971424, time: 0.7441210746765137
Validation Loss Energy: 2.04850437195922, Validation Loss Force: 4.611691551875431, time: 0.06530642509460449
Test Loss Energy: 5.809564880378811, Test Loss Force: 8.085001450943018, time: 8.330767154693604

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–†â–â–…â–â–†â–â–„â–‚â–…â–â–„â–‚â–†â–‚â–…â–â–…â–‚
wandb:   test_error_force â–…â–ˆâ–‚â–â–‚â–â–‚â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚
wandb:          test_loss â–„â–‡â–ˆâ–‚â–…â–â–…â–â–„â–‚â–†â–â–…â–‚â–†â–‚â–„â–‚â–…â–
wandb: train_error_energy â–ˆâ–â–â–â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–â–â–‚
wandb:  train_error_force â–ˆâ–ˆâ–„â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–†â–„â–â–„â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–„â–â–ƒâ–
wandb:  valid_error_force â–…â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–‚
wandb:         valid_loss â–…â–ˆâ–ƒâ–â–ƒâ–‚â–‚â–â–‚â–â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1435
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 5.80956
wandb:   test_error_force 8.085
wandb:          test_loss 4.59379
wandb: train_error_energy 3.00313
wandb:  train_error_force 4.36179
wandb:         train_loss 1.4079
wandb: valid_error_energy 2.0485
wandb:  valid_error_force 4.61169
wandb:         valid_loss 1.25213
wandb: 
wandb: ğŸš€ View run al_73_104 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/2btjpzxl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_114656-2btjpzxl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.516226053237915, Uncertainty Bias: 0.07428446412086487
3.528595e-05 0.010904312
3.4180727 9.02529
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
No uncertainty samples found in iteration 105.
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1793 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_131046-64leljru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_106
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/64leljru
Training model 106. Added 1 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 7.642576477062941, Training Loss Force: 5.292106930923426, time: 0.741218090057373
Validation Loss Energy: 5.704892626551429, Validation Loss Force: 5.175896200555908, time: 0.0623927116394043
Test Loss Energy: 9.230643099517641, Test Loss Force: 8.565972103574262, time: 7.9818198680877686


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.497272907328169, Training Loss Force: 4.46806415840601, time: 0.7368340492248535
Validation Loss Energy: 5.850049529436024, Validation Loss Force: 4.718084428483749, time: 0.06529021263122559
Test Loss Energy: 6.773620602887129, Test Loss Force: 7.983244952819576, time: 8.023759841918945


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.429128869867295, Training Loss Force: 4.378032698903661, time: 0.7002980709075928
Validation Loss Energy: 3.1051092158291214, Validation Loss Force: 4.659605276027026, time: 0.06232261657714844
Test Loss Energy: 7.567813552140762, Test Loss Force: 8.05121741195477, time: 8.005712270736694


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.318969992468003, Training Loss Force: 4.3649812388590945, time: 0.7386188507080078
Validation Loss Energy: 4.304571792317341, Validation Loss Force: 4.684916523182929, time: 0.0977334976196289
Test Loss Energy: 8.215950776432251, Test Loss Force: 8.091551570477739, time: 8.19036602973938


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.491645756170176, Training Loss Force: 4.378466928479236, time: 0.7535786628723145
Validation Loss Energy: 5.90227256956876, Validation Loss Force: 4.625749991072728, time: 0.06979632377624512
Test Loss Energy: 6.690112244641709, Test Loss Force: 8.027412214963814, time: 8.029032230377197


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.4884286620390315, Training Loss Force: 4.381238501235007, time: 0.7293953895568848
Validation Loss Energy: 6.112570885756238, Validation Loss Force: 4.63999190964627, time: 0.06675529479980469
Test Loss Energy: 10.058786133657192, Test Loss Force: 8.07076606088894, time: 8.045334339141846


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.478053111136941, Training Loss Force: 4.375352900473437, time: 0.7055983543395996
Validation Loss Energy: 2.1421532253386535, Validation Loss Force: 4.548729624172889, time: 0.06435513496398926
Test Loss Energy: 5.855371027074516, Test Loss Force: 8.028572351525082, time: 8.244761228561401


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.365388248368632, Training Loss Force: 4.372628340596677, time: 0.7554538249969482
Validation Loss Energy: 3.4331078818588496, Validation Loss Force: 4.558282575871484, time: 0.06179237365722656
Test Loss Energy: 5.863702448481147, Test Loss Force: 8.029724336763477, time: 8.067546367645264


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.420171107847564, Training Loss Force: 4.382603463099544, time: 0.7417302131652832
Validation Loss Energy: 5.942163524392578, Validation Loss Force: 4.684990226670232, time: 0.062262535095214844
Test Loss Energy: 9.454942556651874, Test Loss Force: 8.108524699831335, time: 8.04810643196106


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.563908212879284, Training Loss Force: 4.356775183134999, time: 0.7190029621124268
Validation Loss Energy: 5.249884927033939, Validation Loss Force: 4.615823177878121, time: 0.062226295471191406
Test Loss Energy: 6.530487966592994, Test Loss Force: 8.010867682912883, time: 8.2154381275177


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.388114183035232, Training Loss Force: 4.394570860881262, time: 0.7041575908660889
Validation Loss Energy: 2.595919767036742, Validation Loss Force: 4.726682797553751, time: 0.06452703475952148
Test Loss Energy: 6.773412291820789, Test Loss Force: 8.00008609416257, time: 8.034638166427612


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.456003823470986, Training Loss Force: 4.405658953050321, time: 0.7017011642456055
Validation Loss Energy: 4.108284709468223, Validation Loss Force: 4.693415359144701, time: 0.06237196922302246
Test Loss Energy: 8.273068844498674, Test Loss Force: 8.031676709161427, time: 8.023583173751831


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.433118809018331, Training Loss Force: 4.3803345931558235, time: 0.7427635192871094
Validation Loss Energy: 6.164277333470421, Validation Loss Force: 4.6284796921326565, time: 0.06300759315490723
Test Loss Energy: 6.905609993806655, Test Loss Force: 7.971708303487686, time: 8.087098836898804


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.558935533349104, Training Loss Force: 4.413319563382756, time: 0.7719295024871826
Validation Loss Energy: 5.3122472067264965, Validation Loss Force: 4.927322394198319, time: 0.06273460388183594
Test Loss Energy: 9.11960427781182, Test Loss Force: 8.283759297448915, time: 8.235428094863892


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.495802410184869, Training Loss Force: 4.404412817338457, time: 0.7031261920928955
Validation Loss Energy: 2.371828767277632, Validation Loss Force: 4.6513838858210805, time: 0.0630025863647461
Test Loss Energy: 5.661820304375177, Test Loss Force: 7.971984058823294, time: 8.08799934387207


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.422937371181253, Training Loss Force: 4.365663551552454, time: 0.7173824310302734
Validation Loss Energy: 3.441089568729204, Validation Loss Force: 4.594648010107826, time: 0.06233549118041992
Test Loss Energy: 5.761643274205772, Test Loss Force: 8.043755743226972, time: 8.14723825454712


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.375216112342992, Training Loss Force: 4.403459605362164, time: 0.7266407012939453
Validation Loss Energy: 6.338216450157642, Validation Loss Force: 4.640322573327972, time: 0.06275582313537598
Test Loss Energy: 10.206491797353218, Test Loss Force: 8.038501422887938, time: 8.273542165756226


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.579589917572699, Training Loss Force: 4.3732317838785475, time: 0.7673492431640625
Validation Loss Energy: 5.776924091236755, Validation Loss Force: 4.74702006132792, time: 0.0693979263305664
Test Loss Energy: 6.728588423831688, Test Loss Force: 8.104947355623212, time: 8.131217956542969


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.502554589780358, Training Loss Force: 4.3735067456363454, time: 0.7585797309875488
Validation Loss Energy: 2.9759692386148306, Validation Loss Force: 4.850472369195115, time: 0.06290173530578613
Test Loss Energy: 7.5347947419031485, Test Loss Force: 8.293056263567799, time: 9.340967178344727


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.44555845589524, Training Loss Force: 4.983792472226181, time: 0.7332499027252197
Validation Loss Energy: 4.261806178819596, Validation Loss Force: 4.8180524095554675, time: 0.06457328796386719
Test Loss Energy: 8.181596130853357, Test Loss Force: 8.113356559676001, time: 8.11448860168457

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–ƒâ–„â–…â–ƒâ–ˆâ–â–â–‡â–‚â–ƒâ–…â–ƒâ–†â–â–â–ˆâ–ƒâ–„â–…
wandb:   test_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–â–…â–â–‚â–‚â–ƒâ–…â–ƒ
wandb:          test_loss â–†â–ƒâ–„â–…â–ƒâ–ˆâ–‚â–â–‡â–‚â–ƒâ–…â–ƒâ–†â–â–â–ˆâ–ƒâ–„â–†
wandb: train_error_energy â–ˆâ–â–â–â–â–â–â–â–â–‚â–â–â–â–‚â–â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚
wandb: valid_error_energy â–‡â–‡â–ƒâ–…â–‡â–ˆâ–â–ƒâ–‡â–†â–‚â–„â–ˆâ–†â–â–ƒâ–ˆâ–‡â–‚â–…
wandb:  valid_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–‚â–‚â–‚â–ƒâ–„â–„
wandb:         valid_loss â–ˆâ–‡â–‚â–„â–‡â–ˆâ–â–‚â–‡â–†â–‚â–„â–ˆâ–†â–‚â–ƒâ–ˆâ–‡â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1436
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.1816
wandb:   test_error_force 8.11336
wandb:          test_loss 4.96202
wandb: train_error_energy 4.44556
wandb:  train_error_force 4.98379
wandb:         train_loss 2.11252
wandb: valid_error_energy 4.26181
wandb:  valid_error_force 4.81805
wandb:         valid_loss 1.92365
wandb: 
wandb: ğŸš€ View run al_73_106 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/64leljru
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_131046-64leljru/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.3156919479370117, Uncertainty Bias: 0.05170568823814392
0.0001449585 0.024627686
3.4617758 9.499703
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1369 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 149 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.19.0 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241206_135452-alos7jd8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_73_107
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/alos7jd8
Training model 107. Added 2 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.1362264838999, Training Loss Force: 4.864113664962635, time: 0.7726061344146729
Validation Loss Energy: 5.016691991931312, Validation Loss Force: 4.890861434898373, time: 0.07967758178710938
Test Loss Energy: 8.727861283574018, Test Loss Force: 8.158809870205781, time: 10.579014539718628


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 4.347685803857211, Training Loss Force: 4.430669131728117, time: 0.7544386386871338
Validation Loss Energy: 5.128143688865964, Validation Loss Force: 4.768247333678362, time: 0.07703137397766113
Test Loss Energy: 6.503512252415789, Test Loss Force: 8.022455385266964, time: 11.964035987854004


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.480059696619572, Training Loss Force: 4.378492456259767, time: 0.8873696327209473
Validation Loss Energy: 2.77561165244358, Validation Loss Force: 4.664392662664474, time: 0.0845649242401123
Test Loss Energy: 6.813205089188692, Test Loss Force: 8.105933190041306, time: 11.337921380996704


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.466827449021324, Training Loss Force: 4.359011607710055, time: 0.711712121963501
Validation Loss Energy: 4.370407710686372, Validation Loss Force: 4.753049719130498, time: 0.06258916854858398
Test Loss Energy: 8.201608999490313, Test Loss Force: 8.04305685122891, time: 8.649931907653809


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 4.427541679246919, Training Loss Force: 4.38108867953722, time: 0.7859501838684082
Validation Loss Energy: 6.198266887919715, Validation Loss Force: 4.539998766961061, time: 0.06612777709960938
Test Loss Energy: 6.877278716501324, Test Loss Force: 7.99225976565378, time: 8.186155557632446


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.493723034158435, Training Loss Force: 4.377654438454966, time: 0.7222530841827393
Validation Loss Energy: 5.37947079921295, Validation Loss Force: 4.734893276971546, time: 0.06339716911315918
Test Loss Energy: 8.779724667569603, Test Loss Force: 8.007518981445994, time: 9.263283967971802


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 4.52738470829035, Training Loss Force: 4.368853504788812, time: 0.7124893665313721
Validation Loss Energy: 2.1649841608780673, Validation Loss Force: 4.62899784323523, time: 0.06478357315063477
Test Loss Energy: 5.554325263292606, Test Loss Force: 8.024663689617501, time: 8.165546178817749


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.419862179148605, Training Loss Force: 4.370252287622515, time: 0.7318694591522217
Validation Loss Energy: 3.343557588113936, Validation Loss Force: 4.671938029343383, time: 0.06339311599731445
Test Loss Energy: 5.8005779886233775, Test Loss Force: 8.002233184316694, time: 8.638165712356567


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.494314624019437, Training Loss Force: 4.425833747519214, time: 0.7648530006408691
Validation Loss Energy: 6.1187978284221085, Validation Loss Force: 4.881225427608348, time: 0.07455682754516602
Test Loss Energy: 9.985389067079259, Test Loss Force: 8.102718603017074, time: 10.455975532531738


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 4.54032962362269, Training Loss Force: 4.361067388229325, time: 0.7306828498840332
Validation Loss Energy: 4.752097140524219, Validation Loss Force: 4.734285390203164, time: 0.07027339935302734
Test Loss Energy: 6.349934094530961, Test Loss Force: 8.017030418755654, time: 10.754376411437988


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.400173533277813, Training Loss Force: 4.455698459952463, time: 0.771826982498169
Validation Loss Energy: 2.579903843377594, Validation Loss Force: 4.629880726398834, time: 0.07657384872436523
Test Loss Energy: 7.031682100230643, Test Loss Force: 8.004255262649586, time: 10.03005313873291


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 4.450634565243704, Training Loss Force: 4.3677197922546265, time: 0.7652926445007324
Validation Loss Energy: 3.797602020906142, Validation Loss Force: 4.699087410298921, time: 0.06825947761535645
Test Loss Energy: 8.052325187458338, Test Loss Force: 7.98893157306446, time: 9.014591217041016


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 4.4118519164045225, Training Loss Force: 4.377299964019258, time: 0.7599904537200928
Validation Loss Energy: 6.094141005886087, Validation Loss Force: 4.77311287718603, time: 0.06934165954589844
Test Loss Energy: 6.679242208442372, Test Loss Force: 7.979895990211911, time: 8.565535068511963


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 4.469170984877876, Training Loss Force: 4.365901763004767, time: 0.7694070339202881
Validation Loss Energy: 5.408250786324117, Validation Loss Force: 4.7039513951225675, time: 0.07191705703735352
Test Loss Energy: 9.05157857860042, Test Loss Force: 8.080805883921236, time: 9.294182538986206


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 4.429293756369855, Training Loss Force: 4.425509006836792, time: 0.7706573009490967
Validation Loss Energy: 2.4029600292352233, Validation Loss Force: 5.3937768465005185, time: 0.06803083419799805
Test Loss Energy: 5.845735361365954, Test Loss Force: 8.27024335023952, time: 10.358776807785034


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 4.459746622136954, Training Loss Force: 4.454047828418309, time: 0.9812047481536865
Validation Loss Energy: 4.460373616392159, Validation Loss Force: 4.691071543714665, time: 0.0747828483581543
Test Loss Energy: 6.041839942950942, Test Loss Force: 7.9925287686349735, time: 10.486735582351685


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.5128673182940755, Training Loss Force: 4.363327005032982, time: 0.7462019920349121
Validation Loss Energy: 6.546543921734514, Validation Loss Force: 4.726514905017721, time: 0.0738832950592041
Test Loss Energy: 9.818104793207958, Test Loss Force: 8.048607137334516, time: 10.793841123580933


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 4.527939965969042, Training Loss Force: 4.434343598181404, time: 0.8095171451568604
Validation Loss Energy: 5.477454130187014, Validation Loss Force: 4.748939246696671, time: 0.08041882514953613
Test Loss Energy: 6.548840289983554, Test Loss Force: 8.046427577122524, time: 11.129742622375488


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 4.59425133244666, Training Loss Force: 4.370007821641301, time: 0.7733991146087646
Validation Loss Energy: 3.27886719116613, Validation Loss Force: 4.631925719835035, time: 0.09177017211914062
Test Loss Energy: 7.380364861711271, Test Loss Force: 8.027599000568843, time: 12.071715831756592


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 4.409958328091146, Training Loss Force: 4.358990508571428, time: 0.8022453784942627
Validation Loss Energy: 4.066228297200258, Validation Loss Force: 4.686959067258526, time: 0.08397483825683594
Test Loss Energy: 8.374345114056965, Test Loss Force: 7.998410633580816, time: 10.12090277671814

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.039 MB of 0.048 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–ƒâ–…â–ƒâ–†â–â–â–ˆâ–‚â–ƒâ–…â–ƒâ–‡â–â–‚â–ˆâ–ƒâ–„â–…
wandb:   test_error_force â–…â–‚â–„â–ƒâ–â–‚â–‚â–‚â–„â–‚â–‚â–â–â–ƒâ–ˆâ–â–ƒâ–ƒâ–‚â–
wandb:          test_loss â–…â–‚â–ƒâ–…â–ƒâ–†â–â–â–ˆâ–‚â–ƒâ–…â–‚â–‡â–‚â–‚â–ˆâ–‚â–„â–…
wandb: train_error_energy â–ˆâ–â–‚â–â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–
wandb:  train_error_force â–ˆâ–‚â–â–â–â–â–â–â–‚â–â–‚â–â–â–â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–†â–†â–‚â–…â–‡â–†â–â–ƒâ–‡â–…â–‚â–„â–‡â–†â–â–…â–ˆâ–†â–ƒâ–„
wandb:  valid_error_force â–„â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–„â–ƒâ–‚â–‚â–ƒâ–‚â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚
wandb:         valid_loss â–…â–…â–â–„â–‡â–†â–â–‚â–‡â–„â–â–ƒâ–‡â–†â–ƒâ–„â–ˆâ–†â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1437
wandb:                 lr 0.0001
wandb:    max_uncertainty 8
wandb:  test_error_energy 8.37435
wandb:   test_error_force 7.99841
wandb:          test_loss 4.75256
wandb: train_error_energy 4.40996
wandb:  train_error_force 4.35899
wandb:         train_loss 1.79738
wandb: valid_error_energy 4.06623
wandb:  valid_error_force 4.68696
wandb:         valid_loss 1.8105
wandb: 
wandb: ğŸš€ View run al_73_107 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential/runs/alos7jd8
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-Evidential
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241206_135452-alos7jd8/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.4062637090682983, Uncertainty Bias: 0.006338596343994141
slurmstepd: error: *** JOB 5124172 ON aimat01 CANCELLED AT 2024-12-06T13:59:18 ***
