wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_102236-4bpw8ntt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/4bpw8ntt
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
56
Uncertainty Slope: 5.450332164764404, Uncertainty Bias: -0.39419645071029663
0.00025558472 0.0021858215
1.6673849 2.2779677

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.996635108316337, Test Loss Force: 13.38648040575182, time: 6.300750255584717

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.044 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: - 0.044 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: \ 0.056 MB of 0.056 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 5.4%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.99664
wandb:   test_error_force 13.38648
wandb:          test_loss 16.63181
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_57 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/4bpw8ntt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_102236-4bpw8ntt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 2489 steps.
Found uncertainty sample 1 after 1230 steps.
Found uncertainty sample 2 after 994 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1288 steps.
Found uncertainty sample 5 after 3689 steps.
Found uncertainty sample 6 after 216 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1188 steps.
Found uncertainty sample 11 after 2638 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1426 steps.
Found uncertainty sample 14 after 326 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2331 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3946 steps.
Found uncertainty sample 21 after 1092 steps.
Found uncertainty sample 22 after 2481 steps.
Found uncertainty sample 23 after 1587 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2214 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1636 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1044 steps.
Found uncertainty sample 31 after 560 steps.
Found uncertainty sample 32 after 2129 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 344 steps.
Found uncertainty sample 35 after 875 steps.
Found uncertainty sample 36 after 405 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1148 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1402 steps.
Found uncertainty sample 43 after 3123 steps.
Found uncertainty sample 44 after 3341 steps.
Found uncertainty sample 45 after 1265 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1612 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3221 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1727 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 329 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3044 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 278 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2958 steps.
Found uncertainty sample 69 after 639 steps.
Found uncertainty sample 70 after 2505 steps.
Found uncertainty sample 71 after 2077 steps.
Found uncertainty sample 72 after 298 steps.
Found uncertainty sample 73 after 1666 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1528 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 488 steps.
Found uncertainty sample 81 after 3277 steps.
Found uncertainty sample 82 after 2377 steps.
Found uncertainty sample 83 after 3133 steps.
Found uncertainty sample 84 after 751 steps.
Found uncertainty sample 85 after 389 steps.
Found uncertainty sample 86 after 849 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3651 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2357 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3157 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 246 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_105004-zj0zd2sd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zj0zd2sd
Training model 0. Added 52 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 41.511532204400524, Training Loss Force: 32.467149058179544, time: 0.7378923892974854
Validation Loss Energy: 20.080348113597093, Validation Loss Force: 21.78267511045304, time: 0.03153347969055176
Test Loss Energy: 32.43085648474631, Test Loss Force: 31.300680968725015, time: 6.315850019454956


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.984526276590442, Training Loss Force: 15.799931123855773, time: 0.38869762420654297
Validation Loss Energy: 9.39236894528692, Validation Loss Force: 10.939977403462986, time: 0.02952742576599121
Test Loss Energy: 14.892845874873874, Test Loss Force: 17.6849146273373, time: 6.380556106567383


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 20.361148363612507, Training Loss Force: 10.543540917723554, time: 0.3757438659667969
Validation Loss Energy: 30.15592923662791, Validation Loss Force: 12.913541249679906, time: 0.028731822967529297
Test Loss Energy: 38.87317165013597, Test Loss Force: 19.305915092488714, time: 6.355778694152832


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 23.810287619895128, Training Loss Force: 12.85500024468265, time: 0.4004809856414795
Validation Loss Energy: 9.505153539729095, Validation Loss Force: 10.21655563134745, time: 0.028323888778686523
Test Loss Energy: 16.355562856661034, Test Loss Force: 16.742126235475357, time: 6.653932094573975


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 11.165470018902155, Training Loss Force: 7.173856057762925, time: 0.3929591178894043
Validation Loss Energy: 29.167267540589528, Validation Loss Force: 6.497350740670417, time: 0.030912160873413086
Test Loss Energy: 21.67854926339362, Test Loss Force: 12.98482021273012, time: 6.6513752937316895


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 11.504860677600705, Training Loss Force: 6.390721892496452, time: 0.40031909942626953
Validation Loss Energy: 6.848846902327894, Validation Loss Force: 5.586755956517733, time: 0.0318148136138916
Test Loss Energy: 14.913811828077367, Test Loss Force: 13.835049731837442, time: 6.333547592163086


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.517064148052257, Training Loss Force: 4.902373553447921, time: 0.38542890548706055
Validation Loss Energy: 6.034185111653571, Validation Loss Force: 5.210570239959783, time: 0.031108617782592773
Test Loss Energy: 14.873502132849465, Test Loss Force: 12.921184551145585, time: 6.413972854614258


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 18.873514957462508, Training Loss Force: 7.256730594437335, time: 0.3957340717315674
Validation Loss Energy: 7.815492854570104, Validation Loss Force: 9.892658419651138, time: 0.030183792114257812
Test Loss Energy: 14.929935289275928, Test Loss Force: 15.15791652827676, time: 6.403776407241821


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.504054334192242, Training Loss Force: 6.856365680661377, time: 0.41210317611694336
Validation Loss Energy: 5.909904109207143, Validation Loss Force: 4.640601355098673, time: 0.028855562210083008
Test Loss Energy: 9.56815604684332, Test Loss Force: 11.784059836521326, time: 6.589959144592285


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 19.570064637685235, Training Loss Force: 7.517442714464853, time: 0.39289379119873047
Validation Loss Energy: 14.530354387733746, Validation Loss Force: 5.738049398394952, time: 0.03244590759277344
Test Loss Energy: 25.038177550610804, Test Loss Force: 12.387364530877356, time: 6.44478178024292


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 15.504052143998903, Training Loss Force: 7.36789486673962, time: 0.3893744945526123
Validation Loss Energy: 2.177682202928318, Validation Loss Force: 10.072263352756492, time: 0.031450748443603516
Test Loss Energy: 10.81304224775068, Test Loss Force: 13.462177036055907, time: 6.399355173110962


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 18.678114456558927, Training Loss Force: 8.343150874058491, time: 0.411635160446167
Validation Loss Energy: 46.19837190037932, Validation Loss Force: 10.321087216564958, time: 0.03196597099304199
Test Loss Energy: 50.65796954044568, Test Loss Force: 16.206315497083796, time: 6.417586326599121


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 14.216635465167847, Training Loss Force: 5.6426025164031675, time: 0.4251677989959717
Validation Loss Energy: 19.082633580761872, Validation Loss Force: 5.400619246685734, time: 0.03156471252441406
Test Loss Energy: 29.34888338825949, Test Loss Force: 12.628934752567448, time: 6.662729740142822


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 15.133845597076446, Training Loss Force: 5.763391637797168, time: 0.39637064933776855
Validation Loss Energy: 11.071166938830968, Validation Loss Force: 6.299101274638238, time: 0.030211448669433594
Test Loss Energy: 18.653974891361663, Test Loss Force: 12.881940408221634, time: 6.438704013824463


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 23.346400485116447, Training Loss Force: 8.103194833727615, time: 0.37779664993286133
Validation Loss Energy: 23.555707577230315, Validation Loss Force: 7.99939441151528, time: 0.02890157699584961
Test Loss Energy: 17.633897875735197, Test Loss Force: 12.992828066722543, time: 6.407840967178345


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 17.50742251095424, Training Loss Force: 7.054399701924364, time: 0.4228551387786865
Validation Loss Energy: 7.9091296838156575, Validation Loss Force: 4.755837091499222, time: 0.029695510864257812
Test Loss Energy: 16.96783458907849, Test Loss Force: 11.58862420900945, time: 6.713603973388672


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.200166191162475, Training Loss Force: 4.966984255458999, time: 0.4004554748535156
Validation Loss Energy: 6.012952717912772, Validation Loss Force: 6.196682374277293, time: 0.03180980682373047
Test Loss Energy: 14.77256956652469, Test Loss Force: 12.641588384946967, time: 6.472993612289429


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.273833419101271, Training Loss Force: 5.299942814861727, time: 0.39931392669677734
Validation Loss Energy: 10.316989213603303, Validation Loss Force: 3.9181891648907734, time: 0.032343149185180664
Test Loss Energy: 10.188727514031878, Test Loss Force: 11.052799327046797, time: 6.6181066036224365


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.578434828432462, Training Loss Force: 4.078732035679671, time: 0.38565635681152344
Validation Loss Energy: 7.819465272133456, Validation Loss Force: 3.554777977234701, time: 0.03196907043457031
Test Loss Energy: 9.659182843956485, Test Loss Force: 10.625453644154282, time: 6.412644863128662


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.896827946784607, Training Loss Force: 3.658409649222444, time: 0.41805148124694824
Validation Loss Energy: 2.392236171832768, Validation Loss Force: 3.5575470907334585, time: 0.029868125915527344
Test Loss Energy: 13.494852574408604, Test Loss Force: 11.302704504870487, time: 6.418582439422607

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.045 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: - 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: \ 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–†â–‚â–ƒâ–‚â–‚â–‚â–â–„â–â–ˆâ–„â–ƒâ–‚â–‚â–‚â–â–â–‚
wandb:   test_error_force â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–
wandb:          test_loss â–ˆâ–ƒâ–†â–„â–ƒâ–‡â–…â–‚â–â–…â–â–‡â–…â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–„
wandb: train_error_energy â–ˆâ–‚â–„â–„â–‚â–‚â–â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–â–â–
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–â–
wandb: valid_error_energy â–„â–‚â–…â–‚â–…â–‚â–‚â–‚â–‚â–ƒâ–â–ˆâ–„â–‚â–„â–‚â–‚â–‚â–‚â–
wandb:  valid_error_force â–ˆâ–„â–…â–„â–‚â–‚â–‚â–ƒâ–â–‚â–„â–„â–‚â–‚â–ƒâ–â–‚â–â–â–
wandb:         valid_loss â–ˆâ–…â–‡â–…â–…â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–ˆâ–„â–ƒâ–…â–‚â–ƒâ–‚â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 846
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.49485
wandb:   test_error_force 11.3027
wandb:          test_loss 4.88994
wandb: train_error_energy 6.89683
wandb:  train_error_force 3.65841
wandb:         train_loss -0.55067
wandb: valid_error_energy 2.39224
wandb:  valid_error_force 3.55755
wandb:         valid_loss -0.92404
wandb: 
wandb: ğŸš€ View run al_57_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zj0zd2sd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_105004-zj0zd2sd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.6679046154022217, Uncertainty Bias: -0.6609399318695068
5.722046e-05 0.035930395
2.1075928 7.0391703
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 11 steps.
Found uncertainty sample 1 after 23 steps.
Found uncertainty sample 2 after 63 steps.
Found uncertainty sample 3 after 131 steps.
Found uncertainty sample 4 after 19 steps.
Found uncertainty sample 5 after 59 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 68 steps.
Found uncertainty sample 8 after 182 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 16 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 11 steps.
Found uncertainty sample 13 after 52 steps.
Found uncertainty sample 14 after 18 steps.
Found uncertainty sample 15 after 184 steps.
Found uncertainty sample 16 after 133 steps.
Found uncertainty sample 17 after 61 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 100 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 112 steps.
Found uncertainty sample 23 after 18 steps.
Found uncertainty sample 24 after 98 steps.
Found uncertainty sample 25 after 298 steps.
Found uncertainty sample 26 after 97 steps.
Found uncertainty sample 27 after 46 steps.
Found uncertainty sample 28 after 66 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 254 steps.
Found uncertainty sample 31 after 45 steps.
Found uncertainty sample 32 after 4 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 74 steps.
Found uncertainty sample 35 after 91 steps.
Found uncertainty sample 36 after 38 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 212 steps.
Found uncertainty sample 39 after 49 steps.
Found uncertainty sample 40 after 16 steps.
Found uncertainty sample 41 after 30 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 8 steps.
Found uncertainty sample 44 after 35 steps.
Found uncertainty sample 45 after 36 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 20 steps.
Found uncertainty sample 48 after 6 steps.
Found uncertainty sample 49 after 6 steps.
Found uncertainty sample 50 after 28 steps.
Found uncertainty sample 51 after 3 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 42 steps.
Found uncertainty sample 54 after 36 steps.
Found uncertainty sample 55 after 11 steps.
Found uncertainty sample 56 after 192 steps.
Found uncertainty sample 57 after 6 steps.
Found uncertainty sample 58 after 63 steps.
Found uncertainty sample 59 after 11 steps.
Found uncertainty sample 60 after 5 steps.
Found uncertainty sample 61 after 87 steps.
Found uncertainty sample 62 after 59 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 107 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 272 steps.
Found uncertainty sample 67 after 632 steps.
Found uncertainty sample 68 after 26 steps.
Found uncertainty sample 69 after 23 steps.
Found uncertainty sample 70 after 21 steps.
Found uncertainty sample 71 after 2 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 37 steps.
Found uncertainty sample 74 after 47 steps.
Found uncertainty sample 75 after 13 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 12 steps.
Found uncertainty sample 78 after 464 steps.
Found uncertainty sample 79 after 24 steps.
Found uncertainty sample 80 after 97 steps.
Found uncertainty sample 81 after 469 steps.
Found uncertainty sample 82 after 151 steps.
Found uncertainty sample 83 after 89 steps.
Found uncertainty sample 84 after 34 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 17 steps.
Found uncertainty sample 88 after 219 steps.
Found uncertainty sample 89 after 78 steps.
Found uncertainty sample 90 after 59 steps.
Found uncertainty sample 91 after 57 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 19 steps.
Found uncertainty sample 94 after 6 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 6 steps.
Found uncertainty sample 97 after 107 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 82 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_105526-wh1udi8g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wh1udi8g
Training model 1. Added 119 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 37.571851957826915, Training Loss Force: 37.27451478865761, time: 0.4562687873840332
Validation Loss Energy: 4.9704937108799445, Validation Loss Force: 20.27702553545902, time: 0.03684377670288086
Test Loss Energy: 12.460744674600202, Test Loss Force: 23.574856107196357, time: 6.773895740509033


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 19.799129971323808, Training Loss Force: 16.614905829006766, time: 0.4337284564971924
Validation Loss Energy: 3.551018876713148, Validation Loss Force: 10.543817819177022, time: 0.03476834297180176
Test Loss Energy: 7.901023853067413, Test Loss Force: 15.350369746232607, time: 6.779257535934448


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 16.944578217361077, Training Loss Force: 9.602814950496585, time: 0.4292643070220947
Validation Loss Energy: 22.816253626607978, Validation Loss Force: 10.4443230100404, time: 0.03902840614318848
Test Loss Energy: 29.46311104664349, Test Loss Force: 16.675129748030642, time: 7.162318229675293


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 21.56651784947486, Training Loss Force: 8.632257963152252, time: 0.43402624130249023
Validation Loss Energy: 32.948328583990424, Validation Loss Force: 9.219858251170825, time: 0.03496098518371582
Test Loss Energy: 39.901941342793485, Test Loss Force: 15.046865479586632, time: 7.07812762260437


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 14.458846945194143, Training Loss Force: 7.919586122996157, time: 0.4399294853210449
Validation Loss Energy: 5.556025833026531, Validation Loss Force: 7.287454796578657, time: 0.04043078422546387
Test Loss Energy: 13.528818339399303, Test Loss Force: 12.210734359633808, time: 6.84059739112854


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 18.199113138062547, Training Loss Force: 8.101860250532187, time: 0.4426155090332031
Validation Loss Energy: 27.380958648655454, Validation Loss Force: 8.47395847411217, time: 0.03565859794616699
Test Loss Energy: 25.493005903538027, Test Loss Force: 12.430755789882229, time: 6.903430461883545


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.071157962422246, Training Loss Force: 7.31740011524273, time: 0.44211649894714355
Validation Loss Energy: 14.505735196283386, Validation Loss Force: 6.31382816661161, time: 0.036403656005859375
Test Loss Energy: 18.55602827864634, Test Loss Force: 12.117538364001682, time: 6.855456352233887


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 12.986552206248948, Training Loss Force: 5.960455883798206, time: 0.4621095657348633
Validation Loss Energy: 23.18898396335942, Validation Loss Force: 5.948400041831723, time: 0.03532266616821289
Test Loss Energy: 27.5818315769172, Test Loss Force: 12.259226831206652, time: 7.090966463088989


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.50033658720923, Training Loss Force: 4.7262063449599045, time: 0.49063563346862793
Validation Loss Energy: 12.862079738026244, Validation Loss Force: 4.944213852939255, time: 0.03495025634765625
Test Loss Energy: 10.17900470191496, Test Loss Force: 10.921955481447542, time: 6.876332998275757


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.592331534291342, Training Loss Force: 5.9712945123007755, time: 0.433640718460083
Validation Loss Energy: 21.01060280198203, Validation Loss Force: 5.7012225936882475, time: 0.03631472587585449
Test Loss Energy: 15.053039845520503, Test Loss Force: 11.45764284947419, time: 6.883833646774292


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 18.9620587429587, Training Loss Force: 5.499447310176399, time: 0.45551013946533203
Validation Loss Energy: 28.035682535869352, Validation Loss Force: 4.669411179875394, time: 0.03674006462097168
Test Loss Energy: 33.9368562401978, Test Loss Force: 11.430691880717356, time: 6.9124016761779785


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.383768129252044, Training Loss Force: 5.3844622250111165, time: 0.42864155769348145
Validation Loss Energy: 13.160486676573326, Validation Loss Force: 5.395045392624869, time: 0.035181283950805664
Test Loss Energy: 10.248535248178438, Test Loss Force: 11.117625804570846, time: 7.065874338150024


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.387665634150112, Training Loss Force: 6.67908928953205, time: 0.43828821182250977
Validation Loss Energy: 12.482316618969818, Validation Loss Force: 9.184504625533577, time: 0.03715944290161133
Test Loss Energy: 19.97240945262225, Test Loss Force: 14.228947048896288, time: 7.207680702209473


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 14.428276141476854, Training Loss Force: 7.386530483004203, time: 0.4377932548522949
Validation Loss Energy: 37.80411918306688, Validation Loss Force: 5.916593535689106, time: 0.04044485092163086
Test Loss Energy: 35.61868873155673, Test Loss Force: 11.529434651044268, time: 6.995244026184082


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 13.792357788115742, Training Loss Force: 6.747952291027703, time: 0.44642066955566406
Validation Loss Energy: 36.28915669371358, Validation Loss Force: 6.7742629812227975, time: 0.03558206558227539
Test Loss Energy: 31.06388130874507, Test Loss Force: 11.869003070079884, time: 6.8854289054870605


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.897079930534895, Training Loss Force: 5.75152264823214, time: 0.4878239631652832
Validation Loss Energy: 3.8923390584017246, Validation Loss Force: 4.109781714136296, time: 0.03462696075439453
Test Loss Energy: 10.642765319211021, Test Loss Force: 11.169248925060556, time: 7.016499280929565


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 20.651745821833792, Training Loss Force: 4.470028921674831, time: 0.4518611431121826
Validation Loss Energy: 3.5783920401603426, Validation Loss Force: 5.002397300770186, time: 0.03499889373779297
Test Loss Energy: 7.987539601782264, Test Loss Force: 10.837345346941614, time: 6.921407699584961


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.64366358086569, Training Loss Force: 5.341254175342717, time: 0.4650130271911621
Validation Loss Energy: 19.901131515482238, Validation Loss Force: 7.318089617675401, time: 0.03871917724609375
Test Loss Energy: 13.60650892877031, Test Loss Force: 11.8337302721768, time: 6.964766025543213


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 17.644579841687857, Training Loss Force: 7.356223341822603, time: 0.4212355613708496
Validation Loss Energy: 18.706851786034633, Validation Loss Force: 5.3211526365487325, time: 0.03754377365112305
Test Loss Energy: 23.71690609582975, Test Loss Force: 11.236006986311299, time: 6.992605447769165


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.45555500956732, Training Loss Force: 5.043413536389865, time: 0.43617749214172363
Validation Loss Energy: 5.7935198453518995, Validation Loss Force: 4.564395066596347, time: 0.03854870796203613
Test Loss Energy: 8.862995448328585, Test Loss Force: 11.220486746321322, time: 6.904865980148315

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–†â–ˆâ–‚â–…â–ƒâ–…â–â–ƒâ–‡â–‚â–„â–‡â–†â–‚â–â–‚â–„â–
wandb:   test_error_force â–ˆâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–ƒâ–â–‚â–â–â–‚â–â–
wandb:          test_loss â–…â–‚â–‡â–ˆâ–ƒâ–ƒâ–„â–…â–ƒâ–â–†â–‚â–…â–…â–†â–â–‚â–‚â–ƒâ–‚
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–‚â–â–‚â–‚â–â–„â–â–ƒâ–
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–
wandb: valid_error_energy â–â–â–…â–‡â–â–†â–ƒâ–…â–ƒâ–…â–†â–ƒâ–ƒâ–ˆâ–ˆâ–â–â–„â–„â–
wandb:  valid_error_force â–ˆâ–„â–„â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚â–
wandb:         valid_loss â–ˆâ–…â–‡â–ˆâ–„â–‡â–„â–…â–ƒâ–„â–„â–ƒâ–…â–†â–‡â–â–‚â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 953
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.863
wandb:   test_error_force 11.22049
wandb:          test_loss 3.4551
wandb: train_error_energy 10.45556
wandb:  train_error_force 5.04341
wandb:         train_loss 0.50069
wandb: valid_error_energy 5.79352
wandb:  valid_error_force 4.5644
wandb:         valid_loss -0.07056
wandb: 
wandb: ğŸš€ View run al_57_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wh1udi8g
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_105526-wh1udi8g/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.8005006313323975, Uncertainty Bias: -0.2821669578552246
0.0005493164 1.3540386
3.7383387 5.5321407
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 6 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 11 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_110017-cc99qe76
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cc99qe76
Training model 2. Added 198 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 31.221179865725396, Training Loss Force: 20.448053413879837, time: 0.5373528003692627
Validation Loss Energy: 44.63524162137892, Validation Loss Force: 11.340494177596465, time: 0.04256248474121094
Test Loss Energy: 44.12766359597013, Test Loss Force: 15.873406265826969, time: 7.037477016448975


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 16.053989036237912, Training Loss Force: 8.870814109777795, time: 0.5486340522766113
Validation Loss Energy: 7.854989016998191, Validation Loss Force: 7.19410521053135, time: 0.04040217399597168
Test Loss Energy: 9.543577891801005, Test Loss Force: 11.984390286784857, time: 7.03130578994751


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.315766923572536, Training Loss Force: 6.234225777777626, time: 0.5264954566955566
Validation Loss Energy: 17.044412849303605, Validation Loss Force: 5.884151531804011, time: 0.04137706756591797
Test Loss Energy: 12.125879400984834, Test Loss Force: 10.873558913825594, time: 7.067039966583252


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 12.149039692170444, Training Loss Force: 5.67513407039645, time: 0.5066261291503906
Validation Loss Energy: 10.341825730140089, Validation Loss Force: 5.379689237645105, time: 0.043245553970336914
Test Loss Energy: 10.014648510991309, Test Loss Force: 10.942060434851507, time: 7.31220006942749


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.0954859756941, Training Loss Force: 4.925730384027983, time: 0.5405232906341553
Validation Loss Energy: 4.332988383382353, Validation Loss Force: 4.237369798738042, time: 0.04101753234863281
Test Loss Energy: 14.029597126297178, Test Loss Force: 11.000151639365674, time: 7.1666810512542725


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 10.592511206972578, Training Loss Force: 4.360188149417411, time: 0.5119304656982422
Validation Loss Energy: 11.849188966881167, Validation Loss Force: 5.936477890420457, time: 0.04156494140625
Test Loss Energy: 10.172304081353735, Test Loss Force: 11.449415506657463, time: 7.121478080749512


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 15.518727875674248, Training Loss Force: 5.921017068571598, time: 0.5593376159667969
Validation Loss Energy: 18.47849121673693, Validation Loss Force: 5.017761917177495, time: 0.04169607162475586
Test Loss Energy: 13.103910983914101, Test Loss Force: 10.834650057008288, time: 7.060437202453613


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.358999579747469, Training Loss Force: 4.306308877621502, time: 0.5136392116546631
Validation Loss Energy: 14.980553101706633, Validation Loss Force: 6.302732117731736, time: 0.04247689247131348
Test Loss Energy: 23.523042988137398, Test Loss Force: 12.09520311446305, time: 7.290088891983032


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.372453349495054, Training Loss Force: 4.976895844681628, time: 0.5242328643798828
Validation Loss Energy: 3.619358264289845, Validation Loss Force: 4.156943039243801, time: 0.04093360900878906
Test Loss Energy: 10.348187030902288, Test Loss Force: 10.80237546767833, time: 7.206779718399048


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.409688999494699, Training Loss Force: 3.9010458302342688, time: 0.5450005531311035
Validation Loss Energy: 11.519049003009624, Validation Loss Force: 3.469513285206886, time: 0.04165911674499512
Test Loss Energy: 9.974535613319356, Test Loss Force: 10.23392873044587, time: 7.411939859390259


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 16.845519968403764, Training Loss Force: 4.11411067448431, time: 0.5237643718719482
Validation Loss Energy: 15.533698887254607, Validation Loss Force: 4.740974371346835, time: 0.04041242599487305
Test Loss Energy: 25.7366327627451, Test Loss Force: 10.983170848328168, time: 7.048837423324585


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.180274062641963, Training Loss Force: 5.207070734550857, time: 0.5271644592285156
Validation Loss Energy: 14.81727337970412, Validation Loss Force: 4.922150457945854, time: 0.04757571220397949
Test Loss Energy: 11.289659781532617, Test Loss Force: 10.927156207305028, time: 7.2456231117248535


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.068398177891691, Training Loss Force: 4.428645737199072, time: 0.5511124134063721
Validation Loss Energy: 7.327720058236778, Validation Loss Force: 5.193683457270912, time: 0.04140138626098633
Test Loss Energy: 17.61569229714084, Test Loss Force: 11.464298665738994, time: 7.124179840087891


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.694327783872303, Training Loss Force: 4.353923390108257, time: 0.526698112487793
Validation Loss Energy: 23.286997577337328, Validation Loss Force: 3.9089844677364107, time: 0.04252266883850098
Test Loss Energy: 29.301254695770172, Test Loss Force: 10.730254316291093, time: 7.140131711959839


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 28.016883019031702, Training Loss Force: 5.740954896745591, time: 0.5646097660064697
Validation Loss Energy: 8.72577857394824, Validation Loss Force: 10.463020092885664, time: 0.04065513610839844
Test Loss Energy: 12.611123804321643, Test Loss Force: 16.0163181495997, time: 7.183142423629761


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 16.859821265416215, Training Loss Force: 7.957019013325265, time: 0.5701584815979004
Validation Loss Energy: 5.166040418818852, Validation Loss Force: 5.287588825506454, time: 0.04089927673339844
Test Loss Energy: 10.103248736695422, Test Loss Force: 10.656101536279634, time: 7.346667528152466


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.942584379475756, Training Loss Force: 4.732205579971896, time: 0.5224418640136719
Validation Loss Energy: 2.160192877530566, Validation Loss Force: 4.228589063637526, time: 0.04122138023376465
Test Loss Energy: 11.567919597103238, Test Loss Force: 11.149893469006942, time: 7.1406073570251465


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 7.605818887204673, Training Loss Force: 5.227483619241086, time: 0.5369131565093994
Validation Loss Energy: 18.83513771573972, Validation Loss Force: 6.462194845234754, time: 0.04469180107116699
Test Loss Energy: 13.466709400070261, Test Loss Force: 11.21857472483687, time: 7.288567066192627


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.212154392884337, Training Loss Force: 5.908282187148205, time: 0.5203909873962402
Validation Loss Energy: 1.4987927013143179, Validation Loss Force: 5.412124561455823, time: 0.04082083702087402
Test Loss Energy: 11.539215823461946, Test Loss Force: 10.918954199807041, time: 7.195234060287476


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 12.035597574296105, Training Loss Force: 5.0583117376336055, time: 0.525062084197998
Validation Loss Energy: 6.794849634440405, Validation Loss Force: 4.3087584175990745, time: 0.04193735122680664
Test Loss Energy: 14.797582632880639, Test Loss Force: 10.713459350233606, time: 7.594613552093506

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–â–‚â–â–‚â–„â–â–â–„â–â–ƒâ–…â–‚â–â–â–‚â–â–‚
wandb:   test_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚
wandb:          test_loss â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‡â–ƒâ–„â–†â–‚â–†â–‡â–†â–â–„â–„â–ƒâ–„
wandb: train_error_energy â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–â–„â–‚â–‚â–‚â–‡â–„â–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–‚â–ƒâ–â–‚â–‚â–
wandb:         train_loss â–ˆâ–„â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ˆâ–‚â–„â–‚â–â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–…â–‚â–‚â–â–„â–â–‚
wandb:  valid_error_force â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–‚â–â–‚â–‚â–ƒâ–â–‡â–ƒâ–‚â–„â–ƒâ–‚
wandb:         valid_loss â–ˆâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–„â–â–â–ƒâ–ƒâ–‚â–ƒâ–…â–‚â–â–„â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1131
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.79758
wandb:   test_error_force 10.71346
wandb:          test_loss 3.71994
wandb: train_error_energy 12.0356
wandb:  train_error_force 5.05831
wandb:         train_loss 0.59996
wandb: valid_error_energy 6.79485
wandb:  valid_error_force 4.30876
wandb:         valid_loss -0.14148
wandb: 
wandb: ğŸš€ View run al_57_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cc99qe76
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_110017-cc99qe76/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.1318906545639038, Uncertainty Bias: -0.07241058349609375
7.05719e-05 1.3275871
3.9877105 4.716689
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_110520-xley1yr3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xley1yr3
Training model 3. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 27.0866947899947, Training Loss Force: 14.521987686901742, time: 0.5912501811981201
Validation Loss Energy: 19.77875522491008, Validation Loss Force: 7.080028912373647, time: 0.0530850887298584
Test Loss Energy: 28.47951733767225, Test Loss Force: 12.362121408822041, time: 7.463390350341797


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.627603932161142, Training Loss Force: 6.015697250910202, time: 0.5967822074890137
Validation Loss Energy: 2.2033579594761052, Validation Loss Force: 4.46321153465701, time: 0.05168461799621582
Test Loss Energy: 11.44458762454644, Test Loss Force: 10.741340581718228, time: 7.498082876205444


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.257086345300362, Training Loss Force: 5.589882600631484, time: 0.6374044418334961
Validation Loss Energy: 15.030275121992307, Validation Loss Force: 5.100500205075614, time: 0.051580190658569336
Test Loss Energy: 21.406611339643792, Test Loss Force: 11.56060745012403, time: 7.5434675216674805


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 13.587063303384888, Training Loss Force: 6.383789508832973, time: 0.6007997989654541
Validation Loss Energy: 19.01939019925888, Validation Loss Force: 8.131581281987874, time: 0.05194497108459473
Test Loss Energy: 12.098494528171662, Test Loss Force: 11.70741885121387, time: 7.68048620223999


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 11.17598001993883, Training Loss Force: 5.279167136257313, time: 0.6085669994354248
Validation Loss Energy: 1.6596969888680722, Validation Loss Force: 5.721077778761482, time: 0.05170702934265137
Test Loss Energy: 12.365448099851884, Test Loss Force: 11.397289531619439, time: 7.475892543792725


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.022525065650964, Training Loss Force: 6.534771376834538, time: 0.5982589721679688
Validation Loss Energy: 32.1898943153692, Validation Loss Force: 4.295135296582067, time: 0.05163764953613281
Test Loss Energy: 38.785259315874626, Test Loss Force: 11.179348712544106, time: 7.5173659324646


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 21.992785162593115, Training Loss Force: 5.092318607475331, time: 0.6047611236572266
Validation Loss Energy: 10.942212111011518, Validation Loss Force: 4.927290775179598, time: 0.05183696746826172
Test Loss Energy: 14.181395826616845, Test Loss Force: 10.794881212311966, time: 7.815929889678955


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 13.900486973099971, Training Loss Force: 5.3475947062467535, time: 0.8019390106201172
Validation Loss Energy: 16.593449934821898, Validation Loss Force: 3.757071226291502, time: 0.051918745040893555
Test Loss Energy: 12.592004167717441, Test Loss Force: 10.367255787023737, time: 7.474706649780273


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.422413128327658, Training Loss Force: 4.756670878831626, time: 0.6099710464477539
Validation Loss Energy: 2.858741838038531, Validation Loss Force: 5.177216183252968, time: 0.05173087120056152
Test Loss Energy: 10.345534428159784, Test Loss Force: 10.707215618780456, time: 7.556492805480957


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.186517245850935, Training Loss Force: 5.170832427198816, time: 0.5766561031341553
Validation Loss Energy: 13.01905569650754, Validation Loss Force: 4.755010543629538, time: 0.051718950271606445
Test Loss Energy: 22.380291025489537, Test Loss Force: 11.277094498674327, time: 7.469582557678223


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 13.074491059496617, Training Loss Force: 5.539200333231382, time: 0.6080856323242188
Validation Loss Energy: 6.3194536799143295, Validation Loss Force: 5.306749728182686, time: 0.051301002502441406
Test Loss Energy: 16.140338549870513, Test Loss Force: 11.291674934971645, time: 7.666394233703613


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 11.785377670436961, Training Loss Force: 4.97594025792984, time: 0.5991747379302979
Validation Loss Energy: 15.092232366508423, Validation Loss Force: 4.229319195767023, time: 0.05165982246398926
Test Loss Energy: 11.242577661355865, Test Loss Force: 10.653258580562538, time: 7.480421304702759


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.602043403873196, Training Loss Force: 4.766935774392163, time: 0.5911381244659424
Validation Loss Energy: 16.6502020653828, Validation Loss Force: 5.520279419015868, time: 0.0599820613861084
Test Loss Energy: 11.739203027488314, Test Loss Force: 11.2739140091746, time: 7.51708722114563


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 14.302766170807994, Training Loss Force: 4.5301014004032645, time: 0.5756607055664062
Validation Loss Energy: 1.755423011375293, Validation Loss Force: 4.544243286220737, time: 0.05301833152770996
Test Loss Energy: 9.263869714861336, Test Loss Force: 10.20158923364278, time: 7.481470823287964


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 6.846010887612694, Training Loss Force: 4.989927176883658, time: 0.6023397445678711
Validation Loss Energy: 9.995899859837142, Validation Loss Force: 4.743963259292624, time: 0.05179262161254883
Test Loss Energy: 17.171194081179916, Test Loss Force: 10.455184456573416, time: 7.6856749057769775


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 14.51250783585447, Training Loss Force: 5.957498037017548, time: 0.6027674674987793
Validation Loss Energy: 7.855396501535239, Validation Loss Force: 4.774624132679442, time: 0.06905794143676758
Test Loss Energy: 9.1096746002293, Test Loss Force: 11.330653940730572, time: 7.5116846561431885


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 11.093908611197639, Training Loss Force: 4.947125306331809, time: 0.620293140411377
Validation Loss Energy: 1.9497337942197284, Validation Loss Force: 3.9846766131807896, time: 0.05359983444213867
Test Loss Energy: 11.463609258747061, Test Loss Force: 10.702219832475334, time: 7.54154372215271


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.068461415579122, Training Loss Force: 4.652962132141688, time: 0.6273260116577148
Validation Loss Energy: 7.7283909194192395, Validation Loss Force: 5.563672959505128, time: 0.0526883602142334
Test Loss Energy: 17.698589516016217, Test Loss Force: 11.49827456858777, time: 7.814209222793579


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.0066580284067, Training Loss Force: 4.964441883919958, time: 0.6068780422210693
Validation Loss Energy: 13.864430687817975, Validation Loss Force: 4.084074783908078, time: 0.05194211006164551
Test Loss Energy: 20.773549191921486, Test Loss Force: 10.844531670697883, time: 7.766404390335083


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.750861560482573, Training Loss Force: 5.682764261046011, time: 0.6224792003631592
Validation Loss Energy: 16.82496617125569, Validation Loss Force: 5.1537116735471225, time: 0.05591320991516113
Test Loss Energy: 24.14500989838153, Test Loss Force: 11.608813464252576, time: 7.48061203956604

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–„â–‚â–‚â–ˆâ–‚â–‚â–â–„â–ƒâ–‚â–‚â–â–ƒâ–â–‚â–ƒâ–„â–…
wandb:   test_error_force â–ˆâ–ƒâ–…â–†â–…â–„â–ƒâ–‚â–ƒâ–„â–…â–‚â–„â–â–‚â–…â–ƒâ–…â–ƒâ–†
wandb:          test_loss â–‡â–ƒâ–†â–ƒâ–„â–ˆâ–„â–ƒâ–„â–†â–„â–ƒâ–…â–ƒâ–„â–â–„â–‡â–…â–†
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–â–„â–‚â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–‚â–â–â–â–â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–â–â–â–ƒâ–â–â–â–‚
wandb: valid_error_energy â–…â–â–„â–…â–â–ˆâ–ƒâ–„â–â–„â–‚â–„â–„â–â–ƒâ–‚â–â–‚â–„â–„
wandb:  valid_error_force â–†â–‚â–ƒâ–ˆâ–„â–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–ƒâ–â–„â–‚â–ƒ
wandb:         valid_loss â–‡â–‚â–„â–ˆâ–ƒâ–‡â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–‚â–ƒâ–ƒâ–â–„â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1311
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 24.14501
wandb:   test_error_force 11.60881
wandb:          test_loss 4.12325
wandb: train_error_energy 11.75086
wandb:  train_error_force 5.68276
wandb:         train_loss 0.9001
wandb: valid_error_energy 16.82497
wandb:  valid_error_force 5.15371
wandb:         valid_loss 1.01122
wandb: 
wandb: ğŸš€ View run al_57_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xley1yr3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_110520-xley1yr3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: -0.1782909780740738, Uncertainty Bias: 0.4251304566860199
2.670288e-05 3.6348143
4.989877 5.354295
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_111036-xj80q5ac
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xj80q5ac
Training model 4. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 23.028887382075492, Training Loss Force: 14.254219594135554, time: 0.6863579750061035
Validation Loss Energy: 9.894213095628007, Validation Loss Force: 6.784935736056262, time: 0.05655241012573242
Test Loss Energy: 9.819097393970152, Test Loss Force: 12.04137110671928, time: 7.594126224517822


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.136226290920856, Training Loss Force: 5.933983797005128, time: 0.6950986385345459
Validation Loss Energy: 28.344009830205806, Validation Loss Force: 5.650225347203843, time: 0.055379629135131836
Test Loss Energy: 34.98831766753593, Test Loss Force: 11.473231937365117, time: 7.625068426132202


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 14.966312052490293, Training Loss Force: 6.128447148484475, time: 0.6829361915588379
Validation Loss Energy: 5.230001240310026, Validation Loss Force: 8.622398188215179, time: 0.05755305290222168
Test Loss Energy: 8.892177095604794, Test Loss Force: 13.28905921294601, time: 7.656047582626343


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 12.452601485403914, Training Loss Force: 6.1623296890897645, time: 0.7202775478363037
Validation Loss Energy: 1.818768709350841, Validation Loss Force: 5.1604839329513705, time: 0.053395986557006836
Test Loss Energy: 11.601189990833149, Test Loss Force: 10.942775475608785, time: 7.77634334564209


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.551569941264386, Training Loss Force: 4.9311770103081916, time: 0.6790826320648193
Validation Loss Energy: 5.41338019276971, Validation Loss Force: 5.896601631760271, time: 0.054467201232910156
Test Loss Energy: 9.560487046327102, Test Loss Force: 10.730751616934631, time: 7.9268481731414795


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.694932945443334, Training Loss Force: 4.139439050845907, time: 0.6854321956634521
Validation Loss Energy: 3.9690675060512515, Validation Loss Force: 3.5978525441724205, time: 0.054213762283325195
Test Loss Energy: 9.612085848081819, Test Loss Force: 10.499235226614312, time: 7.612381219863892


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.38829831562724, Training Loss Force: 4.0147892798679745, time: 0.6755251884460449
Validation Loss Energy: 8.628373737415297, Validation Loss Force: 3.332372360241118, time: 0.06113767623901367
Test Loss Energy: 18.00204286953685, Test Loss Force: 10.731821478061429, time: 7.66216254234314


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.81805265670287, Training Loss Force: 3.6790456100570887, time: 0.7412679195404053
Validation Loss Energy: 2.806812164505555, Validation Loss Force: 4.195021689888912, time: 0.05635237693786621
Test Loss Energy: 13.58652202965113, Test Loss Force: 10.718049216514737, time: 7.484193325042725


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.98277366410481, Training Loss Force: 4.2415580063920055, time: 0.6863257884979248
Validation Loss Energy: 5.589565818470196, Validation Loss Force: 4.718684521832025, time: 0.05430746078491211
Test Loss Energy: 9.739088961018494, Test Loss Force: 10.718151126703537, time: 7.5724732875823975


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 13.800264356918033, Training Loss Force: 4.814983592861574, time: 0.6916038990020752
Validation Loss Energy: 12.277033925294363, Validation Loss Force: 4.8926258652107055, time: 0.05386948585510254
Test Loss Energy: 20.962266268759763, Test Loss Force: 11.167958306711393, time: 7.481737375259399


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 7.665613179370332, Training Loss Force: 4.667934106464703, time: 0.6962330341339111
Validation Loss Energy: 7.218546712003259, Validation Loss Force: 4.4672594370608305, time: 0.05488300323486328
Test Loss Energy: 10.002270778507476, Test Loss Force: 10.846202407429482, time: 7.716383457183838


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.849625831111322, Training Loss Force: 4.58104404337501, time: 0.6914846897125244
Validation Loss Energy: 3.355547208276418, Validation Loss Force: 4.93524607575616, time: 0.055544376373291016
Test Loss Energy: 9.780688010860725, Test Loss Force: 11.293040398133215, time: 7.495828151702881


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 22.69868990797496, Training Loss Force: 4.6912641762141005, time: 0.6715569496154785
Validation Loss Energy: 8.202056734681456, Validation Loss Force: 5.607776146562462, time: 0.05699896812438965
Test Loss Energy: 13.458090416034254, Test Loss Force: 11.740731810890674, time: 7.550650119781494


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 17.03097374775396, Training Loss Force: 7.1447978286212415, time: 0.6811697483062744
Validation Loss Energy: 6.603477972987644, Validation Loss Force: 9.977358645394027, time: 0.05600333213806152
Test Loss Energy: 12.52123160793219, Test Loss Force: 14.263154364443844, time: 7.583375930786133


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.681419796664922, Training Loss Force: 5.595899234888951, time: 0.6902427673339844
Validation Loss Energy: 2.193821373959737, Validation Loss Force: 4.802955664130709, time: 0.05383419990539551
Test Loss Energy: 8.746116308708455, Test Loss Force: 11.273268879534303, time: 8.079424858093262


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 14.942748665745912, Training Loss Force: 5.479841404001638, time: 0.7232451438903809
Validation Loss Energy: 2.032929667212728, Validation Loss Force: 5.087751951132955, time: 0.05556631088256836
Test Loss Energy: 10.821904148669406, Test Loss Force: 11.487485607273692, time: 7.518640518188477


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.587722067934212, Training Loss Force: 5.980634707578471, time: 0.7010695934295654
Validation Loss Energy: 13.5337291523604, Validation Loss Force: 6.3569754350254755, time: 0.054410457611083984
Test Loss Energy: 20.081721285074853, Test Loss Force: 11.626858487900456, time: 7.577259063720703


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.881170067216043, Training Loss Force: 4.599040002669085, time: 0.7218947410583496
Validation Loss Energy: 1.313404549483641, Validation Loss Force: 4.1943507877522315, time: 0.06273555755615234
Test Loss Energy: 11.390397070513828, Test Loss Force: 11.122724806768657, time: 7.784806966781616


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.491316698180722, Training Loss Force: 3.544849927515688, time: 0.6890201568603516
Validation Loss Energy: 7.073842272823189, Validation Loss Force: 3.658167826406464, time: 0.05676984786987305
Test Loss Energy: 9.548227176935697, Test Loss Force: 10.376702041729802, time: 7.533708095550537


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.3951317450884595, Training Loss Force: 3.319673147993441, time: 0.6858115196228027
Validation Loss Energy: 5.496735719540339, Validation Loss Force: 3.803554523849657, time: 0.0542144775390625
Test Loss Energy: 10.196936996684645, Test Loss Force: 10.391651959586056, time: 7.58787202835083

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ˆâ–â–‚â–â–â–ƒâ–‚â–â–„â–â–â–‚â–‚â–â–‚â–„â–‚â–â–
wandb:   test_error_force â–„â–ƒâ–†â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–ƒâ–‚â–â–
wandb:          test_loss â–â–ˆâ–ƒâ–‚â–‚â–ƒâ–†â–†â–„â–†â–ƒâ–„â–…â–„â–ƒâ–ƒâ–…â–„â–„â–†
wandb: train_error_energy â–ˆâ–ƒâ–…â–„â–ƒâ–â–â–‚â–ƒâ–„â–‚â–‚â–ˆâ–…â–ƒâ–…â–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–
wandb:         train_loss â–ˆâ–„â–„â–„â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–„â–…â–ƒâ–„â–„â–‚â–â–
wandb: valid_error_energy â–ƒâ–ˆâ–‚â–â–‚â–‚â–ƒâ–â–‚â–„â–ƒâ–‚â–ƒâ–‚â–â–â–„â–â–‚â–‚
wandb:  valid_error_force â–…â–ƒâ–‡â–ƒâ–„â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ˆâ–ƒâ–ƒâ–„â–‚â–â–
wandb:         valid_loss â–†â–ˆâ–‡â–ƒâ–„â–â–â–‚â–ƒâ–„â–ƒâ–ƒâ–…â–ˆâ–‚â–ƒâ–†â–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1491
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.19694
wandb:   test_error_force 10.39165
wandb:          test_loss 4.31596
wandb: train_error_energy 6.39513
wandb:  train_error_force 3.31967
wandb:         train_loss -0.80814
wandb: valid_error_energy 5.49674
wandb:  valid_error_force 3.80355
wandb:         valid_loss -0.54117
wandb: 
wandb: ğŸš€ View run al_57_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xj80q5ac
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_111036-xj80q5ac/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.6585619449615479, Uncertainty Bias: -0.13797065615653992
2.2888184e-05 0.31442046
3.1104295 4.1791887
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 55 steps.
Found uncertainty sample 1 after 162 steps.
Found uncertainty sample 2 after 78 steps.
Found uncertainty sample 3 after 42 steps.
Found uncertainty sample 4 after 684 steps.
Found uncertainty sample 5 after 154 steps.
Found uncertainty sample 6 after 13 steps.
Found uncertainty sample 7 after 10 steps.
Found uncertainty sample 8 after 69 steps.
Found uncertainty sample 9 after 121 steps.
Found uncertainty sample 10 after 256 steps.
Found uncertainty sample 11 after 582 steps.
Found uncertainty sample 12 after 173 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 72 steps.
Found uncertainty sample 15 after 4 steps.
Found uncertainty sample 16 after 1117 steps.
Found uncertainty sample 17 after 127 steps.
Found uncertainty sample 18 after 190 steps.
Found uncertainty sample 19 after 997 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 193 steps.
Found uncertainty sample 22 after 11 steps.
Found uncertainty sample 23 after 78 steps.
Found uncertainty sample 24 after 685 steps.
Found uncertainty sample 25 after 58 steps.
Found uncertainty sample 26 after 351 steps.
Found uncertainty sample 27 after 125 steps.
Found uncertainty sample 28 after 36 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 260 steps.
Found uncertainty sample 31 after 3 steps.
Found uncertainty sample 32 after 513 steps.
Found uncertainty sample 33 after 291 steps.
Found uncertainty sample 34 after 113 steps.
Found uncertainty sample 35 after 119 steps.
Found uncertainty sample 36 after 274 steps.
Found uncertainty sample 37 after 124 steps.
Found uncertainty sample 38 after 30 steps.
Found uncertainty sample 39 after 4 steps.
Found uncertainty sample 40 after 38 steps.
Found uncertainty sample 41 after 461 steps.
Found uncertainty sample 42 after 133 steps.
Found uncertainty sample 43 after 682 steps.
Found uncertainty sample 44 after 490 steps.
Found uncertainty sample 45 after 725 steps.
Found uncertainty sample 46 after 457 steps.
Found uncertainty sample 47 after 356 steps.
Found uncertainty sample 48 after 312 steps.
Found uncertainty sample 49 after 31 steps.
Found uncertainty sample 50 after 192 steps.
Found uncertainty sample 51 after 118 steps.
Found uncertainty sample 52 after 79 steps.
Found uncertainty sample 53 after 325 steps.
Found uncertainty sample 54 after 16 steps.
Found uncertainty sample 55 after 181 steps.
Found uncertainty sample 56 after 69 steps.
Found uncertainty sample 57 after 83 steps.
Found uncertainty sample 58 after 287 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 105 steps.
Found uncertainty sample 61 after 158 steps.
Found uncertainty sample 62 after 121 steps.
Found uncertainty sample 63 after 18 steps.
Found uncertainty sample 64 after 23 steps.
Found uncertainty sample 65 after 260 steps.
Found uncertainty sample 66 after 119 steps.
Found uncertainty sample 67 after 625 steps.
Found uncertainty sample 68 after 673 steps.
Found uncertainty sample 69 after 972 steps.
Found uncertainty sample 70 after 47 steps.
Found uncertainty sample 71 after 386 steps.
Found uncertainty sample 72 after 689 steps.
Found uncertainty sample 73 after 116 steps.
Found uncertainty sample 74 after 68 steps.
Found uncertainty sample 75 after 2 steps.
Found uncertainty sample 76 after 590 steps.
Found uncertainty sample 77 after 77 steps.
Found uncertainty sample 78 after 210 steps.
Found uncertainty sample 79 after 835 steps.
Found uncertainty sample 80 after 357 steps.
Found uncertainty sample 81 after 821 steps.
Found uncertainty sample 82 after 1136 steps.
Found uncertainty sample 83 after 36 steps.
Found uncertainty sample 84 after 1022 steps.
Found uncertainty sample 85 after 182 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 152 steps.
Found uncertainty sample 88 after 571 steps.
Found uncertainty sample 89 after 1401 steps.
Found uncertainty sample 90 after 460 steps.
Found uncertainty sample 91 after 9 steps.
Found uncertainty sample 92 after 104 steps.
Found uncertainty sample 93 after 160 steps.
Found uncertainty sample 94 after 12 steps.
Found uncertainty sample 95 after 295 steps.
Found uncertainty sample 96 after 353 steps.
Found uncertainty sample 97 after 4 steps.
Found uncertainty sample 98 after 137 steps.
Found uncertainty sample 99 after 110 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_111817-qxozo0f1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qxozo0f1
Training model 5. Added 105 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 27.868217252943623, Training Loss Force: 15.267110403276513, time: 0.7528300285339355
Validation Loss Energy: 2.7422493569783657, Validation Loss Force: 9.199029333922446, time: 0.05808377265930176
Test Loss Energy: 13.77045307218813, Test Loss Force: 13.624442701783336, time: 7.661534786224365


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.496372573179446, Training Loss Force: 7.2248681109208315, time: 0.7462332248687744
Validation Loss Energy: 32.63478192487342, Validation Loss Force: 5.987716287589901, time: 0.056303977966308594
Test Loss Energy: 22.664650865810273, Test Loss Force: 10.666410828615945, time: 7.586164951324463


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 13.21295375318323, Training Loss Force: 6.724055773774911, time: 0.7698042392730713
Validation Loss Energy: 2.483294937706769, Validation Loss Force: 4.61821219514478, time: 0.055733442306518555
Test Loss Energy: 8.89138626106818, Test Loss Force: 10.12830446226282, time: 7.953309774398804


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.961633242665211, Training Loss Force: 5.181093120286546, time: 0.7535600662231445
Validation Loss Energy: 12.008539469134636, Validation Loss Force: 4.562056372556668, time: 0.061847686767578125
Test Loss Energy: 10.139078603837717, Test Loss Force: 10.429784645387784, time: 7.865234613418579


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 11.336037258691873, Training Loss Force: 4.8031339953963, time: 0.7565622329711914
Validation Loss Energy: 15.395722396318744, Validation Loss Force: 5.66209227666692, time: 0.05680251121520996
Test Loss Energy: 24.427992006587345, Test Loss Force: 11.120866734171104, time: 7.631468057632446


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.506049146334478, Training Loss Force: 4.697797937728236, time: 0.7089724540710449
Validation Loss Energy: 4.038584702075334, Validation Loss Force: 5.609846969619591, time: 0.05762004852294922
Test Loss Energy: 15.653990323116025, Test Loss Force: 11.804976042406523, time: 7.638044834136963


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.699913283903689, Training Loss Force: 5.384938573692694, time: 0.7594377994537354
Validation Loss Energy: 31.21615323346115, Validation Loss Force: 4.574983207154359, time: 0.05640816688537598
Test Loss Energy: 41.000128689623295, Test Loss Force: 11.262781773643999, time: 7.79417872428894


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.198465680422164, Training Loss Force: 5.085476005258598, time: 0.7052173614501953
Validation Loss Energy: 5.084182564723733, Validation Loss Force: 3.9872295149388517, time: 0.057103872299194336
Test Loss Energy: 13.312995926961522, Test Loss Force: 10.750111377147865, time: 7.6691977977752686


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.987028755492576, Training Loss Force: 4.765199638811134, time: 0.7261135578155518
Validation Loss Energy: 4.85799391027541, Validation Loss Force: 7.21325364373541, time: 0.05733942985534668
Test Loss Energy: 9.53341259995111, Test Loss Force: 13.047666165947653, time: 7.627427339553833


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 14.631411180848607, Training Loss Force: 4.780573273318853, time: 0.7215087413787842
Validation Loss Energy: 15.283658359232792, Validation Loss Force: 5.020341093894777, time: 0.062166452407836914
Test Loss Energy: 11.409900313595145, Test Loss Force: 10.886804584992499, time: 7.5882391929626465


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.092820918745826, Training Loss Force: 4.788793599166281, time: 0.7925691604614258
Validation Loss Energy: 6.737397432084701, Validation Loss Force: 6.643223970197462, time: 0.0553736686706543
Test Loss Energy: 18.535578167081663, Test Loss Force: 12.710716070264143, time: 7.817566633224487


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.333648037513906, Training Loss Force: 4.880932671122048, time: 0.7546939849853516
Validation Loss Energy: 1.6891711470416686, Validation Loss Force: 4.273509891798707, time: 0.05638837814331055
Test Loss Energy: 12.520597035840506, Test Loss Force: 11.057479981717501, time: 7.655689477920532


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.61859138545153, Training Loss Force: 5.090712591270892, time: 0.7569515705108643
Validation Loss Energy: 17.674399975758092, Validation Loss Force: 6.105632292499982, time: 0.05884838104248047
Test Loss Energy: 12.676396683353573, Test Loss Force: 11.236009840206947, time: 7.937077522277832


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 11.221263934853287, Training Loss Force: 4.852904138937793, time: 0.7130897045135498
Validation Loss Energy: 14.650920823487805, Validation Loss Force: 5.299987043551713, time: 0.055826663970947266
Test Loss Energy: 25.485173191069844, Test Loss Force: 11.963399786348186, time: 7.852360963821411


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.08423308415312, Training Loss Force: 5.256483357542727, time: 0.8082828521728516
Validation Loss Energy: 27.05031367116095, Validation Loss Force: 4.6336469523330575, time: 0.056180477142333984
Test Loss Energy: 17.491984379790836, Test Loss Force: 11.244562060805004, time: 7.675520658493042


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 17.872404895400756, Training Loss Force: 4.87441387600661, time: 0.7510123252868652
Validation Loss Energy: 12.826006445709357, Validation Loss Force: 7.016620755702666, time: 0.05556511878967285
Test Loss Energy: 18.451198918329727, Test Loss Force: 12.002983985861214, time: 7.600752353668213


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 16.146845307946585, Training Loss Force: 4.868034347081801, time: 0.7248003482818604
Validation Loss Energy: 15.194076335134582, Validation Loss Force: 4.251182411198235, time: 0.05681276321411133
Test Loss Energy: 11.29456111881404, Test Loss Force: 10.449491974650703, time: 7.615250825881958


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.800895257747525, Training Loss Force: 4.260837345365664, time: 0.7127461433410645
Validation Loss Energy: 4.492664650596316, Validation Loss Force: 3.3250321831801815, time: 0.056092262268066406
Test Loss Energy: 15.324250963188339, Test Loss Force: 10.592755633704948, time: 7.824406147003174


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.207528730883688, Training Loss Force: 3.4079407996147855, time: 0.7545170783996582
Validation Loss Energy: 6.5532044012275055, Validation Loss Force: 3.4644558008954283, time: 0.05747056007385254
Test Loss Energy: 10.828343316015875, Test Loss Force: 10.377492692068902, time: 7.699273347854614


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 5.985943556171809, Training Loss Force: 3.376330491710029, time: 0.7248244285583496
Validation Loss Energy: 3.1348562550410524, Validation Loss Force: 4.5483403985058075, time: 0.05570697784423828
Test Loss Energy: 11.950617481513305, Test Loss Force: 11.09182414435943, time: 7.645645618438721

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–â–â–„â–‚â–ˆâ–‚â–â–‚â–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–‚â–‚â–â–‚
wandb:   test_error_force â–ˆâ–‚â–â–‚â–ƒâ–„â–ƒâ–‚â–‡â–ƒâ–†â–ƒâ–ƒâ–…â–ƒâ–…â–‚â–‚â–â–ƒ
wandb:          test_loss â–„â–„â–â–ƒâ–†â–†â–ˆâ–„â–†â–„â–ˆâ–„â–„â–‡â–…â–†â–ƒâ–…â–…â–‡
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–ƒâ–â–ƒâ–ƒâ–ƒâ–…â–„â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–â–
wandb: valid_error_energy â–â–ˆâ–â–ƒâ–„â–‚â–ˆâ–‚â–‚â–„â–‚â–â–…â–„â–‡â–„â–„â–‚â–‚â–
wandb:  valid_error_force â–ˆâ–„â–ƒâ–‚â–„â–„â–‚â–‚â–†â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–…â–‚â–â–â–‚
wandb:         valid_loss â–†â–ˆâ–ƒâ–„â–…â–„â–†â–‚â–…â–…â–…â–‚â–†â–…â–†â–†â–„â–â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1585
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.95062
wandb:   test_error_force 11.09182
wandb:          test_loss 4.79504
wandb: train_error_energy 5.98594
wandb:  train_error_force 3.37633
wandb:         train_loss -0.81026
wandb: valid_error_energy 3.13486
wandb:  valid_error_force 4.54834
wandb:         valid_loss -0.15399
wandb: 
wandb: ğŸš€ View run al_57_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qxozo0f1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_111817-qxozo0f1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.423213005065918, Uncertainty Bias: -0.2642921209335327
0.00039672852 0.058332443
3.598686 5.621917
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 2 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 13 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 11 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 2 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 16 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 32 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 2 steps.
Found uncertainty sample 99 after 17 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_112335-z71rwore
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/z71rwore
Training model 6. Added 192 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 38.92737379496138, Training Loss Force: 17.390038844994937, time: 0.8210813999176025
Validation Loss Energy: 8.543149793841188, Validation Loss Force: 9.111034050158121, time: 0.05912518501281738
Test Loss Energy: 10.640152908832262, Test Loss Force: 13.327335297677717, time: 7.661016225814819


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 7.294944014196022, Training Loss Force: 6.3035207470701335, time: 0.8090088367462158
Validation Loss Energy: 8.75588878653718, Validation Loss Force: 4.641569297876021, time: 0.05859732627868652
Test Loss Energy: 9.458502908056486, Test Loss Force: 10.922233363215206, time: 7.690474987030029


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.145722204441249, Training Loss Force: 4.616544277737353, time: 0.7993946075439453
Validation Loss Energy: 4.483442585248571, Validation Loss Force: 5.434414856308924, time: 0.05904555320739746
Test Loss Energy: 9.215482674214572, Test Loss Force: 11.627667865763957, time: 7.693077564239502


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 7.323004445962123, Training Loss Force: 4.361477961344871, time: 0.814889669418335
Validation Loss Energy: 5.222228083094833, Validation Loss Force: 4.23080172694061, time: 0.05840659141540527
Test Loss Energy: 9.578315001366109, Test Loss Force: 10.765410253695805, time: 7.905856609344482


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.453239820920927, Training Loss Force: 3.436165451090567, time: 0.7879421710968018
Validation Loss Energy: 2.6850302892184477, Validation Loss Force: 4.143751228362455, time: 0.05905032157897949
Test Loss Energy: 10.793580931753993, Test Loss Force: 10.64373368517633, time: 7.745339870452881


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.057032257506808, Training Loss Force: 3.356472325704209, time: 0.8453619480133057
Validation Loss Energy: 4.062128512885436, Validation Loss Force: 3.617139366250675, time: 0.06139349937438965
Test Loss Energy: 15.781480859978943, Test Loss Force: 10.966999449143845, time: 7.751974582672119


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.081356477115292, Training Loss Force: 3.383110292310969, time: 0.8124959468841553
Validation Loss Energy: 5.797505623064007, Validation Loss Force: 3.788322061580456, time: 0.05957174301147461
Test Loss Energy: 16.38185818486123, Test Loss Force: 11.2277047380602, time: 7.9195332527160645


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.048443301268883, Training Loss Force: 3.3557666507439947, time: 0.7927427291870117
Validation Loss Energy: 4.527844371630593, Validation Loss Force: 3.811588983307596, time: 0.05887126922607422
Test Loss Energy: 10.947431405843641, Test Loss Force: 10.942379511576972, time: 7.756323575973511


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 5.908331947629525, Training Loss Force: 3.393232908606915, time: 0.802924394607544
Validation Loss Energy: 10.1855765637511, Validation Loss Force: 3.645674194632175, time: 0.05929970741271973
Test Loss Energy: 10.92737739820762, Test Loss Force: 10.55704860998278, time: 7.7490153312683105


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.156251452847394, Training Loss Force: 3.363630272360383, time: 0.8091232776641846
Validation Loss Energy: 8.657211618504405, Validation Loss Force: 3.439014514958303, time: 0.060251712799072266
Test Loss Energy: 19.94359057185639, Test Loss Force: 10.80705355757353, time: 7.716871023178101


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.730246740394154, Training Loss Force: 3.6092865865974275, time: 0.8306798934936523
Validation Loss Energy: 9.239357833618014, Validation Loss Force: 4.304146048910327, time: 0.05907487869262695
Test Loss Energy: 20.2917644888721, Test Loss Force: 10.9768796172327, time: 8.19771695137024


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.407607362091674, Training Loss Force: 4.112353299859966, time: 0.804969310760498
Validation Loss Energy: 11.224435456032566, Validation Loss Force: 3.82194354393153, time: 0.061434268951416016
Test Loss Energy: 22.594950190992847, Test Loss Force: 10.64521529536235, time: 7.736347436904907


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 5.620949886830485, Training Loss Force: 3.876060259645954, time: 0.7980632781982422
Validation Loss Energy: 28.37097951716058, Validation Loss Force: 6.672431482068809, time: 0.058767080307006836
Test Loss Energy: 38.29749212007837, Test Loss Force: 13.113254638273595, time: 7.752606391906738


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.661978051334556, Training Loss Force: 5.018997200579974, time: 0.7908129692077637
Validation Loss Energy: 5.869892022367941, Validation Loss Force: 6.528440029494, time: 0.06583452224731445
Test Loss Energy: 9.231713664791892, Test Loss Force: 11.859666219370315, time: 7.870128631591797


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 13.70563896568915, Training Loss Force: 4.745382455264049, time: 0.8245372772216797
Validation Loss Energy: 36.65117040980981, Validation Loss Force: 4.965035644774963, time: 0.05931901931762695
Test Loss Energy: 25.326324016157464, Test Loss Force: 11.157355967789353, time: 7.702459812164307


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 17.071904484882026, Training Loss Force: 5.409433147343402, time: 0.7938573360443115
Validation Loss Energy: 2.4244451524566495, Validation Loss Force: 7.804480083950808, time: 0.05889582633972168
Test Loss Energy: 10.866600873741987, Test Loss Force: 13.677346647843022, time: 7.739936351776123


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 14.064705805434633, Training Loss Force: 5.634182723489833, time: 0.8446640968322754
Validation Loss Energy: 1.4999699530888382, Validation Loss Force: 5.627613295434877, time: 0.05893826484680176
Test Loss Energy: 10.414791783863155, Test Loss Force: 11.723928782111654, time: 7.749924182891846


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 8.14980808354841, Training Loss Force: 4.842947196583477, time: 0.8310291767120361
Validation Loss Energy: 1.9025137401249845, Validation Loss Force: 7.370121385011785, time: 0.05896139144897461
Test Loss Energy: 10.552764199137583, Test Loss Force: 13.065355749016664, time: 7.925372838973999


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.133082521097917, Training Loss Force: 4.548001151940662, time: 0.8245940208435059
Validation Loss Energy: 5.439234752641676, Validation Loss Force: 4.442067540567145, time: 0.05823469161987305
Test Loss Energy: 11.034525795891302, Test Loss Force: 11.203823236666423, time: 7.756903409957886


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 13.027093408959276, Training Loss Force: 4.282386710659956, time: 0.776839017868042
Validation Loss Energy: 2.3982847565127505, Validation Loss Force: 5.85279637602019, time: 0.05887103080749512
Test Loss Energy: 10.84547289201191, Test Loss Force: 12.07752011120901, time: 7.76285982131958

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–â–ƒâ–ƒâ–â–â–„â–„â–„â–ˆâ–â–…â–â–â–â–â–
wandb:   test_error_force â–‡â–‚â–ƒâ–â–â–‚â–ƒâ–‚â–â–‚â–‚â–â–‡â–„â–‚â–ˆâ–„â–‡â–‚â–„
wandb:          test_loss â–â–‚â–ƒâ–‚â–ƒâ–„â–„â–„â–ƒâ–…â–„â–„â–ˆâ–‚â–„â–„â–‚â–„â–ƒâ–„
wandb: train_error_energy â–ˆâ–â–‚â–â–â–â–â–â–â–â–â–‚â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–†â–‚â–ˆâ–â–â–â–‚â–
wandb:  valid_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–â–â–â–â–â–‚â–â–…â–…â–ƒâ–†â–„â–†â–‚â–„
wandb:         valid_loss â–†â–ƒâ–ƒâ–‚â–‚â–â–â–â–‚â–â–ƒâ–‚â–ˆâ–„â–‡â–…â–ƒâ–…â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1757
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.84547
wandb:   test_error_force 12.07752
wandb:          test_loss 4.73718
wandb: train_error_energy 13.02709
wandb:  train_error_force 4.28239
wandb:         train_loss 0.25078
wandb: valid_error_energy 2.39828
wandb:  valid_error_force 5.8528
wandb:         valid_loss 0.49017
wandb: 
wandb: ğŸš€ View run al_57_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/z71rwore
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_112335-z71rwore/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.7957096099853516, Uncertainty Bias: -0.3801425099372864
8.773804e-05 0.0027542114
5.4323387 6.607144
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_112903-oihg46zt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/oihg46zt
Training model 7. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 12.374517466244608, Training Loss Force: 9.56982106198505, time: 0.9111769199371338
Validation Loss Energy: 1.5691417892675865, Validation Loss Force: 4.718635089281628, time: 0.06284570693969727
Test Loss Energy: 11.8866323342923, Test Loss Force: 11.037329664429736, time: 7.760268688201904


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.957490799207141, Training Loss Force: 4.989665166613569, time: 0.9063796997070312
Validation Loss Energy: 1.7007696488493282, Validation Loss Force: 4.223792547565095, time: 0.061658382415771484
Test Loss Energy: 11.33803841437896, Test Loss Force: 10.471026669153565, time: 7.744264841079712


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.690354141347745, Training Loss Force: 4.808060503963972, time: 0.910686731338501
Validation Loss Energy: 1.795757133466793, Validation Loss Force: 4.703061831884586, time: 0.061359405517578125
Test Loss Energy: 12.707722207819684, Test Loss Force: 10.702092027380413, time: 7.724985837936401


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 12.97016520494482, Training Loss Force: 4.795163236908611, time: 0.8979570865631104
Validation Loss Energy: 27.709854337339554, Validation Loss Force: 6.925951438164892, time: 0.09576869010925293
Test Loss Energy: 34.26062311000306, Test Loss Force: 11.896334180535288, time: 7.99076771736145


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.736800329461602, Training Loss Force: 5.607148741565828, time: 0.8946638107299805
Validation Loss Energy: 10.5449289382152, Validation Loss Force: 4.054668428489417, time: 0.06186366081237793
Test Loss Energy: 19.284755871793013, Test Loss Force: 10.761250961926091, time: 7.814544200897217


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 9.159290874610765, Training Loss Force: 4.256512154169513, time: 0.9100906848907471
Validation Loss Energy: 16.03869380601057, Validation Loss Force: 4.460656406207488, time: 0.06080031394958496
Test Loss Energy: 12.158783969126707, Test Loss Force: 10.324172450302509, time: 7.782280206680298


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.48842313925283, Training Loss Force: 4.40008685041005, time: 0.9134788513183594
Validation Loss Energy: 8.118733940275277, Validation Loss Force: 4.191013422593066, time: 0.0635840892791748
Test Loss Energy: 9.435006379465682, Test Loss Force: 10.54073263673498, time: 7.938973665237427


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 5.65780703815605, Training Loss Force: 4.35430071534654, time: 0.9097497463226318
Validation Loss Energy: 2.832407537491662, Validation Loss Force: 4.149885763332765, time: 0.06366896629333496
Test Loss Energy: 10.692008836325977, Test Loss Force: 11.190475832513394, time: 8.088677406311035


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.208428524744873, Training Loss Force: 5.447157587326701, time: 0.8964145183563232
Validation Loss Energy: 9.71232758513006, Validation Loss Force: 3.724239217397314, time: 0.06161808967590332
Test Loss Energy: 10.099653271182564, Test Loss Force: 10.488269664185564, time: 7.7444539070129395


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.67881931161136, Training Loss Force: 4.632405955127466, time: 0.8841860294342041
Validation Loss Energy: 14.803959546130805, Validation Loss Force: 5.309381009480115, time: 0.06127429008483887
Test Loss Energy: 25.898567922174777, Test Loss Force: 12.25624368019734, time: 7.704594135284424


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 8.590211257312214, Training Loss Force: 4.589619363275923, time: 1.1266090869903564
Validation Loss Energy: 7.1840775282136375, Validation Loss Force: 4.742724773502973, time: 0.06165266036987305
Test Loss Energy: 16.122022709245673, Test Loss Force: 11.080995904674332, time: 7.67919397354126


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.56580731391969, Training Loss Force: 4.519310857687079, time: 0.8969337940216064
Validation Loss Energy: 10.146822334917244, Validation Loss Force: 4.7405648827874725, time: 0.06322026252746582
Test Loss Energy: 10.269995885954462, Test Loss Force: 10.752483845783495, time: 7.680917501449585


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.951020095705058, Training Loss Force: 4.6907531122347335, time: 0.9106738567352295
Validation Loss Energy: 20.647674361034333, Validation Loss Force: 5.466663138037061, time: 0.061460256576538086
Test Loss Energy: 15.03476122678305, Test Loss Force: 11.241152350323745, time: 7.7341907024383545


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 13.929035264061595, Training Loss Force: 4.632261530459292, time: 0.9238438606262207
Validation Loss Energy: 4.143585785187031, Validation Loss Force: 5.410473247069621, time: 0.06221938133239746
Test Loss Energy: 10.417292206817008, Test Loss Force: 10.542690278580782, time: 7.9169838428497314


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 13.899626311444615, Training Loss Force: 4.8179600785164975, time: 0.8874006271362305
Validation Loss Energy: 26.55833242796959, Validation Loss Force: 5.318598176106649, time: 0.061629533767700195
Test Loss Energy: 20.388288714399373, Test Loss Force: 11.782820952025668, time: 7.6867101192474365


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 10.725545667143555, Training Loss Force: 4.880648834980753, time: 0.8657052516937256
Validation Loss Energy: 6.7911865043207476, Validation Loss Force: 4.1794548898971, time: 0.06110191345214844
Test Loss Energy: 9.946905431387409, Test Loss Force: 10.670794869331358, time: 7.720940113067627


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.905858268700381, Training Loss Force: 5.471705283729649, time: 0.8726611137390137
Validation Loss Energy: 12.472178047417433, Validation Loss Force: 6.160500864755486, time: 0.062073707580566406
Test Loss Energy: 21.564898343745323, Test Loss Force: 12.504280656891854, time: 7.742894411087036


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 10.359987162278095, Training Loss Force: 5.276816679927001, time: 1.1310253143310547
Validation Loss Energy: 14.119827744814229, Validation Loss Force: 6.334903133266238, time: 0.06184864044189453
Test Loss Energy: 24.48968515383832, Test Loss Force: 13.124978096526654, time: 7.691100835800171


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 15.356640843840376, Training Loss Force: 6.152682257482327, time: 0.8677783012390137
Validation Loss Energy: 9.432298867211273, Validation Loss Force: 5.059556247860703, time: 0.061430931091308594
Test Loss Energy: 20.584555399122593, Test Loss Force: 11.633023755876136, time: 8.06876516342163


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.028630623449134, Training Loss Force: 4.62516427996109, time: 0.8911800384521484
Validation Loss Energy: 11.468065339343122, Validation Loss Force: 4.800701807035629, time: 0.07417464256286621
Test Loss Energy: 10.940416241214749, Test Loss Force: 10.73689399312314, time: 7.690228462219238

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–ˆâ–„â–‚â–â–â–â–†â–ƒâ–â–ƒâ–â–„â–â–„â–…â–„â–
wandb:   test_error_force â–ƒâ–â–‚â–…â–‚â–â–‚â–ƒâ–â–†â–ƒâ–‚â–ƒâ–‚â–…â–‚â–†â–ˆâ–„â–‚
wandb:          test_loss â–‚â–â–ƒâ–ˆâ–ƒâ–‚â–‚â–ƒâ–â–‡â–„â–‚â–„â–‚â–†â–‚â–†â–‡â–ƒâ–‚
wandb: train_error_energy â–†â–„â–ƒâ–†â–…â–„â–‡â–â–†â–…â–ƒâ–ƒâ–…â–‡â–‡â–…â–ƒâ–„â–ˆâ–…
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–â–â–â–ƒâ–â–â–â–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–
wandb:         train_loss â–ˆâ–ƒâ–‚â–ƒâ–„â–‚â–ƒâ–â–„â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒ
wandb: valid_error_energy â–â–â–â–ˆâ–ƒâ–…â–ƒâ–â–ƒâ–…â–ƒâ–ƒâ–†â–‚â–ˆâ–‚â–„â–„â–ƒâ–„
wandb:  valid_error_force â–ƒâ–‚â–ƒâ–ˆâ–‚â–ƒâ–‚â–‚â–â–„â–ƒâ–ƒâ–…â–…â–„â–‚â–†â–‡â–„â–ƒ
wandb:         valid_loss â–‚â–â–‚â–ˆâ–‚â–ƒâ–‚â–â–‚â–„â–‚â–ƒâ–…â–ƒâ–†â–‚â–…â–…â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1937
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.94042
wandb:   test_error_force 10.73689
wandb:          test_loss 3.45202
wandb: train_error_energy 11.02863
wandb:  train_error_force 4.62516
wandb:         train_loss 0.32283
wandb: valid_error_energy 11.46807
wandb:  valid_error_force 4.8007
wandb:         valid_loss 0.4293
wandb: 
wandb: ğŸš€ View run al_57_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/oihg46zt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_112903-oihg46zt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: -1.121703028678894, Uncertainty Bias: 0.6776449680328369
6.484985e-05 2.0593987
4.067609 4.9425783
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_113438-zrvxc8x5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zrvxc8x5
Training model 8. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 22.415529294919715, Training Loss Force: 9.557726801870757, time: 1.0247936248779297
Validation Loss Energy: 6.261282478886424, Validation Loss Force: 6.791623381185057, time: 0.0692603588104248
Test Loss Energy: 17.770706834229884, Test Loss Force: 12.553077772498924, time: 7.651022672653198


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 15.772006369791612, Training Loss Force: 5.246741426938795, time: 0.9749271869659424
Validation Loss Energy: 10.221323423100056, Validation Loss Force: 6.048659496815461, time: 0.06420135498046875
Test Loss Energy: 16.19616779959385, Test Loss Force: 12.220959802464087, time: 7.6400041580200195


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.43983177643074, Training Loss Force: 4.627747472895344, time: 0.9604835510253906
Validation Loss Energy: 15.503659928792363, Validation Loss Force: 4.41922680758531, time: 0.06847381591796875
Test Loss Energy: 23.150614147741155, Test Loss Force: 10.783897351375812, time: 7.6462273597717285


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.09328995201686, Training Loss Force: 4.646001454110473, time: 1.0131444931030273
Validation Loss Energy: 7.719320714429017, Validation Loss Force: 4.133882754484082, time: 0.0996091365814209
Test Loss Energy: 9.930618393470505, Test Loss Force: 10.82036796938714, time: 7.732439279556274


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 6.616737716237307, Training Loss Force: 3.637693798910525, time: 0.9563069343566895
Validation Loss Energy: 7.537029946085482, Validation Loss Force: 3.3745694994093096, time: 0.0649421215057373
Test Loss Energy: 17.199093345367935, Test Loss Force: 11.08626615460086, time: 7.62091064453125


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 6.188828182940937, Training Loss Force: 3.7136417247351727, time: 0.9634020328521729
Validation Loss Energy: 1.0721475399266662, Validation Loss Force: 3.609047903491378, time: 0.06367111206054688
Test Loss Energy: 11.914508921201644, Test Loss Force: 11.138455908610796, time: 7.629640102386475


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 16.788317739490257, Training Loss Force: 5.062059108882494, time: 0.9746863842010498
Validation Loss Energy: 33.45963394634198, Validation Loss Force: 5.8881976528546645, time: 0.06436419486999512
Test Loss Energy: 44.66446209935624, Test Loss Force: 11.650080571522773, time: 8.152093172073364


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 15.339085528613344, Training Loss Force: 6.347042746024152, time: 0.9837286472320557
Validation Loss Energy: 20.526444371225406, Validation Loss Force: 5.862072104632103, time: 0.06551575660705566
Test Loss Energy: 14.955978099006572, Test Loss Force: 11.342990827998715, time: 7.687488317489624


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.342869791509907, Training Loss Force: 5.315006004329301, time: 0.9929492473602295
Validation Loss Energy: 3.0436598796348675, Validation Loss Force: 4.385264196102674, time: 0.06893610954284668
Test Loss Energy: 11.17407297399801, Test Loss Force: 11.124378117016521, time: 7.676104784011841


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.09397227610791, Training Loss Force: 4.42614680298275, time: 1.0428955554962158
Validation Loss Energy: 16.050172845821443, Validation Loss Force: 6.476004562996049, time: 0.06711626052856445
Test Loss Energy: 12.178850175767664, Test Loss Force: 11.64103690263255, time: 7.657080888748169


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 10.942684294229139, Training Loss Force: 5.078894697608321, time: 1.187150239944458
Validation Loss Energy: 20.59077972222003, Validation Loss Force: 6.496425773038233, time: 0.0635826587677002
Test Loss Energy: 13.609426272303446, Test Loss Force: 11.638471586195246, time: 7.642049789428711


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.217108726931302, Training Loss Force: 4.550720871259419, time: 0.9451925754547119
Validation Loss Energy: 9.408088496312837, Validation Loss Force: 4.219256331724255, time: 0.06341075897216797
Test Loss Energy: 10.089397601307175, Test Loss Force: 10.753592630875964, time: 7.714577674865723


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 6.975956907964784, Training Loss Force: 3.7081656058122703, time: 0.9912865161895752
Validation Loss Energy: 6.832545071485375, Validation Loss Force: 4.112394736563758, time: 0.06435751914978027
Test Loss Energy: 16.66963606418877, Test Loss Force: 10.601016467826517, time: 7.674556732177734


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.866130420592012, Training Loss Force: 4.433666180516568, time: 0.9479506015777588
Validation Loss Energy: 10.62153647651849, Validation Loss Force: 4.184175921129062, time: 0.06448841094970703
Test Loss Energy: 10.11071605725578, Test Loss Force: 10.812278690767346, time: 7.836596965789795


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.885833280028912, Training Loss Force: 3.865611210079949, time: 0.9568126201629639
Validation Loss Energy: 1.2472217125852545, Validation Loss Force: 2.994361376064747, time: 0.06375885009765625
Test Loss Energy: 10.545687125491279, Test Loss Force: 10.320041557592452, time: 7.669880151748657


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 13.778865807870671, Training Loss Force: 4.105951788209237, time: 0.9725332260131836
Validation Loss Energy: 1.5469632186584543, Validation Loss Force: 6.018893753395272, time: 0.06389641761779785
Test Loss Energy: 11.672751172453243, Test Loss Force: 11.950707495807002, time: 8.005512475967407


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.597394435898591, Training Loss Force: 3.7129670671337918, time: 0.965386152267456
Validation Loss Energy: 8.248275278625105, Validation Loss Force: 3.317964553153861, time: 0.0648350715637207
Test Loss Energy: 18.01386103795439, Test Loss Force: 10.882390466455274, time: 7.838854789733887


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 5.7248654723277665, Training Loss Force: 3.169507043797988, time: 1.0081150531768799
Validation Loss Energy: 5.997471645542143, Validation Loss Force: 3.3226497346533277, time: 0.06377196311950684
Test Loss Energy: 16.90261712318711, Test Loss Force: 11.15881838412816, time: 7.637814283370972


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 5.651933899192518, Training Loss Force: 3.175190780097238, time: 0.9954347610473633
Validation Loss Energy: 4.107978984730864, Validation Loss Force: 3.6653293114777936, time: 0.0642697811126709
Test Loss Energy: 11.233772455965434, Test Loss Force: 10.691771104953004, time: 7.636099100112915


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 5.6455056337079474, Training Loss Force: 3.1911097263582042, time: 0.9970643520355225
Validation Loss Energy: 6.676774643760131, Validation Loss Force: 3.7630651456961584, time: 0.06303882598876953
Test Loss Energy: 11.12987467807019, Test Loss Force: 10.721540803956502, time: 7.6683385372161865

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–„â–â–‚â–â–ˆâ–‚â–â–â–‚â–â–‚â–â–â–â–ƒâ–‚â–â–
wandb:   test_error_force â–ˆâ–‡â–‚â–ƒâ–ƒâ–„â–…â–„â–„â–…â–…â–‚â–‚â–ƒâ–â–†â–ƒâ–„â–‚â–‚
wandb:          test_loss â–„â–„â–ƒâ–â–„â–ƒâ–ˆâ–â–â–ƒâ–ƒâ–â–ƒâ–‚â–‚â–„â–„â–†â–…â–…
wandb: train_error_energy â–ˆâ–…â–‚â–ƒâ–â–â–†â–…â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–„â–â–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–‚â–„â–…â–„â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–â–â–
wandb: valid_error_energy â–‚â–ƒâ–„â–‚â–‚â–â–ˆâ–…â–â–„â–…â–ƒâ–‚â–ƒâ–â–â–ƒâ–‚â–‚â–‚
wandb:  valid_error_force â–ˆâ–‡â–„â–ƒâ–‚â–‚â–†â–†â–„â–‡â–‡â–ƒâ–ƒâ–ƒâ–â–‡â–‚â–‚â–‚â–‚
wandb:         valid_loss â–…â–…â–„â–ƒâ–‚â–‚â–ˆâ–†â–ƒâ–‡â–‡â–ƒâ–ƒâ–„â–â–„â–‚â–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2117
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.12987
wandb:   test_error_force 10.72154
wandb:          test_loss 4.81602
wandb: train_error_energy 5.64551
wandb:  train_error_force 3.19111
wandb:         train_loss -0.97874
wandb: valid_error_energy 6.67677
wandb:  valid_error_force 3.76307
wandb:         valid_loss -0.46638
wandb: 
wandb: ğŸš€ View run al_57_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zrvxc8x5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_113438-zrvxc8x5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.2841949462890625, Uncertainty Bias: -0.45917731523513794
4.5776367e-05 0.15639925
2.4955618 5.9458895
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 42 steps.
Found uncertainty sample 1 after 84 steps.
Found uncertainty sample 2 after 274 steps.
Found uncertainty sample 3 after 106 steps.
Found uncertainty sample 4 after 4 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 188 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 58 steps.
Found uncertainty sample 10 after 5 steps.
Found uncertainty sample 11 after 149 steps.
Found uncertainty sample 12 after 80 steps.
Found uncertainty sample 13 after 129 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 8 steps.
Found uncertainty sample 16 after 41 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 75 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 37 steps.
Found uncertainty sample 23 after 273 steps.
Found uncertainty sample 24 after 140 steps.
Found uncertainty sample 25 after 27 steps.
Found uncertainty sample 26 after 57 steps.
Found uncertainty sample 27 after 123 steps.
Found uncertainty sample 28 after 43 steps.
Found uncertainty sample 29 after 32 steps.
Found uncertainty sample 30 after 5 steps.
Found uncertainty sample 31 after 52 steps.
Found uncertainty sample 32 after 89 steps.
Found uncertainty sample 33 after 94 steps.
Found uncertainty sample 34 after 15 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 26 steps.
Found uncertainty sample 38 after 33 steps.
Found uncertainty sample 39 after 142 steps.
Found uncertainty sample 40 after 2 steps.
Found uncertainty sample 41 after 26 steps.
Found uncertainty sample 42 after 158 steps.
Found uncertainty sample 43 after 207 steps.
Found uncertainty sample 44 after 20 steps.
Found uncertainty sample 45 after 15 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 178 steps.
Found uncertainty sample 48 after 67 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 22 steps.
Found uncertainty sample 51 after 49 steps.
Found uncertainty sample 52 after 14 steps.
Found uncertainty sample 53 after 67 steps.
Found uncertainty sample 54 after 12 steps.
Found uncertainty sample 55 after 28 steps.
Found uncertainty sample 56 after 111 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 131 steps.
Found uncertainty sample 59 after 40 steps.
Found uncertainty sample 60 after 72 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 91 steps.
Found uncertainty sample 63 after 19 steps.
Found uncertainty sample 64 after 133 steps.
Found uncertainty sample 65 after 57 steps.
Found uncertainty sample 66 after 30 steps.
Found uncertainty sample 67 after 49 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 173 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 121 steps.
Found uncertainty sample 72 after 15 steps.
Found uncertainty sample 73 after 39 steps.
Found uncertainty sample 74 after 6 steps.
Found uncertainty sample 75 after 123 steps.
Found uncertainty sample 76 after 74 steps.
Found uncertainty sample 77 after 4 steps.
Found uncertainty sample 78 after 27 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 114 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 82 steps.
Found uncertainty sample 84 after 15 steps.
Found uncertainty sample 85 after 306 steps.
Found uncertainty sample 86 after 317 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 85 steps.
Found uncertainty sample 90 after 123 steps.
Found uncertainty sample 91 after 48 steps.
Found uncertainty sample 92 after 266 steps.
Found uncertainty sample 93 after 4 steps.
Found uncertainty sample 94 after 57 steps.
Found uncertainty sample 95 after 63 steps.
Found uncertainty sample 96 after 10 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 5 steps.
Found uncertainty sample 99 after 106 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_114036-7avma7hs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7avma7hs
Training model 9. Added 118 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.85956516341621, Training Loss Force: 10.628574466100499, time: 1.0678269863128662
Validation Loss Energy: 3.8577910497344448, Validation Loss Force: 5.899095303525517, time: 0.06944918632507324
Test Loss Energy: 12.401145349447772, Test Loss Force: 11.598302533929465, time: 7.835562467575073


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.155860548310555, Training Loss Force: 4.140954211238725, time: 1.0554940700531006
Validation Loss Energy: 9.530412682304853, Validation Loss Force: 5.152611019958801, time: 0.06656193733215332
Test Loss Energy: 16.509791639800575, Test Loss Force: 11.476570920664466, time: 8.183712482452393


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 14.899605436374388, Training Loss Force: 5.039802679442706, time: 1.0451085567474365
Validation Loss Energy: 7.156780294945204, Validation Loss Force: 5.823453481308118, time: 0.0682215690612793
Test Loss Energy: 16.505147474890435, Test Loss Force: 11.924360596966283, time: 7.933020114898682


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.406197004029927, Training Loss Force: 4.606229057835433, time: 1.1717944145202637
Validation Loss Energy: 11.09893511734304, Validation Loss Force: 5.504769844994559, time: 0.06725525856018066
Test Loss Energy: 10.698945514161256, Test Loss Force: 12.147794829416249, time: 7.877731561660767


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.469282622852539, Training Loss Force: 5.1242749746858465, time: 1.074415922164917
Validation Loss Energy: 20.722097515016067, Validation Loss Force: 4.984851194740222, time: 0.0654759407043457
Test Loss Energy: 13.973066242597604, Test Loss Force: 11.136394356051301, time: 7.846727132797241


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 14.396114348686307, Training Loss Force: 5.368367376803359, time: 1.02553129196167
Validation Loss Energy: 5.194200272358611, Validation Loss Force: 5.675444854671625, time: 0.06897282600402832
Test Loss Energy: 14.989210095715595, Test Loss Force: 11.435473746092631, time: 7.876233100891113


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.327038901994607, Training Loss Force: 5.090892778960962, time: 0.9915332794189453
Validation Loss Energy: 7.773625265737886, Validation Loss Force: 4.037768730990082, time: 0.06492185592651367
Test Loss Energy: 9.886077630064634, Test Loss Force: 10.697491379715713, time: 8.096254587173462


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.238953444584713, Training Loss Force: 4.417675207623644, time: 1.031709909439087
Validation Loss Energy: 6.298989494726982, Validation Loss Force: 4.9991149348900645, time: 0.06762123107910156
Test Loss Energy: 17.718034450092283, Test Loss Force: 11.17343317442753, time: 7.905885934829712


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.071107236461463, Training Loss Force: 5.044122327272218, time: 0.992936372756958
Validation Loss Energy: 6.854096327443141, Validation Loss Force: 5.622580750067763, time: 0.06653642654418945
Test Loss Energy: 10.299892797822897, Test Loss Force: 11.650303385228773, time: 7.873758316040039


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.595818870895217, Training Loss Force: 4.692877978970882, time: 1.003690242767334
Validation Loss Energy: 8.35692936041032, Validation Loss Force: 4.581912893644779, time: 0.06702542304992676
Test Loss Energy: 10.633373489041132, Test Loss Force: 11.054401705516405, time: 8.070423364639282


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 15.669409434932245, Training Loss Force: 5.221675653667736, time: 1.0202279090881348
Validation Loss Energy: 1.8784346883553589, Validation Loss Force: 4.761756750743713, time: 0.0664832592010498
Test Loss Energy: 11.501900494307142, Test Loss Force: 11.201653665089207, time: 7.859271287918091


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.239924018824227, Training Loss Force: 4.072677298262398, time: 1.0825295448303223
Validation Loss Energy: 1.4297149428497238, Validation Loss Force: 5.374396169377256, time: 0.06951308250427246
Test Loss Energy: 11.730839830844813, Test Loss Force: 12.704450738738032, time: 7.8840813636779785


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.165068506782648, Training Loss Force: 4.920001999700504, time: 0.9852242469787598
Validation Loss Energy: 14.112771359579778, Validation Loss Force: 3.8047056119995304, time: 0.06590127944946289
Test Loss Energy: 11.423483476575626, Test Loss Force: 10.595987134257816, time: 7.893380641937256


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.718260205309337, Training Loss Force: 5.006116234958801, time: 1.0166113376617432
Validation Loss Energy: 10.27166446361141, Validation Loss Force: 3.798819798465221, time: 0.09869956970214844
Test Loss Energy: 21.353797389224887, Test Loss Force: 11.06501613618913, time: 8.437088251113892


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.511127634623852, Training Loss Force: 4.553129442437898, time: 1.0218420028686523
Validation Loss Energy: 7.545325485117022, Validation Loss Force: 5.191057074694694, time: 0.06869792938232422
Test Loss Energy: 17.309374392493375, Test Loss Force: 12.185050786349773, time: 7.864455223083496


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.704731219666881, Training Loss Force: 4.8281501849393305, time: 0.9933273792266846
Validation Loss Energy: 9.96791079353231, Validation Loss Force: 7.458252274285982, time: 0.06868124008178711
Test Loss Energy: 18.780435558942717, Test Loss Force: 12.977178151683145, time: 7.904411792755127


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.458640904917024, Training Loss Force: 5.108920957329884, time: 1.0254499912261963
Validation Loss Energy: 1.6390411968806538, Validation Loss Force: 4.97248704507429, time: 0.06684446334838867
Test Loss Energy: 10.943021185765184, Test Loss Force: 11.905392790408621, time: 8.067485332489014


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.177704316178918, Training Loss Force: 4.449097294571744, time: 0.9920008182525635
Validation Loss Energy: 2.50802234636205, Validation Loss Force: 5.614510329542757, time: 0.06711721420288086
Test Loss Energy: 11.807209780003591, Test Loss Force: 11.473388052918365, time: 7.903887748718262


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.61824331614759, Training Loss Force: 4.727764638780228, time: 1.044145107269287
Validation Loss Energy: 16.755647484775196, Validation Loss Force: 7.425605192117487, time: 0.06689763069152832
Test Loss Energy: 12.576093387030031, Test Loss Force: 12.161946868929714, time: 7.882797002792358


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 13.149768742170151, Training Loss Force: 4.4228509483375165, time: 1.0024349689483643
Validation Loss Energy: 29.238136895002256, Validation Loss Force: 4.350622221055812, time: 0.06673431396484375
Test Loss Energy: 38.44826020033643, Test Loss Force: 11.30034063989086, time: 8.076635837554932

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–ƒâ–â–‚â–‚â–â–ƒâ–â–â–â–â–â–„â–ƒâ–ƒâ–â–â–‚â–ˆ
wandb:   test_error_force â–„â–„â–…â–†â–ƒâ–ƒâ–â–ƒâ–„â–‚â–ƒâ–‡â–â–‚â–†â–ˆâ–…â–„â–†â–ƒ
wandb:          test_loss â–ƒâ–…â–„â–„â–‚â–ƒâ–â–„â–ƒâ–ƒâ–‚â–†â–‚â–„â–†â–†â–ƒâ–„â–…â–ˆ
wandb: train_error_energy â–ˆâ–â–…â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–…â–â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–â–„
wandb:  train_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–ƒâ–‚â–ƒâ–†â–‚â–ƒâ–‚â–‚â–ƒâ–â–â–„â–ƒâ–ƒâ–ƒâ–â–â–…â–ˆ
wandb:  valid_error_force â–…â–„â–…â–„â–ƒâ–…â–â–ƒâ–„â–‚â–ƒâ–„â–â–â–„â–ˆâ–ƒâ–„â–ˆâ–‚
wandb:         valid_loss â–ƒâ–ƒâ–„â–„â–…â–ƒâ–â–‚â–ƒâ–‚â–â–‚â–‚â–â–ƒâ–‡â–â–ƒâ–ˆâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2223
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 38.44826
wandb:   test_error_force 11.30034
wandb:          test_loss 5.66678
wandb: train_error_energy 13.14977
wandb:  train_error_force 4.42285
wandb:         train_loss 0.33739
wandb: valid_error_energy 29.23814
wandb:  valid_error_force 4.35062
wandb:         valid_loss 1.37516
wandb: 
wandb: ğŸš€ View run al_57_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7avma7hs
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_114036-7avma7hs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.932639241218567, Uncertainty Bias: -0.29314473271369934
/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py:240: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(8, 8))
4.1604042e-05 15.434658
3.9414883 5.9054427
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_114615-mhmfz3yq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/mhmfz3yq
Training model 10. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.50165053914011, Training Loss Force: 9.03572095205697, time: 1.1097526550292969
Validation Loss Energy: 6.445719332458411, Validation Loss Force: 5.415900807501612, time: 0.07395410537719727
Test Loss Energy: 10.141022367916436, Test Loss Force: 11.463010141179282, time: 8.252846240997314


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.240695633763171, Training Loss Force: 3.614196611836094, time: 1.1240785121917725
Validation Loss Energy: 7.249986036724241, Validation Loss Force: 3.7949057202181025, time: 0.0697932243347168
Test Loss Energy: 9.973490630514938, Test Loss Force: 10.243317016562338, time: 7.835654020309448


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.106155177424649, Training Loss Force: 4.0067652049459666, time: 1.1006736755371094
Validation Loss Energy: 13.103348437713379, Validation Loss Force: 4.564492595682264, time: 0.06909966468811035
Test Loss Energy: 11.24114999073028, Test Loss Force: 10.999069956955422, time: 8.095149278640747


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.780350956846043, Training Loss Force: 4.84078902420258, time: 1.103039026260376
Validation Loss Energy: 10.090412669502774, Validation Loss Force: 5.828048927141776, time: 0.06873536109924316
Test Loss Energy: 9.932285213090426, Test Loss Force: 10.952810747330371, time: 7.9090447425842285


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.638299956167804, Training Loss Force: 4.681778189081937, time: 1.2292344570159912
Validation Loss Energy: 9.177022942230405, Validation Loss Force: 3.738203912884175, time: 0.06888771057128906
Test Loss Energy: 17.859068144101062, Test Loss Force: 10.907252994478892, time: 7.822779178619385


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.819410406322367, Training Loss Force: 4.046398499339516, time: 1.1300647258758545
Validation Loss Energy: 4.066577442421073, Validation Loss Force: 4.893654596664891, time: 0.06953692436218262
Test Loss Energy: 10.424798595903114, Test Loss Force: 11.18278496145698, time: 7.855833292007446


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 17.631563614998942, Training Loss Force: 4.732652867920937, time: 1.113905668258667
Validation Loss Energy: 6.034753808652271, Validation Loss Force: 5.828263580198449, time: 0.07600736618041992
Test Loss Energy: 10.306271422477815, Test Loss Force: 11.586953943263898, time: 8.1377854347229


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 12.881869850971439, Training Loss Force: 5.735502236227113, time: 1.0940749645233154
Validation Loss Energy: 16.727639268923816, Validation Loss Force: 5.95045839541668, time: 0.07158994674682617
Test Loss Energy: 12.67882657031787, Test Loss Force: 12.001058800083591, time: 7.855061292648315


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 7.553992585706685, Training Loss Force: 4.428013414119621, time: 1.116142749786377
Validation Loss Energy: 13.327013360061756, Validation Loss Force: 3.5638563096487497, time: 0.07037496566772461
Test Loss Energy: 10.860154273209794, Test Loss Force: 10.244249517639659, time: 7.861660718917847


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.388666488680857, Training Loss Force: 3.322473160950463, time: 1.1369998455047607
Validation Loss Energy: 4.369997999457865, Validation Loss Force: 3.7487580963974336, time: 0.06982588768005371
Test Loss Energy: 14.238148236971439, Test Loss Force: 10.935033416296566, time: 8.368802309036255


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 5.323566542952165, Training Loss Force: 3.2299392237041196, time: 1.08740234375
Validation Loss Energy: 8.554938789103188, Validation Loss Force: 4.253308901541845, time: 0.06906652450561523
Test Loss Energy: 19.35265172807878, Test Loss Force: 11.630912815066914, time: 7.805716037750244


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 9.16963020206667, Training Loss Force: 4.135785222087745, time: 1.109626054763794
Validation Loss Energy: 3.6997146603339734, Validation Loss Force: 5.223881624172492, time: 0.06937074661254883
Test Loss Energy: 9.053246135010394, Test Loss Force: 11.669940742752745, time: 7.830676794052124


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.418233047544279, Training Loss Force: 4.6141199493524905, time: 1.0912723541259766
Validation Loss Energy: 13.862366099496931, Validation Loss Force: 3.348377595781262, time: 0.06971216201782227
Test Loss Energy: 21.416838806315106, Test Loss Force: 11.055096633770512, time: 8.125115394592285


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 9.427465037942687, Training Loss Force: 4.854417876020238, time: 1.1139516830444336
Validation Loss Energy: 8.283363037302113, Validation Loss Force: 3.9662594254519563, time: 0.0691382884979248
Test Loss Energy: 9.747749657630635, Test Loss Force: 10.825992671288155, time: 7.815356969833374


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 13.954296162414309, Training Loss Force: 4.142201023347648, time: 1.1103405952453613
Validation Loss Energy: 9.508338599192445, Validation Loss Force: 5.235204572912066, time: 0.07224392890930176
Test Loss Energy: 14.969040108931335, Test Loss Force: 11.76511252018832, time: 7.924848794937134


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.104567834367303, Training Loss Force: 3.359558894715596, time: 1.1461124420166016
Validation Loss Energy: 6.599600189811311, Validation Loss Force: 3.4257944250954244, time: 0.0706784725189209
Test Loss Energy: 15.965105519097603, Test Loss Force: 10.835664658881067, time: 7.826890230178833


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 5.548312477126306, Training Loss Force: 3.1405613315454404, time: 1.1467196941375732
Validation Loss Energy: 6.804480297670928, Validation Loss Force: 3.3175960357173504, time: 0.0736846923828125
Test Loss Energy: 17.241283076998155, Test Loss Force: 10.855606655776034, time: 8.001580476760864


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 5.3875290476462885, Training Loss Force: 3.1466154272867843, time: 1.10422682762146
Validation Loss Energy: 8.005825541787967, Validation Loss Force: 3.4066643620959036, time: 0.07201385498046875
Test Loss Energy: 16.651575954997703, Test Loss Force: 10.835674600883557, time: 7.869155406951904


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.1478195406297775, Training Loss Force: 3.4608633594400304, time: 1.1521403789520264
Validation Loss Energy: 22.850738842576106, Validation Loss Force: 4.506087146712843, time: 0.06921935081481934
Test Loss Energy: 15.495671772275804, Test Loss Force: 10.57830128643458, time: 8.208548307418823


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 15.234014608616839, Training Loss Force: 4.792209876747238, time: 1.1273245811462402
Validation Loss Energy: 2.8074845139916835, Validation Loss Force: 7.330732103773743, time: 0.06985020637512207
Test Loss Energy: 12.111626467866316, Test Loss Force: 12.990637412690695, time: 8.050597429275513

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–â–†â–‚â–‚â–ƒâ–‚â–„â–‡â–â–ˆâ–â–„â–…â–†â–…â–…â–ƒ
wandb:   test_error_force â–„â–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–â–ƒâ–…â–…â–ƒâ–‚â–…â–ƒâ–ƒâ–ƒâ–‚â–ˆ
wandb:          test_loss â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–‚â–†â–ˆâ–â–†â–‚â–„â–…â–†â–†â–…â–…
wandb: train_error_energy â–‡â–‚â–„â–„â–„â–ƒâ–ˆâ–…â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–†â–â–â–â–‚â–‡
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–â–â–‚â–ƒâ–ƒâ–‚â–â–â–â–â–ƒ
wandb:         train_loss â–ˆâ–‚â–ƒâ–„â–„â–ƒâ–…â–…â–ƒâ–‚â–â–ƒâ–ƒâ–„â–„â–‚â–â–â–‚â–…
wandb: valid_error_energy â–‚â–ƒâ–…â–„â–ƒâ–â–‚â–†â–…â–‚â–ƒâ–â–…â–ƒâ–ƒâ–‚â–‚â–ƒâ–ˆâ–
wandb:  valid_error_force â–…â–‚â–ƒâ–…â–‚â–„â–…â–†â–â–‚â–ƒâ–„â–â–‚â–„â–â–â–â–ƒâ–ˆ
wandb:         valid_loss â–…â–‚â–…â–‡â–ƒâ–„â–†â–ˆâ–ƒâ–â–„â–…â–ƒâ–ƒâ–…â–â–â–â–‡â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2403
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.11163
wandb:   test_error_force 12.99064
wandb:          test_loss 4.65325
wandb: train_error_energy 15.23401
wandb:  train_error_force 4.79221
wandb:         train_loss 0.7002
wandb: valid_error_energy 2.80748
wandb:  valid_error_force 7.33073
wandb:         valid_loss 1.20023
wandb: 
wandb: ğŸš€ View run al_57_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/mhmfz3yq
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_114615-mhmfz3yq/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 1.9696412086486816, Uncertainty Bias: -0.12755241990089417
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:801: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:622: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:622: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:649: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:649: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:913: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00031280518 0.0050480366
6.826641 8.402473
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_115153-oc38pqbc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/oc38pqbc
Training model 11. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 14.965498728021144, Training Loss Force: 8.064182924460889, time: 1.2119863033294678
Validation Loss Energy: 3.049894281717127, Validation Loss Force: 4.466251636506362, time: 0.07706809043884277
Test Loss Energy: 8.973294374270894, Test Loss Force: 10.788206635880165, time: 7.849609613418579


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.085016071048537, Training Loss Force: 4.0860620702984605, time: 1.2167038917541504
Validation Loss Energy: 3.1054323087598625, Validation Loss Force: 4.671749428576781, time: 0.07392334938049316
Test Loss Energy: 9.573317802102842, Test Loss Force: 10.84889391548475, time: 7.831553220748901


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.242648198391358, Training Loss Force: 3.8225616349946008, time: 1.18522047996521
Validation Loss Energy: 6.082933177094958, Validation Loss Force: 3.3172495625262868, time: 0.07313323020935059
Test Loss Energy: 10.025779226309526, Test Loss Force: 10.271095433191894, time: 8.071593284606934


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 5.341234555167059, Training Loss Force: 3.151032052397975, time: 1.224463701248169
Validation Loss Energy: 4.641814011267396, Validation Loss Force: 3.242990849708818, time: 0.07238006591796875
Test Loss Energy: 10.229774792062114, Test Loss Force: 10.403839385727581, time: 7.844224691390991


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 5.257725777043995, Training Loss Force: 3.1437962205729213, time: 1.1913084983825684
Validation Loss Energy: 0.9726106741551077, Validation Loss Force: 3.8300462514826963, time: 0.07250189781188965
Test Loss Energy: 11.370610937357778, Test Loss Force: 10.949196885382314, time: 7.845185995101929


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.572280877964447, Training Loss Force: 4.17112103527845, time: 1.2080888748168945
Validation Loss Energy: 8.423548406165578, Validation Loss Force: 5.281031664497172, time: 0.07406759262084961
Test Loss Energy: 9.666283634781346, Test Loss Force: 11.79897265839736, time: 7.846100568771362


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.876787887275793, Training Loss Force: 4.410341046870964, time: 1.1644794940948486
Validation Loss Energy: 8.167387593998793, Validation Loss Force: 4.885800165211435, time: 0.07279467582702637
Test Loss Energy: 17.239824829585352, Test Loss Force: 11.60155959363602, time: 8.05845046043396


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 5.8163987014907175, Training Loss Force: 3.209626913089528, time: 1.1814115047454834
Validation Loss Energy: 7.478777025481022, Validation Loss Force: 3.0968321583366936, time: 0.07808542251586914
Test Loss Energy: 17.745709860674417, Test Loss Force: 10.61885463999848, time: 7.897371292114258


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 5.354677727900636, Training Loss Force: 3.0756016971441618, time: 1.1588172912597656
Validation Loss Energy: 5.539445443082456, Validation Loss Force: 3.409489476884862, time: 0.07403969764709473
Test Loss Energy: 10.852078144893484, Test Loss Force: 10.380355149406277, time: 7.856824636459351


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.865332955508704, Training Loss Force: 4.22284043079112, time: 1.1817617416381836
Validation Loss Energy: 13.122922836993599, Validation Loss Force: 5.587866852886767, time: 0.07297682762145996
Test Loss Energy: 11.098973670582076, Test Loss Force: 12.02828393401522, time: 8.425250053405762


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 12.218464171236263, Training Loss Force: 5.169342195400695, time: 1.2040987014770508
Validation Loss Energy: 3.637461265853774, Validation Loss Force: 5.044431223454412, time: 0.07378768920898438
Test Loss Energy: 10.400221000448182, Test Loss Force: 11.125673151442781, time: 7.86869478225708


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 10.766120732088796, Training Loss Force: 4.738600009008779, time: 1.2497990131378174
Validation Loss Energy: 10.347995001497164, Validation Loss Force: 4.793120145285933, time: 0.07327866554260254
Test Loss Energy: 10.21307508643003, Test Loss Force: 10.649215454470184, time: 7.902218580245972


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.925448402478263, Training Loss Force: 4.593388648398494, time: 1.1724934577941895
Validation Loss Energy: 5.01806185251706, Validation Loss Force: 5.032544699106495, time: 0.07282400131225586
Test Loss Energy: 10.05726203213593, Test Loss Force: 10.873777642543702, time: 8.050612688064575


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 13.596252255530855, Training Loss Force: 5.201646422064496, time: 1.2094125747680664
Validation Loss Energy: 8.762341738386166, Validation Loss Force: 5.704975459473714, time: 0.07482123374938965
Test Loss Energy: 15.478980950093419, Test Loss Force: 11.799792575156559, time: 7.896819353103638


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 5.880301292251229, Training Loss Force: 3.752117988251862, time: 1.2770965099334717
Validation Loss Energy: 1.4711682557359436, Validation Loss Force: 3.7043785769300035, time: 0.07338333129882812
Test Loss Energy: 10.935783734375073, Test Loss Force: 10.418849725031453, time: 7.886429786682129


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.22839819706527, Training Loss Force: 4.194183678681715, time: 1.1689412593841553
Validation Loss Energy: 29.608312771311613, Validation Loss Force: 4.739626109668242, time: 0.07404303550720215
Test Loss Energy: 34.79742933569506, Test Loss Force: 11.135435983384005, time: 7.875518560409546


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.141586823172595, Training Loss Force: 4.057077972552529, time: 1.1756789684295654
Validation Loss Energy: 5.168090978983701, Validation Loss Force: 3.115298333277631, time: 0.08286523818969727
Test Loss Energy: 14.819758012967332, Test Loss Force: 10.528142578145335, time: 8.09945011138916


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 5.692157266801722, Training Loss Force: 3.0735645493591024, time: 1.2661843299865723
Validation Loss Energy: 4.851396668819862, Validation Loss Force: 3.53741791127616, time: 0.07557177543640137
Test Loss Energy: 10.598231238211143, Test Loss Force: 10.40757045325289, time: 7.876454830169678


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 6.774561543435964, Training Loss Force: 3.7037262621690044, time: 1.1875333786010742
Validation Loss Energy: 16.167649524506608, Validation Loss Force: 4.810596110534929, time: 0.07957100868225098
Test Loss Energy: 11.927163500216482, Test Loss Force: 10.87321889920557, time: 8.229805707931519


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 15.612351241683477, Training Loss Force: 4.411903612483002, time: 1.2106835842132568
Validation Loss Energy: 3.373258312143514, Validation Loss Force: 5.04601595976598, time: 0.08100104331970215
Test Loss Energy: 10.620201827968781, Test Loss Force: 11.409140240043264, time: 8.107044696807861

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–â–â–‚â–â–ƒâ–ƒâ–‚â–‚â–â–â–â–ƒâ–‚â–ˆâ–ƒâ–â–‚â–
wandb:   test_error_force â–ƒâ–ƒâ–â–‚â–„â–‡â–†â–‚â–â–ˆâ–„â–ƒâ–ƒâ–‡â–‚â–„â–‚â–‚â–ƒâ–†
wandb:          test_loss â–â–ƒâ–‚â–…â–‡â–ƒâ–†â–‡â–†â–ƒâ–â–â–â–„â–ƒâ–ˆâ–„â–†â–„â–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–â–â–ƒâ–…â–â–â–„â–†â–…â–ƒâ–‡â–â–ƒâ–„â–â–‚â–ˆ
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–ƒâ–ƒâ–â–â–ƒâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–â–â–ƒâ–„â–â–â–„â–…â–…â–„â–†â–‚â–ƒâ–ƒâ–â–‚â–…
wandb: valid_error_energy â–‚â–‚â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–ƒâ–‚â–ƒâ–â–ˆâ–‚â–‚â–…â–‚
wandb:  valid_error_force â–…â–…â–‚â–â–ƒâ–‡â–†â–â–‚â–ˆâ–†â–†â–†â–ˆâ–ƒâ–…â–â–‚â–†â–†
wandb:         valid_loss â–ƒâ–ƒâ–â–â–‚â–…â–„â–â–‚â–†â–„â–…â–„â–†â–â–ˆâ–â–‚â–†â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2583
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.6202
wandb:   test_error_force 11.40914
wandb:          test_loss 3.86646
wandb: train_error_energy 15.61235
wandb:  train_error_force 4.4119
wandb:         train_loss 0.4957
wandb: valid_error_energy 3.37326
wandb:  valid_error_force 5.04602
wandb:         valid_loss 0.03586
wandb: 
wandb: ğŸš€ View run al_57_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/oc38pqbc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_115153-oc38pqbc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.3051974773406982, Uncertainty Bias: -0.6403512358665466
0.00045776367 0.008162975
4.3776307 7.0951357
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_115727-zmwji7ha
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zmwji7ha
Training model 12. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.79121083271057, Training Loss Force: 10.825166509555206, time: 1.289414405822754
Validation Loss Energy: 5.000194657578668, Validation Loss Force: 5.4728092518029605, time: 0.07943272590637207
Test Loss Energy: 9.983289784340505, Test Loss Force: 11.510682957133703, time: 7.906233072280884


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.661197571536471, Training Loss Force: 5.070884714700031, time: 1.2811481952667236
Validation Loss Energy: 14.716438547647307, Validation Loss Force: 5.113741003169062, time: 0.08044219017028809
Test Loss Energy: 22.544607229231485, Test Loss Force: 10.873421022168104, time: 7.9472386837005615


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 8.01519781411084, Training Loss Force: 4.371423296982703, time: 1.294713020324707
Validation Loss Energy: 8.23872188158822, Validation Loss Force: 4.065147015827632, time: 0.0838327407836914
Test Loss Energy: 9.587240555349586, Test Loss Force: 10.480200894443339, time: 8.112172603607178


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.970121306953185, Training Loss Force: 3.791257191563703, time: 1.3384549617767334
Validation Loss Energy: 2.1586186066688566, Validation Loss Force: 4.172145552512875, time: 0.07622385025024414
Test Loss Energy: 10.080521701377434, Test Loss Force: 11.176294535906282, time: 7.919771909713745


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.500280230963817, Training Loss Force: 4.760363919404117, time: 1.2830049991607666
Validation Loss Energy: 1.3074603409658123, Validation Loss Force: 5.541813084111107, time: 0.07568025588989258
Test Loss Energy: 10.424235776903544, Test Loss Force: 11.82037987423127, time: 7.9465882778167725


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.7733842634543, Training Loss Force: 4.456636721359229, time: 1.2543418407440186
Validation Loss Energy: 8.169622301547324, Validation Loss Force: 4.8859143944832955, time: 0.0771172046661377
Test Loss Energy: 15.896330299219711, Test Loss Force: 11.732736291136804, time: 7.957979917526245


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 6.9730093564888564, Training Loss Force: 3.9272012250803385, time: 1.2402067184448242
Validation Loss Energy: 1.0452054639459878, Validation Loss Force: 3.2079438394855138, time: 0.07758069038391113
Test Loss Energy: 10.63604058509684, Test Loss Force: 10.386374752123077, time: 8.576085805892944


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 7.416304619259601, Training Loss Force: 3.648390154190442, time: 1.3221449851989746
Validation Loss Energy: 12.809536944999955, Validation Loss Force: 4.5374832736195145, time: 0.08194875717163086
Test Loss Energy: 20.838768317922103, Test Loss Force: 11.485218644175793, time: 7.937015056610107


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 10.50979867788489, Training Loss Force: 4.696193302626832, time: 1.2668123245239258
Validation Loss Energy: 11.460606813631124, Validation Loss Force: 5.770072561616557, time: 0.0774693489074707
Test Loss Energy: 10.49944444234692, Test Loss Force: 11.264193384111701, time: 7.979897499084473


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.881212466683765, Training Loss Force: 4.369458482354944, time: 1.2673883438110352
Validation Loss Energy: 5.7920208366615125, Validation Loss Force: 6.647946337444298, time: 0.0773780345916748
Test Loss Energy: 13.009942781010354, Test Loss Force: 11.467894644206954, time: 8.18721604347229


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 9.47404608225494, Training Loss Force: 4.962565808845993, time: 1.2475898265838623
Validation Loss Energy: 15.016792059868088, Validation Loss Force: 3.583667628900237, time: 0.07671427726745605
Test Loss Energy: 11.536024706465177, Test Loss Force: 10.277557711497256, time: 7.953571557998657


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 10.776787794640063, Training Loss Force: 4.594138806721737, time: 1.2809648513793945
Validation Loss Energy: 9.275702782292932, Validation Loss Force: 4.7724288375697395, time: 0.07661914825439453
Test Loss Energy: 9.814311816665242, Test Loss Force: 10.692023161762966, time: 8.019735336303711


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 10.090485092002632, Training Loss Force: 4.326454779233061, time: 1.2440109252929688
Validation Loss Energy: 1.9803561458443015, Validation Loss Force: 3.162508200258949, time: 0.0778961181640625
Test Loss Energy: 9.807388265817309, Test Loss Force: 10.189148267784732, time: 8.19735836982727


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 12.830501548379788, Training Loss Force: 4.498862682105032, time: 1.2408239841461182
Validation Loss Energy: 5.16191658623627, Validation Loss Force: 4.033501276808376, time: 0.0762171745300293
Test Loss Energy: 12.545683361511273, Test Loss Force: 10.483103329635961, time: 7.99203085899353


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.962829949435854, Training Loss Force: 4.858534725001975, time: 1.2366960048675537
Validation Loss Energy: 17.323527733047506, Validation Loss Force: 4.984999047053119, time: 0.08008551597595215
Test Loss Energy: 12.706498446173038, Test Loss Force: 10.909784404584041, time: 7.9804277420043945


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.49040796914162, Training Loss Force: 4.326949191757148, time: 1.245577335357666
Validation Loss Energy: 20.506250951719508, Validation Loss Force: 3.556717091492013, time: 0.08051514625549316
Test Loss Energy: 27.932417772547577, Test Loss Force: 10.854406005088281, time: 8.184160947799683


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.180497937406006, Training Loss Force: 3.743591651370862, time: 1.3317196369171143
Validation Loss Energy: 2.0188724526957333, Validation Loss Force: 5.1169385321045855, time: 0.07803606986999512
Test Loss Energy: 10.509116938231704, Test Loss Force: 11.061195613957508, time: 7.959185838699341


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 9.06388899141564, Training Loss Force: 4.443057133439957, time: 1.251159906387329
Validation Loss Energy: 4.064110045615047, Validation Loss Force: 4.978538524453169, time: 0.08483362197875977
Test Loss Energy: 16.236017448708196, Test Loss Force: 11.66417083258922, time: 8.001188278198242


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.49709639230593, Training Loss Force: 3.8457878416352305, time: 1.3255445957183838
Validation Loss Energy: 3.49186414606768, Validation Loss Force: 4.54298654156112, time: 0.07721638679504395
Test Loss Energy: 8.775417425559201, Test Loss Force: 11.120754881979812, time: 8.000355243682861


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.22018761725567, Training Loss Force: 3.529613054420657, time: 1.5356221199035645
Validation Loss Energy: 8.208266086484798, Validation Loss Force: 3.142767578461294, time: 0.08033466339111328
Test Loss Energy: 10.151264892151564, Test Loss Force: 10.227824676666604, time: 7.933162212371826

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.040 MB of 0.058 MB uploadedwandb: / 0.040 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–â–â–‚â–„â–‚â–…â–‚â–ƒâ–‚â–â–â–‚â–‚â–ˆâ–‚â–„â–â–‚
wandb:   test_error_force â–‡â–„â–‚â–…â–ˆâ–ˆâ–‚â–‡â–†â–†â–â–ƒâ–â–‚â–„â–„â–…â–‡â–…â–
wandb:          test_loss â–â–„â–‚â–„â–ƒâ–…â–ƒâ–ˆâ–ƒâ–„â–â–‚â–‚â–‚â–ƒâ–†â–„â–†â–…â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–„â–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–„â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–†â–„â–â–â–„â–â–…â–…â–ƒâ–†â–„â–â–‚â–‡â–ˆâ–â–‚â–‚â–„
wandb:  valid_error_force â–†â–…â–ƒâ–ƒâ–†â–„â–â–„â–†â–ˆâ–‚â–„â–â–ƒâ–…â–‚â–…â–…â–„â–
wandb:         valid_loss â–†â–‡â–„â–ƒâ–…â–…â–â–†â–ˆâ–ˆâ–…â–…â–â–ƒâ–‡â–†â–…â–…â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2763
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.15126
wandb:   test_error_force 10.22782
wandb:          test_loss 3.90607
wandb: train_error_energy 6.22019
wandb:  train_error_force 3.52961
wandb:         train_loss -0.68874
wandb: valid_error_energy 8.20827
wandb:  valid_error_force 3.14277
wandb:         valid_loss -0.82366
wandb: 
wandb: ğŸš€ View run al_57_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/zmwji7ha
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_115727-zmwji7ha/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 9.951176643371582, Uncertainty Bias: -2.207240104675293
7.6293945e-06 1.9047508
2.5201693 10.053494
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 75 steps.
Found uncertainty sample 1 after 277 steps.
Found uncertainty sample 2 after 65 steps.
Found uncertainty sample 3 after 60 steps.
Found uncertainty sample 4 after 505 steps.
Found uncertainty sample 5 after 478 steps.
Found uncertainty sample 6 after 380 steps.
Found uncertainty sample 7 after 478 steps.
Found uncertainty sample 8 after 2 steps.
Found uncertainty sample 9 after 215 steps.
Found uncertainty sample 10 after 254 steps.
Found uncertainty sample 11 after 1869 steps.
Found uncertainty sample 12 after 337 steps.
Found uncertainty sample 13 after 206 steps.
Found uncertainty sample 14 after 227 steps.
Found uncertainty sample 15 after 582 steps.
Found uncertainty sample 16 after 458 steps.
Found uncertainty sample 17 after 205 steps.
Found uncertainty sample 18 after 9 steps.
Found uncertainty sample 19 after 244 steps.
Found uncertainty sample 20 after 231 steps.
Found uncertainty sample 21 after 957 steps.
Found uncertainty sample 22 after 415 steps.
Found uncertainty sample 23 after 216 steps.
Found uncertainty sample 24 after 62 steps.
Found uncertainty sample 25 after 508 steps.
Found uncertainty sample 26 after 105 steps.
Found uncertainty sample 27 after 591 steps.
Found uncertainty sample 28 after 438 steps.
Found uncertainty sample 29 after 750 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 117 steps.
Found uncertainty sample 32 after 148 steps.
Found uncertainty sample 33 after 150 steps.
Found uncertainty sample 34 after 27 steps.
Found uncertainty sample 35 after 922 steps.
Found uncertainty sample 36 after 111 steps.
Found uncertainty sample 37 after 95 steps.
Found uncertainty sample 38 after 500 steps.
Found uncertainty sample 39 after 731 steps.
Found uncertainty sample 40 after 554 steps.
Found uncertainty sample 41 after 332 steps.
Found uncertainty sample 42 after 84 steps.
Found uncertainty sample 43 after 321 steps.
Found uncertainty sample 44 after 178 steps.
Found uncertainty sample 45 after 63 steps.
Found uncertainty sample 46 after 38 steps.
Found uncertainty sample 47 after 182 steps.
Found uncertainty sample 48 after 24 steps.
Found uncertainty sample 49 after 93 steps.
Found uncertainty sample 50 after 20 steps.
Found uncertainty sample 51 after 204 steps.
Found uncertainty sample 52 after 30 steps.
Found uncertainty sample 53 after 401 steps.
Found uncertainty sample 54 after 586 steps.
Found uncertainty sample 55 after 283 steps.
Found uncertainty sample 56 after 116 steps.
Found uncertainty sample 57 after 200 steps.
Found uncertainty sample 58 after 194 steps.
Found uncertainty sample 59 after 155 steps.
Found uncertainty sample 60 after 95 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 755 steps.
Found uncertainty sample 63 after 5 steps.
Found uncertainty sample 64 after 29 steps.
Found uncertainty sample 65 after 11 steps.
Found uncertainty sample 66 after 72 steps.
Found uncertainty sample 67 after 771 steps.
Found uncertainty sample 68 after 501 steps.
Found uncertainty sample 69 after 403 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 104 steps.
Found uncertainty sample 72 after 7 steps.
Found uncertainty sample 73 after 62 steps.
Found uncertainty sample 74 after 12 steps.
Found uncertainty sample 75 after 396 steps.
Found uncertainty sample 76 after 174 steps.
Found uncertainty sample 77 after 2000 steps.
Found uncertainty sample 78 after 161 steps.
Found uncertainty sample 79 after 131 steps.
Found uncertainty sample 80 after 907 steps.
Found uncertainty sample 81 after 194 steps.
Found uncertainty sample 82 after 5 steps.
Found uncertainty sample 83 after 64 steps.
Found uncertainty sample 84 after 72 steps.
Found uncertainty sample 85 after 104 steps.
Found uncertainty sample 86 after 7 steps.
Found uncertainty sample 87 after 399 steps.
Found uncertainty sample 88 after 166 steps.
Found uncertainty sample 89 after 1072 steps.
Found uncertainty sample 90 after 1452 steps.
Found uncertainty sample 91 after 518 steps.
Found uncertainty sample 92 after 1376 steps.
Found uncertainty sample 93 after 229 steps.
Found uncertainty sample 94 after 533 steps.
Found uncertainty sample 95 after 29 steps.
Found uncertainty sample 96 after 394 steps.
Found uncertainty sample 97 after 274 steps.
Found uncertainty sample 98 after 166 steps.
Found uncertainty sample 99 after 4 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_120603-eiclbwhs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/eiclbwhs
Training model 13. Added 101 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 26.106466416914024, Training Loss Force: 46.91025229274543, time: 1.327615737915039
Validation Loss Energy: 25.99677331141188, Validation Loss Force: 19.098117102493106, time: 0.08100461959838867
Test Loss Energy: 25.77381198159558, Test Loss Force: 27.78548018916622, time: 8.03196382522583


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 25.859383192456693, Training Loss Force: 16.593349298264346, time: 1.2669479846954346
Validation Loss Energy: 30.476907701159398, Validation Loss Force: 17.83976922502599, time: 0.08084821701049805
Test Loss Energy: 22.05217733685625, Test Loss Force: 22.009703507375203, time: 8.025722026824951


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 15.36860182875069, Training Loss Force: 13.127994586975007, time: 1.3129067420959473
Validation Loss Energy: 3.617443754973158, Validation Loss Force: 9.108946304245901, time: 0.07962417602539062
Test Loss Energy: 9.45597003369768, Test Loss Force: 15.976338634243579, time: 8.185277223587036


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 19.805418155427116, Training Loss Force: 12.298107026476366, time: 1.2975482940673828
Validation Loss Energy: 16.173169047295865, Validation Loss Force: 8.605628529497064, time: 0.07987165451049805
Test Loss Energy: 12.356297615056807, Test Loss Force: 15.145431779369265, time: 8.023508787155151


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 16.242679597882994, Training Loss Force: 9.269551274985496, time: 1.3097455501556396
Validation Loss Energy: 15.177005182392882, Validation Loss Force: 7.518760833338691, time: 0.08091115951538086
Test Loss Energy: 11.275450370322764, Test Loss Force: 13.62913431037705, time: 8.003865242004395


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 13.458997284926545, Training Loss Force: 7.326276058721843, time: 1.3172616958618164
Validation Loss Energy: 5.932263431495482, Validation Loss Force: 7.286720211066241, time: 0.07939314842224121
Test Loss Energy: 10.686896268797367, Test Loss Force: 13.009989320027657, time: 8.024036884307861


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 16.662314570461668, Training Loss Force: 8.78855258868443, time: 1.5232653617858887
Validation Loss Energy: 7.066158183266367, Validation Loss Force: 9.146744837105437, time: 0.08111977577209473
Test Loss Energy: 10.418166897854492, Test Loss Force: 14.448919188822773, time: 8.049962043762207


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 18.114436233201545, Training Loss Force: 7.681829667867197, time: 1.3016879558563232
Validation Loss Energy: 14.884196146174427, Validation Loss Force: 8.208586730054936, time: 0.08185505867004395
Test Loss Energy: 19.77705677927659, Test Loss Force: 13.197538691885319, time: 8.066939353942871


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.707605094757481, Training Loss Force: 7.30872978445297, time: 1.2763183116912842
Validation Loss Energy: 4.753795660769356, Validation Loss Force: 6.659338090949964, time: 0.08356523513793945
Test Loss Energy: 8.739935327985403, Test Loss Force: 11.842069695683, time: 8.057463645935059


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 13.246354860127996, Training Loss Force: 7.223121632689865, time: 1.3797619342803955
Validation Loss Energy: 13.74022450220458, Validation Loss Force: 7.701213259482169, time: 0.07990837097167969
Test Loss Energy: 13.069861434702567, Test Loss Force: 13.169997363103246, time: 8.221603155136108


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 16.90963165937476, Training Loss Force: 7.46455006037768, time: 1.383840799331665
Validation Loss Energy: 16.5402239928559, Validation Loss Force: 4.914196270715022, time: 0.07999753952026367
Test Loss Energy: 16.762007069469426, Test Loss Force: 11.30947463084784, time: 8.46904993057251


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.565019583171706, Training Loss Force: 5.789554869886225, time: 1.3480687141418457
Validation Loss Energy: 10.784669236884689, Validation Loss Force: 5.8430606129527884, time: 0.07954287528991699
Test Loss Energy: 12.042337150396948, Test Loss Force: 11.326741175182187, time: 8.003814458847046


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 16.35274838087174, Training Loss Force: 6.827814702993894, time: 1.2931652069091797
Validation Loss Energy: 13.858390564565537, Validation Loss Force: 6.655280613772868, time: 0.0797123908996582
Test Loss Energy: 12.719983205712316, Test Loss Force: 12.334752260414314, time: 8.1921706199646


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.428778925433285, Training Loss Force: 5.3743729425112345, time: 1.3332457542419434
Validation Loss Energy: 6.152045003938879, Validation Loss Force: 4.3932333021662835, time: 0.08101940155029297
Test Loss Energy: 8.408201472719554, Test Loss Force: 10.495542709996428, time: 8.007557153701782


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 25.21617250126361, Training Loss Force: 8.055259012549739, time: 1.2700815200805664
Validation Loss Energy: 17.11427752052991, Validation Loss Force: 10.24793327671501, time: 0.08073830604553223
Test Loss Energy: 13.631469258678688, Test Loss Force: 14.216062330243965, time: 8.056824445724487


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.813385150659444, Training Loss Force: 6.071193728192028, time: 1.280975103378296
Validation Loss Energy: 9.904037258346339, Validation Loss Force: 4.77609018633623, time: 0.08040332794189453
Test Loss Energy: 11.382644239144497, Test Loss Force: 10.696929451392727, time: 8.24454140663147


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 10.266930015326356, Training Loss Force: 4.678323297194313, time: 1.2912487983703613
Validation Loss Energy: 42.11410673435148, Validation Loss Force: 7.515176750765837, time: 0.08198022842407227
Test Loss Energy: 39.14824708707456, Test Loss Force: 11.873616975302316, time: 8.023679256439209


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 18.23817994242115, Training Loss Force: 7.352970967002339, time: 1.3097336292266846
Validation Loss Energy: 24.21036021031751, Validation Loss Force: 5.9759949837482615, time: 0.0837252140045166
Test Loss Energy: 20.839240525734773, Test Loss Force: 11.531748847980474, time: 8.056283235549927


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 12.623142112145793, Training Loss Force: 5.439149069554324, time: 1.351266860961914
Validation Loss Energy: 9.064886760341171, Validation Loss Force: 7.694032179525998, time: 0.08005094528198242
Test Loss Energy: 11.109097865401958, Test Loss Force: 12.815537922783378, time: 8.255694150924683


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.655279655058489, Training Loss Force: 4.68981743892148, time: 1.295358419418335
Validation Loss Energy: 7.046413664758658, Validation Loss Force: 4.385538524490457, time: 0.07968521118164062
Test Loss Energy: 7.957624570940704, Test Loss Force: 10.244338981672424, time: 8.089737176895142

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.051 MB of 0.058 MB uploadedwandb: / 0.051 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–â–‚â–‚â–‚â–‚â–„â–â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ˆâ–„â–‚â–
wandb:   test_error_force â–ˆâ–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–â–‚â–â–ƒâ–â–‚â–‚â–‚â–
wandb:          test_loss â–ˆâ–†â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–†â–…â–„â–‚
wandb: train_error_energy â–ˆâ–ˆâ–„â–†â–„â–ƒâ–…â–…â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–ˆâ–‚â–‚â–…â–ƒâ–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–â–â–â–â–
wandb:         train_loss â–ˆâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–â–ƒâ–‚â–
wandb: valid_error_energy â–…â–†â–â–ƒâ–ƒâ–â–‚â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–ˆâ–…â–‚â–‚
wandb:  valid_error_force â–ˆâ–‡â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–â–„â–â–‚â–‚â–ƒâ–
wandb:         valid_loss â–ˆâ–ˆâ–ƒâ–„â–„â–ƒâ–„â–„â–‚â–„â–‚â–‚â–ƒâ–â–…â–‚â–†â–„â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2853
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.95762
wandb:   test_error_force 10.24434
wandb:          test_loss 3.24833
wandb: train_error_energy 6.65528
wandb:  train_error_force 4.68982
wandb:         train_loss 0.04373
wandb: valid_error_energy 7.04641
wandb:  valid_error_force 4.38554
wandb:         valid_loss -0.0928
wandb: 
wandb: ğŸš€ View run al_57_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/eiclbwhs
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_120603-eiclbwhs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: -0.48010048270225525, Uncertainty Bias: 0.43625712394714355
7.05719e-05 0.99605894
4.2719955 4.5119376
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_121153-yov6eywn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yov6eywn
Training model 14. Added 200 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 21.487309462105383, Training Loss Force: 12.251542920852783, time: 1.411228895187378
Validation Loss Energy: 11.28003950447707, Validation Loss Force: 4.669934675037471, time: 0.08148574829101562
Test Loss Energy: 10.89350665115446, Test Loss Force: 10.576245702807167, time: 8.00964903831482


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.987260616062514, Training Loss Force: 5.1040866666925, time: 1.4481964111328125
Validation Loss Energy: 29.175332617055034, Validation Loss Force: 5.091989122310816, time: 0.09015774726867676
Test Loss Energy: 25.126663853650303, Test Loss Force: 10.148019746993024, time: 7.926888465881348


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 9.645296147912944, Training Loss Force: 5.4026609750890895, time: 1.352811574935913
Validation Loss Energy: 1.8233614831547473, Validation Loss Force: 4.313369450272948, time: 0.08179092407226562
Test Loss Energy: 6.959401629652397, Test Loss Force: 10.568552001171243, time: 8.140095233917236


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 9.737265308309498, Training Loss Force: 5.131763210991306, time: 1.339472770690918
Validation Loss Energy: 8.1446348153296, Validation Loss Force: 4.966394149234269, time: 0.08164048194885254
Test Loss Energy: 8.51645136687005, Test Loss Force: 10.182335986224569, time: 7.940144062042236


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.386573068566076, Training Loss Force: 4.362645792403334, time: 1.4337739944458008
Validation Loss Energy: 11.225238400972783, Validation Loss Force: 4.220496153528781, time: 0.08440208435058594
Test Loss Energy: 14.181878792496937, Test Loss Force: 10.302109957643767, time: 7.945325613021851


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 10.284403953765262, Training Loss Force: 5.145651563775515, time: 1.429900884628296
Validation Loss Energy: 10.861141837685544, Validation Loss Force: 4.7277536134765175, time: 0.08418512344360352
Test Loss Energy: 15.060659378512112, Test Loss Force: 10.326838837547538, time: 7.9601287841796875


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 12.284826090251023, Training Loss Force: 5.09798227409289, time: 1.5984768867492676
Validation Loss Energy: 2.157689296988327, Validation Loss Force: 5.20881404840585, time: 0.08031344413757324
Test Loss Energy: 8.320455748606495, Test Loss Force: 10.551262970750578, time: 7.916909694671631


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.671616076497838, Training Loss Force: 4.894163229247448, time: 1.379897117614746
Validation Loss Energy: 21.123300110119004, Validation Loss Force: 4.928237341718936, time: 0.0836784839630127
Test Loss Energy: 27.320536744040528, Test Loss Force: 11.167764339734953, time: 8.025673389434814


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 9.859628130914157, Training Loss Force: 5.2402820786955715, time: 1.3540699481964111
Validation Loss Energy: 19.74840809234987, Validation Loss Force: 4.055961468219819, time: 0.08881688117980957
Test Loss Energy: 14.296122403784569, Test Loss Force: 10.035222118828067, time: 8.003634214401245


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.129766083429178, Training Loss Force: 4.228077817622363, time: 1.394573450088501
Validation Loss Energy: 3.2479474648971705, Validation Loss Force: 4.141288284939348, time: 0.08390593528747559
Test Loss Energy: 10.285631694728599, Test Loss Force: 9.952318749154708, time: 8.12654733657837


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 13.271416337414777, Training Loss Force: 4.985355181741229, time: 1.3884730339050293
Validation Loss Energy: 33.904781633408646, Validation Loss Force: 4.629891637186985, time: 0.08025431632995605
Test Loss Energy: 38.23987547364386, Test Loss Force: 10.327506583844542, time: 8.3898766040802


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 13.722767126313439, Training Loss Force: 4.801353522123587, time: 1.3576991558074951
Validation Loss Energy: 2.5368466446332563, Validation Loss Force: 4.4715177618075534, time: 0.0821068286895752
Test Loss Energy: 8.283017846498801, Test Loss Force: 10.160962131125103, time: 7.952754974365234


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 8.779458095308376, Training Loss Force: 4.958813249247441, time: 1.4303805828094482
Validation Loss Energy: 19.525648097410546, Validation Loss Force: 5.3494879533754816, time: 0.08461976051330566
Test Loss Energy: 14.216036803732871, Test Loss Force: 10.821931517155635, time: 8.275182485580444


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 13.431622231395929, Training Loss Force: 4.934310548918687, time: 1.374258041381836
Validation Loss Energy: 20.26570948946297, Validation Loss Force: 5.3418357055065275, time: 0.08313274383544922
Test Loss Energy: 24.45120288913556, Test Loss Force: 11.031059319933322, time: 8.039490699768066


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 9.661304828965132, Training Loss Force: 4.983393911903898, time: 1.46531081199646
Validation Loss Energy: 13.353964788146564, Validation Loss Force: 4.632198489538796, time: 0.0918111801147461
Test Loss Energy: 17.810441250312504, Test Loss Force: 10.214459295768911, time: 8.046203374862671


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 8.712054504116011, Training Loss Force: 4.699762929890523, time: 1.3354287147521973
Validation Loss Energy: 17.400927528172005, Validation Loss Force: 5.749526434183508, time: 0.08293962478637695
Test Loss Energy: 16.313189281922774, Test Loss Force: 11.31134929521128, time: 8.142852306365967


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.859612562825031, Training Loss Force: 4.9529400130040475, time: 1.4123237133026123
Validation Loss Energy: 49.43668135396415, Validation Loss Force: 5.518665290377037, time: 0.09140896797180176
Test Loss Energy: 52.36875857106655, Test Loss Force: 11.355834631486925, time: 7.9818806648254395


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 16.823596815777318, Training Loss Force: 5.746988085612047, time: 1.4076800346374512
Validation Loss Energy: 31.605154450043827, Validation Loss Force: 4.6909007564797385, time: 0.08414077758789062
Test Loss Energy: 35.27852498149463, Test Loss Force: 10.070769468953884, time: 7.978286504745483


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.93682025275483, Training Loss Force: 4.274749237794425, time: 1.4206116199493408
Validation Loss Energy: 2.3324782304709815, Validation Loss Force: 4.898281661517271, time: 0.08602261543273926
Test Loss Energy: 10.854870495258297, Test Loss Force: 10.264236598624741, time: 8.165464401245117


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 7.232253891794799, Training Loss Force: 4.1157203096337325, time: 1.3721330165863037
Validation Loss Energy: 1.285303313596549, Validation Loss Force: 3.6935565224341946, time: 0.08195924758911133
Test Loss Energy: 8.51084949147101, Test Loss Force: 10.002839645714007, time: 7.99203085899353

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–â–â–‚â–‚â–â–„â–‚â–‚â–†â–â–‚â–„â–ƒâ–‚â–ˆâ–…â–‚â–
wandb:   test_error_force â–„â–‚â–„â–‚â–ƒâ–ƒâ–„â–‡â–â–â–ƒâ–‚â–…â–†â–‚â–ˆâ–ˆâ–‚â–ƒâ–
wandb:          test_loss â–â–ƒâ–â–‚â–ƒâ–‚â–‚â–„â–‚â–‚â–…â–â–ƒâ–„â–ƒâ–„â–ˆâ–„â–‚â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–„â–‚â–„â–‚â–‚â–‚â–†â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–„â–â–
wandb: valid_error_energy â–‚â–…â–â–‚â–‚â–‚â–â–„â–„â–â–†â–â–„â–„â–ƒâ–ƒâ–ˆâ–…â–â–
wandb:  valid_error_force â–„â–†â–ƒâ–…â–ƒâ–…â–†â–…â–‚â–ƒâ–„â–„â–‡â–‡â–„â–ˆâ–‡â–„â–…â–
wandb:         valid_loss â–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–…â–‚â–…â–…â–ƒâ–…â–ˆâ–…â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3033
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.51085
wandb:   test_error_force 10.00284
wandb:          test_loss 3.25422
wandb: train_error_energy 7.23225
wandb:  train_error_force 4.11572
wandb:         train_loss -0.23155
wandb: valid_error_energy 1.2853
wandb:  valid_error_force 3.69356
wandb:         valid_loss -0.88213
wandb: 
wandb: ğŸš€ View run al_57_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yov6eywn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_121153-yov6eywn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 19.728443145751953, Uncertainty Bias: -5.406436920166016
0.00017166138 6.67572e-05
2.657159 4.653949
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 34 steps.
Found uncertainty sample 2 after 133 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 365 steps.
Found uncertainty sample 5 after 60 steps.
Found uncertainty sample 6 after 124 steps.
Found uncertainty sample 7 after 80 steps.
Found uncertainty sample 8 after 844 steps.
Found uncertainty sample 9 after 91 steps.
Found uncertainty sample 10 after 277 steps.
Found uncertainty sample 11 after 47 steps.
Found uncertainty sample 12 after 755 steps.
Found uncertainty sample 13 after 14 steps.
Found uncertainty sample 14 after 157 steps.
Found uncertainty sample 15 after 169 steps.
Found uncertainty sample 16 after 20 steps.
Found uncertainty sample 17 after 52 steps.
Found uncertainty sample 18 after 176 steps.
Found uncertainty sample 19 after 262 steps.
Found uncertainty sample 20 after 14 steps.
Found uncertainty sample 21 after 202 steps.
Found uncertainty sample 22 after 43 steps.
Found uncertainty sample 23 after 257 steps.
Found uncertainty sample 24 after 109 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 19 steps.
Found uncertainty sample 27 after 421 steps.
Found uncertainty sample 28 after 282 steps.
Found uncertainty sample 29 after 42 steps.
Found uncertainty sample 30 after 388 steps.
Found uncertainty sample 31 after 79 steps.
Found uncertainty sample 32 after 163 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 257 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 415 steps.
Found uncertainty sample 37 after 445 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 191 steps.
Found uncertainty sample 40 after 34 steps.
Found uncertainty sample 41 after 40 steps.
Found uncertainty sample 42 after 74 steps.
Found uncertainty sample 43 after 5 steps.
Found uncertainty sample 44 after 167 steps.
Found uncertainty sample 45 after 440 steps.
Found uncertainty sample 46 after 371 steps.
Found uncertainty sample 47 after 359 steps.
Found uncertainty sample 48 after 159 steps.
Found uncertainty sample 49 after 17 steps.
Found uncertainty sample 50 after 116 steps.
Found uncertainty sample 51 after 262 steps.
Found uncertainty sample 52 after 33 steps.
Found uncertainty sample 53 after 611 steps.
Found uncertainty sample 54 after 214 steps.
Found uncertainty sample 55 after 43 steps.
Found uncertainty sample 56 after 55 steps.
Found uncertainty sample 57 after 412 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 107 steps.
Found uncertainty sample 60 after 34 steps.
Found uncertainty sample 61 after 96 steps.
Found uncertainty sample 62 after 579 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 214 steps.
Found uncertainty sample 66 after 985 steps.
Found uncertainty sample 67 after 153 steps.
Found uncertainty sample 68 after 221 steps.
Found uncertainty sample 69 after 89 steps.
Found uncertainty sample 70 after 115 steps.
Found uncertainty sample 71 after 185 steps.
Found uncertainty sample 72 after 2 steps.
Found uncertainty sample 73 after 208 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 37 steps.
Found uncertainty sample 76 after 293 steps.
Found uncertainty sample 77 after 170 steps.
Found uncertainty sample 78 after 55 steps.
Found uncertainty sample 79 after 880 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 48 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 41 steps.
Found uncertainty sample 85 after 3 steps.
Found uncertainty sample 86 after 4 steps.
Found uncertainty sample 87 after 806 steps.
Found uncertainty sample 88 after 329 steps.
Found uncertainty sample 89 after 50 steps.
Found uncertainty sample 90 after 72 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 54 steps.
Found uncertainty sample 93 after 19 steps.
Found uncertainty sample 94 after 9 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 41 steps.
Found uncertainty sample 97 after 89 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_121910-vtirxxym
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vtirxxym
Training model 15. Added 113 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.40166450410905, Training Loss Force: 7.081362636937998, time: 1.4854674339294434
Validation Loss Energy: 2.1139184436312908, Validation Loss Force: 4.040292017751735, time: 0.08891010284423828
Test Loss Energy: 7.853060618256351, Test Loss Force: 9.665485061617558, time: 8.135417938232422


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.828462651537201, Training Loss Force: 4.508120511366505, time: 1.4212255477905273
Validation Loss Energy: 26.322736002105817, Validation Loss Force: 5.430121349837144, time: 0.0883474349975586
Test Loss Energy: 29.32224109722927, Test Loss Force: 11.10223731943006, time: 8.120165348052979


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 9.450177546651688, Training Loss Force: 4.816022444014484, time: 1.4130094051361084
Validation Loss Energy: 7.990787358348587, Validation Loss Force: 5.560826579812734, time: 0.08688855171203613
Test Loss Energy: 14.060869937631868, Test Loss Force: 10.444800272792422, time: 8.335124731063843


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.340111123185224, Training Loss Force: 4.812562033702984, time: 1.3847582340240479
Validation Loss Energy: 30.49285081200783, Validation Loss Force: 4.859286281998376, time: 0.08799886703491211
Test Loss Energy: 36.54483860400362, Test Loss Force: 10.855286898219255, time: 8.201530933380127


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 14.715175319452918, Training Loss Force: 5.172435583480203, time: 1.4980287551879883
Validation Loss Energy: 2.6597633532225844, Validation Loss Force: 4.673603371885777, time: 0.08722186088562012
Test Loss Energy: 10.596522337620062, Test Loss Force: 10.623244034099853, time: 8.151447772979736


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 15.92283294643204, Training Loss Force: 4.694846510548933, time: 1.4429600238800049
Validation Loss Energy: 9.29175633703774, Validation Loss Force: 6.026961947228819, time: 0.08823275566101074
Test Loss Energy: 8.96375107778626, Test Loss Force: 11.714918655821776, time: 8.395631551742554


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 8.96413350471646, Training Loss Force: 4.924209322760993, time: 1.404557466506958
Validation Loss Energy: 9.177334233696412, Validation Loss Force: 4.859605144215344, time: 0.08716559410095215
Test Loss Energy: 8.98130259665834, Test Loss Force: 10.278877204555357, time: 8.254059314727783


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 9.28388691517928, Training Loss Force: 4.582044647887277, time: 1.4896214008331299
Validation Loss Energy: 4.822355713469667, Validation Loss Force: 3.775378638131392, time: 0.08852291107177734
Test Loss Energy: 12.95131224151377, Test Loss Force: 10.361605796436267, time: 8.19946837425232


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 6.788838923964438, Training Loss Force: 3.325068376004932, time: 1.4205455780029297
Validation Loss Energy: 4.368297252521268, Validation Loss Force: 3.446008775501041, time: 0.0931704044342041
Test Loss Energy: 8.758781802008865, Test Loss Force: 9.701698521247286, time: 8.55415940284729


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 6.191848313460299, Training Loss Force: 3.3535866518892066, time: 1.6012885570526123
Validation Loss Energy: 9.64236716617101, Validation Loss Force: 3.753124081676212, time: 0.08916926383972168
Test Loss Energy: 17.188749395919743, Test Loss Force: 10.296260618714525, time: 8.195556640625


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 6.333375215077093, Training Loss Force: 3.2934340317383977, time: 1.5290815830230713
Validation Loss Energy: 2.013657986636397, Validation Loss Force: 3.7627197858508246, time: 0.088897705078125
Test Loss Energy: 9.939028418251457, Test Loss Force: 9.73464431698956, time: 8.175018548965454


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 16.19128984307833, Training Loss Force: 5.289521625502985, time: 1.4426274299621582
Validation Loss Energy: 13.554492159541585, Validation Loss Force: 8.015607842706867, time: 0.09031462669372559
Test Loss Energy: 17.16989962033072, Test Loss Force: 12.401663662597526, time: 8.175156116485596


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 14.609427922072362, Training Loss Force: 6.007286965114396, time: 1.706178903579712
Validation Loss Energy: 6.348753822150384, Validation Loss Force: 4.855786368362683, time: 0.09116601943969727
Test Loss Energy: 8.721235577773616, Test Loss Force: 10.365606062798351, time: 8.161122560501099


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.20576809056926, Training Loss Force: 4.3322773008255036, time: 1.4326648712158203
Validation Loss Energy: 5.3920496019355575, Validation Loss Force: 3.7112867758478405, time: 0.08794546127319336
Test Loss Energy: 8.396720383419897, Test Loss Force: 9.937498310492291, time: 8.123524904251099


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 12.325601300404164, Training Loss Force: 3.8751474757340905, time: 1.4109697341918945
Validation Loss Energy: 20.430392027084828, Validation Loss Force: 5.2715786912451, time: 0.08827376365661621
Test Loss Energy: 13.768166019903203, Test Loss Force: 10.74916069880707, time: 8.180174350738525


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.308554896166074, Training Loss Force: 4.801847978287219, time: 1.4329876899719238
Validation Loss Energy: 7.987124896236368, Validation Loss Force: 4.983632526504559, time: 0.08883476257324219
Test Loss Energy: 15.562857712692068, Test Loss Force: 10.441874437520758, time: 8.35018014907837


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 12.451261432607573, Training Loss Force: 5.029415000191517, time: 1.4628629684448242
Validation Loss Energy: 4.874161026284643, Validation Loss Force: 5.414532950938177, time: 0.09315609931945801
Test Loss Energy: 8.614502216725032, Test Loss Force: 10.745930508621328, time: 8.165296077728271


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 15.503296139667002, Training Loss Force: 5.853186471914647, time: 1.4297127723693848
Validation Loss Energy: 4.008781661573202, Validation Loss Force: 4.402143853378876, time: 0.08830451965332031
Test Loss Energy: 8.921755415723501, Test Loss Force: 10.093746784391891, time: 8.183579444885254


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.504568095686679, Training Loss Force: 4.670867910965798, time: 1.4298386573791504
Validation Loss Energy: 5.993433317911597, Validation Loss Force: 4.560146316622899, time: 0.08730530738830566
Test Loss Energy: 9.42505037329682, Test Loss Force: 10.753018391630567, time: 8.41473388671875


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 10.360586758792584, Training Loss Force: 4.796150167948231, time: 1.4594573974609375
Validation Loss Energy: 14.188014826695113, Validation Loss Force: 4.417705754649477, time: 0.08841753005981445
Test Loss Energy: 11.464229771205758, Test Loss Force: 10.5038724013454, time: 8.616890907287598

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–†â–ƒâ–ˆâ–‚â–â–â–‚â–â–ƒâ–‚â–ƒâ–â–â–‚â–ƒâ–â–â–â–‚
wandb:   test_error_force â–â–…â–ƒâ–„â–ƒâ–†â–ƒâ–ƒâ–â–ƒâ–â–ˆâ–ƒâ–‚â–„â–ƒâ–„â–‚â–„â–ƒ
wandb:          test_loss â–â–‡â–ƒâ–ˆâ–ƒâ–„â–‚â–ƒâ–ƒâ–‡â–…â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–„â–‡â–ˆâ–ƒâ–ƒâ–â–â–â–ˆâ–‡â–„â–…â–ƒâ–…â–‡â–…â–„
wandb:  train_error_force â–ˆâ–ƒâ–„â–„â–„â–„â–„â–ƒâ–â–â–â–…â–†â–ƒâ–‚â–„â–„â–†â–„â–„
wandb:         train_loss â–ˆâ–„â–„â–„â–…â–…â–„â–„â–â–â–â–…â–†â–ƒâ–ƒâ–„â–…â–†â–„â–„
wandb: valid_error_energy â–â–‡â–‚â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–„â–‚â–‚â–†â–‚â–‚â–â–‚â–„
wandb:  valid_error_force â–‚â–„â–„â–ƒâ–ƒâ–…â–ƒâ–‚â–â–â–â–ˆâ–ƒâ–â–„â–ƒâ–„â–‚â–ƒâ–‚
wandb:         valid_loss â–‚â–‡â–…â–‡â–ƒâ–…â–„â–‚â–â–‚â–â–ˆâ–ƒâ–‚â–†â–„â–„â–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3134
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.46423
wandb:   test_error_force 10.50387
wandb:          test_loss 3.48414
wandb: train_error_energy 10.36059
wandb:  train_error_force 4.79615
wandb:         train_loss 0.35595
wandb: valid_error_energy 14.18801
wandb:  valid_error_force 4.41771
wandb:         valid_loss 0.40707
wandb: 
wandb: ğŸš€ View run al_57_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vtirxxym
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_121910-vtirxxym/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.0506391525268555, Uncertainty Bias: -0.346153199672699
8.392334e-05 7.0997696
4.30313 5.158151
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_122501-d2gmn3di
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/d2gmn3di
Training model 16. Added 200 samples to the dataset.
Epoch 0, Batch 100/104, Loss: 1.4765406847000122, Uncertainty: 0.35663527250289917

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.77827066357831, Training Loss Force: 6.994884093424123, time: 1.5146543979644775
Validation Loss Energy: 13.450370285552584, Validation Loss Force: 4.390370890295381, time: 0.09660768508911133
Test Loss Energy: 19.433692301304426, Test Loss Force: 10.62843611433228, time: 8.29869294166565

Epoch 1, Batch 100/104, Loss: 0.2697681188583374, Uncertainty: 0.3317250907421112

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 10.990879970598332, Training Loss Force: 5.063808526283695, time: 1.561462640762329
Validation Loss Energy: 14.94622286346407, Validation Loss Force: 5.902545116603376, time: 0.09553909301757812
Test Loss Energy: 12.266362708160388, Test Loss Force: 11.785122040627439, time: 8.180136680603027

Epoch 2, Batch 100/104, Loss: 1.0291920900344849, Uncertainty: 0.31671857833862305

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.104590711320428, Training Loss Force: 4.780145586695331, time: 1.5235378742218018
Validation Loss Energy: 15.76506459934575, Validation Loss Force: 5.80881164894849, time: 0.09447622299194336
Test Loss Energy: 11.562832169037783, Test Loss Force: 10.892997734409505, time: 8.409945249557495

Epoch 3, Batch 100/104, Loss: 0.5020318627357483, Uncertainty: 0.3088839054107666

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 11.464693683135483, Training Loss Force: 4.454080125626349, time: 1.4920310974121094
Validation Loss Energy: 9.519794481412138, Validation Loss Force: 3.550250556825124, time: 0.09144759178161621
Test Loss Energy: 9.344403791557458, Test Loss Force: 9.765898741215508, time: 8.31726598739624

Epoch 4, Batch 100/104, Loss: 0.4921312630176544, Uncertainty: 0.30530333518981934

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 14.009106235676361, Training Loss Force: 4.534531920412162, time: 1.5103375911712646
Validation Loss Energy: 7.870631969837911, Validation Loss Force: 4.586037171565653, time: 0.10059809684753418
Test Loss Energy: 9.822271233706486, Test Loss Force: 10.364074761252771, time: 8.24500560760498

Epoch 5, Batch 100/104, Loss: 0.9343026876449585, Uncertainty: 0.2993258237838745

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.782193750424073, Training Loss Force: 4.317655174029867, time: 1.547201156616211
Validation Loss Energy: 14.855399236208168, Validation Loss Force: 5.129454319458896, time: 0.09523677825927734
Test Loss Energy: 21.66347950057296, Test Loss Force: 10.899973592688008, time: 8.44752287864685

Epoch 6, Batch 100/104, Loss: 0.20047426223754883, Uncertainty: 0.30026355385780334

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 10.854349747881013, Training Loss Force: 4.389778780920618, time: 1.5580062866210938
Validation Loss Energy: 9.4597851465846, Validation Loss Force: 3.435681157843764, time: 0.09423637390136719
Test Loss Energy: 9.282074500706901, Test Loss Force: 9.969775767707581, time: 8.254646062850952

Epoch 7, Batch 100/104, Loss: 0.20218777656555176, Uncertainty: 0.2245250642299652

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 6.110184701098041, Training Loss Force: 3.27830928505681, time: 1.5298597812652588
Validation Loss Energy: 7.551522144779046, Validation Loss Force: 3.662583021566493, time: 0.09365725517272949
Test Loss Energy: 8.993862013175567, Test Loss Force: 10.008348340487414, time: 8.191217422485352

Epoch 8, Batch 100/104, Loss: 0.23636841773986816, Uncertainty: 0.22195257246494293

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 5.967939601954803, Training Loss Force: 3.243504502466434, time: 1.5213041305541992
Validation Loss Energy: 8.368393258719266, Validation Loss Force: 3.7292228868868964, time: 0.09290194511413574
Test Loss Energy: 9.322748533953051, Test Loss Force: 9.892469279115875, time: 8.43334412574768

Epoch 9, Batch 100/104, Loss: 1.8139115571975708, Uncertainty: 0.3472633957862854

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.558749932884108, Training Loss Force: 3.956493854693693, time: 1.6201140880584717
Validation Loss Energy: 2.857370196099616, Validation Loss Force: 6.113209500866759, time: 0.09199285507202148
Test Loss Energy: 11.768292342846422, Test Loss Force: 11.416345403241408, time: 8.223729133605957

Epoch 10, Batch 100/104, Loss: 0.8516575694084167, Uncertainty: 0.3394972085952759

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 16.219347989317804, Training Loss Force: 6.541661804362819, time: 1.5515062808990479
Validation Loss Energy: 2.272404098921978, Validation Loss Force: 4.601905020242759, time: 0.09264039993286133
Test Loss Energy: 8.25373062373644, Test Loss Force: 10.716899996570657, time: 8.60096263885498

Epoch 11, Batch 100/104, Loss: 0.6181718707084656, Uncertainty: 0.28174811601638794

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 8.341758665277569, Training Loss Force: 4.333002762670661, time: 1.5438997745513916
Validation Loss Energy: 2.7214859044588913, Validation Loss Force: 4.039861820961803, time: 0.0998847484588623
Test Loss Energy: 10.800659283124817, Test Loss Force: 10.006579097723591, time: 8.466116189956665

Epoch 12, Batch 100/104, Loss: 0.5867345929145813, Uncertainty: 0.26759791374206543

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 7.7640064564278095, Training Loss Force: 3.736918906371422, time: 1.503713607788086
Validation Loss Energy: 11.491558270253378, Validation Loss Force: 3.9443966553590366, time: 0.09380459785461426
Test Loss Energy: 18.90506563899315, Test Loss Force: 10.55163192536473, time: 8.217787981033325

Epoch 13, Batch 100/104, Loss: 0.10599475353956223, Uncertainty: 0.28065988421440125

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 7.570801547050328, Training Loss Force: 4.408939139770282, time: 1.5233404636383057
Validation Loss Energy: 5.849485953827681, Validation Loss Force: 6.522688930792977, time: 0.09274554252624512
Test Loss Energy: 12.266605247321626, Test Loss Force: 11.573320599284896, time: 8.230263948440552

Epoch 14, Batch 100/104, Loss: 1.7600297927856445, Uncertainty: 0.2528080344200134

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.165821663294462, Training Loss Force: 3.566349165674143, time: 1.5108065605163574
Validation Loss Energy: 10.567439898191918, Validation Loss Force: 4.122399038621148, time: 0.09263324737548828
Test Loss Energy: 10.66177182123618, Test Loss Force: 10.194832337243794, time: 8.257606983184814

Epoch 15, Batch 100/104, Loss: 1.0332095623016357, Uncertainty: 0.3020861744880676

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 11.619705327207088, Training Loss Force: 5.063010242408197, time: 1.7452185153961182
Validation Loss Energy: 8.298200818510157, Validation Loss Force: 5.600464359817631, time: 0.09311509132385254
Test Loss Energy: 15.883916202882476, Test Loss Force: 10.884075304788913, time: 8.209262371063232

Epoch 16, Batch 100/104, Loss: 0.06954213976860046, Uncertainty: 0.25848934054374695

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.604417449441629, Training Loss Force: 3.3581235695136327, time: 1.5685222148895264
Validation Loss Energy: 2.0431448369513108, Validation Loss Force: 3.858367317484106, time: 0.0928499698638916
Test Loss Energy: 9.007167870297067, Test Loss Force: 9.903108895884037, time: 8.200557470321655

Epoch 17, Batch 100/104, Loss: 0.053730763494968414, Uncertainty: 0.21018026769161224

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 5.943812995335175, Training Loss Force: 3.176406974973368, time: 1.5603933334350586
Validation Loss Energy: 6.886671932815793, Validation Loss Force: 3.176424019868279, time: 0.09238886833190918
Test Loss Energy: 9.851593412027338, Test Loss Force: 9.823523179904297, time: 8.181585550308228

Epoch 18, Batch 100/104, Loss: 0.5408416390419006, Uncertainty: 0.2892215847969055

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 11.034297141850704, Training Loss Force: 3.9800248427584597, time: 1.7473397254943848
Validation Loss Energy: 4.099868038421299, Validation Loss Force: 4.314379700188022, time: 0.09241414070129395
Test Loss Energy: 9.669269229322227, Test Loss Force: 10.442625077362013, time: 8.17633843421936

Epoch 19, Batch 100/104, Loss: 2.824756145477295, Uncertainty: 0.2919868528842926

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 16.23827378120958, Training Loss Force: 4.314094405344802, time: 1.4973711967468262
Validation Loss Energy: 18.413397009292986, Validation Loss Force: 5.315697019804356, time: 0.09160947799682617
Test Loss Energy: 22.474731189054864, Test Loss Force: 10.76793776067897, time: 8.185164451599121

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–ƒâ–ƒâ–‚â–‚â–ˆâ–‚â–â–‚â–ƒâ–â–‚â–†â–ƒâ–‚â–…â–â–‚â–‚â–ˆ
wandb:   test_error_force â–„â–ˆâ–…â–â–ƒâ–…â–‚â–‚â–â–‡â–„â–‚â–„â–‡â–‚â–…â–â–â–ƒâ–„
wandb:          test_loss â–„â–…â–„â–â–ƒâ–ˆâ–‚â–†â–†â–„â–ƒâ–ƒâ–‡â–‡â–…â–†â–„â–†â–„â–ˆ
wandb: train_error_energy â–ˆâ–„â–„â–…â–†â–ƒâ–„â–â–â–„â–ˆâ–ƒâ–‚â–‚â–„â–…â–â–â–„â–ˆ
wandb:  train_error_force â–ˆâ–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚â–‡â–ƒâ–‚â–ƒâ–‚â–„â–â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–…â–„â–„â–…â–ƒâ–„â–â–â–ƒâ–‡â–ƒâ–‚â–ƒâ–‚â–…â–‚â–â–ƒâ–…
wandb: valid_error_energy â–†â–‡â–‡â–„â–ƒâ–†â–„â–ƒâ–„â–â–â–â–…â–ƒâ–…â–„â–â–ƒâ–‚â–ˆ
wandb:  valid_error_force â–„â–‡â–‡â–‚â–„â–…â–‚â–‚â–‚â–‡â–„â–ƒâ–ƒâ–ˆâ–ƒâ–†â–‚â–â–ƒâ–…
wandb:         valid_loss â–…â–ˆâ–ˆâ–ƒâ–„â–‡â–‚â–‚â–ƒâ–…â–ƒâ–‚â–„â–‡â–„â–†â–‚â–â–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3314
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 22.47473
wandb:   test_error_force 10.76794
wandb:          test_loss 4.56963
wandb: train_error_energy 16.23827
wandb:  train_error_force 4.31409
wandb:         train_loss 0.48195
wandb: valid_error_energy 18.4134
wandb:  valid_error_force 5.3157
wandb:         valid_loss 1.19828
wandb: 
wandb: ğŸš€ View run al_57_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/d2gmn3di
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_122501-d2gmn3di/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 7.740888595581055, Uncertainty Bias: -1.913670301437378
0.00011062622 4.7308807
4.7639723 5.768976
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_123047-ex9ln74p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ex9ln74p
Training model 17. Added 200 samples to the dataset.
Epoch 0, Batch 100/110, Loss: 0.5566651821136475, Uncertainty: 0.3347369432449341

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 13.78920927102088, Training Loss Force: 6.711757290454672, time: 1.6411769390106201
Validation Loss Energy: 13.722740075528037, Validation Loss Force: 5.160123208934968, time: 0.10120773315429688
Test Loss Energy: 20.048476916821453, Test Loss Force: 10.887536958968942, time: 8.239544153213501

Epoch 1, Batch 100/110, Loss: 0.10069506615400314, Uncertainty: 0.3318018615245819

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 12.679257888587685, Training Loss Force: 4.96920102134738, time: 1.6477737426757812
Validation Loss Energy: 10.12266495927554, Validation Loss Force: 3.295951704056586, time: 0.09560585021972656
Test Loss Energy: 16.739504773770683, Test Loss Force: 10.040731858164587, time: 8.217601776123047

Epoch 2, Batch 100/110, Loss: 0.45745009183883667, Uncertainty: 0.31000977754592896

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.887193943550988, Training Loss Force: 4.45627360131113, time: 1.7095491886138916
Validation Loss Energy: 12.243983589302594, Validation Loss Force: 6.399057454245222, time: 0.0957190990447998
Test Loss Energy: 11.445100808145188, Test Loss Force: 11.905029795400093, time: 8.417735576629639

Epoch 3, Batch 100/110, Loss: 0.8888213038444519, Uncertainty: 0.33017095923423767

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 10.564357292851136, Training Loss Force: 5.025778474036102, time: 1.5876648426055908
Validation Loss Energy: 8.823645226289837, Validation Loss Force: 4.280457614489945, time: 0.09604358673095703
Test Loss Energy: 14.611477071081309, Test Loss Force: 10.346191467684871, time: 8.223972797393799

Epoch 4, Batch 100/110, Loss: 0.13621582090854645, Uncertainty: 0.3406994640827179

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 10.707444743105983, Training Loss Force: 5.532972896348628, time: 1.6685316562652588
Validation Loss Energy: 1.6565064183433593, Validation Loss Force: 5.813402196060937, time: 0.09650564193725586
Test Loss Energy: 9.06005084815121, Test Loss Force: 10.884190645074888, time: 8.20487380027771

Epoch 5, Batch 100/110, Loss: 1.206434726715088, Uncertainty: 0.30683594942092896

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 8.114839300032468, Training Loss Force: 4.504071418075212, time: 1.6119968891143799
Validation Loss Energy: 4.131748248051218, Validation Loss Force: 3.6941539437527187, time: 0.09628653526306152
Test Loss Energy: 7.59271307355358, Test Loss Force: 10.246442755099924, time: 8.44440746307373

Epoch 6, Batch 100/110, Loss: 0.8994920253753662, Uncertainty: 0.29934412240982056

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.4447541450515775, Training Loss Force: 4.224923297924885, time: 1.6408276557922363
Validation Loss Energy: 10.47496406587323, Validation Loss Force: 5.515245314964732, time: 0.09704780578613281
Test Loss Energy: 9.573112815918202, Test Loss Force: 10.781222285863128, time: 8.168696880340576

Epoch 7, Batch 100/110, Loss: 0.2412722259759903, Uncertainty: 0.3043259084224701

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 10.051346138082561, Training Loss Force: 4.718100320987975, time: 1.6119980812072754
Validation Loss Energy: 19.1971977470183, Validation Loss Force: 4.4198839042349425, time: 0.09671473503112793
Test Loss Energy: 23.49484704004567, Test Loss Force: 11.080685874611554, time: 8.251401662826538

Epoch 8, Batch 100/110, Loss: 0.8831416368484497, Uncertainty: 0.3041517436504364

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 12.665732804747098, Training Loss Force: 4.585569017783399, time: 1.6472549438476562
Validation Loss Energy: 15.062978984793014, Validation Loss Force: 4.991085708157055, time: 0.09576964378356934
Test Loss Energy: 11.151263488142451, Test Loss Force: 11.174644070227611, time: 8.449948072433472

Epoch 9, Batch 100/110, Loss: 0.07142242044210434, Uncertainty: 0.3163311779499054

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 11.25103893017649, Training Loss Force: 5.032255038935884, time: 1.6399128437042236
Validation Loss Energy: 10.068897931284939, Validation Loss Force: 3.4390617208172394, time: 0.09532856941223145
Test Loss Energy: 16.529591002534993, Test Loss Force: 10.161100563717063, time: 8.21648359298706

Epoch 10, Batch 100/110, Loss: 2.0004634857177734, Uncertainty: 0.29588016867637634

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.659021186408511, Training Loss Force: 4.2145158513545296, time: 1.6433825492858887
Validation Loss Energy: 2.98069093785423, Validation Loss Force: 5.073771891475025, time: 0.09723472595214844
Test Loss Energy: 8.11414830354211, Test Loss Force: 11.127028019749908, time: 8.18559193611145

Epoch 11, Batch 100/110, Loss: 0.3299523591995239, Uncertainty: 0.3098146319389343

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 14.288662471934403, Training Loss Force: 4.736062014687634, time: 1.6042428016662598
Validation Loss Energy: 17.64583241501214, Validation Loss Force: 5.542855398383194, time: 0.09596633911132812
Test Loss Energy: 23.43281650823537, Test Loss Force: 11.7331680034759, time: 8.787163257598877

Epoch 12, Batch 100/110, Loss: 0.7990899085998535, Uncertainty: 0.30575549602508545

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 11.17947690974233, Training Loss Force: 4.516204777244185, time: 1.6290316581726074
Validation Loss Energy: 5.3815605491474825, Validation Loss Force: 4.148502542598262, time: 0.09598493576049805
Test Loss Energy: 12.893183591277262, Test Loss Force: 10.237111411662845, time: 8.215195417404175

Epoch 13, Batch 100/110, Loss: 0.6334803104400635, Uncertainty: 0.29292911291122437

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.226740525167113, Training Loss Force: 4.44783842240965, time: 1.593862771987915
Validation Loss Energy: 13.781986100523335, Validation Loss Force: 4.607557921850427, time: 0.10068964958190918
Test Loss Energy: 19.17788816780359, Test Loss Force: 11.117144214343066, time: 8.2189781665802

Epoch 14, Batch 100/110, Loss: 0.3016600012779236, Uncertainty: 0.2320411652326584

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.481366486476448, Training Loss Force: 3.7355681498641182, time: 1.6260180473327637
Validation Loss Energy: 3.767482010874782, Validation Loss Force: 3.456246212154217, time: 0.09630584716796875
Test Loss Energy: 13.21791711564308, Test Loss Force: 10.31375392184592, time: 8.365427017211914

Epoch 15, Batch 100/110, Loss: 0.47801557183265686, Uncertainty: 0.23516879975795746

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 6.659059986295892, Training Loss Force: 3.4343814684029583, time: 1.6365978717803955
Validation Loss Energy: 4.503462990828083, Validation Loss Force: 3.1448508709905942, time: 0.09702062606811523
Test Loss Energy: 9.310087626937563, Test Loss Force: 9.970310085056472, time: 8.198934078216553

Epoch 16, Batch 100/110, Loss: 0.5523126721382141, Uncertainty: 0.2805075943470001

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 6.466198804894758, Training Loss Force: 3.2991392351474573, time: 1.6492741107940674
Validation Loss Energy: 23.086016406222907, Validation Loss Force: 3.8444188768448972, time: 0.09730863571166992
Test Loss Energy: 16.41003958834425, Test Loss Force: 10.182354368670083, time: 8.287202835083008

Epoch 17, Batch 100/110, Loss: 0.10504642874002457, Uncertainty: 0.2768421769142151

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.593344665747594, Training Loss Force: 4.25741726874011, time: 1.664541482925415
Validation Loss Energy: 7.559986244354054, Validation Loss Force: 4.981145980151984, time: 0.09686040878295898
Test Loss Energy: 9.897549521146692, Test Loss Force: 11.397906220231024, time: 8.397414684295654

Epoch 18, Batch 100/110, Loss: 0.49691399931907654, Uncertainty: 0.29280322790145874

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 8.596852597977307, Training Loss Force: 4.347356409614558, time: 1.6119999885559082
Validation Loss Energy: 6.033094923515108, Validation Loss Force: 3.1966495037311917, time: 0.09541678428649902
Test Loss Energy: 14.105573415058867, Test Loss Force: 10.174888353813618, time: 8.279586553573608

Epoch 19, Batch 100/110, Loss: 0.1405339539051056, Uncertainty: 0.20545007288455963

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 6.114495647974963, Training Loss Force: 3.0579926026861175, time: 1.6239445209503174
Validation Loss Energy: 3.6170052080902533, Validation Loss Force: 3.128335389102557, time: 0.09617853164672852
Test Loss Energy: 9.698704794036447, Test Loss Force: 9.995304018187165, time: 8.238526821136475

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–ƒâ–„â–‚â–â–‚â–ˆâ–ƒâ–…â–â–ˆâ–ƒâ–†â–ƒâ–‚â–…â–‚â–„â–‚
wandb:   test_error_force â–„â–â–ˆâ–‚â–„â–‚â–„â–…â–…â–‚â–…â–‡â–‚â–…â–‚â–â–‚â–†â–‚â–
wandb:          test_loss â–„â–‚â–„â–‚â–â–â–‚â–†â–„â–ƒâ–ƒâ–‡â–‚â–†â–ˆâ–…â–†â–…â–ƒâ–†
wandb: train_error_energy â–ˆâ–‡â–…â–…â–…â–ƒâ–‚â–„â–‡â–…â–†â–ˆâ–…â–…â–‚â–â–â–†â–ƒâ–
wandb:  train_error_force â–ˆâ–…â–„â–…â–†â–„â–ƒâ–„â–„â–…â–ƒâ–„â–„â–„â–‚â–‚â–â–ƒâ–ƒâ–
wandb:         train_loss â–ˆâ–…â–„â–…â–†â–„â–ƒâ–„â–…â–…â–„â–…â–„â–„â–‚â–‚â–â–„â–„â–
wandb: valid_error_energy â–…â–„â–„â–ƒâ–â–‚â–„â–‡â–…â–„â–â–†â–‚â–…â–‚â–‚â–ˆâ–ƒâ–‚â–‚
wandb:  valid_error_force â–…â–â–ˆâ–ƒâ–‡â–‚â–†â–„â–…â–‚â–…â–†â–ƒâ–„â–‚â–â–ƒâ–…â–â–
wandb:         valid_loss â–†â–ƒâ–ˆâ–„â–…â–‚â–†â–†â–‡â–ƒâ–„â–ˆâ–ƒâ–†â–‚â–â–†â–…â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3494
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.6987
wandb:   test_error_force 9.9953
wandb:          test_loss 4.64077
wandb: train_error_energy 6.1145
wandb:  train_error_force 3.05799
wandb:         train_loss -1.00177
wandb: valid_error_energy 3.61701
wandb:  valid_error_force 3.12834
wandb:         valid_loss -1.1663
wandb: 
wandb: ğŸš€ View run al_57_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ex9ln74p
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_123047-ex9ln74p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.850000858306885, Uncertainty Bias: -0.7859653234481812
0.00022792816 0.08765745
2.452618 4.7451577
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 145 steps.
Found uncertainty sample 1 after 137 steps.
Found uncertainty sample 2 after 54 steps.
Found uncertainty sample 3 after 1280 steps.
Found uncertainty sample 4 after 422 steps.
Found uncertainty sample 5 after 688 steps.
Found uncertainty sample 6 after 462 steps.
Found uncertainty sample 7 after 1968 steps.
Found uncertainty sample 8 after 184 steps.
Found uncertainty sample 9 after 1143 steps.
Found uncertainty sample 10 after 179 steps.
Found uncertainty sample 11 after 1460 steps.
Found uncertainty sample 12 after 135 steps.
Found uncertainty sample 13 after 76 steps.
Found uncertainty sample 14 after 22 steps.
Found uncertainty sample 15 after 950 steps.
Found uncertainty sample 16 after 338 steps.
Found uncertainty sample 17 after 516 steps.
Found uncertainty sample 18 after 303 steps.
Found uncertainty sample 19 after 6 steps.
Found uncertainty sample 20 after 495 steps.
Found uncertainty sample 21 after 156 steps.
Found uncertainty sample 22 after 235 steps.
Found uncertainty sample 23 after 226 steps.
Found uncertainty sample 24 after 1375 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 341 steps.
Found uncertainty sample 27 after 485 steps.
Found uncertainty sample 28 after 2083 steps.
Found uncertainty sample 29 after 18 steps.
Found uncertainty sample 30 after 460 steps.
Found uncertainty sample 31 after 156 steps.
Found uncertainty sample 32 after 387 steps.
Found uncertainty sample 33 after 218 steps.
Found uncertainty sample 34 after 278 steps.
Found uncertainty sample 35 after 508 steps.
Found uncertainty sample 36 after 275 steps.
Found uncertainty sample 37 after 1372 steps.
Found uncertainty sample 38 after 506 steps.
Found uncertainty sample 39 after 1538 steps.
Found uncertainty sample 40 after 351 steps.
Found uncertainty sample 41 after 1905 steps.
Found uncertainty sample 42 after 884 steps.
Found uncertainty sample 43 after 1251 steps.
Found uncertainty sample 44 after 1071 steps.
Found uncertainty sample 45 after 387 steps.
Found uncertainty sample 46 after 1544 steps.
Found uncertainty sample 47 after 36 steps.
Found uncertainty sample 48 after 9 steps.
Found uncertainty sample 49 after 1334 steps.
Found uncertainty sample 50 after 2436 steps.
Found uncertainty sample 51 after 32 steps.
Found uncertainty sample 52 after 142 steps.
Found uncertainty sample 53 after 1697 steps.
Found uncertainty sample 54 after 1657 steps.
Found uncertainty sample 55 after 149 steps.
Found uncertainty sample 56 after 289 steps.
Found uncertainty sample 57 after 353 steps.
Found uncertainty sample 58 after 224 steps.
Found uncertainty sample 59 after 577 steps.
Found uncertainty sample 60 after 544 steps.
Found uncertainty sample 61 after 551 steps.
Found uncertainty sample 62 after 453 steps.
Found uncertainty sample 63 after 920 steps.
Found uncertainty sample 64 after 636 steps.
Found uncertainty sample 65 after 1328 steps.
Found uncertainty sample 66 after 2769 steps.
Found uncertainty sample 67 after 849 steps.
Found uncertainty sample 68 after 421 steps.
Found uncertainty sample 69 after 183 steps.
Found uncertainty sample 70 after 1537 steps.
Found uncertainty sample 71 after 1492 steps.
Found uncertainty sample 72 after 880 steps.
Found uncertainty sample 73 after 2508 steps.
Found uncertainty sample 74 after 373 steps.
Found uncertainty sample 75 after 1429 steps.
Found uncertainty sample 76 after 1279 steps.
Found uncertainty sample 77 after 188 steps.
Found uncertainty sample 78 after 422 steps.
Found uncertainty sample 79 after 634 steps.
Found uncertainty sample 80 after 2788 steps.
Found uncertainty sample 81 after 338 steps.
Found uncertainty sample 82 after 3079 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 2658 steps.
Found uncertainty sample 85 after 1043 steps.
Found uncertainty sample 86 after 289 steps.
Found uncertainty sample 87 after 12 steps.
Found uncertainty sample 88 after 307 steps.
Found uncertainty sample 89 after 869 steps.
Found uncertainty sample 90 after 254 steps.
Found uncertainty sample 91 after 1075 steps.
Found uncertainty sample 92 after 1767 steps.
Found uncertainty sample 93 after 1884 steps.
Found uncertainty sample 94 after 687 steps.
Found uncertainty sample 95 after 95 steps.
Found uncertainty sample 96 after 660 steps.
Found uncertainty sample 97 after 190 steps.
Found uncertainty sample 98 after 140 steps.
Found uncertainty sample 99 after 34 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_124322-0vj8xh0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0vj8xh0d
Training model 18. Added 100 samples to the dataset.
Epoch 0, Batch 100/112, Loss: 0.7939613461494446, Uncertainty: 0.2932071089744568

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 17.72194402837104, Training Loss Force: 6.523404289222266, time: 1.6006124019622803
Validation Loss Energy: 21.42896606282333, Validation Loss Force: 4.169755421900486, time: 0.10322928428649902
Test Loss Energy: 14.858206366674723, Test Loss Force: 10.152143691493082, time: 8.386101245880127

Epoch 1, Batch 100/112, Loss: 0.5263805985450745, Uncertainty: 0.2736831307411194

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 9.012049361620969, Training Loss Force: 3.5797864082689643, time: 1.715378761291504
Validation Loss Energy: 2.9663081810458887, Validation Loss Force: 3.595488799853824, time: 0.10109424591064453
Test Loss Energy: 10.900908719162798, Test Loss Force: 10.457711651120288, time: 8.374174118041992

Epoch 2, Batch 100/112, Loss: 0.13906335830688477, Uncertainty: 0.27159276604652405

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 7.865896835895354, Training Loss Force: 4.108145215200769, time: 1.6212961673736572
Validation Loss Energy: 2.782373149505775, Validation Loss Force: 4.241663305209822, time: 0.10120534896850586
Test Loss Energy: 10.84503564442096, Test Loss Force: 10.293496345646625, time: 8.952147483825684

Epoch 3, Batch 100/112, Loss: 0.17684361338615417, Uncertainty: 0.26005733013153076

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 8.123229678046377, Training Loss Force: 4.143819102689616, time: 1.639780044555664
Validation Loss Energy: 2.6850208628912706, Validation Loss Force: 4.963947534881862, time: 0.10484552383422852
Test Loss Energy: 10.558544247159189, Test Loss Force: 10.51322660859028, time: 8.364067316055298

Epoch 4, Batch 100/112, Loss: 0.8497402667999268, Uncertainty: 0.26370251178741455

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.212541639262628, Training Loss Force: 4.025007526450848, time: 1.643777847290039
Validation Loss Energy: 6.507510985353005, Validation Loss Force: 3.51737297497907, time: 0.09972095489501953
Test Loss Energy: 13.779594449698559, Test Loss Force: 10.44855137820925, time: 8.388808250427246

Epoch 5, Batch 100/112, Loss: 1.0461864471435547, Uncertainty: 0.25939494371414185

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 9.388098058123536, Training Loss Force: 3.9902719667429407, time: 1.6273956298828125
Validation Loss Energy: 4.110824993308015, Validation Loss Force: 4.3161082807678595, time: 0.10706281661987305
Test Loss Energy: 12.30635903911736, Test Loss Force: 10.558296247357747, time: 8.525723695755005

Epoch 6, Batch 100/112, Loss: 0.34959739446640015, Uncertainty: 0.23685407638549805

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 5.693434900849901, Training Loss Force: 3.7468618061883654, time: 1.6412367820739746
Validation Loss Energy: 3.030055759718312, Validation Loss Force: 3.7563963532217186, time: 0.10422825813293457
Test Loss Energy: 10.957178709234997, Test Loss Force: 10.394865991686135, time: 8.445691585540771

Epoch 7, Batch 100/112, Loss: 0.17451715469360352, Uncertainty: 0.2058134824037552

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 5.953642572155916, Training Loss Force: 3.1366402245709395, time: 1.618974208831787
Validation Loss Energy: 3.515017432307348, Validation Loss Force: 3.1335248419945017, time: 0.10586929321289062
Test Loss Energy: 12.513084593884212, Test Loss Force: 10.163864426420883, time: 8.4423508644104

Epoch 8, Batch 100/112, Loss: 0.5923175811767578, Uncertainty: 0.203424870967865

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 5.704049674725289, Training Loss Force: 3.0329331692839796, time: 1.6504979133605957
Validation Loss Energy: 2.8197437864898838, Validation Loss Force: 3.1546366232812555, time: 0.10331058502197266
Test Loss Energy: 12.549719170998596, Test Loss Force: 10.290231610266472, time: 8.522193193435669

Epoch 9, Batch 100/112, Loss: 0.5548962950706482, Uncertainty: 0.3455117344856262

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 7.667495011482251, Training Loss Force: 3.629796906373776, time: 1.623793363571167
Validation Loss Energy: 10.033161463162793, Validation Loss Force: 4.567000740941994, time: 0.1019449234008789
Test Loss Energy: 9.689862040332658, Test Loss Force: 10.545799994266316, time: 8.38900375366211

Epoch 10, Batch 100/112, Loss: 0.9218504428863525, Uncertainty: 0.26963144540786743

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.222661107996714, Training Loss Force: 4.459834705367962, time: 1.6494324207305908
Validation Loss Energy: 10.481370405647668, Validation Loss Force: 4.4696276718738694, time: 0.1030733585357666
Test Loss Energy: 9.489913517784098, Test Loss Force: 10.708130199071853, time: 8.417969226837158

Epoch 11, Batch 100/112, Loss: 0.5653960704803467, Uncertainty: 0.2686668634414673

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 7.721050043535047, Training Loss Force: 3.6115370105391316, time: 1.6616742610931396
Validation Loss Energy: 10.55927432371855, Validation Loss Force: 3.4581881097758527, time: 0.10566067695617676
Test Loss Energy: 16.80085209601931, Test Loss Force: 9.835515589843041, time: 8.592722654342651

Epoch 12, Batch 100/112, Loss: 0.11260633170604706, Uncertainty: 0.2587248980998993

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.691645287072268, Training Loss Force: 4.143269137732816, time: 1.7255773544311523
Validation Loss Energy: 2.533128960572846, Validation Loss Force: 5.197110038534546, time: 0.103759765625
Test Loss Energy: 12.195929300297951, Test Loss Force: 10.905115095547519, time: 8.865219354629517

Epoch 13, Batch 100/112, Loss: 0.2678814232349396, Uncertainty: 0.27947574853897095

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 8.026472920062657, Training Loss Force: 4.436868931731985, time: 1.6028337478637695
Validation Loss Energy: 5.723856170141321, Validation Loss Force: 3.5351018181547915, time: 0.10983014106750488
Test Loss Energy: 13.017757097043333, Test Loss Force: 10.489665806725377, time: 8.419327974319458

Epoch 14, Batch 100/112, Loss: 1.2090656757354736, Uncertainty: 0.2934263050556183

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 10.860477810458745, Training Loss Force: 4.475901944324661, time: 1.6336512565612793
Validation Loss Energy: 1.8036390831155338, Validation Loss Force: 3.439610526038903, time: 0.10563230514526367
Test Loss Energy: 10.40804633102614, Test Loss Force: 10.357671934443564, time: 8.538272857666016

Epoch 15, Batch 100/112, Loss: 1.0293357372283936, Uncertainty: 0.27871063351631165

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 9.831551482995447, Training Loss Force: 4.104563172436341, time: 1.626246690750122
Validation Loss Energy: 11.317550051907872, Validation Loss Force: 4.501391573986566, time: 0.10217452049255371
Test Loss Energy: 17.898441533057447, Test Loss Force: 10.834442729883092, time: 8.349766731262207

Epoch 16, Batch 100/112, Loss: 1.099363088607788, Uncertainty: 0.2612554728984833

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 8.24171961069197, Training Loss Force: 4.009427306666758, time: 1.6400084495544434
Validation Loss Energy: 2.9676814558918743, Validation Loss Force: 3.5393956957418147, time: 0.10140109062194824
Test Loss Energy: 9.076607838016242, Test Loss Force: 9.885481352402822, time: 8.36377763748169

Epoch 17, Batch 100/112, Loss: 0.7403606176376343, Uncertainty: 0.27714964747428894

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.364171405993266, Training Loss Force: 4.125457828773819, time: 1.6378161907196045
Validation Loss Energy: 7.467293532287234, Validation Loss Force: 3.430643639532391, time: 0.10686922073364258
Test Loss Energy: 14.247281281293098, Test Loss Force: 10.289755093630962, time: 8.592396020889282

Epoch 18, Batch 100/112, Loss: 0.18974435329437256, Uncertainty: 0.21679461002349854

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 5.97745438218214, Training Loss Force: 3.028913245655968, time: 1.672410011291504
Validation Loss Energy: 8.781770066706658, Validation Loss Force: 3.3846433855748015, time: 0.10651206970214844
Test Loss Energy: 16.39814657045108, Test Loss Force: 10.260035920704867, time: 8.405536890029907

Epoch 19, Batch 100/112, Loss: 0.3920958638191223, Uncertainty: 0.2579498887062073

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 5.895268477288576, Training Loss Force: 3.275318970254475, time: 1.6587324142456055
Validation Loss Energy: 10.560656653776471, Validation Loss Force: 3.0162109344550085, time: 0.10778093338012695
Test Loss Energy: 9.455482087489878, Test Loss Force: 9.866191312114214, time: 8.335021257400513

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–‚â–‚â–…â–„â–‚â–„â–„â–â–â–‡â–ƒâ–„â–‚â–ˆâ–â–…â–‡â–
wandb:   test_error_force â–ƒâ–…â–„â–…â–…â–†â–…â–ƒâ–„â–†â–‡â–â–ˆâ–…â–„â–ˆâ–â–„â–„â–
wandb:          test_loss â–‚â–ƒâ–‚â–ƒâ–„â–„â–…â–‡â–ˆâ–‚â–ƒâ–„â–…â–‚â–â–…â–â–ƒâ–ˆâ–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–â–â–â–‚â–„â–‚â–…â–‚â–„â–ƒâ–‚â–„â–â–
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–„â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–ƒâ–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–â–‚â–„â–‚â–„â–„â–„â–ƒâ–ƒâ–„â–â–
wandb: valid_error_energy â–ˆâ–â–â–â–ƒâ–‚â–â–‚â–â–„â–„â–„â–â–‚â–â–„â–â–ƒâ–ƒâ–„
wandb:  valid_error_force â–…â–ƒâ–…â–‡â–ƒâ–…â–ƒâ–â–â–†â–†â–‚â–ˆâ–ƒâ–‚â–†â–ƒâ–‚â–‚â–
wandb:         valid_loss â–ˆâ–‚â–„â–…â–ƒâ–„â–ƒâ–â–â–†â–†â–„â–†â–ƒâ–‚â–†â–‚â–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3584
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.45548
wandb:   test_error_force 9.86619
wandb:          test_loss 3.90127
wandb: train_error_energy 5.89527
wandb:  train_error_force 3.27532
wandb:         train_loss -0.90413
wandb: valid_error_energy 10.56066
wandb:  valid_error_force 3.01621
wandb:         valid_loss -0.76333
wandb: 
wandb: ğŸš€ View run al_57_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0vj8xh0d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_124322-0vj8xh0d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 3.8101906776428223, Uncertainty Bias: -0.6794378757476807
1.4781952e-05 2.8434029
2.63376 4.272802
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1879 steps.
Found uncertainty sample 1 after 389 steps.
Found uncertainty sample 2 after 790 steps.
Found uncertainty sample 3 after 579 steps.
Found uncertainty sample 4 after 1302 steps.
Found uncertainty sample 5 after 141 steps.
Found uncertainty sample 6 after 1381 steps.
Found uncertainty sample 7 after 1462 steps.
Found uncertainty sample 8 after 3176 steps.
Found uncertainty sample 9 after 850 steps.
Found uncertainty sample 10 after 510 steps.
Found uncertainty sample 11 after 2465 steps.
Found uncertainty sample 12 after 718 steps.
Found uncertainty sample 13 after 1483 steps.
Found uncertainty sample 14 after 2676 steps.
Found uncertainty sample 15 after 1033 steps.
Found uncertainty sample 16 after 1276 steps.
Found uncertainty sample 17 after 1038 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 260 steps.
Found uncertainty sample 21 after 3165 steps.
Found uncertainty sample 22 after 2014 steps.
Found uncertainty sample 23 after 1010 steps.
Found uncertainty sample 24 after 1522 steps.
Found uncertainty sample 25 after 1230 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 485 steps.
Found uncertainty sample 28 after 826 steps.
Found uncertainty sample 29 after 1923 steps.
Found uncertainty sample 30 after 576 steps.
Found uncertainty sample 31 after 731 steps.
Found uncertainty sample 32 after 3319 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1621 steps.
Found uncertainty sample 35 after 54 steps.
Found uncertainty sample 36 after 463 steps.
Found uncertainty sample 37 after 463 steps.
Found uncertainty sample 38 after 1576 steps.
Found uncertainty sample 39 after 658 steps.
Found uncertainty sample 40 after 442 steps.
Found uncertainty sample 41 after 877 steps.
Found uncertainty sample 42 after 626 steps.
Found uncertainty sample 43 after 1756 steps.
Found uncertainty sample 44 after 1013 steps.
Found uncertainty sample 45 after 3052 steps.
Found uncertainty sample 46 after 1277 steps.
Found uncertainty sample 47 after 2047 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3770 steps.
Found uncertainty sample 50 after 2155 steps.
Found uncertainty sample 51 after 2770 steps.
Found uncertainty sample 52 after 87 steps.
Found uncertainty sample 53 after 1962 steps.
Found uncertainty sample 54 after 1216 steps.
Found uncertainty sample 55 after 602 steps.
Found uncertainty sample 56 after 1142 steps.
Found uncertainty sample 57 after 385 steps.
Found uncertainty sample 58 after 3178 steps.
Found uncertainty sample 59 after 407 steps.
Found uncertainty sample 60 after 117 steps.
Found uncertainty sample 61 after 941 steps.
Found uncertainty sample 62 after 1626 steps.
Found uncertainty sample 63 after 631 steps.
Found uncertainty sample 64 after 14 steps.
Found uncertainty sample 65 after 484 steps.
Found uncertainty sample 66 after 2155 steps.
Found uncertainty sample 67 after 471 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1742 steps.
Found uncertainty sample 70 after 449 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2304 steps.
Found uncertainty sample 73 after 1003 steps.
Found uncertainty sample 74 after 597 steps.
Found uncertainty sample 75 after 149 steps.
Found uncertainty sample 76 after 228 steps.
Found uncertainty sample 77 after 2330 steps.
Found uncertainty sample 78 after 402 steps.
Found uncertainty sample 79 after 2500 steps.
Found uncertainty sample 80 after 3726 steps.
Found uncertainty sample 81 after 644 steps.
Found uncertainty sample 82 after 2997 steps.
Found uncertainty sample 83 after 705 steps.
Found uncertainty sample 84 after 1855 steps.
Found uncertainty sample 85 after 90 steps.
Found uncertainty sample 86 after 1988 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2299 steps.
Found uncertainty sample 89 after 113 steps.
Found uncertainty sample 90 after 1539 steps.
Found uncertainty sample 91 after 2177 steps.
Found uncertainty sample 92 after 2886 steps.
Found uncertainty sample 93 after 1285 steps.
Found uncertainty sample 94 after 2658 steps.
Found uncertainty sample 95 after 1155 steps.
Found uncertainty sample 96 after 207 steps.
Found uncertainty sample 97 after 2785 steps.
Found uncertainty sample 98 after 1867 steps.
Found uncertainty sample 99 after 84 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_130308-rdvf5dqo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rdvf5dqo
Training model 19. Added 92 samples to the dataset.
Epoch 0, Batch 100/115, Loss: 0.4620504379272461, Uncertainty: 0.28607696294784546

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 16.73233680081587, Training Loss Force: 6.250672181780266, time: 1.6997778415679932
Validation Loss Energy: 8.3879559307578, Validation Loss Force: 4.126083173863572, time: 0.10190057754516602
Test Loss Energy: 14.635934485819408, Test Loss Force: 10.277477793092586, time: 8.038695335388184

Epoch 1, Batch 100/115, Loss: 0.34417277574539185, Uncertainty: 0.26393789052963257

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 8.103457552160473, Training Loss Force: 3.6875393825101237, time: 1.6826462745666504
Validation Loss Energy: 24.59299487067982, Validation Loss Force: 3.572354440491559, time: 0.10064268112182617
Test Loss Energy: 18.144517594319968, Test Loss Force: 9.91736721503111, time: 8.150995254516602

Epoch 2, Batch 100/115, Loss: 0.33804482221603394, Uncertainty: 0.2783116400241852

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 10.647727708266595, Training Loss Force: 4.366516034891587, time: 1.717468500137329
Validation Loss Energy: 8.64279987759557, Validation Loss Force: 5.25320722491423, time: 0.1025857925415039
Test Loss Energy: 9.9985450597049, Test Loss Force: 11.23049026145895, time: 8.301313400268555

Epoch 3, Batch 100/115, Loss: 0.25117090344429016, Uncertainty: 0.2649162709712982

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.698421892386708, Training Loss Force: 3.6112459200052944, time: 1.7055284976959229
Validation Loss Energy: 6.813066345714855, Validation Loss Force: 3.2665923689392393, time: 0.10379528999328613
Test Loss Energy: 15.309843430065742, Test Loss Force: 9.972734021741603, time: 8.491794347763062

Epoch 4, Batch 100/115, Loss: 1.5598485469818115, Uncertainty: 0.2471991777420044

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 9.909949187583024, Training Loss Force: 3.3874080069655728, time: 1.7149059772491455
Validation Loss Energy: 1.6432548022405697, Validation Loss Force: 3.681026632700643, time: 0.10013508796691895
Test Loss Energy: 10.978091650860465, Test Loss Force: 10.362985375189554, time: 8.20805549621582

Epoch 5, Batch 100/115, Loss: 0.2841857671737671, Uncertainty: 0.2711983621120453

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 11.74456431854631, Training Loss Force: 4.184976343131041, time: 1.682328224182129
Validation Loss Energy: 7.668604253737629, Validation Loss Force: 4.546685447190224, time: 0.10170984268188477
Test Loss Energy: 15.818882328284811, Test Loss Force: 10.582013705710366, time: 8.349738121032715

Epoch 6, Batch 100/115, Loss: 1.2405626773834229, Uncertainty: 0.27411383390426636

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 7.726519114172235, Training Loss Force: 4.1330491450980915, time: 1.7160370349884033
Validation Loss Energy: 12.182682328090381, Validation Loss Force: 4.89477180199306, time: 0.10563921928405762
Test Loss Energy: 20.674655542846587, Test Loss Force: 11.145585201086336, time: 8.095892429351807

Epoch 7, Batch 100/115, Loss: 1.1989045143127441, Uncertainty: 0.2880004048347473

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 8.423975748917936, Training Loss Force: 4.884375679043559, time: 1.7838594913482666
Validation Loss Energy: 6.167202612263523, Validation Loss Force: 5.744349005425444, time: 0.1019287109375
Test Loss Energy: 9.202253697404572, Test Loss Force: 10.725856570348034, time: 8.077870845794678

Epoch 8, Batch 100/115, Loss: 0.29343080520629883, Uncertainty: 0.3098342716693878

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.096836396746307, Training Loss Force: 4.816894411885183, time: 1.6854753494262695
Validation Loss Energy: 15.979167217891403, Validation Loss Force: 4.810136892532977, time: 0.10213851928710938
Test Loss Energy: 22.959992282085352, Test Loss Force: 10.986492932088563, time: 8.223739624023438

Epoch 9, Batch 100/115, Loss: 0.5160813927650452, Uncertainty: 0.27877557277679443

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 10.564489005347438, Training Loss Force: 4.273397101163153, time: 1.707953691482544
Validation Loss Energy: 15.480746382999811, Validation Loss Force: 5.1600976762062345, time: 0.10004687309265137
Test Loss Energy: 23.245058648108692, Test Loss Force: 11.33581057110232, time: 8.070279359817505

Epoch 10, Batch 100/115, Loss: 0.38360196352005005, Uncertainty: 0.28410691022872925

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 11.379959210877951, Training Loss Force: 3.940209414348707, time: 1.680016279220581
Validation Loss Energy: 7.456241126559963, Validation Loss Force: 4.547473102182419, time: 0.10067605972290039
Test Loss Energy: 17.827009914569302, Test Loss Force: 10.748740984954104, time: 8.065829992294312

Epoch 11, Batch 100/115, Loss: 0.7054182887077332, Uncertainty: 0.2800721526145935

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 9.726572034386852, Training Loss Force: 4.261753671498732, time: 1.6881458759307861
Validation Loss Energy: 13.541600952007242, Validation Loss Force: 4.324993967259156, time: 0.1075596809387207
Test Loss Energy: 20.25556606815327, Test Loss Force: 10.509567098301504, time: 8.259466886520386

Epoch 12, Batch 100/115, Loss: 0.3411409556865692, Uncertainty: 0.31404954195022583

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 13.85236555086684, Training Loss Force: 4.757658174651038, time: 1.67604398727417
Validation Loss Energy: 24.699596982062264, Validation Loss Force: 5.22066383234469, time: 0.1011362075805664
Test Loss Energy: 16.478009212236703, Test Loss Force: 11.460359287147345, time: 8.071064472198486

Epoch 13, Batch 100/115, Loss: 0.3940472900867462, Uncertainty: 0.30602604150772095

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 10.207778425068833, Training Loss Force: 4.726210872565871, time: 1.6954278945922852
Validation Loss Energy: 13.788353695866384, Validation Loss Force: 5.131862040933812, time: 0.10028457641601562
Test Loss Energy: 20.087286633407505, Test Loss Force: 11.369247451404961, time: 8.06840968132019

Epoch 14, Batch 100/115, Loss: 0.6737269163131714, Uncertainty: 0.28933417797088623

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 11.10563855552304, Training Loss Force: 4.032166388832312, time: 1.6459543704986572
Validation Loss Energy: 10.9425247384924, Validation Loss Force: 4.147790595115683, time: 0.1015005111694336
Test Loss Energy: 9.46043374566667, Test Loss Force: 10.391731989908202, time: 8.255661725997925

Epoch 15, Batch 100/115, Loss: 0.38308095932006836, Uncertainty: 0.2953273057937622

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 12.244996092048549, Training Loss Force: 4.543296888135447, time: 1.7079856395721436
Validation Loss Energy: 7.952701879183, Validation Loss Force: 4.4577959241358505, time: 0.1028451919555664
Test Loss Energy: 9.173879478762482, Test Loss Force: 10.409722864150373, time: 8.082669019699097

Epoch 16, Batch 100/115, Loss: 0.8994295597076416, Uncertainty: 0.2951999008655548

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 9.864396840196129, Training Loss Force: 4.396205296300783, time: 1.6389963626861572
Validation Loss Energy: 4.2389626253619115, Validation Loss Force: 4.631114907251663, time: 0.1022956371307373
Test Loss Energy: 12.474206682249156, Test Loss Force: 10.455983239582473, time: 8.080051898956299

Epoch 17, Batch 100/115, Loss: 0.4555976092815399, Uncertainty: 0.3065221607685089

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 11.682321496009907, Training Loss Force: 4.83484618431021, time: 1.684852123260498
Validation Loss Energy: 18.36339739480539, Validation Loss Force: 4.689948994326996, time: 0.10352516174316406
Test Loss Energy: 12.845227064519944, Test Loss Force: 10.523293552957714, time: 8.747238397598267

Epoch 18, Batch 100/115, Loss: 0.7389938235282898, Uncertainty: 0.26971328258514404

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 7.73067717003442, Training Loss Force: 3.7796555267079994, time: 1.748884677886963
Validation Loss Energy: 9.77762278858973, Validation Loss Force: 4.842074476579498, time: 0.10484027862548828
Test Loss Energy: 8.848411593885007, Test Loss Force: 10.910098547614087, time: 8.056753635406494

Epoch 19, Batch 100/115, Loss: 0.9428983330726624, Uncertainty: 0.2862520217895508

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 11.046002674610166, Training Loss Force: 4.407736551058246, time: 1.6546459197998047
Validation Loss Energy: 8.332816518597797, Validation Loss Force: 5.472351963600272, time: 0.10213899612426758
Test Loss Energy: 14.574005355906031, Test Loss Force: 11.431761662569274, time: 8.151830673217773

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–†â–‚â–„â–‚â–„â–‡â–â–ˆâ–ˆâ–…â–‡â–…â–†â–â–â–ƒâ–ƒâ–â–„
wandb:   test_error_force â–ƒâ–â–‡â–â–ƒâ–„â–‡â–…â–†â–‡â–…â–„â–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–„â–†â–ˆ
wandb:          test_loss â–ƒâ–„â–„â–„â–„â–…â–ˆâ–‚â–†â–ˆâ–†â–…â–„â–†â–‚â–â–‚â–‚â–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–„â–â–ƒâ–…â–‚â–‚â–„â–„â–„â–ƒâ–†â–ƒâ–„â–…â–ƒâ–„â–‚â–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–…â–„â–ƒâ–‚â–ƒâ–„â–„â–ƒâ–„â–ƒâ–…â–‚â–ƒ
wandb:         train_loss â–ˆâ–â–ƒâ–â–â–ƒâ–‚â–„â–„â–ƒâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–ƒâ–„â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–ˆâ–ƒâ–ƒâ–â–ƒâ–„â–‚â–…â–…â–ƒâ–…â–ˆâ–…â–„â–ƒâ–‚â–†â–ƒâ–ƒ
wandb:  valid_error_force â–ƒâ–‚â–‡â–â–‚â–…â–†â–ˆâ–…â–†â–…â–„â–‡â–†â–ƒâ–„â–…â–…â–…â–‡
wandb:         valid_loss â–ƒâ–…â–…â–â–â–„â–…â–…â–†â–†â–„â–„â–ˆâ–†â–„â–„â–ƒâ–†â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3666
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.57401
wandb:   test_error_force 11.43176
wandb:          test_loss 4.46431
wandb: train_error_energy 11.046
wandb:  train_error_force 4.40774
wandb:         train_loss 0.18863
wandb: valid_error_energy 8.33282
wandb:  valid_error_force 5.47235
wandb:         valid_loss 0.61987
wandb: 
wandb: ğŸš€ View run al_57_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rdvf5dqo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_130308-rdvf5dqo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 10.706451416015625, Uncertainty Bias: -2.735358953475952
5.340576e-05 0.8836136
4.7045536 6.2446938
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1 steps.
Found uncertainty sample 1 after 1 steps.
Found uncertainty sample 2 after 1 steps.
Found uncertainty sample 3 after 1 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 1 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 1 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 1 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 1 steps.
Found uncertainty sample 23 after 1 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 1 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 1 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 1 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 1 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 1 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 1 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 1 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 1 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 1 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 1 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 1 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1 steps.
Found uncertainty sample 95 after 1 steps.
Found uncertainty sample 96 after 1 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 1 steps.
Found uncertainty sample 99 after 1 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_130901-c2uv3lh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_57_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/c2uv3lh2
Training model 20. Added 200 samples to the dataset.
Epoch 0, Batch 100/121, Loss: 1.0190885066986084, Uncertainty: 0.3142002820968628

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 12.506157994889236, Training Loss Force: 5.888474769207375, time: 1.7812044620513916
Validation Loss Energy: 11.375903025181904, Validation Loss Force: 4.53155403960175, time: 0.10512757301330566
Test Loss Energy: 9.55584386069488, Test Loss Force: 10.781771688755207, time: 8.227618217468262

Epoch 1, Batch 100/121, Loss: 0.27007418870925903, Uncertainty: 0.2664512097835541

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 6.395122975087758, Training Loss Force: 3.522501606069841, time: 1.7754738330841064
Validation Loss Energy: 7.9915920846419715, Validation Loss Force: 3.3568933174865996, time: 0.10427284240722656
Test Loss Energy: 15.911431566810004, Test Loss Force: 10.261868797880526, time: 8.241690158843994

Epoch 2, Batch 100/121, Loss: 0.08913348615169525, Uncertainty: 0.20817525684833527

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 5.525540316192732, Training Loss Force: 3.156911468323521, time: 1.7843353748321533
Validation Loss Energy: 2.3770986037312567, Validation Loss Force: 3.418973698040413, time: 0.10616946220397949
Test Loss Energy: 10.195059809514756, Test Loss Force: 10.219112348791976, time: 8.480666160583496

Epoch 3, Batch 100/121, Loss: 0.6616485118865967, Uncertainty: 0.22774270176887512

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 6.9289119864012, Training Loss Force: 3.41571641403001, time: 1.8441805839538574
Validation Loss Energy: 8.072246708895547, Validation Loss Force: 3.017652420282696, time: 0.10605835914611816
Test Loss Energy: 16.132336072580195, Test Loss Force: 10.209544551706449, time: 8.237756967544556

Epoch 4, Batch 100/121, Loss: 2.6801223754882812, Uncertainty: 0.2719413936138153

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 8.592956260940396, Training Loss Force: 3.552743706882081, time: 1.7818098068237305
Validation Loss Energy: 2.26072376620319, Validation Loss Force: 5.190618639146361, time: 0.1038961410522461
Test Loss Energy: 8.377949432708537, Test Loss Force: 11.611808595095106, time: 8.246321201324463

Epoch 5, Batch 100/121, Loss: 1.4224765300750732, Uncertainty: 0.3007681965827942

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 12.39497123467306, Training Loss Force: 4.635364585319927, time: 1.7968921661376953
Validation Loss Energy: 15.967232745454062, Validation Loss Force: 4.898049046482825, time: 0.1067960262298584
Test Loss Energy: 22.703752966803652, Test Loss Force: 10.705600943378121, time: 8.446990966796875

Epoch 6, Batch 100/121, Loss: 0.6624380350112915, Uncertainty: 0.2700008451938629

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 14.859520626791108, Training Loss Force: 4.947645743911228, time: 1.775885820388794
Validation Loss Energy: 7.581744879509728, Validation Loss Force: 5.0623956505865255, time: 0.10493993759155273
Test Loss Energy: 8.729347249215165, Test Loss Force: 10.467272817095337, time: 8.253777265548706

Epoch 7, Batch 100/121, Loss: 0.24285712838172913, Uncertainty: 0.32706373929977417

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 11.07569020581689, Training Loss Force: 4.436580295602842, time: 1.7879221439361572
Validation Loss Energy: 8.469899660920198, Validation Loss Force: 3.570476894253096, time: 0.10947513580322266
Test Loss Energy: 8.809690450655138, Test Loss Force: 10.433668153842525, time: 8.709239959716797

Epoch 8, Batch 100/121, Loss: 1.059086799621582, Uncertainty: 0.29253458976745605

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 11.461505726212874, Training Loss Force: 4.3422693161954635, time: 1.755500316619873
Validation Loss Energy: 19.98931027862281, Validation Loss Force: 4.298864039876725, time: 0.10476064682006836
Test Loss Energy: 14.206267793014305, Test Loss Force: 10.400484039160528, time: 8.429997205734253

Epoch 9, Batch 100/121, Loss: 0.48085111379623413, Uncertainty: 0.2879225015640259

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 9.351159331359291, Training Loss Force: 4.278680944735551, time: 1.7807018756866455
Validation Loss Energy: 29.050490933699155, Validation Loss Force: 5.631745515221957, time: 0.10373473167419434
Test Loss Energy: 20.69542134563307, Test Loss Force: 11.824228469096576, time: 8.210951089859009

Epoch 10, Batch 100/121, Loss: 0.16887587308883667, Uncertainty: 0.30940544605255127

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 14.092057943209706, Training Loss Force: 4.8890022597845695, time: 1.8051159381866455
Validation Loss Energy: 20.82795769280428, Validation Loss Force: 3.9362883068561736, time: 0.10276675224304199
Test Loss Energy: 13.016431886867473, Test Loss Force: 10.296095004165464, time: 8.228460788726807

Epoch 11, Batch 100/121, Loss: 0.42662644386291504, Uncertainty: 0.3081938624382019

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 10.137272592598737, Training Loss Force: 4.710521651285918, time: 1.8787662982940674
Validation Loss Energy: 5.999072710924413, Validation Loss Force: 4.089152456888766, time: 0.10515475273132324
Test Loss Energy: 14.09685763639538, Test Loss Force: 10.446173043232562, time: 8.43546724319458

Epoch 12, Batch 100/121, Loss: 0.7004848718643188, Uncertainty: 0.31492602825164795

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 12.572827776085433, Training Loss Force: 4.5908235313486925, time: 1.8166840076446533
Validation Loss Energy: 5.920802279439336, Validation Loss Force: 4.607521923671836, time: 0.10492849349975586
Test Loss Energy: 14.149114382341452, Test Loss Force: 10.486794316715002, time: 8.30153203010559

Epoch 13, Batch 100/121, Loss: 0.0944509357213974, Uncertainty: 0.3182107210159302

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 13.05646503958469, Training Loss Force: 4.984399796535165, time: 1.795898199081421
Validation Loss Energy: 1.9808579678761742, Validation Loss Force: 5.067936994952085, time: 0.11361861228942871
Test Loss Energy: 9.571513874247769, Test Loss Force: 10.745458711172738, time: 8.275219917297363

Epoch 14, Batch 100/121, Loss: 0.42327362298965454, Uncertainty: 0.2930859923362732

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 7.802863148024521, Training Loss Force: 3.9566423413588536, time: 1.774052619934082
Validation Loss Energy: 4.169809753172093, Validation Loss Force: 3.483303036968097, time: 0.11191916465759277
Test Loss Energy: 10.967839772189592, Test Loss Force: 10.015506572957081, time: 8.469271659851074

Epoch 15, Batch 100/121, Loss: 0.30702918767929077, Uncertainty: 0.22106847167015076

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 5.506054070431229, Training Loss Force: 3.2742181934028767, time: 1.8401930332183838
Validation Loss Energy: 8.09857985898516, Validation Loss Force: 3.8130494702357365, time: 0.10738635063171387
Test Loss Energy: 8.73633460235115, Test Loss Force: 10.159715752821748, time: 8.289707660675049

Epoch 16, Batch 100/121, Loss: 0.6891400218009949, Uncertainty: 0.28236711025238037

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 7.864217042886134, Training Loss Force: 3.71862674956216, time: 1.784273624420166
Validation Loss Energy: 9.689540515412395, Validation Loss Force: 3.756952061186906, time: 0.10440635681152344
Test Loss Energy: 16.165417470334912, Test Loss Force: 10.570005133022727, time: 8.250443458557129

Epoch 17, Batch 100/121, Loss: 0.528092622756958, Uncertainty: 0.24151113629341125

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 6.5813049944104725, Training Loss Force: 3.544658673004283, time: 1.829291582107544
Validation Loss Energy: 13.18060379478522, Validation Loss Force: 3.4991792728496995, time: 0.1064000129699707
Test Loss Energy: 10.091545614780484, Test Loss Force: 10.028853580735719, time: 8.436510801315308

Epoch 18, Batch 100/121, Loss: 0.8272326588630676, Uncertainty: 0.23429769277572632

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 10.195007607772782, Training Loss Force: 4.441739876478068, time: 1.8302586078643799
Validation Loss Energy: 2.0636133270754793, Validation Loss Force: 3.8843387044346365, time: 0.10418891906738281
Test Loss Energy: 8.6076242442694, Test Loss Force: 10.45629958831945, time: 8.271780014038086

Epoch 19, Batch 100/121, Loss: 0.30125969648361206, Uncertainty: 0.2716514468193054

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 9.146298790320841, Training Loss Force: 3.7977414154719744, time: 1.8055927753448486
Validation Loss Energy: 6.044166330342833, Validation Loss Force: 3.241046205834382, time: 0.10438966751098633
Test Loss Energy: 8.666399945396217, Test Loss Force: 9.932331337080424, time: 8.234329223632812

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–‚â–…â–â–ˆâ–â–â–„â–‡â–ƒâ–„â–„â–‚â–‚â–â–…â–‚â–â–
wandb:   test_error_force â–„â–‚â–‚â–‚â–‡â–„â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–ƒâ–ƒâ–„â–â–‚â–ƒâ–â–ƒâ–
wandb:          test_loss â–‚â–‡â–ƒâ–‡â–„â–…â–â–â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–„â–„â–‚
wandb: train_error_energy â–†â–‚â–â–‚â–ƒâ–†â–ˆâ–…â–…â–„â–‡â–„â–†â–‡â–ƒâ–â–ƒâ–‚â–…â–„
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–…â–†â–„â–„â–„â–…â–…â–…â–†â–ƒâ–â–‚â–‚â–„â–ƒ
wandb:         train_loss â–ˆâ–‚â–â–‚â–ƒâ–†â–‡â–…â–…â–„â–‡â–…â–†â–†â–ƒâ–â–ƒâ–‚â–…â–ƒ
wandb: valid_error_energy â–ƒâ–ƒâ–â–ƒâ–â–…â–‚â–ƒâ–†â–ˆâ–†â–‚â–‚â–â–‚â–ƒâ–ƒâ–„â–â–‚
wandb:  valid_error_force â–…â–‚â–‚â–â–‡â–†â–†â–‚â–„â–ˆâ–ƒâ–„â–…â–†â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚
wandb:         valid_loss â–„â–‚â–â–â–ƒâ–…â–„â–‚â–…â–ˆâ–…â–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3846
wandb:                 lr 0.001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.6664
wandb:   test_error_force 9.93233
wandb:          test_loss 3.67589
wandb: train_error_energy 9.1463
wandb:  train_error_force 3.79774
wandb:         train_loss -0.30832
wandb: valid_error_energy 6.04417
wandb:  valid_error_force 3.24105
wandb:         valid_loss -0.89054
wandb: 
wandb: ğŸš€ View run al_57_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/c2uv3lh2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_130901-c2uv3lh2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.032143592834473, Uncertainty Bias: -0.8013850450515747
2.670288e-05 1.073143
2.652068 3.8108327
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2203 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3530 steps.
Found uncertainty sample 17 after 3615 steps.
Found uncertainty sample 18 after 1409 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1128 steps.
Found uncertainty sample 25 after 668 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
slurmstepd: error: *** JOB 5123550 ON aimat01 CANCELLED AT 2024-11-28T13:25:18 ***
Did not find any uncertainty samples for sample 31.
