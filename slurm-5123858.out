wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_234935-6n8kwtko
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/6n8kwtko
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
66
Uncertainty Slope: 5.450408935546875, Uncertainty Bias: -0.394203782081604
0.00025177002 0.0021781921
1.6673805 2.2779703
(48745, 22, 3)

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.996635182927987, Test Loss Force: 13.386480545648661, time: 7.305221080780029

wandb: - 0.039 MB of 0.047 MB uploadedwandb: \ 0.039 MB of 0.047 MB uploadedwandb: | 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 6
wandb:  test_error_energy 10.99664
wandb:   test_error_force 13.38648
wandb:          test_loss 16.63181
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_67 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/6n8kwtko
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_234935-6n8kwtko/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Found uncertainty sample 0 after 306 steps.
Found uncertainty sample 1 after 2485 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2634 steps.
Found uncertainty sample 4 after 2227 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 539 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1848 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1117 steps.
Found uncertainty sample 11 after 689 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1548 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 75 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 672 steps.
Found uncertainty sample 21 after 2180 steps.
Found uncertainty sample 22 after 2692 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1342 steps.
Found uncertainty sample 28 after 1040 steps.
Found uncertainty sample 29 after 951 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1209 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 474 steps.
Found uncertainty sample 34 after 1560 steps.
Found uncertainty sample 35 after 3823 steps.
Found uncertainty sample 36 after 1371 steps.
Found uncertainty sample 37 after 633 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2531 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 338 steps.
Found uncertainty sample 43 after 1833 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1892 steps.
Found uncertainty sample 46 after 3242 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1896 steps.
Found uncertainty sample 49 after 540 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 200 steps.
Found uncertainty sample 52 after 608 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1916 steps.
Found uncertainty sample 56 after 242 steps.
Found uncertainty sample 57 after 2657 steps.
Found uncertainty sample 58 after 885 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 164 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2151 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1399 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2518 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 615 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2625 steps.
Found uncertainty sample 72 after 2052 steps.
Found uncertainty sample 73 after 1571 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3153 steps.
Found uncertainty sample 78 after 1364 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3142 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2518 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1108 steps.
Found uncertainty sample 92 after 666 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 474 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_001900-vaf0auwu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vaf0auwu
Training model 0. Added 50 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2532564869969756, Training Loss Force: 2.6137781253088423, time: 0.5382239818572998
Validation Loss Energy: 0.940421427584284, Validation Loss Force: 2.1608069990350347, time: 0.033737897872924805
Test Loss Energy: 11.865519032404551, Test Loss Force: 12.407101373711471, time: 7.344560623168945


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.019645275448709, Training Loss Force: 2.0337479804475147, time: 0.3816835880279541
Validation Loss Energy: 2.525783773456126, Validation Loss Force: 2.159890492830396, time: 0.03419971466064453
Test Loss Energy: 11.248623606648692, Test Loss Force: 11.778256024688883, time: 6.967648029327393


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.262285617074759, Training Loss Force: 2.009618698229721, time: 0.4221982955932617
Validation Loss Energy: 1.1032669447522367, Validation Loss Force: 2.213406350024389, time: 0.03392839431762695
Test Loss Energy: 12.032691808489899, Test Loss Force: 11.573059561097445, time: 7.067502975463867


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.099119868686941, Training Loss Force: 1.960009459866458, time: 0.3904101848602295
Validation Loss Energy: 0.9204038053690947, Validation Loss Force: 2.1355004279311958, time: 0.0320734977722168
Test Loss Energy: 12.18390275086565, Test Loss Force: 11.458820225990062, time: 7.295980453491211


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7917109897368744, Training Loss Force: 1.9280699913792034, time: 0.38762545585632324
Validation Loss Energy: 0.8945413407424471, Validation Loss Force: 2.0989457249208145, time: 0.03445744514465332
Test Loss Energy: 12.687457259056627, Test Loss Force: 11.170731104160412, time: 7.12669563293457


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6284202930319205, Training Loss Force: 1.9275949762383988, time: 0.4014923572540283
Validation Loss Energy: 1.0012248005862012, Validation Loss Force: 2.1085550119133285, time: 0.03383946418762207
Test Loss Energy: 13.466985066804536, Test Loss Force: 11.265806837748254, time: 7.011331081390381


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0530936160448134, Training Loss Force: 1.9515780184328537, time: 0.3963451385498047
Validation Loss Energy: 0.8056022181358187, Validation Loss Force: 2.1447082424536017, time: 0.034140586853027344
Test Loss Energy: 12.791411032995944, Test Loss Force: 11.091250268845831, time: 7.067968130111694


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.287481781393743, Training Loss Force: 1.900311074254202, time: 0.409862756729126
Validation Loss Energy: 1.0963973789312187, Validation Loss Force: 2.0852800740969344, time: 0.03267312049865723
Test Loss Energy: 13.654302471039264, Test Loss Force: 11.14211223857795, time: 7.228781223297119


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.156454639870936, Training Loss Force: 1.8959231931760736, time: 0.4168424606323242
Validation Loss Energy: 1.6256647932773338, Validation Loss Force: 2.1123749011117194, time: 0.03343915939331055
Test Loss Energy: 12.346861409607488, Test Loss Force: 10.982188404076965, time: 7.094468116760254


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.263981749811832, Training Loss Force: 1.8851623067193506, time: 0.4143855571746826
Validation Loss Energy: 0.7751734216663433, Validation Loss Force: 2.0988021033216913, time: 0.038751840591430664
Test Loss Energy: 13.49666907432687, Test Loss Force: 11.096709351534557, time: 7.066212177276611


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.202148070177696, Training Loss Force: 1.8964998444114858, time: 0.4377114772796631
Validation Loss Energy: 1.5399805925785914, Validation Loss Force: 2.100860679575794, time: 0.035088539123535156
Test Loss Energy: 12.675549099661538, Test Loss Force: 10.949935862489875, time: 7.070589065551758


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.5151304485673953, Training Loss Force: 1.955878250337541, time: 0.38924074172973633
Validation Loss Energy: 1.334133877956502, Validation Loss Force: 2.092741271838683, time: 0.036199092864990234
Test Loss Energy: 14.206128964047952, Test Loss Force: 11.014123151326336, time: 7.597732067108154


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.488585968964284, Training Loss Force: 1.961121432469697, time: 0.40616583824157715
Validation Loss Energy: 1.6707604167180672, Validation Loss Force: 2.093206427684526, time: 0.03400731086730957
Test Loss Energy: 12.646789847594503, Test Loss Force: 10.87858621889003, time: 7.201090097427368


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1445375005772047, Training Loss Force: 1.8851657415971017, time: 0.3865540027618408
Validation Loss Energy: 1.1545351795872343, Validation Loss Force: 2.0764579225352757, time: 0.0390474796295166
Test Loss Energy: 14.031044307869495, Test Loss Force: 10.937819289437424, time: 8.357852697372437


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.982630568909111, Training Loss Force: 1.9005035098783158, time: 0.42842531204223633
Validation Loss Energy: 1.126633733591326, Validation Loss Force: 2.1616469070534747, time: 0.042742252349853516
Test Loss Energy: 14.039198307433296, Test Loss Force: 10.926805364669152, time: 8.304639101028442


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0798252305093143, Training Loss Force: 1.88593577686225, time: 0.4084775447845459
Validation Loss Energy: 1.5447684245543307, Validation Loss Force: 2.179879056722042, time: 0.04463624954223633
Test Loss Energy: 14.935888413011693, Test Loss Force: 11.001880153494508, time: 8.674854755401611


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2687079581014356, Training Loss Force: 1.9929684891378894, time: 0.38480663299560547
Validation Loss Energy: 2.929920925233245, Validation Loss Force: 2.15038140695355, time: 0.043454885482788086
Test Loss Energy: 15.868584688400453, Test Loss Force: 11.010731781321537, time: 8.326492071151733


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1353924354571725, Training Loss Force: 1.9179718837588378, time: 0.401073694229126
Validation Loss Energy: 1.1249971153687566, Validation Loss Force: 2.1846969490324812, time: 0.04042625427246094
Test Loss Energy: 13.05751195671832, Test Loss Force: 10.820464218416918, time: 8.368828058242798


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.704916391612925, Training Loss Force: 1.9143975326523612, time: 0.3980586528778076
Validation Loss Energy: 0.6914400253550743, Validation Loss Force: 2.2418220504128175, time: 0.04326629638671875
Test Loss Energy: 13.783028772698188, Test Loss Force: 10.827146479848773, time: 8.449530124664307


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8082541825939469, Training Loss Force: 1.891945938744052, time: 0.4052541255950928
Validation Loss Energy: 1.0732368930558316, Validation Loss Force: 2.1646992557058526, time: 0.03957343101501465
Test Loss Energy: 14.105978085337702, Test Loss Force: 10.757630566795344, time: 8.467725276947021

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–‚â–ƒâ–„â–ƒâ–…â–ƒâ–„â–ƒâ–…â–ƒâ–…â–…â–‡â–ˆâ–„â–…â–…
wandb:   test_error_force â–ˆâ–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:          test_loss â–ˆâ–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb: train_error_energy â–ˆâ–ƒâ–„â–ƒâ–‚â–â–ƒâ–„â–ƒâ–„â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–„â–ƒâ–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–‚â–â–â–â–â–‚â–‚â–â–â–â–‚â–â–â–
wandb: valid_error_energy â–‚â–‡â–‚â–‚â–‚â–‚â–â–‚â–„â–â–„â–ƒâ–„â–‚â–‚â–„â–ˆâ–‚â–â–‚
wandb:  valid_error_force â–…â–…â–‡â–ƒâ–‚â–‚â–„â–â–ƒâ–‚â–‚â–‚â–‚â–â–…â–…â–„â–†â–ˆâ–…
wandb:         valid_loss â–†â–ˆâ–‡â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–â–ƒâ–„â–…â–„â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 845
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.10598
wandb:   test_error_force 10.75763
wandb:          test_loss 9.95779
wandb: train_error_energy 1.80825
wandb:  train_error_force 1.89195
wandb:         train_loss -2.54474
wandb: valid_error_energy 1.07324
wandb:  valid_error_force 2.1647
wandb:         valid_loss -2.22474
wandb: 
wandb: ğŸš€ View run al_67_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vaf0auwu
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_001900-vaf0auwu/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.0112996101379395, Uncertainty Bias: -0.35472261905670166
0.00020599365 0.019001007
1.5007174 3.604847
(48745, 22, 3)
Found uncertainty sample 0 after 2388 steps.
Found uncertainty sample 1 after 2310 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2068 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2841 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 922 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2607 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1888 steps.
Found uncertainty sample 21 after 2194 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2278 steps.
Found uncertainty sample 25 after 3824 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1929 steps.
Found uncertainty sample 32 after 3270 steps.
Found uncertainty sample 33 after 918 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 920 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1116 steps.
Found uncertainty sample 41 after 1324 steps.
Found uncertainty sample 42 after 2002 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3117 steps.
Found uncertainty sample 47 after 1745 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 83 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3568 steps.
Found uncertainty sample 56 after 3196 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1348 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2159 steps.
Found uncertainty sample 64 after 2577 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2548 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1004 steps.
Found uncertainty sample 77 after 605 steps.
Found uncertainty sample 78 after 173 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 500 steps.
Found uncertainty sample 81 after 3903 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1043 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 997 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 933 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2597 steps.
Found uncertainty sample 95 after 1298 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_005536-enua14b1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/enua14b1
Training model 1. Added 36 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.289528523278711, Training Loss Force: 3.0995344750679084, time: 0.41234540939331055
Validation Loss Energy: 1.7252668176077197, Validation Loss Force: 2.3570996486128006, time: 0.04390859603881836
Test Loss Energy: 13.124063469602971, Test Loss Force: 10.68694891198037, time: 7.363802909851074


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.140992664806047, Training Loss Force: 2.4633568680201976, time: 0.40156054496765137
Validation Loss Energy: 0.8730283838777797, Validation Loss Force: 2.2401005952456496, time: 0.03795933723449707
Test Loss Energy: 14.314570605478266, Test Loss Force: 10.654311304325741, time: 7.3979713916778564


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.073840511341206, Training Loss Force: 2.3175095595674793, time: 0.4311099052429199
Validation Loss Energy: 1.9831602183989703, Validation Loss Force: 2.2010976449757926, time: 0.034143686294555664
Test Loss Energy: 13.455205099552307, Test Loss Force: 10.557417191538677, time: 7.333785057067871


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.082202614530557, Training Loss Force: 2.301762878691871, time: 0.44383764266967773
Validation Loss Energy: 0.9855562407947006, Validation Loss Force: 2.2186767060393535, time: 0.03406786918640137
Test Loss Energy: 14.803084300169168, Test Loss Force: 10.630118173381916, time: 7.560199499130249


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.2545922720609, Training Loss Force: 2.2878194640133844, time: 0.441115140914917
Validation Loss Energy: 1.52728366387407, Validation Loss Force: 2.289794113880646, time: 0.04012870788574219
Test Loss Energy: 15.444328450140542, Test Loss Force: 10.748028462340047, time: 7.341950178146362


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.449554352216588, Training Loss Force: 2.306329298011863, time: 0.4116184711456299
Validation Loss Energy: 2.204721585325767, Validation Loss Force: 2.277836335406032, time: 0.03639054298400879
Test Loss Energy: 15.298764178133796, Test Loss Force: 10.527122417704556, time: 7.359870672225952


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.799955785867081, Training Loss Force: 2.234545405630696, time: 0.4177107810974121
Validation Loss Energy: 0.8860710620986404, Validation Loss Force: 2.2626603197653234, time: 0.03798723220825195
Test Loss Energy: 14.523692803055676, Test Loss Force: 10.412737356716331, time: 7.348715543746948


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.507065122522023, Training Loss Force: 2.3650768582428277, time: 0.4257180690765381
Validation Loss Energy: 1.740171622228688, Validation Loss Force: 2.4343248711268926, time: 0.034815073013305664
Test Loss Energy: 13.695210299893796, Test Loss Force: 10.41607754779178, time: 7.893652439117432


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.619153246641528, Training Loss Force: 2.2166689937801567, time: 0.4030032157897949
Validation Loss Energy: 1.542926616713789, Validation Loss Force: 2.2318032748609427, time: 0.03497791290283203
Test Loss Energy: 13.439116948317578, Test Loss Force: 10.336520436053739, time: 7.482519626617432


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.02174255957743, Training Loss Force: 2.2348710910664935, time: 0.431668758392334
Validation Loss Energy: 1.544447112976757, Validation Loss Force: 2.2553042218604533, time: 0.039122819900512695
Test Loss Energy: 13.0020967550257, Test Loss Force: 10.298495414864393, time: 7.304994821548462


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.670011559512572, Training Loss Force: 2.207335172378564, time: 0.4056553840637207
Validation Loss Energy: 2.4779194818549266, Validation Loss Force: 2.314889149295854, time: 0.03483152389526367
Test Loss Energy: 16.44541380679717, Test Loss Force: 10.65500932430014, time: 7.340675592422485


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.9525310525045936, Training Loss Force: 2.2583137464645877, time: 0.4075126647949219
Validation Loss Energy: 0.9402399522303528, Validation Loss Force: 2.259855356534071, time: 0.03673553466796875
Test Loss Energy: 14.632891873987486, Test Loss Force: 10.38213108390255, time: 7.59035849571228


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9199704951923486, Training Loss Force: 2.1774880354330692, time: 0.42917966842651367
Validation Loss Energy: 0.8027974219064258, Validation Loss Force: 2.271021768864058, time: 0.03667402267456055
Test Loss Energy: 14.63292820986152, Test Loss Force: 10.371609502766255, time: 7.358590364456177


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.77630586128024, Training Loss Force: 2.1702290491094667, time: 0.43314647674560547
Validation Loss Energy: 0.7564642033526258, Validation Loss Force: 2.241379606819859, time: 0.03576803207397461
Test Loss Energy: 14.546598080944651, Test Loss Force: 10.351809179406832, time: 7.3838605880737305


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.574592436715083, Training Loss Force: 2.2261575583094646, time: 0.4238591194152832
Validation Loss Energy: 2.075439433861802, Validation Loss Force: 2.2366543448741254, time: 0.03403067588806152
Test Loss Energy: 15.40309129478499, Test Loss Force: 10.415197932385327, time: 7.287462472915649


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.7010652172915774, Training Loss Force: 2.1741066652839396, time: 0.5485734939575195
Validation Loss Energy: 1.8823656894575682, Validation Loss Force: 2.239667949095112, time: 0.05234336853027344
Test Loss Energy: 15.731561501202851, Test Loss Force: 10.417558579737504, time: 7.438131093978882


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.448507846993075, Training Loss Force: 2.1622840191472608, time: 0.3979470729827881
Validation Loss Energy: 0.7938339867716757, Validation Loss Force: 2.237571519086202, time: 0.034020423889160156
Test Loss Energy: 14.339256728242793, Test Loss Force: 10.32907369431937, time: 7.453077554702759


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.5092095208303853, Training Loss Force: 2.1905572589971127, time: 0.41013526916503906
Validation Loss Energy: 0.7676296693387423, Validation Loss Force: 2.378216922405154, time: 0.03672003746032715
Test Loss Energy: 14.048170722196824, Test Loss Force: 10.2990518872104, time: 7.443126916885376


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.6376126957813884, Training Loss Force: 2.205794830727966, time: 0.4496471881866455
Validation Loss Energy: 1.0004815309770942, Validation Loss Force: 2.220618826330136, time: 0.041602373123168945
Test Loss Energy: 14.55575812069428, Test Loss Force: 10.194570655530855, time: 7.959442853927612


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.4755511151634346, Training Loss Force: 2.1130982378560312, time: 0.4396986961364746
Validation Loss Energy: 1.7179465694353437, Validation Loss Force: 2.219114250911102, time: 0.03619122505187988
Test Loss Energy: 13.128182000095107, Test Loss Force: 10.110371985627232, time: 7.348665475845337

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–‚â–…â–†â–†â–„â–‚â–‚â–â–ˆâ–„â–„â–„â–†â–‡â–„â–ƒâ–„â–
wandb:   test_error_force â–‡â–‡â–†â–‡â–ˆâ–†â–„â–„â–ƒâ–ƒâ–‡â–„â–„â–„â–„â–„â–ƒâ–ƒâ–‚â–
wandb:          test_loss â–‡â–…â–ƒâ–…â–‡â–…â–„â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–„â–…â–…â–…â–„â–ƒâ–‚â–
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–…â–‚â–‚â–‚â–â–â–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–
wandb: valid_error_energy â–…â–â–†â–‚â–„â–‡â–‚â–…â–„â–„â–ˆâ–‚â–â–â–†â–†â–â–â–‚â–…
wandb:  valid_error_force â–†â–‚â–â–‚â–„â–ƒâ–ƒâ–ˆâ–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–†â–‚â–‚
wandb:         valid_loss â–†â–â–‚â–â–„â–…â–‚â–ˆâ–‚â–ƒâ–†â–‚â–‚â–â–ƒâ–ƒâ–â–…â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 877
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.12818
wandb:   test_error_force 10.11037
wandb:          test_loss 7.9431
wandb: train_error_energy 2.47555
wandb:  train_error_force 2.1131
wandb:         train_loss -2.21999
wandb: valid_error_energy 1.71795
wandb:  valid_error_force 2.21911
wandb:         valid_loss -2.14769
wandb: 
wandb: ğŸš€ View run al_67_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/enua14b1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_005536-enua14b1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 4.080725193023682, Uncertainty Bias: -0.4378742575645447
0.00017166138 0.048941612
1.1554908 4.411562
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2886 steps.
Found uncertainty sample 2 after 3627 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3942 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3793 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 599 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2306 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1205 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1855 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1915 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1473 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3635 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3821 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_013735-12ygogdk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/12ygogdk
Training model 2. Added 12 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.0335760340028814, Training Loss Force: 2.8076086878266513, time: 0.41196274757385254
Validation Loss Energy: 1.6506523908296313, Validation Loss Force: 2.5810462474307765, time: 0.040654659271240234
Test Loss Energy: 14.475493480659573, Test Loss Force: 10.131239507410154, time: 7.759385347366333


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.8506664651131453, Training Loss Force: 2.48510258173835, time: 0.4161660671234131
Validation Loss Energy: 1.6074634832854775, Validation Loss Force: 2.5372550198468877, time: 0.03722095489501953
Test Loss Energy: 14.388648134976469, Test Loss Force: 10.018380208052424, time: 7.775740146636963


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 4.641244717833485, Training Loss Force: 2.384836267749671, time: 0.4025099277496338
Validation Loss Energy: 5.805623694786242, Validation Loss Force: 2.568345199347055, time: 0.03636503219604492
Test Loss Energy: 18.74779007975891, Test Loss Force: 10.109495191473833, time: 7.708451747894287


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 3.5576890065278746, Training Loss Force: 2.392121151290192, time: 0.4144740104675293
Validation Loss Energy: 3.1801587381183527, Validation Loss Force: 2.435979302881136, time: 0.03645801544189453
Test Loss Energy: 13.274064094418934, Test Loss Force: 9.834004167639222, time: 7.9272541999816895


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.760698634909739, Training Loss Force: 2.340534205335146, time: 0.4012289047241211
Validation Loss Energy: 2.661632883371794, Validation Loss Force: 2.499207542882207, time: 0.03641533851623535
Test Loss Energy: 13.34983279025143, Test Loss Force: 9.830117213058854, time: 8.069490671157837


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.6053822275849248, Training Loss Force: 2.2810071003054615, time: 0.4119744300842285
Validation Loss Energy: 1.5311741391917204, Validation Loss Force: 2.4305982803006447, time: 0.042446136474609375
Test Loss Energy: 13.84464146527325, Test Loss Force: 9.79913850219946, time: 7.710265398025513


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.5707211586587997, Training Loss Force: 2.301576138803132, time: 0.40669989585876465
Validation Loss Energy: 1.486587760087724, Validation Loss Force: 2.4336989481576894, time: 0.03827834129333496
Test Loss Energy: 13.96489781034256, Test Loss Force: 9.78139500288615, time: 7.875872611999512


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.5589595894759785, Training Loss Force: 2.225949287109562, time: 0.4141571521759033
Validation Loss Energy: 2.616118864605862, Validation Loss Force: 2.421548783540994, time: 0.037468910217285156
Test Loss Energy: 15.614415655241409, Test Loss Force: 9.831396173337552, time: 7.674944162368774


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3851944270946612, Training Loss Force: 2.281220218535523, time: 0.42495036125183105
Validation Loss Energy: 1.6425553613416861, Validation Loss Force: 2.3929342396052515, time: 0.03621792793273926
Test Loss Energy: 13.262687454435826, Test Loss Force: 9.760372825140404, time: 7.711544036865234


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.6113153105979268, Training Loss Force: 2.2544488542413106, time: 0.406571626663208
Validation Loss Energy: 1.5457368126699707, Validation Loss Force: 2.4077070014226845, time: 0.03617405891418457
Test Loss Energy: 14.674104519415687, Test Loss Force: 9.763434248434836, time: 7.742421388626099


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.7289956898011516, Training Loss Force: 2.2655249265178066, time: 0.39942479133605957
Validation Loss Energy: 1.4316451503411989, Validation Loss Force: 2.3800042876395167, time: 0.03718137741088867
Test Loss Energy: 13.699797414870298, Test Loss Force: 9.704938630119385, time: 7.95028018951416


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.6983353213961463, Training Loss Force: 2.272769673944774, time: 0.40838027000427246
Validation Loss Energy: 1.758463447228364, Validation Loss Force: 2.375747521576815, time: 0.03920125961303711
Test Loss Energy: 14.844044809512525, Test Loss Force: 9.737341915220844, time: 7.718939542770386


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.9016367209160734, Training Loss Force: 2.2600937914507777, time: 0.40338778495788574
Validation Loss Energy: 2.817372360085753, Validation Loss Force: 2.6032285477481025, time: 0.04402446746826172
Test Loss Energy: 12.961693771917924, Test Loss Force: 9.730259021865761, time: 7.738794565200806


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.572832221211585, Training Loss Force: 2.2532553078567905, time: 0.42061519622802734
Validation Loss Energy: 1.4015539759642366, Validation Loss Force: 2.449704406366979, time: 0.03798842430114746
Test Loss Energy: 13.767961817140893, Test Loss Force: 9.714517544340909, time: 7.719931602478027


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.358473908902298, Training Loss Force: 2.221286233356472, time: 0.4165523052215576
Validation Loss Energy: 1.3550330473204195, Validation Loss Force: 2.396251119202992, time: 0.037108659744262695
Test Loss Energy: 13.790166463647692, Test Loss Force: 9.667958456500838, time: 7.872194766998291


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3701903855949515, Training Loss Force: 2.2322449391118906, time: 0.4332618713378906
Validation Loss Energy: 1.9475507459130526, Validation Loss Force: 2.422325676191136, time: 0.03553295135498047
Test Loss Energy: 15.241591340452315, Test Loss Force: 9.697193101365391, time: 8.011309146881104


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.322971244046083, Training Loss Force: 2.2094788440325237, time: 0.4233841896057129
Validation Loss Energy: 1.2582900948237463, Validation Loss Force: 2.3485075142788854, time: 0.03658342361450195
Test Loss Energy: 14.288614876870785, Test Loss Force: 9.655165029866733, time: 7.703296899795532


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.4427487252418905, Training Loss Force: 2.1709415704952617, time: 0.4071784019470215
Validation Loss Energy: 1.304069312542478, Validation Loss Force: 2.4190003351658502, time: 0.03740525245666504
Test Loss Energy: 14.12516498434527, Test Loss Force: 9.64093936730665, time: 7.730104923248291


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.725958824606885, Training Loss Force: 2.211164214869347, time: 0.4115569591522217
Validation Loss Energy: 2.633689241572732, Validation Loss Force: 2.3556750114171545, time: 0.05844688415527344
Test Loss Energy: 15.678414274528656, Test Loss Force: 9.666166028166472, time: 7.868122100830078


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.874881736720909, Training Loss Force: 2.182816587619816, time: 0.413330078125
Validation Loss Energy: 2.1841917127403714, Validation Loss Force: 2.3391908145441205, time: 0.038152456283569336
Test Loss Energy: 13.216489477660097, Test Loss Force: 9.636576339097447, time: 7.756586074829102

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–ˆâ–â–â–‚â–‚â–„â–â–ƒâ–‚â–ƒâ–â–‚â–‚â–„â–ƒâ–‚â–„â–
wandb:   test_error_force â–ˆâ–†â–ˆâ–„â–„â–ƒâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–â–â–â–
wandb:          test_loss â–„â–„â–ˆâ–â–â–‚â–ƒâ–…â–‚â–ƒâ–â–‚â–â–â–‚â–‚â–‚â–â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–…â–ƒâ–‚â–‚â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–
wandb:         train_loss â–ˆâ–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–ˆâ–„â–ƒâ–â–â–ƒâ–‚â–â–â–‚â–ƒâ–â–â–‚â–â–â–ƒâ–‚
wandb:  valid_error_force â–‡â–†â–‡â–„â–…â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–ˆâ–„â–ƒâ–ƒâ–â–ƒâ–â–
wandb:         valid_loss â–„â–„â–ˆâ–„â–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–†â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 887
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.21649
wandb:   test_error_force 9.63658
wandb:          test_loss 7.15454
wandb: train_error_energy 2.87488
wandb:  train_error_force 2.18282
wandb:         train_loss -2.11642
wandb: valid_error_energy 2.18419
wandb:  valid_error_force 2.33919
wandb:         valid_loss -1.97964
wandb: 
wandb: ğŸš€ View run al_67_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/12ygogdk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_013735-12ygogdk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 11.85594654083252, Uncertainty Bias: -1.5752325057983398
0.00041866302 0.017534256
0.006259675 17.94264
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3007 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2450 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1761 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2499 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 705 steps.
Found uncertainty sample 13 after 2929 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2807 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2891 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1355 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2638 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3519 steps.
Found uncertainty sample 34 after 3414 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 363 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 352 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3614 steps.
Found uncertainty sample 46 after 813 steps.
Found uncertainty sample 47 after 2039 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3286 steps.
Found uncertainty sample 50 after 203 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2042 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2133 steps.
Found uncertainty sample 60 after 3425 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1109 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3941 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1140 steps.
Found uncertainty sample 70 after 1160 steps.
Found uncertainty sample 71 after 2972 steps.
Found uncertainty sample 72 after 1001 steps.
Found uncertainty sample 73 after 2140 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 971 steps.
Found uncertainty sample 76 after 1289 steps.
Found uncertainty sample 77 after 1945 steps.
Found uncertainty sample 78 after 302 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2572 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3217 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 804 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1427 steps.
Found uncertainty sample 95 after 813 steps.
Found uncertainty sample 96 after 284 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3182 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_021334-w6c1s4bc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w6c1s4bc
Training model 3. Added 40 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.944433857733678, Training Loss Force: 2.9133780358446435, time: 0.43210577964782715
Validation Loss Energy: 2.5158235598896304, Validation Loss Force: 2.3899422342914196, time: 0.04001140594482422
Test Loss Energy: 13.074055192391812, Test Loss Force: 9.640886919979232, time: 7.821953296661377


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.7554975108318773, Training Loss Force: 2.3324708900674125, time: 0.42621707916259766
Validation Loss Energy: 2.488744542384206, Validation Loss Force: 2.4217580925381657, time: 0.0372011661529541
Test Loss Energy: 15.559382120122985, Test Loss Force: 9.668026390409066, time: 7.875821113586426


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.890669618244091, Training Loss Force: 2.2699974255276953, time: 0.4408724308013916
Validation Loss Energy: 1.948483061627052, Validation Loss Force: 2.3527916686465358, time: 0.03728461265563965
Test Loss Energy: 13.672255605775717, Test Loss Force: 9.586408677410084, time: 8.142086744308472


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.689812189748835, Training Loss Force: 2.2546610842627963, time: 0.44269227981567383
Validation Loss Energy: 2.079506485812173, Validation Loss Force: 2.3946922125123513, time: 0.0387568473815918
Test Loss Energy: 13.223083767292204, Test Loss Force: 9.58376931823563, time: 7.959724426269531


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.7481279606392954, Training Loss Force: 2.252790072212029, time: 0.4230821132659912
Validation Loss Energy: 1.618843546660982, Validation Loss Force: 2.405068817381732, time: 0.03960442543029785
Test Loss Energy: 13.832728955086258, Test Loss Force: 9.581088680165262, time: 7.867319107055664


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4968318915229877, Training Loss Force: 2.2482848265780877, time: 0.4202253818511963
Validation Loss Energy: 2.426119958437745, Validation Loss Force: 2.41578677405182, time: 0.03883218765258789
Test Loss Energy: 15.946051815876743, Test Loss Force: 9.570200597272843, time: 7.857717275619507


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4865148218567192, Training Loss Force: 2.3200352405708977, time: 0.42159223556518555
Validation Loss Energy: 1.4130097468493563, Validation Loss Force: 2.4420138594049248, time: 0.04034280776977539
Test Loss Energy: 13.530454992596082, Test Loss Force: 9.61239963670652, time: 8.01685094833374


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8541079018043958, Training Loss Force: 2.2534014756172684, time: 0.4213850498199463
Validation Loss Energy: 1.5656257321188136, Validation Loss Force: 2.5174724249152254, time: 0.03793954849243164
Test Loss Energy: 13.66777436006875, Test Loss Force: 9.631638955062137, time: 7.84642219543457


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.215674292862511, Training Loss Force: 2.26310313191411, time: 0.4411756992340088
Validation Loss Energy: 1.4981432867502193, Validation Loss Force: 2.456296081093879, time: 0.036627769470214844
Test Loss Energy: 14.136902054561412, Test Loss Force: 9.520205894718934, time: 7.75132942199707


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.824775812304586, Training Loss Force: 2.2483376605916447, time: 0.4420294761657715
Validation Loss Energy: 1.0430805879536853, Validation Loss Force: 2.3754034977463565, time: 0.036810874938964844
Test Loss Energy: 14.270185216172356, Test Loss Force: 9.53897095810471, time: 7.710244178771973


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.292746065622073, Training Loss Force: 2.2690157578848873, time: 0.46252870559692383
Validation Loss Energy: 2.3252058561649798, Validation Loss Force: 2.411119183414882, time: 0.03777146339416504
Test Loss Energy: 13.430846727117673, Test Loss Force: 9.537093808240641, time: 7.973228693008423


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.397580073930983, Training Loss Force: 2.2535889400034, time: 0.4172945022583008
Validation Loss Energy: 1.1559585921025777, Validation Loss Force: 2.3207132834767408, time: 0.038449764251708984
Test Loss Energy: 14.996897054323561, Test Loss Force: 9.545108927542579, time: 7.745135307312012


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8939450666729787, Training Loss Force: 2.1895103687643864, time: 0.4336695671081543
Validation Loss Energy: 0.9889999304710468, Validation Loss Force: 2.404323766419458, time: 0.039063215255737305
Test Loss Energy: 14.091033227084035, Test Loss Force: 9.628435583101696, time: 7.861241579055786


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8524697325760517, Training Loss Force: 2.1990301926688387, time: 0.45528364181518555
Validation Loss Energy: 3.5288463738382423, Validation Loss Force: 2.3818007823088623, time: 0.038224220275878906
Test Loss Energy: 17.272649507301924, Test Loss Force: 9.51666270399405, time: 8.133623123168945


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.082755689346044, Training Loss Force: 2.247949805491547, time: 0.43733644485473633
Validation Loss Energy: 1.0403946413809315, Validation Loss Force: 2.36262674215302, time: 0.0397646427154541
Test Loss Energy: 14.138124757655264, Test Loss Force: 9.601450045834314, time: 7.988415002822876


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8854676914099266, Training Loss Force: 2.2037662425507807, time: 0.42589330673217773
Validation Loss Energy: 2.6117670188178495, Validation Loss Force: 2.347200891730581, time: 0.03854203224182129
Test Loss Energy: 15.76302903962017, Test Loss Force: 9.572859915063939, time: 7.884353399276733


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3634056618602144, Training Loss Force: 2.242043153196477, time: 0.4272496700286865
Validation Loss Energy: 0.955259542796047, Validation Loss Force: 2.4194728390935087, time: 0.03668475151062012
Test Loss Energy: 13.955135351459598, Test Loss Force: 9.505970635235244, time: 7.76349401473999


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1135119611053996, Training Loss Force: 2.1941566522675333, time: 0.47762489318847656
Validation Loss Energy: 2.006968226150715, Validation Loss Force: 2.3028948530813076, time: 0.04254937171936035
Test Loss Energy: 15.642609430268806, Test Loss Force: 9.524542211957083, time: 8.01069688796997


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4605840745847356, Training Loss Force: 2.1823052136665924, time: 0.43115878105163574
Validation Loss Energy: 2.8390636749363085, Validation Loss Force: 2.4159689174131893, time: 0.04048490524291992
Test Loss Energy: 16.001608826338522, Test Loss Force: 9.543475804409535, time: 7.7657105922698975


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2408841967635937, Training Loss Force: 2.208613147115284, time: 0.41099119186401367
Validation Loss Energy: 1.6081565410021779, Validation Loss Force: 2.338757055047853, time: 0.042901039123535156
Test Loss Energy: 15.402967971052355, Test Loss Force: 9.476542876765011, time: 7.881563425064087

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–‚â–â–‚â–†â–‚â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–ˆâ–ƒâ–…â–‚â–…â–†â–…
wandb:   test_error_force â–‡â–ˆâ–…â–…â–…â–„â–†â–‡â–ƒâ–ƒâ–ƒâ–„â–‡â–‚â–†â–…â–‚â–ƒâ–ƒâ–
wandb:          test_loss â–â–ƒâ–‚â–ƒâ–„â–†â–„â–„â–ƒâ–„â–„â–…â–†â–ˆâ–†â–†â–„â–‡â–ˆâ–†
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚â–â–â–
wandb: valid_error_energy â–…â–…â–„â–„â–ƒâ–…â–‚â–ƒâ–‚â–â–…â–‚â–â–ˆâ–â–†â–â–„â–†â–ƒ
wandb:  valid_error_force â–„â–…â–ƒâ–„â–„â–…â–†â–ˆâ–†â–ƒâ–…â–‚â–„â–„â–ƒâ–‚â–…â–â–…â–‚
wandb:         valid_loss â–†â–‡â–„â–…â–…â–‡â–…â–ˆâ–†â–ƒâ–†â–â–ƒâ–ˆâ–‚â–…â–„â–‚â–‡â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 923
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 15.40297
wandb:   test_error_force 9.47654
wandb:          test_loss 7.07708
wandb: train_error_energy 2.24088
wandb:  train_error_force 2.20861
wandb:         train_loss -2.1284
wandb: valid_error_energy 1.60816
wandb:  valid_error_force 2.33876
wandb:         valid_loss -2.01921
wandb: 
wandb: ğŸš€ View run al_67_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w6c1s4bc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_021334-w6c1s4bc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 11.276718139648438, Uncertainty Bias: -1.488783597946167
0.00036621094 0.0015907288
0.19037142 13.458479
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 435 steps.
Found uncertainty sample 15 after 2814 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3078 steps.
Found uncertainty sample 25 after 964 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3386 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2231 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1711 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2395 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1630 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1142 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3553 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3027 steps.
Found uncertainty sample 76 after 837 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1689 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 623 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2702 steps.
Found uncertainty sample 95 after 3044 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_025425-skaxl01m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/skaxl01m
Training model 4. Added 17 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.072198043684692, Training Loss Force: 2.6644772887310944, time: 0.4674053192138672
Validation Loss Energy: 1.747892674863734, Validation Loss Force: 2.472490585408061, time: 0.039780378341674805
Test Loss Energy: 13.47475277387179, Test Loss Force: 9.500103114379305, time: 8.159687757492065


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9147805833741463, Training Loss Force: 2.255389990304312, time: 0.4289233684539795
Validation Loss Energy: 0.9719092941790783, Validation Loss Force: 2.3748428168369107, time: 0.044122934341430664
Test Loss Energy: 14.48261270056223, Test Loss Force: 9.488848268589981, time: 7.889804363250732


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3749864829698635, Training Loss Force: 2.3053505523348674, time: 0.44719767570495605
Validation Loss Energy: 1.0951683565802701, Validation Loss Force: 2.415552526110304, time: 0.03853631019592285
Test Loss Energy: 13.94392410685382, Test Loss Force: 9.556596608315278, time: 7.869765996932983


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.151661795365312, Training Loss Force: 2.225405908653084, time: 0.44764280319213867
Validation Loss Energy: 1.01016151542344, Validation Loss Force: 2.364927359768746, time: 0.039999961853027344
Test Loss Energy: 14.125331955893733, Test Loss Force: 9.514170264486856, time: 8.041170120239258


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.3027590360357495, Training Loss Force: 2.2545080126619017, time: 0.4337279796600342
Validation Loss Energy: 1.2038746542802055, Validation Loss Force: 2.3280190581546316, time: 0.040596723556518555
Test Loss Energy: 14.635993988611077, Test Loss Force: 9.481167036426228, time: 7.945638179779053


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0494483685254994, Training Loss Force: 2.254745693419417, time: 0.47202539443969727
Validation Loss Energy: 2.500844161104776, Validation Loss Force: 2.4196311568562634, time: 0.03942084312438965
Test Loss Energy: 12.790008562455483, Test Loss Force: 9.496236575411938, time: 7.883636236190796


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4513739388004683, Training Loss Force: 2.219790229904309, time: 0.4437904357910156
Validation Loss Energy: 3.1426383190220823, Validation Loss Force: 2.4498103968804403, time: 0.040815114974975586
Test Loss Energy: 12.508450119162243, Test Loss Force: 9.42260922463645, time: 8.05755090713501


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.336975380865746, Training Loss Force: 2.218053636946371, time: 0.4562091827392578
Validation Loss Energy: 2.2337266909434668, Validation Loss Force: 2.420724907701061, time: 0.041080474853515625
Test Loss Energy: 12.898015950087345, Test Loss Force: 9.494283596794322, time: 7.937429428100586


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.030157781483103, Training Loss Force: 2.234325830525567, time: 0.4636342525482178
Validation Loss Energy: 2.6828013710677108, Validation Loss Force: 2.37103272508094, time: 0.03840041160583496
Test Loss Energy: 12.486009336106514, Test Loss Force: 9.486685500662691, time: 7.855182647705078


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9101974047548533, Training Loss Force: 2.2840791914935314, time: 0.4344046115875244
Validation Loss Energy: 1.7766626418633338, Validation Loss Force: 2.419934877571309, time: 0.04028940200805664
Test Loss Energy: 13.138670682156542, Test Loss Force: 9.371922839435252, time: 7.888505220413208


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7686261858053858, Training Loss Force: 2.2496400606163056, time: 0.4353952407836914
Validation Loss Energy: 1.770544584409822, Validation Loss Force: 2.3688928745885742, time: 0.03861379623413086
Test Loss Energy: 14.830450356856606, Test Loss Force: 9.513010006681654, time: 8.087372064590454


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8855808909009728, Training Loss Force: 2.1763175379559754, time: 0.4379456043243408
Validation Loss Energy: 2.3764444760035692, Validation Loss Force: 2.3751627923996086, time: 0.03859233856201172
Test Loss Energy: 12.709904659233155, Test Loss Force: 9.389393246116251, time: 8.25373101234436


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9485650818069544, Training Loss Force: 2.239466084669719, time: 0.44887590408325195
Validation Loss Energy: 1.2022149898010326, Validation Loss Force: 2.3416744661977993, time: 0.045273780822753906
Test Loss Energy: 13.842392213116005, Test Loss Force: 9.367368045293315, time: 7.854108095169067


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.5869653054685724, Training Loss Force: 2.2202100094893646, time: 0.47499942779541016
Validation Loss Energy: 3.18749368245436, Validation Loss Force: 2.3740017954727413, time: 0.03931474685668945
Test Loss Energy: 12.542865214168126, Test Loss Force: 9.398493088253215, time: 7.988251686096191


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.5542843219226103, Training Loss Force: 2.255508442867641, time: 0.5967340469360352
Validation Loss Energy: 2.382225857708438, Validation Loss Force: 2.3803817118418644, time: 0.03904223442077637
Test Loss Energy: 12.820811301736013, Test Loss Force: 9.384420491495144, time: 7.943979501724243


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.9225433212000307, Training Loss Force: 2.2753532923813524, time: 0.47229480743408203
Validation Loss Energy: 1.815157127138465, Validation Loss Force: 2.3566369421275626, time: 0.03789472579956055
Test Loss Energy: 14.486751567392485, Test Loss Force: 9.397130894014607, time: 7.949100017547607


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.4489410130338087, Training Loss Force: 2.2356674343966962, time: 0.41963791847229004
Validation Loss Energy: 4.165021030519769, Validation Loss Force: 2.5019737616820676, time: 0.03842282295227051
Test Loss Energy: 17.248365205583813, Test Loss Force: 9.522279576334942, time: 7.926607131958008


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.6628231984028745, Training Loss Force: 2.3129502168850107, time: 0.47710585594177246
Validation Loss Energy: 2.442950851170989, Validation Loss Force: 2.3989340597422757, time: 0.04034113883972168
Test Loss Energy: 12.706414736563849, Test Loss Force: 9.336021293812493, time: 8.11029863357544


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7501727159948002, Training Loss Force: 2.1804490303571784, time: 0.4792060852050781
Validation Loss Energy: 2.1813845228176594, Validation Loss Force: 2.3104558066004315, time: 0.04036355018615723
Test Loss Energy: 15.969758460203193, Test Loss Force: 9.466869154451217, time: 7.849820852279663


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0119008617276277, Training Loss Force: 2.1977075072290417, time: 0.47942018508911133
Validation Loss Energy: 0.9509749430901044, Validation Loss Force: 2.380434707098595, time: 0.04623699188232422
Test Loss Energy: 13.399708254060592, Test Loss Force: 9.341037020081343, time: 7.965500593185425

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–ƒâ–ƒâ–„â–â–â–‚â–â–‚â–„â–â–ƒâ–â–â–„â–ˆâ–â–†â–‚
wandb:   test_error_force â–†â–†â–ˆâ–‡â–†â–†â–„â–†â–†â–‚â–‡â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‡â–â–…â–
wandb:          test_loss â–â–‚â–„â–„â–…â–…â–„â–…â–…â–ƒâ–…â–„â–…â–ƒâ–ƒâ–„â–ˆâ–‚â–†â–„
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–
wandb: valid_error_energy â–ƒâ–â–â–â–‚â–„â–†â–„â–…â–ƒâ–ƒâ–„â–‚â–†â–„â–ƒâ–ˆâ–„â–„â–
wandb:  valid_error_force â–‡â–ƒâ–…â–ƒâ–‚â–…â–†â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–ƒâ–„â–ƒâ–ˆâ–„â–â–„
wandb:         valid_loss â–„â–‚â–ƒâ–â–â–„â–†â–„â–„â–ƒâ–‚â–ƒâ–â–„â–ƒâ–‚â–ˆâ–„â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 938
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.39971
wandb:   test_error_force 9.34104
wandb:          test_loss 6.78611
wandb: train_error_energy 2.0119
wandb:  train_error_force 2.19771
wandb:         train_loss -2.15599
wandb: valid_error_energy 0.95097
wandb:  valid_error_force 2.38043
wandb:         valid_loss -2.01777
wandb: 
wandb: ğŸš€ View run al_67_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/skaxl01m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_025425-skaxl01m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 11.933213233947754, Uncertainty Bias: -1.5951493978500366
4.196167e-05 0.015428543
0.27627897 11.206505
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2733 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3818 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2015 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2119 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1810 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1908 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1766 steps.
Found uncertainty sample 59 after 3027 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1604 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1769 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3260 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2759 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2299 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_033629-7tc8apns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7tc8apns
Training model 5. Added 13 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.654414298180287, Training Loss Force: 2.87547316055202, time: 0.44075560569763184
Validation Loss Energy: 2.886760964678062, Validation Loss Force: 2.7094446250545543, time: 0.046861886978149414
Test Loss Energy: 12.503496814865903, Test Loss Force: 9.450755159605876, time: 8.305058002471924


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2484532303573577, Training Loss Force: 2.2891918903308746, time: 0.45815253257751465
Validation Loss Energy: 1.0405621999132422, Validation Loss Force: 2.3961843184592135, time: 0.03983640670776367
Test Loss Energy: 13.530985938430995, Test Loss Force: 9.353705891890574, time: 7.942969560623169


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0913442734507752, Training Loss Force: 2.272193279485765, time: 0.44859910011291504
Validation Loss Energy: 2.0777565289943265, Validation Loss Force: 2.5086872364317903, time: 0.03865790367126465
Test Loss Energy: 15.444825284461263, Test Loss Force: 9.476346638796448, time: 8.007534503936768


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.367077729522681, Training Loss Force: 2.234034364035853, time: 0.4709286689758301
Validation Loss Energy: 1.9340881693502583, Validation Loss Force: 2.423070949822556, time: 0.03881692886352539
Test Loss Energy: 15.044684874811528, Test Loss Force: 9.392969834881407, time: 8.099538803100586


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2426253924463433, Training Loss Force: 2.2142350280955685, time: 0.42817187309265137
Validation Loss Energy: 1.9926880084840743, Validation Loss Force: 2.519626303563785, time: 0.04147052764892578
Test Loss Energy: 15.021548076969525, Test Loss Force: 9.475835479038732, time: 8.057852029800415


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2822356208555847, Training Loss Force: 2.2343529256494743, time: 0.43355560302734375
Validation Loss Energy: 0.9017377848696871, Validation Loss Force: 2.4243617628614995, time: 0.04231882095336914
Test Loss Energy: 13.967795176606145, Test Loss Force: 9.362000445815159, time: 7.893943548202515


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.728751917849624, Training Loss Force: 2.2176469837074677, time: 0.42960572242736816
Validation Loss Energy: 1.387115663203987, Validation Loss Force: 2.393189195777339, time: 0.04044222831726074
Test Loss Energy: 15.19441377798426, Test Loss Force: 9.363132868811311, time: 8.108121633529663


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8452335292731712, Training Loss Force: 2.287260012820805, time: 0.4219796657562256
Validation Loss Energy: 3.44573979117276, Validation Loss Force: 2.5713013549283925, time: 0.03977012634277344
Test Loss Energy: 16.375755772538287, Test Loss Force: 9.484525801139544, time: 8.040087938308716


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2713431843538996, Training Loss Force: 2.2553298325233873, time: 0.43125104904174805
Validation Loss Energy: 0.916662629713789, Validation Loss Force: 2.418350363928887, time: 0.03876304626464844
Test Loss Energy: 13.766721025384905, Test Loss Force: 9.289925175930053, time: 7.939695596694946


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6930234568677067, Training Loss Force: 2.263430083291644, time: 0.4357290267944336
Validation Loss Energy: 0.9171919142736594, Validation Loss Force: 2.475701251823194, time: 0.0394895076751709
Test Loss Energy: 13.78605672334069, Test Loss Force: 9.403678113021392, time: 7.895001411437988


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9399849641846143, Training Loss Force: 2.2577187124774065, time: 0.4533851146697998
Validation Loss Energy: 0.9580856595961624, Validation Loss Force: 2.403043418830373, time: 0.03918933868408203
Test Loss Energy: 13.537769578443635, Test Loss Force: 9.328163894214295, time: 8.099505186080933


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9104732510039808, Training Loss Force: 2.2060888740828797, time: 0.4291970729827881
Validation Loss Energy: 0.8717316701064692, Validation Loss Force: 2.3631676055084787, time: 0.03975534439086914
Test Loss Energy: 13.726812288506204, Test Loss Force: 9.278237302771288, time: 8.256732702255249


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6025770107336685, Training Loss Force: 2.231690032755629, time: 0.4574618339538574
Validation Loss Energy: 1.524320828218355, Validation Loss Force: 2.424896836819164, time: 0.04473876953125
Test Loss Energy: 13.681982656767062, Test Loss Force: 9.290865473924901, time: 7.932831287384033


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1934096587089167, Training Loss Force: 2.2271573610653603, time: 0.4428243637084961
Validation Loss Energy: 3.026361827033467, Validation Loss Force: 2.422528527783076, time: 0.04075336456298828
Test Loss Energy: 12.748271289866564, Test Loss Force: 9.270923728844252, time: 8.162435531616211


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9328249468740717, Training Loss Force: 2.2061678956516166, time: 0.4529857635498047
Validation Loss Energy: 1.1844665888519936, Validation Loss Force: 2.4094807838391454, time: 0.04520440101623535
Test Loss Energy: 14.388164492928286, Test Loss Force: 9.336048326546294, time: 7.974452972412109


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8450780709533658, Training Loss Force: 2.183009309886275, time: 0.43993639945983887
Validation Loss Energy: 1.075746040326719, Validation Loss Force: 2.3326461230070112, time: 0.03861856460571289
Test Loss Energy: 13.265686590991361, Test Loss Force: 9.27743345083319, time: 7.855554819107056


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3796219814161446, Training Loss Force: 2.229913322239899, time: 0.44538187980651855
Validation Loss Energy: 1.468187940552273, Validation Loss Force: 2.3960540570088456, time: 0.03976869583129883
Test Loss Energy: 14.136918734928635, Test Loss Force: 9.338221106424502, time: 7.9349987506866455


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7620021832296497, Training Loss Force: 2.2140669685576797, time: 0.44627857208251953
Validation Loss Energy: 0.8321895821670343, Validation Loss Force: 2.3733756498343923, time: 0.04314136505126953
Test Loss Energy: 14.047954833384681, Test Loss Force: 9.294035746291671, time: 8.070095539093018


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.001834006340418, Training Loss Force: 2.1780431199246477, time: 0.4267537593841553
Validation Loss Energy: 1.1563293362305476, Validation Loss Force: 2.4210540126987423, time: 0.045935630798339844
Test Loss Energy: 14.340009536485155, Test Loss Force: 9.342422861550089, time: 7.92694878578186


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2032126381691683, Training Loss Force: 2.1870674031146753, time: 0.44144368171691895
Validation Loss Energy: 0.8660409704112793, Validation Loss Force: 2.539255479453903, time: 0.04081463813781738
Test Loss Energy: 13.591839602017295, Test Loss Force: 9.32248929577168, time: 7.971837043762207

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–†â–†â–†â–„â–†â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–„â–‚â–„â–„â–„â–ƒ
wandb:   test_error_force â–‡â–„â–ˆâ–…â–ˆâ–„â–„â–ˆâ–‚â–…â–ƒâ–â–‚â–â–ƒâ–â–ƒâ–‚â–ƒâ–ƒ
wandb:          test_loss â–â–‚â–†â–†â–‡â–†â–‡â–ˆâ–…â–†â–„â–…â–…â–„â–…â–†â–‡â–…â–†â–‡
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–‚â–ƒâ–â–‚â–‚â–â–ƒâ–‚â–‚â–„â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–
wandb: valid_error_energy â–‡â–‚â–„â–„â–„â–â–‚â–ˆâ–â–â–â–â–ƒâ–‡â–‚â–‚â–ƒâ–â–‚â–
wandb:  valid_error_force â–ˆâ–‚â–„â–ƒâ–„â–ƒâ–‚â–…â–ƒâ–„â–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–…
wandb:         valid_loss â–ˆâ–‚â–„â–ƒâ–…â–‚â–‚â–‡â–‚â–ƒâ–‚â–â–ƒâ–„â–‚â–â–‚â–â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 949
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.59184
wandb:   test_error_force 9.32249
wandb:          test_loss 6.8633
wandb: train_error_energy 2.20321
wandb:  train_error_force 2.18707
wandb:         train_loss -2.15527
wandb: valid_error_energy 0.86604
wandb:  valid_error_force 2.53926
wandb:         valid_loss -1.84002
wandb: 
wandb: ğŸš€ View run al_67_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7tc8apns
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_033629-7tc8apns/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 13.154571533203125, Uncertainty Bias: -1.7498862743377686
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:925: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.00015258789 0.0069823265
0.4619405 9.903304
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2158 steps.
Found uncertainty sample 3 after 2268 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3144 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1119 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2999 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2257 steps.
Found uncertainty sample 16 after 1394 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1192 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3617 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2415 steps.
Found uncertainty sample 37 after 1614 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2461 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3894 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 537 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2162 steps.
Found uncertainty sample 66 after 1108 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1497 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2606 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3906 steps.
Found uncertainty sample 95 after 2376 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_041731-1i4xxuee
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1i4xxuee
Training model 6. Added 20 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.55284321397476, Training Loss Force: 2.927507938710458, time: 0.4909837245941162
Validation Loss Energy: 0.8904949970226472, Validation Loss Force: 2.4272348628514058, time: 0.0424196720123291
Test Loss Energy: 13.785124436771868, Test Loss Force: 9.364402222839947, time: 8.190023422241211


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.087118699923552, Training Loss Force: 2.3297859019131897, time: 0.45627617835998535
Validation Loss Energy: 0.8513385163766728, Validation Loss Force: 2.388872531714383, time: 0.0389399528503418
Test Loss Energy: 14.158548647887844, Test Loss Force: 9.199545308463266, time: 7.8419811725616455


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.386400740784163, Training Loss Force: 2.2651911629121875, time: 0.44104814529418945
Validation Loss Energy: 1.9849898907710588, Validation Loss Force: 2.36212751792785, time: 0.03858184814453125
Test Loss Energy: 15.194687831241584, Test Loss Force: 9.277914994428688, time: 7.851050853729248


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0106843012469744, Training Loss Force: 2.277784345751896, time: 0.47182226181030273
Validation Loss Energy: 1.289315032264157, Validation Loss Force: 2.462610755403245, time: 0.039133548736572266
Test Loss Energy: 14.575307049422147, Test Loss Force: 9.336045211509864, time: 8.018440961837769


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6843040610114486, Training Loss Force: 2.2235532896269343, time: 0.45580506324768066
Validation Loss Energy: 1.0771167915890503, Validation Loss Force: 2.362457068263823, time: 0.03956890106201172
Test Loss Energy: 13.887734622753042, Test Loss Force: 9.217924270544842, time: 7.735032320022583


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6462347588790298, Training Loss Force: 2.2585343861916054, time: 0.4421250820159912
Validation Loss Energy: 1.3983171459244572, Validation Loss Force: 2.426712703704205, time: 0.041480302810668945
Test Loss Energy: 14.570003755860686, Test Loss Force: 9.255568436561704, time: 7.7730231285095215


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9727137852037138, Training Loss Force: 2.3014184453092335, time: 0.4532177448272705
Validation Loss Energy: 1.339795352326289, Validation Loss Force: 2.4427404288280874, time: 0.04558825492858887
Test Loss Energy: 14.08358437757052, Test Loss Force: 9.308544863177099, time: 8.046137571334839


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.4075850846781317, Training Loss Force: 2.2501705775182126, time: 0.4806487560272217
Validation Loss Energy: 1.8852479188824574, Validation Loss Force: 2.3869700465315757, time: 0.03939557075500488
Test Loss Energy: 15.250252428775624, Test Loss Force: 9.296578688560134, time: 7.843383312225342


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.3770187918067656, Training Loss Force: 2.2621646402892996, time: 0.49548792839050293
Validation Loss Energy: 3.1771865503585084, Validation Loss Force: 2.485165581201709, time: 0.03876185417175293
Test Loss Energy: 16.33565928942955, Test Loss Force: 9.301743927251113, time: 7.809596538543701


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.301766899178264, Training Loss Force: 2.2574747216833253, time: 0.44221925735473633
Validation Loss Energy: 1.0685821058947842, Validation Loss Force: 2.3594091729943636, time: 0.03869175910949707
Test Loss Energy: 14.379584073789383, Test Loss Force: 9.253629946594065, time: 7.809071779251099


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.706543009077787, Training Loss Force: 2.200128323086315, time: 0.45882415771484375
Validation Loss Energy: 1.3463270177183617, Validation Loss Force: 2.3919740902480107, time: 0.042923927307128906
Test Loss Energy: 13.129941739199882, Test Loss Force: 9.235214653301682, time: 7.98129940032959


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1639588269240755, Training Loss Force: 2.2680319435529945, time: 0.44541215896606445
Validation Loss Energy: 0.8334439888006185, Validation Loss Force: 2.380478572920343, time: 0.04466843605041504
Test Loss Energy: 14.186622125617703, Test Loss Force: 9.1399348428587, time: 8.17758321762085


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6845652752639684, Training Loss Force: 2.2036364431574667, time: 0.44539594650268555
Validation Loss Energy: 1.121191254326559, Validation Loss Force: 2.4597242952645835, time: 0.041463613510131836
Test Loss Energy: 13.970271029010682, Test Loss Force: 9.202370525260342, time: 7.824121475219727


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8294185310579942, Training Loss Force: 2.270038235655057, time: 0.44434475898742676
Validation Loss Energy: 2.0021100307248627, Validation Loss Force: 2.4490731393382736, time: 0.04086661338806152
Test Loss Energy: 14.847011322123665, Test Loss Force: 9.278657548232268, time: 7.746659994125366


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.009956514326385, Training Loss Force: 2.2454115345081784, time: 0.4453620910644531
Validation Loss Energy: 0.9115972406476508, Validation Loss Force: 2.468365194141457, time: 0.04233264923095703
Test Loss Energy: 13.741559402568608, Test Loss Force: 9.23617156637856, time: 8.056059122085571


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0721975345075148, Training Loss Force: 2.2029083940619154, time: 0.4727647304534912
Validation Loss Energy: 2.249394137389238, Validation Loss Force: 2.3542733091435393, time: 0.03846001625061035
Test Loss Energy: 15.015357879375959, Test Loss Force: 9.261964692882394, time: 7.855517148971558


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.101698382451401, Training Loss Force: 2.2129446491417455, time: 0.45583152770996094
Validation Loss Energy: 2.120150507687518, Validation Loss Force: 2.356029500697472, time: 0.04018211364746094
Test Loss Energy: 15.338368504139678, Test Loss Force: 9.209583457396644, time: 7.782586097717285


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2372830027232418, Training Loss Force: 2.2842994617984136, time: 0.46699094772338867
Validation Loss Energy: 1.7062120167795223, Validation Loss Force: 2.386789461854228, time: 0.03933072090148926
Test Loss Energy: 13.02485956196711, Test Loss Force: 9.194799037508744, time: 8.002205848693848


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6076912127673186, Training Loss Force: 2.253296349525741, time: 0.4790382385253906
Validation Loss Energy: 2.5138674114426545, Validation Loss Force: 2.431001756793066, time: 0.041135549545288086
Test Loss Energy: 15.620589848635838, Test Loss Force: 9.263920613996996, time: 7.823371171951294


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1850619145369707, Training Loss Force: 2.267160987554448, time: 0.46597743034362793
Validation Loss Energy: 1.9299026574142537, Validation Loss Force: 2.3974003146651253, time: 0.04152083396911621
Test Loss Energy: 13.100198844432004, Test Loss Force: 9.208985057966007, time: 7.797571420669556

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–†â–„â–ƒâ–„â–ƒâ–†â–ˆâ–„â–â–ƒâ–ƒâ–…â–ƒâ–…â–†â–â–†â–
wandb:   test_error_force â–ˆâ–ƒâ–…â–‡â–ƒâ–…â–†â–†â–†â–…â–„â–â–ƒâ–…â–„â–…â–ƒâ–ƒâ–…â–ƒ
wandb:          test_loss â–ƒâ–â–„â–…â–„â–†â–…â–†â–ˆâ–†â–†â–…â–†â–‡â–…â–ˆâ–ˆâ–…â–‡â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–â–â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–â–â–‚â–â–‚
wandb: valid_error_energy â–â–â–„â–‚â–‚â–ƒâ–ƒâ–„â–ˆâ–‚â–ƒâ–â–‚â–„â–â–…â–…â–„â–†â–„
wandb:  valid_error_force â–…â–ƒâ–â–‡â–â–…â–†â–ƒâ–ˆâ–â–ƒâ–‚â–‡â–†â–‡â–â–â–ƒâ–…â–ƒ
wandb:         valid_loss â–‚â–â–ƒâ–„â–â–ƒâ–„â–ƒâ–ˆâ–â–‚â–â–„â–…â–„â–ƒâ–ƒâ–ƒâ–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 967
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.1002
wandb:   test_error_force 9.20899
wandb:          test_loss 6.45415
wandb: train_error_energy 2.18506
wandb:  train_error_force 2.26716
wandb:         train_loss -2.06789
wandb: valid_error_energy 1.9299
wandb:  valid_error_force 2.3974
wandb:         valid_loss -1.93823
wandb: 
wandb: ğŸš€ View run al_67_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1i4xxuee
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_041731-1i4xxuee/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 11.686925888061523, Uncertainty Bias: -1.6006450653076172
0.0001373291 0.0211792
0.44122514 9.576095
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2063 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3329 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1688 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1231 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3391 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 888 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2704 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3730 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2452 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_050023-lma6b2em
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lma6b2em
Training model 7. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.253129528974768, Training Loss Force: 2.6943333199408035, time: 0.45600199699401855
Validation Loss Energy: 1.389317193049775, Validation Loss Force: 2.4805135774049853, time: 0.04289412498474121
Test Loss Energy: 14.331725381559428, Test Loss Force: 9.201733551606141, time: 8.137902736663818


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6239973371737724, Training Loss Force: 2.2518112253340354, time: 0.46077919006347656
Validation Loss Energy: 2.024588258337127, Validation Loss Force: 2.3444852188268457, time: 0.03861355781555176
Test Loss Energy: 15.28610428770205, Test Loss Force: 9.172648316572698, time: 7.773102045059204


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.62028007151587, Training Loss Force: 2.230456729889636, time: 0.4404306411743164
Validation Loss Energy: 0.8432565170560778, Validation Loss Force: 2.328554577450588, time: 0.037899017333984375
Test Loss Energy: 14.150129744320425, Test Loss Force: 9.163016101652996, time: 7.967972278594971


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8646194864684855, Training Loss Force: 2.23472171316211, time: 0.5226054191589355
Validation Loss Energy: 1.0263070325255181, Validation Loss Force: 2.378476554629306, time: 0.041471004486083984
Test Loss Energy: 14.358918446470815, Test Loss Force: 9.19431929858255, time: 8.005596160888672


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7632219587055977, Training Loss Force: 2.2651797744628044, time: 0.4473111629486084
Validation Loss Energy: 2.2080475943584905, Validation Loss Force: 2.3933929380458627, time: 0.043557167053222656
Test Loss Energy: 12.850179729954023, Test Loss Force: 9.153076486731209, time: 7.732519626617432


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8940572077095013, Training Loss Force: 2.24802847878576, time: 0.4411163330078125
Validation Loss Energy: 3.697273761156313, Validation Loss Force: 2.4203040630152572, time: 0.03975200653076172
Test Loss Energy: 16.831339643043457, Test Loss Force: 9.20646072664124, time: 7.737234354019165


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8137852104545555, Training Loss Force: 2.2646542214068472, time: 0.4497382640838623
Validation Loss Energy: 1.050214016712628, Validation Loss Force: 2.3724152778080057, time: 0.040195465087890625
Test Loss Energy: 13.53059126611339, Test Loss Force: 9.111547567177682, time: 7.946927785873413


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7041383654650966, Training Loss Force: 2.214075176309999, time: 0.4809737205505371
Validation Loss Energy: 0.9269653084267219, Validation Loss Force: 2.3445892053179938, time: 0.03950190544128418
Test Loss Energy: 14.410226272113125, Test Loss Force: 9.092947143726278, time: 7.675540208816528


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8675990241058644, Training Loss Force: 2.2360752075656323, time: 0.46180224418640137
Validation Loss Energy: 1.1808494399109697, Validation Loss Force: 2.325075817383758, time: 0.039121389389038086
Test Loss Energy: 13.392975163441504, Test Loss Force: 9.16492075523691, time: 7.729740142822266


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.08972502072801, Training Loss Force: 2.22949117541845, time: 0.46405553817749023
Validation Loss Energy: 2.1908232452443928, Validation Loss Force: 2.3726041012437524, time: 0.038430213928222656
Test Loss Energy: 15.406757384888738, Test Loss Force: 9.142578450234033, time: 7.751261949539185


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.166171852962381, Training Loss Force: 2.222763862858739, time: 0.4550304412841797
Validation Loss Energy: 0.8782233107195615, Validation Loss Force: 2.352209166160789, time: 0.03929924964904785
Test Loss Energy: 13.663756102972322, Test Loss Force: 9.064140457302129, time: 7.941821336746216


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5679737908326548, Training Loss Force: 2.226640406989018, time: 0.4456517696380615
Validation Loss Energy: 1.88054091580669, Validation Loss Force: 2.3903532815348023, time: 0.03991341590881348
Test Loss Energy: 15.254836256176256, Test Loss Force: 9.170347088074083, time: 8.192094087600708


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8135961930811653, Training Loss Force: 2.2205168151297983, time: 0.473391056060791
Validation Loss Energy: 0.8657575682557996, Validation Loss Force: 2.410338060050967, time: 0.04033064842224121
Test Loss Energy: 13.824734018235919, Test Loss Force: 9.227617130747117, time: 7.778912544250488


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9861376837767166, Training Loss Force: 2.2415417566467863, time: 0.44121813774108887
Validation Loss Energy: 0.8993321230843698, Validation Loss Force: 2.463623232009779, time: 0.04020547866821289
Test Loss Energy: 14.25145131247733, Test Loss Force: 9.044593757597339, time: 7.725847959518433


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6544330507525231, Training Loss Force: 2.2467776851386403, time: 0.4946136474609375
Validation Loss Energy: 0.8985015115027727, Validation Loss Force: 2.4113244843674275, time: 0.039201974868774414
Test Loss Energy: 13.721581405552037, Test Loss Force: 9.060248494414687, time: 7.94290828704834


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4257727687844026, Training Loss Force: 2.2211762785369666, time: 0.4701716899871826
Validation Loss Energy: 1.5245263518400463, Validation Loss Force: 2.3398606033350715, time: 0.040799617767333984
Test Loss Energy: 14.827186348940046, Test Loss Force: 9.094981602930005, time: 7.78708553314209


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7515838056284925, Training Loss Force: 2.255350723797574, time: 0.44187164306640625
Validation Loss Energy: 0.8992740064372827, Validation Loss Force: 2.3385092242884356, time: 0.03919076919555664
Test Loss Energy: 13.627129737802774, Test Loss Force: 9.123639289887127, time: 7.7319746017456055


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.5475791017336133, Training Loss Force: 2.201317760609418, time: 0.45581960678100586
Validation Loss Energy: 1.311695396786786, Validation Loss Force: 2.3719098188467496, time: 0.041999101638793945
Test Loss Energy: 14.914499355788337, Test Loss Force: 9.081353533062085, time: 7.961766958236694


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9198468146324572, Training Loss Force: 2.232690374372568, time: 0.44958019256591797
Validation Loss Energy: 0.8608414231847195, Validation Loss Force: 2.3359607759132923, time: 0.04167628288269043
Test Loss Energy: 14.12385079804085, Test Loss Force: 9.088591744558387, time: 7.773015260696411


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6896335572332848, Training Loss Force: 2.1912293506693112, time: 0.4533822536468506
Validation Loss Energy: 1.5726314601225666, Validation Loss Force: 2.3683070320656383, time: 0.04116034507751465
Test Loss Energy: 14.626986287199857, Test Loss Force: 9.060586662396348, time: 7.8036675453186035

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–ƒâ–„â–â–ˆâ–‚â–„â–‚â–…â–‚â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–…â–ƒâ–„
wandb:   test_error_force â–‡â–†â–†â–‡â–…â–‡â–„â–ƒâ–†â–…â–‚â–†â–ˆâ–â–‚â–ƒâ–„â–‚â–ƒâ–‚
wandb:          test_loss â–â–ƒâ–„â–‡â–†â–ˆâ–„â–„â–†â–‡â–…â–‡â–ˆâ–„â–„â–„â–†â–‡â–…â–†
wandb: train_error_energy â–ˆâ–â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–„â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–‚â–‚â–â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–„â–â–â–„â–ˆâ–‚â–â–‚â–„â–â–„â–â–â–â–ƒâ–â–‚â–â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–â–ƒâ–„â–…â–ƒâ–‚â–â–ƒâ–‚â–„â–…â–‡â–…â–‚â–‚â–ƒâ–â–ƒ
wandb:         valid_loss â–†â–ƒâ–â–ƒâ–…â–ˆâ–ƒâ–‚â–â–„â–‚â–„â–ƒâ–…â–ƒâ–‚â–â–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 975
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.62699
wandb:   test_error_force 9.06059
wandb:          test_loss 6.53126
wandb: train_error_energy 1.68963
wandb:  train_error_force 2.19123
wandb:         train_loss -2.18549
wandb: valid_error_energy 1.57263
wandb:  valid_error_force 2.36831
wandb:         valid_loss -1.99207
wandb: 
wandb: ğŸš€ View run al_67_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lma6b2em
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_050023-lma6b2em/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 13.195060729980469, Uncertainty Bias: -1.7942054271697998
0.00038671494 0.02961731
0.48702016 9.433291
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3018 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2418 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2732 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3809 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3927 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2578 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3760 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_054358-7ph57pk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7ph57pk9
Training model 8. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.130338231569441, Training Loss Force: 2.679397909086583, time: 0.4585452079772949
Validation Loss Energy: 0.9262412996987376, Validation Loss Force: 2.446444084732304, time: 0.0416567325592041
Test Loss Energy: 13.761330105102589, Test Loss Force: 9.030637494392845, time: 7.724760055541992


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7834796936802917, Training Loss Force: 2.234459839880748, time: 0.4484128952026367
Validation Loss Energy: 1.7175734872813417, Validation Loss Force: 2.3758049702164645, time: 0.03907322883605957
Test Loss Energy: 12.980319493382241, Test Loss Force: 9.080097021563878, time: 7.8509321212768555


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9572469636584242, Training Loss Force: 2.2087821978280955, time: 0.4383068084716797
Validation Loss Energy: 1.8017769381596642, Validation Loss Force: 2.3703152850927607, time: 0.03945755958557129
Test Loss Energy: 15.120293542642326, Test Loss Force: 9.136341088750585, time: 8.219775199890137


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8248877957512932, Training Loss Force: 2.2498016506577887, time: 0.4637162685394287
Validation Loss Energy: 0.9284509013010656, Validation Loss Force: 2.3429501377348196, time: 0.03934335708618164
Test Loss Energy: 13.443906433407712, Test Loss Force: 9.065801643742402, time: 7.946090221405029


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.859581586267556, Training Loss Force: 2.244099014818945, time: 0.4537014961242676
Validation Loss Energy: 1.3322247126993172, Validation Loss Force: 2.391650551978978, time: 0.04153895378112793
Test Loss Energy: 13.95030915277395, Test Loss Force: 9.04323495818885, time: 7.783801078796387


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5764824116668148, Training Loss Force: 2.231868556426516, time: 0.4552910327911377
Validation Loss Energy: 1.2606890208673993, Validation Loss Force: 2.3939881326729275, time: 0.04050707817077637
Test Loss Energy: 13.102066719135209, Test Loss Force: 9.107945228066479, time: 7.736500263214111


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4429138845308962, Training Loss Force: 2.240053906553762, time: 0.46891236305236816
Validation Loss Energy: 1.303126086040328, Validation Loss Force: 2.423499365259321, time: 0.042241573333740234
Test Loss Energy: 12.970629650288606, Test Loss Force: 9.084353387754762, time: 7.936913251876831


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.196838846159275, Training Loss Force: 2.245962231220436, time: 0.44945788383483887
Validation Loss Energy: 1.1896296183386212, Validation Loss Force: 2.4614435237402916, time: 0.042771339416503906
Test Loss Energy: 14.208308202497198, Test Loss Force: 9.168184455380407, time: 7.745635986328125


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0886219572849, Training Loss Force: 2.221008903167985, time: 0.45675158500671387
Validation Loss Energy: 2.4966138926704398, Validation Loss Force: 2.3816489219513395, time: 0.03863978385925293
Test Loss Energy: 15.568847881112553, Test Loss Force: 9.093054584503708, time: 7.8011252880096436


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.192743314106852, Training Loss Force: 2.189904946912273, time: 0.4384298324584961
Validation Loss Energy: 1.9681921757405583, Validation Loss Force: 2.362402514323071, time: 0.0386967658996582
Test Loss Energy: 14.919952366953964, Test Loss Force: 9.02477511241437, time: 7.7416698932647705


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.204617149904889, Training Loss Force: 2.1769603526544743, time: 0.47605395317077637
Validation Loss Energy: 1.7330226066295304, Validation Loss Force: 2.3621353113479575, time: 0.038590431213378906
Test Loss Energy: 12.926543910699534, Test Loss Force: 9.049591833547503, time: 7.969210863113403


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1139351689573003, Training Loss Force: 2.1869003212858797, time: 0.4467597007751465
Validation Loss Energy: 1.573879632020065, Validation Loss Force: 2.442602151288466, time: 0.04105567932128906
Test Loss Energy: 12.85034955073491, Test Loss Force: 9.038855669302958, time: 7.753371238708496


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1217195996958655, Training Loss Force: 2.2104354264506636, time: 0.4465782642364502
Validation Loss Energy: 1.7155312772094649, Validation Loss Force: 2.3368630312925913, time: 0.040258169174194336
Test Loss Energy: 12.996840849189082, Test Loss Force: 9.050773145827966, time: 7.7507641315460205


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1672448201564123, Training Loss Force: 2.19615890078212, time: 0.4705634117126465
Validation Loss Energy: 2.240498282340277, Validation Loss Force: 2.37399912344299, time: 0.04644775390625
Test Loss Energy: 15.167207931164418, Test Loss Force: 9.088472804260253, time: 7.733985424041748


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.171685081756829, Training Loss Force: 2.1953052339653243, time: 0.45493030548095703
Validation Loss Energy: 0.950671222375059, Validation Loss Force: 2.3715813818565064, time: 0.04055619239807129
Test Loss Energy: 13.664075902498153, Test Loss Force: 9.07841532158281, time: 8.449634790420532


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9023657315845428, Training Loss Force: 2.2143011388044243, time: 0.47230029106140137
Validation Loss Energy: 0.9364846370842806, Validation Loss Force: 2.3648122398203015, time: 0.042662620544433594
Test Loss Energy: 13.743084557979437, Test Loss Force: 9.09119158287396, time: 7.767331838607788


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8527568451821883, Training Loss Force: 2.220073725078029, time: 0.4595332145690918
Validation Loss Energy: 0.9127723770652847, Validation Loss Force: 2.431627457093123, time: 0.04307436943054199
Test Loss Energy: 13.88462425421556, Test Loss Force: 9.011391400366673, time: 7.84259295463562


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9043738804599681, Training Loss Force: 2.296158867199219, time: 0.467850923538208
Validation Loss Energy: 2.4618331947456653, Validation Loss Force: 2.5114808435366003, time: 0.039605140686035156
Test Loss Energy: 15.54475334480228, Test Loss Force: 9.049786532650764, time: 7.9662511348724365


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0295399496642044, Training Loss Force: 2.241999079566706, time: 0.46003031730651855
Validation Loss Energy: 1.220102002293412, Validation Loss Force: 2.4135128767336056, time: 0.04124116897583008
Test Loss Energy: 12.928182107424842, Test Loss Force: 9.035079293852586, time: 7.815704107284546


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.210216156600649, Training Loss Force: 2.2110720447217465, time: 0.4687361717224121
Validation Loss Energy: 2.7644793084929207, Validation Loss Force: 2.3823196014188737, time: 0.0433344841003418
Test Loss Energy: 12.520613767503242, Test Loss Force: 9.044229699372782, time: 7.784202575683594

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–‡â–ƒâ–„â–‚â–‚â–…â–ˆâ–‡â–‚â–‚â–‚â–‡â–„â–„â–„â–ˆâ–‚â–
wandb:   test_error_force â–‚â–„â–‡â–ƒâ–‚â–…â–„â–ˆâ–…â–‚â–ƒâ–‚â–ƒâ–„â–„â–…â–â–ƒâ–‚â–‚
wandb:          test_loss â–â–ƒâ–‡â–…â–…â–…â–…â–‡â–‡â–†â–…â–…â–†â–ˆâ–†â–‡â–…â–†â–„â–„
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–â–â–‚â–‚â–â–â–‚â–â–â–â–â–â–â–â–â–â–‚â–‚â–
wandb: valid_error_energy â–â–„â–„â–â–ƒâ–‚â–‚â–‚â–‡â–…â–„â–ƒâ–„â–†â–â–â–â–‡â–‚â–ˆ
wandb:  valid_error_force â–…â–ƒâ–‚â–â–ƒâ–ƒâ–„â–†â–ƒâ–‚â–‚â–…â–â–‚â–‚â–‚â–…â–ˆâ–„â–ƒ
wandb:         valid_loss â–„â–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–…â–…â–ƒâ–ƒâ–…â–‚â–„â–‚â–‚â–ƒâ–ˆâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 981
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.52061
wandb:   test_error_force 9.04423
wandb:          test_loss 6.30457
wandb: train_error_energy 2.21022
wandb:  train_error_force 2.21107
wandb:         train_loss -2.12885
wandb: valid_error_energy 2.76448
wandb:  valid_error_force 2.38232
wandb:         valid_loss -1.89754
wandb: 
wandb: ğŸš€ View run al_67_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7ph57pk9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_054358-7ph57pk9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 12.67794132232666, Uncertainty Bias: -1.728024959564209
0.00010681152 0.162961
0.62708265 9.126157
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1009 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2259 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2089 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1894 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_062601-0emulqez
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0emulqez
Training model 9. Added 4 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.246754112647686, Training Loss Force: 2.7042068290150243, time: 0.4589543342590332
Validation Loss Energy: 1.1543024903297399, Validation Loss Force: 2.468554462915496, time: 0.0438232421875
Test Loss Energy: 13.256235323315, Test Loss Force: 9.012792476601906, time: 7.174400568008423


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2379617808831, Training Loss Force: 2.3414517970518713, time: 0.4410076141357422
Validation Loss Energy: 1.0074982811035709, Validation Loss Force: 2.4572787200348585, time: 0.036972761154174805
Test Loss Energy: 13.025415008402918, Test Loss Force: 9.030580990056906, time: 7.1582019329071045


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9552056173273469, Training Loss Force: 2.2941287387242277, time: 0.47568225860595703
Validation Loss Energy: 1.0768232023201445, Validation Loss Force: 2.3997127337455852, time: 0.042746782302856445
Test Loss Energy: 14.24469953630289, Test Loss Force: 9.112992155995128, time: 7.184446334838867


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.50438251931637, Training Loss Force: 2.287382495695675, time: 0.43552398681640625
Validation Loss Energy: 1.8476847473101692, Validation Loss Force: 2.4387248134504254, time: 0.036074161529541016
Test Loss Energy: 12.908861919366007, Test Loss Force: 9.063080999837418, time: 7.31161093711853


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9557071921485816, Training Loss Force: 2.2581228145982983, time: 0.453230619430542
Validation Loss Energy: 0.9101375330615211, Validation Loss Force: 2.370632588625708, time: 0.038114070892333984
Test Loss Energy: 13.333583016190964, Test Loss Force: 9.00183251937344, time: 7.580760717391968


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5180489800094825, Training Loss Force: 2.2536678981357867, time: 0.45455360412597656
Validation Loss Energy: 0.9495449618349562, Validation Loss Force: 2.4260295547644986, time: 0.03775978088378906
Test Loss Energy: 13.202948554200534, Test Loss Force: 9.02942064365037, time: 7.1555399894714355


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.806784239310218, Training Loss Force: 2.262077124132074, time: 0.4347958564758301
Validation Loss Energy: 1.5372492215000682, Validation Loss Force: 2.369951443708315, time: 0.039537906646728516
Test Loss Energy: 12.128999002714128, Test Loss Force: 8.967206497230206, time: 7.10678768157959


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.279434349263285, Training Loss Force: 2.237497970030727, time: 0.4656815528869629
Validation Loss Energy: 1.4361781374794238, Validation Loss Force: 2.445207157626675, time: 0.03732776641845703
Test Loss Energy: 14.572145086928005, Test Loss Force: 9.011990965604358, time: 7.323341369628906


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2338376484154576, Training Loss Force: 2.2266451189554606, time: 0.4955563545227051
Validation Loss Energy: 2.0361717299774362, Validation Loss Force: 2.399108632352683, time: 0.036331892013549805
Test Loss Energy: 14.991170423580831, Test Loss Force: 9.009739288568452, time: 7.137247323989868


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.21640318941355, Training Loss Force: 2.2257163803135467, time: 0.45657777786254883
Validation Loss Energy: 0.8791002931507981, Validation Loss Force: 2.3449425812525813, time: 0.03756427764892578
Test Loss Energy: 13.84298707315645, Test Loss Force: 8.969459960282505, time: 7.124160051345825


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.284625612838473, Training Loss Force: 2.2497316499428974, time: 0.4325270652770996
Validation Loss Energy: 1.4999122817800428, Validation Loss Force: 2.3775101705359796, time: 0.03977704048156738
Test Loss Energy: 12.951497231775946, Test Loss Force: 8.948456244257153, time: 7.213817834854126


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2550034676730615, Training Loss Force: 2.2233023450909117, time: 0.44025301933288574
Validation Loss Energy: 2.559539525302195, Validation Loss Force: 2.4121726311442666, time: 0.03858757019042969
Test Loss Energy: 12.665133606966496, Test Loss Force: 8.97849840635716, time: 7.344493865966797


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3553478996674735, Training Loss Force: 2.2231460888134755, time: 0.4554142951965332
Validation Loss Energy: 0.8602910407232724, Validation Loss Force: 2.35828625249145, time: 0.03978562355041504
Test Loss Energy: 13.671663361806292, Test Loss Force: 9.01030417337811, time: 7.165876626968384


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8335522921704785, Training Loss Force: 2.2656871081546113, time: 0.44725728034973145
Validation Loss Energy: 1.043007775142967, Validation Loss Force: 2.408738850244914, time: 0.038092851638793945
Test Loss Energy: 13.401305516968876, Test Loss Force: 9.045266778005422, time: 7.122148513793945


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5727298601321587, Training Loss Force: 2.2941030563522515, time: 0.43621325492858887
Validation Loss Energy: 0.9007027073448418, Validation Loss Force: 2.4164512187832687, time: 0.03835892677307129
Test Loss Energy: 13.38780249156479, Test Loss Force: 8.98740713541334, time: 7.210043668746948


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.120805494367421, Training Loss Force: 2.2590612824453147, time: 0.44464707374572754
Validation Loss Energy: 0.8041896607413392, Validation Loss Force: 2.414270174498906, time: 0.03644442558288574
Test Loss Energy: 13.886938684313177, Test Loss Force: 9.038874518071289, time: 7.672988653182983


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6259094240656387, Training Loss Force: 2.2109815009824243, time: 0.4718005657196045
Validation Loss Energy: 1.0093349675537562, Validation Loss Force: 2.334234422024914, time: 0.036743879318237305
Test Loss Energy: 14.062484780910419, Test Loss Force: 8.94916138498099, time: 7.162045001983643


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7769897428387018, Training Loss Force: 2.275549508911602, time: 0.45694422721862793
Validation Loss Energy: 0.9530265052661101, Validation Loss Force: 2.4264740023797704, time: 0.03733968734741211
Test Loss Energy: 13.187019190548801, Test Loss Force: 9.009024387708022, time: 7.148756742477417


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.50988240771497, Training Loss Force: 2.2664405954043665, time: 0.456925630569458
Validation Loss Energy: 2.071056859731651, Validation Loss Force: 2.4399457083775475, time: 0.03725767135620117
Test Loss Energy: 12.702814598496351, Test Loss Force: 8.955459690193614, time: 7.1726226806640625


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6282525930368634, Training Loss Force: 2.2286202517428455, time: 0.4433770179748535
Validation Loss Energy: 1.5325338683313285, Validation Loss Force: 2.383450315341895, time: 0.038918495178222656
Test Loss Energy: 12.81781596571145, Test Loss Force: 8.906043447106613, time: 7.321053504943848

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ƒâ–†â–ƒâ–„â–„â–â–‡â–ˆâ–…â–ƒâ–‚â–…â–„â–„â–…â–†â–„â–‚â–ƒ
wandb:   test_error_force â–…â–…â–ˆâ–†â–„â–…â–ƒâ–…â–…â–ƒâ–‚â–ƒâ–…â–†â–„â–…â–‚â–„â–ƒâ–
wandb:          test_loss â–â–â–…â–„â–„â–…â–ƒâ–‡â–ˆâ–‡â–†â–†â–‡â–‡â–…â–‡â–‡â–ˆâ–†â–…
wandb: train_error_energy â–ˆâ–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–‚â–‚â–‚â–…â–â–‚â–„â–„â–†â–â–„â–ˆâ–â–‚â–â–â–‚â–‚â–†â–„
wandb:  valid_error_force â–ˆâ–‡â–„â–†â–ƒâ–†â–ƒâ–‡â–„â–‚â–ƒâ–…â–‚â–…â–…â–…â–â–†â–‡â–„
wandb:         valid_loss â–†â–†â–„â–‡â–‚â–…â–„â–‡â–†â–â–„â–ˆâ–‚â–„â–„â–„â–â–…â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 984
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.81782
wandb:   test_error_force 8.90604
wandb:          test_loss 6.17935
wandb: train_error_energy 1.62825
wandb:  train_error_force 2.22862
wandb:         train_loss -2.14743
wandb: valid_error_energy 1.53253
wandb:  valid_error_force 2.38345
wandb:         valid_loss -1.97875
wandb: 
wandb: ğŸš€ View run al_67_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0emulqez
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_062601-0emulqez/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 13.851104736328125, Uncertainty Bias: -1.9022741317749023
8.010864e-05 0.0010766983
0.5785176 9.2914915
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1435 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1461 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 986 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3497 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1314 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2045 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 367 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_070528-frd1ce5f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/frd1ce5f
Training model 10. Added 7 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.649465404344576, Training Loss Force: 2.6622261817196806, time: 0.4608142375946045
Validation Loss Energy: 1.067257001807368, Validation Loss Force: 2.467057458247423, time: 0.04031658172607422
Test Loss Energy: 13.135589118379572, Test Loss Force: 8.958011730420267, time: 7.146974563598633


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9126599416870544, Training Loss Force: 2.264103715040795, time: 0.47716331481933594
Validation Loss Energy: 1.1751542311655745, Validation Loss Force: 2.3998534606458115, time: 0.03787350654602051
Test Loss Energy: 13.10987444136353, Test Loss Force: 8.931288639635248, time: 7.19184136390686


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6147156898723023, Training Loss Force: 2.2391609565898993, time: 0.4459264278411865
Validation Loss Energy: 1.855474493376734, Validation Loss Force: 2.4128384118905903, time: 0.036844730377197266
Test Loss Energy: 14.992300057966526, Test Loss Force: 8.939924970880114, time: 7.191861867904663


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.272933338588875, Training Loss Force: 2.2819759020777806, time: 0.441389799118042
Validation Loss Energy: 2.7830552593228, Validation Loss Force: 2.397567984532009, time: 0.037293434143066406
Test Loss Energy: 15.758310193110614, Test Loss Force: 9.012430437555155, time: 7.305920362472534


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.293658813448936, Training Loss Force: 2.2289621099362877, time: 0.5019881725311279
Validation Loss Energy: 1.3580641310693615, Validation Loss Force: 2.367447529162357, time: 0.04009890556335449
Test Loss Energy: 14.304138465058601, Test Loss Force: 8.997630605698095, time: 7.106212377548218


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2340080172478762, Training Loss Force: 2.2226723781627036, time: 0.4484577178955078
Validation Loss Energy: 1.6893911441578453, Validation Loss Force: 2.3778216846711326, time: 0.03760647773742676
Test Loss Energy: 12.86429118539258, Test Loss Force: 8.9592214930559, time: 7.123996734619141


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2093324743421268, Training Loss Force: 2.235686657088864, time: 0.4782412052154541
Validation Loss Energy: 1.929439282921578, Validation Loss Force: 2.4490490910705134, time: 0.038214683532714844
Test Loss Energy: 12.973093564828979, Test Loss Force: 8.94389979000598, time: 7.169668197631836


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6925010491930077, Training Loss Force: 2.236347499608161, time: 0.4613018035888672
Validation Loss Energy: 0.8784399121312627, Validation Loss Force: 2.3801053794317677, time: 0.037714242935180664
Test Loss Energy: 13.690227220885486, Test Loss Force: 8.964114734973192, time: 7.720736503601074


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.991068530398585, Training Loss Force: 2.256553198240027, time: 0.4675455093383789
Validation Loss Energy: 1.6816980365006131, Validation Loss Force: 2.4401274064006246, time: 0.036666154861450195
Test Loss Energy: 12.857405616538228, Test Loss Force: 8.975964319559026, time: 7.106099843978882


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9528857406262174, Training Loss Force: 2.283632406091656, time: 0.4506218433380127
Validation Loss Energy: 1.4729812279220875, Validation Loss Force: 2.3516210969463933, time: 0.03682661056518555
Test Loss Energy: 13.102183449063185, Test Loss Force: 8.924015817659342, time: 7.124579906463623


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.023722975014646, Training Loss Force: 2.2677127401494306, time: 0.4665486812591553
Validation Loss Energy: 0.857043912235494, Validation Loss Force: 2.3779570675118564, time: 0.0378110408782959
Test Loss Energy: 13.316441530310135, Test Loss Force: 8.918516407373254, time: 7.144133806228638


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6967588944827796, Training Loss Force: 2.226247773047428, time: 0.46248650550842285
Validation Loss Energy: 1.0018449341576101, Validation Loss Force: 2.4225507946976688, time: 0.0370631217956543
Test Loss Energy: 13.833677404403982, Test Loss Force: 8.98052553030295, time: 7.291723728179932


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5802752501554136, Training Loss Force: 2.2043049677622983, time: 0.4480125904083252
Validation Loss Energy: 1.7873058930349632, Validation Loss Force: 2.3581515376581637, time: 0.03998160362243652
Test Loss Energy: 12.93743310344026, Test Loss Force: 8.900446869134793, time: 7.090927600860596


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7214686153067102, Training Loss Force: 2.208498743596767, time: 0.4466135501861572
Validation Loss Energy: 1.399430714323242, Validation Loss Force: 2.355054209838308, time: 0.039740562438964844
Test Loss Energy: 14.184131910470352, Test Loss Force: 8.908346382346748, time: 7.126960277557373


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6571670956565163, Training Loss Force: 2.208412681971866, time: 0.464491605758667
Validation Loss Energy: 0.8471865161471303, Validation Loss Force: 2.3785901158937293, time: 0.03772401809692383
Test Loss Energy: 13.261976713174935, Test Loss Force: 8.998289766992007, time: 7.1121437549591064


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.18351682590341, Training Loss Force: 2.248818110265912, time: 0.4900481700897217
Validation Loss Energy: 2.8898012891965603, Validation Loss Force: 2.381131661525349, time: 0.037355899810791016
Test Loss Energy: 15.862537885073634, Test Loss Force: 8.936116955426494, time: 7.286120176315308


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8184263268074738, Training Loss Force: 2.251356513389424, time: 0.46082305908203125
Validation Loss Energy: 2.85627689059311, Validation Loss Force: 2.3474012939619158, time: 0.037164926528930664
Test Loss Energy: 15.283564395184824, Test Loss Force: 8.94957111952564, time: 7.127861976623535


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.349365797889021, Training Loss Force: 2.228394666349393, time: 0.44384145736694336
Validation Loss Energy: 1.442165933482568, Validation Loss Force: 2.3541029672469045, time: 0.03824305534362793
Test Loss Energy: 12.655934372783955, Test Loss Force: 8.903918861691718, time: 7.128851413726807


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1917639146428027, Training Loss Force: 2.2512966728521744, time: 0.502284049987793
Validation Loss Energy: 0.816981112498307, Validation Loss Force: 2.3757559830043604, time: 0.03771018981933594
Test Loss Energy: 13.568218140880132, Test Loss Force: 8.948107299555152, time: 7.126763582229614


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.218371309918557, Training Loss Force: 2.242851428325815, time: 0.4665799140930176
Validation Loss Energy: 2.077590195142318, Validation Loss Force: 2.3521635189858734, time: 0.0385432243347168
Test Loss Energy: 12.44215982166771, Test Loss Force: 8.889145829407049, time: 7.70577335357666

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–†â–ˆâ–…â–‚â–‚â–„â–‚â–‚â–ƒâ–„â–‚â–…â–ƒâ–ˆâ–‡â–â–ƒâ–
wandb:   test_error_force â–…â–ƒâ–„â–ˆâ–‡â–…â–„â–…â–†â–ƒâ–ƒâ–†â–‚â–‚â–‡â–„â–„â–‚â–„â–
wandb:          test_loss â–â–‚â–…â–‡â–†â–…â–†â–‡â–†â–„â–„â–‡â–†â–‡â–ˆâ–ˆâ–‡â–„â–†â–„
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–‚â–…â–ˆâ–ƒâ–„â–…â–â–„â–ƒâ–â–‚â–„â–ƒâ–â–ˆâ–ˆâ–ƒâ–â–…
wandb:  valid_error_force â–ˆâ–„â–…â–„â–‚â–ƒâ–‡â–ƒâ–†â–â–ƒâ–…â–‚â–â–ƒâ–ƒâ–â–â–ƒâ–
wandb:         valid_loss â–†â–ƒâ–†â–ˆâ–‚â–„â–ˆâ–â–‡â–‚â–â–„â–ƒâ–‚â–â–ˆâ–†â–‚â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 990
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 12.44216
wandb:   test_error_force 8.88915
wandb:          test_loss 6.09089
wandb: train_error_energy 2.21837
wandb:  train_error_force 2.24285
wandb:         train_loss -2.09316
wandb: valid_error_energy 2.07759
wandb:  valid_error_force 2.35216
wandb:         valid_loss -1.97828
wandb: 
wandb: ğŸš€ View run al_67_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/frd1ce5f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_070528-frd1ce5f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 14.23729133605957, Uncertainty Bias: -1.9709640741348267
8.392334e-05 0.022083282
0.5531369 8.940799
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1765 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3650 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1327 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3775 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3467 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3360 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3252 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1863 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 593 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_074515-yrvwbnib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yrvwbnib
Training model 11. Added 9 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 7.966596885025863, Training Loss Force: 2.5825227178285477, time: 0.46292853355407715
Validation Loss Energy: 4.9383380595165125, Validation Loss Force: 2.3894922199474995, time: 0.03969097137451172
Test Loss Energy: 11.665899976253858, Test Loss Force: 8.851665328709867, time: 7.121807336807251


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.3887597724068055, Training Loss Force: 2.455530833344228, time: 0.47703027725219727
Validation Loss Energy: 0.9077987833545551, Validation Loss Force: 2.3628694515220814, time: 0.03922843933105469
Test Loss Energy: 13.284342222401273, Test Loss Force: 8.81435312858118, time: 7.133314609527588


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1958444083910234, Training Loss Force: 2.2863046622156062, time: 0.47919774055480957
Validation Loss Energy: 2.0384781369909564, Validation Loss Force: 2.442493934083545, time: 0.03660321235656738
Test Loss Energy: 12.775422297122931, Test Loss Force: 8.922818566464937, time: 7.141849994659424


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1896717134958297, Training Loss Force: 2.2353928197862825, time: 0.4686930179595947
Validation Loss Energy: 1.99763460356086, Validation Loss Force: 2.444961330889571, time: 0.03809070587158203
Test Loss Energy: 14.698560950212636, Test Loss Force: 8.916772495264944, time: 7.313238143920898


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4119670188028373, Training Loss Force: 2.2532423368820105, time: 0.4611985683441162
Validation Loss Energy: 1.8708040393935597, Validation Loss Force: 2.421232593353776, time: 0.038960933685302734
Test Loss Energy: 12.352813222976135, Test Loss Force: 8.92811044444379, time: 7.152617931365967


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.4887818586017785, Training Loss Force: 2.2919256560305046, time: 0.4763779640197754
Validation Loss Energy: 1.4589547417472313, Validation Loss Force: 2.4984028165888237, time: 0.04104924201965332
Test Loss Energy: 14.317105121293396, Test Loss Force: 8.882332517273458, time: 7.195840358734131


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1796180971810277, Training Loss Force: 2.261709686034866, time: 0.4531731605529785
Validation Loss Energy: 1.4425238741346469, Validation Loss Force: 2.390853619105702, time: 0.04010200500488281
Test Loss Energy: 12.672065365096039, Test Loss Force: 8.88886629685661, time: 7.179473638534546


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2164364613354204, Training Loss Force: 2.223299435801798, time: 0.45085763931274414
Validation Loss Energy: 2.6468641295989874, Validation Loss Force: 2.3875467596195286, time: 0.038105010986328125
Test Loss Energy: 11.811100782266028, Test Loss Force: 8.90791131714659, time: 7.309016942977905


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7371168572681561, Training Loss Force: 2.248185370972158, time: 0.46663808822631836
Validation Loss Energy: 1.5139050335792907, Validation Loss Force: 2.4040545594220313, time: 0.037904977798461914
Test Loss Energy: 12.452095738649545, Test Loss Force: 8.851090497234487, time: 7.176007509231567


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.616939709806875, Training Loss Force: 2.244465174925445, time: 0.47156572341918945
Validation Loss Energy: 1.1969772548159463, Validation Loss Force: 2.4111276448424275, time: 0.03804969787597656
Test Loss Energy: 12.637467830613796, Test Loss Force: 8.963782022968507, time: 7.156775712966919


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0068686043227477, Training Loss Force: 2.214176847894996, time: 0.46298646926879883
Validation Loss Energy: 3.7766731252112433, Validation Loss Force: 2.386251493197667, time: 0.039258480072021484
Test Loss Energy: 11.773412590711855, Test Loss Force: 8.894348476514546, time: 7.5711376667022705


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.438598053820298, Training Loss Force: 2.286628151775764, time: 0.4650747776031494
Validation Loss Energy: 2.4424625377339693, Validation Loss Force: 2.5251371422563516, time: 0.03879404067993164
Test Loss Energy: 14.598073237203991, Test Loss Force: 8.968654704712723, time: 7.341490983963013


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5808713388260354, Training Loss Force: 2.2295541042555422, time: 0.45883703231811523
Validation Loss Energy: 1.0732964570523673, Validation Loss Force: 2.3641903248957252, time: 0.03865766525268555
Test Loss Energy: 12.982082799856578, Test Loss Force: 8.895445678148203, time: 7.1365883350372314


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5866308119744683, Training Loss Force: 2.2848784732943495, time: 0.47951292991638184
Validation Loss Energy: 0.9535976516254149, Validation Loss Force: 2.4084714246006547, time: 0.03926873207092285
Test Loss Energy: 13.551678799002172, Test Loss Force: 8.904901879519988, time: 7.238626718521118


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0611783187724377, Training Loss Force: 2.2924291353238853, time: 0.47942590713500977
Validation Loss Energy: 1.3918636374026052, Validation Loss Force: 2.543079376696921, time: 0.039054155349731445
Test Loss Energy: 12.594278139647306, Test Loss Force: 8.991484606181286, time: 7.1879050731658936


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5002243299732254, Training Loss Force: 2.268320781686338, time: 0.49193787574768066
Validation Loss Energy: 1.534024526928742, Validation Loss Force: 2.420777902957792, time: 0.0378413200378418
Test Loss Energy: 14.042070972577177, Test Loss Force: 8.953164747726593, time: 7.372936487197876


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6036296094209606, Training Loss Force: 2.266255511441036, time: 0.4605729579925537
Validation Loss Energy: 1.0627697731786312, Validation Loss Force: 2.445372155463808, time: 0.038659095764160156
Test Loss Energy: 13.146402058012985, Test Loss Force: 8.948826369341582, time: 7.1503190994262695


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3301925769177028, Training Loss Force: 2.3798127469443484, time: 0.4703333377838135
Validation Loss Energy: 1.1792726083540819, Validation Loss Force: 2.4539391281842335, time: 0.04052901268005371
Test Loss Energy: 12.63463865939922, Test Loss Force: 8.829065324390921, time: 7.177168846130371


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4197103122584354, Training Loss Force: 2.265224149707563, time: 0.4614243507385254
Validation Loss Energy: 2.82592396863511, Validation Loss Force: 2.454860533110083, time: 0.03955578804016113
Test Loss Energy: 12.055564840155967, Test Loss Force: 8.828535749545097, time: 7.145535707473755


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0410320459789837, Training Loss Force: 2.250782434284427, time: 0.48091721534729004
Validation Loss Energy: 0.8539141303876195, Validation Loss Force: 2.435238259963488, time: 0.04178309440612793
Test Loss Energy: 13.513658147257637, Test Loss Force: 8.879538530115552, time: 7.366179943084717

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–„â–ˆâ–ƒâ–‡â–ƒâ–â–ƒâ–ƒâ–â–ˆâ–„â–…â–ƒâ–†â–„â–ƒâ–‚â–…
wandb:   test_error_force â–‚â–â–…â–…â–…â–„â–„â–…â–‚â–‡â–„â–‡â–„â–…â–ˆâ–†â–†â–‚â–‚â–„
wandb:          test_loss â–â–„â–„â–†â–…â–†â–…â–…â–…â–‡â–…â–ˆâ–†â–†â–…â–†â–†â–„â–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–†â–‚â–â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–„â–‚â–‚
wandb:         train_loss â–ˆâ–„â–‚â–â–‚â–‚â–‚â–â–â–â–â–‚â–â–‚â–‚â–â–â–ƒâ–‚â–
wandb: valid_error_energy â–ˆâ–â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–‚â–‚â–†â–„â–â–â–‚â–‚â–â–‚â–„â–
wandb:  valid_error_force â–‚â–â–„â–„â–ƒâ–†â–‚â–‚â–ƒâ–ƒâ–‚â–‡â–â–ƒâ–ˆâ–ƒâ–„â–…â–…â–„
wandb:         valid_loss â–ˆâ–â–…â–…â–„â–…â–ƒâ–„â–ƒâ–ƒâ–†â–ˆâ–â–‚â–†â–„â–ƒâ–„â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 998
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 13.51366
wandb:   test_error_force 8.87954
wandb:          test_loss 5.99687
wandb: train_error_energy 2.04103
wandb:  train_error_force 2.25078
wandb:         train_loss -2.095
wandb: valid_error_energy 0.85391
wandb:  valid_error_force 2.43524
wandb:         valid_loss -1.97029
wandb: 
wandb: ğŸš€ View run al_67_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/yrvwbnib
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_074515-yrvwbnib/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 14.512365341186523, Uncertainty Bias: -2.03991961479187
7.6293945e-06 0.005432129
0.65910065 8.960812
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3265 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3839 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2377 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_082554-uvu9gah3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/uvu9gah3
Training model 12. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.642221058913154, Training Loss Force: 2.8079750367241356, time: 0.5263645648956299
Validation Loss Energy: 1.2576396782484913, Validation Loss Force: 2.5900131339372883, time: 0.045868873596191406
Test Loss Energy: 13.1391783911254, Test Loss Force: 9.03989541996535, time: 7.290022611618042


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0004929708554786, Training Loss Force: 2.285467537561491, time: 0.5450925827026367
Validation Loss Energy: 1.3096105455734641, Validation Loss Force: 2.3782262745092835, time: 0.03933000564575195
Test Loss Energy: 12.951799007924835, Test Loss Force: 8.78915867197522, time: 7.277404308319092


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.885102918029403, Training Loss Force: 2.248439123339175, time: 0.4598217010498047
Validation Loss Energy: 2.169789249712616, Validation Loss Force: 2.400666203028448, time: 0.03903031349182129
Test Loss Energy: 14.831539113384013, Test Loss Force: 8.875870863840673, time: 7.270985841751099


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.802413584039926, Training Loss Force: 2.2413426994089214, time: 0.5121762752532959
Validation Loss Energy: 2.9208992621168353, Validation Loss Force: 2.379515751533351, time: 0.04330778121948242
Test Loss Energy: 11.872392514171441, Test Loss Force: 8.839149289541234, time: 7.868471384048462


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0985922167764217, Training Loss Force: 2.233271433437001, time: 0.5083889961242676
Validation Loss Energy: 1.313776907962919, Validation Loss Force: 2.3532321082171808, time: 0.03927445411682129
Test Loss Energy: 14.413978492041483, Test Loss Force: 8.822643145184738, time: 7.244824647903442


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1651372563535087, Training Loss Force: 2.1807319839271075, time: 0.4597604274749756
Validation Loss Energy: 2.282766230296873, Validation Loss Force: 2.46321908750992, time: 0.03902745246887207
Test Loss Energy: 12.398718782701943, Test Loss Force: 8.854181746536403, time: 7.258808612823486


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0834627946544986, Training Loss Force: 2.2033278921829944, time: 0.4476191997528076
Validation Loss Energy: 2.36050626387635, Validation Loss Force: 2.3604975797796586, time: 0.039319515228271484
Test Loss Energy: 15.238901637066352, Test Loss Force: 8.843187300072266, time: 7.272866249084473


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2895238857364326, Training Loss Force: 2.1874748231704495, time: 0.4595651626586914
Validation Loss Energy: 2.4917884296090387, Validation Loss Force: 2.3495674194135012, time: 0.03879499435424805
Test Loss Energy: 15.069971905823452, Test Loss Force: 8.857109652281382, time: 7.400261402130127


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1021900909195015, Training Loss Force: 2.1975095126078474, time: 0.4817378520965576
Validation Loss Energy: 3.011320971564337, Validation Loss Force: 2.4454861620665227, time: 0.03783893585205078
Test Loss Energy: 12.027875976160512, Test Loss Force: 8.864893251630294, time: 7.304069995880127


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.27015241980948, Training Loss Force: 2.217264190395339, time: 0.5098426342010498
Validation Loss Energy: 1.7754723639437768, Validation Loss Force: 2.403231796927828, time: 0.03802013397216797
Test Loss Energy: 14.79216440007083, Test Loss Force: 8.839198822351038, time: 7.254162549972534


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8770397879283103, Training Loss Force: 2.192846003078849, time: 0.4658033847808838
Validation Loss Energy: 1.0800563583190161, Validation Loss Force: 2.3816237603378494, time: 0.03931427001953125
Test Loss Energy: 14.079207266412192, Test Loss Force: 8.880636305326274, time: 7.250938177108765


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7276471890489473, Training Loss Force: 2.2509249529754376, time: 0.45437002182006836
Validation Loss Energy: 0.8765436060172552, Validation Loss Force: 2.3802603571573338, time: 0.038735151290893555
Test Loss Energy: 13.529309563856517, Test Loss Force: 8.829143065068028, time: 7.399708271026611


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.163014010368939, Training Loss Force: 2.2275146392767304, time: 0.4759557247161865
Validation Loss Energy: 1.7241368830267092, Validation Loss Force: 2.4017993663120745, time: 0.03858542442321777
Test Loss Energy: 14.318463375104187, Test Loss Force: 8.908297950058797, time: 7.24833345413208


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.555145991675018, Training Loss Force: 2.2392535966065945, time: 0.4678659439086914
Validation Loss Energy: 3.166611547280106, Validation Loss Force: 2.4890667446383636, time: 0.04064655303955078
Test Loss Energy: 15.57209300761818, Test Loss Force: 8.937400476342358, time: 7.215494394302368


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.189681514417456, Training Loss Force: 2.2493301548018376, time: 0.45260119438171387
Validation Loss Energy: 1.455672153197964, Validation Loss Force: 2.3921940873641874, time: 0.03920912742614746
Test Loss Energy: 12.541007915666452, Test Loss Force: 8.787464665734968, time: 7.265017509460449


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0062638088283675, Training Loss Force: 2.27296088312137, time: 0.46406126022338867
Validation Loss Energy: 1.0338041913343337, Validation Loss Force: 2.438710785294232, time: 0.03840065002441406
Test Loss Energy: 13.958751559011432, Test Loss Force: 8.80449889270427, time: 7.8315346240997314


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6546686881315524, Training Loss Force: 2.2451500495510324, time: 0.46440768241882324
Validation Loss Energy: 0.8563861475784234, Validation Loss Force: 2.40722826275894, time: 0.03815722465515137
Test Loss Energy: 13.212558292360372, Test Loss Force: 8.877550964334473, time: 7.313902378082275


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6293221722704572, Training Loss Force: 2.218304462373854, time: 0.47290563583374023
Validation Loss Energy: 1.4943369803697297, Validation Loss Force: 2.4383883603709284, time: 0.03803586959838867
Test Loss Energy: 12.180913369783482, Test Loss Force: 8.940845286942182, time: 7.225453853607178


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7007152149411624, Training Loss Force: 2.2179227239568045, time: 0.45948362350463867
Validation Loss Energy: 1.770106371530636, Validation Loss Force: 2.3862448131232887, time: 0.04156088829040527
Test Loss Energy: 14.279562571681955, Test Loss Force: 8.818971916203528, time: 7.3721630573272705


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0591652209517886, Training Loss Force: 2.22372203052792, time: 0.5230526924133301
Validation Loss Energy: 1.6376084322611815, Validation Loss Force: 2.4336118845216315, time: 0.04028487205505371
Test Loss Energy: 14.244303679525329, Test Loss Force: 8.901063809560702, time: 7.216869115829468

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.040 MB of 0.058 MB uploadedwandb: / 0.040 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–‡â–â–†â–‚â–‡â–‡â–â–‡â–…â–„â–†â–ˆâ–‚â–…â–„â–‚â–†â–…
wandb:   test_error_force â–ˆâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–„â–…â–â–â–ƒâ–…â–‚â–„
wandb:          test_loss â–‚â–â–…â–ƒâ–„â–„â–‡â–ˆâ–…â–ˆâ–‡â–‡â–ˆâ–ˆâ–ƒâ–…â–†â–…â–†â–‡
wandb: train_error_energy â–ˆâ–‚â–…â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–„â–ƒâ–‚â–â–â–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–‚â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–…â–‡â–‚â–…â–†â–†â–ˆâ–„â–‚â–â–„â–ˆâ–ƒâ–‚â–â–ƒâ–„â–ƒ
wandb:  valid_error_force â–ˆâ–‚â–‚â–‚â–â–„â–â–â–„â–ƒâ–‚â–‚â–ƒâ–…â–‚â–„â–ƒâ–„â–‚â–ƒ
wandb:         valid_loss â–‡â–‚â–„â–„â–â–†â–ƒâ–ƒâ–‡â–ƒâ–‚â–â–ƒâ–ˆâ–‚â–ƒâ–‚â–„â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 1000
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.2443
wandb:   test_error_force 8.90106
wandb:          test_loss 6.18682
wandb: train_error_energy 2.05917
wandb:  train_error_force 2.22372
wandb:         train_loss -2.12431
wandb: valid_error_energy 1.63761
wandb:  valid_error_force 2.43361
wandb:         valid_loss -1.91749
wandb: 
wandb: ğŸš€ View run al_67_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/uvu9gah3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_082554-uvu9gah3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 15.574676513671875, Uncertainty Bias: -2.171830654144287
1.5258789e-05 0.011839867
0.6856785 8.519674
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1790 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3242 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1497 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 991 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1220 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 674 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2573 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2141 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_090520-862pbry6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/862pbry6
Training model 13. Added 8 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.238651872013008, Training Loss Force: 2.734729235413876, time: 0.48889589309692383
Validation Loss Energy: 0.9174450334252928, Validation Loss Force: 2.537640014800197, time: 0.0458526611328125
Test Loss Energy: 13.079819693210645, Test Loss Force: 8.844557720245396, time: 7.1449103355407715


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.127451548906455, Training Loss Force: 2.2922873437868048, time: 0.4646151065826416
Validation Loss Energy: 1.2538321471876992, Validation Loss Force: 2.5159798736300716, time: 0.03895092010498047
Test Loss Energy: 12.9289360395052, Test Loss Force: 8.884710469865437, time: 7.202475309371948


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3329552469280506, Training Loss Force: 2.2511295128572315, time: 0.49320149421691895
Validation Loss Energy: 1.0591215618917502, Validation Loss Force: 2.517938916775944, time: 0.038509368896484375
Test Loss Energy: 14.05886805107703, Test Loss Force: 8.814352764849382, time: 7.109861850738525


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2204451513547228, Training Loss Force: 2.2807756829460573, time: 0.5034620761871338
Validation Loss Energy: 0.9432232734474933, Validation Loss Force: 2.4188538188678295, time: 0.03896212577819824
Test Loss Energy: 13.12847659953582, Test Loss Force: 8.751260374011853, time: 7.32146954536438


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0140191542514887, Training Loss Force: 2.263732228158587, time: 0.47335386276245117
Validation Loss Energy: 1.4664604733181652, Validation Loss Force: 2.4450510665553797, time: 0.040372610092163086
Test Loss Energy: 14.217507688494063, Test Loss Force: 8.821841830042775, time: 7.165890216827393


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2655425805030616, Training Loss Force: 2.261024821846895, time: 0.4644186496734619
Validation Loss Energy: 1.9225541302603448, Validation Loss Force: 2.4724656464637174, time: 0.03941154479980469
Test Loss Energy: 12.040346740046676, Test Loss Force: 8.781304219537237, time: 7.2006003856658936


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.486569127454189, Training Loss Force: 2.297632356591353, time: 0.47585058212280273
Validation Loss Energy: 1.752345612443998, Validation Loss Force: 2.482633387674218, time: 0.04016685485839844
Test Loss Energy: 12.753143360727888, Test Loss Force: 8.809283416119609, time: 7.11344313621521


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9794541653222293, Training Loss Force: 2.2570495756895483, time: 0.44325947761535645
Validation Loss Energy: 1.52736104140228, Validation Loss Force: 2.5170475721847954, time: 0.04743146896362305
Test Loss Energy: 14.348280121416863, Test Loss Force: 8.914948730037162, time: 7.764601469039917


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7597067151858437, Training Loss Force: 2.286064426561588, time: 0.4679858684539795
Validation Loss Energy: 0.9825427479082869, Validation Loss Force: 2.3828580154137273, time: 0.03686380386352539
Test Loss Energy: 12.765691939902808, Test Loss Force: 8.79928665333639, time: 7.178679466247559


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1536117378376325, Training Loss Force: 2.2685320807890017, time: 0.46447205543518066
Validation Loss Energy: 0.9872888294191647, Validation Loss Force: 2.411501951676732, time: 0.03757834434509277
Test Loss Energy: 13.649588665479381, Test Loss Force: 8.725745259846073, time: 7.172767162322998


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8018223800614606, Training Loss Force: 2.261412457517107, time: 0.473463773727417
Validation Loss Energy: 1.5904148201275166, Validation Loss Force: 2.4216020014668707, time: 0.044187068939208984
Test Loss Energy: 14.469636284190843, Test Loss Force: 8.806164695740446, time: 7.174241542816162


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.300692916168487, Training Loss Force: 2.2113782829224844, time: 0.46875834465026855
Validation Loss Energy: 2.439302862553254, Validation Loss Force: 2.412466331747745, time: 0.03895282745361328
Test Loss Energy: 15.090668371070025, Test Loss Force: 8.742442512620128, time: 7.296702146530151


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1926278308059075, Training Loss Force: 2.2172767538060567, time: 0.4901766777038574
Validation Loss Energy: 2.2470630141005197, Validation Loss Force: 2.4452087163106966, time: 0.04284477233886719
Test Loss Energy: 14.970252758105214, Test Loss Force: 8.872639097483802, time: 7.148254632949829


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.635607951778934, Training Loss Force: 2.2807349692844063, time: 0.4739232063293457
Validation Loss Energy: 1.904284349506116, Validation Loss Force: 2.4856075794563752, time: 0.0391385555267334
Test Loss Energy: 14.27332988741638, Test Loss Force: 8.826484824482641, time: 7.1808788776397705


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1290428383014035, Training Loss Force: 2.26879379009878, time: 0.4593689441680908
Validation Loss Energy: 0.8567458695836697, Validation Loss Force: 2.5315010264469677, time: 0.0413050651550293
Test Loss Energy: 13.16291340653214, Test Loss Force: 8.950877252434983, time: 7.181952714920044


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.856819881231662, Training Loss Force: 2.290828923506675, time: 0.4708120822906494
Validation Loss Energy: 1.035829367216547, Validation Loss Force: 2.429508982838766, time: 0.04367351531982422
Test Loss Energy: 13.487358780701829, Test Loss Force: 8.795483240488991, time: 7.383406639099121


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.663638646776437, Training Loss Force: 2.244761592788345, time: 0.5225651264190674
Validation Loss Energy: 0.8247888390984054, Validation Loss Force: 2.424209679834831, time: 0.03859663009643555
Test Loss Energy: 13.569047957672774, Test Loss Force: 8.756255530781171, time: 7.207059383392334


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.161272727210167, Training Loss Force: 2.2547763950876476, time: 0.5306262969970703
Validation Loss Energy: 0.8378788345127758, Validation Loss Force: 2.418451233051992, time: 0.039582252502441406
Test Loss Energy: 13.208670535704758, Test Loss Force: 8.798066025379082, time: 7.148759126663208


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.955147283005457, Training Loss Force: 2.2520175765576833, time: 0.4728999137878418
Validation Loss Energy: 3.1056324883220516, Validation Loss Force: 2.4808384516888937, time: 0.03792381286621094
Test Loss Energy: 11.58265526760367, Test Loss Force: 8.807769704270749, time: 7.20533299446106


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.239707911248395, Training Loss Force: 2.2119334005824873, time: 0.4967968463897705
Validation Loss Energy: 2.290641147311755, Validation Loss Force: 2.4273649016326275, time: 0.04289984703063965
Test Loss Energy: 14.99534138274747, Test Loss Force: 8.764170278759613, time: 7.808133125305176

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–„â–†â–„â–†â–‚â–ƒâ–‡â–ƒâ–…â–‡â–ˆâ–ˆâ–†â–„â–…â–…â–„â–â–ˆ
wandb:   test_error_force â–…â–†â–„â–‚â–„â–ƒâ–„â–‡â–ƒâ–â–„â–‚â–†â–„â–ˆâ–ƒâ–‚â–ƒâ–„â–‚
wandb:          test_loss â–â–‚â–ƒâ–ƒâ–…â–‚â–„â–‡â–„â–„â–†â–†â–ˆâ–†â–‡â–…â–„â–„â–‚â–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–‚â–â–ƒâ–‚â–â–‚â–‚â–â–‚â–‚â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–â–â–â–â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–â–‚â–‚â–â–ƒâ–„â–„â–ƒâ–â–â–ƒâ–†â–…â–„â–â–‚â–â–â–ˆâ–…
wandb:  valid_error_force â–ˆâ–‡â–‡â–ƒâ–„â–…â–†â–‡â–â–‚â–ƒâ–‚â–„â–†â–ˆâ–ƒâ–ƒâ–ƒâ–…â–ƒ
wandb:         valid_loss â–…â–…â–…â–‚â–„â–…â–†â–†â–â–‚â–ƒâ–…â–…â–†â–…â–ƒâ–‚â–‚â–ˆâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1007
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.99534
wandb:   test_error_force 8.76417
wandb:          test_loss 5.97319
wandb: train_error_energy 2.23971
wandb:  train_error_force 2.21193
wandb:         train_loss -2.12485
wandb: valid_error_energy 2.29064
wandb:  valid_error_force 2.42736
wandb:         valid_loss -1.88344
wandb: 
wandb: ğŸš€ View run al_67_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/862pbry6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_090520-862pbry6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 17.245948791503906, Uncertainty Bias: -2.458716869354248
4.5776367e-05 0.13012147
0.40501913 8.947623
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1257 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2736 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2020 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241201_094548-mmc7zi8d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_67_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/mmc7zi8d
Training model 14. Added 3 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.080091452077371, Training Loss Force: 2.795055734606146, time: 0.4793565273284912
Validation Loss Energy: 1.0371191782443336, Validation Loss Force: 2.4758849538685843, time: 0.04247093200683594
Test Loss Energy: 14.148048536254123, Test Loss Force: 8.789017147662973, time: 7.2931976318359375


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6219726691994323, Training Loss Force: 2.2573127149527488, time: 0.4774181842803955
Validation Loss Energy: 1.10816911733441, Validation Loss Force: 2.425453955022275, time: 0.0393986701965332
Test Loss Energy: 13.853575105294404, Test Loss Force: 8.752701031727938, time: 7.763901233673096


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7885190902201265, Training Loss Force: 2.2408388513197677, time: 0.46517109870910645
Validation Loss Energy: 1.9328579223190074, Validation Loss Force: 2.3640683022037567, time: 0.03913235664367676
Test Loss Energy: 14.373415098547298, Test Loss Force: 8.729421982110088, time: 7.303762912750244


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6850203367003744, Training Loss Force: 2.1895789909321803, time: 0.49854493141174316
Validation Loss Energy: 0.8716515648812218, Validation Loss Force: 2.417594179509316, time: 0.04011034965515137
Test Loss Energy: 13.298815660927842, Test Loss Force: 8.716861954709971, time: 7.474944353103638


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.632258205867334, Training Loss Force: 2.197050445371463, time: 0.465653657913208
Validation Loss Energy: 0.9964638002425463, Validation Loss Force: 2.4709054037582012, time: 0.03937101364135742
Test Loss Energy: 13.649680988071026, Test Loss Force: 8.879777459938166, time: 7.361560821533203


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.222271013996893, Training Loss Force: 2.251407984978652, time: 0.45078206062316895
Validation Loss Energy: 2.963720988239354, Validation Loss Force: 2.5164512642120007, time: 0.042522430419921875
Test Loss Energy: 11.620566865093826, Test Loss Force: 8.81153963047654, time: 7.417048692703247


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.271510771183748, Training Loss Force: 2.2146090452280367, time: 0.45662355422973633
Validation Loss Energy: 1.3336214049171493, Validation Loss Force: 2.4472138519697766, time: 0.03998875617980957
Test Loss Energy: 13.85824400863008, Test Loss Force: 8.791280226291795, time: 7.303911924362183


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9932559278803659, Training Loss Force: 2.2275603595149587, time: 0.4901885986328125
Validation Loss Energy: 1.012653628504664, Validation Loss Force: 2.440172830906394, time: 0.04115772247314453
Test Loss Energy: 12.670046630297756, Test Loss Force: 8.84944697043936, time: 7.536951541900635


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8437911772393112, Training Loss Force: 2.198087735670946, time: 0.49863648414611816
Validation Loss Energy: 1.8473623223868658, Validation Loss Force: 2.472506394917422, time: 0.0394287109375
Test Loss Energy: 14.230156648318932, Test Loss Force: 8.776962185181329, time: 7.354058504104614


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9261575728716753, Training Loss Force: 2.2206197309235414, time: 0.46904993057250977
Validation Loss Energy: 0.8192932532423347, Validation Loss Force: 2.5256100915223025, time: 0.039176225662231445
Test Loss Energy: 13.287291844799922, Test Loss Force: 8.839979847787161, time: 7.311514139175415


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 4.1990404052385895, Training Loss Force: 2.2250418427439156, time: 0.4825453758239746
Validation Loss Energy: 2.9833521681517854, Validation Loss Force: 2.400338879383934, time: 0.04247641563415527
Test Loss Energy: 15.355173953134127, Test Loss Force: 8.771441538554079, time: 7.307399272918701


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9253957991086215, Training Loss Force: 2.230692472430455, time: 0.5319077968597412
Validation Loss Energy: 2.273341090688042, Validation Loss Force: 2.4408279235337136, time: 0.03816676139831543
Test Loss Energy: 11.99176026245681, Test Loss Force: 8.76500641422645, time: 7.487708568572998


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9555289100879345, Training Loss Force: 2.231055586660971, time: 0.4893310070037842
Validation Loss Energy: 1.1011932269962112, Validation Loss Force: 2.3956599326205534, time: 0.04057765007019043
Test Loss Energy: 12.601875111940949, Test Loss Force: 8.719866528589572, time: 7.2688891887664795


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9613276947782399, Training Loss Force: 2.2466208523231987, time: 0.4631979465484619
Validation Loss Energy: 1.89299212910868, Validation Loss Force: 2.3911787160587568, time: 0.04404258728027344
Test Loss Energy: 11.965616055492466, Test Loss Force: 8.756400347332518, time: 7.75761866569519


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6952762322778274, Training Loss Force: 2.2079068952919076, time: 0.47676658630371094
Validation Loss Energy: 2.791553427277134, Validation Loss Force: 2.6461112852166053, time: 0.04069709777832031
Test Loss Energy: 15.197900529658398, Test Loss Force: 8.904383272586857, time: 7.5928795337677


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9930934211543034, Training Loss Force: 2.2392414576589363, time: 0.4939899444580078
Validation Loss Energy: 2.2616587539469406, Validation Loss Force: 2.3972357621662845, time: 0.03937864303588867
Test Loss Energy: 12.1345593753823, Test Loss Force: 8.742918796094232, time: 7.294362306594849


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1236180299208893, Training Loss Force: 2.21955587689079, time: 0.46372342109680176
Validation Loss Energy: 1.0653345877360003, Validation Loss Force: 2.4612226359475313, time: 0.03858041763305664
Test Loss Energy: 13.516101007322751, Test Loss Force: 8.759731487082055, time: 7.310773849487305


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.297142874141317, Training Loss Force: 2.220254188207652, time: 0.49111151695251465
Validation Loss Energy: 0.8383973752863552, Validation Loss Force: 2.5396660813589937, time: 0.03991580009460449
Test Loss Energy: 12.72294859914869, Test Loss Force: 8.860433386824557, time: 7.3061113357543945


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.641482734492506, Training Loss Force: 2.2169061210126597, time: 0.4933350086212158
Validation Loss Energy: 1.7381595838260846, Validation Loss Force: 2.403036738755995, time: 0.04017829895019531
Test Loss Energy: 12.162279865391318, Test Loss Force: 8.748917437600332, time: 7.489392995834351


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6900280962081826, Training Loss Force: 2.1731053395307294, time: 0.49433231353759766
Validation Loss Energy: 1.7045387694824479, Validation Loss Force: 2.3690120025816457, time: 0.04165959358215332
Test Loss Energy: 14.263365823189211, Test Loss Force: 8.775041093718055, time: 7.306879043579102

wandb: - 0.039 MB of 0.058 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–…â–†â–„â–…â–â–…â–ƒâ–†â–„â–ˆâ–‚â–ƒâ–‚â–ˆâ–‚â–…â–ƒâ–‚â–†
wandb:   test_error_force â–„â–‚â–â–â–‡â–…â–„â–†â–ƒâ–†â–ƒâ–ƒâ–â–‚â–ˆâ–‚â–ƒâ–†â–‚â–ƒ
wandb:          test_loss â–â–ƒâ–…â–…â–‡â–…â–‡â–†â–‡â–‡â–‡â–…â–…â–„â–ˆâ–„â–†â–‡â–…â–‡
wandb: train_error_energy â–ˆâ–â–â–â–â–ƒâ–ƒâ–‚â–‚â–‚â–ˆâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–‚â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–‚â–‚â–…â–â–‚â–ˆâ–ƒâ–‚â–„â–â–ˆâ–†â–‚â–„â–‡â–†â–‚â–â–„â–„
wandb:  valid_error_force â–„â–ƒâ–â–‚â–„â–…â–ƒâ–ƒâ–„â–…â–‚â–ƒâ–‚â–‚â–ˆâ–‚â–ƒâ–…â–‚â–
wandb:         valid_loss â–‚â–â–â–â–‚â–†â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–ˆâ–‚â–‚â–„â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1009
wandb:                 lr 0.0001
wandb:    max_uncertainty 6
wandb:  test_error_energy 14.26337
wandb:   test_error_force 8.77504
wandb:          test_loss 6.17496
wandb: train_error_energy 1.69003
wandb:  train_error_force 2.17311
wandb:         train_loss -2.20671
wandb: valid_error_energy 1.70454
wandb:  valid_error_force 2.36901
wandb:         valid_loss -1.98123
wandb: 
wandb: ğŸš€ View run al_67_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/mmc7zi8d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241201_094548-mmc7zi8d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 18.949806213378906, Uncertainty Bias: -2.6170828342437744
0.00022125244 0.02110815
0.45289478 8.14057
(48745, 22, 3)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2432 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
Training model 15. Added 1 samples to the dataset.
Traceback (most recent call last):
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 944, in <module>
    al.improve_model(
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 545, in improve_model
    self.add_data(
  File "/home/ws/fq0795/git/gnn_uncertainty/active_learning.py", line 645, in add_data
    ) = train_test_split(
        ^^^^^^^^^^^^^^^^^
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/model_selection/_split.py", line 2660, in train_test_split
    n_train, n_test = _validate_shuffle_split(
                      ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/sklearn/model_selection/_split.py", line 2308, in _validate_shuffle_split
    raise ValueError(
ValueError: With n_samples=1, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.
