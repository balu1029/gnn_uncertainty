wandb: Currently logged in as: l-baer-99 (l-baer-99-Karlsruhe Institute of Technology). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_132543-u6tj4ymc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/u6tj4ymc
['H1', 'CH3', 'H2', 'H3', 'C', 'O', 'N', 'H', 'CA', 'HA', 'CB', 'HB1', 'HB2', 'HB3', 'C', 'O', 'N', 'H', 'C', 'H1', 'H2', 'H3']
57
Uncertainty Slope: 5.450382232666016, Uncertainty Bias: -0.3942011892795563
0.0002632141 0.0020942688
1.6673818 2.2779717

Training and Validation Results of Epoch Initital validation:
================================
Training Loss Energy: 0.0, Training Loss Force: 0.0, time: 0
Validation Loss Energy: 0.0, Validation Loss Force: 0.0, time: 0
Test Loss Energy: 10.996635071010509, Test Loss Force: 13.386480830105581, time: 6.17837381362915

wandb: - 0.039 MB of 0.047 MB uploadedwandb: \ 0.039 MB of 0.050 MB uploadedwandb: | 0.039 MB of 0.050 MB uploadedwandb: / 0.050 MB of 0.050 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–
wandb:    max_uncertainty â–
wandb:  test_error_energy â–
wandb:   test_error_force â–
wandb:          test_loss â–
wandb: train_error_energy â–
wandb:  train_error_force â–
wandb:         train_loss â–
wandb: valid_error_energy â–
wandb:  valid_error_force â–
wandb:         valid_loss â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 800
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.99664
wandb:   test_error_force 13.38648
wandb:          test_loss 16.63181
wandb: train_error_energy 0.0
wandb:  train_error_force 0.0
wandb:         train_loss 0.0
wandb: valid_error_energy 0.0
wandb:  valid_error_force 0.0
wandb:         valid_loss 0.0
wandb: 
wandb: ğŸš€ View run al_58 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning/runs/u6tj4ymc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/ActiveLearning
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_132543-u6tj4ymc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 2353 steps.
Found uncertainty sample 2 after 139 steps.
Found uncertainty sample 3 after 1645 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2527 steps.
Found uncertainty sample 15 after 377 steps.
Found uncertainty sample 16 after 1228 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 1135 steps.
Found uncertainty sample 19 after 2839 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3053 steps.
Found uncertainty sample 23 after 1794 steps.
Found uncertainty sample 24 after 3692 steps.
Found uncertainty sample 25 after 1008 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 880 steps.
Found uncertainty sample 28 after 3650 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3341 steps.
Found uncertainty sample 31 after 999 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1065 steps.
Found uncertainty sample 34 after 2765 steps.
Found uncertainty sample 35 after 1552 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1837 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1141 steps.
Found uncertainty sample 40 after 284 steps.
Found uncertainty sample 41 after 419 steps.
Found uncertainty sample 42 after 3619 steps.
Found uncertainty sample 43 after 1422 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1766 steps.
Found uncertainty sample 46 after 1356 steps.
Found uncertainty sample 47 after 3867 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 673 steps.
Found uncertainty sample 50 after 3283 steps.
Found uncertainty sample 51 after 615 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3906 steps.
Found uncertainty sample 54 after 704 steps.
Found uncertainty sample 55 after 886 steps.
Found uncertainty sample 56 after 1606 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2078 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 261 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3398 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3337 steps.
Found uncertainty sample 70 after 940 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 777 steps.
Found uncertainty sample 73 after 2428 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1495 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1094 steps.
Found uncertainty sample 78 after 1654 steps.
Found uncertainty sample 79 after 2417 steps.
Found uncertainty sample 80 after 1258 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3188 steps.
Found uncertainty sample 85 after 2413 steps.
Found uncertainty sample 86 after 429 steps.
Found uncertainty sample 87 after 133 steps.
Found uncertainty sample 88 after 1985 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 938 steps.
Found uncertainty sample 92 after 1270 steps.
Found uncertainty sample 93 after 2745 steps.
Found uncertainty sample 94 after 1023 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1018 steps.
Found uncertainty sample 97 after 2879 steps.
Found uncertainty sample 98 after 1833 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_135153-02ooltx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_0
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/02ooltx4
Training model 0. Added 59 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.85488880688919, Training Loss Force: 2.612300064012185, time: 0.5353055000305176
Validation Loss Energy: 1.3477441954976193, Validation Loss Force: 2.1554181830344366, time: 0.03393197059631348
Test Loss Energy: 12.861717316594781, Test Loss Force: 11.848514104497948, time: 6.314912557601929


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8258885594153844, Training Loss Force: 2.069651009214317, time: 0.3872072696685791
Validation Loss Energy: 1.562451917447332, Validation Loss Force: 2.201426527304328, time: 0.03029346466064453
Test Loss Energy: 11.986794148272642, Test Loss Force: 11.631130308029556, time: 6.328512907028198


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9774169976498601, Training Loss Force: 2.0511156501450394, time: 0.3901026248931885
Validation Loss Energy: 5.164201617011781, Validation Loss Force: 2.4980641368178675, time: 0.028211116790771484
Test Loss Energy: 11.419406099072239, Test Loss Force: 11.351786776881193, time: 6.406627416610718


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.141451169108181, Training Loss Force: 2.07620158086628, time: 0.40862393379211426
Validation Loss Energy: 1.0961105810712637, Validation Loss Force: 2.1266831750907476, time: 0.029212236404418945
Test Loss Energy: 13.518377362162223, Test Loss Force: 11.392252345174468, time: 6.547452449798584


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5864659642586063, Training Loss Force: 1.9714887841990139, time: 0.4067575931549072
Validation Loss Energy: 0.980155957333087, Validation Loss Force: 2.1372929145559145, time: 0.031575918197631836
Test Loss Energy: 12.826646464451564, Test Loss Force: 11.165422387264577, time: 6.702491044998169


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7273660742777321, Training Loss Force: 1.9575312141248224, time: 0.3824951648712158
Validation Loss Energy: 1.0151780286120473, Validation Loss Force: 2.1557096569464558, time: 0.03291034698486328
Test Loss Energy: 12.833296050643511, Test Loss Force: 11.137885451243458, time: 6.460845470428467


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.897532216918558, Training Loss Force: 1.9218710390496765, time: 0.3842427730560303
Validation Loss Energy: 2.9791949351973135, Validation Loss Force: 2.1434844528275825, time: 0.030778169631958008
Test Loss Energy: 11.766998469563982, Test Loss Force: 11.068840062577321, time: 6.344213485717773


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.011857030337128, Training Loss Force: 1.9249105677321527, time: 0.39095449447631836
Validation Loss Energy: 0.9794488714601933, Validation Loss Force: 2.150254262871225, time: 0.029646635055541992
Test Loss Energy: 13.357373136965192, Test Loss Force: 11.21645377673996, time: 6.370096683502197


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4350973096920956, Training Loss Force: 1.9191868243480574, time: 0.4005622863769531
Validation Loss Energy: 1.4380075871823665, Validation Loss Force: 2.1321448039020643, time: 0.028805017471313477
Test Loss Energy: 12.397974732002115, Test Loss Force: 11.096164360056346, time: 6.655284881591797


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4470681266822543, Training Loss Force: 1.888636959777489, time: 0.38570404052734375
Validation Loss Energy: 1.0055902291921155, Validation Loss Force: 2.1528096139898927, time: 0.029193401336669922
Test Loss Energy: 13.218500103104558, Test Loss Force: 11.225456315957574, time: 6.358649015426636


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4665673421377023, Training Loss Force: 1.8999148881145589, time: 0.3780984878540039
Validation Loss Energy: 1.1520379451156542, Validation Loss Force: 2.1298742466210383, time: 0.03407907485961914
Test Loss Energy: 12.343129045704742, Test Loss Force: 11.091803043251884, time: 6.356672763824463


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6337382466385786, Training Loss Force: 1.8986986609924958, time: 0.40291666984558105
Validation Loss Energy: 1.0694543009393833, Validation Loss Force: 2.1696051023289336, time: 0.03207087516784668
Test Loss Energy: 13.440142928467134, Test Loss Force: 11.226011664465588, time: 6.373997926712036


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.510039140523001, Training Loss Force: 1.854358430258814, time: 0.3761632442474365
Validation Loss Energy: 1.7997453048722192, Validation Loss Force: 2.10561422050306, time: 0.03165864944458008
Test Loss Energy: 12.136119243863751, Test Loss Force: 11.002503375288786, time: 6.570311784744263


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.638376063524254, Training Loss Force: 1.8900830680517062, time: 0.3894224166870117
Validation Loss Energy: 3.820075349797196, Validation Loss Force: 2.1569412399925825, time: 0.029668092727661133
Test Loss Energy: 15.819802583724915, Test Loss Force: 11.430257925365506, time: 6.387003660202026


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.032398017824058, Training Loss Force: 1.891758331741602, time: 0.4114408493041992
Validation Loss Energy: 1.7750570859866215, Validation Loss Force: 2.1294667620839904, time: 0.029890775680541992
Test Loss Energy: 12.207603999837088, Test Loss Force: 11.017313037230862, time: 6.387246370315552


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6249030400673634, Training Loss Force: 1.8691007977378282, time: 0.37237024307250977
Validation Loss Energy: 2.968975534744958, Validation Loss Force: 2.092782910968971, time: 0.029196977615356445
Test Loss Energy: 11.741194487064927, Test Loss Force: 10.978715795973919, time: 6.730870246887207


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9749137779141077, Training Loss Force: 1.8422024308857952, time: 0.37937355041503906
Validation Loss Energy: 0.7836619035128295, Validation Loss Force: 2.183294801420574, time: 0.03176236152648926
Test Loss Energy: 13.236804826593401, Test Loss Force: 11.144115099747482, time: 6.476093053817749


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.502656182121527, Training Loss Force: 1.887764921425993, time: 0.38983845710754395
Validation Loss Energy: 1.1358245139240684, Validation Loss Force: 2.1352267675508507, time: 0.03360772132873535
Test Loss Energy: 13.535347068706326, Test Loss Force: 11.165854752455619, time: 6.641990661621094


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3770002925395577, Training Loss Force: 1.9061873460032577, time: 0.4064655303955078
Validation Loss Energy: 0.804859783536009, Validation Loss Force: 2.153495212290204, time: 0.030801057815551758
Test Loss Energy: 13.11304330543539, Test Loss Force: 11.10467098360919, time: 6.448104619979858


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3238237460124347, Training Loss Force: 1.85719101683467, time: 0.3971266746520996
Validation Loss Energy: 0.9717044385648248, Validation Loss Force: 2.085895976954571, time: 0.030419349670410156
Test Loss Energy: 13.012518696965325, Test Loss Force: 11.153623603886613, time: 6.354418992996216

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–„â–‚â–„â–‚â–ˆâ–‚â–‚â–„â–„â–„â–„
wandb:   test_error_force â–ˆâ–†â–„â–„â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–…â–â–â–‚â–ƒâ–‚â–‚
wandb:          test_loss â–ˆâ–‡â–†â–…â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–â–â–‚â–‚â–â–
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–â–â–â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–â–
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–â–â–â–â–â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–‚â–‚â–ˆâ–â–â–â–…â–â–‚â–â–‚â–â–ƒâ–†â–ƒâ–„â–â–‚â–â–
wandb:  valid_error_force â–‚â–ƒâ–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–ƒâ–‚â–‚â–
wandb:         valid_loss â–ƒâ–ƒâ–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 853
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.01252
wandb:   test_error_force 11.15362
wandb:          test_loss 9.94878
wandb: train_error_energy 1.32382
wandb:  train_error_force 1.85719
wandb:         train_loss -2.62251
wandb: valid_error_energy 0.9717
wandb:  valid_error_force 2.0859
wandb:         valid_loss -2.33795
wandb: 
wandb: ğŸš€ View run al_58_0 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/02ooltx4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_135153-02ooltx4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 6.046326160430908, Uncertainty Bias: -0.6125303506851196
0.000102996826 0.003396988
1.1104358 3.7672029
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1705 steps.
Found uncertainty sample 3 after 2389 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 425 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1578 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1682 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 348 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2267 steps.
Found uncertainty sample 24 after 3430 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1307 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1342 steps.
Found uncertainty sample 30 after 2280 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1915 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 788 steps.
Found uncertainty sample 37 after 729 steps.
Found uncertainty sample 38 after 1811 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1369 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2822 steps.
Found uncertainty sample 43 after 1141 steps.
Found uncertainty sample 44 after 897 steps.
Found uncertainty sample 45 after 3564 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 465 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 361 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1099 steps.
Found uncertainty sample 54 after 3003 steps.
Found uncertainty sample 55 after 921 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2307 steps.
Found uncertainty sample 62 after 3586 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2524 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3641 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1107 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3084 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1151 steps.
Found uncertainty sample 75 after 735 steps.
Found uncertainty sample 76 after 1291 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2839 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1934 steps.
Found uncertainty sample 82 after 3533 steps.
Found uncertainty sample 83 after 299 steps.
Found uncertainty sample 84 after 3223 steps.
Found uncertainty sample 85 after 2951 steps.
Found uncertainty sample 86 after 3702 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 767 steps.
Found uncertainty sample 90 after 1906 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 600 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 672 steps.
Found uncertainty sample 95 after 2672 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 999 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_142259-8cnmy36e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_1
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8cnmy36e
Training model 1. Added 47 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.053431114697455, Training Loss Force: 2.5797184474562007, time: 0.400435209274292
Validation Loss Energy: 1.0898484566803364, Validation Loss Force: 2.2917950188259533, time: 0.035752058029174805
Test Loss Energy: 13.47071203068904, Test Loss Force: 11.13078596145926, time: 6.971431732177734


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.827052184486153, Training Loss Force: 2.0771573024652263, time: 0.43409037590026855
Validation Loss Energy: 5.289090060888299, Validation Loss Force: 2.28890700000327, time: 0.03363966941833496
Test Loss Energy: 11.15721313310999, Test Loss Force: 10.781044327749056, time: 7.2273945808410645


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0053351785869507, Training Loss Force: 2.1102438540030874, time: 0.4467902183532715
Validation Loss Energy: 0.8554459827770298, Validation Loss Force: 2.2588186089906315, time: 0.03702259063720703
Test Loss Energy: 12.775235581466326, Test Loss Force: 10.982234751901913, time: 6.969205141067505


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7131514957420682, Training Loss Force: 2.082726504331435, time: 0.41726207733154297
Validation Loss Energy: 1.2634935387603599, Validation Loss Force: 2.222434470546031, time: 0.033296823501586914
Test Loss Energy: 12.689264553762452, Test Loss Force: 10.933957236495575, time: 7.2549285888671875


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6882125086536328, Training Loss Force: 2.0974702754213146, time: 0.3999338150024414
Validation Loss Energy: 2.1223970167007833, Validation Loss Force: 2.240054725401589, time: 0.034111738204956055
Test Loss Energy: 13.894095615742184, Test Loss Force: 10.988572517351452, time: 7.054736137390137


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8519246561256535, Training Loss Force: 2.0432748200652466, time: 0.4122309684753418
Validation Loss Energy: 1.2206527744258642, Validation Loss Force: 2.242193907886517, time: 0.03434038162231445
Test Loss Energy: 13.446399245973161, Test Loss Force: 10.99472611326698, time: 6.978326320648193


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6151141168031238, Training Loss Force: 2.01451001421835, time: 0.40915417671203613
Validation Loss Energy: 1.2467036171499668, Validation Loss Force: 2.2127105089433643, time: 0.03618311882019043
Test Loss Energy: 13.586283967188956, Test Loss Force: 10.96762413052854, time: 7.095927953720093


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.54897830683311, Training Loss Force: 2.0152545721275157, time: 0.42359471321105957
Validation Loss Energy: 1.3396635321918997, Validation Loss Force: 2.240494942303088, time: 0.03534364700317383
Test Loss Energy: 13.299538633836264, Test Loss Force: 11.076606435961311, time: 7.164470672607422


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5966265179093604, Training Loss Force: 1.9950472000138837, time: 0.4411745071411133
Validation Loss Energy: 1.0387284081619539, Validation Loss Force: 2.20347909149149, time: 0.033393144607543945
Test Loss Energy: 12.585587528426347, Test Loss Force: 10.855690906319687, time: 7.004833936691284


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0305147408004456, Training Loss Force: 2.1727243908933063, time: 0.4183964729309082
Validation Loss Energy: 1.1548441330272092, Validation Loss Force: 2.2268889668103165, time: 0.03327369689941406
Test Loss Energy: 13.427695601965837, Test Loss Force: 10.85279457995599, time: 6.994299411773682


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.656253603373684, Training Loss Force: 2.0395303123252218, time: 0.40407848358154297
Validation Loss Energy: 0.852332567111381, Validation Loss Force: 2.2311900440330574, time: 0.033686161041259766
Test Loss Energy: 12.940871632671715, Test Loss Force: 10.89972423122394, time: 6.983925104141235


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4226093397815525, Training Loss Force: 2.007132786602025, time: 0.4147489070892334
Validation Loss Energy: 0.9677884676299658, Validation Loss Force: 2.2433736090216425, time: 0.0358424186706543
Test Loss Energy: 12.938280262778532, Test Loss Force: 10.768111871629786, time: 7.215773344039917


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5192417966907936, Training Loss Force: 2.005349640152731, time: 0.39194226264953613
Validation Loss Energy: 1.484190949400957, Validation Loss Force: 2.2155880623161894, time: 0.03542280197143555
Test Loss Energy: 12.335020881010792, Test Loss Force: 10.744321886089178, time: 7.345494031906128


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9816185944126652, Training Loss Force: 2.0145932527165797, time: 0.42012977600097656
Validation Loss Energy: 1.9819573596726683, Validation Loss Force: 2.202292487612841, time: 0.03409910202026367
Test Loss Energy: 12.356318277820906, Test Loss Force: 10.706152510008074, time: 7.267428398132324


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.10758557009548, Training Loss Force: 2.0606910543158476, time: 0.4082345962524414
Validation Loss Energy: 1.002258987434463, Validation Loss Force: 2.276636816716919, time: 0.036214351654052734
Test Loss Energy: 13.365370783151112, Test Loss Force: 10.798467491265296, time: 7.64703106880188


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.409893454377867, Training Loss Force: 2.013940923572411, time: 0.4141523838043213
Validation Loss Energy: 1.7743414273516096, Validation Loss Force: 2.2023944700816758, time: 0.03273129463195801
Test Loss Energy: 12.17182709764054, Test Loss Force: 10.662988219645518, time: 7.023277759552002


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3213497007210073, Training Loss Force: 2.0044231297414647, time: 0.38799238204956055
Validation Loss Energy: 0.7994401278586996, Validation Loss Force: 2.2501578925597703, time: 0.033669233322143555
Test Loss Energy: 12.947875358401864, Test Loss Force: 10.797695428553745, time: 7.58447527885437


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8442658176476032, Training Loss Force: 2.077729216237837, time: 0.4067699909210205
Validation Loss Energy: 1.594104670544686, Validation Loss Force: 2.2468942308879067, time: 0.04192829132080078
Test Loss Energy: 12.046854172390573, Test Loss Force: 10.73746124218949, time: 8.262439250946045


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2595532322772773, Training Loss Force: 2.011049982217187, time: 0.44643330574035645
Validation Loss Energy: 0.7677598194545371, Validation Loss Force: 2.205570400110044, time: 0.04166412353515625
Test Loss Energy: 12.678371938212239, Test Loss Force: 10.745463989947046, time: 9.19899868965149


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9322607932537372, Training Loss Force: 2.0412858279192467, time: 0.5139894485473633
Validation Loss Energy: 2.1829169318799346, Validation Loss Force: 2.181756157622213, time: 0.0404813289642334
Test Loss Energy: 14.26270854583948, Test Loss Force: 10.796089072350496, time: 7.441062688827515

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.039 MB of 0.039 MB uploadedwandb: - 0.045 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: \ 0.045 MB of 0.046 MB uploaded (0.003 MB deduped)wandb: | 0.064 MB of 0.064 MB uploaded (0.003 MB deduped)wandb:                                                                                
wandb: W&B sync reduced upload amount by 4.7%             
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–…â–„â–‡â–†â–†â–†â–„â–†â–…â–…â–„â–„â–†â–ƒâ–…â–ƒâ–„â–ˆ
wandb:   test_error_force â–ˆâ–ƒâ–†â–…â–†â–†â–†â–‡â–„â–„â–…â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–‚â–ƒ
wandb:          test_loss â–ˆâ–â–„â–„â–…â–†â–‡â–ˆâ–†â–„â–ƒâ–„â–ƒâ–ƒâ–‚â–â–„â–‚â–ƒâ–…
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–â–â–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–ƒâ–‚â–â–â–â–‚â–â–â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–â–â–ƒâ–â–â–â–â–‚â–â–â–‚â–â–‚
wandb: valid_error_energy â–â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–â–â–‚â–ƒâ–â–ƒâ–â–‚â–â–ƒ
wandb:  valid_error_force â–ˆâ–ˆâ–†â–„â–…â–…â–ƒâ–…â–‚â–„â–„â–…â–ƒâ–‚â–‡â–‚â–…â–…â–ƒâ–
wandb:         valid_loss â–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 895
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.26271
wandb:   test_error_force 10.79609
wandb:          test_loss 8.95041
wandb: train_error_energy 1.93226
wandb:  train_error_force 2.04129
wandb:         train_loss -2.3467
wandb: valid_error_energy 2.18292
wandb:  valid_error_force 2.18176
wandb:         valid_loss -2.15357
wandb: 
wandb: ğŸš€ View run al_58_1 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8cnmy36e
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_142259-8cnmy36e/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 7.42802619934082, Uncertainty Bias: -0.8541890382766724
0.00022125244 0.07767987
0.8259769 4.610438
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 151 steps.
Found uncertainty sample 1 after 2332 steps.
Found uncertainty sample 2 after 1333 steps.
Found uncertainty sample 3 after 535 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3968 steps.
Found uncertainty sample 6 after 3226 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2812 steps.
Found uncertainty sample 9 after 249 steps.
Found uncertainty sample 10 after 3028 steps.
Found uncertainty sample 11 after 816 steps.
Found uncertainty sample 12 after 3295 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1895 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3724 steps.
Found uncertainty sample 17 after 1239 steps.
Found uncertainty sample 18 after 489 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2494 steps.
Found uncertainty sample 21 after 556 steps.
Found uncertainty sample 22 after 1124 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1426 steps.
Found uncertainty sample 25 after 419 steps.
Found uncertainty sample 26 after 88 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 389 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 359 steps.
Found uncertainty sample 31 after 971 steps.
Found uncertainty sample 32 after 2771 steps.
Found uncertainty sample 33 after 3001 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3020 steps.
Found uncertainty sample 36 after 2633 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 470 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1625 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2195 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 592 steps.
Found uncertainty sample 45 after 2054 steps.
Found uncertainty sample 46 after 3546 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 267 steps.
Found uncertainty sample 50 after 770 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 222 steps.
Found uncertainty sample 53 after 1264 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1248 steps.
Found uncertainty sample 59 after 627 steps.
Found uncertainty sample 60 after 579 steps.
Found uncertainty sample 61 after 2308 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 601 steps.
Found uncertainty sample 64 after 859 steps.
Found uncertainty sample 65 after 1956 steps.
Found uncertainty sample 66 after 1231 steps.
Found uncertainty sample 67 after 944 steps.
Found uncertainty sample 68 after 1429 steps.
Found uncertainty sample 69 after 3311 steps.
Found uncertainty sample 70 after 821 steps.
Found uncertainty sample 71 after 202 steps.
Found uncertainty sample 72 after 2033 steps.
Found uncertainty sample 73 after 2103 steps.
Found uncertainty sample 74 after 3187 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 120 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3385 steps.
Found uncertainty sample 79 after 700 steps.
Found uncertainty sample 80 after 1229 steps.
Found uncertainty sample 81 after 3079 steps.
Found uncertainty sample 82 after 514 steps.
Found uncertainty sample 83 after 948 steps.
Found uncertainty sample 84 after 735 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2179 steps.
Found uncertainty sample 88 after 1722 steps.
Found uncertainty sample 89 after 140 steps.
Found uncertainty sample 90 after 410 steps.
Found uncertainty sample 91 after 1033 steps.
Found uncertainty sample 92 after 564 steps.
Found uncertainty sample 93 after 676 steps.
Found uncertainty sample 94 after 743 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1427 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_144917-w1txa2vx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_2
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w1txa2vx
Training model 2. Added 71 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.8648412385422, Training Loss Force: 2.41318237634261, time: 0.4704756736755371
Validation Loss Energy: 1.8615418935995474, Validation Loss Force: 2.2192097759747047, time: 0.04483962059020996
Test Loss Energy: 14.21708196373996, Test Loss Force: 10.783024749464552, time: 7.939977407455444


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6626382033497176, Training Loss Force: 2.0791084869807417, time: 0.4498453140258789
Validation Loss Energy: 2.0850582956275905, Validation Loss Force: 2.2707147081118237, time: 0.04103994369506836
Test Loss Energy: 14.180254827944056, Test Loss Force: 10.774238229629471, time: 7.954150199890137


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9365901448190705, Training Loss Force: 2.1198975444042865, time: 0.47474169731140137
Validation Loss Energy: 2.3532016025441886, Validation Loss Force: 2.3240390698403184, time: 0.03774118423461914
Test Loss Energy: 11.860839030585794, Test Loss Force: 10.488815322505408, time: 7.935415029525757


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1027226872190234, Training Loss Force: 2.080091207567074, time: 0.4324779510498047
Validation Loss Energy: 2.2686069219764713, Validation Loss Force: 2.2995750787846703, time: 0.03837299346923828
Test Loss Energy: 11.918923063055004, Test Loss Force: 10.541302464566515, time: 8.089627981185913


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0950793832274304, Training Loss Force: 2.0745939628258663, time: 0.433394193649292
Validation Loss Energy: 2.4289137882117013, Validation Loss Force: 2.288270388915062, time: 0.03813648223876953
Test Loss Energy: 11.730083422590296, Test Loss Force: 10.485555684033663, time: 7.917120933532715


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0820043994246484, Training Loss Force: 2.0856916223458954, time: 0.45056986808776855
Validation Loss Energy: 3.2271826763628204, Validation Loss Force: 2.3103097356407027, time: 0.03975486755371094
Test Loss Energy: 11.503963483140918, Test Loss Force: 10.493677801106353, time: 7.889836311340332


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0470505576831526, Training Loss Force: 2.0823278708929376, time: 0.4348139762878418
Validation Loss Energy: 2.441313787610128, Validation Loss Force: 2.321561875591872, time: 0.04131484031677246
Test Loss Energy: 11.93473948332005, Test Loss Force: 10.55126574537135, time: 8.13042402267456


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1306007956328625, Training Loss Force: 2.0826969450023127, time: 0.469207763671875
Validation Loss Energy: 2.7476953989494675, Validation Loss Force: 2.262348360291879, time: 0.038849830627441406
Test Loss Energy: 11.728412653216095, Test Loss Force: 10.467026360822425, time: 7.901511192321777


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8608344737229348, Training Loss Force: 2.1045286453270706, time: 0.4752533435821533
Validation Loss Energy: 1.2521727053776723, Validation Loss Force: 2.368048958525508, time: 0.037868499755859375
Test Loss Energy: 13.522061321756384, Test Loss Force: 10.581393333148515, time: 8.283756017684937


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.088041611278002, Training Loss Force: 2.1116724207789943, time: 0.46418094635009766
Validation Loss Energy: 4.334812934364085, Validation Loss Force: 2.376672489208999, time: 0.04374051094055176
Test Loss Energy: 15.827374453861221, Test Loss Force: 10.911479031033643, time: 7.916281700134277


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.023020879085484, Training Loss Force: 2.1325788640016787, time: 0.43755650520324707
Validation Loss Energy: 1.019566726143711, Validation Loss Force: 2.2397006814595635, time: 0.040703773498535156
Test Loss Energy: 12.987235475810825, Test Loss Force: 10.564704460195511, time: 8.120308876037598


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.765206007806418, Training Loss Force: 2.108426524393823, time: 0.4344770908355713
Validation Loss Energy: 1.410350409239541, Validation Loss Force: 2.376424435780436, time: 0.04022336006164551
Test Loss Energy: 12.523312400971184, Test Loss Force: 10.654558725886888, time: 7.950348854064941


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7257611097113077, Training Loss Force: 2.084847765661268, time: 0.43462085723876953
Validation Loss Energy: 2.324003665446116, Validation Loss Force: 2.2882472313238855, time: 0.041876792907714844
Test Loss Energy: 11.755548416379517, Test Loss Force: 10.52504341068196, time: 7.955726623535156


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.064053722112296, Training Loss Force: 2.120106074059448, time: 0.47193074226379395
Validation Loss Energy: 2.1836508493849127, Validation Loss Force: 2.2651994160363382, time: 0.03953099250793457
Test Loss Energy: 14.239817276287981, Test Loss Force: 10.643861872655963, time: 8.060180187225342


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.707557617561821, Training Loss Force: 2.0779972269187694, time: 0.4476180076599121
Validation Loss Energy: 0.8492347382859471, Validation Loss Force: 2.3257119831336737, time: 0.038223981857299805
Test Loss Energy: 12.333045835997398, Test Loss Force: 10.599360154459697, time: 7.9144909381866455


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8147805416565672, Training Loss Force: 2.054048533089475, time: 0.4278097152709961
Validation Loss Energy: 0.7848258508058805, Validation Loss Force: 2.2085597333941247, time: 0.03856635093688965
Test Loss Energy: 12.501726378315666, Test Loss Force: 10.56037097353687, time: 7.953619480133057


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5940734300635124, Training Loss Force: 2.077470350896827, time: 0.45012974739074707
Validation Loss Energy: 2.1390315152473187, Validation Loss Force: 2.257460327200472, time: 0.039231061935424805
Test Loss Energy: 14.225078294895532, Test Loss Force: 10.612449831317294, time: 7.970327854156494


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2332127185985313, Training Loss Force: 2.1553717231171388, time: 0.44924187660217285
Validation Loss Energy: 2.8433219996830315, Validation Loss Force: 2.216353153501597, time: 0.038995981216430664
Test Loss Energy: 14.374327743598998, Test Loss Force: 10.501583376514947, time: 8.1060311794281


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.888773027532012, Training Loss Force: 2.046091354669782, time: 0.4553055763244629
Validation Loss Energy: 1.69462431442544, Validation Loss Force: 2.1990250405654965, time: 0.04084300994873047
Test Loss Energy: 13.682512674619565, Test Loss Force: 10.553346211984369, time: 7.947545289993286


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5989898534710247, Training Loss Force: 2.079461165218672, time: 0.43318819999694824
Validation Loss Energy: 2.828402276229286, Validation Loss Force: 2.2520113905304733, time: 0.04018664360046387
Test Loss Energy: 14.435532576247146, Test Loss Force: 10.68875781549992, time: 8.229248762130737

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–…â–‚â–‚â–â–â–‚â–â–„â–ˆâ–ƒâ–ƒâ–â–…â–‚â–ƒâ–…â–†â–…â–†
wandb:   test_error_force â–†â–†â–â–‚â–â–â–‚â–â–ƒâ–ˆâ–ƒâ–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–‚â–„
wandb:          test_loss â–„â–„â–â–‚â–‚â–â–ƒâ–‚â–„â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–†
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–‚â–â–â–â–‚â–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–‚
wandb:         train_loss â–ˆâ–â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–â–â–ƒâ–â–
wandb: valid_error_energy â–ƒâ–„â–„â–„â–„â–†â–„â–…â–‚â–ˆâ–â–‚â–„â–„â–â–â–„â–…â–ƒâ–…
wandb:  valid_error_force â–‚â–„â–†â–…â–…â–…â–†â–ƒâ–ˆâ–ˆâ–ƒâ–ˆâ–…â–„â–†â–â–ƒâ–‚â–â–ƒ
wandb:         valid_loss â–‚â–„â–…â–„â–„â–†â–…â–„â–…â–ˆâ–‚â–…â–„â–„â–ƒâ–â–ƒâ–ƒâ–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 958
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.43553
wandb:   test_error_force 10.68876
wandb:          test_loss 8.72288
wandb: train_error_energy 1.59899
wandb:  train_error_force 2.07946
wandb:         train_loss -2.3226
wandb: valid_error_energy 2.8284
wandb:  valid_error_force 2.25201
wandb:         valid_loss -2.02758
wandb: 
wandb: ğŸš€ View run al_58_2 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w1txa2vx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_144917-w1txa2vx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 6.4497971534729, Uncertainty Bias: -0.7316740155220032
9.1552734e-05 0.13440514
1.1855351 4.2180405
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2056 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 184 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1149 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 453 steps.
Found uncertainty sample 9 after 2630 steps.
Found uncertainty sample 10 after 2407 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3999 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1172 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 549 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1012 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1145 steps.
Found uncertainty sample 30 after 1071 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 579 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2244 steps.
Found uncertainty sample 39 after 2299 steps.
Found uncertainty sample 40 after 901 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1581 steps.
Found uncertainty sample 44 after 809 steps.
Found uncertainty sample 45 after 2450 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 812 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 404 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 613 steps.
Found uncertainty sample 60 after 629 steps.
Found uncertainty sample 61 after 3124 steps.
Found uncertainty sample 62 after 1977 steps.
Found uncertainty sample 63 after 1994 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1028 steps.
Found uncertainty sample 71 after 956 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 270 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3872 steps.
Found uncertainty sample 77 after 4 steps.
Found uncertainty sample 78 after 5 steps.
Found uncertainty sample 79 after 6 steps.
Found uncertainty sample 80 after 4 steps.
Found uncertainty sample 81 after 4 steps.
Found uncertainty sample 82 after 4 steps.
Found uncertainty sample 83 after 4 steps.
Found uncertainty sample 84 after 3 steps.
Found uncertainty sample 85 after 3 steps.
Found uncertainty sample 86 after 3 steps.
Found uncertainty sample 87 after 3 steps.
Found uncertainty sample 88 after 3 steps.
Found uncertainty sample 89 after 3 steps.
Found uncertainty sample 90 after 2 steps.
Found uncertainty sample 91 after 2 steps.
Found uncertainty sample 92 after 2 steps.
Found uncertainty sample 93 after 2 steps.
Found uncertainty sample 94 after 2 steps.
Found uncertainty sample 95 after 2 steps.
Found uncertainty sample 96 after 3 steps.
Found uncertainty sample 97 after 2 steps.
Found uncertainty sample 98 after 2 steps.
Found uncertainty sample 99 after 2 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_151613-wl3uknjc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_3
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wl3uknjc
Training model 3. Added 53 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 13.487086294963161, Training Loss Force: 9.179153621537322, time: 0.5295553207397461
Validation Loss Energy: 6.085230677342641, Validation Loss Force: 6.418859866730871, time: 0.04079604148864746
Test Loss Energy: 14.270129952255115, Test Loss Force: 10.731838219050621, time: 7.2328760623931885


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 11.96332251536381, Training Loss Force: 8.309496977368113, time: 0.478008508682251
Validation Loss Energy: 11.79520416846585, Validation Loss Force: 5.9100377106947, time: 0.03876376152038574
Test Loss Energy: 22.38750107575082, Test Loss Force: 11.298570893498395, time: 8.027793407440186


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 11.035950988830809, Training Loss Force: 7.324531797904455, time: 0.5044329166412354
Validation Loss Energy: 6.825229722034209, Validation Loss Force: 5.326956285168195, time: 0.042942047119140625
Test Loss Energy: 17.542234655228757, Test Loss Force: 10.618177660509664, time: 9.4277982711792


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 8.404507734390531, Training Loss Force: 6.5483309251315145, time: 0.5151576995849609
Validation Loss Energy: 4.593612821248408, Validation Loss Force: 4.9393151317288435, time: 0.04624152183532715
Test Loss Energy: 12.909743679857426, Test Loss Force: 10.40655720837951, time: 9.357923030853271


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 5.652273899867174, Training Loss Force: 5.8591016286413184, time: 0.4662768840789795
Validation Loss Energy: 6.009514260961356, Validation Loss Force: 4.330072308247283, time: 0.040601253509521484
Test Loss Energy: 18.631608071768206, Test Loss Force: 10.123725964932008, time: 8.033662557601929


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 4.89666928987717, Training Loss Force: 5.174349206664575, time: 0.47679638862609863
Validation Loss Energy: 3.49293585266703, Validation Loss Force: 4.013796616077788, time: 0.04274296760559082
Test Loss Energy: 16.368485692540556, Test Loss Force: 10.284801537520297, time: 8.425964593887329


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.74801636111791, Training Loss Force: 4.665385133839928, time: 0.46575188636779785
Validation Loss Energy: 2.0313950314589935, Validation Loss Force: 3.745014916719814, time: 0.04719281196594238
Test Loss Energy: 15.158784424990776, Test Loss Force: 10.098881614171868, time: 8.15765905380249


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 4.983600121185416, Training Loss Force: 4.373029723380601, time: 0.46362853050231934
Validation Loss Energy: 2.1920410228034717, Validation Loss Force: 3.511354599079885, time: 0.0420384407043457
Test Loss Energy: 14.877346927183794, Test Loss Force: 10.070200583094442, time: 8.070493459701538


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 4.56084719559335, Training Loss Force: 4.142981537667501, time: 0.46312808990478516
Validation Loss Energy: 1.593000565584603, Validation Loss Force: 3.5521048341378374, time: 0.042925119400024414
Test Loss Energy: 14.612028213357503, Test Loss Force: 10.059799154695614, time: 8.034846782684326


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.435923324456782, Training Loss Force: 4.101436993057149, time: 0.5190815925598145
Validation Loss Energy: 3.4047020902474148, Validation Loss Force: 3.49627900722399, time: 0.04152846336364746
Test Loss Energy: 12.535816157196773, Test Loss Force: 10.173546822339105, time: 8.189171552658081


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 3.2248625508423885, Training Loss Force: 3.920633000517796, time: 0.5544633865356445
Validation Loss Energy: 1.4018165028872853, Validation Loss Force: 3.3842864469338796, time: 0.041687965393066406
Test Loss Energy: 13.800826365458466, Test Loss Force: 10.072181909476205, time: 8.13726806640625


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 3.009491953282865, Training Loss Force: 3.8422156456676664, time: 0.4569993019104004
Validation Loss Energy: 1.4541188132359717, Validation Loss Force: 3.2478100780341332, time: 0.04400205612182617
Test Loss Energy: 13.66131652581985, Test Loss Force: 9.970000344113837, time: 8.092110395431519


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.969023159848146, Training Loss Force: 3.7755492514060487, time: 0.4720466136932373
Validation Loss Energy: 2.335775960522172, Validation Loss Force: 3.301077881799562, time: 0.0450747013092041
Test Loss Energy: 14.849635222696683, Test Loss Force: 10.179689837389875, time: 8.064568281173706


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1631914674916386, Training Loss Force: 3.957563993509563, time: 0.4842708110809326
Validation Loss Energy: 2.0296216943808245, Validation Loss Force: 3.3956830991607556, time: 0.04421067237854004
Test Loss Energy: 13.22320245111279, Test Loss Force: 9.95033797303387, time: 8.325943946838379


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.4324190061470463, Training Loss Force: 3.675031813341521, time: 0.4826030731201172
Validation Loss Energy: 2.4629452044604285, Validation Loss Force: 3.2487991743803444, time: 0.04162883758544922
Test Loss Energy: 15.193055393603082, Test Loss Force: 10.088835952777881, time: 8.083529710769653


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.25089166244953, Training Loss Force: 3.5784712477505956, time: 0.4588892459869385
Validation Loss Energy: 1.1699498965523774, Validation Loss Force: 3.164407345404567, time: 0.040578365325927734
Test Loss Energy: 13.63779580906444, Test Loss Force: 10.04386703973925, time: 8.013556003570557


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.6467884397364108, Training Loss Force: 3.6188898205948945, time: 0.529789924621582
Validation Loss Energy: 4.447864731781374, Validation Loss Force: 3.1214978876385526, time: 0.04327869415283203
Test Loss Energy: 17.07334401127775, Test Loss Force: 9.963692521252483, time: 8.472782611846924


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 3.291239753550732, Training Loss Force: 3.541039997209653, time: 0.5973284244537354
Validation Loss Energy: 2.619439529579083, Validation Loss Force: 3.1983795316604775, time: 0.0430755615234375
Test Loss Energy: 15.444350474567266, Test Loss Force: 10.135740846967385, time: 8.063847541809082


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.3775588605270332, Training Loss Force: 3.4786204393585107, time: 0.47159790992736816
Validation Loss Energy: 1.7643147470450544, Validation Loss Force: 3.176839631829153, time: 0.0428919792175293
Test Loss Energy: 12.797549664612214, Test Loss Force: 10.016063679502125, time: 8.630288124084473


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 3.3435303807276675, Training Loss Force: 3.4484539819349926, time: 0.48359107971191406
Validation Loss Energy: 2.281675151481827, Validation Loss Force: 3.093028523985955, time: 0.04635429382324219
Test Loss Energy: 12.526608086196815, Test Loss Force: 10.02613781456742, time: 9.212379693984985

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–…â–â–…â–„â–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–â–ƒâ–‚â–„â–ƒâ–â–
wandb:   test_error_force â–…â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–â–‚â–â–
wandb:          test_loss â–…â–„â–‚â–â–„â–…â–†â–…â–…â–‡â–…â–†â–ˆâ–…â–‡â–†â–ˆâ–‡â–‡â–‡
wandb: train_error_energy â–ˆâ–‡â–†â–…â–ƒâ–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–â–
wandb:  train_error_force â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         train_loss â–ˆâ–…â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–â–â–â–â–
wandb: valid_error_energy â–„â–ˆâ–…â–ƒâ–„â–ƒâ–‚â–‚â–â–‚â–â–â–‚â–‚â–‚â–â–ƒâ–‚â–â–‚
wandb:  valid_error_force â–ˆâ–‡â–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–â–â–â–
wandb:         valid_loss â–ˆâ–ˆâ–†â–…â–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1005
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.52661
wandb:   test_error_force 10.02614
wandb:          test_loss 4.67738
wandb: train_error_energy 3.34353
wandb:  train_error_force 3.44845
wandb:         train_loss -0.92588
wandb: valid_error_energy 2.28168
wandb:  valid_error_force 3.09303
wandb:         valid_loss -1.2559
wandb: 
wandb: ğŸš€ View run al_58_3 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wl3uknjc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_151613-wl3uknjc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 2.9278852939605713, Uncertainty Bias: -0.4748513996601105
0.00019741058 0.111019135
0.9394344 80.4594
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3 steps.
Found uncertainty sample 1 after 3 steps.
Found uncertainty sample 2 after 5 steps.
Found uncertainty sample 3 after 6 steps.
Found uncertainty sample 4 after 6 steps.
Found uncertainty sample 5 after 8 steps.
Found uncertainty sample 6 after 1077 steps.
Found uncertainty sample 7 after 2800 steps.
Found uncertainty sample 8 after 1005 steps.
Found uncertainty sample 9 after 600 steps.
Found uncertainty sample 10 after 1370 steps.
Found uncertainty sample 11 after 90 steps.
Found uncertainty sample 12 after 1677 steps.
Found uncertainty sample 13 after 2019 steps.
Found uncertainty sample 14 after 359 steps.
Found uncertainty sample 15 after 1589 steps.
Found uncertainty sample 16 after 302 steps.
Found uncertainty sample 17 after 384 steps.
Found uncertainty sample 18 after 59 steps.
Found uncertainty sample 19 after 158 steps.
Found uncertainty sample 20 after 3588 steps.
Found uncertainty sample 21 after 53 steps.
Found uncertainty sample 22 after 248 steps.
Found uncertainty sample 23 after 2152 steps.
Found uncertainty sample 24 after 2043 steps.
Found uncertainty sample 25 after 645 steps.
Found uncertainty sample 26 after 407 steps.
Found uncertainty sample 27 after 1565 steps.
Found uncertainty sample 28 after 888 steps.
Found uncertainty sample 29 after 1368 steps.
Found uncertainty sample 30 after 444 steps.
Found uncertainty sample 31 after 33 steps.
Found uncertainty sample 32 after 386 steps.
Found uncertainty sample 33 after 591 steps.
Found uncertainty sample 34 after 294 steps.
Found uncertainty sample 35 after 849 steps.
Found uncertainty sample 36 after 104 steps.
Found uncertainty sample 37 after 390 steps.
Found uncertainty sample 38 after 1925 steps.
Found uncertainty sample 39 after 209 steps.
Found uncertainty sample 40 after 328 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 644 steps.
Found uncertainty sample 43 after 924 steps.
Found uncertainty sample 44 after 1244 steps.
Found uncertainty sample 45 after 713 steps.
Found uncertainty sample 46 after 1055 steps.
Found uncertainty sample 47 after 766 steps.
Found uncertainty sample 48 after 128 steps.
Found uncertainty sample 49 after 1427 steps.
Found uncertainty sample 50 after 146 steps.
Found uncertainty sample 51 after 10 steps.
Found uncertainty sample 52 after 133 steps.
Found uncertainty sample 53 after 550 steps.
Found uncertainty sample 54 after 452 steps.
Found uncertainty sample 55 after 19 steps.
Found uncertainty sample 56 after 1483 steps.
Found uncertainty sample 57 after 1185 steps.
Found uncertainty sample 58 after 506 steps.
Found uncertainty sample 59 after 1408 steps.
Found uncertainty sample 60 after 2 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 44 steps.
Found uncertainty sample 63 after 2159 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 231 steps.
Found uncertainty sample 66 after 71 steps.
Found uncertainty sample 67 after 413 steps.
Found uncertainty sample 68 after 350 steps.
Found uncertainty sample 69 after 1215 steps.
Found uncertainty sample 70 after 817 steps.
Found uncertainty sample 71 after 1105 steps.
Found uncertainty sample 72 after 316 steps.
Found uncertainty sample 73 after 55 steps.
Found uncertainty sample 74 after 14 steps.
Found uncertainty sample 75 after 282 steps.
Found uncertainty sample 76 after 604 steps.
Found uncertainty sample 77 after 2157 steps.
Found uncertainty sample 78 after 479 steps.
Found uncertainty sample 79 after 10 steps.
Found uncertainty sample 80 after 1585 steps.
Found uncertainty sample 81 after 1600 steps.
Found uncertainty sample 82 after 34 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 188 steps.
Found uncertainty sample 85 after 96 steps.
Found uncertainty sample 86 after 2104 steps.
Found uncertainty sample 87 after 145 steps.
Found uncertainty sample 88 after 1332 steps.
Found uncertainty sample 89 after 263 steps.
Found uncertainty sample 90 after 648 steps.
Found uncertainty sample 91 after 260 steps.
Found uncertainty sample 92 after 939 steps.
Found uncertainty sample 93 after 1 steps.
Found uncertainty sample 94 after 1056 steps.
Found uncertainty sample 95 after 3 steps.
Found uncertainty sample 96 after 1490 steps.
Found uncertainty sample 97 after 68 steps.
Found uncertainty sample 98 after 249 steps.
Found uncertainty sample 99 after 713 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_152825-za6pp9os
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_4
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/za6pp9os
Training model 4. Added 101 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 6.179910410933519, Training Loss Force: 4.400564232095688, time: 0.5537683963775635
Validation Loss Energy: 3.9190108140392472, Validation Loss Force: 3.859061599881109, time: 0.05003976821899414
Test Loss Energy: 15.464405582725142, Test Loss Force: 10.266401488320858, time: 9.145395755767822


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.593070568395219, Training Loss Force: 3.884294178027756, time: 0.5765624046325684
Validation Loss Energy: 2.5304760803682624, Validation Loss Force: 3.5412931337573137, time: 0.05202984809875488
Test Loss Energy: 12.398644017164422, Test Loss Force: 10.203879792675306, time: 8.907943725585938


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.8246294751932832, Training Loss Force: 3.7478543491348564, time: 0.5314700603485107
Validation Loss Energy: 2.050849634738704, Validation Loss Force: 3.5008998373402833, time: 0.050384521484375
Test Loss Energy: 14.509326059190021, Test Loss Force: 10.116871425198015, time: 9.520389556884766


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7483238651184156, Training Loss Force: 3.5603394318051254, time: 0.5152881145477295
Validation Loss Energy: 2.0112352349941296, Validation Loss Force: 3.4688951556577905, time: 0.0490422248840332
Test Loss Energy: 14.148469220058555, Test Loss Force: 10.00767210711511, time: 9.214178800582886


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.2776011739270796, Training Loss Force: 3.558727167225144, time: 0.5515530109405518
Validation Loss Energy: 2.3246391631885936, Validation Loss Force: 3.4786892580414244, time: 0.056328773498535156
Test Loss Energy: 14.908395847606773, Test Loss Force: 10.186672205534927, time: 8.995431423187256


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.265120988188217, Training Loss Force: 3.4881415982769246, time: 0.5097250938415527
Validation Loss Energy: 3.4669804236719575, Validation Loss Force: 3.4000759160716187, time: 0.05248856544494629
Test Loss Energy: 15.529314053790399, Test Loss Force: 10.141509344172773, time: 9.25877594947815


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.858503283039535, Training Loss Force: 3.461000042551373, time: 0.5787584781646729
Validation Loss Energy: 1.4779547659655305, Validation Loss Force: 3.4240580510954794, time: 0.04964876174926758
Test Loss Energy: 13.353075850946965, Test Loss Force: 10.005855304087008, time: 9.052412509918213


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.728997132776742, Training Loss Force: 3.5129417911140335, time: 0.5439126491546631
Validation Loss Energy: 1.5165522357206533, Validation Loss Force: 3.385147285852036, time: 0.047518014907836914
Test Loss Energy: 13.631543399343636, Test Loss Force: 10.086638579034215, time: 9.049041032791138


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.146528094522417, Training Loss Force: 3.4577664380332216, time: 0.5429198741912842
Validation Loss Energy: 2.4945515310408566, Validation Loss Force: 3.4636597586987365, time: 0.04970979690551758
Test Loss Energy: 14.464130867666851, Test Loss Force: 10.05889089774164, time: 8.982709169387817


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.7539580895562232, Training Loss Force: 3.4936841927706888, time: 0.5366075038909912
Validation Loss Energy: 2.532661132697252, Validation Loss Force: 3.5420593382884515, time: 0.05073189735412598
Test Loss Energy: 12.132529556090622, Test Loss Force: 10.121580297062478, time: 9.305792808532715


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.696573340842043, Training Loss Force: 3.4417436879742573, time: 0.5840177536010742
Validation Loss Energy: 1.2979708499738078, Validation Loss Force: 3.2536831994271243, time: 0.05150294303894043
Test Loss Energy: 13.003849513277887, Test Loss Force: 10.028779001727324, time: 9.118905067443848


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.373155709975996, Training Loss Force: 3.3687403488106633, time: 0.5340032577514648
Validation Loss Energy: 1.7919417533186068, Validation Loss Force: 3.4499560314509026, time: 0.052107810974121094
Test Loss Energy: 13.989760436293967, Test Loss Force: 10.165813520569417, time: 9.02338719367981


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.828783986812693, Training Loss Force: 3.355740640963485, time: 0.5384140014648438
Validation Loss Energy: 1.2672763535459541, Validation Loss Force: 3.272943857880732, time: 0.04170727729797363
Test Loss Energy: 13.135292905461908, Test Loss Force: 10.118885566716529, time: 7.660997629165649


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.196033604054543, Training Loss Force: 3.3171825645612647, time: 0.5272369384765625
Validation Loss Energy: 2.835090144027227, Validation Loss Force: 3.2549132237892295, time: 0.04841041564941406
Test Loss Energy: 15.14809821324657, Test Loss Force: 10.156696163347384, time: 9.723280668258667


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 3.146534122494296, Training Loss Force: 3.2654082154815245, time: 0.5496180057525635
Validation Loss Energy: 1.9936964770459813, Validation Loss Force: 3.2152870225799206, time: 0.051099538803100586
Test Loss Energy: 13.922122605750245, Test Loss Force: 10.017777966121761, time: 8.110280513763428


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.862205151228609, Training Loss Force: 3.274932595547708, time: 0.5061359405517578
Validation Loss Energy: 1.2716135031703355, Validation Loss Force: 3.3786032623223647, time: 0.04018568992614746
Test Loss Energy: 12.75813481955725, Test Loss Force: 10.07906445655869, time: 7.605873107910156


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.4914207312768863, Training Loss Force: 3.3081448788093106, time: 0.5273623466491699
Validation Loss Energy: 1.2631905973873252, Validation Loss Force: 3.286212489617423, time: 0.04113578796386719
Test Loss Energy: 13.026585730492167, Test Loss Force: 10.176083012253152, time: 7.320729970932007


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.482634135206351, Training Loss Force: 3.316431212062161, time: 0.5488171577453613
Validation Loss Energy: 2.751125617142485, Validation Loss Force: 3.420605120649577, time: 0.04185748100280762
Test Loss Energy: 11.766740728278856, Test Loss Force: 10.108375135358832, time: 7.385484218597412


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.1272481083869432, Training Loss Force: 3.249937675361497, time: 0.5580923557281494
Validation Loss Energy: 2.5405133374592492, Validation Loss Force: 3.1560679405512793, time: 0.048520803451538086
Test Loss Energy: 14.330952484130034, Test Loss Force: 10.046559401165279, time: 7.379584312438965


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.8609875199949686, Training Loss Force: 3.2059958566342184, time: 0.520625114440918
Validation Loss Energy: 2.750973979454108, Validation Loss Force: 3.164980273117039, time: 0.04512810707092285
Test Loss Energy: 12.159587942308741, Test Loss Force: 10.026153669543255, time: 7.542836904525757

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–†â–…â–‡â–ˆâ–„â–„â–†â–‚â–ƒâ–…â–„â–‡â–…â–ƒâ–ƒâ–â–†â–‚
wandb:   test_error_force â–ˆâ–†â–„â–â–†â–…â–â–ƒâ–‚â–„â–‚â–…â–„â–…â–â–ƒâ–†â–„â–‚â–‚
wandb:          test_loss â–â–„â–„â–„â–‡â–†â–…â–‡â–‡â–…â–„â–†â–†â–ˆâ–‡â–‡â–‡â–†â–ˆâ–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–â–â–‚â–‚
wandb:  train_error_force â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–…â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–â–
wandb: valid_error_energy â–ˆâ–„â–ƒâ–ƒâ–„â–‡â–‚â–‚â–„â–„â–â–‚â–â–…â–ƒâ–â–â–…â–„â–…
wandb:  valid_error_force â–ˆâ–…â–„â–„â–„â–ƒâ–„â–ƒâ–„â–…â–‚â–„â–‚â–‚â–‚â–ƒâ–‚â–„â–â–
wandb:         valid_loss â–ˆâ–„â–„â–ƒâ–„â–„â–ƒâ–‚â–„â–„â–â–ƒâ–â–‚â–â–‚â–â–ƒâ–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1095
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.15959
wandb:   test_error_force 10.02615
wandb:          test_loss 4.87156
wandb: train_error_energy 2.86099
wandb:  train_error_force 3.206
wandb:         train_loss -1.1545
wandb: valid_error_energy 2.75097
wandb:  valid_error_force 3.16498
wandb:         valid_loss -1.1909
wandb: 
wandb: ğŸš€ View run al_58_4 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/za6pp9os
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_152825-za6pp9os/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 14.948019027709961, Uncertainty Bias: -2.984196662902832
7.6293945e-06 0.3843975
-4.452104 26.125853
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 164 steps.
Found uncertainty sample 1 after 57 steps.
Found uncertainty sample 2 after 68 steps.
Found uncertainty sample 3 after 83 steps.
Found uncertainty sample 4 after 28 steps.
Found uncertainty sample 5 after 189 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 7 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 51 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 252 steps.
Found uncertainty sample 12 after 1 steps.
Found uncertainty sample 13 after 111 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 1 steps.
Found uncertainty sample 16 after 191 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 1 steps.
Found uncertainty sample 19 after 102 steps.
Found uncertainty sample 20 after 21 steps.
Found uncertainty sample 21 after 23 steps.
Found uncertainty sample 22 after 133 steps.
Found uncertainty sample 23 after 342 steps.
Found uncertainty sample 24 after 74 steps.
Found uncertainty sample 25 after 25 steps.
Found uncertainty sample 26 after 156 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 47 steps.
Found uncertainty sample 29 after 9 steps.
Found uncertainty sample 30 after 137 steps.
Found uncertainty sample 31 after 34 steps.
Found uncertainty sample 32 after 181 steps.
Found uncertainty sample 33 after 1 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 31 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 55 steps.
Found uncertainty sample 38 after 617 steps.
Found uncertainty sample 39 after 1 steps.
Found uncertainty sample 40 after 150 steps.
Found uncertainty sample 41 after 34 steps.
Found uncertainty sample 42 after 27 steps.
Found uncertainty sample 43 after 39 steps.
Found uncertainty sample 44 after 33 steps.
Found uncertainty sample 45 after 1 steps.
Found uncertainty sample 46 after 195 steps.
Found uncertainty sample 47 after 31 steps.
Found uncertainty sample 48 after 43 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 27 steps.
Found uncertainty sample 51 after 49 steps.
Found uncertainty sample 52 after 226 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 7 steps.
Found uncertainty sample 55 after 119 steps.
Found uncertainty sample 56 after 2 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 1 steps.
Found uncertainty sample 59 after 147 steps.
Found uncertainty sample 60 after 1 steps.
Found uncertainty sample 61 after 226 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 21 steps.
Found uncertainty sample 64 after 38 steps.
Found uncertainty sample 65 after 190 steps.
Found uncertainty sample 66 after 1 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 144 steps.
Found uncertainty sample 69 after 30 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 24 steps.
Found uncertainty sample 72 after 37 steps.
Found uncertainty sample 73 after 1 steps.
Found uncertainty sample 74 after 5 steps.
Found uncertainty sample 75 after 11 steps.
Found uncertainty sample 76 after 110 steps.
Found uncertainty sample 77 after 84 steps.
Found uncertainty sample 78 after 18 steps.
Found uncertainty sample 79 after 55 steps.
Found uncertainty sample 80 after 1 steps.
Found uncertainty sample 81 after 44 steps.
Found uncertainty sample 82 after 172 steps.
Found uncertainty sample 83 after 27 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 23 steps.
Found uncertainty sample 87 after 2 steps.
Found uncertainty sample 88 after 8 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 90 steps.
Found uncertainty sample 91 after 189 steps.
Found uncertainty sample 92 after 9 steps.
Found uncertainty sample 93 after 27 steps.
Found uncertainty sample 94 after 28 steps.
Found uncertainty sample 95 after 19 steps.
Found uncertainty sample 96 after 311 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 58 steps.
Found uncertainty sample 99 after 139 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_153437-vlwbuxip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_5
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vlwbuxip
Training model 5. Added 124 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 5.082547390920754, Training Loss Force: 3.4127421750311457, time: 0.5709788799285889
Validation Loss Energy: 2.230778551451383, Validation Loss Force: 3.1884663012837726, time: 0.050295114517211914
Test Loss Energy: 12.209721208024991, Test Loss Force: 9.993482985611099, time: 8.212352275848389


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.396855909112332, Training Loss Force: 3.1589821171388945, time: 0.5673885345458984
Validation Loss Energy: 3.28199736268501, Validation Loss Force: 3.155451592355351, time: 0.04912376403808594
Test Loss Energy: 15.254244837598213, Test Loss Force: 10.068817436971589, time: 8.636479377746582


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.273441083943303, Training Loss Force: 3.198467948890554, time: 0.5664458274841309
Validation Loss Energy: 2.2105526222501783, Validation Loss Force: 3.1523985756955355, time: 0.04796195030212402
Test Loss Energy: 11.970927602967814, Test Loss Force: 10.00515857582682, time: 8.420790195465088


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.7980735812603346, Training Loss Force: 3.1011946336465677, time: 0.6807219982147217
Validation Loss Energy: 1.338827075545222, Validation Loss Force: 3.0769531476648444, time: 0.04934573173522949
Test Loss Energy: 12.278886870672528, Test Loss Force: 10.070995593551897, time: 8.323272466659546


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.2826759249332955, Training Loss Force: 3.15387969467796, time: 0.5495293140411377
Validation Loss Energy: 4.453031101305191, Validation Loss Force: 3.3280758477358687, time: 0.04724836349487305
Test Loss Energy: 11.586049029844528, Test Loss Force: 9.996845606814125, time: 8.309164762496948


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.3612576200507367, Training Loss Force: 3.23498621033729, time: 0.5652053356170654
Validation Loss Energy: 2.6808412145761085, Validation Loss Force: 3.099738658698489, time: 0.0502009391784668
Test Loss Energy: 11.556978833721992, Test Loss Force: 9.97955999920295, time: 8.266727685928345


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.6357726161380333, Training Loss Force: 3.096223067397009, time: 0.5601937770843506
Validation Loss Energy: 2.372266089480234, Validation Loss Force: 3.1385438787667623, time: 0.04832959175109863
Test Loss Energy: 13.95039613596932, Test Loss Force: 10.070669074314246, time: 8.388331651687622


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.631920621724082, Training Loss Force: 3.2063830869848484, time: 0.5498764514923096
Validation Loss Energy: 4.651253847039859, Validation Loss Force: 3.198386657073147, time: 0.04718446731567383
Test Loss Energy: 16.37751474221041, Test Loss Force: 10.112913193174807, time: 8.24416971206665


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.860151090713561, Training Loss Force: 3.148436576704327, time: 0.5698044300079346
Validation Loss Energy: 2.3150325482258314, Validation Loss Force: 3.0959094173959687, time: 0.04692888259887695
Test Loss Energy: 11.694193441773434, Test Loss Force: 10.086022240164743, time: 8.251776456832886


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.7721433550562056, Training Loss Force: 3.1252872653042374, time: 0.6220188140869141
Validation Loss Energy: 2.5392757423461827, Validation Loss Force: 3.111878580534472, time: 0.047972679138183594
Test Loss Energy: 11.752597003301247, Test Loss Force: 10.027810491201944, time: 8.4701669216156


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9455048121521497, Training Loss Force: 3.084850328664462, time: 0.5818846225738525
Validation Loss Energy: 1.3927113388411523, Validation Loss Force: 3.0326333035285233, time: 0.047921180725097656
Test Loss Energy: 13.18704503882264, Test Loss Force: 10.03216063024844, time: 8.331106424331665


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2738314784639475, Training Loss Force: 3.0750566042324055, time: 0.5778820514678955
Validation Loss Energy: 3.3124273281675016, Validation Loss Force: 3.1288252612235983, time: 0.048107147216796875
Test Loss Energy: 11.415927783177894, Test Loss Force: 10.15551936973503, time: 8.60172724723816


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1668149597802424, Training Loss Force: 3.0837676907679605, time: 0.5560793876647949
Validation Loss Energy: 1.088342211242708, Validation Loss Force: 3.1330390521411355, time: 0.053436994552612305
Test Loss Energy: 12.615832387065955, Test Loss Force: 10.200214122262093, time: 9.536958694458008


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.284051503135337, Training Loss Force: 3.103996347666203, time: 0.7477385997772217
Validation Loss Energy: 4.476298245701478, Validation Loss Force: 3.0591191304291963, time: 0.07735300064086914
Test Loss Energy: 11.330198548518743, Test Loss Force: 10.104812247158089, time: 9.514981746673584


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.251377990565739, Training Loss Force: 2.9970700876278147, time: 0.5528266429901123
Validation Loss Energy: 1.7909564423478763, Validation Loss Force: 3.079464187623472, time: 0.04965662956237793
Test Loss Energy: 11.833760555180646, Test Loss Force: 10.05919782209445, time: 9.53945803642273


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.8161142413231177, Training Loss Force: 3.003235629276696, time: 0.587435245513916
Validation Loss Energy: 2.5350543806776837, Validation Loss Force: 3.1834270758422805, time: 0.054609060287475586
Test Loss Energy: 13.979841358229118, Test Loss Force: 10.098196557971832, time: 9.501418352127075


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.399949233282346, Training Loss Force: 2.997148959383188, time: 0.8127007484436035
Validation Loss Energy: 2.184493874771395, Validation Loss Force: 3.11304937490376, time: 0.05352663993835449
Test Loss Energy: 11.669661116937744, Test Loss Force: 10.006334464772904, time: 9.527854681015015


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.6689620969071504, Training Loss Force: 3.012150308658059, time: 0.6104464530944824
Validation Loss Energy: 1.4046478524123303, Validation Loss Force: 3.0922391618636413, time: 0.05407834053039551
Test Loss Energy: 13.59524378657315, Test Loss Force: 10.126774564348922, time: 9.53733229637146


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2002461142139067, Training Loss Force: 3.015723433565048, time: 0.60030198097229
Validation Loss Energy: 1.595405392360623, Validation Loss Force: 3.009143489986309, time: 0.05450296401977539
Test Loss Energy: 13.847151303284814, Test Loss Force: 10.037752670899232, time: 9.563567876815796


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.491999978482027, Training Loss Force: 2.9903107137354596, time: 0.7875058650970459
Validation Loss Energy: 2.9369744157688, Validation Loss Force: 3.2668959412081877, time: 0.054472923278808594
Test Loss Energy: 14.005581827560258, Test Loss Force: 10.106944172494151, time: 9.427473545074463

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–‚â–‚â–â–â–…â–ˆâ–‚â–‚â–„â–â–ƒâ–â–‚â–…â–â–„â–„â–…
wandb:   test_error_force â–â–„â–‚â–„â–‚â–â–„â–…â–„â–ƒâ–ƒâ–‡â–ˆâ–…â–„â–…â–‚â–†â–ƒâ–…
wandb:          test_loss â–ƒâ–‡â–ƒâ–…â–â–ƒâ–†â–ˆâ–…â–…â–‡â–‡â–ˆâ–†â–‡â–ˆâ–‡â–ˆâ–ˆâ–ˆ
wandb: train_error_energy â–ˆâ–‚â–„â–ƒâ–„â–„â–‚â–…â–…â–…â–ƒâ–â–â–„â–â–ƒâ–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–„â–„â–ƒâ–„â–…â–ƒâ–…â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–â–â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–„â–ƒâ–„â–…â–ƒâ–…â–„â–„â–ƒâ–‚â–‚â–ƒâ–â–‚â–â–‚â–â–
wandb: valid_error_energy â–ƒâ–…â–ƒâ–â–ˆâ–„â–„â–ˆâ–ƒâ–„â–‚â–…â–â–ˆâ–‚â–„â–ƒâ–‚â–‚â–…
wandb:  valid_error_force â–…â–„â–„â–‚â–ˆâ–ƒâ–„â–…â–ƒâ–ƒâ–‚â–„â–„â–‚â–ƒâ–…â–ƒâ–ƒâ–â–‡
wandb:         valid_loss â–„â–…â–ƒâ–‚â–ˆâ–ƒâ–ƒâ–‡â–ƒâ–ƒâ–â–„â–‚â–…â–‚â–„â–ƒâ–‚â–â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 1206
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.00558
wandb:   test_error_force 10.10694
wandb:          test_loss 5.27991
wandb: train_error_energy 2.492
wandb:  train_error_force 2.99031
wandb:         train_loss -1.3522
wandb: valid_error_energy 2.93697
wandb:  valid_error_force 3.2669
wandb:         valid_loss -1.09404
wandb: 
wandb: ğŸš€ View run al_58_5 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vlwbuxip
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_153437-vlwbuxip/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 21.887893676757812, Uncertainty Bias: -4.25658655166626
9.918213e-05 0.020820022
-5.9446464 33.718983
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 18 steps.
Found uncertainty sample 1 after 132 steps.
Found uncertainty sample 2 after 12 steps.
Found uncertainty sample 3 after 21 steps.
Found uncertainty sample 4 after 69 steps.
Found uncertainty sample 5 after 20 steps.
Found uncertainty sample 6 after 62 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 15 steps.
Found uncertainty sample 9 after 83 steps.
Found uncertainty sample 10 after 1 steps.
Found uncertainty sample 11 after 69 steps.
Found uncertainty sample 12 after 140 steps.
Found uncertainty sample 13 after 128 steps.
Found uncertainty sample 14 after 1 steps.
Found uncertainty sample 15 after 2 steps.
Found uncertainty sample 16 after 49 steps.
Found uncertainty sample 17 after 1 steps.
Found uncertainty sample 18 after 363 steps.
Found uncertainty sample 19 after 20 steps.
Found uncertainty sample 20 after 30 steps.
Found uncertainty sample 21 after 19 steps.
Found uncertainty sample 22 after 20 steps.
Found uncertainty sample 23 after 22 steps.
Found uncertainty sample 24 after 172 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 55 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 3 steps.
Found uncertainty sample 30 after 21 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 16 steps.
Found uncertainty sample 33 after 49 steps.
Found uncertainty sample 34 after 132 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 120 steps.
Found uncertainty sample 37 after 149 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 32 steps.
Found uncertainty sample 40 after 55 steps.
Found uncertainty sample 41 after 1 steps.
Found uncertainty sample 42 after 92 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 180 steps.
Found uncertainty sample 45 after 118 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 1 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 145 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 10 steps.
Found uncertainty sample 54 after 1 steps.
Found uncertainty sample 55 after 57 steps.
Found uncertainty sample 56 after 19 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 7 steps.
Found uncertainty sample 59 after 37 steps.
Found uncertainty sample 60 after 5 steps.
Found uncertainty sample 61 after 82 steps.
Found uncertainty sample 62 after 149 steps.
Found uncertainty sample 63 after 19 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 26 steps.
Found uncertainty sample 66 after 3 steps.
Found uncertainty sample 67 after 1 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 1 steps.
Found uncertainty sample 70 after 135 steps.
Found uncertainty sample 71 after 21 steps.
Found uncertainty sample 72 after 26 steps.
Found uncertainty sample 73 after 233 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 265 steps.
Found uncertainty sample 76 after 13 steps.
Found uncertainty sample 77 after 24 steps.
Found uncertainty sample 78 after 110 steps.
Found uncertainty sample 79 after 32 steps.
Found uncertainty sample 80 after 4 steps.
Found uncertainty sample 81 after 1 steps.
Found uncertainty sample 82 after 70 steps.
Found uncertainty sample 83 after 212 steps.
Found uncertainty sample 84 after 3 steps.
Found uncertainty sample 85 after 164 steps.
Found uncertainty sample 86 after 3 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1 steps.
Found uncertainty sample 89 after 1 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 234 steps.
Found uncertainty sample 92 after 68 steps.
Found uncertainty sample 93 after 13 steps.
Found uncertainty sample 94 after 84 steps.
Found uncertainty sample 95 after 15 steps.
Found uncertainty sample 96 after 61 steps.
Found uncertainty sample 97 after 21 steps.
Found uncertainty sample 98 after 6 steps.
Found uncertainty sample 99 after 12 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_154046-p1bnx0go
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_6
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p1bnx0go
Training model 6. Added 124 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.0369662207848656, Training Loss Force: 3.160548192213444, time: 0.6519174575805664
Validation Loss Energy: 0.9813960574740453, Validation Loss Force: 2.58401654250288, time: 0.05117321014404297
Test Loss Energy: 12.594502813981357, Test Loss Force: 9.893445026971401, time: 7.561058521270752


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9361801539287196, Training Loss Force: 2.9260554842895727, time: 0.6438713073730469
Validation Loss Energy: 2.7659338946886938, Validation Loss Force: 3.150459238769077, time: 0.055048227310180664
Test Loss Energy: 14.543380896502317, Test Loss Force: 10.122067618397702, time: 7.532024145126343


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.531361200826618, Training Loss Force: 2.865298545757051, time: 0.695854663848877
Validation Loss Energy: 0.9588096683241467, Validation Loss Force: 2.2617772139325742, time: 0.05614638328552246
Test Loss Energy: 12.758478308282276, Test Loss Force: 9.987078270194477, time: 7.625898838043213


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7925228097803174, Training Loss Force: 2.8610532895685354, time: 0.6503143310546875
Validation Loss Energy: 3.957887065565071, Validation Loss Force: 2.5336138226381038, time: 0.052475929260253906
Test Loss Energy: 15.334025588433645, Test Loss Force: 9.860557288420056, time: 7.755826711654663


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.426563320540931, Training Loss Force: 2.9111155350550724, time: 0.615015983581543
Validation Loss Energy: 2.5861175372292817, Validation Loss Force: 2.5658048783957383, time: 0.05153322219848633
Test Loss Energy: 14.064504093948994, Test Loss Force: 9.983550281593487, time: 7.63532280921936


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9397861230230415, Training Loss Force: 2.7864263217460494, time: 0.6503462791442871
Validation Loss Energy: 0.9078462675499241, Validation Loss Force: 2.628909425686246, time: 0.05271339416503906
Test Loss Energy: 12.717415492375725, Test Loss Force: 9.96723241041181, time: 7.66500186920166


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.230928040647584, Training Loss Force: 2.7992565470934636, time: 0.6310374736785889
Validation Loss Energy: 1.7298872023857212, Validation Loss Force: 6.792731271520622, time: 0.05199408531188965
Test Loss Energy: 11.903959985568804, Test Loss Force: 9.901401492189201, time: 7.830528974533081


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9721408154201125, Training Loss Force: 2.80996161546132, time: 0.6115925312042236
Validation Loss Energy: 1.0079636039512734, Validation Loss Force: 2.4997873733382026, time: 0.05535483360290527
Test Loss Energy: 12.102551546020782, Test Loss Force: 9.9018872047107, time: 10.175642967224121


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6972959849900344, Training Loss Force: 2.817613304006586, time: 0.7223308086395264
Validation Loss Energy: 1.3954557360647122, Validation Loss Force: 2.434458806618168, time: 0.062048912048339844
Test Loss Energy: 13.822549347125836, Test Loss Force: 9.968365560871558, time: 10.277162790298462


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.5951635799663477, Training Loss Force: 2.7772060722121727, time: 0.6367347240447998
Validation Loss Energy: 0.6766458594659889, Validation Loss Force: 2.436357395090921, time: 0.062489986419677734
Test Loss Energy: 12.687584868295962, Test Loss Force: 9.921305614344838, time: 8.535933017730713


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1971212021374638, Training Loss Force: 2.805561429262055, time: 0.6323089599609375
Validation Loss Energy: 2.316222714810815, Validation Loss Force: 2.8785978024537764, time: 0.05478811264038086
Test Loss Energy: 11.983983961060012, Test Loss Force: 9.82978053731021, time: 8.409111738204956


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9193240651212848, Training Loss Force: 2.7003797429172485, time: 0.6335442066192627
Validation Loss Energy: 1.8179195048955585, Validation Loss Force: 3.244170996182235, time: 0.05461406707763672
Test Loss Energy: 12.171866781712412, Test Loss Force: 9.850148133052123, time: 8.785589694976807


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.4955501120323555, Training Loss Force: 2.7644315035479483, time: 0.6054534912109375
Validation Loss Energy: 1.5478363600469236, Validation Loss Force: 2.595107135988678, time: 0.05739569664001465
Test Loss Energy: 13.223231960020755, Test Loss Force: 9.963605416813179, time: 8.371628284454346


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.5105435071635247, Training Loss Force: 2.7504003731309057, time: 0.6153302192687988
Validation Loss Energy: 1.6066238536034705, Validation Loss Force: 2.800693105040886, time: 0.05567526817321777
Test Loss Energy: 12.881986518221945, Test Loss Force: 9.90436389649631, time: 8.642207145690918


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.600400066413723, Training Loss Force: 2.728470248272166, time: 0.60774827003479
Validation Loss Energy: 3.4375051521526316, Validation Loss Force: 3.0614750813276848, time: 0.05523252487182617
Test Loss Energy: 11.524111189020902, Test Loss Force: 9.854908818044969, time: 8.407397747039795


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.899884564906561, Training Loss Force: 2.7622378492977857, time: 0.6619055271148682
Validation Loss Energy: 2.1066395005854845, Validation Loss Force: 2.519246207331686, time: 0.055844783782958984
Test Loss Energy: 11.656155806551844, Test Loss Force: 9.929412557273006, time: 8.368335247039795


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3206890920645296, Training Loss Force: 2.819330541714097, time: 0.6235973834991455
Validation Loss Energy: 2.108090969413215, Validation Loss Force: 2.4407163662916034, time: 0.05457639694213867
Test Loss Energy: 14.102355507816167, Test Loss Force: 9.822053339706223, time: 8.54682993888855


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.480702207330641, Training Loss Force: 2.731316453010232, time: 0.627392053604126
Validation Loss Energy: 1.4726097044521071, Validation Loss Force: 2.443810910747135, time: 0.060260772705078125
Test Loss Energy: 13.14312539875836, Test Loss Force: 9.904685962351042, time: 8.448987245559692


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0830624418258257, Training Loss Force: 2.699471536439942, time: 0.6261918544769287
Validation Loss Energy: 1.8941029141431405, Validation Loss Force: 2.615926923802072, time: 0.06003975868225098
Test Loss Energy: 11.496146369171031, Test Loss Force: 9.813345255369244, time: 8.382341146469116


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9135804139079464, Training Loss Force: 2.746978552745677, time: 0.6480693817138672
Validation Loss Energy: 1.6724099497511002, Validation Loss Force: 2.4930261360566783, time: 0.05493021011352539
Test Loss Energy: 13.236883322713473, Test Loss Force: 9.898820628549123, time: 8.545476198196411

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‡â–ƒâ–ˆâ–†â–ƒâ–‚â–‚â–…â–ƒâ–‚â–‚â–„â–„â–â–â–†â–„â–â–„
wandb:   test_error_force â–ƒâ–ˆâ–…â–‚â–…â–„â–ƒâ–ƒâ–…â–ƒâ–â–‚â–„â–ƒâ–‚â–„â–â–ƒâ–â–ƒ
wandb:          test_loss â–â–†â–„â–‡â–ˆâ–‡â–…â–…â–‡â–†â–„â–…â–ˆâ–‡â–†â–„â–†â–†â–„â–†
wandb: train_error_energy â–ˆâ–‚â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–â–„â–‚â–‚â–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–â–‚â–ƒâ–â–â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚
wandb: valid_error_energy â–‚â–…â–‚â–ˆâ–…â–â–ƒâ–‚â–ƒâ–â–„â–ƒâ–ƒâ–ƒâ–‡â–„â–„â–ƒâ–„â–ƒ
wandb:  valid_error_force â–â–‚â–â–â–â–‚â–ˆâ–â–â–â–‚â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–
wandb:         valid_loss â–‚â–ƒâ–â–‚â–‚â–‚â–ˆâ–â–â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–‚â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1317
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.23688
wandb:   test_error_force 9.89882
wandb:          test_loss 5.49061
wandb: train_error_energy 1.91358
wandb:  train_error_force 2.74698
wandb:         train_loss -1.60419
wandb: valid_error_energy 1.67241
wandb:  valid_error_force 2.49303
wandb:         valid_loss -1.84946
wandb: 
wandb: ğŸš€ View run al_58_6 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p1bnx0go
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_154046-p1bnx0go/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 24.65792465209961, Uncertainty Bias: -4.432581424713135
4.7683716e-06 0.01883769
-5.422118 44.41727
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 13 steps.
Found uncertainty sample 1 after 119 steps.
Found uncertainty sample 2 after 50 steps.
Found uncertainty sample 3 after 54 steps.
Found uncertainty sample 4 after 1 steps.
Found uncertainty sample 5 after 40 steps.
Found uncertainty sample 6 after 1 steps.
Found uncertainty sample 7 after 1 steps.
Found uncertainty sample 8 after 146 steps.
Found uncertainty sample 9 after 138 steps.
Found uncertainty sample 10 after 689 steps.
Found uncertainty sample 11 after 109 steps.
Found uncertainty sample 12 after 132 steps.
Found uncertainty sample 13 after 333 steps.
Found uncertainty sample 14 after 53 steps.
Found uncertainty sample 15 after 4 steps.
Found uncertainty sample 16 after 89 steps.
Found uncertainty sample 17 after 124 steps.
Found uncertainty sample 18 after 29 steps.
Found uncertainty sample 19 after 6 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 9 steps.
Found uncertainty sample 22 after 98 steps.
Found uncertainty sample 23 after 24 steps.
Found uncertainty sample 24 after 177 steps.
Found uncertainty sample 25 after 89 steps.
Found uncertainty sample 26 after 173 steps.
Found uncertainty sample 27 after 1 steps.
Found uncertainty sample 28 after 16 steps.
Found uncertainty sample 29 after 28 steps.
Found uncertainty sample 30 after 19 steps.
Found uncertainty sample 31 after 115 steps.
Found uncertainty sample 32 after 54 steps.
Found uncertainty sample 33 after 20 steps.
Found uncertainty sample 34 after 68 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 240 steps.
Found uncertainty sample 37 after 4 steps.
Found uncertainty sample 38 after 92 steps.
Found uncertainty sample 39 after 41 steps.
Found uncertainty sample 40 after 72 steps.
Found uncertainty sample 41 after 123 steps.
Found uncertainty sample 42 after 84 steps.
Found uncertainty sample 43 after 46 steps.
Found uncertainty sample 44 after 45 steps.
Found uncertainty sample 45 after 111 steps.
Found uncertainty sample 46 after 1 steps.
Found uncertainty sample 47 after 19 steps.
Found uncertainty sample 48 after 166 steps.
Found uncertainty sample 49 after 1 steps.
Found uncertainty sample 50 after 73 steps.
Found uncertainty sample 51 after 140 steps.
Found uncertainty sample 52 after 3 steps.
Found uncertainty sample 53 after 22 steps.
Found uncertainty sample 54 after 73 steps.
Found uncertainty sample 55 after 242 steps.
Found uncertainty sample 56 after 53 steps.
Found uncertainty sample 57 after 52 steps.
Found uncertainty sample 58 after 233 steps.
Found uncertainty sample 59 after 236 steps.
Found uncertainty sample 60 after 19 steps.
Found uncertainty sample 61 after 71 steps.
Found uncertainty sample 62 after 38 steps.
Found uncertainty sample 63 after 28 steps.
Found uncertainty sample 64 after 160 steps.
Found uncertainty sample 65 after 69 steps.
Found uncertainty sample 66 after 25 steps.
Found uncertainty sample 67 after 47 steps.
Found uncertainty sample 68 after 1 steps.
Found uncertainty sample 69 after 105 steps.
Found uncertainty sample 70 after 1 steps.
Found uncertainty sample 71 after 386 steps.
Found uncertainty sample 72 after 1 steps.
Found uncertainty sample 73 after 531 steps.
Found uncertainty sample 74 after 179 steps.
Found uncertainty sample 75 after 10 steps.
Found uncertainty sample 76 after 270 steps.
Found uncertainty sample 77 after 329 steps.
Found uncertainty sample 78 after 1 steps.
Found uncertainty sample 79 after 171 steps.
Found uncertainty sample 80 after 12 steps.
Found uncertainty sample 81 after 70 steps.
Found uncertainty sample 82 after 1 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 27 steps.
Found uncertainty sample 85 after 24 steps.
Found uncertainty sample 86 after 192 steps.
Found uncertainty sample 87 after 36 steps.
Found uncertainty sample 88 after 220 steps.
Found uncertainty sample 89 after 32 steps.
Found uncertainty sample 90 after 38 steps.
Found uncertainty sample 91 after 97 steps.
Found uncertainty sample 92 after 202 steps.
Found uncertainty sample 93 after 273 steps.
Found uncertainty sample 94 after 182 steps.
Found uncertainty sample 95 after 69 steps.
Found uncertainty sample 96 after 60 steps.
Found uncertainty sample 97 after 85 steps.
Found uncertainty sample 98 after 30 steps.
Found uncertainty sample 99 after 49 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_154716-kz6kcxh9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_7
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kz6kcxh9
Training model 7. Added 111 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.378694977559141, Training Loss Force: 2.90993498636342, time: 0.6908540725708008
Validation Loss Energy: 1.6804747478801723, Validation Loss Force: 2.5332036660713046, time: 0.06367039680480957
Test Loss Energy: 11.759538143845901, Test Loss Force: 9.890969902030463, time: 9.867829084396362


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.402081921087749, Training Loss Force: 2.7245603740538664, time: 0.7072587013244629
Validation Loss Energy: 2.8399180564492337, Validation Loss Force: 4.216135512309504, time: 0.0639033317565918
Test Loss Energy: 13.27929077580451, Test Loss Force: 9.826281642589878, time: 9.937230587005615


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7320276751146455, Training Loss Force: 2.650442853267729, time: 0.6911118030548096
Validation Loss Energy: 1.2389717372277, Validation Loss Force: 2.523992066173418, time: 0.06333303451538086
Test Loss Energy: 13.532202728551505, Test Loss Force: 9.829427563579053, time: 10.107352018356323


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3349912633184653, Training Loss Force: 2.683998192986057, time: 0.6905577182769775
Validation Loss Energy: 1.0588517425541721, Validation Loss Force: 3.8578467170209265, time: 0.06995368003845215
Test Loss Energy: 12.873772218454459, Test Loss Force: 9.689161870610068, time: 9.99945330619812


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8850581911625681, Training Loss Force: 2.653148533275015, time: 0.7015831470489502
Validation Loss Energy: 1.461355449144052, Validation Loss Force: 2.5543610203099254, time: 0.06612992286682129
Test Loss Energy: 12.941900200912913, Test Loss Force: 9.86143645149337, time: 9.985074281692505


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.333163187978973, Training Loss Force: 2.629321279486758, time: 0.6771869659423828
Validation Loss Energy: 2.245422721837043, Validation Loss Force: 2.387233575465781, time: 0.06577062606811523
Test Loss Energy: 11.263874922932358, Test Loss Force: 9.868178905874663, time: 10.176383972167969


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.4072166047921, Training Loss Force: 2.595932662054393, time: 0.734825849533081
Validation Loss Energy: 1.699430683607578, Validation Loss Force: 2.317809510811983, time: 0.06228518486022949
Test Loss Energy: 13.297846371643354, Test Loss Force: 9.74965667547124, time: 9.974409103393555


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.3910467450041684, Training Loss Force: 2.58753273325314, time: 0.6757421493530273
Validation Loss Energy: 1.296906491456273, Validation Loss Force: 2.5542374389339355, time: 0.05926012992858887
Test Loss Energy: 11.888634244163278, Test Loss Force: 9.7616783378404, time: 9.972336769104004


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.4879159524333034, Training Loss Force: 2.6294993653214673, time: 0.6771934032440186
Validation Loss Energy: 0.8428059738729362, Validation Loss Force: 2.5371227543742068, time: 0.06490540504455566
Test Loss Energy: 12.016732241109203, Test Loss Force: 9.742736719972239, time: 10.216966390609741


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.7278041179706274, Training Loss Force: 2.67424687276766, time: 0.7509686946868896
Validation Loss Energy: 2.834455314292187, Validation Loss Force: 4.740551745307863, time: 0.06544685363769531
Test Loss Energy: 12.636574990292207, Test Loss Force: 9.891082523654406, time: 10.335263013839722


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.037359053819657, Training Loss Force: 2.677969574306159, time: 0.6606206893920898
Validation Loss Energy: 2.803619868294961, Validation Loss Force: 2.7047046669451893, time: 0.06494259834289551
Test Loss Energy: 14.052839840040992, Test Loss Force: 9.859083237326924, time: 9.88327693939209


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9325216745899445, Training Loss Force: 2.632346546622787, time: 0.8897271156311035
Validation Loss Energy: 2.3110563452869988, Validation Loss Force: 2.5135084687794187, time: 0.06743335723876953
Test Loss Energy: 11.36236385043291, Test Loss Force: 9.717587683208821, time: 9.88522219657898


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.761192169781101, Training Loss Force: 2.5979374463910423, time: 0.6648190021514893
Validation Loss Energy: 1.4229745251333439, Validation Loss Force: 2.4727727072159515, time: 0.06410527229309082
Test Loss Energy: 13.272935882317837, Test Loss Force: 9.732883258191208, time: 9.846367120742798


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7114316234035032, Training Loss Force: 2.6142364295425953, time: 0.7219786643981934
Validation Loss Energy: 1.0212123624666902, Validation Loss Force: 2.497150636646699, time: 0.06167483329772949
Test Loss Energy: 13.076083183698048, Test Loss Force: 9.76102840507507, time: 10.137288570404053


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5176088521556894, Training Loss Force: 2.6049907686876868, time: 0.6798496246337891
Validation Loss Energy: 3.7156093406431636, Validation Loss Force: 4.442275402214868, time: 0.07030653953552246
Test Loss Energy: 11.796193425693435, Test Loss Force: 9.870680098261165, time: 10.094886064529419


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3024907184778547, Training Loss Force: 2.579248557770348, time: 0.7052383422851562
Validation Loss Energy: 1.1512820390325158, Validation Loss Force: 2.447516904677384, time: 0.06609773635864258
Test Loss Energy: 13.120868258291859, Test Loss Force: 9.7327317312545, time: 9.969242811203003


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3265787178359942, Training Loss Force: 2.559498254813048, time: 0.7571415901184082
Validation Loss Energy: 2.069718618164625, Validation Loss Force: 2.393155572736304, time: 0.06314849853515625
Test Loss Energy: 11.87020013474516, Test Loss Force: 9.731485809947507, time: 8.64485216140747


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3771758253910646, Training Loss Force: 2.638976483331263, time: 0.6796996593475342
Validation Loss Energy: 1.9403258558024201, Validation Loss Force: 2.363271926003346, time: 0.06379389762878418
Test Loss Energy: 14.05232613416069, Test Loss Force: 9.746435849047694, time: 10.563132047653198


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.255859165328239, Training Loss Force: 2.5380961525456303, time: 0.7022390365600586
Validation Loss Energy: 1.8529007720535278, Validation Loss Force: 2.3511890074687205, time: 0.06692266464233398
Test Loss Energy: 11.843361433206931, Test Loss Force: 9.69276859315577, time: 8.563365697860718


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.345727285878593, Training Loss Force: 2.5610655932420148, time: 0.7054741382598877
Validation Loss Energy: 2.692806675136257, Validation Loss Force: 2.4162415757823776, time: 0.058165550231933594
Test Loss Energy: 14.639904949490152, Test Loss Force: 9.711809938821938, time: 8.031356573104858

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–†â–„â–„â–â–…â–‚â–ƒâ–„â–‡â–â–…â–…â–‚â–…â–‚â–‡â–‚â–ˆ
wandb:   test_error_force â–ˆâ–†â–†â–â–‡â–‡â–ƒâ–„â–ƒâ–ˆâ–‡â–‚â–ƒâ–ƒâ–‡â–ƒâ–‚â–ƒâ–â–‚
wandb:          test_loss â–â–ƒâ–…â–â–…â–„â–…â–…â–…â–†â–‡â–„â–…â–†â–‡â–‡â–†â–ˆâ–…â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–†â–„â–‚â–‚â–‚â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–…â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–„â–ƒâ–‚â–‚â–‚â–‚â–â–ƒâ–â–
wandb:         train_loss â–ˆâ–„â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–â–‚â–â–ƒâ–â–
wandb: valid_error_energy â–ƒâ–†â–‚â–‚â–ƒâ–„â–ƒâ–‚â–â–†â–†â–…â–‚â–â–ˆâ–‚â–„â–„â–ƒâ–†
wandb:  valid_error_force â–‚â–†â–‚â–…â–‚â–â–â–‚â–‚â–ˆâ–‚â–‚â–â–‚â–‡â–â–â–â–â–
wandb:         valid_loss â–‚â–†â–‚â–…â–‚â–â–â–‚â–â–ˆâ–‚â–‚â–â–â–ˆâ–â–â–â–â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1416
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.6399
wandb:   test_error_force 9.71181
wandb:          test_loss 5.88887
wandb: train_error_energy 2.34573
wandb:  train_error_force 2.56107
wandb:         train_loss -1.7539
wandb: valid_error_energy 2.69281
wandb:  valid_error_force 2.41624
wandb:         valid_loss -1.86924
wandb: 
wandb: ğŸš€ View run al_58_7 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kz6kcxh9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_154716-kz6kcxh9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 25.758256912231445, Uncertainty Bias: -4.20222282409668
9.918213e-05 0.041643977
-4.0559382 43.070427
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 58 steps.
Found uncertainty sample 1 after 170 steps.
Found uncertainty sample 2 after 30 steps.
Found uncertainty sample 3 after 58 steps.
Found uncertainty sample 4 after 243 steps.
Found uncertainty sample 5 after 1014 steps.
Found uncertainty sample 6 after 29 steps.
Found uncertainty sample 7 after 45 steps.
Found uncertainty sample 8 after 282 steps.
Found uncertainty sample 9 after 183 steps.
Found uncertainty sample 10 after 164 steps.
Found uncertainty sample 11 after 97 steps.
Found uncertainty sample 12 after 124 steps.
Found uncertainty sample 13 after 167 steps.
Found uncertainty sample 14 after 71 steps.
Found uncertainty sample 15 after 137 steps.
Found uncertainty sample 16 after 172 steps.
Found uncertainty sample 17 after 146 steps.
Found uncertainty sample 18 after 674 steps.
Found uncertainty sample 19 after 360 steps.
Found uncertainty sample 20 after 792 steps.
Found uncertainty sample 21 after 1 steps.
Found uncertainty sample 22 after 12 steps.
Found uncertainty sample 23 after 19 steps.
Found uncertainty sample 24 after 93 steps.
Found uncertainty sample 25 after 148 steps.
Found uncertainty sample 26 after 360 steps.
Found uncertainty sample 27 after 608 steps.
Found uncertainty sample 28 after 92 steps.
Found uncertainty sample 29 after 61 steps.
Found uncertainty sample 30 after 32 steps.
Found uncertainty sample 31 after 70 steps.
Found uncertainty sample 32 after 134 steps.
Found uncertainty sample 33 after 300 steps.
Found uncertainty sample 34 after 128 steps.
Found uncertainty sample 35 after 511 steps.
Found uncertainty sample 36 after 114 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 80 steps.
Found uncertainty sample 39 after 141 steps.
Found uncertainty sample 40 after 130 steps.
Found uncertainty sample 41 after 231 steps.
Found uncertainty sample 42 after 184 steps.
Found uncertainty sample 43 after 292 steps.
Found uncertainty sample 44 after 24 steps.
Found uncertainty sample 45 after 342 steps.
Found uncertainty sample 46 after 422 steps.
Found uncertainty sample 47 after 545 steps.
Found uncertainty sample 48 after 507 steps.
Found uncertainty sample 49 after 368 steps.
Found uncertainty sample 50 after 178 steps.
Found uncertainty sample 51 after 617 steps.
Found uncertainty sample 52 after 68 steps.
Found uncertainty sample 53 after 67 steps.
Found uncertainty sample 54 after 46 steps.
Found uncertainty sample 55 after 574 steps.
Found uncertainty sample 56 after 13 steps.
Found uncertainty sample 57 after 1 steps.
Found uncertainty sample 58 after 575 steps.
Found uncertainty sample 59 after 132 steps.
Found uncertainty sample 60 after 818 steps.
Found uncertainty sample 61 after 3 steps.
Found uncertainty sample 62 after 143 steps.
Found uncertainty sample 63 after 71 steps.
Found uncertainty sample 64 after 232 steps.
Found uncertainty sample 65 after 225 steps.
Found uncertainty sample 66 after 11 steps.
Found uncertainty sample 67 after 127 steps.
Found uncertainty sample 68 after 28 steps.
Found uncertainty sample 69 after 57 steps.
Found uncertainty sample 70 after 795 steps.
Found uncertainty sample 71 after 69 steps.
Found uncertainty sample 72 after 669 steps.
Found uncertainty sample 73 after 286 steps.
Found uncertainty sample 74 after 22 steps.
Found uncertainty sample 75 after 147 steps.
Found uncertainty sample 76 after 1063 steps.
Found uncertainty sample 77 after 373 steps.
Found uncertainty sample 78 after 313 steps.
Found uncertainty sample 79 after 180 steps.
Found uncertainty sample 80 after 305 steps.
Found uncertainty sample 81 after 157 steps.
Found uncertainty sample 82 after 28 steps.
Found uncertainty sample 83 after 53 steps.
Found uncertainty sample 84 after 21 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 126 steps.
Found uncertainty sample 87 after 160 steps.
Found uncertainty sample 88 after 203 steps.
Found uncertainty sample 89 after 379 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 457 steps.
Found uncertainty sample 92 after 62 steps.
Found uncertainty sample 93 after 13 steps.
Found uncertainty sample 94 after 391 steps.
Found uncertainty sample 95 after 352 steps.
Found uncertainty sample 96 after 235 steps.
Found uncertainty sample 97 after 20 steps.
Found uncertainty sample 98 after 2 steps.
Found uncertainty sample 99 after 196 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_155528-gaj59rmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_8
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/gaj59rmk
Training model 8. Added 103 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.426159196258593, Training Loss Force: 2.8049251432310385, time: 0.703484058380127
Validation Loss Energy: 1.9538961485645565, Validation Loss Force: 3.0950596006005355, time: 0.06210732460021973
Test Loss Energy: 13.362635035050031, Test Loss Force: 9.684970188057365, time: 8.675232172012329


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0659760229935142, Training Loss Force: 2.588147797390327, time: 0.7050385475158691
Validation Loss Energy: 3.7168630792693103, Validation Loss Force: 3.46856304462664, time: 0.05909013748168945
Test Loss Energy: 14.323049697331893, Test Loss Force: 9.836130734926098, time: 8.781235933303833


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.736768234179164, Training Loss Force: 2.58484674585771, time: 0.7167601585388184
Validation Loss Energy: 1.8994588307774283, Validation Loss Force: 2.510331648074467, time: 0.060292720794677734
Test Loss Energy: 13.26717247735763, Test Loss Force: 9.769659923868446, time: 8.96071982383728


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9724590025055564, Training Loss Force: 2.5531484731563054, time: 0.7418832778930664
Validation Loss Energy: 1.9692176228248424, Validation Loss Force: 2.700080942129999, time: 0.059958457946777344
Test Loss Energy: 11.726653291832804, Test Loss Force: 9.726239384453788, time: 8.731908082962036


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.432609312053151, Training Loss Force: 2.5442320629618105, time: 0.7046341896057129
Validation Loss Energy: 1.7910652162256622, Validation Loss Force: 2.455207006301146, time: 0.059734344482421875
Test Loss Energy: 13.312731004304995, Test Loss Force: 9.750418712242185, time: 8.788654327392578


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.83777766121021, Training Loss Force: 2.5710675291304654, time: 0.7431881427764893
Validation Loss Energy: 1.3807085255317744, Validation Loss Force: 2.4171646507268214, time: 0.058061838150024414
Test Loss Energy: 11.534356138134687, Test Loss Force: 9.859264940013231, time: 8.73750615119934


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.338513332070284, Training Loss Force: 2.6450003981254526, time: 0.9126427173614502
Validation Loss Energy: 2.5117795541958623, Validation Loss Force: 2.807472044519512, time: 0.06021285057067871
Test Loss Energy: 13.875094243268032, Test Loss Force: 9.815785928380338, time: 8.634803533554077


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.063153627783447, Training Loss Force: 2.5642009229535123, time: 0.730095624923706
Validation Loss Energy: 2.016817327813393, Validation Loss Force: 3.328032538586986, time: 0.059133291244506836
Test Loss Energy: 13.350734602624046, Test Loss Force: 9.666320278428442, time: 9.021690845489502


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.2986819629491144, Training Loss Force: 2.5413620501868337, time: 0.729295015335083
Validation Loss Energy: 3.7330373206912126, Validation Loss Force: 3.5492028984935335, time: 0.059580326080322266
Test Loss Energy: 11.513842560034382, Test Loss Force: 9.67753390594382, time: 8.699851036071777


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0936874417486058, Training Loss Force: 2.5476822657106752, time: 0.7312338352203369
Validation Loss Energy: 0.8746806167742072, Validation Loss Force: 2.6459113283235625, time: 0.05919051170349121
Test Loss Energy: 12.098331734875654, Test Loss Force: 9.661693306840625, time: 8.942125797271729


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6750054764143156, Training Loss Force: 2.5421263249187067, time: 0.7291004657745361
Validation Loss Energy: 2.7967446244107217, Validation Loss Force: 2.4795316064714434, time: 0.05812406539916992
Test Loss Energy: 14.206511628552974, Test Loss Force: 9.662986205508375, time: 8.702232599258423


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8083066435993587, Training Loss Force: 2.493939413558701, time: 0.7189621925354004
Validation Loss Energy: 4.283238974791729, Validation Loss Force: 2.7034730838990626, time: 0.06487178802490234
Test Loss Energy: 15.961333876823842, Test Loss Force: 9.744461372948136, time: 8.74561858177185


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0711031969489717, Training Loss Force: 2.530111304237298, time: 0.7356336116790771
Validation Loss Energy: 0.7460807235733644, Validation Loss Force: 2.3998439972071095, time: 0.05849003791809082
Test Loss Energy: 12.342266912740767, Test Loss Force: 9.707760060375172, time: 8.964373111724854


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8523980117959307, Training Loss Force: 2.532586763521982, time: 0.8000545501708984
Validation Loss Energy: 1.840800986331098, Validation Loss Force: 2.408233391283658, time: 0.06621360778808594
Test Loss Energy: 13.76198451456698, Test Loss Force: 9.717853324002492, time: 8.738021850585938


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.4044045199366457, Training Loss Force: 2.555154673452239, time: 0.6971652507781982
Validation Loss Energy: 1.1725056930093365, Validation Loss Force: 2.393008054427127, time: 0.06499242782592773
Test Loss Energy: 12.147943586395412, Test Loss Force: 9.670008738037804, time: 8.802471399307251


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3083319384179615, Training Loss Force: 2.46692483789579, time: 0.6854555606842041
Validation Loss Energy: 2.660677076062899, Validation Loss Force: 2.40413639033316, time: 0.06003546714782715
Test Loss Energy: 14.418545639074887, Test Loss Force: 9.649445939563984, time: 8.825989246368408


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.185036757225724, Training Loss Force: 2.491411130658086, time: 0.7017474174499512
Validation Loss Energy: 1.391540321802718, Validation Loss Force: 3.074783570841497, time: 0.06021881103515625
Test Loss Energy: 13.273462668553208, Test Loss Force: 9.676342609691808, time: 8.67735481262207


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7190825288403808, Training Loss Force: 2.502010168087427, time: 0.7318224906921387
Validation Loss Energy: 1.7455352766157965, Validation Loss Force: 2.4416057068604395, time: 0.058837175369262695
Test Loss Energy: 11.519223570956804, Test Loss Force: 9.680328280149666, time: 9.077956438064575


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2876789367532777, Training Loss Force: 2.5026540112839366, time: 0.7165367603302002
Validation Loss Energy: 3.4317353492433504, Validation Loss Force: 3.0669010830756536, time: 0.05919694900512695
Test Loss Energy: 15.0517207161942, Test Loss Force: 9.703616805447188, time: 8.935694456100464


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8391871395079054, Training Loss Force: 2.509135228197635, time: 0.7426786422729492
Validation Loss Energy: 1.3694950743447105, Validation Loss Force: 2.490386727335423, time: 0.06584858894348145
Test Loss Energy: 11.938791539494378, Test Loss Force: 9.582577560324026, time: 8.766503810882568

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–„â–â–„â–â–…â–„â–â–‚â–…â–ˆâ–‚â–…â–‚â–†â–„â–â–‡â–‚
wandb:   test_error_force â–„â–‡â–†â–…â–…â–ˆâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–…â–„â–„â–ƒâ–ƒâ–ƒâ–ƒâ–„â–
wandb:          test_loss â–â–„â–„â–‚â–„â–„â–†â–‚â–ƒâ–ƒâ–…â–ˆâ–…â–…â–ƒâ–†â–†â–ƒâ–†â–‚
wandb: train_error_energy â–ˆâ–‚â–„â–‚â–ƒâ–â–ƒâ–‚â–…â–‚â–â–â–‚â–â–ƒâ–ƒâ–‚â–â–ƒâ–
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–„â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–â–â–‚â–
wandb: valid_error_energy â–ƒâ–‡â–ƒâ–ƒâ–ƒâ–‚â–„â–„â–‡â–â–…â–ˆâ–â–ƒâ–‚â–…â–‚â–ƒâ–†â–‚
wandb:  valid_error_force â–…â–ˆâ–‚â–ƒâ–â–â–„â–‡â–ˆâ–ƒâ–‚â–ƒâ–â–â–â–â–…â–â–…â–‚
wandb:         valid_loss â–…â–‡â–‚â–ƒâ–‚â–â–„â–†â–ˆâ–‚â–‚â–„â–â–â–â–‚â–…â–‚â–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1508
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.93879
wandb:   test_error_force 9.58258
wandb:          test_loss 5.60816
wandb: train_error_energy 1.83919
wandb:  train_error_force 2.50914
wandb:         train_loss -1.8386
wandb: valid_error_energy 1.3695
wandb:  valid_error_force 2.49039
wandb:         valid_loss -1.88644
wandb: 
wandb: ğŸš€ View run al_58_8 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/gaj59rmk
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_155528-gaj59rmk/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 27.07642364501953, Uncertainty Bias: -4.442006587982178
0.00018310547 0.011238098
-4.1336584 37.226734
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 290 steps.
Found uncertainty sample 1 after 164 steps.
Found uncertainty sample 2 after 87 steps.
Found uncertainty sample 3 after 15 steps.
Found uncertainty sample 4 after 115 steps.
Found uncertainty sample 5 after 57 steps.
Found uncertainty sample 6 after 739 steps.
Found uncertainty sample 7 after 284 steps.
Found uncertainty sample 8 after 119 steps.
Found uncertainty sample 9 after 1479 steps.
Found uncertainty sample 10 after 547 steps.
Found uncertainty sample 11 after 433 steps.
Found uncertainty sample 12 after 94 steps.
Found uncertainty sample 13 after 201 steps.
Found uncertainty sample 14 after 39 steps.
Found uncertainty sample 15 after 705 steps.
Found uncertainty sample 16 after 170 steps.
Found uncertainty sample 17 after 81 steps.
Found uncertainty sample 18 after 459 steps.
Found uncertainty sample 19 after 75 steps.
Found uncertainty sample 20 after 1 steps.
Found uncertainty sample 21 after 147 steps.
Found uncertainty sample 22 after 267 steps.
Found uncertainty sample 23 after 13 steps.
Found uncertainty sample 24 after 384 steps.
Found uncertainty sample 25 after 281 steps.
Found uncertainty sample 26 after 46 steps.
Found uncertainty sample 27 after 125 steps.
Found uncertainty sample 28 after 59 steps.
Found uncertainty sample 29 after 33 steps.
Found uncertainty sample 30 after 1 steps.
Found uncertainty sample 31 after 511 steps.
Found uncertainty sample 32 after 264 steps.
Found uncertainty sample 33 after 355 steps.
Found uncertainty sample 34 after 512 steps.
Found uncertainty sample 35 after 47 steps.
Found uncertainty sample 36 after 184 steps.
Found uncertainty sample 37 after 75 steps.
Found uncertainty sample 38 after 629 steps.
Found uncertainty sample 39 after 324 steps.
Found uncertainty sample 40 after 309 steps.
Found uncertainty sample 41 after 23 steps.
Found uncertainty sample 42 after 285 steps.
Found uncertainty sample 43 after 225 steps.
Found uncertainty sample 44 after 978 steps.
Found uncertainty sample 45 after 284 steps.
Found uncertainty sample 46 after 48 steps.
Found uncertainty sample 47 after 133 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 14 steps.
Found uncertainty sample 50 after 27 steps.
Found uncertainty sample 51 after 73 steps.
Found uncertainty sample 52 after 39 steps.
Found uncertainty sample 53 after 16 steps.
Found uncertainty sample 54 after 126 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 437 steps.
Found uncertainty sample 57 after 1324 steps.
Found uncertainty sample 58 after 241 steps.
Found uncertainty sample 59 after 1 steps.
Found uncertainty sample 60 after 1367 steps.
Found uncertainty sample 61 after 231 steps.
Found uncertainty sample 62 after 1960 steps.
Found uncertainty sample 63 after 71 steps.
Found uncertainty sample 64 after 1 steps.
Found uncertainty sample 65 after 158 steps.
Found uncertainty sample 66 after 315 steps.
Found uncertainty sample 67 after 86 steps.
Found uncertainty sample 68 after 446 steps.
Found uncertainty sample 69 after 192 steps.
Found uncertainty sample 70 after 89 steps.
Found uncertainty sample 71 after 96 steps.
Found uncertainty sample 72 after 68 steps.
Found uncertainty sample 73 after 306 steps.
Found uncertainty sample 74 after 14 steps.
Found uncertainty sample 75 after 1 steps.
Found uncertainty sample 76 after 1 steps.
Found uncertainty sample 77 after 132 steps.
Found uncertainty sample 78 after 134 steps.
Found uncertainty sample 79 after 341 steps.
Found uncertainty sample 80 after 56 steps.
Found uncertainty sample 81 after 32 steps.
Found uncertainty sample 82 after 382 steps.
Found uncertainty sample 83 after 376 steps.
Found uncertainty sample 84 after 224 steps.
Found uncertainty sample 85 after 12 steps.
Found uncertainty sample 86 after 246 steps.
Found uncertainty sample 87 after 116 steps.
Found uncertainty sample 88 after 197 steps.
Found uncertainty sample 89 after 443 steps.
Found uncertainty sample 90 after 470 steps.
Found uncertainty sample 91 after 195 steps.
Found uncertainty sample 92 after 21 steps.
Found uncertainty sample 93 after 4 steps.
Found uncertainty sample 94 after 344 steps.
Found uncertainty sample 95 after 7 steps.
Found uncertainty sample 96 after 42 steps.
Found uncertainty sample 97 after 34 steps.
Found uncertainty sample 98 after 186 steps.
Found uncertainty sample 99 after 204 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_160335-6xxg474n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_9
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6xxg474n
Training model 9. Added 105 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0247219331731188, Training Loss Force: 2.717781233445333, time: 0.7746143341064453
Validation Loss Energy: 0.9980074262630475, Validation Loss Force: 2.3641267528545624, time: 0.06223917007446289
Test Loss Energy: 12.016033223203975, Test Loss Force: 9.689102712897288, time: 7.99415135383606


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6989748744082867, Training Loss Force: 2.4821262543283056, time: 0.7793023586273193
Validation Loss Energy: 1.7829133544605322, Validation Loss Force: 2.6957633873904596, time: 0.057028770446777344
Test Loss Energy: 11.48631567793323, Test Loss Force: 9.657194504079527, time: 7.9557294845581055


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7042855837483741, Training Loss Force: 2.500433932497959, time: 0.7634921073913574
Validation Loss Energy: 1.7602199727860153, Validation Loss Force: 2.575526167968653, time: 0.05717062950134277
Test Loss Energy: 11.548207259533244, Test Loss Force: 9.634318693129464, time: 7.9839560985565186


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.128703248138366, Training Loss Force: 2.4456730797163444, time: 0.9088637828826904
Validation Loss Energy: 2.448611880202484, Validation Loss Force: 2.9288700381990393, time: 0.08867430686950684
Test Loss Energy: 11.44751295152623, Test Loss Force: 9.708771621823173, time: 10.260991334915161


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.578807909285052, Training Loss Force: 2.4360840097724616, time: 0.7794511318206787
Validation Loss Energy: 1.642079795713271, Validation Loss Force: 2.5293406903931768, time: 0.06746268272399902
Test Loss Energy: 13.457099755174992, Test Loss Force: 9.753406824926289, time: 10.821805000305176


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8335207301922403, Training Loss Force: 2.517981188985177, time: 0.7992973327636719
Validation Loss Energy: 2.657936130211101, Validation Loss Force: 2.576311188042622, time: 0.061594247817993164
Test Loss Energy: 14.454695193825543, Test Loss Force: 9.587592601098333, time: 9.176960468292236


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7920457976600723, Training Loss Force: 2.4321935802984593, time: 0.8114302158355713
Validation Loss Energy: 0.9272964452803596, Validation Loss Force: 2.629233965966436, time: 0.06352043151855469
Test Loss Energy: 12.789067229223978, Test Loss Force: 9.708324306322567, time: 8.923049449920654


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6650809121507948, Training Loss Force: 2.4449376646522083, time: 0.8068239688873291
Validation Loss Energy: 1.5573745042473137, Validation Loss Force: 3.157468863482884, time: 0.06688332557678223
Test Loss Energy: 11.624779769998009, Test Loss Force: 9.720396252281269, time: 8.856452226638794


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1041124797495754, Training Loss Force: 2.4449309256359975, time: 0.7438828945159912
Validation Loss Energy: 0.9742985341148835, Validation Loss Force: 2.4673778791484136, time: 0.0611572265625
Test Loss Energy: 12.585842495090697, Test Loss Force: 9.687708892645116, time: 9.407332181930542


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.950080450785383, Training Loss Force: 2.4687458448633897, time: 0.7263970375061035
Validation Loss Energy: 3.537336971041615, Validation Loss Force: 2.386750383419118, time: 0.06335639953613281
Test Loss Energy: 11.246341739873507, Test Loss Force: 9.585885617094036, time: 8.929290056228638


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.3275705108074374, Training Loss Force: 2.4723637818785478, time: 0.7462673187255859
Validation Loss Energy: 1.7183441451953976, Validation Loss Force: 2.401563782355683, time: 0.060645103454589844
Test Loss Energy: 13.3284503221695, Test Loss Force: 9.565275710689074, time: 8.896836757659912


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1003679662401114, Training Loss Force: 2.4283452724045618, time: 0.7321264743804932
Validation Loss Energy: 1.6909511085269289, Validation Loss Force: 2.603257828740792, time: 0.06141257286071777
Test Loss Energy: 13.299894918459435, Test Loss Force: 9.80640321482155, time: 8.874300956726074


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7667399567800504, Training Loss Force: 2.464859172385467, time: 0.9755268096923828
Validation Loss Energy: 1.4516063815951818, Validation Loss Force: 2.883253034953116, time: 0.0640254020690918
Test Loss Energy: 12.727933701998037, Test Loss Force: 9.642753829394202, time: 8.898218393325806


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2882502504555413, Training Loss Force: 2.499488533880121, time: 0.7310194969177246
Validation Loss Energy: 1.9477575498823327, Validation Loss Force: 2.3233017009635786, time: 0.06154894828796387
Test Loss Energy: 11.782601127448933, Test Loss Force: 9.594954444100331, time: 8.886151552200317


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7027283536254205, Training Loss Force: 2.4850840231694353, time: 0.755007266998291
Validation Loss Energy: 2.8974094485746207, Validation Loss Force: 3.0348752478242975, time: 0.0632486343383789
Test Loss Energy: 14.920493040282878, Test Loss Force: 9.562473553555384, time: 8.919888019561768


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8929616627302428, Training Loss Force: 2.470609902154277, time: 0.7395505905151367
Validation Loss Energy: 0.7884699983808481, Validation Loss Force: 2.5027350674919946, time: 0.060718536376953125
Test Loss Energy: 12.761311032876733, Test Loss Force: 9.685790202744359, time: 9.081102848052979


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5329975222519518, Training Loss Force: 2.4530583276320534, time: 0.7325079441070557
Validation Loss Energy: 1.0775346859086703, Validation Loss Force: 2.428027119672617, time: 0.060923099517822266
Test Loss Energy: 12.394360063315583, Test Loss Force: 9.586165149644476, time: 8.896406888961792


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5570835739099738, Training Loss Force: 2.434875824450905, time: 0.752593994140625
Validation Loss Energy: 2.5297008577367146, Validation Loss Force: 2.7289197138956904, time: 0.06692242622375488
Test Loss Energy: 14.064071691452128, Test Loss Force: 9.59376962507227, time: 8.899209022521973


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7638251838228773, Training Loss Force: 2.446232086241134, time: 0.7724874019622803
Validation Loss Energy: 2.8918564140789007, Validation Loss Force: 2.542148396997797, time: 0.0658259391784668
Test Loss Energy: 11.43250877701002, Test Loss Force: 9.5984987913058, time: 9.033649921417236


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9709614529666293, Training Loss Force: 2.41530506646613, time: 0.7679846286773682
Validation Loss Energy: 0.9786875378166229, Validation Loss Force: 2.807763184427812, time: 0.06668257713317871
Test Loss Energy: 12.563127378983959, Test Loss Force: 9.646945852362562, time: 9.288287162780762

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–â–…â–‡â–„â–‚â–„â–â–…â–…â–„â–‚â–ˆâ–„â–ƒâ–†â–â–„
wandb:   test_error_force â–…â–„â–ƒâ–…â–†â–‚â–…â–†â–…â–‚â–â–ˆâ–ƒâ–‚â–â–…â–‚â–‚â–‚â–ƒ
wandb:          test_loss â–â–ƒâ–„â–„â–ˆâ–†â–‡â–†â–†â–„â–…â–ˆâ–…â–„â–…â–…â–…â–‡â–†â–‡
wandb: train_error_energy â–ˆâ–‚â–‚â–„â–â–‚â–‚â–‚â–„â–ƒâ–…â–„â–‚â–…â–‚â–ƒâ–â–â–‚â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–â–ƒâ–â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–ƒâ–â–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–â–â–
wandb: valid_error_energy â–‚â–„â–ƒâ–…â–ƒâ–†â–â–ƒâ–â–ˆâ–ƒâ–ƒâ–ƒâ–„â–†â–â–‚â–…â–†â–
wandb:  valid_error_force â–â–„â–ƒâ–†â–ƒâ–ƒâ–„â–ˆâ–‚â–‚â–‚â–ƒâ–†â–â–‡â–ƒâ–‚â–„â–ƒâ–…
wandb:         valid_loss â–â–„â–ƒâ–†â–ƒâ–„â–ƒâ–ˆâ–‚â–ƒâ–‚â–ƒâ–†â–â–ˆâ–‚â–‚â–…â–„â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 1602
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.56313
wandb:   test_error_force 9.64695
wandb:          test_loss 6.07392
wandb: train_error_energy 1.97096
wandb:  train_error_force 2.41531
wandb:         train_loss -1.92287
wandb: valid_error_energy 0.97869
wandb:  valid_error_force 2.80776
wandb:         valid_loss -1.57725
wandb: 
wandb: ğŸš€ View run al_58_9 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/6xxg474n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_160335-6xxg474n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 28.890230178833008, Uncertainty Bias: -4.443544387817383
/home/ws/fq0795/git/gnn_uncertainty/datasets/helper/cv_visualizer.py:240: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  fig, ax = plt.subplots(figsize=(8, 8))
0.00034332275 0.002137661
-3.207697 36.02848
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 500 steps.
Found uncertainty sample 1 after 57 steps.
Found uncertainty sample 2 after 590 steps.
Found uncertainty sample 3 after 508 steps.
Found uncertainty sample 4 after 32 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 202 steps.
Found uncertainty sample 7 after 208 steps.
Found uncertainty sample 8 after 1 steps.
Found uncertainty sample 9 after 46 steps.
Found uncertainty sample 10 after 156 steps.
Found uncertainty sample 11 after 202 steps.
Found uncertainty sample 12 after 153 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 3 steps.
Found uncertainty sample 15 after 666 steps.
Found uncertainty sample 16 after 173 steps.
Found uncertainty sample 17 after 38 steps.
Found uncertainty sample 18 after 272 steps.
Found uncertainty sample 19 after 147 steps.
Found uncertainty sample 20 after 508 steps.
Found uncertainty sample 21 after 48 steps.
Found uncertainty sample 22 after 317 steps.
Found uncertainty sample 23 after 137 steps.
Found uncertainty sample 24 after 43 steps.
Found uncertainty sample 25 after 18 steps.
Found uncertainty sample 26 after 63 steps.
Found uncertainty sample 27 after 324 steps.
Found uncertainty sample 28 after 582 steps.
Found uncertainty sample 29 after 5 steps.
Found uncertainty sample 30 after 481 steps.
Found uncertainty sample 31 after 1 steps.
Found uncertainty sample 32 after 106 steps.
Found uncertainty sample 33 after 391 steps.
Found uncertainty sample 34 after 718 steps.
Found uncertainty sample 35 after 25 steps.
Found uncertainty sample 36 after 114 steps.
Found uncertainty sample 37 after 198 steps.
Found uncertainty sample 38 after 902 steps.
Found uncertainty sample 39 after 26 steps.
Found uncertainty sample 40 after 110 steps.
Found uncertainty sample 41 after 55 steps.
Found uncertainty sample 42 after 180 steps.
Found uncertainty sample 43 after 178 steps.
Found uncertainty sample 44 after 82 steps.
Found uncertainty sample 45 after 243 steps.
Found uncertainty sample 46 after 466 steps.
Found uncertainty sample 47 after 431 steps.
Found uncertainty sample 48 after 116 steps.
Found uncertainty sample 49 after 29 steps.
Found uncertainty sample 50 after 378 steps.
Found uncertainty sample 51 after 150 steps.
Found uncertainty sample 52 after 209 steps.
Found uncertainty sample 53 after 233 steps.
Found uncertainty sample 54 after 128 steps.
Found uncertainty sample 55 after 1 steps.
Found uncertainty sample 56 after 183 steps.
Found uncertainty sample 57 after 17 steps.
Found uncertainty sample 58 after 403 steps.
Found uncertainty sample 59 after 6 steps.
Found uncertainty sample 60 after 394 steps.
Found uncertainty sample 61 after 28 steps.
Found uncertainty sample 62 after 226 steps.
Found uncertainty sample 63 after 105 steps.
Found uncertainty sample 64 after 22 steps.
Found uncertainty sample 65 after 84 steps.
Found uncertainty sample 66 after 538 steps.
Found uncertainty sample 67 after 412 steps.
Found uncertainty sample 68 after 1040 steps.
Found uncertainty sample 69 after 254 steps.
Found uncertainty sample 70 after 104 steps.
Found uncertainty sample 71 after 393 steps.
Found uncertainty sample 72 after 91 steps.
Found uncertainty sample 73 after 54 steps.
Found uncertainty sample 74 after 134 steps.
Found uncertainty sample 75 after 59 steps.
Found uncertainty sample 76 after 579 steps.
Found uncertainty sample 77 after 105 steps.
Found uncertainty sample 78 after 407 steps.
Found uncertainty sample 79 after 564 steps.
Found uncertainty sample 80 after 361 steps.
Found uncertainty sample 81 after 16 steps.
Found uncertainty sample 82 after 131 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 460 steps.
Found uncertainty sample 85 after 82 steps.
Found uncertainty sample 86 after 590 steps.
Found uncertainty sample 87 after 488 steps.
Found uncertainty sample 88 after 1259 steps.
Found uncertainty sample 89 after 119 steps.
Found uncertainty sample 90 after 1 steps.
Found uncertainty sample 91 after 35 steps.
Found uncertainty sample 92 after 469 steps.
Found uncertainty sample 93 after 327 steps.
Found uncertainty sample 94 after 685 steps.
Found uncertainty sample 95 after 67 steps.
Found uncertainty sample 96 after 344 steps.
Found uncertainty sample 97 after 1 steps.
Found uncertainty sample 98 after 218 steps.
Found uncertainty sample 99 after 112 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_161144-st1s5jd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_10
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/st1s5jd4
Training model 10. Added 108 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.73647238226701, Training Loss Force: 2.873572510327916, time: 0.83211350440979
Validation Loss Energy: 1.866874708309945, Validation Loss Force: 2.829919766458784, time: 0.07963180541992188
Test Loss Energy: 11.793618153263951, Test Loss Force: 9.572486950073543, time: 10.1921968460083


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7068396674963575, Training Loss Force: 2.3949047852619123, time: 0.8239905834197998
Validation Loss Energy: 2.0681176270054045, Validation Loss Force: 2.3851697664867495, time: 0.07216978073120117
Test Loss Energy: 11.506421946367544, Test Loss Force: 9.565277687897824, time: 10.339234352111816


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6410809885181958, Training Loss Force: 2.3503057923631494, time: 0.8501214981079102
Validation Loss Energy: 1.477904220069405, Validation Loss Force: 2.849808463238481, time: 0.06967329978942871
Test Loss Energy: 12.25738290218019, Test Loss Force: 9.505187548652263, time: 10.442518711090088


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0847991211122388, Training Loss Force: 2.3905452656353705, time: 0.910658597946167
Validation Loss Energy: 1.0719374515874835, Validation Loss Force: 2.380859782498171, time: 0.07300066947937012
Test Loss Energy: 12.200666547905934, Test Loss Force: 9.539931932853339, time: 10.34627652168274


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1869635116702644, Training Loss Force: 2.367970376934509, time: 0.888434648513794
Validation Loss Energy: 1.6743816293710043, Validation Loss Force: 2.8484832478164916, time: 0.07051968574523926
Test Loss Energy: 13.221054274426495, Test Loss Force: 9.486031571510804, time: 10.282691717147827


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7592157648332758, Training Loss Force: 2.4049946170123544, time: 0.8269109725952148
Validation Loss Energy: 1.09245719272674, Validation Loss Force: 2.650620780759935, time: 0.07307100296020508
Test Loss Energy: 13.213761549792686, Test Loss Force: 9.668115145631148, time: 10.579866409301758


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8240220651950394, Training Loss Force: 2.408275702544887, time: 0.8721194267272949
Validation Loss Energy: 2.170877322494192, Validation Loss Force: 2.4030806045777426, time: 0.07074189186096191
Test Loss Energy: 14.12703755491926, Test Loss Force: 9.577705508115615, time: 10.434374332427979


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8561085509858932, Training Loss Force: 2.3722803361820706, time: 0.9012329578399658
Validation Loss Energy: 1.6355137279381524, Validation Loss Force: 2.7920608902607036, time: 0.0741736888885498
Test Loss Energy: 12.165758568333603, Test Loss Force: 9.572169971800765, time: 10.953022003173828


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8388936982985187, Training Loss Force: 2.37053788001564, time: 0.934971809387207
Validation Loss Energy: 3.343590877151252, Validation Loss Force: 2.377005268247588, time: 0.07376790046691895
Test Loss Energy: 11.41911327165824, Test Loss Force: 9.485502281121898, time: 10.352169513702393


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.955000655566153, Training Loss Force: 2.3623133332683754, time: 0.8504385948181152
Validation Loss Energy: 0.7673729318134875, Validation Loss Force: 2.4938333117106666, time: 0.06939578056335449
Test Loss Energy: 12.806591099816139, Test Loss Force: 9.594076950462702, time: 10.36492657661438


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.611117211818974, Training Loss Force: 2.389105921967337, time: 0.8176455497741699
Validation Loss Energy: 1.9865076593369893, Validation Loss Force: 3.2126712167881335, time: 0.07103753089904785
Test Loss Energy: 13.55049147115735, Test Loss Force: 9.440169431102643, time: 10.462540864944458


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2369224003834227, Training Loss Force: 2.6335359709772854, time: 0.8494794368743896
Validation Loss Energy: 1.978881074087103, Validation Loss Force: 2.620862385421562, time: 0.07192659378051758
Test Loss Energy: 13.899001271172907, Test Loss Force: 9.456388558427458, time: 10.228460311889648


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8983484080957675, Training Loss Force: 2.3696152132979638, time: 0.8516936302185059
Validation Loss Energy: 1.0028579674370086, Validation Loss Force: 2.501063267544369, time: 0.06533503532409668
Test Loss Energy: 13.173049175484383, Test Loss Force: 9.54882252195187, time: 10.48125410079956


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7030285984702462, Training Loss Force: 2.3335281010617717, time: 0.8095612525939941
Validation Loss Energy: 2.516946257723398, Validation Loss Force: 2.35219680802319, time: 0.0669548511505127
Test Loss Energy: 11.49952998422735, Test Loss Force: 9.530387088176946, time: 10.612693786621094


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2830909911844577, Training Loss Force: 2.3660719575253664, time: 0.903977632522583
Validation Loss Energy: 2.392957285861855, Validation Loss Force: 2.53557787583976, time: 0.07248449325561523
Test Loss Energy: 14.599897417459081, Test Loss Force: 9.56479654067672, time: 10.429839611053467


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6076445493817655, Training Loss Force: 2.349308894349825, time: 0.8769738674163818
Validation Loss Energy: 1.1396297069588281, Validation Loss Force: 2.471378464358725, time: 0.07742929458618164
Test Loss Energy: 13.340198388277704, Test Loss Force: 9.542152011855046, time: 10.11449146270752


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.4118101206203173, Training Loss Force: 2.357331403896933, time: 0.8005838394165039
Validation Loss Energy: 4.277316643517487, Validation Loss Force: 2.3742806885780157, time: 0.05946159362792969
Test Loss Energy: 15.896598397534635, Test Loss Force: 9.485900823918897, time: 9.512006044387817


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1151885432852846, Training Loss Force: 2.393448508430031, time: 0.8691844940185547
Validation Loss Energy: 2.6435276551164053, Validation Loss Force: 2.502729389428773, time: 0.06860733032226562
Test Loss Energy: 14.462305377044638, Test Loss Force: 9.587762020841595, time: 10.034735679626465


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.168996035207902, Training Loss Force: 2.353787822367622, time: 0.8522920608520508
Validation Loss Energy: 1.7363218953647426, Validation Loss Force: 2.342735930016437, time: 0.05936098098754883
Test Loss Energy: 14.220185011009189, Test Loss Force: 9.509751254223264, time: 8.585088968276978


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.26464575126674, Training Loss Force: 2.3545549959218945, time: 0.796931266784668
Validation Loss Energy: 3.763033526677437, Validation Loss Force: 2.4472485883565414, time: 0.05844593048095703
Test Loss Energy: 11.284081446109463, Test Loss Force: 9.479810960343002, time: 8.1502046585083

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–‚â–‚â–„â–„â–…â–‚â–â–ƒâ–„â–…â–„â–â–†â–„â–ˆâ–†â–…â–
wandb:   test_error_force â–…â–…â–ƒâ–„â–‚â–ˆâ–…â–…â–‚â–†â–â–â–„â–„â–…â–„â–‚â–†â–ƒâ–‚
wandb:          test_loss â–â–â–‚â–‚â–‚â–†â–…â–ƒâ–‚â–†â–„â–ƒâ–‚â–‚â–†â–…â–‡â–ˆâ–†â–ƒ
wandb: train_error_energy â–ˆâ–‚â–â–„â–…â–‚â–‚â–ƒâ–‚â–ƒâ–â–…â–ƒâ–‚â–…â–â–†â–„â–„â–…
wandb:  train_error_force â–ˆâ–‚â–â–‚â–â–‚â–‚â–‚â–â–â–‚â–…â–â–â–â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–‚â–â–‚â–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–„â–‚â–‚â–ƒâ–‚â–„â–ƒâ–†â–â–ƒâ–ƒâ–â–„â–„â–‚â–ˆâ–…â–ƒâ–‡
wandb:  valid_error_force â–…â–â–…â–â–…â–ƒâ–â–…â–â–‚â–ˆâ–ƒâ–‚â–â–ƒâ–‚â–â–‚â–â–‚
wandb:         valid_loss â–…â–‚â–…â–â–…â–ƒâ–‚â–…â–‚â–‚â–ˆâ–ƒâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1699
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.28408
wandb:   test_error_force 9.47981
wandb:          test_loss 5.90955
wandb: train_error_energy 2.26465
wandb:  train_error_force 2.35455
wandb:         train_loss -1.9699
wandb: valid_error_energy 3.76303
wandb:  valid_error_force 2.44725
wandb:         valid_loss -1.7669
wandb: 
wandb: ğŸš€ View run al_58_10 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/st1s5jd4
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_161144-st1s5jd4/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 25.841426849365234, Uncertainty Bias: -3.8919711112976074
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:801: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:622: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:622: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:649: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:649: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
/home/ws/fq0795/git/gnn_uncertainty/uncertainty/base_uncertainty.py:913: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
  plt.figure(figsize=(10, 8))
0.0003681183 0.005247593
-2.5527146 35.66415
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 612 steps.
Found uncertainty sample 2 after 1780 steps.
Found uncertainty sample 3 after 392 steps.
Found uncertainty sample 4 after 982 steps.
Found uncertainty sample 5 after 931 steps.
Found uncertainty sample 6 after 380 steps.
Found uncertainty sample 7 after 437 steps.
Found uncertainty sample 8 after 109 steps.
Found uncertainty sample 9 after 939 steps.
Found uncertainty sample 10 after 416 steps.
Found uncertainty sample 11 after 608 steps.
Found uncertainty sample 12 after 1639 steps.
Found uncertainty sample 13 after 32 steps.
Found uncertainty sample 14 after 323 steps.
Found uncertainty sample 15 after 122 steps.
Found uncertainty sample 16 after 1040 steps.
Found uncertainty sample 17 after 264 steps.
Found uncertainty sample 18 after 5 steps.
Found uncertainty sample 19 after 1856 steps.
Found uncertainty sample 20 after 179 steps.
Found uncertainty sample 21 after 43 steps.
Found uncertainty sample 22 after 84 steps.
Found uncertainty sample 23 after 1148 steps.
Found uncertainty sample 24 after 80 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 517 steps.
Found uncertainty sample 27 after 1052 steps.
Found uncertainty sample 28 after 1412 steps.
Found uncertainty sample 29 after 2222 steps.
Found uncertainty sample 30 after 95 steps.
Found uncertainty sample 31 after 178 steps.
Found uncertainty sample 32 after 122 steps.
Found uncertainty sample 33 after 497 steps.
Found uncertainty sample 34 after 206 steps.
Found uncertainty sample 35 after 1887 steps.
Found uncertainty sample 36 after 2520 steps.
Found uncertainty sample 37 after 16 steps.
Found uncertainty sample 38 after 322 steps.
Found uncertainty sample 39 after 19 steps.
Found uncertainty sample 40 after 967 steps.
Found uncertainty sample 41 after 895 steps.
Found uncertainty sample 42 after 286 steps.
Found uncertainty sample 43 after 316 steps.
Found uncertainty sample 44 after 55 steps.
Found uncertainty sample 45 after 368 steps.
Found uncertainty sample 46 after 83 steps.
Found uncertainty sample 47 after 150 steps.
Found uncertainty sample 48 after 391 steps.
Found uncertainty sample 49 after 1661 steps.
Found uncertainty sample 50 after 1 steps.
Found uncertainty sample 51 after 7 steps.
Found uncertainty sample 52 after 262 steps.
Found uncertainty sample 53 after 121 steps.
Found uncertainty sample 54 after 736 steps.
Found uncertainty sample 55 after 832 steps.
Found uncertainty sample 56 after 469 steps.
Found uncertainty sample 57 after 1223 steps.
Found uncertainty sample 58 after 1424 steps.
Found uncertainty sample 59 after 305 steps.
Found uncertainty sample 60 after 16 steps.
Found uncertainty sample 61 after 2057 steps.
Found uncertainty sample 62 after 1044 steps.
Found uncertainty sample 63 after 1943 steps.
Found uncertainty sample 64 after 333 steps.
Found uncertainty sample 65 after 1143 steps.
Found uncertainty sample 66 after 3 steps.
Found uncertainty sample 67 after 1878 steps.
Found uncertainty sample 68 after 315 steps.
Found uncertainty sample 69 after 523 steps.
Found uncertainty sample 70 after 3207 steps.
Found uncertainty sample 71 after 801 steps.
Found uncertainty sample 72 after 754 steps.
Found uncertainty sample 73 after 451 steps.
Found uncertainty sample 74 after 2415 steps.
Found uncertainty sample 75 after 236 steps.
Found uncertainty sample 76 after 1176 steps.
Found uncertainty sample 77 after 1388 steps.
Found uncertainty sample 78 after 2856 steps.
Found uncertainty sample 79 after 123 steps.
Found uncertainty sample 80 after 3304 steps.
Found uncertainty sample 81 after 576 steps.
Found uncertainty sample 82 after 1282 steps.
Found uncertainty sample 83 after 267 steps.
Found uncertainty sample 84 after 2419 steps.
Found uncertainty sample 85 after 442 steps.
Found uncertainty sample 86 after 1673 steps.
Found uncertainty sample 87 after 590 steps.
Found uncertainty sample 88 after 1011 steps.
Found uncertainty sample 89 after 206 steps.
Found uncertainty sample 90 after 12 steps.
Found uncertainty sample 91 after 159 steps.
Found uncertainty sample 92 after 200 steps.
Found uncertainty sample 93 after 32 steps.
Found uncertainty sample 94 after 26 steps.
Found uncertainty sample 95 after 3218 steps.
Found uncertainty sample 96 after 26 steps.
Found uncertainty sample 97 after 443 steps.
Found uncertainty sample 98 after 354 steps.
Found uncertainty sample 99 after 85 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_162554-n505wqps
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_11
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n505wqps
Training model 11. Added 99 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.946831538493522, Training Loss Force: 2.6448790779016234, time: 0.8718235492706299
Validation Loss Energy: 2.611454614006113, Validation Loss Force: 2.4305834728024407, time: 0.0822904109954834
Test Loss Energy: 11.497475524437931, Test Loss Force: 9.57833696050764, time: 8.953924179077148


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.086355378194674, Training Loss Force: 2.3666208043502266, time: 0.8388752937316895
Validation Loss Energy: 1.247686701429238, Validation Loss Force: 2.331833157955229, time: 0.06284141540527344
Test Loss Energy: 13.391942873944208, Test Loss Force: 9.454142924935288, time: 8.868800163269043


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1980522766035158, Training Loss Force: 2.3393287600681405, time: 0.8449807167053223
Validation Loss Energy: 1.3013441762000408, Validation Loss Force: 2.521074432354326, time: 0.0628042221069336
Test Loss Energy: 13.379046860953219, Test Loss Force: 9.47578695348622, time: 9.055794954299927


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.606187157657841, Training Loss Force: 2.327288301756279, time: 0.8536763191223145
Validation Loss Energy: 1.0716974142481734, Validation Loss Force: 2.270889837395096, time: 0.07148170471191406
Test Loss Energy: 11.845281745911095, Test Loss Force: 9.46684849635035, time: 10.202397584915161


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5309010056624797, Training Loss Force: 2.327702205924328, time: 0.9314413070678711
Validation Loss Energy: 0.9038040153756808, Validation Loss Force: 2.5098586988085163, time: 0.066986083984375
Test Loss Energy: 12.362379434564081, Test Loss Force: 9.467998774847228, time: 10.05984091758728


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8483701875551495, Training Loss Force: 2.3267849442350874, time: 0.886899471282959
Validation Loss Energy: 2.179745677903631, Validation Loss Force: 2.585414570735588, time: 0.06424283981323242
Test Loss Energy: 13.920262280813475, Test Loss Force: 9.558627901187066, time: 10.644380569458008


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.149770926686052, Training Loss Force: 2.3147381219595107, time: 0.8901684284210205
Validation Loss Energy: 2.573626132146452, Validation Loss Force: 2.975289986385178, time: 0.07578420639038086
Test Loss Energy: 11.599592084399374, Test Loss Force: 9.44058359105084, time: 10.753729820251465


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1927740953585655, Training Loss Force: 2.3008466488355475, time: 0.9149460792541504
Validation Loss Energy: 1.4929774182319813, Validation Loss Force: 2.318451632961552, time: 0.07127189636230469
Test Loss Energy: 11.992825740149112, Test Loss Force: 9.47155691121845, time: 10.27230978012085


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.140529729684814, Training Loss Force: 2.3148666716408193, time: 0.9266471862792969
Validation Loss Energy: 1.8674933388646187, Validation Loss Force: 2.3425308517330374, time: 0.08047986030578613
Test Loss Energy: 14.108554010619136, Test Loss Force: 9.525114245495551, time: 10.507060527801514


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9347162911772777, Training Loss Force: 2.3043706047746477, time: 0.9118199348449707
Validation Loss Energy: 1.2860931767244412, Validation Loss Force: 2.842524955475183, time: 0.07442355155944824
Test Loss Energy: 13.171494930856122, Test Loss Force: 9.50269077234285, time: 10.347105264663696


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6957121714962813, Training Loss Force: 2.3353743190620877, time: 0.9070084095001221
Validation Loss Energy: 1.4550988914817728, Validation Loss Force: 2.7778058342075527, time: 0.07290410995483398
Test Loss Energy: 12.827169669327684, Test Loss Force: 9.446163926998885, time: 10.340636491775513


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.57007722930804, Training Loss Force: 2.349825461143754, time: 0.8597588539123535
Validation Loss Energy: 3.1088430434026115, Validation Loss Force: 2.44706110093567, time: 0.07987260818481445
Test Loss Energy: 11.628483930696676, Test Loss Force: 9.514689608210038, time: 10.356912851333618


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6772201142493057, Training Loss Force: 2.378191432752298, time: 0.9116380214691162
Validation Loss Energy: 1.2578462038813392, Validation Loss Force: 2.3409427753842804, time: 0.0750267505645752
Test Loss Energy: 12.159422173873148, Test Loss Force: 9.465306086995225, time: 10.443364381790161


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.6566438569024426, Training Loss Force: 2.339937515643815, time: 0.8882267475128174
Validation Loss Energy: 1.4612388261788722, Validation Loss Force: 2.7198200052436325, time: 0.0742037296295166
Test Loss Energy: 13.411809699600804, Test Loss Force: 9.488342485534366, time: 10.54081654548645


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.3265297872631447, Training Loss Force: 2.3415515548173644, time: 0.8967092037200928
Validation Loss Energy: 3.98973832820602, Validation Loss Force: 2.733838809332954, time: 0.07493329048156738
Test Loss Energy: 11.094517984028796, Test Loss Force: 9.471828586229394, time: 10.24225378036499


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4243425437308415, Training Loss Force: 2.3204192945962427, time: 0.9027585983276367
Validation Loss Energy: 3.7653466137653346, Validation Loss Force: 2.658379575815216, time: 0.07143616676330566
Test Loss Energy: 15.51761806195136, Test Loss Force: 9.423609501072239, time: 10.300564050674438


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8171295513083254, Training Loss Force: 2.3024744159595656, time: 0.9714784622192383
Validation Loss Energy: 2.069394745891873, Validation Loss Force: 2.8812657128257104, time: 0.07308506965637207
Test Loss Energy: 12.024390758688451, Test Loss Force: 9.551551536351447, time: 10.41447138786316


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.235212365330623, Training Loss Force: 2.335487164604256, time: 0.9824371337890625
Validation Loss Energy: 0.8402818242683421, Validation Loss Force: 2.395880041071303, time: 0.07705545425415039
Test Loss Energy: 12.950056112400274, Test Loss Force: 9.418616563999539, time: 10.687496662139893


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.084768231290789, Training Loss Force: 2.2779781716757532, time: 0.8928489685058594
Validation Loss Energy: 1.6058743492582774, Validation Loss Force: 2.299408188259797, time: 0.08003377914428711
Test Loss Energy: 12.13674053508156, Test Loss Force: 9.368275961831634, time: 10.450980186462402


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0675354287016154, Training Loss Force: 2.2754909076128054, time: 0.9113028049468994
Validation Loss Energy: 3.706622079909799, Validation Loss Force: 2.9244959254964336, time: 0.07467198371887207
Test Loss Energy: 15.48743683772359, Test Loss Force: 9.467863517913665, time: 10.216180324554443

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–…â–‚â–ƒâ–…â–‚â–‚â–†â–„â–„â–‚â–ƒâ–…â–â–ˆâ–‚â–„â–ƒâ–ˆ
wandb:   test_error_force â–ˆâ–„â–…â–„â–„â–‡â–ƒâ–„â–†â–…â–„â–†â–„â–…â–„â–ƒâ–‡â–ƒâ–â–„
wandb:          test_loss â–â–‚â–ƒâ–â–„â–†â–‚â–ƒâ–…â–†â–ƒâ–ƒâ–ƒâ–„â–„â–†â–†â–…â–…â–ˆ
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–â–â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–â–â–‡â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–â–
wandb: valid_error_energy â–…â–‚â–‚â–‚â–â–„â–…â–‚â–ƒâ–‚â–‚â–†â–‚â–‚â–ˆâ–ˆâ–„â–â–ƒâ–‡
wandb:  valid_error_force â–ƒâ–‚â–ƒâ–â–ƒâ–„â–ˆâ–â–‚â–‡â–†â–ƒâ–‚â–…â–†â–…â–‡â–‚â–â–‡
wandb:         valid_loss â–ƒâ–‚â–ƒâ–â–ƒâ–„â–ˆâ–‚â–‚â–†â–…â–„â–‚â–…â–†â–†â–‡â–‚â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 1788
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 15.48744
wandb:   test_error_force 9.46786
wandb:          test_loss 6.44366
wandb: train_error_energy 2.06754
wandb:  train_error_force 2.27549
wandb:         train_loss -2.06729
wandb: valid_error_energy 3.70662
wandb:  valid_error_force 2.9245
wandb:         valid_loss -1.24933
wandb: 
wandb: ğŸš€ View run al_58_11 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n505wqps
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_162554-n505wqps/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 32.277000427246094, Uncertainty Bias: -4.763758659362793
6.1035156e-05 0.2444334
-3.0804226 34.269524
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 704 steps.
Found uncertainty sample 1 after 58 steps.
Found uncertainty sample 2 after 163 steps.
Found uncertainty sample 3 after 958 steps.
Found uncertainty sample 4 after 157 steps.
Found uncertainty sample 5 after 415 steps.
Found uncertainty sample 6 after 541 steps.
Found uncertainty sample 7 after 10 steps.
Found uncertainty sample 8 after 682 steps.
Found uncertainty sample 9 after 1164 steps.
Found uncertainty sample 10 after 535 steps.
Found uncertainty sample 11 after 253 steps.
Found uncertainty sample 12 after 2 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 92 steps.
Found uncertainty sample 15 after 382 steps.
Found uncertainty sample 16 after 83 steps.
Found uncertainty sample 17 after 269 steps.
Found uncertainty sample 18 after 327 steps.
Found uncertainty sample 19 after 430 steps.
Found uncertainty sample 20 after 391 steps.
Found uncertainty sample 21 after 120 steps.
Found uncertainty sample 22 after 2466 steps.
Found uncertainty sample 23 after 542 steps.
Found uncertainty sample 24 after 1 steps.
Found uncertainty sample 25 after 662 steps.
Found uncertainty sample 26 after 213 steps.
Found uncertainty sample 27 after 82 steps.
Found uncertainty sample 28 after 1 steps.
Found uncertainty sample 29 after 287 steps.
Found uncertainty sample 30 after 1132 steps.
Found uncertainty sample 31 after 435 steps.
Found uncertainty sample 32 after 158 steps.
Found uncertainty sample 33 after 629 steps.
Found uncertainty sample 34 after 84 steps.
Found uncertainty sample 35 after 1562 steps.
Found uncertainty sample 36 after 478 steps.
Found uncertainty sample 37 after 789 steps.
Found uncertainty sample 38 after 1 steps.
Found uncertainty sample 39 after 54 steps.
Found uncertainty sample 40 after 25 steps.
Found uncertainty sample 41 after 24 steps.
Found uncertainty sample 42 after 1977 steps.
Found uncertainty sample 43 after 12 steps.
Found uncertainty sample 44 after 278 steps.
Found uncertainty sample 45 after 2299 steps.
Found uncertainty sample 46 after 645 steps.
Found uncertainty sample 47 after 233 steps.
Found uncertainty sample 48 after 1073 steps.
Found uncertainty sample 49 after 3572 steps.
Found uncertainty sample 50 after 364 steps.
Found uncertainty sample 51 after 629 steps.
Found uncertainty sample 52 after 1248 steps.
Found uncertainty sample 53 after 575 steps.
Found uncertainty sample 54 after 1602 steps.
Found uncertainty sample 55 after 35 steps.
Found uncertainty sample 56 after 120 steps.
Found uncertainty sample 57 after 560 steps.
Found uncertainty sample 58 after 1043 steps.
Found uncertainty sample 59 after 713 steps.
Found uncertainty sample 60 after 212 steps.
Found uncertainty sample 61 after 1 steps.
Found uncertainty sample 62 after 275 steps.
Found uncertainty sample 63 after 18 steps.
Found uncertainty sample 64 after 761 steps.
Found uncertainty sample 65 after 985 steps.
Found uncertainty sample 66 after 12 steps.
Found uncertainty sample 67 after 186 steps.
Found uncertainty sample 68 after 127 steps.
Found uncertainty sample 69 after 346 steps.
Found uncertainty sample 70 after 91 steps.
Found uncertainty sample 71 after 219 steps.
Found uncertainty sample 72 after 99 steps.
Found uncertainty sample 73 after 645 steps.
Found uncertainty sample 74 after 154 steps.
Found uncertainty sample 75 after 29 steps.
Found uncertainty sample 76 after 1114 steps.
Found uncertainty sample 77 after 1839 steps.
Found uncertainty sample 78 after 323 steps.
Found uncertainty sample 79 after 847 steps.
Found uncertainty sample 80 after 1545 steps.
Found uncertainty sample 81 after 26 steps.
Found uncertainty sample 82 after 4 steps.
Found uncertainty sample 83 after 457 steps.
Found uncertainty sample 84 after 860 steps.
Found uncertainty sample 85 after 594 steps.
Found uncertainty sample 86 after 33 steps.
Found uncertainty sample 87 after 322 steps.
Found uncertainty sample 88 after 35 steps.
Found uncertainty sample 89 after 578 steps.
Found uncertainty sample 90 after 94 steps.
Found uncertainty sample 91 after 538 steps.
Found uncertainty sample 92 after 460 steps.
Found uncertainty sample 93 after 48 steps.
Found uncertainty sample 94 after 292 steps.
Found uncertainty sample 95 after 29 steps.
Found uncertainty sample 96 after 677 steps.
Found uncertainty sample 97 after 1031 steps.
Found uncertainty sample 98 after 94 steps.
Found uncertainty sample 99 after 578 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_163704-10xjft62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_12
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/10xjft62
Training model 12. Added 105 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.940882147001747, Training Loss Force: 2.5550907203103175, time: 0.9211218357086182
Validation Loss Energy: 1.8351901135247233, Validation Loss Force: 2.342104440318586, time: 0.06632494926452637
Test Loss Energy: 13.9506231978762, Test Loss Force: 9.450336480989566, time: 9.058672428131104


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.424545592281189, Training Loss Force: 2.319342590712236, time: 0.8612358570098877
Validation Loss Energy: 2.3227466981173537, Validation Loss Force: 2.369688805450693, time: 0.0675821304321289
Test Loss Energy: 11.830524484664156, Test Loss Force: 9.377693043382157, time: 8.954233884811401


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.154738762859411, Training Loss Force: 2.265646665886201, time: 0.8522641658782959
Validation Loss Energy: 1.1835972885062915, Validation Loss Force: 2.439278146278056, time: 0.07009720802307129
Test Loss Energy: 13.552366601843612, Test Loss Force: 9.477706328881519, time: 9.22520399093628


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.190465867869772, Training Loss Force: 2.2798440619527165, time: 0.8697619438171387
Validation Loss Energy: 3.5444759665292054, Validation Loss Force: 2.3136715944059203, time: 0.06613469123840332
Test Loss Energy: 15.647612314007233, Test Loss Force: 9.433134228582231, time: 9.070818424224854


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.581819261297618, Training Loss Force: 2.2974068606205176, time: 0.8713340759277344
Validation Loss Energy: 0.9035533734182959, Validation Loss Force: 2.631126987710541, time: 0.06565618515014648
Test Loss Energy: 12.529666259221198, Test Loss Force: 9.32406749073991, time: 9.042562484741211


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6327148494243666, Training Loss Force: 2.301207617255599, time: 0.8547420501708984
Validation Loss Energy: 2.8096342732610435, Validation Loss Force: 2.5173373760782205, time: 0.06490969657897949
Test Loss Energy: 14.102444943869564, Test Loss Force: 9.451336239807027, time: 9.520317077636719


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6244665020990634, Training Loss Force: 2.2882948127011282, time: 0.8535778522491455
Validation Loss Energy: 0.8061112676370529, Validation Loss Force: 2.4345902927488385, time: 0.06395530700683594
Test Loss Energy: 12.730072929949438, Test Loss Force: 9.422834803636766, time: 8.999639987945557


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.071602033999515, Training Loss Force: 2.2915672981096558, time: 0.8729171752929688
Validation Loss Energy: 2.7828204547084194, Validation Loss Force: 2.332522207627302, time: 0.06528115272521973
Test Loss Energy: 11.209426986683194, Test Loss Force: 9.353840314106295, time: 8.999019384384155


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1387121850477384, Training Loss Force: 2.2555824941339564, time: 0.9120392799377441
Validation Loss Energy: 1.0050865237503837, Validation Loss Force: 2.4213896864362283, time: 0.06648135185241699
Test Loss Energy: 12.168123729690663, Test Loss Force: 9.381665470271967, time: 9.240241765975952


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6174633697004819, Training Loss Force: 2.2724249939681886, time: 0.9074034690856934
Validation Loss Energy: 0.9009671269556312, Validation Loss Force: 2.5326030160501647, time: 0.0641942024230957
Test Loss Energy: 12.537418106649385, Test Loss Force: 9.348510556724873, time: 9.050495862960815


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.573065370580967, Training Loss Force: 2.265325225990814, time: 0.8815286159515381
Validation Loss Energy: 2.0459371080412456, Validation Loss Force: 2.5466103526784707, time: 0.064788818359375
Test Loss Energy: 11.55602251287509, Test Loss Force: 9.357738264578726, time: 9.018943071365356


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7301469534925529, Training Loss Force: 2.295136726033464, time: 0.8558545112609863
Validation Loss Energy: 2.0830074014590227, Validation Loss Force: 2.5434520135126313, time: 0.06760072708129883
Test Loss Energy: 11.503304741537544, Test Loss Force: 9.299820662723507, time: 9.257380485534668


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.834059396771162, Training Loss Force: 2.2750362444776173, time: 0.8470263481140137
Validation Loss Energy: 2.398628891677782, Validation Loss Force: 2.708671740449039, time: 0.06658625602722168
Test Loss Energy: 13.90189562965431, Test Loss Force: 9.426956006158651, time: 8.992512464523315


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.821774436179034, Training Loss Force: 2.276543776867428, time: 0.9057321548461914
Validation Loss Energy: 1.017144837344384, Validation Loss Force: 2.9207009752423865, time: 0.06502079963684082
Test Loss Energy: 13.108482267230906, Test Loss Force: 9.31445139193682, time: 9.199754476547241


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9379628785601608, Training Loss Force: 2.3002148581906403, time: 0.8988246917724609
Validation Loss Energy: 2.1983994516000127, Validation Loss Force: 2.362636094257149, time: 0.06448030471801758
Test Loss Energy: 14.478634635829547, Test Loss Force: 9.410227155350402, time: 9.234201908111572


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.145711999109938, Training Loss Force: 2.2508211295941565, time: 0.855139970779419
Validation Loss Energy: 1.7403744181533418, Validation Loss Force: 2.3251147844842954, time: 0.06733107566833496
Test Loss Energy: 11.722343587637916, Test Loss Force: 9.342849859365485, time: 9.084560871124268


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0535544261032026, Training Loss Force: 2.2415735478719094, time: 0.8694143295288086
Validation Loss Energy: 2.5149590469305654, Validation Loss Force: 2.376406622248761, time: 0.06717443466186523
Test Loss Energy: 11.898314527639133, Test Loss Force: 9.380436723634384, time: 8.991437673568726


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9209876698019828, Training Loss Force: 2.250028487819507, time: 0.9085485935211182
Validation Loss Energy: 0.9725560088797824, Validation Loss Force: 2.452602779304948, time: 0.06747817993164062
Test Loss Energy: 12.50526553534817, Test Loss Force: 9.395224934726802, time: 9.541253805160522


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6615998665524243, Training Loss Force: 2.3093758593556553, time: 0.9035205841064453
Validation Loss Energy: 2.2731219842484487, Validation Loss Force: 2.3127059896546047, time: 0.06462407112121582
Test Loss Energy: 14.302907223593937, Test Loss Force: 9.3138891931466, time: 9.30230975151062


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.895230647507552, Training Loss Force: 2.2953348525106474, time: 0.982485294342041
Validation Loss Energy: 0.8531474248509037, Validation Loss Force: 2.4829425637833387, time: 0.07385134696960449
Test Loss Energy: 12.85267783062024, Test Loss Force: 9.503919789447668, time: 10.211498737335205

wandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–…â–ˆâ–ƒâ–†â–ƒâ–â–ƒâ–ƒâ–‚â–â–…â–„â–†â–‚â–‚â–ƒâ–†â–„
wandb:   test_error_force â–†â–„â–‡â–†â–‚â–†â–…â–ƒâ–„â–ƒâ–ƒâ–â–…â–‚â–…â–‚â–„â–„â–â–ˆ
wandb:          test_loss â–ƒâ–â–…â–†â–ƒâ–‡â–…â–â–ƒâ–„â–„â–ƒâ–ˆâ–„â–‡â–ƒâ–…â–†â–„â–‡
wandb: train_error_energy â–ˆâ–…â–„â–„â–†â–â–â–„â–„â–â–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–â–â–â–‚â–â–‚â–‚â–â–â–â–‚â–‚
wandb: valid_error_energy â–„â–…â–‚â–ˆâ–â–†â–â–†â–‚â–â–„â–„â–…â–‚â–…â–ƒâ–…â–â–…â–
wandb:  valid_error_force â–â–‚â–‚â–â–…â–ƒâ–‚â–â–‚â–„â–„â–„â–†â–ˆâ–‚â–â–‚â–ƒâ–â–ƒ
wandb:         valid_loss â–â–‚â–‚â–‚â–„â–„â–‚â–‚â–‚â–ƒâ–„â–„â–†â–ˆâ–‚â–â–‚â–‚â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 1882
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.85268
wandb:   test_error_force 9.50392
wandb:          test_loss 6.3415
wandb: train_error_energy 1.89523
wandb:  train_error_force 2.29533
wandb:         train_loss -2.05524
wandb: valid_error_energy 0.85315
wandb:  valid_error_force 2.48294
wandb:         valid_loss -1.91964
wandb: 
wandb: ğŸš€ View run al_58_12 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/10xjft62
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_163704-10xjft62/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 34.58434295654297, Uncertainty Bias: -5.134946346282959
1.335144e-05 0.0026254654
-3.4783556 31.887447
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 19 steps.
Found uncertainty sample 1 after 398 steps.
Found uncertainty sample 2 after 204 steps.
Found uncertainty sample 3 after 311 steps.
Found uncertainty sample 4 after 99 steps.
Found uncertainty sample 5 after 82 steps.
Found uncertainty sample 6 after 216 steps.
Found uncertainty sample 7 after 125 steps.
Found uncertainty sample 8 after 113 steps.
Found uncertainty sample 9 after 535 steps.
Found uncertainty sample 10 after 376 steps.
Found uncertainty sample 11 after 701 steps.
Found uncertainty sample 12 after 111 steps.
Found uncertainty sample 13 after 370 steps.
Found uncertainty sample 14 after 249 steps.
Found uncertainty sample 15 after 299 steps.
Found uncertainty sample 16 after 6 steps.
Found uncertainty sample 17 after 322 steps.
Found uncertainty sample 18 after 135 steps.
Found uncertainty sample 19 after 98 steps.
Found uncertainty sample 20 after 1127 steps.
Found uncertainty sample 21 after 173 steps.
Found uncertainty sample 22 after 318 steps.
Found uncertainty sample 23 after 38 steps.
Found uncertainty sample 24 after 251 steps.
Found uncertainty sample 25 after 136 steps.
Found uncertainty sample 26 after 350 steps.
Found uncertainty sample 27 after 1148 steps.
Found uncertainty sample 28 after 763 steps.
Found uncertainty sample 29 after 90 steps.
Found uncertainty sample 30 after 96 steps.
Found uncertainty sample 31 after 256 steps.
Found uncertainty sample 32 after 195 steps.
Found uncertainty sample 33 after 66 steps.
Found uncertainty sample 34 after 315 steps.
Found uncertainty sample 35 after 1147 steps.
Found uncertainty sample 36 after 1 steps.
Found uncertainty sample 37 after 133 steps.
Found uncertainty sample 38 after 252 steps.
Found uncertainty sample 39 after 395 steps.
Found uncertainty sample 40 after 7 steps.
Found uncertainty sample 41 after 86 steps.
Found uncertainty sample 42 after 1905 steps.
Found uncertainty sample 43 after 891 steps.
Found uncertainty sample 44 after 1996 steps.
Found uncertainty sample 45 after 932 steps.
Found uncertainty sample 46 after 1836 steps.
Found uncertainty sample 47 after 24 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 295 steps.
Found uncertainty sample 50 after 105 steps.
Found uncertainty sample 51 after 87 steps.
Found uncertainty sample 52 after 790 steps.
Found uncertainty sample 53 after 225 steps.
Found uncertainty sample 54 after 11 steps.
Found uncertainty sample 55 after 99 steps.
Found uncertainty sample 56 after 62 steps.
Found uncertainty sample 57 after 539 steps.
Found uncertainty sample 58 after 1516 steps.
Found uncertainty sample 59 after 351 steps.
Found uncertainty sample 60 after 404 steps.
Found uncertainty sample 61 after 471 steps.
Found uncertainty sample 62 after 226 steps.
Found uncertainty sample 63 after 420 steps.
Found uncertainty sample 64 after 474 steps.
Found uncertainty sample 65 after 1128 steps.
Found uncertainty sample 66 after 211 steps.
Found uncertainty sample 67 after 277 steps.
Found uncertainty sample 68 after 283 steps.
Found uncertainty sample 69 after 458 steps.
Found uncertainty sample 70 after 346 steps.
Found uncertainty sample 71 after 178 steps.
Found uncertainty sample 72 after 870 steps.
Found uncertainty sample 73 after 475 steps.
Found uncertainty sample 74 after 346 steps.
Found uncertainty sample 75 after 646 steps.
Found uncertainty sample 76 after 185 steps.
Found uncertainty sample 77 after 1268 steps.
Found uncertainty sample 78 after 276 steps.
Found uncertainty sample 79 after 549 steps.
Found uncertainty sample 80 after 228 steps.
Found uncertainty sample 81 after 994 steps.
Found uncertainty sample 82 after 238 steps.
Found uncertainty sample 83 after 643 steps.
Found uncertainty sample 84 after 264 steps.
Found uncertainty sample 85 after 309 steps.
Found uncertainty sample 86 after 966 steps.
Found uncertainty sample 87 after 736 steps.
Found uncertainty sample 88 after 2012 steps.
Found uncertainty sample 89 after 588 steps.
Found uncertainty sample 90 after 1132 steps.
Found uncertainty sample 91 after 1 steps.
Found uncertainty sample 92 after 2 steps.
Found uncertainty sample 93 after 163 steps.
Found uncertainty sample 94 after 3 steps.
Found uncertainty sample 95 after 243 steps.
Found uncertainty sample 96 after 191 steps.
Found uncertainty sample 97 after 278 steps.
Found uncertainty sample 98 after 366 steps.
Found uncertainty sample 99 after 749 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_164711-y7gheql7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_13
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/y7gheql7
Training model 13. Added 101 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.6156982893074654, Training Loss Force: 2.430273249789191, time: 0.915755033493042
Validation Loss Energy: 1.0000007326237497, Validation Loss Force: 2.7164682779245544, time: 0.06790971755981445
Test Loss Energy: 12.877654024830912, Test Loss Force: 9.461969104220772, time: 8.880061864852905


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6830059447836634, Training Loss Force: 2.257593021849975, time: 0.9241397380828857
Validation Loss Energy: 2.1846716760844185, Validation Loss Force: 2.3563367841188523, time: 0.07140827178955078
Test Loss Energy: 11.687641839332153, Test Loss Force: 9.313196274743843, time: 8.872314929962158


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8405727307036142, Training Loss Force: 2.242939795653807, time: 0.933513879776001
Validation Loss Energy: 2.5404969712770233, Validation Loss Force: 2.6535493253671776, time: 0.06638312339782715
Test Loss Energy: 14.459358034964575, Test Loss Force: 9.367735815447508, time: 9.128421068191528


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5263833721134081, Training Loss Force: 2.2404208204132776, time: 0.9506583213806152
Validation Loss Energy: 1.9994488004273068, Validation Loss Force: 2.502661364004693, time: 0.06499958038330078
Test Loss Energy: 11.854133914672595, Test Loss Force: 9.304686167759542, time: 8.897259712219238


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.692419243421944, Training Loss Force: 2.2414394240127624, time: 0.9354057312011719
Validation Loss Energy: 0.9269665331070245, Validation Loss Force: 2.525818621177464, time: 0.0664522647857666
Test Loss Energy: 12.708367509999425, Test Loss Force: 9.376908758349531, time: 8.939171075820923


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4369207983398173, Training Loss Force: 2.2577349734305034, time: 0.8910548686981201
Validation Loss Energy: 1.623353320540744, Validation Loss Force: 2.392696206288255, time: 0.06530642509460449
Test Loss Energy: 11.937623377517403, Test Loss Force: 9.244165873693102, time: 9.374881982803345


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.585196608198515, Training Loss Force: 2.2533812654819725, time: 0.9897503852844238
Validation Loss Energy: 0.9380790038364102, Validation Loss Force: 2.287944067281705, time: 0.0671546459197998
Test Loss Energy: 12.489073846458007, Test Loss Force: 9.305371746241132, time: 9.052706241607666


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.239145998251306, Training Loss Force: 2.2753305120108642, time: 0.9221880435943604
Validation Loss Energy: 2.037016870720805, Validation Loss Force: 2.3534187049614683, time: 0.06828498840332031
Test Loss Energy: 13.916478859225313, Test Loss Force: 9.326920719548704, time: 8.868618488311768


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1540004539694713, Training Loss Force: 2.266396884014446, time: 0.9330379962921143
Validation Loss Energy: 1.2522958970826568, Validation Loss Force: 2.4976753564890775, time: 0.0697789192199707
Test Loss Energy: 13.125098715586937, Test Loss Force: 9.29123773010461, time: 9.141470909118652


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.3948863548971047, Training Loss Force: 2.2184746212193915, time: 0.9259798526763916
Validation Loss Energy: 0.9750396326998176, Validation Loss Force: 2.3695828149372318, time: 0.07335400581359863
Test Loss Energy: 12.287775664428207, Test Loss Force: 9.312838563172848, time: 8.938238143920898


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3368351249523036, Training Loss Force: 2.209228773370286, time: 0.9538869857788086
Validation Loss Energy: 4.712901804112279, Validation Loss Force: 2.370901016281124, time: 0.06762552261352539
Test Loss Energy: 16.386249971198666, Test Loss Force: 9.363287599385783, time: 8.927929162979126


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.398046803134814, Training Loss Force: 2.232570644813659, time: 0.9191944599151611
Validation Loss Energy: 1.8413388436530866, Validation Loss Force: 2.5056505859542, time: 0.06889033317565918
Test Loss Energy: 11.767598529103852, Test Loss Force: 9.396476484550217, time: 9.185848474502563


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9631253456099877, Training Loss Force: 2.2456699312777144, time: 0.9677047729492188
Validation Loss Energy: 1.682759054980959, Validation Loss Force: 2.533371335938188, time: 0.06644892692565918
Test Loss Energy: 13.17121064647616, Test Loss Force: 9.298230744399616, time: 8.927388906478882


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.5696632157614683, Training Loss Force: 2.2045118058502386, time: 0.9221069812774658
Validation Loss Energy: 2.703370322088217, Validation Loss Force: 2.3086544132098754, time: 0.06696844100952148
Test Loss Energy: 14.100148154764183, Test Loss Force: 9.388989480503682, time: 8.93604588508606


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.542879624545404, Training Loss Force: 2.211550201572562, time: 0.9220430850982666
Validation Loss Energy: 1.2936106540928227, Validation Loss Force: 2.3073814137026067, time: 0.06757974624633789
Test Loss Energy: 12.401762224588486, Test Loss Force: 9.29159718105972, time: 9.144276142120361


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5888411759717096, Training Loss Force: 2.227162309348413, time: 0.9405591487884521
Validation Loss Energy: 2.407840268906522, Validation Loss Force: 2.2885248997488574, time: 0.06740379333496094
Test Loss Energy: 14.084048937688966, Test Loss Force: 9.313058364433441, time: 9.011916875839233


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.844192191632746, Training Loss Force: 2.222853717041997, time: 0.9703550338745117
Validation Loss Energy: 0.8305531031126814, Validation Loss Force: 2.5845393696575183, time: 0.06720852851867676
Test Loss Energy: 12.801127316593401, Test Loss Force: 9.32320314274254, time: 8.976639747619629


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7243393117268442, Training Loss Force: 2.2172095282625213, time: 0.913917064666748
Validation Loss Energy: 0.8158680172714572, Validation Loss Force: 2.3793890527893184, time: 0.06739997863769531
Test Loss Energy: 12.711842113964135, Test Loss Force: 9.276809030589268, time: 9.573917627334595


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5166761672618327, Training Loss Force: 2.2189156892916584, time: 0.9191653728485107
Validation Loss Energy: 1.0617945936540405, Validation Loss Force: 2.4057338187860458, time: 0.0667726993560791
Test Loss Energy: 13.110658166808774, Test Loss Force: 9.230666051926779, time: 9.053420305252075


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3229100672669956, Training Loss Force: 2.2161279236604914, time: 0.9517307281494141
Validation Loss Energy: 0.766059935360881, Validation Loss Force: 2.240049938014951, time: 0.06896185874938965
Test Loss Energy: 12.35414867826432, Test Loss Force: 9.28073384125606, time: 8.984753847122192

wandb: - 0.039 MB of 0.048 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–…â–â–ƒâ–â–‚â–„â–ƒâ–‚â–ˆâ–â–ƒâ–…â–‚â–…â–ƒâ–ƒâ–ƒâ–‚
wandb:   test_error_force â–ˆâ–ƒâ–…â–ƒâ–…â–â–ƒâ–„â–ƒâ–ƒâ–…â–†â–ƒâ–†â–ƒâ–ƒâ–„â–‚â–â–ƒ
wandb:          test_loss â–‚â–â–…â–ƒâ–„â–â–‚â–„â–‚â–ƒâ–ˆâ–„â–…â–†â–„â–†â–„â–…â–„â–ƒ
wandb: train_error_energy â–ƒâ–„â–…â–ƒâ–„â–‚â–ƒâ–ˆâ–‡â–‚â–â–‚â–†â–ƒâ–ƒâ–ƒâ–…â–„â–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–â–‚â–‚â–â–â–‚â–‚â–â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–…â–„â–â–â–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–â–„â–„â–ƒâ–â–ƒâ–â–ƒâ–‚â–â–ˆâ–ƒâ–ƒâ–„â–‚â–„â–â–â–‚â–
wandb:  valid_error_force â–ˆâ–ƒâ–‡â–…â–…â–ƒâ–‚â–ƒâ–…â–ƒâ–ƒâ–…â–…â–‚â–‚â–‚â–†â–ƒâ–ƒâ–
wandb:         valid_loss â–‡â–„â–ˆâ–†â–…â–„â–‚â–„â–…â–ƒâ–†â–…â–†â–ƒâ–‚â–ƒâ–†â–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 1972
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.35415
wandb:   test_error_force 9.28073
wandb:          test_loss 6.24492
wandb: train_error_energy 1.32291
wandb:  train_error_force 2.21613
wandb:         train_loss -2.18303
wandb: valid_error_energy 0.76606
wandb:  valid_error_force 2.24005
wandb:         valid_loss -2.19249
wandb: 
wandb: ğŸš€ View run al_58_13 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/y7gheql7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_164711-y7gheql7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 33.18675231933594, Uncertainty Bias: -4.797843933105469
2.2888184e-05 0.002421856
-2.9417408 30.66115
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 328 steps.
Found uncertainty sample 1 after 274 steps.
Found uncertainty sample 2 after 260 steps.
Found uncertainty sample 3 after 893 steps.
Found uncertainty sample 4 after 423 steps.
Found uncertainty sample 5 after 1552 steps.
Found uncertainty sample 6 after 159 steps.
Found uncertainty sample 7 after 1481 steps.
Found uncertainty sample 8 after 372 steps.
Found uncertainty sample 9 after 6 steps.
Found uncertainty sample 10 after 62 steps.
Found uncertainty sample 11 after 123 steps.
Found uncertainty sample 12 after 240 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 439 steps.
Found uncertainty sample 15 after 27 steps.
Found uncertainty sample 16 after 679 steps.
Found uncertainty sample 17 after 486 steps.
Found uncertainty sample 18 after 59 steps.
Found uncertainty sample 19 after 1776 steps.
Found uncertainty sample 20 after 45 steps.
Found uncertainty sample 21 after 323 steps.
Found uncertainty sample 22 after 75 steps.
Found uncertainty sample 23 after 2273 steps.
Found uncertainty sample 24 after 650 steps.
Found uncertainty sample 25 after 20 steps.
Found uncertainty sample 26 after 271 steps.
Found uncertainty sample 27 after 439 steps.
Found uncertainty sample 28 after 915 steps.
Found uncertainty sample 29 after 3060 steps.
Found uncertainty sample 30 after 169 steps.
Found uncertainty sample 31 after 452 steps.
Found uncertainty sample 32 after 2337 steps.
Found uncertainty sample 33 after 323 steps.
Found uncertainty sample 34 after 29 steps.
Found uncertainty sample 35 after 117 steps.
Found uncertainty sample 36 after 39 steps.
Found uncertainty sample 37 after 860 steps.
Found uncertainty sample 38 after 366 steps.
Found uncertainty sample 39 after 356 steps.
Found uncertainty sample 40 after 2344 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1692 steps.
Found uncertainty sample 43 after 2584 steps.
Found uncertainty sample 44 after 595 steps.
Found uncertainty sample 45 after 101 steps.
Found uncertainty sample 46 after 757 steps.
Found uncertainty sample 47 after 300 steps.
Found uncertainty sample 48 after 267 steps.
Found uncertainty sample 49 after 629 steps.
Found uncertainty sample 50 after 335 steps.
Found uncertainty sample 51 after 280 steps.
Found uncertainty sample 52 after 591 steps.
Found uncertainty sample 53 after 607 steps.
Found uncertainty sample 54 after 94 steps.
Found uncertainty sample 55 after 118 steps.
Found uncertainty sample 56 after 802 steps.
Found uncertainty sample 57 after 315 steps.
Found uncertainty sample 58 after 65 steps.
Found uncertainty sample 59 after 222 steps.
Found uncertainty sample 60 after 813 steps.
Found uncertainty sample 61 after 470 steps.
Found uncertainty sample 62 after 523 steps.
Found uncertainty sample 63 after 774 steps.
Found uncertainty sample 64 after 895 steps.
Found uncertainty sample 65 after 657 steps.
Found uncertainty sample 66 after 42 steps.
Found uncertainty sample 67 after 838 steps.
Found uncertainty sample 68 after 774 steps.
Found uncertainty sample 69 after 61 steps.
Found uncertainty sample 70 after 521 steps.
Found uncertainty sample 71 after 164 steps.
Found uncertainty sample 72 after 912 steps.
Found uncertainty sample 73 after 461 steps.
Found uncertainty sample 74 after 1 steps.
Found uncertainty sample 75 after 158 steps.
Found uncertainty sample 76 after 347 steps.
Found uncertainty sample 77 after 977 steps.
Found uncertainty sample 78 after 2704 steps.
Found uncertainty sample 79 after 382 steps.
Found uncertainty sample 80 after 240 steps.
Found uncertainty sample 81 after 275 steps.
Found uncertainty sample 82 after 3604 steps.
Found uncertainty sample 83 after 912 steps.
Found uncertainty sample 84 after 417 steps.
Found uncertainty sample 85 after 1 steps.
Found uncertainty sample 86 after 1114 steps.
Found uncertainty sample 87 after 367 steps.
Found uncertainty sample 88 after 302 steps.
Found uncertainty sample 89 after 1464 steps.
Found uncertainty sample 90 after 870 steps.
Found uncertainty sample 91 after 343 steps.
Found uncertainty sample 92 after 357 steps.
Found uncertainty sample 93 after 335 steps.
Found uncertainty sample 94 after 870 steps.
Found uncertainty sample 95 after 1485 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 938 steps.
Found uncertainty sample 98 after 1095 steps.
Found uncertainty sample 99 after 207 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_165951-m8ubv6ig
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_14
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m8ubv6ig
Training model 14. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.023058119172129, Training Loss Force: 2.4178523952151316, time: 0.9929640293121338
Validation Loss Energy: 4.007820176201086, Validation Loss Force: 2.5318937034858116, time: 0.07214951515197754
Test Loss Energy: 16.076488146627963, Test Loss Force: 9.373730661085865, time: 8.162343978881836


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.485647764385857, Training Loss Force: 2.309852052913965, time: 1.0884170532226562
Validation Loss Energy: 1.4833508187133715, Validation Loss Force: 2.4851438709599805, time: 0.06402420997619629
Test Loss Energy: 13.650393837111059, Test Loss Force: 9.328577070221348, time: 8.219263553619385


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.58866428779557, Training Loss Force: 2.237291606841375, time: 0.9911096096038818
Validation Loss Energy: 2.878255114638194, Validation Loss Force: 2.493921377357881, time: 0.06791114807128906
Test Loss Energy: 11.551662534417119, Test Loss Force: 9.21683676376259, time: 8.455417156219482


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7419997119370012, Training Loss Force: 2.226072351697381, time: 1.0153019428253174
Validation Loss Energy: 1.5677207704455618, Validation Loss Force: 2.402069241316939, time: 0.06579971313476562
Test Loss Energy: 13.681701515402898, Test Loss Force: 9.262444655643538, time: 8.269435167312622


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.820808694444098, Training Loss Force: 2.2409805614434415, time: 1.022325038909912
Validation Loss Energy: 2.7984837817749906, Validation Loss Force: 2.666745366962296, time: 0.07081127166748047
Test Loss Energy: 11.621519348103929, Test Loss Force: 9.167808118876033, time: 8.1483736038208


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.732063606587651, Training Loss Force: 2.24505182526635, time: 0.9787123203277588
Validation Loss Energy: 3.2664540542880935, Validation Loss Force: 2.5635831969922434, time: 0.07006335258483887
Test Loss Energy: 14.957776654822775, Test Loss Force: 9.284796394357038, time: 8.305088758468628


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.055124161235053, Training Loss Force: 2.2451315476719502, time: 0.9673972129821777
Validation Loss Energy: 1.5769135548006177, Validation Loss Force: 2.4424963834441504, time: 0.06798458099365234
Test Loss Energy: 11.569047100393654, Test Loss Force: 9.3608987768089, time: 8.422155857086182


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2065294892195824, Training Loss Force: 2.2534857154896133, time: 0.9971957206726074
Validation Loss Energy: 1.8029321456887377, Validation Loss Force: 2.492991399669914, time: 0.06656265258789062
Test Loss Energy: 13.497802308724728, Test Loss Force: 9.262957354266556, time: 8.285709381103516


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3269571751618878, Training Loss Force: 2.258293784665038, time: 1.0165774822235107
Validation Loss Energy: 1.3774925707244257, Validation Loss Force: 2.4833281154095124, time: 0.07392191886901855
Test Loss Energy: 12.895594130507808, Test Loss Force: 9.152364267226986, time: 8.252179145812988


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9366729787405121, Training Loss Force: 2.2323975222877177, time: 1.0493967533111572
Validation Loss Energy: 2.0431088758842435, Validation Loss Force: 2.5326988751174864, time: 0.06502985954284668
Test Loss Energy: 11.526087577044017, Test Loss Force: 9.245495621189983, time: 8.731114864349365


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2281480657679404, Training Loss Force: 2.229472795599908, time: 1.0008466243743896
Validation Loss Energy: 0.7803098143563894, Validation Loss Force: 2.2907168548213708, time: 0.07106995582580566
Test Loss Energy: 12.679369104274826, Test Loss Force: 9.229054710732594, time: 8.240475177764893


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5088755285024387, Training Loss Force: 2.240847131239844, time: 1.009577751159668
Validation Loss Energy: 0.9443590809272278, Validation Loss Force: 2.329652336340012, time: 0.0668635368347168
Test Loss Energy: 12.649221930939273, Test Loss Force: 9.183342241296327, time: 8.174115419387817


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9175192074718883, Training Loss Force: 2.199295777128672, time: 1.0380370616912842
Validation Loss Energy: 2.407663469604656, Validation Loss Force: 2.535699341858863, time: 0.08120369911193848
Test Loss Energy: 14.498475916322134, Test Loss Force: 9.297200660609256, time: 10.540533781051636


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8520050905525516, Training Loss Force: 2.1779089983048037, time: 1.0588691234588623
Validation Loss Energy: 1.211147974930077, Validation Loss Force: 2.619681348271561, time: 0.08076667785644531
Test Loss Energy: 12.85275201325424, Test Loss Force: 9.23852096602435, time: 10.4724702835083


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0417003684989607, Training Loss Force: 2.1924550007153827, time: 1.0454106330871582
Validation Loss Energy: 0.74271683295219, Validation Loss Force: 2.3870086796283942, time: 0.06824898719787598
Test Loss Energy: 12.823144930344075, Test Loss Force: 9.239999032156947, time: 8.930700063705444


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8523207823034502, Training Loss Force: 2.211439266809508, time: 0.9743633270263672
Validation Loss Energy: 2.6967206420488026, Validation Loss Force: 2.51954647667497, time: 0.07092618942260742
Test Loss Energy: 11.870652565807088, Test Loss Force: 9.210636120537885, time: 9.324940204620361


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.049383552820062, Training Loss Force: 2.178131093649471, time: 0.9531497955322266
Validation Loss Energy: 1.5078664690108752, Validation Loss Force: 2.4906250946561395, time: 0.07376956939697266
Test Loss Energy: 11.990913802602767, Test Loss Force: 9.181770327696462, time: 8.967147588729858


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.120671234900826, Training Loss Force: 2.1677151277264493, time: 1.0067222118377686
Validation Loss Energy: 1.3640995226024477, Validation Loss Force: 2.4506975107578164, time: 0.06820058822631836
Test Loss Energy: 13.493055319633065, Test Loss Force: 9.25804508171503, time: 9.073798894882202


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0723089428983394, Training Loss Force: 2.1741467153273035, time: 0.9790759086608887
Validation Loss Energy: 2.35023898955762, Validation Loss Force: 2.467526176799601, time: 0.06939530372619629
Test Loss Energy: 14.313049894123898, Test Loss Force: 9.301327426362368, time: 9.208108186721802


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5725304796648885, Training Loss Force: 2.2031331903888476, time: 0.9766461849212646
Validation Loss Energy: 1.7844975897665218, Validation Loss Force: 2.6610507148897655, time: 0.07440900802612305
Test Loss Energy: 11.934530594013415, Test Loss Force: 9.264204819102078, time: 9.015685796737671

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–â–„â–â–†â–â–„â–ƒâ–â–ƒâ–ƒâ–†â–ƒâ–ƒâ–‚â–‚â–„â–…â–‚
wandb:   test_error_force â–ˆâ–‡â–ƒâ–„â–â–…â–ˆâ–„â–â–„â–ƒâ–‚â–†â–„â–„â–ƒâ–‚â–„â–†â–…
wandb:          test_loss â–…â–„â–â–…â–‚â–†â–†â–ƒâ–‚â–â–„â–„â–†â–…â–†â–„â–„â–†â–ˆâ–„
wandb: train_error_energy â–ˆâ–†â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–â–„â–…â–‚â–ƒâ–ƒâ–„â–ƒâ–„â–„â–„â–‚
wandb:  train_error_force â–ˆâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–â–â–â–‚
wandb:         train_loss â–ˆâ–…â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–â–â–
wandb: valid_error_energy â–ˆâ–ƒâ–†â–ƒâ–…â–†â–ƒâ–ƒâ–‚â–„â–â–â–…â–‚â–â–…â–ƒâ–‚â–„â–ƒ
wandb:  valid_error_force â–…â–…â–…â–ƒâ–ˆâ–†â–„â–…â–…â–†â–â–‚â–†â–‡â–ƒâ–…â–…â–„â–„â–ˆ
wandb:         valid_loss â–‡â–„â–†â–ƒâ–ˆâ–‡â–„â–…â–„â–…â–â–‚â–†â–†â–‚â–†â–„â–„â–…â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 2062
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.93453
wandb:   test_error_force 9.2642
wandb:          test_loss 6.32041
wandb: train_error_energy 1.57253
wandb:  train_error_force 2.20313
wandb:         train_loss -2.18123
wandb: valid_error_energy 1.7845
wandb:  valid_error_force 2.66105
wandb:         valid_loss -1.64275
wandb: 
wandb: ğŸš€ View run al_58_14 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m8ubv6ig
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_165951-m8ubv6ig/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 32.92946243286133, Uncertainty Bias: -4.664906978607178
0.0005226135 0.03947258
-2.3307366 28.821682
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 38 steps.
Found uncertainty sample 1 after 246 steps.
Found uncertainty sample 2 after 439 steps.
Found uncertainty sample 3 after 117 steps.
Found uncertainty sample 4 after 610 steps.
Found uncertainty sample 5 after 617 steps.
Found uncertainty sample 6 after 13 steps.
Found uncertainty sample 7 after 228 steps.
Found uncertainty sample 8 after 87 steps.
Found uncertainty sample 9 after 21 steps.
Found uncertainty sample 10 after 69 steps.
Found uncertainty sample 11 after 746 steps.
Found uncertainty sample 12 after 292 steps.
Found uncertainty sample 13 after 184 steps.
Found uncertainty sample 14 after 23 steps.
Found uncertainty sample 15 after 1066 steps.
Found uncertainty sample 16 after 334 steps.
Found uncertainty sample 17 after 556 steps.
Found uncertainty sample 18 after 356 steps.
Found uncertainty sample 19 after 406 steps.
Found uncertainty sample 20 after 1121 steps.
Found uncertainty sample 21 after 151 steps.
Found uncertainty sample 22 after 817 steps.
Found uncertainty sample 23 after 355 steps.
Found uncertainty sample 24 after 89 steps.
Found uncertainty sample 25 after 143 steps.
Found uncertainty sample 26 after 287 steps.
Found uncertainty sample 27 after 2184 steps.
Found uncertainty sample 28 after 195 steps.
Found uncertainty sample 29 after 438 steps.
Found uncertainty sample 30 after 120 steps.
Found uncertainty sample 31 after 611 steps.
Found uncertainty sample 32 after 347 steps.
Found uncertainty sample 33 after 109 steps.
Found uncertainty sample 34 after 673 steps.
Found uncertainty sample 35 after 775 steps.
Found uncertainty sample 36 after 711 steps.
Found uncertainty sample 37 after 334 steps.
Found uncertainty sample 38 after 107 steps.
Found uncertainty sample 39 after 594 steps.
Found uncertainty sample 40 after 1752 steps.
Found uncertainty sample 41 after 1172 steps.
Found uncertainty sample 42 after 183 steps.
Found uncertainty sample 43 after 2841 steps.
Found uncertainty sample 44 after 680 steps.
Found uncertainty sample 45 after 583 steps.
Found uncertainty sample 46 after 1101 steps.
Found uncertainty sample 47 after 422 steps.
Found uncertainty sample 48 after 1511 steps.
Found uncertainty sample 49 after 249 steps.
Found uncertainty sample 50 after 686 steps.
Found uncertainty sample 51 after 80 steps.
Found uncertainty sample 52 after 204 steps.
Found uncertainty sample 53 after 526 steps.
Found uncertainty sample 54 after 25 steps.
Found uncertainty sample 55 after 995 steps.
Found uncertainty sample 56 after 2183 steps.
Found uncertainty sample 57 after 270 steps.
Found uncertainty sample 58 after 590 steps.
Found uncertainty sample 59 after 464 steps.
Found uncertainty sample 60 after 906 steps.
Found uncertainty sample 61 after 1592 steps.
Found uncertainty sample 62 after 543 steps.
Found uncertainty sample 63 after 199 steps.
Found uncertainty sample 64 after 2431 steps.
Found uncertainty sample 65 after 48 steps.
Found uncertainty sample 66 after 251 steps.
Found uncertainty sample 67 after 379 steps.
Found uncertainty sample 68 after 297 steps.
Found uncertainty sample 69 after 1566 steps.
Found uncertainty sample 70 after 1320 steps.
Found uncertainty sample 71 after 276 steps.
Found uncertainty sample 72 after 168 steps.
Found uncertainty sample 73 after 684 steps.
Found uncertainty sample 74 after 1793 steps.
Found uncertainty sample 75 after 115 steps.
Found uncertainty sample 76 after 325 steps.
Found uncertainty sample 77 after 345 steps.
Found uncertainty sample 78 after 1131 steps.
Found uncertainty sample 79 after 153 steps.
Found uncertainty sample 80 after 189 steps.
Found uncertainty sample 81 after 378 steps.
Found uncertainty sample 82 after 318 steps.
Found uncertainty sample 83 after 1007 steps.
Found uncertainty sample 84 after 1564 steps.
Found uncertainty sample 85 after 37 steps.
Found uncertainty sample 86 after 569 steps.
Found uncertainty sample 87 after 245 steps.
Found uncertainty sample 88 after 193 steps.
Found uncertainty sample 89 after 921 steps.
Found uncertainty sample 90 after 1240 steps.
Found uncertainty sample 91 after 374 steps.
Found uncertainty sample 92 after 1530 steps.
Found uncertainty sample 93 after 629 steps.
Found uncertainty sample 94 after 1581 steps.
Found uncertainty sample 95 after 16 steps.
Found uncertainty sample 96 after 669 steps.
Found uncertainty sample 97 after 336 steps.
Found uncertainty sample 98 after 924 steps.
Found uncertainty sample 99 after 101 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_171134-le5dt75i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_15
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/le5dt75i
Training model 15. Added 100 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.83995448250187, Training Loss Force: 2.44388976509571, time: 0.9756834506988525
Validation Loss Energy: 1.607664609191537, Validation Loss Force: 2.5404878418420402, time: 0.07392644882202148
Test Loss Energy: 11.992118948642494, Test Loss Force: 9.222065492305335, time: 9.559542894363403


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6708541980857847, Training Loss Force: 2.2414742526677904, time: 1.022162914276123
Validation Loss Energy: 2.0119014610787453, Validation Loss Force: 2.409469761716422, time: 0.07274317741394043
Test Loss Energy: 11.939346911318536, Test Loss Force: 9.114799040336873, time: 9.12973141670227


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6830672888393925, Training Loss Force: 2.20510257223445, time: 0.992887020111084
Validation Loss Energy: 1.2092194374571967, Validation Loss Force: 2.389806851450696, time: 0.0697476863861084
Test Loss Energy: 12.584102793877443, Test Loss Force: 9.132151630557727, time: 9.373031377792358


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8532563984200348, Training Loss Force: 2.2674510202435894, time: 0.9890406131744385
Validation Loss Energy: 1.8885645201437653, Validation Loss Force: 2.357561353086882, time: 0.07026481628417969
Test Loss Energy: 11.847210895432676, Test Loss Force: 9.132782518699143, time: 9.121443510055542


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6395546514652493, Training Loss Force: 2.2040282443608152, time: 0.9880759716033936
Validation Loss Energy: 1.8945470277546936, Validation Loss Force: 2.4182560635455865, time: 0.07256555557250977
Test Loss Energy: 11.603516573303422, Test Loss Force: 9.196556328418719, time: 9.218050003051758


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5482208147000995, Training Loss Force: 2.2057372447912686, time: 0.9947481155395508
Validation Loss Energy: 2.0292450495204877, Validation Loss Force: 2.3538122726768957, time: 0.0690619945526123
Test Loss Energy: 13.798640850304078, Test Loss Force: 9.190190425050298, time: 9.326158285140991


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.039322444362301, Training Loss Force: 2.1929733155956477, time: 0.9894585609436035
Validation Loss Energy: 1.760671545813957, Validation Loss Force: 2.31735732544389, time: 0.06999683380126953
Test Loss Energy: 12.0038150011035, Test Loss Force: 9.175417611937355, time: 9.224541187286377


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1698081487563767, Training Loss Force: 2.171971808474626, time: 0.9985544681549072
Validation Loss Energy: 1.745620113560395, Validation Loss Force: 2.426167275631255, time: 0.07135486602783203
Test Loss Energy: 11.715257942978205, Test Loss Force: 9.154140696025443, time: 9.22814154624939


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5662501332426406, Training Loss Force: 2.167226033133823, time: 0.9979274272918701
Validation Loss Energy: 0.9496047485006378, Validation Loss Force: 2.416586044951128, time: 0.07294368743896484
Test Loss Energy: 13.112323671398348, Test Loss Force: 9.018324156427047, time: 9.328980445861816


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.480396830881661, Training Loss Force: 2.181501389736536, time: 0.9895305633544922
Validation Loss Energy: 0.796648302107057, Validation Loss Force: 2.3255997578841265, time: 0.07286977767944336
Test Loss Energy: 12.707371873475681, Test Loss Force: 9.251134713813185, time: 9.494143962860107


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9282485203691744, Training Loss Force: 2.217838042348494, time: 0.9908363819122314
Validation Loss Energy: 1.366122193456769, Validation Loss Force: 2.2599179265640768, time: 0.07999849319458008
Test Loss Energy: 12.199200172486398, Test Loss Force: 9.254966451108592, time: 9.135432481765747


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.272888781705827, Training Loss Force: 2.2071388766621394, time: 0.9793307781219482
Validation Loss Energy: 1.6693036038308346, Validation Loss Force: 2.3622676881552116, time: 0.07185649871826172
Test Loss Energy: 13.795005733361947, Test Loss Force: 9.178094407507697, time: 9.415016889572144


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8855441179647352, Training Loss Force: 2.2312630287574544, time: 0.9997210502624512
Validation Loss Energy: 0.9843043948562946, Validation Loss Force: 2.32295879047885, time: 0.07678413391113281
Test Loss Energy: 13.075020872337685, Test Loss Force: 9.216061893787673, time: 9.295400857925415


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7551304863339228, Training Loss Force: 2.205555040850794, time: 0.9875290393829346
Validation Loss Energy: 0.9509594675844625, Validation Loss Force: 2.481816971250674, time: 0.0700845718383789
Test Loss Energy: 12.291559384462973, Test Loss Force: 9.150748216172333, time: 9.221035718917847


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.3769001111621275, Training Loss Force: 2.162940334817609, time: 1.0554728507995605
Validation Loss Energy: 2.8367259829077858, Validation Loss Force: 2.2797368165665257, time: 0.07263493537902832
Test Loss Energy: 14.66095353043389, Test Loss Force: 9.098788517861774, time: 9.307006120681763


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6112051345686278, Training Loss Force: 2.1841537836709994, time: 1.0138022899627686
Validation Loss Energy: 1.0091920974630002, Validation Loss Force: 2.4535141641192304, time: 0.07063770294189453
Test Loss Energy: 12.627981430176273, Test Loss Force: 9.180236955677568, time: 9.386808156967163


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.4924465045293673, Training Loss Force: 2.1898063627358613, time: 1.0357658863067627
Validation Loss Energy: 0.7797960609694474, Validation Loss Force: 2.6083134203645093, time: 0.08483743667602539
Test Loss Energy: 12.55792377125145, Test Loss Force: 9.150408257511048, time: 10.362784385681152


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.700707176237074, Training Loss Force: 2.1928652031762077, time: 1.0557770729064941
Validation Loss Energy: 1.5834365917632856, Validation Loss Force: 2.6428622083738, time: 0.08185768127441406
Test Loss Energy: 12.14410293767094, Test Loss Force: 9.09367475188352, time: 10.358731746673584


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4894883482562402, Training Loss Force: 2.202696407806281, time: 1.0540788173675537
Validation Loss Energy: 0.802358986358094, Validation Loss Force: 2.317356434767307, time: 0.08243775367736816
Test Loss Energy: 13.022922895321692, Test Loss Force: 9.142755307826253, time: 10.607325315475464


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4512969639882747, Training Loss Force: 2.1625921097442955, time: 1.0740375518798828
Validation Loss Energy: 3.0315922139367384, Validation Loss Force: 2.3867854538096016, time: 0.07935333251953125
Test Loss Energy: 14.75417559351158, Test Loss Force: 9.127478451041807, time: 10.50122857093811

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–‚â–â–†â–‚â–â–„â–ƒâ–‚â–†â–„â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–„â–ˆ
wandb:   test_error_force â–‡â–„â–„â–„â–†â–†â–†â–…â–â–ˆâ–ˆâ–†â–‡â–…â–ƒâ–†â–…â–ƒâ–…â–„
wandb:          test_loss â–‚â–â–ƒâ–„â–„â–‡â–…â–†â–†â–ˆâ–‡â–ˆâ–‡â–†â–ˆâ–ˆâ–…â–…â–†â–ˆ
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–„â–…â–‚â–â–„â–…â–ƒâ–ƒâ–â–‚â–†â–ƒâ–‚â–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–„â–‚â–‚â–‚â–â–â–â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–â–â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–
wandb: valid_error_energy â–„â–…â–‚â–„â–„â–…â–„â–„â–‚â–â–ƒâ–„â–‚â–‚â–‡â–‚â–â–ƒâ–â–ˆ
wandb:  valid_error_force â–†â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–„â–‚â–â–ƒâ–‚â–…â–â–…â–‡â–ˆâ–‚â–ƒ
wandb:         valid_loss â–†â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–â–ƒâ–‚â–„â–ƒâ–„â–‡â–ˆâ–â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2152
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.75418
wandb:   test_error_force 9.12748
wandb:          test_loss 6.43338
wandb: train_error_energy 1.4513
wandb:  train_error_force 2.16259
wandb:         train_loss -2.2355
wandb: valid_error_energy 3.03159
wandb:  valid_error_force 2.38679
wandb:         valid_loss -1.87023
wandb: 
wandb: ğŸš€ View run al_58_15 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/le5dt75i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_171134-le5dt75i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 35.4731330871582, Uncertainty Bias: -5.015822410583496
4.9591064e-05 0.028593063
-2.6563325 29.553581
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1149 steps.
Found uncertainty sample 1 after 2252 steps.
Found uncertainty sample 2 after 2214 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 117 steps.
Found uncertainty sample 5 after 3416 steps.
Found uncertainty sample 6 after 108 steps.
Found uncertainty sample 7 after 464 steps.
Found uncertainty sample 8 after 2480 steps.
Found uncertainty sample 9 after 139 steps.
Found uncertainty sample 10 after 131 steps.
Found uncertainty sample 11 after 1527 steps.
Found uncertainty sample 12 after 116 steps.
Found uncertainty sample 13 after 1403 steps.
Found uncertainty sample 14 after 2150 steps.
Found uncertainty sample 15 after 327 steps.
Found uncertainty sample 16 after 3813 steps.
Found uncertainty sample 17 after 46 steps.
Found uncertainty sample 18 after 637 steps.
Found uncertainty sample 19 after 475 steps.
Found uncertainty sample 20 after 178 steps.
Found uncertainty sample 21 after 1386 steps.
Found uncertainty sample 22 after 464 steps.
Found uncertainty sample 23 after 1439 steps.
Found uncertainty sample 24 after 1158 steps.
Found uncertainty sample 25 after 113 steps.
Found uncertainty sample 26 after 60 steps.
Found uncertainty sample 27 after 1927 steps.
Found uncertainty sample 28 after 637 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 256 steps.
Found uncertainty sample 31 after 798 steps.
Found uncertainty sample 32 after 1359 steps.
Found uncertainty sample 33 after 2461 steps.
Found uncertainty sample 34 after 1553 steps.
Found uncertainty sample 35 after 1 steps.
Found uncertainty sample 36 after 540 steps.
Found uncertainty sample 37 after 1481 steps.
Found uncertainty sample 38 after 264 steps.
Found uncertainty sample 39 after 369 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 629 steps.
Found uncertainty sample 42 after 578 steps.
Found uncertainty sample 43 after 609 steps.
Found uncertainty sample 44 after 322 steps.
Found uncertainty sample 45 after 89 steps.
Found uncertainty sample 46 after 1674 steps.
Found uncertainty sample 47 after 120 steps.
Found uncertainty sample 48 after 60 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 964 steps.
Found uncertainty sample 51 after 1 steps.
Found uncertainty sample 52 after 798 steps.
Found uncertainty sample 53 after 337 steps.
Found uncertainty sample 54 after 79 steps.
Found uncertainty sample 55 after 84 steps.
Found uncertainty sample 56 after 1075 steps.
Found uncertainty sample 57 after 2405 steps.
Found uncertainty sample 58 after 209 steps.
Found uncertainty sample 59 after 1016 steps.
Found uncertainty sample 60 after 827 steps.
Found uncertainty sample 61 after 391 steps.
Found uncertainty sample 62 after 528 steps.
Found uncertainty sample 63 after 177 steps.
Found uncertainty sample 64 after 949 steps.
Found uncertainty sample 65 after 2224 steps.
Found uncertainty sample 66 after 455 steps.
Found uncertainty sample 67 after 120 steps.
Found uncertainty sample 68 after 2288 steps.
Found uncertainty sample 69 after 19 steps.
Found uncertainty sample 70 after 165 steps.
Found uncertainty sample 71 after 584 steps.
Found uncertainty sample 72 after 441 steps.
Found uncertainty sample 73 after 2409 steps.
Found uncertainty sample 74 after 110 steps.
Found uncertainty sample 75 after 1485 steps.
Found uncertainty sample 76 after 1165 steps.
Found uncertainty sample 77 after 1126 steps.
Found uncertainty sample 78 after 69 steps.
Found uncertainty sample 79 after 147 steps.
Found uncertainty sample 80 after 527 steps.
Found uncertainty sample 81 after 282 steps.
Found uncertainty sample 82 after 570 steps.
Found uncertainty sample 83 after 2530 steps.
Found uncertainty sample 84 after 151 steps.
Found uncertainty sample 85 after 633 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 114 steps.
Found uncertainty sample 88 after 1805 steps.
Found uncertainty sample 89 after 732 steps.
Found uncertainty sample 90 after 1358 steps.
Found uncertainty sample 91 after 134 steps.
Found uncertainty sample 92 after 1884 steps.
Found uncertainty sample 93 after 528 steps.
Found uncertainty sample 94 after 1471 steps.
Found uncertainty sample 95 after 275 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 20 steps.
Found uncertainty sample 98 after 133 steps.
Found uncertainty sample 99 after 1595 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_172745-1s29inb6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_16
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1s29inb6
Training model 16. Added 95 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.751371367535882, Training Loss Force: 2.4083764625718924, time: 1.0972235202789307
Validation Loss Energy: 1.7612021107214164, Validation Loss Force: 2.458414778017382, time: 0.07778787612915039
Test Loss Energy: 11.953313829999436, Test Loss Force: 9.04634079873176, time: 9.070101499557495


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5801991120067487, Training Loss Force: 2.177635043193705, time: 1.0249676704406738
Validation Loss Energy: 0.9958924868813821, Validation Loss Force: 2.6013227225281064, time: 0.07269787788391113
Test Loss Energy: 12.728061008127538, Test Loss Force: 9.15214447529285, time: 9.205873727798462


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9058806956279033, Training Loss Force: 2.1771998172620615, time: 1.0231328010559082
Validation Loss Energy: 2.6158876226978163, Validation Loss Force: 2.2401255341899935, time: 0.0723268985748291
Test Loss Energy: 11.575822714990577, Test Loss Force: 9.117266265769263, time: 9.275062322616577


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8539994407054625, Training Loss Force: 2.161874145688376, time: 1.0867559909820557
Validation Loss Energy: 2.09273403509144, Validation Loss Force: 2.3409826331614014, time: 0.07494282722473145
Test Loss Energy: 11.560127547984854, Test Loss Force: 9.173597185580954, time: 9.03515362739563


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3858008448406187, Training Loss Force: 2.1755710974321976, time: 1.0327510833740234
Validation Loss Energy: 1.9414071928423318, Validation Loss Force: 2.328065039333266, time: 0.07706427574157715
Test Loss Energy: 11.509366802946987, Test Loss Force: 9.167486747842299, time: 9.115392446517944


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5009230144100154, Training Loss Force: 2.1773414380198597, time: 1.1133763790130615
Validation Loss Energy: 0.8659814620820301, Validation Loss Force: 2.293482516948367, time: 0.0746307373046875
Test Loss Energy: 12.499861772535422, Test Loss Force: 9.083982745052007, time: 9.298194646835327


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.610277515512945, Training Loss Force: 2.158219410195519, time: 1.0625147819519043
Validation Loss Energy: 1.8176431168181757, Validation Loss Force: 2.470516066756547, time: 0.08135485649108887
Test Loss Energy: 13.66638814554175, Test Loss Force: 9.225934236979635, time: 9.592936038970947


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.600198089657201, Training Loss Force: 2.1890664842936447, time: 1.0390946865081787
Validation Loss Energy: 1.5510337219805874, Validation Loss Force: 2.4764598856033695, time: 0.07181453704833984
Test Loss Energy: 11.93675066368867, Test Loss Force: 9.10709384384347, time: 9.061227083206177


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8760779644768353, Training Loss Force: 2.2031673515062034, time: 1.0346269607543945
Validation Loss Energy: 2.818601382436701, Validation Loss Force: 2.4281386769147266, time: 0.07373213768005371
Test Loss Energy: 14.383094659222785, Test Loss Force: 9.312116728092102, time: 9.224801540374756


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.906884162881743, Training Loss Force: 2.199097982206221, time: 1.0681090354919434
Validation Loss Energy: 1.413084675016961, Validation Loss Force: 2.2625645720325744, time: 0.07202577590942383
Test Loss Energy: 12.383254785907129, Test Loss Force: 9.159303892222479, time: 9.217208623886108


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9630404761372233, Training Loss Force: 2.178227732792878, time: 1.088667392730713
Validation Loss Energy: 2.1062491615726735, Validation Loss Force: 2.445007423402778, time: 0.07331991195678711
Test Loss Energy: 14.083035189186944, Test Loss Force: 9.056115545220997, time: 9.07259464263916


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3535848519304436, Training Loss Force: 2.173808715676008, time: 1.1196503639221191
Validation Loss Energy: 1.0189910985678443, Validation Loss Force: 2.431285103281259, time: 0.07333731651306152
Test Loss Energy: 12.1767895045583, Test Loss Force: 9.101871629830502, time: 9.168676376342773


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4858892915107778, Training Loss Force: 2.121270657550059, time: 0.9993035793304443
Validation Loss Energy: 0.7831152229259335, Validation Loss Force: 2.3024101023506227, time: 0.07564520835876465
Test Loss Energy: 12.423017181358869, Test Loss Force: 9.029704825439314, time: 9.072521209716797


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6240334968473522, Training Loss Force: 2.1765404748350434, time: 1.0437498092651367
Validation Loss Energy: 1.258692012632146, Validation Loss Force: 2.306059872321525, time: 0.07602858543395996
Test Loss Energy: 12.185138441050002, Test Loss Force: 9.109778995918722, time: 9.166377782821655


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4682752308337113, Training Loss Force: 2.163529083219679, time: 1.0530362129211426
Validation Loss Energy: 0.8169169559506365, Validation Loss Force: 2.399080576040296, time: 0.08025693893432617
Test Loss Energy: 12.381498973240484, Test Loss Force: 9.012923578599153, time: 9.28843879699707


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8841662589722843, Training Loss Force: 2.1555990094668567, time: 1.051546335220337
Validation Loss Energy: 1.7611300772527085, Validation Loss Force: 2.540474481693285, time: 0.0769352912902832
Test Loss Energy: 13.675326033763781, Test Loss Force: 8.99191968537113, time: 9.106616735458374


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.382655118291402, Training Loss Force: 2.146006203172129, time: 1.0772347450256348
Validation Loss Energy: 1.5848081223676278, Validation Loss Force: 2.3397011722265875, time: 0.07183647155761719
Test Loss Energy: 11.97911531300818, Test Loss Force: 9.158710365865296, time: 9.125259160995483


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6133644096928195, Training Loss Force: 2.1551310098179206, time: 1.0772526264190674
Validation Loss Energy: 0.7599629201416593, Validation Loss Force: 2.237086991024663, time: 0.07363700866699219
Test Loss Energy: 12.317855752563059, Test Loss Force: 9.015368961470717, time: 9.647053956985474


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5522791121042556, Training Loss Force: 2.14601347968172, time: 1.082857608795166
Validation Loss Energy: 1.3295311397083152, Validation Loss Force: 2.373806291962617, time: 0.07172989845275879
Test Loss Energy: 13.54244978544443, Test Loss Force: 9.069862280256594, time: 9.029761791229248


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8840831286276398, Training Loss Force: 2.1468741166071523, time: 1.0236682891845703
Validation Loss Energy: 2.114398184306192, Validation Loss Force: 2.3996061865592586, time: 0.07206439971923828
Test Loss Energy: 14.325413445730815, Test Loss Force: 9.194873392682185, time: 9.073935747146606

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–â–â–â–ƒâ–†â–‚â–ˆâ–ƒâ–‡â–ƒâ–ƒâ–ƒâ–ƒâ–†â–‚â–ƒâ–†â–ˆ
wandb:   test_error_force â–‚â–…â–„â–…â–…â–ƒâ–†â–„â–ˆâ–…â–‚â–ƒâ–‚â–„â–â–â–…â–‚â–ƒâ–…
wandb:          test_loss â–â–„â–ƒâ–…â–†â–…â–‡â–„â–ˆâ–…â–…â–„â–„â–„â–‚â–„â–†â–„â–†â–‡
wandb: train_error_energy â–ˆâ–‚â–„â–ƒâ–â–‚â–‚â–‚â–„â–„â–„â–†â–‚â–‚â–â–„â–â–‚â–‚â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–„â–‚â–‡â–†â–…â–â–…â–„â–ˆâ–ƒâ–†â–‚â–â–ƒâ–â–„â–„â–â–ƒâ–†
wandb:  valid_error_force â–…â–ˆâ–â–ƒâ–ƒâ–‚â–…â–†â–…â–â–…â–…â–‚â–‚â–„â–‡â–ƒâ–â–„â–„
wandb:         valid_loss â–†â–ˆâ–ƒâ–„â–„â–‚â–‡â–†â–‡â–‚â–†â–…â–‚â–ƒâ–„â–ˆâ–„â–â–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 2237
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.32541
wandb:   test_error_force 9.19487
wandb:          test_loss 6.59008
wandb: train_error_energy 1.88408
wandb:  train_error_force 2.14687
wandb:         train_loss -2.22527
wandb: valid_error_energy 2.1144
wandb:  valid_error_force 2.39961
wandb:         valid_loss -1.91324
wandb: 
wandb: ğŸš€ View run al_58_16 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/1s29inb6
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_172745-1s29inb6/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 34.96609878540039, Uncertainty Bias: -4.871232032775879
0.00015115738 0.023257494
-2.5219827 27.918064
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 385 steps.
Found uncertainty sample 1 after 690 steps.
Found uncertainty sample 2 after 968 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 643 steps.
Found uncertainty sample 5 after 2015 steps.
Found uncertainty sample 6 after 177 steps.
Found uncertainty sample 7 after 228 steps.
Found uncertainty sample 8 after 881 steps.
Found uncertainty sample 9 after 774 steps.
Found uncertainty sample 10 after 1841 steps.
Found uncertainty sample 11 after 1817 steps.
Found uncertainty sample 12 after 1607 steps.
Found uncertainty sample 13 after 330 steps.
Found uncertainty sample 14 after 1453 steps.
Found uncertainty sample 15 after 1244 steps.
Found uncertainty sample 16 after 167 steps.
Found uncertainty sample 17 after 74 steps.
Found uncertainty sample 18 after 35 steps.
Found uncertainty sample 19 after 250 steps.
Found uncertainty sample 20 after 45 steps.
Found uncertainty sample 21 after 436 steps.
Found uncertainty sample 22 after 796 steps.
Found uncertainty sample 23 after 932 steps.
Found uncertainty sample 24 after 3011 steps.
Found uncertainty sample 25 after 2779 steps.
Found uncertainty sample 26 after 36 steps.
Found uncertainty sample 27 after 3624 steps.
Found uncertainty sample 28 after 293 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 650 steps.
Found uncertainty sample 31 after 1718 steps.
Found uncertainty sample 32 after 2982 steps.
Found uncertainty sample 33 after 681 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 103 steps.
Found uncertainty sample 36 after 2174 steps.
Found uncertainty sample 37 after 1 steps.
Found uncertainty sample 38 after 1179 steps.
Found uncertainty sample 39 after 1408 steps.
Found uncertainty sample 40 after 791 steps.
Found uncertainty sample 41 after 208 steps.
Found uncertainty sample 42 after 348 steps.
Found uncertainty sample 43 after 1 steps.
Found uncertainty sample 44 after 913 steps.
Found uncertainty sample 45 after 1008 steps.
Found uncertainty sample 46 after 435 steps.
Found uncertainty sample 47 after 391 steps.
Found uncertainty sample 48 after 577 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2038 steps.
Found uncertainty sample 51 after 75 steps.
Found uncertainty sample 52 after 1646 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 33 steps.
Found uncertainty sample 55 after 162 steps.
Found uncertainty sample 56 after 1117 steps.
Found uncertainty sample 57 after 468 steps.
Found uncertainty sample 58 after 82 steps.
Found uncertainty sample 59 after 416 steps.
Found uncertainty sample 60 after 2434 steps.
Found uncertainty sample 61 after 2114 steps.
Found uncertainty sample 62 after 394 steps.
Found uncertainty sample 63 after 2470 steps.
Found uncertainty sample 64 after 618 steps.
Found uncertainty sample 65 after 1784 steps.
Found uncertainty sample 66 after 599 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2645 steps.
Found uncertainty sample 69 after 1905 steps.
Found uncertainty sample 70 after 274 steps.
Found uncertainty sample 71 after 361 steps.
Found uncertainty sample 72 after 178 steps.
Found uncertainty sample 73 after 1007 steps.
Found uncertainty sample 74 after 654 steps.
Found uncertainty sample 75 after 1335 steps.
Found uncertainty sample 76 after 1448 steps.
Found uncertainty sample 77 after 1285 steps.
Found uncertainty sample 78 after 1520 steps.
Found uncertainty sample 79 after 196 steps.
Found uncertainty sample 80 after 282 steps.
Found uncertainty sample 81 after 104 steps.
Found uncertainty sample 82 after 1787 steps.
Found uncertainty sample 83 after 339 steps.
Found uncertainty sample 84 after 2121 steps.
Found uncertainty sample 85 after 828 steps.
Found uncertainty sample 86 after 3451 steps.
Found uncertainty sample 87 after 2663 steps.
Found uncertainty sample 88 after 911 steps.
Found uncertainty sample 89 after 1249 steps.
Found uncertainty sample 90 after 268 steps.
Found uncertainty sample 91 after 483 steps.
Found uncertainty sample 92 after 350 steps.
Found uncertainty sample 93 after 825 steps.
Found uncertainty sample 94 after 94 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 506 steps.
Found uncertainty sample 97 after 196 steps.
Found uncertainty sample 98 after 973 steps.
Found uncertainty sample 99 after 366 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_174408-rekmklhz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_17
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rekmklhz
Training model 17. Added 98 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0955948163953955, Training Loss Force: 2.4065458092790317, time: 1.1264288425445557
Validation Loss Energy: 1.6961965255975497, Validation Loss Force: 2.415030700966822, time: 0.07542228698730469
Test Loss Energy: 13.883412477065352, Test Loss Force: 9.100466179487231, time: 8.982648849487305


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8323573601164675, Training Loss Force: 2.1867071832049505, time: 1.0763063430786133
Validation Loss Energy: 1.2314615801074908, Validation Loss Force: 2.3363979867813214, time: 0.07275700569152832
Test Loss Energy: 13.533935500207678, Test Loss Force: 9.15981410534487, time: 9.078794240951538


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4577817336500982, Training Loss Force: 2.1417371222855532, time: 1.088916540145874
Validation Loss Energy: 1.1586615728649952, Validation Loss Force: 2.357098757936217, time: 0.07253456115722656
Test Loss Energy: 13.073960603471269, Test Loss Force: 9.12578574584222, time: 9.144119501113892


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.2966269768600605, Training Loss Force: 2.170444157799068, time: 1.071641445159912
Validation Loss Energy: 1.0826821842223695, Validation Loss Force: 2.4223046339568457, time: 0.07254934310913086
Test Loss Energy: 12.194120508695875, Test Loss Force: 9.146868955918475, time: 9.099607229232788


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7153987585650152, Training Loss Force: 2.171542889722157, time: 1.0586271286010742
Validation Loss Energy: 0.9165492354512252, Validation Loss Force: 2.6361363754864784, time: 0.07516002655029297
Test Loss Energy: 12.084199336879312, Test Loss Force: 9.049245957249646, time: 9.104380130767822


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9815242094662904, Training Loss Force: 2.138981995764448, time: 1.0759656429290771
Validation Loss Energy: 2.7075438098903417, Validation Loss Force: 2.427817588006299, time: 0.07122588157653809
Test Loss Energy: 11.74212722130366, Test Loss Force: 9.077804392058036, time: 9.252840995788574


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.963971757365667, Training Loss Force: 2.131533731134737, time: 1.112966537475586
Validation Loss Energy: 0.959340567235325, Validation Loss Force: 2.3620272054776095, time: 0.07901549339294434
Test Loss Energy: 13.070501831166258, Test Loss Force: 9.14112730025453, time: 9.115570306777954


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3555782123082485, Training Loss Force: 2.1372752611630097, time: 1.0440137386322021
Validation Loss Energy: 4.931802720083532, Validation Loss Force: 2.504605376983215, time: 0.07363414764404297
Test Loss Energy: 10.958481475293592, Test Loss Force: 9.020970253966231, time: 9.076692819595337


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.121344734934153, Training Loss Force: 2.1984139738986945, time: 1.1098072528839111
Validation Loss Energy: 0.9459697303606531, Validation Loss Force: 2.323003435642608, time: 0.0747215747833252
Test Loss Energy: 12.11047602615645, Test Loss Force: 9.135672810845568, time: 9.22528624534607


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.865971582080766, Training Loss Force: 2.175157641157034, time: 1.0809519290924072
Validation Loss Energy: 1.3113592220437216, Validation Loss Force: 2.2297213183465177, time: 0.07564544677734375
Test Loss Energy: 12.58364762550057, Test Loss Force: 9.059829223568396, time: 9.488978862762451


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.593121437565129, Training Loss Force: 2.1242637665359307, time: 1.1042113304138184
Validation Loss Energy: 2.6354268402529795, Validation Loss Force: 2.463599851749456, time: 0.07328486442565918
Test Loss Energy: 14.707965734830433, Test Loss Force: 9.082800057119226, time: 9.161585330963135


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0422802744254844, Training Loss Force: 2.1194824956743417, time: 1.0533132553100586
Validation Loss Energy: 1.7029378896578, Validation Loss Force: 2.4266457916258535, time: 0.07254195213317871
Test Loss Energy: 13.697250494868193, Test Loss Force: 9.065203920479851, time: 9.241055727005005


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.013626745087631, Training Loss Force: 2.1253491611872315, time: 1.1156327724456787
Validation Loss Energy: 1.3698716635377606, Validation Loss Force: 2.3770024848832643, time: 0.07798004150390625
Test Loss Energy: 12.21210317565644, Test Loss Force: 8.979475138153834, time: 8.973605632781982


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9290107126840026, Training Loss Force: 2.151638648805917, time: 1.0923573970794678
Validation Loss Energy: 1.11454591633549, Validation Loss Force: 2.2021142409615257, time: 0.07565641403198242
Test Loss Energy: 12.338640348159132, Test Loss Force: 9.024322550782053, time: 9.01839303970337


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5183791849710977, Training Loss Force: 2.148512987099808, time: 1.08467698097229
Validation Loss Energy: 3.3588169933497944, Validation Loss Force: 2.3817111579776262, time: 0.07203125953674316
Test Loss Energy: 15.292001196222024, Test Loss Force: 9.05865431856346, time: 9.240794658660889


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.836897640431787, Training Loss Force: 2.1852544256414097, time: 1.0603346824645996
Validation Loss Energy: 1.1509954638417068, Validation Loss Force: 2.4168224082495304, time: 0.0806434154510498
Test Loss Energy: 12.190589871381277, Test Loss Force: 9.134476734784663, time: 9.036421537399292


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3792839218890132, Training Loss Force: 2.1512717571591975, time: 1.0797274112701416
Validation Loss Energy: 0.91987285079063, Validation Loss Force: 2.4733161312665883, time: 0.07339119911193848
Test Loss Energy: 12.715614810127466, Test Loss Force: 8.997477278755309, time: 9.053960084915161


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0743904135881066, Training Loss Force: 2.159195222148417, time: 1.0877270698547363
Validation Loss Energy: 4.970105598558593, Validation Loss Force: 2.2555678621292317, time: 0.07599544525146484
Test Loss Energy: 16.552842385220007, Test Loss Force: 9.062539020804614, time: 9.223975658416748


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8695897841248401, Training Loss Force: 2.156380261682565, time: 1.0810258388519287
Validation Loss Energy: 1.9658783093106498, Validation Loss Force: 2.3596075712033855, time: 0.0759727954864502
Test Loss Energy: 13.617231397113672, Test Loss Force: 9.120877287811354, time: 9.065256595611572


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8434908395272585, Training Loss Force: 2.1461923734897517, time: 1.0769882202148438
Validation Loss Energy: 0.8653654478898208, Validation Loss Force: 2.2921980499800823, time: 0.0712590217590332
Test Loss Energy: 12.376706690213442, Test Loss Force: 8.993243039582172, time: 9.086439847946167

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–„â–„â–ƒâ–‚â–‚â–„â–â–‚â–ƒâ–†â–„â–ƒâ–ƒâ–†â–ƒâ–ƒâ–ˆâ–„â–ƒ
wandb:   test_error_force â–†â–ˆâ–‡â–‡â–„â–…â–‡â–ƒâ–‡â–„â–…â–„â–â–ƒâ–„â–‡â–‚â–„â–†â–‚
wandb:          test_loss â–„â–ˆâ–ˆâ–„â–â–ƒâ–‡â–ƒâ–„â–ƒâ–‡â–‡â–ƒâ–„â–‡â–…â–‚â–‡â–‡â–‚
wandb: train_error_energy â–ˆâ–ƒâ–‚â–â–ƒâ–„â–„â–â–„â–ƒâ–‚â–„â–„â–ƒâ–‚â–ƒâ–â–„â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–‚â–â–â–â–ƒâ–‚â–â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–â–â–‚â–‚â–â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–‚â–‚â–â–â–„â–â–ˆâ–â–‚â–„â–‚â–‚â–â–…â–â–â–ˆâ–ƒâ–
wandb:  valid_error_force â–„â–ƒâ–ƒâ–…â–ˆâ–…â–„â–†â–ƒâ–â–…â–…â–„â–â–„â–„â–…â–‚â–„â–‚
wandb:         valid_loss â–„â–ƒâ–ƒâ–„â–‡â–…â–ƒâ–ˆâ–‚â–‚â–†â–„â–„â–â–…â–„â–„â–…â–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 2325
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.37671
wandb:   test_error_force 8.99324
wandb:          test_loss 6.26294
wandb: train_error_energy 1.84349
wandb:  train_error_force 2.14619
wandb:         train_loss -2.22768
wandb: valid_error_energy 0.86537
wandb:  valid_error_force 2.2922
wandb:         valid_loss -2.12196
wandb: 
wandb: ğŸš€ View run al_58_17 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rekmklhz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_174408-rekmklhz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 36.72154235839844, Uncertainty Bias: -5.120543003082275
0.00012207031 0.003332615
-2.8597417 26.44924
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 380 steps.
Found uncertainty sample 1 after 2638 steps.
Found uncertainty sample 2 after 3094 steps.
Found uncertainty sample 3 after 625 steps.
Found uncertainty sample 4 after 2455 steps.
Found uncertainty sample 5 after 1324 steps.
Found uncertainty sample 6 after 249 steps.
Found uncertainty sample 7 after 189 steps.
Found uncertainty sample 8 after 372 steps.
Found uncertainty sample 9 after 1391 steps.
Found uncertainty sample 10 after 1151 steps.
Found uncertainty sample 11 after 141 steps.
Found uncertainty sample 12 after 3926 steps.
Found uncertainty sample 13 after 2894 steps.
Found uncertainty sample 14 after 361 steps.
Found uncertainty sample 15 after 456 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1873 steps.
Found uncertainty sample 18 after 297 steps.
Found uncertainty sample 19 after 249 steps.
Found uncertainty sample 20 after 163 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 28 steps.
Found uncertainty sample 23 after 1575 steps.
Found uncertainty sample 24 after 800 steps.
Found uncertainty sample 25 after 1049 steps.
Found uncertainty sample 26 after 35 steps.
Found uncertainty sample 27 after 568 steps.
Found uncertainty sample 28 after 56 steps.
Found uncertainty sample 29 after 2647 steps.
Found uncertainty sample 30 after 2013 steps.
Found uncertainty sample 31 after 993 steps.
Found uncertainty sample 32 after 550 steps.
Found uncertainty sample 33 after 145 steps.
Found uncertainty sample 34 after 1716 steps.
Found uncertainty sample 35 after 2528 steps.
Found uncertainty sample 36 after 2697 steps.
Found uncertainty sample 37 after 1590 steps.
Found uncertainty sample 38 after 2549 steps.
Found uncertainty sample 39 after 1270 steps.
Found uncertainty sample 40 after 14 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 560 steps.
Found uncertainty sample 43 after 1629 steps.
Found uncertainty sample 44 after 501 steps.
Found uncertainty sample 45 after 879 steps.
Found uncertainty sample 46 after 1303 steps.
Found uncertainty sample 47 after 113 steps.
Found uncertainty sample 48 after 1 steps.
Found uncertainty sample 49 after 98 steps.
Found uncertainty sample 50 after 226 steps.
Found uncertainty sample 51 after 1975 steps.
Found uncertainty sample 52 after 263 steps.
Found uncertainty sample 53 after 1506 steps.
Found uncertainty sample 54 after 385 steps.
Found uncertainty sample 55 after 93 steps.
Found uncertainty sample 56 after 1201 steps.
Found uncertainty sample 57 after 3789 steps.
Found uncertainty sample 58 after 1048 steps.
Found uncertainty sample 59 after 158 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 529 steps.
Found uncertainty sample 62 after 88 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 456 steps.
Found uncertainty sample 65 after 2731 steps.
Found uncertainty sample 66 after 1662 steps.
Found uncertainty sample 67 after 21 steps.
Found uncertainty sample 68 after 203 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 19 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 631 steps.
Found uncertainty sample 74 after 883 steps.
Found uncertainty sample 75 after 609 steps.
Found uncertainty sample 76 after 180 steps.
Found uncertainty sample 77 after 95 steps.
Found uncertainty sample 78 after 1026 steps.
Found uncertainty sample 79 after 2749 steps.
Found uncertainty sample 80 after 159 steps.
Found uncertainty sample 81 after 2599 steps.
Found uncertainty sample 82 after 476 steps.
Found uncertainty sample 83 after 895 steps.
Found uncertainty sample 84 after 1 steps.
Found uncertainty sample 85 after 560 steps.
Found uncertainty sample 86 after 1182 steps.
Found uncertainty sample 87 after 1 steps.
Found uncertainty sample 88 after 1467 steps.
Found uncertainty sample 89 after 2311 steps.
Found uncertainty sample 90 after 281 steps.
Found uncertainty sample 91 after 1953 steps.
Found uncertainty sample 92 after 1835 steps.
Found uncertainty sample 93 after 2590 steps.
Found uncertainty sample 94 after 56 steps.
Found uncertainty sample 95 after 3128 steps.
Found uncertainty sample 96 after 216 steps.
Found uncertainty sample 97 after 2637 steps.
Found uncertainty sample 98 after 1146 steps.
Found uncertainty sample 99 after 164 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_180227-4n0cwe0w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_18
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/4n0cwe0w
Training model 18. Added 94 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.548449872300553, Training Loss Force: 2.3995758229843402, time: 1.1522886753082275
Validation Loss Energy: 1.5896194459382624, Validation Loss Force: 2.2647901501461227, time: 0.07820439338684082
Test Loss Energy: 12.138878918988661, Test Loss Force: 9.000911121442433, time: 8.343364715576172


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.40854553151633, Training Loss Force: 2.1496860888520324, time: 1.1761939525604248
Validation Loss Energy: 2.7776318182700104, Validation Loss Force: 2.4848086425607865, time: 0.07925772666931152
Test Loss Energy: 14.387806347677072, Test Loss Force: 8.987735501289352, time: 8.83080768585205


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4070482778103968, Training Loss Force: 2.1212192976140427, time: 1.1631932258605957
Validation Loss Energy: 2.4122185009883275, Validation Loss Force: 2.289563205976319, time: 0.07329368591308594
Test Loss Energy: 13.906525361873214, Test Loss Force: 9.095088143704393, time: 8.648691415786743


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5746482888416649, Training Loss Force: 2.136463693191551, time: 1.1406316757202148
Validation Loss Energy: 2.470063491717448, Validation Loss Force: 2.363108932188527, time: 0.07102704048156738
Test Loss Energy: 14.320094651598867, Test Loss Force: 9.146572761653722, time: 8.380687952041626


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.4662937486491314, Training Loss Force: 2.1475765755658704, time: 1.2093634605407715
Validation Loss Energy: 4.728412268810173, Validation Loss Force: 2.2304133740520613, time: 0.0747385025024414
Test Loss Energy: 15.740727164805673, Test Loss Force: 8.955620389700165, time: 8.420613765716553


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.797123166926595, Training Loss Force: 2.1390068941924794, time: 1.1790473461151123
Validation Loss Energy: 1.558771363467005, Validation Loss Force: 2.4997678897879343, time: 0.07254791259765625
Test Loss Energy: 13.466556674683913, Test Loss Force: 9.116542486122365, time: 8.537312269210815


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2471510255453766, Training Loss Force: 2.1358830174717576, time: 1.1018519401550293
Validation Loss Energy: 1.534971316137227, Validation Loss Force: 2.5207805090817015, time: 0.07066059112548828
Test Loss Energy: 12.256929869561827, Test Loss Force: 9.024521446790683, time: 10.101272821426392


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.028040231452194, Training Loss Force: 2.1909434616794075, time: 1.2260124683380127
Validation Loss Energy: 1.2272575866323743, Validation Loss Force: 2.4236396468212558, time: 0.07912516593933105
Test Loss Energy: 12.867134402250452, Test Loss Force: 8.944834091089382, time: 10.984956502914429


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5546718692080437, Training Loss Force: 2.124178670178567, time: 1.1336796283721924
Validation Loss Energy: 1.0790119286900417, Validation Loss Force: 2.3864338592281813, time: 0.0908346176147461
Test Loss Energy: 12.747515170732187, Test Loss Force: 9.104812406085278, time: 9.439329147338867


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4775358410686465, Training Loss Force: 2.1316599374420204, time: 1.1256372928619385
Validation Loss Energy: 1.6463380647927075, Validation Loss Force: 2.320408894754258, time: 0.07839155197143555
Test Loss Energy: 12.032059642623963, Test Loss Force: 9.152400659059754, time: 9.166083574295044


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6851014230615466, Training Loss Force: 2.115520326932024, time: 1.1201601028442383
Validation Loss Energy: 0.7971302694734177, Validation Loss Force: 2.21848198187124, time: 0.07806587219238281
Test Loss Energy: 12.879535968493556, Test Loss Force: 8.970477723823995, time: 9.179325342178345


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9994253176219832, Training Loss Force: 2.0922489415674654, time: 1.1145386695861816
Validation Loss Energy: 0.8887398631471579, Validation Loss Force: 2.3497338646000827, time: 0.0760345458984375
Test Loss Energy: 12.326763866073112, Test Loss Force: 8.95480014651499, time: 9.381211757659912


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9626429918096415, Training Loss Force: 2.119710098880373, time: 1.1059415340423584
Validation Loss Energy: 2.4444939483522683, Validation Loss Force: 2.346732618516695, time: 0.07594156265258789
Test Loss Energy: 14.290150543197946, Test Loss Force: 9.09256917509204, time: 9.142271995544434


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.898038870366311, Training Loss Force: 2.145355402492598, time: 1.1295907497406006
Validation Loss Energy: 2.2621926032243023, Validation Loss Force: 2.4718785792604785, time: 0.08066272735595703
Test Loss Energy: 13.962356514193647, Test Loss Force: 9.10676112251233, time: 9.156481266021729


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.37888656417756, Training Loss Force: 2.171576200372187, time: 1.154686450958252
Validation Loss Energy: 3.114870474513731, Validation Loss Force: 2.4147960076870145, time: 0.07925057411193848
Test Loss Energy: 11.611170977915412, Test Loss Force: 9.001397794588938, time: 9.687345027923584


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1195123489022536, Training Loss Force: 2.1165797178767045, time: 1.1946320533752441
Validation Loss Energy: 2.6089523694787493, Validation Loss Force: 2.474852325704344, time: 0.07752227783203125
Test Loss Energy: 14.354385135821135, Test Loss Force: 9.114601650550949, time: 9.251368522644043


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5931266007159839, Training Loss Force: 2.143931710175894, time: 1.104628324508667
Validation Loss Energy: 2.1953953108177275, Validation Loss Force: 2.3891228118344054, time: 0.0757753849029541
Test Loss Energy: 11.752811698326976, Test Loss Force: 8.926026433777349, time: 9.150303602218628


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7476261289090942, Training Loss Force: 2.140827029879436, time: 1.1140203475952148
Validation Loss Energy: 0.841069683373921, Validation Loss Force: 2.504012297713037, time: 0.07918548583984375
Test Loss Energy: 12.210620893965563, Test Loss Force: 9.282423137635844, time: 9.32003903388977


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5203282598297612, Training Loss Force: 2.170680170939402, time: 1.193225383758545
Validation Loss Energy: 1.4786614065001324, Validation Loss Force: 2.5892718683504947, time: 0.07772040367126465
Test Loss Energy: 13.281288749910903, Test Loss Force: 9.017755806838846, time: 9.210581064224243


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9017210929003032, Training Loss Force: 2.104179730197707, time: 1.165306806564331
Validation Loss Energy: 1.048538041718516, Validation Loss Force: 2.36515926968423, time: 0.07741022109985352
Test Loss Energy: 12.35054799926235, Test Loss Force: 9.007576856393591, time: 9.189089059829712

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.039 MB of 0.058 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–…â–†â–ˆâ–„â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–†â–…â–â–†â–â–‚â–„â–‚
wandb:   test_error_force â–‚â–‚â–„â–…â–‚â–…â–ƒâ–â–…â–…â–‚â–‚â–„â–…â–‚â–…â–â–ˆâ–ƒâ–ƒ
wandb:          test_loss â–â–„â–†â–‡â–†â–†â–„â–ƒâ–„â–†â–„â–„â–†â–†â–ƒâ–‡â–ƒâ–ˆâ–…â–„
wandb: train_error_energy â–…â–â–â–‚â–ˆâ–‚â–„â–ƒâ–‚â–â–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–â–‚â–„â–‚â–‚â–ƒâ–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–…â–„â–„â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–â–„â–„â–…â–„â–ƒâ–â–‚â–
wandb:  valid_error_force â–‚â–†â–‚â–„â–â–†â–‡â–…â–„â–ƒâ–â–ƒâ–ƒâ–†â–…â–†â–„â–†â–ˆâ–„
wandb:         valid_loss â–‚â–‡â–„â–…â–…â–‡â–‡â–…â–„â–„â–â–ƒâ–…â–‡â–‡â–‡â–…â–†â–ˆâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2409
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.35055
wandb:   test_error_force 9.00758
wandb:          test_loss 6.38557
wandb: train_error_energy 1.90172
wandb:  train_error_force 2.10418
wandb:         train_loss -2.27347
wandb: valid_error_energy 1.04854
wandb:  valid_error_force 2.36516
wandb:         valid_loss -2.01961
wandb: 
wandb: ğŸš€ View run al_58_18 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/4n0cwe0w
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_180227-4n0cwe0w/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 35.506988525390625, Uncertainty Bias: -4.8560357093811035
2.2888184e-05 0.0019557476
-2.411824 27.16255
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1584 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2858 steps.
Found uncertainty sample 4 after 1658 steps.
Found uncertainty sample 5 after 1146 steps.
Found uncertainty sample 6 after 3023 steps.
Found uncertainty sample 7 after 1147 steps.
Found uncertainty sample 8 after 16 steps.
Found uncertainty sample 9 after 336 steps.
Found uncertainty sample 10 after 1587 steps.
Found uncertainty sample 11 after 133 steps.
Found uncertainty sample 12 after 1135 steps.
Found uncertainty sample 13 after 1 steps.
Found uncertainty sample 14 after 271 steps.
Found uncertainty sample 15 after 2498 steps.
Found uncertainty sample 16 after 3536 steps.
Found uncertainty sample 17 after 392 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 909 steps.
Found uncertainty sample 20 after 3570 steps.
Found uncertainty sample 21 after 1102 steps.
Found uncertainty sample 22 after 472 steps.
Found uncertainty sample 23 after 313 steps.
Found uncertainty sample 24 after 1710 steps.
Found uncertainty sample 25 after 442 steps.
Found uncertainty sample 26 after 410 steps.
Found uncertainty sample 27 after 62 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 82 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 25 steps.
Found uncertainty sample 32 after 1740 steps.
Found uncertainty sample 33 after 2665 steps.
Found uncertainty sample 34 after 599 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 25 steps.
Found uncertainty sample 37 after 2628 steps.
Found uncertainty sample 38 after 2635 steps.
Found uncertainty sample 39 after 3794 steps.
Found uncertainty sample 40 after 334 steps.
Found uncertainty sample 41 after 45 steps.
Found uncertainty sample 42 after 397 steps.
Found uncertainty sample 43 after 291 steps.
Found uncertainty sample 44 after 422 steps.
Found uncertainty sample 45 after 327 steps.
Found uncertainty sample 46 after 1180 steps.
Found uncertainty sample 47 after 42 steps.
Found uncertainty sample 48 after 384 steps.
Found uncertainty sample 49 after 314 steps.
Found uncertainty sample 50 after 1697 steps.
Found uncertainty sample 51 after 2736 steps.
Found uncertainty sample 52 after 1630 steps.
Found uncertainty sample 53 after 162 steps.
Found uncertainty sample 54 after 36 steps.
Found uncertainty sample 55 after 3542 steps.
Found uncertainty sample 56 after 2989 steps.
Found uncertainty sample 57 after 1827 steps.
Found uncertainty sample 58 after 446 steps.
Found uncertainty sample 59 after 72 steps.
Found uncertainty sample 60 after 2825 steps.
Found uncertainty sample 61 after 130 steps.
Found uncertainty sample 62 after 55 steps.
Found uncertainty sample 63 after 16 steps.
Found uncertainty sample 64 after 385 steps.
Found uncertainty sample 65 after 1075 steps.
Found uncertainty sample 66 after 749 steps.
Found uncertainty sample 67 after 300 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1005 steps.
Found uncertainty sample 70 after 1087 steps.
Found uncertainty sample 71 after 2597 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 135 steps.
Found uncertainty sample 74 after 550 steps.
Found uncertainty sample 75 after 1223 steps.
Found uncertainty sample 76 after 1689 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1947 steps.
Found uncertainty sample 79 after 914 steps.
Found uncertainty sample 80 after 470 steps.
Found uncertainty sample 81 after 1626 steps.
Found uncertainty sample 82 after 2173 steps.
Found uncertainty sample 83 after 594 steps.
Found uncertainty sample 84 after 125 steps.
Found uncertainty sample 85 after 2748 steps.
Found uncertainty sample 86 after 649 steps.
Found uncertainty sample 87 after 398 steps.
Found uncertainty sample 88 after 2816 steps.
Found uncertainty sample 89 after 310 steps.
Found uncertainty sample 90 after 1147 steps.
Found uncertainty sample 91 after 328 steps.
Found uncertainty sample 92 after 1686 steps.
Found uncertainty sample 93 after 628 steps.
Found uncertainty sample 94 after 1861 steps.
Found uncertainty sample 95 after 1157 steps.
Found uncertainty sample 96 after 3534 steps.
Found uncertainty sample 97 after 166 steps.
Found uncertainty sample 98 after 3339 steps.
Found uncertainty sample 99 after 1215 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_182213-b95yypwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_19
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/b95yypwc
Training model 19. Added 92 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8671883510331084, Training Loss Force: 2.345684945911441, time: 1.2238292694091797
Validation Loss Energy: 1.0566175638448625, Validation Loss Force: 2.26006266150893, time: 0.08386039733886719
Test Loss Energy: 12.748092226567413, Test Loss Force: 9.050642127768823, time: 10.317363500595093


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6538519723179224, Training Loss Force: 2.140881159328958, time: 1.229912519454956
Validation Loss Energy: 2.4659934337336074, Validation Loss Force: 2.230685921086677, time: 0.07988810539245605
Test Loss Energy: 14.279059446666409, Test Loss Force: 9.036364558815793, time: 10.490148305892944


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.039331598566288, Training Loss Force: 2.096552825217765, time: 1.1856493949890137
Validation Loss Energy: 1.5901417164200362, Validation Loss Force: 2.36241787849414, time: 0.08708715438842773
Test Loss Energy: 13.67126404957664, Test Loss Force: 8.993436801376566, time: 10.49385404586792


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.047622342360676, Training Loss Force: 2.1129188375868657, time: 1.1996941566467285
Validation Loss Energy: 0.9233720407515986, Validation Loss Force: 2.223426238921993, time: 0.08196735382080078
Test Loss Energy: 13.348181177418622, Test Loss Force: 8.966990860232384, time: 10.41739821434021


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9417572701333534, Training Loss Force: 2.1178243045305054, time: 1.1920759677886963
Validation Loss Energy: 0.8105537954347446, Validation Loss Force: 2.3988643642996, time: 0.09017634391784668
Test Loss Energy: 13.01716841111701, Test Loss Force: 9.077271921347506, time: 10.467990159988403


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8716127665947375, Training Loss Force: 2.147784449534019, time: 1.227062463760376
Validation Loss Energy: 0.8677627595821659, Validation Loss Force: 2.343123151661205, time: 0.07832980155944824
Test Loss Energy: 13.248745763819416, Test Loss Force: 9.017132132711438, time: 10.854147672653198


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.302841101649283, Training Loss Force: 2.131338341931236, time: 1.1763207912445068
Validation Loss Energy: 1.2834789296166762, Validation Loss Force: 2.2493739858315314, time: 0.09840536117553711
Test Loss Energy: 12.313394964438142, Test Loss Force: 8.882544101925985, time: 10.375644207000732


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.752499667377238, Training Loss Force: 2.130605914596696, time: 1.2176153659820557
Validation Loss Energy: 0.9166007833585076, Validation Loss Force: 2.2585573067478855, time: 0.09538388252258301
Test Loss Energy: 12.332077586612796, Test Loss Force: 8.938732079804062, time: 10.562707901000977


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8161300863947456, Training Loss Force: 2.160037477304569, time: 1.207324743270874
Validation Loss Energy: 1.254318289600546, Validation Loss Force: 2.300950840102785, time: 0.08568310737609863
Test Loss Energy: 12.335080141314593, Test Loss Force: 9.002436822450962, time: 10.480397462844849


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4367343892711786, Training Loss Force: 2.1309434624661603, time: 1.1948370933532715
Validation Loss Energy: 2.3634303551006735, Validation Loss Force: 2.2490218345772464, time: 0.07861495018005371
Test Loss Energy: 14.340213324220155, Test Loss Force: 8.944333838622397, time: 10.459243535995483


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.574374806806985, Training Loss Force: 2.0964311365295147, time: 1.221064567565918
Validation Loss Energy: 1.9159097942804326, Validation Loss Force: 2.2918526901347485, time: 0.12003684043884277
Test Loss Energy: 13.369421435693758, Test Loss Force: 9.019422477235466, time: 10.428033351898193


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6522128661958573, Training Loss Force: 2.1152010064929043, time: 1.2372665405273438
Validation Loss Energy: 1.025820611776239, Validation Loss Force: 2.346294294302936, time: 0.09454560279846191
Test Loss Energy: 12.946756547368791, Test Loss Force: 9.002920585743077, time: 10.444899082183838


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4651558783437184, Training Loss Force: 2.1001990924317178, time: 1.2516679763793945
Validation Loss Energy: 2.9461853476592488, Validation Loss Force: 2.355271534924734, time: 0.08117127418518066
Test Loss Energy: 11.590318760847397, Test Loss Force: 8.957518374867771, time: 10.355490446090698


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.786163404767168, Training Loss Force: 2.124854814468307, time: 1.1912870407104492
Validation Loss Energy: 1.264191216861838, Validation Loss Force: 2.4652773297603034, time: 0.08041214942932129
Test Loss Energy: 11.857651984587235, Test Loss Force: 8.868492582959318, time: 10.333274602890015


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5302898329438954, Training Loss Force: 2.108597967075364, time: 1.2380218505859375
Validation Loss Energy: 1.4051174059738054, Validation Loss Force: 2.2228430684288085, time: 0.07907629013061523
Test Loss Energy: 12.04371785298823, Test Loss Force: 8.950903170657245, time: 10.437066555023193


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8253536076561367, Training Loss Force: 2.1680122928334598, time: 1.248924970626831
Validation Loss Energy: 0.9759336771543611, Validation Loss Force: 2.3414259674309434, time: 0.10143065452575684
Test Loss Energy: 12.239282782491282, Test Loss Force: 8.929297646381453, time: 10.520868062973022


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.872839033415005, Training Loss Force: 2.1071910192305223, time: 1.2150423526763916
Validation Loss Energy: 1.9552710192060876, Validation Loss Force: 2.336213282724774, time: 0.09277153015136719
Test Loss Energy: 14.270255234543585, Test Loss Force: 8.999196219276676, time: 10.509716749191284


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7614716060468396, Training Loss Force: 2.097011108294777, time: 1.3106050491333008
Validation Loss Energy: 1.151467912102079, Validation Loss Force: 2.33872988941205, time: 0.08155632019042969
Test Loss Energy: 13.47132827629395, Test Loss Force: 9.017594720284356, time: 10.570563554763794


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.835883804278386, Training Loss Force: 2.150227855166938, time: 1.2709002494812012
Validation Loss Energy: 0.9504031287233619, Validation Loss Force: 2.3723335582314506, time: 0.07893252372741699
Test Loss Energy: 12.835440552705993, Test Loss Force: 9.097866108010251, time: 9.2481689453125


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9877248638084914, Training Loss Force: 2.0969128912182944, time: 1.2493500709533691
Validation Loss Energy: 2.001328350688083, Validation Loss Force: 2.2688289231149614, time: 0.09521174430847168
Test Loss Energy: 14.129934431543887, Test Loss Force: 8.97001134970979, time: 10.98153281211853

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–†â–…â–…â–…â–ƒâ–ƒâ–ƒâ–ˆâ–†â–„â–â–‚â–‚â–ƒâ–ˆâ–†â–„â–‡
wandb:   test_error_force â–‡â–†â–…â–„â–‡â–†â–â–ƒâ–…â–ƒâ–†â–…â–„â–â–„â–ƒâ–…â–†â–ˆâ–„
wandb:          test_loss â–ƒâ–†â–…â–†â–†â–ƒâ–â–‚â–…â–†â–‡â–…â–„â–‚â–„â–ƒâ–†â–‡â–ˆâ–…
wandb: train_error_energy â–ˆâ–ƒâ–„â–„â–„â–„â–â–ƒâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–„â–ƒâ–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–ƒâ–â–â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚â–â–‚â–â–‚â–â–ƒâ–‚â–â–ƒâ–‚
wandb: valid_error_energy â–‚â–†â–„â–â–â–â–ƒâ–â–‚â–†â–…â–‚â–ˆâ–‚â–ƒâ–‚â–…â–‚â–â–…
wandb:  valid_error_force â–‚â–â–…â–â–†â–„â–‚â–‚â–ƒâ–‚â–ƒâ–…â–…â–ˆâ–â–„â–„â–„â–…â–‚
wandb:         valid_loss â–‚â–ƒâ–†â–â–…â–„â–‚â–‚â–„â–„â–„â–„â–ˆâ–ˆâ–‚â–„â–…â–„â–…â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2491
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.12993
wandb:   test_error_force 8.97001
wandb:          test_loss 6.43516
wandb: train_error_energy 1.98772
wandb:  train_error_force 2.09691
wandb:         train_loss -2.27627
wandb: valid_error_energy 2.00133
wandb:  valid_error_force 2.26883
wandb:         valid_loss -2.07237
wandb: 
wandb: ğŸš€ View run al_58_19 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/b95yypwc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_182213-b95yypwc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.13975524902344, Uncertainty Bias: -5.14070987701416
5.340576e-05 0.064834595
-2.6417253 30.336487
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 24 steps.
Found uncertainty sample 1 after 1594 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 924 steps.
Found uncertainty sample 4 after 220 steps.
Found uncertainty sample 5 after 1851 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 349 steps.
Found uncertainty sample 8 after 1211 steps.
Found uncertainty sample 9 after 3512 steps.
Found uncertainty sample 10 after 1109 steps.
Found uncertainty sample 11 after 311 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2303 steps.
Found uncertainty sample 14 after 2694 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 951 steps.
Found uncertainty sample 17 after 1 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 374 steps.
Found uncertainty sample 20 after 1216 steps.
Found uncertainty sample 21 after 979 steps.
Found uncertainty sample 22 after 1749 steps.
Found uncertainty sample 23 after 663 steps.
Found uncertainty sample 24 after 26 steps.
Found uncertainty sample 25 after 3601 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 882 steps.
Found uncertainty sample 28 after 46 steps.
Found uncertainty sample 29 after 478 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2986 steps.
Found uncertainty sample 33 after 838 steps.
Found uncertainty sample 34 after 1451 steps.
Found uncertainty sample 35 after 273 steps.
Found uncertainty sample 36 after 2465 steps.
Found uncertainty sample 37 after 3103 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2259 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 380 steps.
Found uncertainty sample 43 after 686 steps.
Found uncertainty sample 44 after 3433 steps.
Found uncertainty sample 45 after 243 steps.
Found uncertainty sample 46 after 304 steps.
Found uncertainty sample 47 after 420 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 120 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 643 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2328 steps.
Found uncertainty sample 54 after 1431 steps.
Found uncertainty sample 55 after 175 steps.
Found uncertainty sample 56 after 415 steps.
Found uncertainty sample 57 after 74 steps.
Found uncertainty sample 58 after 2164 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1943 steps.
Found uncertainty sample 61 after 682 steps.
Found uncertainty sample 62 after 1 steps.
Found uncertainty sample 63 after 1096 steps.
Found uncertainty sample 64 after 647 steps.
Found uncertainty sample 65 after 119 steps.
Found uncertainty sample 66 after 2460 steps.
Found uncertainty sample 67 after 187 steps.
Found uncertainty sample 68 after 2570 steps.
Found uncertainty sample 69 after 1240 steps.
Found uncertainty sample 70 after 1233 steps.
Found uncertainty sample 71 after 352 steps.
Found uncertainty sample 72 after 1504 steps.
Found uncertainty sample 73 after 997 steps.
Found uncertainty sample 74 after 2013 steps.
Found uncertainty sample 75 after 164 steps.
Found uncertainty sample 76 after 1007 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 174 steps.
Found uncertainty sample 80 after 339 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2785 steps.
Found uncertainty sample 83 after 414 steps.
Found uncertainty sample 84 after 928 steps.
Found uncertainty sample 85 after 15 steps.
Found uncertainty sample 86 after 21 steps.
Found uncertainty sample 87 after 3967 steps.
Found uncertainty sample 88 after 358 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1767 steps.
Found uncertainty sample 91 after 2741 steps.
Found uncertainty sample 92 after 1474 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2405 steps.
Found uncertainty sample 96 after 932 steps.
Found uncertainty sample 97 after 846 steps.
Found uncertainty sample 98 after 482 steps.
Found uncertainty sample 99 after 2637 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_184545-cxb3od35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_20
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cxb3od35
Training model 20. Added 81 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1497522882845224, Training Loss Force: 2.287696265386806, time: 1.217649221420288
Validation Loss Energy: 2.276448327284891, Validation Loss Force: 2.2646527632830855, time: 0.08259749412536621
Test Loss Energy: 11.711788958203462, Test Loss Force: 8.948237030563313, time: 9.85007119178772


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.088708207859336, Training Loss Force: 2.1081240880124192, time: 1.221224069595337
Validation Loss Energy: 1.295840963925722, Validation Loss Force: 2.2328572792631918, time: 0.08643078804016113
Test Loss Energy: 13.400025157721723, Test Loss Force: 8.98889771765039, time: 9.937065601348877


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0722049597165664, Training Loss Force: 2.105772466791768, time: 1.238732099533081
Validation Loss Energy: 0.8087736391139817, Validation Loss Force: 2.2454046856362226, time: 0.08652758598327637
Test Loss Energy: 12.62515574705638, Test Loss Force: 9.007983107506783, time: 9.60839295387268


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.749595678043559, Training Loss Force: 2.1286939558250264, time: 1.2996788024902344
Validation Loss Energy: 2.4589829183432164, Validation Loss Force: 2.5381063953263427, time: 0.08647012710571289
Test Loss Energy: 14.32369336738177, Test Loss Force: 9.079284799131184, time: 10.427551507949829


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9273105005977158, Training Loss Force: 2.145621753620778, time: 1.4407069683074951
Validation Loss Energy: 5.316758483622994, Validation Loss Force: 2.330894050832278, time: 0.09392929077148438
Test Loss Energy: 11.129716599297879, Test Loss Force: 8.959444815053773, time: 11.199999332427979


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.432824741531022, Training Loss Force: 2.165930140505522, time: 1.3162133693695068
Validation Loss Energy: 2.0033125554474456, Validation Loss Force: 2.563705331018785, time: 0.13444876670837402
Test Loss Energy: 14.289415450559465, Test Loss Force: 9.189349341898357, time: 11.64690351486206


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.827438918099692, Training Loss Force: 2.238562508120154, time: 1.333031415939331
Validation Loss Energy: 1.6852453229971023, Validation Loss Force: 2.3274367783380305, time: 0.08150696754455566
Test Loss Energy: 13.842266856215884, Test Loss Force: 8.977142554108887, time: 11.253630638122559


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.96526111923292, Training Loss Force: 2.1229697189951073, time: 1.4042773246765137
Validation Loss Energy: 1.566476105587112, Validation Loss Force: 2.345758329668688, time: 0.10351014137268066
Test Loss Energy: 13.778963113887235, Test Loss Force: 9.012001355276757, time: 11.454609155654907


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5877042658651357, Training Loss Force: 2.1435247133334676, time: 1.3074336051940918
Validation Loss Energy: 1.847614940532921, Validation Loss Force: 2.2996290760525575, time: 0.09307098388671875
Test Loss Energy: 13.69379637646491, Test Loss Force: 8.962137624149708, time: 11.298450946807861


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.961236120824859, Training Loss Force: 2.1039762566441085, time: 1.2645268440246582
Validation Loss Energy: 1.42247140419812, Validation Loss Force: 2.204216905706522, time: 0.10584211349487305
Test Loss Energy: 12.18357365286281, Test Loss Force: 8.967206156814548, time: 11.852390766143799


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6232294450215612, Training Loss Force: 2.1181901381482757, time: 1.408027172088623
Validation Loss Energy: 1.344817042572539, Validation Loss Force: 2.429087581480098, time: 0.1002802848815918
Test Loss Energy: 12.05388966869436, Test Loss Force: 8.922370994486778, time: 11.75651741027832


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8454091517960918, Training Loss Force: 2.1384161140825113, time: 1.3648817539215088
Validation Loss Energy: 1.3790278188183114, Validation Loss Force: 2.2223774672446734, time: 0.1017005443572998
Test Loss Energy: 13.39640205791863, Test Loss Force: 9.010868451968102, time: 11.598894119262695


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9879933656076574, Training Loss Force: 2.0777762338392405, time: 1.3581440448760986
Validation Loss Energy: 1.6775209303248673, Validation Loss Force: 2.357175690126135, time: 0.09076571464538574
Test Loss Energy: 12.045079053959238, Test Loss Force: 8.909034231820469, time: 11.910631656646729


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9700074777057293, Training Loss Force: 2.0833880392444764, time: 1.3734345436096191
Validation Loss Energy: 2.111336817553404, Validation Loss Force: 2.380179639591935, time: 0.09720849990844727
Test Loss Energy: 13.929639328550017, Test Loss Force: 8.932581752811496, time: 11.693481683731079


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.275838532709258, Training Loss Force: 2.1561153573813345, time: 1.4264538288116455
Validation Loss Energy: 1.9158522343062103, Validation Loss Force: 2.5046676130095022, time: 0.0903778076171875
Test Loss Energy: 13.869431302895885, Test Loss Force: 9.05690371938593, time: 11.678958654403687


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6296010381004797, Training Loss Force: 2.1396235856338364, time: 1.4223508834838867
Validation Loss Energy: 1.628426057688698, Validation Loss Force: 2.381061298075236, time: 0.10239577293395996
Test Loss Energy: 13.550910630086161, Test Loss Force: 9.091310802965786, time: 11.680990934371948


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6654010803255388, Training Loss Force: 2.1120188339043686, time: 1.3826212882995605
Validation Loss Energy: 2.7768916660289458, Validation Loss Force: 2.293411596825389, time: 0.08848428726196289
Test Loss Energy: 11.538419288128871, Test Loss Force: 8.991664089170976, time: 11.76059865951538


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.075744481657467, Training Loss Force: 2.1328123632525537, time: 1.3916184902191162
Validation Loss Energy: 1.0617766131205069, Validation Loss Force: 2.523816157548135, time: 0.09567117691040039
Test Loss Energy: 13.324633567826258, Test Loss Force: 8.886032854125014, time: 11.644809484481812


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6057155456094543, Training Loss Force: 2.1192691378494053, time: 1.3049378395080566
Validation Loss Energy: 1.8113495960776729, Validation Loss Force: 2.3086210128379863, time: 0.0938115119934082
Test Loss Energy: 13.912661470683037, Test Loss Force: 9.015047077481883, time: 11.559027671813965


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6874687342099803, Training Loss Force: 2.101594301563078, time: 1.4579718112945557
Validation Loss Energy: 2.861526427042931, Validation Loss Force: 2.341813745748577, time: 0.13153839111328125
Test Loss Energy: 11.43133216526357, Test Loss Force: 8.884893907272627, time: 12.256832599639893

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–†â–„â–ˆâ–â–ˆâ–‡â–‡â–‡â–ƒâ–ƒâ–†â–ƒâ–‡â–‡â–†â–‚â–†â–‡â–‚
wandb:   test_error_force â–‚â–ƒâ–„â–…â–ƒâ–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–„â–‚â–‚â–…â–†â–ƒâ–â–„â–
wandb:          test_loss â–â–…â–…â–ˆâ–â–‡â–‚â–„â–ƒâ–‚â–ƒâ–…â–ƒâ–†â–†â–‡â–ƒâ–‚â–†â–
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–…â–‡â–ƒâ–â–ƒâ–â–‚â–ƒâ–ƒâ–„â–â–â–ƒâ–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–„â–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–â–„â–ƒâ–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–„â–†â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–â–ƒâ–‚â–
wandb: valid_error_energy â–ƒâ–‚â–â–„â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–„â–â–ƒâ–„
wandb:  valid_error_force â–‚â–‚â–‚â–ˆâ–ƒâ–ˆâ–ƒâ–„â–ƒâ–â–…â–â–„â–„â–‡â–„â–ƒâ–‡â–ƒâ–„
wandb:         valid_loss â–ƒâ–â–â–ˆâ–‡â–ˆâ–ƒâ–„â–ƒâ–â–…â–â–„â–…â–‡â–„â–„â–†â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 2563
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.43133
wandb:   test_error_force 8.88489
wandb:          test_loss 6.24522
wandb: train_error_energy 1.68747
wandb:  train_error_force 2.10159
wandb:         train_loss -2.291
wandb: valid_error_energy 2.86153
wandb:  valid_error_force 2.34181
wandb:         valid_loss -1.92596
wandb: 
wandb: ğŸš€ View run al_58_20 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cxb3od35
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_184545-cxb3od35/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.54823684692383, Uncertainty Bias: -5.133588790893555
1.1444092e-05 0.008381844
-2.5565696 26.024708
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 993 steps.
Found uncertainty sample 2 after 1281 steps.
Found uncertainty sample 3 after 121 steps.
Found uncertainty sample 4 after 2607 steps.
Found uncertainty sample 5 after 7 steps.
Found uncertainty sample 6 after 3628 steps.
Found uncertainty sample 7 after 865 steps.
Found uncertainty sample 8 after 1299 steps.
Found uncertainty sample 9 after 3401 steps.
Found uncertainty sample 10 after 627 steps.
Found uncertainty sample 11 after 1393 steps.
Found uncertainty sample 12 after 1266 steps.
Found uncertainty sample 13 after 256 steps.
Found uncertainty sample 14 after 108 steps.
Found uncertainty sample 15 after 2952 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1048 steps.
Found uncertainty sample 18 after 1417 steps.
Found uncertainty sample 19 after 946 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 113 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 692 steps.
Found uncertainty sample 24 after 3243 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1516 steps.
Found uncertainty sample 27 after 838 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1817 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 107 steps.
Found uncertainty sample 32 after 1778 steps.
Found uncertainty sample 33 after 787 steps.
Found uncertainty sample 34 after 13 steps.
Found uncertainty sample 35 after 1337 steps.
Found uncertainty sample 36 after 248 steps.
Found uncertainty sample 37 after 695 steps.
Found uncertainty sample 38 after 140 steps.
Found uncertainty sample 39 after 821 steps.
Found uncertainty sample 40 after 2072 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3622 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1053 steps.
Found uncertainty sample 48 after 337 steps.
Found uncertainty sample 49 after 577 steps.
Found uncertainty sample 50 after 350 steps.
Found uncertainty sample 51 after 1287 steps.
Found uncertainty sample 52 after 211 steps.
Found uncertainty sample 53 after 1 steps.
Found uncertainty sample 54 after 2703 steps.
Found uncertainty sample 55 after 1340 steps.
Found uncertainty sample 56 after 509 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 335 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1567 steps.
Found uncertainty sample 61 after 1442 steps.
Found uncertainty sample 62 after 393 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 236 steps.
Found uncertainty sample 65 after 115 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1746 steps.
Found uncertainty sample 68 after 3289 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3917 steps.
Found uncertainty sample 71 after 2882 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1592 steps.
Found uncertainty sample 74 after 27 steps.
Found uncertainty sample 75 after 2171 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1353 steps.
Found uncertainty sample 78 after 1873 steps.
Found uncertainty sample 79 after 1360 steps.
Found uncertainty sample 80 after 48 steps.
Found uncertainty sample 81 after 1595 steps.
Found uncertainty sample 82 after 2233 steps.
Found uncertainty sample 83 after 927 steps.
Found uncertainty sample 84 after 1534 steps.
Found uncertainty sample 85 after 133 steps.
Found uncertainty sample 86 after 961 steps.
Found uncertainty sample 87 after 48 steps.
Found uncertainty sample 88 after 2195 steps.
Found uncertainty sample 89 after 979 steps.
Found uncertainty sample 90 after 503 steps.
Found uncertainty sample 91 after 4 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 998 steps.
Found uncertainty sample 94 after 7 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2038 steps.
Found uncertainty sample 99 after 930 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_190953-p3lvwle1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_21
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p3lvwle1
Training model 21. Added 78 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.16388678585349, Training Loss Force: 2.2148361984828777, time: 1.23846435546875
Validation Loss Energy: 0.9990996462574665, Validation Loss Force: 2.300685752484558, time: 0.0883643627166748
Test Loss Energy: 11.982102031387052, Test Loss Force: 8.835866055134865, time: 9.281832218170166


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8082048880194288, Training Loss Force: 2.138393444737239, time: 1.2606024742126465
Validation Loss Energy: 1.1462126419217509, Validation Loss Force: 2.359785483850982, time: 0.08292913436889648
Test Loss Energy: 13.128454948167347, Test Loss Force: 8.943280849055183, time: 9.316829681396484


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.984376268930788, Training Loss Force: 2.151983826682894, time: 1.3366000652313232
Validation Loss Energy: 2.1612576813863926, Validation Loss Force: 2.291289225860978, time: 0.08149480819702148
Test Loss Energy: 11.732757466856002, Test Loss Force: 8.959435176161113, time: 9.46724247932434


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7401441125288126, Training Loss Force: 2.121745454586669, time: 1.2629666328430176
Validation Loss Energy: 1.1971052339075683, Validation Loss Force: 2.345150220231159, time: 0.08101439476013184
Test Loss Energy: 12.197717265922941, Test Loss Force: 8.806909469240644, time: 9.359136819839478


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5791835748587941, Training Loss Force: 2.0559165851716252, time: 1.1995394229888916
Validation Loss Energy: 1.0315368349222809, Validation Loss Force: 2.302387612766884, time: 0.09083104133605957
Test Loss Energy: 12.216315567605522, Test Loss Force: 8.99650597961947, time: 9.397945642471313


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.560666249729862, Training Loss Force: 2.10290106402895, time: 1.2356302738189697
Validation Loss Energy: 4.469472100363915, Validation Loss Force: 2.2527745890281405, time: 0.0846414566040039
Test Loss Energy: 16.01945306537036, Test Loss Force: 9.001094307035302, time: 9.478505849838257


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.686106218923926, Training Loss Force: 2.0758799378187063, time: 1.241940975189209
Validation Loss Energy: 0.8817442387559014, Validation Loss Force: 2.2999589603922495, time: 0.08224034309387207
Test Loss Energy: 13.113014090310795, Test Loss Force: 8.957354891413992, time: 9.395482778549194


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5347044397882403, Training Loss Force: 2.126768576756493, time: 1.2074081897735596
Validation Loss Energy: 1.1737613799905098, Validation Loss Force: 2.2380006025304047, time: 0.08392643928527832
Test Loss Energy: 12.383991804458848, Test Loss Force: 8.833315185378487, time: 9.307323932647705


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.369229236224151, Training Loss Force: 2.1184450323850217, time: 1.2199122905731201
Validation Loss Energy: 2.4768712668504715, Validation Loss Force: 2.288229083788493, time: 0.08760309219360352
Test Loss Energy: 11.595525907970094, Test Loss Force: 8.968621022215528, time: 9.503424882888794


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5339029059802025, Training Loss Force: 2.08459172999095, time: 1.2895481586456299
Validation Loss Energy: 1.384383512783453, Validation Loss Force: 2.2589849428426394, time: 0.08507132530212402
Test Loss Energy: 12.104221965652863, Test Loss Force: 8.975195273956116, time: 9.329521417617798


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4578653081352424, Training Loss Force: 2.1216098410285165, time: 1.2399704456329346
Validation Loss Energy: 3.6707950596683103, Validation Loss Force: 2.3263385741103146, time: 0.08698701858520508
Test Loss Energy: 15.199668751175247, Test Loss Force: 8.854570263392798, time: 9.346609354019165


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6397861733963168, Training Loss Force: 2.098545031792718, time: 1.4245257377624512
Validation Loss Energy: 0.9870979462938181, Validation Loss Force: 2.1813384303044527, time: 0.08176732063293457
Test Loss Energy: 12.23040585665134, Test Loss Force: 8.932123548673072, time: 9.393762350082397


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8588200382735616, Training Loss Force: 2.0741751077201807, time: 1.2364022731781006
Validation Loss Energy: 5.2847123854793585, Validation Loss Force: 2.344945809955197, time: 0.0794839859008789
Test Loss Energy: 16.931916367751736, Test Loss Force: 9.056253632734071, time: 9.28531289100647


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.029241773869558, Training Loss Force: 2.1023497741236645, time: 1.2288129329681396
Validation Loss Energy: 1.8194959467814409, Validation Loss Force: 2.3998376511364508, time: 0.08788609504699707
Test Loss Energy: 13.548085455258143, Test Loss Force: 8.930225871278525, time: 9.465488195419312


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.806902863723126, Training Loss Force: 2.076176083758649, time: 1.1969494819641113
Validation Loss Energy: 2.2516011226291015, Validation Loss Force: 2.376727933826335, time: 0.08431077003479004
Test Loss Energy: 12.093602904394551, Test Loss Force: 8.910172218047846, time: 9.772642850875854


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9163400903325154, Training Loss Force: 2.0943565795508823, time: 1.2425096035003662
Validation Loss Energy: 1.7137684055811546, Validation Loss Force: 2.2145250398135303, time: 0.08167815208435059
Test Loss Energy: 11.73392932677293, Test Loss Force: 8.976397594079563, time: 9.329036951065063


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9551766738865441, Training Loss Force: 2.059673614601844, time: 1.2427256107330322
Validation Loss Energy: 3.3279328941441833, Validation Loss Force: 2.230753501172466, time: 0.08394479751586914
Test Loss Energy: 11.429596502405923, Test Loss Force: 8.84020176615335, time: 9.52669644355774


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7427201202349063, Training Loss Force: 2.0916893921829827, time: 1.300246238708496
Validation Loss Energy: 1.2735566254722743, Validation Loss Force: 2.187236379307215, time: 0.08403587341308594
Test Loss Energy: 13.294484552515575, Test Loss Force: 8.919581591282176, time: 9.423439025878906


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0234757234719383, Training Loss Force: 2.106311673923322, time: 1.232497215270996
Validation Loss Energy: 1.8689342309079175, Validation Loss Force: 2.3434854343616296, time: 0.0818932056427002
Test Loss Energy: 14.03551533644351, Test Loss Force: 8.880007613565335, time: 9.424956321716309


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6127306837030582, Training Loss Force: 2.1502724318687045, time: 1.2459113597869873
Validation Loss Energy: 1.6598830289394948, Validation Loss Force: 2.2493109704632337, time: 0.0860452651977539
Test Loss Energy: 13.436721508619899, Test Loss Force: 8.87293182697001, time: 9.42225432395935

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–â–‚â–‚â–‡â–ƒâ–‚â–â–‚â–†â–‚â–ˆâ–„â–‚â–â–â–ƒâ–„â–„
wandb:   test_error_force â–‚â–…â–…â–â–†â–†â–…â–‚â–†â–†â–‚â–…â–ˆâ–„â–„â–†â–‚â–„â–ƒâ–ƒ
wandb:          test_loss â–â–„â–ƒâ–‚â–†â–‡â–†â–ƒâ–ƒâ–…â–…â–„â–ˆâ–…â–…â–…â–„â–…â–„â–ƒ
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–ƒâ–„â–ƒâ–ƒâ–ƒâ–‚â–„â–‚
wandb:  train_error_force â–ˆâ–…â–…â–„â–â–ƒâ–‚â–„â–„â–‚â–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–…
wandb:         train_loss â–ˆâ–„â–„â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–„
wandb: valid_error_energy â–â–â–ƒâ–‚â–â–‡â–â–â–„â–‚â–…â–â–ˆâ–‚â–ƒâ–‚â–…â–‚â–ƒâ–‚
wandb:  valid_error_force â–…â–‡â–…â–†â–…â–ƒâ–…â–ƒâ–„â–ƒâ–†â–â–†â–ˆâ–‡â–‚â–ƒâ–â–†â–ƒ
wandb:         valid_loss â–ƒâ–„â–„â–„â–ƒâ–†â–ƒâ–‚â–„â–ƒâ–†â–â–ˆâ–†â–†â–‚â–„â–â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2633
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.43672
wandb:   test_error_force 8.87293
wandb:          test_loss 6.28721
wandb: train_error_energy 1.61273
wandb:  train_error_force 2.15027
wandb:         train_loss -2.2383
wandb: valid_error_energy 1.65988
wandb:  valid_error_force 2.24931
wandb:         valid_loss -2.11759
wandb: 
wandb: ğŸš€ View run al_58_21 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p3lvwle1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_190953-p3lvwle1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 34.72911834716797, Uncertainty Bias: -4.771224021911621
0.00017547607 0.0024662018
-2.2634373 29.463745
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 222 steps.
Found uncertainty sample 1 after 2458 steps.
Found uncertainty sample 2 after 582 steps.
Found uncertainty sample 3 after 3574 steps.
Found uncertainty sample 4 after 342 steps.
Found uncertainty sample 5 after 537 steps.
Found uncertainty sample 6 after 508 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3601 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1073 steps.
Found uncertainty sample 11 after 1873 steps.
Found uncertainty sample 12 after 771 steps.
Found uncertainty sample 13 after 1567 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 817 steps.
Found uncertainty sample 18 after 1065 steps.
Found uncertainty sample 19 after 3375 steps.
Found uncertainty sample 20 after 1802 steps.
Found uncertainty sample 21 after 1140 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 200 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1806 steps.
Found uncertainty sample 26 after 1074 steps.
Found uncertainty sample 27 after 2094 steps.
Found uncertainty sample 28 after 3372 steps.
Found uncertainty sample 29 after 457 steps.
Found uncertainty sample 30 after 123 steps.
Found uncertainty sample 31 after 3133 steps.
Found uncertainty sample 32 after 3813 steps.
Found uncertainty sample 33 after 2546 steps.
Found uncertainty sample 34 after 2682 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 650 steps.
Found uncertainty sample 38 after 755 steps.
Found uncertainty sample 39 after 1265 steps.
Found uncertainty sample 40 after 1887 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 737 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 543 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1948 steps.
Found uncertainty sample 47 after 1874 steps.
Found uncertainty sample 48 after 5 steps.
Found uncertainty sample 49 after 236 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2205 steps.
Found uncertainty sample 52 after 1156 steps.
Found uncertainty sample 53 after 1615 steps.
Found uncertainty sample 54 after 845 steps.
Found uncertainty sample 55 after 877 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 55 steps.
Found uncertainty sample 58 after 3313 steps.
Found uncertainty sample 59 after 691 steps.
Found uncertainty sample 60 after 988 steps.
Found uncertainty sample 61 after 495 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 680 steps.
Found uncertainty sample 64 after 1343 steps.
Found uncertainty sample 65 after 621 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1317 steps.
Found uncertainty sample 69 after 1827 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 359 steps.
Found uncertainty sample 72 after 862 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 271 steps.
Found uncertainty sample 75 after 1153 steps.
Found uncertainty sample 76 after 1025 steps.
Found uncertainty sample 77 after 766 steps.
Found uncertainty sample 78 after 847 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 170 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1987 steps.
Found uncertainty sample 83 after 36 steps.
Found uncertainty sample 84 after 1636 steps.
Found uncertainty sample 85 after 2753 steps.
Found uncertainty sample 86 after 1818 steps.
Found uncertainty sample 87 after 3407 steps.
Found uncertainty sample 88 after 3431 steps.
Found uncertainty sample 89 after 835 steps.
Found uncertainty sample 90 after 1314 steps.
Found uncertainty sample 91 after 1729 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 95 steps.
Found uncertainty sample 95 after 1978 steps.
Found uncertainty sample 96 after 1080 steps.
Found uncertainty sample 97 after 1115 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 235 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_193459-ilhbjfm2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_22
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ilhbjfm2
Training model 22. Added 76 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4927532609125276, Training Loss Force: 2.2273354590522754, time: 1.354341983795166
Validation Loss Energy: 0.8949847585129189, Validation Loss Force: 2.219394146027533, time: 0.08878850936889648
Test Loss Energy: 12.703595787145458, Test Loss Force: 8.780079786385727, time: 9.325352191925049


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2950421305057953, Training Loss Force: 2.079020981935847, time: 1.2514197826385498
Validation Loss Energy: 2.350854447076964, Validation Loss Force: 2.2724867091751166, time: 0.09128212928771973
Test Loss Energy: 11.695158170420754, Test Loss Force: 8.939239546285052, time: 9.969760656356812


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8669740311923049, Training Loss Force: 2.1170646342304926, time: 1.3301005363464355
Validation Loss Energy: 1.4983595541582018, Validation Loss Force: 2.209237872278048, time: 0.08436012268066406
Test Loss Energy: 13.457974833260414, Test Loss Force: 8.917951471268086, time: 9.65463900566101


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5859459459854965, Training Loss Force: 2.113636837891892, time: 1.2245266437530518
Validation Loss Energy: 2.807893000539888, Validation Loss Force: 2.403300379024774, time: 0.08428239822387695
Test Loss Energy: 14.618082501165556, Test Loss Force: 8.877900272768274, time: 9.46344518661499


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7895456178432796, Training Loss Force: 2.076645036657873, time: 1.2971105575561523
Validation Loss Energy: 0.8437628945275608, Validation Loss Force: 2.255015753981904, time: 0.0839695930480957
Test Loss Energy: 12.626417569971494, Test Loss Force: 8.864633985469553, time: 9.377830028533936


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9511965471338826, Training Loss Force: 2.0906419065265025, time: 1.2441742420196533
Validation Loss Energy: 1.7813530560877298, Validation Loss Force: 2.3096643291212313, time: 0.08442020416259766
Test Loss Energy: 11.771484173317097, Test Loss Force: 8.831311727315745, time: 9.62737226486206


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.061829058033761, Training Loss Force: 2.0884201426044418, time: 1.2524738311767578
Validation Loss Energy: 2.187180823355306, Validation Loss Force: 2.2421206497375064, time: 0.0868065357208252
Test Loss Energy: 11.66960610949805, Test Loss Force: 8.775652881276818, time: 9.394974946975708


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5663655490463402, Training Loss Force: 2.0903944058413475, time: 1.25266432762146
Validation Loss Energy: 2.038310578458646, Validation Loss Force: 2.3412491681290772, time: 0.08543157577514648
Test Loss Energy: 14.027022623300349, Test Loss Force: 8.871849967357091, time: 9.478698253631592


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9982259754826168, Training Loss Force: 2.078615697893889, time: 1.4825756549835205
Validation Loss Energy: 1.4262994208203374, Validation Loss Force: 2.3011751792673074, time: 0.08547043800354004
Test Loss Energy: 12.152205562449806, Test Loss Force: 8.863273703154501, time: 9.454955101013184


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4884173968750085, Training Loss Force: 2.1025923709745813, time: 1.2591626644134521
Validation Loss Energy: 3.9928663843680137, Validation Loss Force: 2.241856898134155, time: 0.08684206008911133
Test Loss Energy: 11.482937849943088, Test Loss Force: 8.863957514272611, time: 9.518638372421265


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5285081319860752, Training Loss Force: 2.0821776798991003, time: 1.2525451183319092
Validation Loss Energy: 0.9622692231771401, Validation Loss Force: 2.3160165231816863, time: 0.08759522438049316
Test Loss Energy: 12.339597764864653, Test Loss Force: 8.902472836599992, time: 9.699032068252563


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8738147872278401, Training Loss Force: 2.108558540564382, time: 1.2402522563934326
Validation Loss Energy: 2.6865521214962915, Validation Loss Force: 2.229258166522988, time: 0.08260750770568848
Test Loss Energy: 14.661570671378609, Test Loss Force: 8.794931888367534, time: 9.922306299209595


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5372027334216725, Training Loss Force: 2.085554597647675, time: 1.2769334316253662
Validation Loss Energy: 1.1999572359958979, Validation Loss Force: 2.396503069341609, time: 0.08809351921081543
Test Loss Energy: 13.402968055745324, Test Loss Force: 8.808651837820422, time: 9.55376148223877


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7843709434152288, Training Loss Force: 2.1272760513390576, time: 1.2464697360992432
Validation Loss Energy: 1.3399115856204633, Validation Loss Force: 2.3467335091932786, time: 0.08450698852539062
Test Loss Energy: 13.523725003023735, Test Loss Force: 8.841758860014034, time: 9.586440324783325


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5178709734352236, Training Loss Force: 2.088334969036487, time: 1.2651150226593018
Validation Loss Energy: 0.8556073900741841, Validation Loss Force: 2.279694175425081, time: 0.08379101753234863
Test Loss Energy: 12.57660127320156, Test Loss Force: 8.863414234199144, time: 9.507103681564331


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.29449301725848, Training Loss Force: 2.0761146649486424, time: 1.2551593780517578
Validation Loss Energy: 1.1587793091759044, Validation Loss Force: 2.31060488359363, time: 0.08702898025512695
Test Loss Energy: 13.38074388430211, Test Loss Force: 8.97128760065291, time: 9.577623844146729


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6240248114408422, Training Loss Force: 2.0997998942431417, time: 1.2722187042236328
Validation Loss Energy: 0.7781501184763925, Validation Loss Force: 2.2233490840629297, time: 0.08615779876708984
Test Loss Energy: 12.489275199987892, Test Loss Force: 8.845411823130437, time: 9.651354312896729


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.1343235333019224, Training Loss Force: 2.0989548962699898, time: 1.2847607135772705
Validation Loss Energy: 1.7092094774874291, Validation Loss Force: 2.363872910028205, time: 0.09480714797973633
Test Loss Energy: 12.316606040051548, Test Loss Force: 8.97442844804982, time: 9.456655979156494


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.629702596980478, Training Loss Force: 2.0976971234028468, time: 1.2405853271484375
Validation Loss Energy: 1.0342053298007226, Validation Loss Force: 2.3741767020868676, time: 0.08423399925231934
Test Loss Energy: 11.997257299159754, Test Loss Force: 8.876301601565075, time: 9.580277681350708


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8131975508964608, Training Loss Force: 2.0871542082581906, time: 1.3003413677215576
Validation Loss Energy: 0.7900799798068359, Validation Loss Force: 2.2201110293428474, time: 0.08574390411376953
Test Loss Energy: 12.658744886422557, Test Loss Force: 8.894645911197996, time: 9.622078895568848

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–…â–ˆâ–„â–‚â–â–‡â–‚â–â–ƒâ–ˆâ–…â–…â–ƒâ–…â–ƒâ–ƒâ–‚â–„
wandb:   test_error_force â–â–‡â–†â–…â–„â–ƒâ–â–„â–„â–„â–…â–‚â–‚â–ƒâ–„â–ˆâ–ƒâ–ˆâ–…â–…
wandb:          test_loss â–â–†â–†â–‡â–†â–„â–ƒâ–†â–…â–ƒâ–…â–†â–…â–†â–…â–ˆâ–…â–‡â–„â–†
wandb: train_error_energy â–ˆâ–‚â–…â–ƒâ–„â–…â–†â–ƒâ–…â–ˆâ–ƒâ–…â–ƒâ–„â–ƒâ–‚â–„â–â–„â–„
wandb:  train_error_force â–ˆâ–â–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–â–ƒâ–â–ƒâ–‚â–â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–„â–‚â–ƒâ–‚â–„â–‚â–â–‚â–â–‚â–‚
wandb: valid_error_energy â–â–„â–ƒâ–…â–â–ƒâ–„â–„â–‚â–ˆâ–â–…â–‚â–‚â–â–‚â–â–ƒâ–‚â–
wandb:  valid_error_force â–â–ƒâ–â–ˆâ–ƒâ–…â–‚â–†â–„â–‚â–…â–‚â–ˆâ–†â–„â–…â–‚â–‡â–‡â–
wandb:         valid_loss â–â–„â–‚â–ˆâ–‚â–„â–ƒâ–…â–„â–†â–ƒâ–„â–†â–…â–‚â–„â–â–†â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 2701
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.65874
wandb:   test_error_force 8.89465
wandb:          test_loss 6.49974
wandb: train_error_energy 1.8132
wandb:  train_error_force 2.08715
wandb:         train_loss -2.30031
wandb: valid_error_energy 0.79008
wandb:  valid_error_force 2.22011
wandb:         valid_loss -2.20531
wandb: 
wandb: ğŸš€ View run al_58_22 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ilhbjfm2
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_193459-ilhbjfm2/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 36.57268142700195, Uncertainty Bias: -4.882363796234131
1.335144e-05 0.0014891624
-2.0008302 27.26217
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 152 steps.
Found uncertainty sample 2 after 559 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3534 steps.
Found uncertainty sample 6 after 904 steps.
Found uncertainty sample 7 after 1622 steps.
Found uncertainty sample 8 after 1698 steps.
Found uncertainty sample 9 after 398 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1 steps.
Found uncertainty sample 12 after 1408 steps.
Found uncertainty sample 13 after 3080 steps.
Found uncertainty sample 14 after 679 steps.
Found uncertainty sample 15 after 1589 steps.
Found uncertainty sample 16 after 1156 steps.
Found uncertainty sample 17 after 3467 steps.
Found uncertainty sample 18 after 1987 steps.
Found uncertainty sample 19 after 1233 steps.
Found uncertainty sample 20 after 163 steps.
Found uncertainty sample 21 after 441 steps.
Found uncertainty sample 22 after 1631 steps.
Found uncertainty sample 23 after 1941 steps.
Found uncertainty sample 24 after 337 steps.
Found uncertainty sample 25 after 1 steps.
Found uncertainty sample 26 after 1714 steps.
Found uncertainty sample 27 after 3777 steps.
Found uncertainty sample 28 after 1993 steps.
Found uncertainty sample 29 after 1188 steps.
Found uncertainty sample 30 after 687 steps.
Found uncertainty sample 31 after 1067 steps.
Found uncertainty sample 32 after 192 steps.
Found uncertainty sample 33 after 559 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1133 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 326 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1408 steps.
Found uncertainty sample 40 after 1591 steps.
Found uncertainty sample 41 after 149 steps.
Found uncertainty sample 42 after 3103 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1824 steps.
Found uncertainty sample 46 after 2258 steps.
Found uncertainty sample 47 after 937 steps.
Found uncertainty sample 48 after 2983 steps.
Found uncertainty sample 49 after 2506 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 8 steps.
Found uncertainty sample 53 after 2734 steps.
Found uncertainty sample 54 after 2703 steps.
Found uncertainty sample 55 after 1458 steps.
Found uncertainty sample 56 after 2337 steps.
Found uncertainty sample 57 after 874 steps.
Found uncertainty sample 58 after 1276 steps.
Found uncertainty sample 59 after 3932 steps.
Found uncertainty sample 60 after 879 steps.
Found uncertainty sample 61 after 1144 steps.
Found uncertainty sample 62 after 3035 steps.
Found uncertainty sample 63 after 851 steps.
Found uncertainty sample 64 after 1726 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1355 steps.
Found uncertainty sample 67 after 2870 steps.
Found uncertainty sample 68 after 1421 steps.
Found uncertainty sample 69 after 944 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 757 steps.
Found uncertainty sample 72 after 382 steps.
Found uncertainty sample 73 after 987 steps.
Found uncertainty sample 74 after 192 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3461 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2617 steps.
Found uncertainty sample 80 after 1919 steps.
Found uncertainty sample 81 after 1399 steps.
Found uncertainty sample 82 after 1334 steps.
Found uncertainty sample 83 after 1858 steps.
Found uncertainty sample 84 after 97 steps.
Found uncertainty sample 85 after 46 steps.
Found uncertainty sample 86 after 162 steps.
Found uncertainty sample 87 after 3975 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 339 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 195 steps.
Found uncertainty sample 92 after 288 steps.
Found uncertainty sample 93 after 3099 steps.
Found uncertainty sample 94 after 705 steps.
Found uncertainty sample 95 after 3385 steps.
Found uncertainty sample 96 after 1657 steps.
Found uncertainty sample 97 after 339 steps.
Found uncertainty sample 98 after 311 steps.
Found uncertainty sample 99 after 2458 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_195923-59bl8zqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_23
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/59bl8zqg
Training model 23. Added 83 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.221365932503033, Training Loss Force: 2.3226603012090252, time: 1.3377306461334229
Validation Loss Energy: 1.3862155788488604, Validation Loss Force: 2.303959990940853, time: 0.08743667602539062
Test Loss Energy: 13.363941102674184, Test Loss Force: 8.910196937820464, time: 9.372650623321533


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5854788875755805, Training Loss Force: 2.1106387318650124, time: 1.279627799987793
Validation Loss Energy: 2.5994968355314985, Validation Loss Force: 2.2551557015401196, time: 0.08815646171569824
Test Loss Energy: 14.682059473747554, Test Loss Force: 8.988752164308991, time: 9.417532920837402


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8926206613059866, Training Loss Force: 2.1228697701714507, time: 1.29530668258667
Validation Loss Energy: 2.656606906744485, Validation Loss Force: 2.2640769408717163, time: 0.08909940719604492
Test Loss Energy: 14.270556847479488, Test Loss Force: 8.877287673807809, time: 9.57545804977417


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6204635638749558, Training Loss Force: 2.089331058036983, time: 1.2716069221496582
Validation Loss Energy: 0.8784642665690986, Validation Loss Force: 2.364091459794933, time: 0.09244918823242188
Test Loss Energy: 12.80731945408989, Test Loss Force: 9.011405334092496, time: 9.43447470664978


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1357893046763667, Training Loss Force: 2.131731678413319, time: 1.294301986694336
Validation Loss Energy: 1.0731860688232735, Validation Loss Force: 2.315707681076284, time: 0.08849310874938965
Test Loss Energy: 13.380149877632425, Test Loss Force: 8.823089220266649, time: 9.39875078201294


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3833877504396492, Training Loss Force: 2.082938679873933, time: 1.292891025543213
Validation Loss Energy: 1.8408280962996149, Validation Loss Force: 2.2610512011822763, time: 0.0853421688079834
Test Loss Energy: 12.072434571750971, Test Loss Force: 8.816550987300579, time: 9.967246294021606


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9048592901988555, Training Loss Force: 2.0882155598389325, time: 1.3267755508422852
Validation Loss Energy: 0.9155938178133356, Validation Loss Force: 2.278684259513725, time: 0.08856630325317383
Test Loss Energy: 12.389920297023332, Test Loss Force: 8.808957810874682, time: 9.503676414489746


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7024085871820211, Training Loss Force: 2.101611476425799, time: 1.2980117797851562
Validation Loss Energy: 0.9241608462010479, Validation Loss Force: 2.4057814699832742, time: 0.0888519287109375
Test Loss Energy: 12.585583905098046, Test Loss Force: 8.825174835083587, time: 9.502789974212646


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8723471493719164, Training Loss Force: 2.0661373778226513, time: 1.5189406871795654
Validation Loss Energy: 0.9047998752971995, Validation Loss Force: 2.306769518889597, time: 0.08799457550048828
Test Loss Energy: 12.870830234423583, Test Loss Force: 8.844145551495634, time: 9.51341700553894


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.725049111488316, Training Loss Force: 2.099280762643556, time: 1.322188138961792
Validation Loss Energy: 3.107805293848015, Validation Loss Force: 2.3424942226585324, time: 0.08735084533691406
Test Loss Energy: 11.628819930277231, Test Loss Force: 8.902573203260262, time: 9.330500602722168


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9968709456481155, Training Loss Force: 2.0883683083136235, time: 1.2999260425567627
Validation Loss Energy: 1.4019657468823434, Validation Loss Force: 2.339142829343173, time: 0.08698439598083496
Test Loss Energy: 13.338350197060675, Test Loss Force: 8.865722140440527, time: 9.550694704055786


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5976051427728053, Training Loss Force: 2.0831655285453246, time: 1.3182435035705566
Validation Loss Energy: 2.1125473583652408, Validation Loss Force: 2.34247273508595, time: 0.08634805679321289
Test Loss Energy: 13.92643912758474, Test Loss Force: 8.892190241245054, time: 9.428386449813843


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5558191538644692, Training Loss Force: 2.084230240262195, time: 1.302649974822998
Validation Loss Energy: 2.3515342559794816, Validation Loss Force: 2.280868198496985, time: 0.08777308464050293
Test Loss Energy: 13.865238986144153, Test Loss Force: 8.898051406120974, time: 9.37879729270935


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4622027218805076, Training Loss Force: 2.088103344827047, time: 1.2623207569122314
Validation Loss Energy: 1.8920426678704438, Validation Loss Force: 2.262248715849076, time: 0.08707022666931152
Test Loss Energy: 13.80810946052607, Test Loss Force: 8.870663007907293, time: 9.62655234336853


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.665773589549648, Training Loss Force: 2.055595286267783, time: 1.274695634841919
Validation Loss Energy: 0.8511700115004919, Validation Loss Force: 2.272001735775286, time: 0.08471417427062988
Test Loss Energy: 12.686171942797907, Test Loss Force: 8.865500170778828, time: 9.3928964138031


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6054400554840305, Training Loss Force: 2.0561457410327173, time: 1.2548489570617676
Validation Loss Energy: 2.1750941194451996, Validation Loss Force: 2.240034351174736, time: 0.10044717788696289
Test Loss Energy: 12.188505646206334, Test Loss Force: 8.772648456620518, time: 9.451019048690796


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.836207260424637, Training Loss Force: 2.11919534023249, time: 1.3165009021759033
Validation Loss Energy: 1.8294424105281757, Validation Loss Force: 2.3441806074352165, time: 0.08966350555419922
Test Loss Energy: 12.099486210277902, Test Loss Force: 8.79709430655271, time: 9.546843528747559


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.4802718355039006, Training Loss Force: 2.061756030932219, time: 1.2760207653045654
Validation Loss Energy: 1.5846410648408955, Validation Loss Force: 2.1975124490572093, time: 0.08828401565551758
Test Loss Energy: 13.589912588254222, Test Loss Force: 8.727973392242863, time: 9.816726922988892


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.753801299828277, Training Loss Force: 2.080716375252772, time: 1.3339862823486328
Validation Loss Energy: 1.2020338484508204, Validation Loss Force: 2.289976368576588, time: 0.0927276611328125
Test Loss Energy: 12.423533960306548, Test Loss Force: 8.766425355288865, time: 9.365822076797485


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9349410683217723, Training Loss Force: 2.062089843974658, time: 1.2854866981506348
Validation Loss Energy: 1.2281617346994143, Validation Loss Force: 2.305474029798589, time: 0.08672022819519043
Test Loss Energy: 12.940027704950579, Test Loss Force: 8.861099197881865, time: 9.582680463790894

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–ˆâ–‡â–„â–…â–‚â–ƒâ–ƒâ–„â–â–…â–†â–†â–†â–ƒâ–‚â–‚â–…â–ƒâ–„
wandb:   test_error_force â–†â–‡â–…â–ˆâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–…â–„â–…â–…â–…â–„â–‚â–ƒâ–â–‚â–„
wandb:          test_loss â–ƒâ–ˆâ–ƒâ–…â–â–â–‚â–â–ƒâ–â–„â–†â–†â–…â–…â–ƒâ–ƒâ–„â–ƒâ–…
wandb: train_error_energy â–ˆâ–ƒâ–…â–ƒâ–‡â–â–…â–„â–…â–„â–†â–ƒâ–‚â–‚â–ƒâ–ƒâ–…â–‚â–„â–†
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–â–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–â–‚â–‚
wandb: valid_error_energy â–ƒâ–†â–‡â–â–‚â–„â–â–â–â–ˆâ–ƒâ–…â–†â–„â–â–…â–„â–ƒâ–‚â–‚
wandb:  valid_error_force â–…â–ƒâ–ƒâ–‡â–…â–ƒâ–„â–ˆâ–…â–†â–†â–†â–„â–ƒâ–„â–‚â–†â–â–„â–…
wandb:         valid_loss â–„â–„â–…â–…â–„â–ƒâ–‚â–†â–ƒâ–ˆâ–…â–†â–…â–ƒâ–‚â–ƒâ–†â–â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 2775
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.94003
wandb:   test_error_force 8.8611
wandb:          test_loss 6.43047
wandb: train_error_energy 1.93494
wandb:  train_error_force 2.06209
wandb:         train_loss -2.32173
wandb: valid_error_energy 1.22816
wandb:  valid_error_force 2.30547
wandb:         valid_loss -2.07513
wandb: 
wandb: ğŸš€ View run al_58_23 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/59bl8zqg
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_195923-59bl8zqg/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 38.10829544067383, Uncertainty Bias: -5.139712810516357
0.0001373291 0.0026855469
-2.2765195 25.152927
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2155 steps.
Found uncertainty sample 1 after 595 steps.
Found uncertainty sample 2 after 1107 steps.
Found uncertainty sample 3 after 3530 steps.
Found uncertainty sample 4 after 2265 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3182 steps.
Found uncertainty sample 7 after 1078 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 16 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 122 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3711 steps.
Found uncertainty sample 16 after 2063 steps.
Found uncertainty sample 17 after 3036 steps.
Found uncertainty sample 18 after 3511 steps.
Found uncertainty sample 19 after 412 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1397 steps.
Found uncertainty sample 22 after 2199 steps.
Found uncertainty sample 23 after 2727 steps.
Found uncertainty sample 24 after 3264 steps.
Found uncertainty sample 25 after 1897 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 165 steps.
Found uncertainty sample 30 after 3510 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 806 steps.
Found uncertainty sample 34 after 3495 steps.
Found uncertainty sample 35 after 2774 steps.
Found uncertainty sample 36 after 1054 steps.
Found uncertainty sample 37 after 3880 steps.
Found uncertainty sample 38 after 1315 steps.
Found uncertainty sample 39 after 1717 steps.
Found uncertainty sample 40 after 2286 steps.
Found uncertainty sample 41 after 939 steps.
Found uncertainty sample 42 after 419 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 391 steps.
Found uncertainty sample 45 after 657 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3065 steps.
Found uncertainty sample 50 after 483 steps.
Found uncertainty sample 51 after 3881 steps.
Found uncertainty sample 52 after 3274 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 700 steps.
Found uncertainty sample 55 after 2938 steps.
Found uncertainty sample 56 after 996 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1920 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1054 steps.
Found uncertainty sample 63 after 1194 steps.
Found uncertainty sample 64 after 652 steps.
Found uncertainty sample 65 after 3681 steps.
Found uncertainty sample 66 after 1529 steps.
Found uncertainty sample 67 after 1816 steps.
Found uncertainty sample 68 after 1436 steps.
Found uncertainty sample 69 after 526 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2487 steps.
Found uncertainty sample 72 after 3262 steps.
Found uncertainty sample 73 after 1656 steps.
Found uncertainty sample 74 after 2364 steps.
Found uncertainty sample 75 after 1566 steps.
Found uncertainty sample 76 after 2515 steps.
Found uncertainty sample 77 after 483 steps.
Found uncertainty sample 78 after 25 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 257 steps.
Found uncertainty sample 82 after 3349 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1085 steps.
Found uncertainty sample 85 after 3909 steps.
Found uncertainty sample 86 after 1834 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 786 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 565 steps.
Found uncertainty sample 95 after 3166 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1789 steps.
Found uncertainty sample 98 after 2921 steps.
Found uncertainty sample 99 after 2543 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_203005-vbkzl14n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_24
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vbkzl14n
Training model 24. Added 68 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4113195956538194, Training Loss Force: 2.3123799845116633, time: 1.307852029800415
Validation Loss Energy: 1.1596703197633347, Validation Loss Force: 2.2704778994751296, time: 0.0908207893371582
Test Loss Energy: 12.94496407706537, Test Loss Force: 8.782468851450476, time: 9.401243448257446


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6197935339238017, Training Loss Force: 2.097684784574033, time: 1.329965591430664
Validation Loss Energy: 2.2422020353103433, Validation Loss Force: 2.298094440298823, time: 0.09535861015319824
Test Loss Energy: 14.03211172546472, Test Loss Force: 8.831337267816524, time: 10.323739290237427


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.2803856067140718, Training Loss Force: 2.0798789900271557, time: 1.3248696327209473
Validation Loss Energy: 0.8238987191875591, Validation Loss Force: 2.2845178571333142, time: 0.10300993919372559
Test Loss Energy: 12.656343869503967, Test Loss Force: 8.816037346705468, time: 10.908878087997437


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0255199861045052, Training Loss Force: 2.0855073642531154, time: 1.4060826301574707
Validation Loss Energy: 0.9621139114478555, Validation Loss Force: 2.2467301237273576, time: 0.0929267406463623
Test Loss Energy: 12.54110508801541, Test Loss Force: 8.880446707794649, time: 10.736971378326416


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.451594101641974, Training Loss Force: 2.117912621474381, time: 1.4487030506134033
Validation Loss Energy: 0.8357485866273279, Validation Loss Force: 2.224550272770637, time: 0.10444331169128418
Test Loss Energy: 12.406172290780411, Test Loss Force: 8.766423853729389, time: 10.812383651733398


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4052856118728745, Training Loss Force: 2.0733138316928743, time: 1.42201566696167
Validation Loss Energy: 1.8925016446474876, Validation Loss Force: 2.2068121146023105, time: 0.10027146339416504
Test Loss Energy: 11.691101077959987, Test Loss Force: 8.796639567192832, time: 10.746602535247803


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3904607138888005, Training Loss Force: 2.049754128810695, time: 1.4575762748718262
Validation Loss Energy: 3.14990490393029, Validation Loss Force: 2.246396120008466, time: 0.09689927101135254
Test Loss Energy: 11.57453401789143, Test Loss Force: 8.760667303714614, time: 10.787402153015137


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9022722335445965, Training Loss Force: 2.076271942509465, time: 1.3545186519622803
Validation Loss Energy: 1.7887407730113218, Validation Loss Force: 2.2071593671353846, time: 0.09211182594299316
Test Loss Energy: 12.024748307046458, Test Loss Force: 8.796388951320377, time: 10.751769065856934


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4919177188786825, Training Loss Force: 2.0989739701266905, time: 1.3103058338165283
Validation Loss Energy: 1.0957478530325473, Validation Loss Force: 2.254323586941787, time: 0.09216833114624023
Test Loss Energy: 12.356706272395744, Test Loss Force: 8.8128897562806, time: 10.822062730789185


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7527746370935386, Training Loss Force: 2.0598880030448603, time: 1.3621113300323486
Validation Loss Energy: 0.8465536347671171, Validation Loss Force: 2.2618528101076167, time: 0.09345817565917969
Test Loss Energy: 12.9812038419653, Test Loss Force: 8.853612403680598, time: 11.179245233535767


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6412409553808764, Training Loss Force: 2.08184846484723, time: 1.2854700088500977
Validation Loss Energy: 2.075979072536958, Validation Loss Force: 2.336978151241036, time: 0.10322856903076172
Test Loss Energy: 13.852987846315912, Test Loss Force: 8.751898201036813, time: 11.326539039611816


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8403515330383688, Training Loss Force: 2.052244080249873, time: 1.346665620803833
Validation Loss Energy: 2.335690455570136, Validation Loss Force: 2.2540042793865265, time: 0.10408186912536621
Test Loss Energy: 14.395502213050872, Test Loss Force: 8.826643868543186, time: 10.651606798171997


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7015089097883336, Training Loss Force: 2.054625005119313, time: 1.3948655128479004
Validation Loss Energy: 1.6903270225781797, Validation Loss Force: 2.2441532850361083, time: 0.10498452186584473
Test Loss Energy: 12.265993217274998, Test Loss Force: 8.830861282789025, time: 10.991455554962158


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2060742034386336, Training Loss Force: 2.0770308339853947, time: 1.430924415588379
Validation Loss Energy: 0.8140419354393467, Validation Loss Force: 2.222283278195946, time: 0.10521531105041504
Test Loss Energy: 12.700413464997053, Test Loss Force: 8.851942692859202, time: 10.836838960647583


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7968207820700561, Training Loss Force: 2.0460597637140445, time: 1.324016809463501
Validation Loss Energy: 1.1348607461932063, Validation Loss Force: 2.223157254593713, time: 0.10173892974853516
Test Loss Energy: 12.564328258169894, Test Loss Force: 8.757348736028272, time: 10.969334363937378


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8261743273726252, Training Loss Force: 2.1071767336832945, time: 1.3497354984283447
Validation Loss Energy: 1.3112415414000986, Validation Loss Force: 2.1865382002001583, time: 0.10122895240783691
Test Loss Energy: 12.27141837964189, Test Loss Force: 8.794117460227907, time: 10.823309421539307


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5327837531510695, Training Loss Force: 2.075533150051332, time: 1.3615930080413818
Validation Loss Energy: 0.8871628367547677, Validation Loss Force: 2.208817027592244, time: 0.09968733787536621
Test Loss Energy: 12.434559808949292, Test Loss Force: 8.808149915917747, time: 10.713022470474243


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6600395096817957, Training Loss Force: 2.0618374063680442, time: 1.4015395641326904
Validation Loss Energy: 2.3287053244623808, Validation Loss Force: 2.3461493366889368, time: 0.10399365425109863
Test Loss Energy: 14.587571642663706, Test Loss Force: 8.950658626307892, time: 10.97763180732727


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9141236556027985, Training Loss Force: 2.1013253625624393, time: 1.4020814895629883
Validation Loss Energy: 1.146519090333834, Validation Loss Force: 2.2035083724841797, time: 0.10304856300354004
Test Loss Energy: 13.400781715199546, Test Loss Force: 8.78432797327437, time: 10.68625545501709


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5501292636778836, Training Loss Force: 2.084173980125941, time: 1.3918063640594482
Validation Loss Energy: 1.3503758664660532, Validation Loss Force: 2.3750660426557033, time: 0.1048429012298584
Test Loss Energy: 13.532056214585099, Test Loss Force: 8.9261657756988, time: 11.017532587051392

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‡â–„â–ƒâ–ƒâ–â–â–‚â–ƒâ–„â–†â–ˆâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ˆâ–…â–†
wandb:   test_error_force â–‚â–„â–ƒâ–†â–‚â–ƒâ–â–ƒâ–ƒâ–…â–â–„â–„â–…â–â–‚â–ƒâ–ˆâ–‚â–‡
wandb:          test_loss â–â–…â–ƒâ–†â–â–„â–„â–‚â–„â–…â–„â–†â–„â–…â–„â–ƒâ–„â–ˆâ–…â–‡
wandb: train_error_energy â–ˆâ–ƒâ–â–†â–‚â–‚â–‚â–…â–‚â–„â–ƒâ–„â–„â–‡â–„â–„â–ƒâ–ƒâ–…â–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–â–‚â–â–â–‚â–â–ƒâ–‚â–â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–â–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚
wandb: valid_error_energy â–‚â–…â–â–â–â–„â–ˆâ–„â–‚â–â–…â–†â–„â–â–‚â–‚â–â–†â–‚â–ƒ
wandb:  valid_error_force â–„â–…â–…â–ƒâ–‚â–‚â–ƒâ–‚â–„â–„â–‡â–„â–ƒâ–‚â–‚â–â–‚â–‡â–‚â–ˆ
wandb:         valid_loss â–ƒâ–†â–ƒâ–‚â–â–ƒâ–†â–ƒâ–ƒâ–ƒâ–‡â–…â–„â–â–‚â–â–â–ˆâ–â–‡
wandb: 
wandb: Run summary:
wandb:       dataset_size 2836
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.53206
wandb:   test_error_force 8.92617
wandb:          test_loss 6.6014
wandb: train_error_energy 1.55013
wandb:  train_error_force 2.08417
wandb:         train_loss -2.32124
wandb: valid_error_energy 1.35038
wandb:  valid_error_force 2.37507
wandb:         valid_loss -1.9815
wandb: 
wandb: ğŸš€ View run al_58_24 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vbkzl14n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_203005-vbkzl14n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 38.035648345947266, Uncertainty Bias: -5.0974907875061035
3.0517578e-05 0.0052337646
-2.049846 26.325792
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2003 steps.
Found uncertainty sample 1 after 1078 steps.
Found uncertainty sample 2 after 2491 steps.
Found uncertainty sample 3 after 256 steps.
Found uncertainty sample 4 after 2334 steps.
Found uncertainty sample 5 after 1162 steps.
Found uncertainty sample 6 after 1332 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 359 steps.
Found uncertainty sample 9 after 187 steps.
Found uncertainty sample 10 after 154 steps.
Found uncertainty sample 11 after 588 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1119 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 205 steps.
Found uncertainty sample 16 after 1596 steps.
Found uncertainty sample 17 after 2072 steps.
Found uncertainty sample 18 after 1353 steps.
Found uncertainty sample 19 after 1039 steps.
Found uncertainty sample 20 after 2571 steps.
Found uncertainty sample 21 after 3557 steps.
Found uncertainty sample 22 after 3283 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3694 steps.
Found uncertainty sample 25 after 747 steps.
Found uncertainty sample 26 after 792 steps.
Found uncertainty sample 27 after 1640 steps.
Found uncertainty sample 28 after 423 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2562 steps.
Found uncertainty sample 31 after 1519 steps.
Found uncertainty sample 32 after 965 steps.
Found uncertainty sample 33 after 1875 steps.
Found uncertainty sample 34 after 1 steps.
Found uncertainty sample 35 after 2956 steps.
Found uncertainty sample 36 after 339 steps.
Found uncertainty sample 37 after 975 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2917 steps.
Found uncertainty sample 41 after 99 steps.
Found uncertainty sample 42 after 3106 steps.
Found uncertainty sample 43 after 708 steps.
Found uncertainty sample 44 after 3310 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3112 steps.
Found uncertainty sample 47 after 1794 steps.
Found uncertainty sample 48 after 13 steps.
Found uncertainty sample 49 after 1422 steps.
Found uncertainty sample 50 after 879 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1266 steps.
Found uncertainty sample 53 after 1051 steps.
Found uncertainty sample 54 after 1818 steps.
Found uncertainty sample 55 after 3645 steps.
Found uncertainty sample 56 after 1828 steps.
Found uncertainty sample 57 after 2247 steps.
Found uncertainty sample 58 after 2915 steps.
Found uncertainty sample 59 after 3546 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1362 steps.
Found uncertainty sample 62 after 1537 steps.
Found uncertainty sample 63 after 1497 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1887 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3419 steps.
Found uncertainty sample 68 after 2419 steps.
Found uncertainty sample 69 after 2446 steps.
Found uncertainty sample 70 after 1071 steps.
Found uncertainty sample 71 after 1382 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1458 steps.
Found uncertainty sample 74 after 298 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1991 steps.
Found uncertainty sample 77 after 1832 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3538 steps.
Found uncertainty sample 80 after 871 steps.
Found uncertainty sample 81 after 1352 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 400 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 995 steps.
Found uncertainty sample 86 after 933 steps.
Found uncertainty sample 87 after 396 steps.
Found uncertainty sample 88 after 2446 steps.
Found uncertainty sample 89 after 76 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1199 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 892 steps.
Found uncertainty sample 96 after 1188 steps.
Found uncertainty sample 97 after 502 steps.
Found uncertainty sample 98 after 1587 steps.
Found uncertainty sample 99 after 654 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_205632-8gnzzwq9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_25
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8gnzzwq9
Training model 25. Added 79 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5797498009847866, Training Loss Force: 2.31526100432264, time: 1.417339563369751
Validation Loss Energy: 2.524531370844855, Validation Loss Force: 2.2383624398925375, time: 0.11220097541809082
Test Loss Energy: 14.964286777849338, Test Loss Force: 8.783630107186507, time: 10.702250003814697


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.078670320348224, Training Loss Force: 2.0776773701129496, time: 1.5091238021850586
Validation Loss Energy: 1.6741645826210112, Validation Loss Force: 2.3124095056868015, time: 0.11093306541442871
Test Loss Energy: 13.749116975247299, Test Loss Force: 8.879639876053739, time: 10.864008665084839


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1016362337641463, Training Loss Force: 2.0767312036439987, time: 1.4645664691925049
Validation Loss Energy: 1.8880648505803035, Validation Loss Force: 2.2493172051993198, time: 0.10364270210266113
Test Loss Energy: 11.792953937030683, Test Loss Force: 8.792208889532317, time: 11.528464555740356


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4944526062175805, Training Loss Force: 2.0690217762959007, time: 1.4752743244171143
Validation Loss Energy: 1.027193756731889, Validation Loss Force: 2.2118829590625237, time: 0.10796594619750977
Test Loss Energy: 12.562577561064574, Test Loss Force: 8.740380628971431, time: 10.880903005599976


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.3093552627383989, Training Loss Force: 2.0707960835753485, time: 1.4609153270721436
Validation Loss Energy: 1.0759689321417927, Validation Loss Force: 2.2987172458999834, time: 0.09947681427001953
Test Loss Energy: 12.168082977739537, Test Loss Force: 8.83062847112179, time: 11.168415546417236


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6333691396091512, Training Loss Force: 2.0742186857495017, time: 1.4987225532531738
Validation Loss Energy: 2.5341986631498834, Validation Loss Force: 2.194182654649005, time: 0.10413837432861328
Test Loss Energy: 14.278658320440991, Test Loss Force: 8.696737299166916, time: 10.77291750907898


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8251987256660696, Training Loss Force: 2.104765339652114, time: 1.3706047534942627
Validation Loss Energy: 2.1878560675403316, Validation Loss Force: 2.211728983348115, time: 0.10352635383605957
Test Loss Energy: 11.427863446292834, Test Loss Force: 8.738469502826796, time: 10.80526065826416


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5837749320249666, Training Loss Force: 2.083478719856998, time: 1.6610429286956787
Validation Loss Energy: 0.9551262753122092, Validation Loss Force: 2.1929421648370413, time: 0.10572314262390137
Test Loss Energy: 12.328143813221429, Test Loss Force: 8.72592130137336, time: 10.96854305267334


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5140456307930914, Training Loss Force: 2.0822002882013333, time: 1.4256532192230225
Validation Loss Energy: 1.189581076464809, Validation Loss Force: 2.2039983559397935, time: 0.09279537200927734
Test Loss Energy: 12.08901134536159, Test Loss Force: 8.747831721497699, time: 9.778806209564209


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4977159748715292, Training Loss Force: 2.091756913940835, time: 1.4212796688079834
Validation Loss Energy: 0.9049324747735996, Validation Loss Force: 2.2677461943928874, time: 0.10663056373596191
Test Loss Energy: 12.415045206244114, Test Loss Force: 8.783423647421756, time: 11.009827852249146


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7054798659462298, Training Loss Force: 2.087027763849246, time: 1.4231696128845215
Validation Loss Energy: 1.0307432699198373, Validation Loss Force: 2.2688589834496615, time: 0.09124565124511719
Test Loss Energy: 13.121414275680273, Test Loss Force: 8.794327547984185, time: 8.619914531707764


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.467923989298555, Training Loss Force: 2.063572522750579, time: 1.3963205814361572
Validation Loss Energy: 1.3267973192691866, Validation Loss Force: 2.234269112982947, time: 0.08539032936096191
Test Loss Energy: 13.73785447710052, Test Loss Force: 8.745114509728662, time: 8.56071400642395


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.607466817205382, Training Loss Force: 2.068265732573867, time: 1.3910863399505615
Validation Loss Energy: 1.4592683712392707, Validation Loss Force: 2.3540471886258496, time: 0.08463907241821289
Test Loss Energy: 12.93813272756515, Test Loss Force: 8.807827560942867, time: 8.927892923355103


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9396135696262036, Training Loss Force: 2.1001208870310424, time: 1.4257540702819824
Validation Loss Energy: 0.9813994531785207, Validation Loss Force: 2.2223818092930188, time: 0.09392428398132324
Test Loss Energy: 12.102209610150743, Test Loss Force: 8.753273275111672, time: 8.747580289840698


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4269110281209885, Training Loss Force: 2.04149691276403, time: 1.3883545398712158
Validation Loss Energy: 2.2485840670363526, Validation Loss Force: 2.1863955806121913, time: 0.08328866958618164
Test Loss Energy: 14.029656353958384, Test Loss Force: 8.777888059811398, time: 8.95927619934082


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.512373568413972, Training Loss Force: 2.061383070870772, time: 1.4265170097351074
Validation Loss Energy: 0.8262786348528786, Validation Loss Force: 2.212958339702782, time: 0.08919215202331543
Test Loss Energy: 12.547988581733218, Test Loss Force: 8.75367050754155, time: 8.868135929107666


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3639570963206626, Training Loss Force: 2.0617697456303308, time: 1.4703283309936523
Validation Loss Energy: 1.0251423615577429, Validation Loss Force: 2.1747703585070206, time: 0.08619809150695801
Test Loss Energy: 13.062346619163126, Test Loss Force: 8.712057351434055, time: 8.667455196380615


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6509308306441444, Training Loss Force: 2.0578253244299805, time: 1.4456532001495361
Validation Loss Energy: 2.294712652645045, Validation Loss Force: 2.292334434831963, time: 0.09048295021057129
Test Loss Energy: 14.451491737926993, Test Loss Force: 8.798821179225225, time: 8.634210109710693


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7937756013489097, Training Loss Force: 2.0673854688313704, time: 1.371647596359253
Validation Loss Energy: 1.4000437781492678, Validation Loss Force: 2.215894121057267, time: 0.08346176147460938
Test Loss Energy: 12.07546551618597, Test Loss Force: 8.780361081636421, time: 8.834223985671997


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.999049217586297, Training Loss Force: 2.0449870216165613, time: 1.4234960079193115
Validation Loss Energy: 3.0308005137883915, Validation Loss Force: 2.3172859599826205, time: 0.08701634407043457
Test Loss Energy: 11.46287164796536, Test Loss Force: 8.833418760339747, time: 8.690224885940552

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–†â–‚â–ƒâ–‚â–‡â–â–ƒâ–‚â–ƒâ–„â–†â–„â–‚â–†â–ƒâ–„â–‡â–‚â–
wandb:   test_error_force â–„â–ˆâ–…â–ƒâ–†â–â–ƒâ–‚â–ƒâ–„â–…â–ƒâ–…â–ƒâ–„â–ƒâ–‚â–…â–„â–†
wandb:          test_loss â–â–†â–‚â–„â–ƒâ–„â–â–ƒâ–â–‚â–ƒâ–…â–…â–ƒâ–ˆâ–…â–ƒâ–„â–ƒâ–…
wandb: train_error_energy â–ˆâ–…â–…â–‚â–â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–‡â–ƒâ–„â–‚â–‚â–â–ƒâ–„â–…
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–â–‚â–â–‚â–‚â–‚
wandb: valid_error_energy â–†â–„â–„â–‚â–‚â–†â–…â–â–‚â–â–‚â–ƒâ–ƒâ–â–†â–â–‚â–†â–ƒâ–ˆ
wandb:  valid_error_force â–ƒâ–†â–„â–‚â–†â–‚â–‚â–‚â–‚â–…â–…â–ƒâ–ˆâ–ƒâ–â–‚â–â–†â–ƒâ–‡
wandb:         valid_loss â–…â–†â–„â–‚â–„â–„â–„â–â–‚â–ƒâ–„â–ƒâ–‡â–‚â–ƒâ–‚â–â–†â–ƒâ–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2907
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.46287
wandb:   test_error_force 8.83342
wandb:          test_loss 6.4214
wandb: train_error_energy 1.99905
wandb:  train_error_force 2.04499
wandb:         train_loss -2.3388
wandb: valid_error_energy 3.0308
wandb:  valid_error_force 2.31729
wandb:         valid_loss -1.93486
wandb: 
wandb: ğŸš€ View run al_58_25 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8gnzzwq9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_205632-8gnzzwq9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.40446853637695, Uncertainty Bias: -4.949264049530029
0.00015258789 0.10138321
-1.8876857 24.426563
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 712 steps.
Found uncertainty sample 2 after 1105 steps.
Found uncertainty sample 3 after 2456 steps.
Found uncertainty sample 4 after 2039 steps.
Found uncertainty sample 5 after 392 steps.
Found uncertainty sample 6 after 333 steps.
Found uncertainty sample 7 after 700 steps.
Found uncertainty sample 8 after 164 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 300 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1986 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 346 steps.
Found uncertainty sample 17 after 762 steps.
Found uncertainty sample 18 after 2938 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 639 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 424 steps.
Found uncertainty sample 23 after 1186 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 964 steps.
Found uncertainty sample 28 after 15 steps.
Found uncertainty sample 29 after 969 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2107 steps.
Found uncertainty sample 32 after 375 steps.
Found uncertainty sample 33 after 818 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3676 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1340 steps.
Found uncertainty sample 38 after 2160 steps.
Found uncertainty sample 39 after 1230 steps.
Found uncertainty sample 40 after 240 steps.
Found uncertainty sample 41 after 527 steps.
Found uncertainty sample 42 after 1996 steps.
Found uncertainty sample 43 after 3821 steps.
Found uncertainty sample 44 after 1167 steps.
Found uncertainty sample 45 after 2004 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 168 steps.
Found uncertainty sample 48 after 469 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2058 steps.
Found uncertainty sample 51 after 800 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 934 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1779 steps.
Found uncertainty sample 57 after 3481 steps.
Found uncertainty sample 58 after 1054 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 283 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3542 steps.
Found uncertainty sample 63 after 2952 steps.
Found uncertainty sample 64 after 3820 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2831 steps.
Found uncertainty sample 69 after 2058 steps.
Found uncertainty sample 70 after 1578 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2585 steps.
Found uncertainty sample 73 after 1372 steps.
Found uncertainty sample 74 after 844 steps.
Found uncertainty sample 75 after 3664 steps.
Found uncertainty sample 76 after 1935 steps.
Found uncertainty sample 77 after 3501 steps.
Found uncertainty sample 78 after 1354 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 163 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1769 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1661 steps.
Found uncertainty sample 87 after 634 steps.
Found uncertainty sample 88 after 1967 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1067 steps.
Found uncertainty sample 91 after 47 steps.
Found uncertainty sample 92 after 365 steps.
Found uncertainty sample 93 after 663 steps.
Found uncertainty sample 94 after 2916 steps.
Found uncertainty sample 95 after 2395 steps.
Found uncertainty sample 96 after 3054 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1311 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_212510-pb4tj147
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_26
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pb4tj147
Training model 26. Added 67 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6956814182089737, Training Loss Force: 2.315345544427665, time: 1.3968210220336914
Validation Loss Energy: 0.7964631805458613, Validation Loss Force: 2.190242301442667, time: 0.1065831184387207
Test Loss Energy: 12.902283414761312, Test Loss Force: 8.719539566345244, time: 10.631839513778687


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7982836638953867, Training Loss Force: 2.0868191608392954, time: 1.4824483394622803
Validation Loss Energy: 1.5931817626021016, Validation Loss Force: 2.1797787442718013, time: 0.10943078994750977
Test Loss Energy: 13.567083922541128, Test Loss Force: 8.735527183043487, time: 10.480576753616333


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.691916303255758, Training Loss Force: 2.0663410025644686, time: 1.4604666233062744
Validation Loss Energy: 1.2207264222458798, Validation Loss Force: 2.338244693343073, time: 0.1085960865020752
Test Loss Energy: 12.256955624571102, Test Loss Force: 8.697600616590854, time: 10.884957313537598


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8971442185255953, Training Loss Force: 2.060618212773627, time: 1.4457709789276123
Validation Loss Energy: 1.0381041552113452, Validation Loss Force: 2.291296351273648, time: 0.1088860034942627
Test Loss Energy: 12.435668897151595, Test Loss Force: 8.79877484072673, time: 10.565252542495728


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6139404594593063, Training Loss Force: 2.0699232786440893, time: 1.4551379680633545
Validation Loss Energy: 2.4164138103667527, Validation Loss Force: 2.280197741698596, time: 0.09339451789855957
Test Loss Energy: 11.798424071570214, Test Loss Force: 8.805272139875775, time: 10.870525360107422


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4750638733940042, Training Loss Force: 2.05813491188371, time: 1.3810076713562012
Validation Loss Energy: 1.9018388856109638, Validation Loss Force: 2.2770920637857683, time: 0.10484051704406738
Test Loss Energy: 13.793090732074686, Test Loss Force: 8.79157435008323, time: 10.7770836353302


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6094678342153899, Training Loss Force: 2.0785017200226763, time: 1.4161655902862549
Validation Loss Energy: 1.6360775262156415, Validation Loss Force: 2.242616311256342, time: 0.09746527671813965
Test Loss Energy: 13.917575841687245, Test Loss Force: 8.816852474329323, time: 11.135822057723999


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6791258912200444, Training Loss Force: 2.088553702008797, time: 1.3679780960083008
Validation Loss Energy: 2.6747819417771215, Validation Loss Force: 2.1816683146441447, time: 0.11241817474365234
Test Loss Energy: 14.713689045354691, Test Loss Force: 8.724110425308286, time: 10.828661918640137


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.526288684154108, Training Loss Force: 2.0686426521199994, time: 1.4373517036437988
Validation Loss Energy: 1.3434348795164788, Validation Loss Force: 2.3984383982234405, time: 0.10637640953063965
Test Loss Energy: 13.259984381574652, Test Loss Force: 8.783532617738029, time: 10.822702884674072


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4705814662705643, Training Loss Force: 2.0578328025271078, time: 1.3815975189208984
Validation Loss Energy: 2.0911450680660995, Validation Loss Force: 2.1438433954908183, time: 0.10698199272155762
Test Loss Energy: 13.917219132710311, Test Loss Force: 8.730106674578325, time: 10.992022275924683


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6215705319953329, Training Loss Force: 2.0584863209075084, time: 1.4750168323516846
Validation Loss Energy: 1.1016328315575592, Validation Loss Force: 2.226161729379716, time: 0.10581207275390625
Test Loss Energy: 13.319322351440112, Test Loss Force: 8.75616762426662, time: 10.733675956726074


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6055070092148047, Training Loss Force: 2.0911270797511174, time: 1.4547829627990723
Validation Loss Energy: 0.84376116884168, Validation Loss Force: 2.332347635016895, time: 0.11009812355041504
Test Loss Energy: 12.49685180330081, Test Loss Force: 8.918464514969989, time: 10.708482265472412


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.569972288317465, Training Loss Force: 2.073649795247288, time: 1.4956541061401367
Validation Loss Energy: 1.008615941047912, Validation Loss Force: 2.143746089074048, time: 0.09999370574951172
Test Loss Energy: 13.248683649619966, Test Loss Force: 8.703783199132788, time: 10.990046262741089


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3978318995457824, Training Loss Force: 2.156380622531872, time: 1.518631935119629
Validation Loss Energy: 4.030777365146241, Validation Loss Force: 2.448226885249175, time: 0.11212563514709473
Test Loss Energy: 16.10128240965415, Test Loss Force: 8.852950076054746, time: 10.699511051177979


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.109762286911025, Training Loss Force: 2.093806482724131, time: 1.4502191543579102
Validation Loss Energy: 2.2669504861999146, Validation Loss Force: 2.201633275606322, time: 0.10574197769165039
Test Loss Energy: 13.550787124487632, Test Loss Force: 8.749821805422, time: 11.06662106513977


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6425634390839559, Training Loss Force: 2.060895967393107, time: 1.4490830898284912
Validation Loss Energy: 2.7183320186759703, Validation Loss Force: 2.2621243551310757, time: 0.09616255760192871
Test Loss Energy: 11.398673232666443, Test Loss Force: 8.69557201440173, time: 10.890066385269165


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9072096282992181, Training Loss Force: 2.065261002138005, time: 1.4814910888671875
Validation Loss Energy: 1.3948219083408286, Validation Loss Force: 2.1639223630557107, time: 0.11460089683532715
Test Loss Energy: 11.890359862427408, Test Loss Force: 8.711474867601222, time: 10.727255821228027


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7297456763905759, Training Loss Force: 2.040745815135982, time: 1.730633020401001
Validation Loss Energy: 3.4122016984168355, Validation Loss Force: 2.2125127787417807, time: 0.10383272171020508
Test Loss Energy: 11.453516335535399, Test Loss Force: 8.746061042459596, time: 9.81775712966919


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.847017886738202, Training Loss Force: 2.0600213828452, time: 1.4183204174041748
Validation Loss Energy: 3.0981578190969747, Validation Loss Force: 2.1697601913890727, time: 0.10376501083374023
Test Loss Energy: 11.34906537753324, Test Loss Force: 8.684364775508968, time: 12.025593996047974


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7778118738384185, Training Loss Force: 2.0705296869372294, time: 1.5214953422546387
Validation Loss Energy: 1.3161666489043022, Validation Loss Force: 2.258199477430379, time: 0.08400344848632812
Test Loss Energy: 13.311761360615163, Test Loss Force: 8.696372452856794, time: 8.898884534835815

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.048 MB uploadedwandb: | 0.039 MB of 0.048 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–‚â–ƒâ–‚â–…â–…â–†â–„â–…â–„â–ƒâ–„â–ˆâ–„â–â–‚â–â–â–„
wandb:   test_error_force â–‚â–ƒâ–â–„â–…â–„â–…â–‚â–„â–‚â–ƒâ–ˆâ–‚â–†â–ƒâ–â–‚â–ƒâ–â–
wandb:          test_loss â–â–…â–„â–†â–†â–ˆâ–ˆâ–†â–…â–…â–†â–‡â–ƒâ–ˆâ–„â–„â–ƒâ–…â–„â–†
wandb: train_error_energy â–ˆâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–â–â–‚â–‚â–‚â–†â–…â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚â–„â–‚â–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–â–â–‚â–‚â–â–â–â–‚â–‚â–„â–ƒâ–â–‚â–â–‚â–‚
wandb: valid_error_energy â–â–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–…â–‚â–„â–‚â–â–â–ˆâ–„â–…â–‚â–‡â–†â–‚
wandb:  valid_error_force â–‚â–‚â–…â–„â–„â–„â–ƒâ–‚â–‡â–â–ƒâ–…â–â–ˆâ–‚â–„â–â–ƒâ–‚â–„
wandb:         valid_loss â–â–‚â–„â–ƒâ–„â–„â–ƒâ–ƒâ–…â–‚â–‚â–„â–â–ˆâ–ƒâ–„â–‚â–„â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 2967
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.31176
wandb:   test_error_force 8.69637
wandb:          test_loss 6.38274
wandb: train_error_energy 1.77781
wandb:  train_error_force 2.07053
wandb:         train_loss -2.32202
wandb: valid_error_energy 1.31617
wandb:  valid_error_force 2.2582
wandb:         valid_loss -2.12272
wandb: 
wandb: ğŸš€ View run al_58_26 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pb4tj147
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_212510-pb4tj147/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.78802490234375, Uncertainty Bias: -5.294196605682373
7.6293945e-06 0.0053081512
-2.0763168 25.428082
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 363 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1006 steps.
Found uncertainty sample 4 after 2466 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1661 steps.
Found uncertainty sample 7 after 2957 steps.
Found uncertainty sample 8 after 1247 steps.
Found uncertainty sample 9 after 3927 steps.
Found uncertainty sample 10 after 1257 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 305 steps.
Found uncertainty sample 13 after 937 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2616 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 330 steps.
Found uncertainty sample 19 after 2457 steps.
Found uncertainty sample 20 after 420 steps.
Found uncertainty sample 21 after 42 steps.
Found uncertainty sample 22 after 1286 steps.
Found uncertainty sample 23 after 2623 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 452 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1824 steps.
Found uncertainty sample 29 after 2684 steps.
Found uncertainty sample 30 after 954 steps.
Found uncertainty sample 31 after 2119 steps.
Found uncertainty sample 32 after 2196 steps.
Found uncertainty sample 33 after 2067 steps.
Found uncertainty sample 34 after 467 steps.
Found uncertainty sample 35 after 2897 steps.
Found uncertainty sample 36 after 1225 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 641 steps.
Found uncertainty sample 39 after 27 steps.
Found uncertainty sample 40 after 1395 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 296 steps.
Found uncertainty sample 44 after 1109 steps.
Found uncertainty sample 45 after 3437 steps.
Found uncertainty sample 46 after 566 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2805 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3634 steps.
Found uncertainty sample 53 after 2335 steps.
Found uncertainty sample 54 after 3420 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1290 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 758 steps.
Found uncertainty sample 59 after 879 steps.
Found uncertainty sample 60 after 3364 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3027 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1865 steps.
Found uncertainty sample 66 after 1100 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1343 steps.
Found uncertainty sample 69 after 132 steps.
Found uncertainty sample 70 after 2378 steps.
Found uncertainty sample 71 after 253 steps.
Found uncertainty sample 72 after 2286 steps.
Found uncertainty sample 73 after 1091 steps.
Found uncertainty sample 74 after 2111 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1918 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 784 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1696 steps.
Found uncertainty sample 81 after 444 steps.
Found uncertainty sample 82 after 1674 steps.
Found uncertainty sample 83 after 1 steps.
Found uncertainty sample 84 after 445 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2630 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2091 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1824 steps.
Found uncertainty sample 93 after 3475 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 32 steps.
Found uncertainty sample 98 after 276 steps.
Found uncertainty sample 99 after 1771 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_215447-p0ha16s3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_27
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p0ha16s3
Training model 27. Added 67 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.4573817244378793, Training Loss Force: 2.2746571063584753, time: 1.4574754238128662
Validation Loss Energy: 1.0159993437568018, Validation Loss Force: 2.2618523647693243, time: 0.10057449340820312
Test Loss Energy: 12.97775769768222, Test Loss Force: 8.697355657214192, time: 10.71070146560669


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.635491434654845, Training Loss Force: 2.065341668188323, time: 1.416870355606079
Validation Loss Energy: 2.782738067124426, Validation Loss Force: 2.2621059849265364, time: 0.09686040878295898
Test Loss Energy: 11.221489475615133, Test Loss Force: 8.621642542398464, time: 10.690230131149292


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0171686850763813, Training Loss Force: 2.066845117370257, time: 1.4022712707519531
Validation Loss Energy: 2.8478674562934287, Validation Loss Force: 2.250638523911255, time: 0.11139273643493652
Test Loss Energy: 11.524509480003578, Test Loss Force: 8.76718422572787, time: 10.922352313995361


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9554989281086024, Training Loss Force: 2.0512491301411853, time: 1.4121203422546387
Validation Loss Energy: 2.198312053960236, Validation Loss Force: 2.15339400916338, time: 0.09527301788330078
Test Loss Energy: 11.7391033649755, Test Loss Force: 8.63674696699424, time: 10.695155382156372


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.912708311209655, Training Loss Force: 2.086286930065448, time: 1.4070842266082764
Validation Loss Energy: 2.2737147295149085, Validation Loss Force: 2.2204384643219344, time: 0.10929703712463379
Test Loss Energy: 11.752940501352729, Test Loss Force: 8.628559098404114, time: 11.01809024810791


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.558574471790547, Training Loss Force: 2.0688683818136435, time: 1.4214239120483398
Validation Loss Energy: 1.258511372287512, Validation Loss Force: 2.1725535758247365, time: 0.10605549812316895
Test Loss Energy: 12.185497285785445, Test Loss Force: 8.677070446724661, time: 10.860553741455078


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.311536869246257, Training Loss Force: 2.0457593594656514, time: 1.5006959438323975
Validation Loss Energy: 2.21868672615092, Validation Loss Force: 2.3642919733608414, time: 0.10307931900024414
Test Loss Energy: 14.08130069679957, Test Loss Force: 8.794547750282403, time: 10.685264348983765


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9437136273965094, Training Loss Force: 2.05888579351381, time: 1.4890110492706299
Validation Loss Energy: 3.0238187227178264, Validation Loss Force: 2.227823509215775, time: 0.0959005355834961
Test Loss Energy: 11.236775565591389, Test Loss Force: 8.678690969815143, time: 10.88222622871399


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8684143300946334, Training Loss Force: 2.034274313447557, time: 1.4543216228485107
Validation Loss Energy: 1.3882172631361782, Validation Loss Force: 2.2025162701044985, time: 0.11086010932922363
Test Loss Energy: 11.789661660624859, Test Loss Force: 8.68789075425861, time: 10.756335020065308


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8701696227683822, Training Loss Force: 2.0712791526839167, time: 1.5254108905792236
Validation Loss Energy: 4.227811057641654, Validation Loss Force: 2.2242337485797004, time: 0.10886526107788086
Test Loss Energy: 11.088790910279391, Test Loss Force: 8.634925985713684, time: 10.977957010269165


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0199899992546015, Training Loss Force: 2.0998044508259706, time: 1.5240745544433594
Validation Loss Energy: 1.1795814504594837, Validation Loss Force: 2.260648392697293, time: 0.10540533065795898
Test Loss Energy: 11.966076129585394, Test Loss Force: 8.734069332005081, time: 11.21549654006958


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6734378543995894, Training Loss Force: 2.061057565386159, time: 1.4820904731750488
Validation Loss Energy: 1.3882222731919616, Validation Loss Force: 2.191558164760527, time: 0.10893678665161133
Test Loss Energy: 11.96326006670525, Test Loss Force: 8.588636987386975, time: 10.621178388595581


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6921418188934054, Training Loss Force: 2.0894618182366016, time: 1.6925547122955322
Validation Loss Energy: 2.3431744768993417, Validation Loss Force: 2.243328184515873, time: 0.10464596748352051
Test Loss Energy: 11.715257747122623, Test Loss Force: 8.679076884590211, time: 10.620092868804932


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8858867361531237, Training Loss Force: 2.052686670427866, time: 1.4961719512939453
Validation Loss Energy: 0.8927789144524285, Validation Loss Force: 2.4161604128786873, time: 0.1148831844329834
Test Loss Energy: 12.988077015959131, Test Loss Force: 8.85087078457523, time: 10.705318450927734


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.5012416460392575, Training Loss Force: 2.0568266008177565, time: 1.458878755569458
Validation Loss Energy: 1.379056877141855, Validation Loss Force: 2.1676810182389716, time: 0.110809326171875
Test Loss Energy: 13.093875147941903, Test Loss Force: 8.606767254846112, time: 10.956151962280273


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4677920875482422, Training Loss Force: 2.0422384223467547, time: 1.4955718517303467
Validation Loss Energy: 0.8246501997214222, Validation Loss Force: 2.1194052340560976, time: 0.10724592208862305
Test Loss Energy: 12.430476672359097, Test Loss Force: 8.662251961954855, time: 10.73036527633667


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3757729300178114, Training Loss Force: 2.0692153753473423, time: 1.5426092147827148
Validation Loss Energy: 1.077390507636682, Validation Loss Force: 2.2658372518048484, time: 0.10152125358581543
Test Loss Energy: 12.9228208126312, Test Loss Force: 8.70620050004421, time: 10.899434804916382


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7341861909132763, Training Loss Force: 2.0623840195517653, time: 1.6109800338745117
Validation Loss Energy: 1.4909302537716076, Validation Loss Force: 2.256774617565587, time: 0.1167457103729248
Test Loss Energy: 13.228409197197864, Test Loss Force: 8.727795779207675, time: 10.794273138046265


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.3753744293018448, Training Loss Force: 2.0460974192788277, time: 1.4657235145568848
Validation Loss Energy: 0.9776913438913852, Validation Loss Force: 2.348633879019199, time: 0.10506248474121094
Test Loss Energy: 12.133114865839737, Test Loss Force: 8.794240079813083, time: 10.762117862701416


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4401817714991203, Training Loss Force: 2.0631603402937855, time: 1.564746618270874
Validation Loss Energy: 1.2264750715862975, Validation Loss Force: 2.20526222601208, time: 0.10979652404785156
Test Loss Energy: 12.319255635011874, Test Loss Force: 8.70348555460407, time: 9.456000804901123

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‚â–ƒâ–ƒâ–„â–ˆâ–â–ƒâ–â–ƒâ–ƒâ–‚â–…â–†â–„â–…â–†â–ƒâ–„
wandb:   test_error_force â–„â–‚â–†â–‚â–‚â–ƒâ–†â–ƒâ–„â–‚â–…â–â–ƒâ–ˆâ–â–ƒâ–„â–…â–†â–„
wandb:          test_loss â–ƒâ–‚â–„â–ƒâ–â–„â–ˆâ–‚â–„â–‚â–ƒâ–â–‚â–ˆâ–„â–…â–‡â–‡â–ˆâ–„
wandb: train_error_energy â–ˆâ–ƒâ–…â–…â–…â–‚â–â–…â–„â–„â–…â–ƒâ–ƒâ–„â–ˆâ–‚â–â–ƒâ–â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–ƒâ–‚â–â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–â–‚
wandb: valid_error_energy â–â–…â–…â–„â–„â–‚â–„â–†â–‚â–ˆâ–‚â–‚â–„â–â–‚â–â–‚â–‚â–â–‚
wandb:  valid_error_force â–„â–„â–„â–‚â–ƒâ–‚â–‡â–„â–ƒâ–ƒâ–„â–ƒâ–„â–ˆâ–‚â–â–„â–„â–†â–ƒ
wandb:         valid_loss â–„â–†â–†â–ƒâ–…â–ƒâ–ˆâ–†â–ƒâ–‡â–„â–ƒâ–…â–ˆâ–ƒâ–â–…â–…â–†â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3027
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.31926
wandb:   test_error_force 8.70349
wandb:          test_loss 6.26173
wandb: train_error_energy 1.44018
wandb:  train_error_force 2.06316
wandb:         train_loss -2.35367
wandb: valid_error_energy 1.22648
wandb:  valid_error_force 2.20526
wandb:         valid_loss -2.19446
wandb: 
wandb: ğŸš€ View run al_58_27 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p0ha16s3
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_215447-p0ha16s3/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 38.35569763183594, Uncertainty Bias: -5.136552333831787
0.00021362305 0.009365082
-1.9912963 28.512987
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1646 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 472 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1270 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 376 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3456 steps.
Found uncertainty sample 10 after 2023 steps.
Found uncertainty sample 11 after 3938 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1066 steps.
Found uncertainty sample 14 after 2655 steps.
Found uncertainty sample 15 after 669 steps.
Found uncertainty sample 16 after 882 steps.
Found uncertainty sample 17 after 2458 steps.
Found uncertainty sample 18 after 1278 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 22 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 78 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 3507 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 898 steps.
Found uncertainty sample 32 after 26 steps.
Found uncertainty sample 33 after 13 steps.
Found uncertainty sample 34 after 861 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 3349 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 625 steps.
Found uncertainty sample 39 after 927 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1124 steps.
Found uncertainty sample 42 after 1844 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1728 steps.
Found uncertainty sample 45 after 1543 steps.
Found uncertainty sample 46 after 2663 steps.
Found uncertainty sample 47 after 1545 steps.
Found uncertainty sample 48 after 873 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1011 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1936 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 655 steps.
Found uncertainty sample 56 after 2295 steps.
Found uncertainty sample 57 after 1364 steps.
Found uncertainty sample 58 after 1800 steps.
Found uncertainty sample 59 after 730 steps.
Found uncertainty sample 60 after 1251 steps.
Found uncertainty sample 61 after 1654 steps.
Found uncertainty sample 62 after 1013 steps.
Found uncertainty sample 63 after 724 steps.
Found uncertainty sample 64 after 1652 steps.
Found uncertainty sample 65 after 1462 steps.
Found uncertainty sample 66 after 1462 steps.
Found uncertainty sample 67 after 2583 steps.
Found uncertainty sample 68 after 3701 steps.
Found uncertainty sample 69 after 615 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3525 steps.
Found uncertainty sample 73 after 2830 steps.
Found uncertainty sample 74 after 673 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 25 steps.
Found uncertainty sample 80 after 833 steps.
Found uncertainty sample 81 after 3934 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1402 steps.
Found uncertainty sample 84 after 1832 steps.
Found uncertainty sample 85 after 1294 steps.
Found uncertainty sample 86 after 626 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3688 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 193 steps.
Found uncertainty sample 94 after 1167 steps.
Found uncertainty sample 95 after 1692 steps.
Found uncertainty sample 96 after 1460 steps.
Found uncertainty sample 97 after 583 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3134 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_222450-o9ua3u8f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_28
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/o9ua3u8f
Training model 28. Added 64 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.1898081671965226, Training Loss Force: 2.1515134339358646, time: 1.430715560913086
Validation Loss Energy: 0.9149011219339975, Validation Loss Force: 2.3519827116393803, time: 0.09587717056274414
Test Loss Energy: 12.45678696485855, Test Loss Force: 8.763119145157217, time: 9.492979764938354


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.3517836657422622, Training Loss Force: 2.063774069330292, time: 1.4079833030700684
Validation Loss Energy: 0.9120493146811706, Validation Loss Force: 2.163075774962893, time: 0.0969705581665039
Test Loss Energy: 12.607353173968395, Test Loss Force: 8.703507038096326, time: 10.083156108856201


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4194299640383339, Training Loss Force: 2.0485920726126796, time: 1.5749008655548096
Validation Loss Energy: 2.2253571144209063, Validation Loss Force: 2.2090400307418907, time: 0.11140727996826172
Test Loss Energy: 11.570336683506161, Test Loss Force: 8.736105773080787, time: 10.961292266845703


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4575814607797577, Training Loss Force: 2.0483202475311195, time: 1.5159974098205566
Validation Loss Energy: 1.8414290246571876, Validation Loss Force: 2.184768314493751, time: 0.11052489280700684
Test Loss Energy: 11.741846089265948, Test Loss Force: 8.753302051892813, time: 10.802332639694214


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4322023124468608, Training Loss Force: 2.0451245217565672, time: 1.5430641174316406
Validation Loss Energy: 1.698396107088311, Validation Loss Force: 2.3860508682971857, time: 0.11263322830200195
Test Loss Energy: 13.53189236273629, Test Loss Force: 8.842966151138727, time: 11.442936182022095


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.621691028795205, Training Loss Force: 2.061989866227358, time: 1.697171926498413
Validation Loss Energy: 3.7030523594968576, Validation Loss Force: 2.3152528793457265, time: 0.10434913635253906
Test Loss Energy: 14.657349078880314, Test Loss Force: 8.721698128040709, time: 10.903566837310791


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6928570973054473, Training Loss Force: 2.052530054507392, time: 1.4989418983459473
Validation Loss Energy: 0.8059906644608897, Validation Loss Force: 2.223100362626928, time: 0.1115415096282959
Test Loss Energy: 12.638666639326422, Test Loss Force: 8.7151146244554, time: 11.094359636306763


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5925057017722442, Training Loss Force: 2.045190624650651, time: 1.5227015018463135
Validation Loss Energy: 2.571623779851696, Validation Loss Force: 2.3272588656904345, time: 0.10954070091247559
Test Loss Energy: 14.254247332802725, Test Loss Force: 8.711773458765261, time: 11.125900030136108


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.032311985297482, Training Loss Force: 2.0531539103264307, time: 1.5031471252441406
Validation Loss Energy: 1.6105434985792373, Validation Loss Force: 2.262054771022973, time: 0.10721302032470703
Test Loss Energy: 11.950128947738756, Test Loss Force: 8.637129556887611, time: 10.95225191116333


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8453217966808222, Training Loss Force: 2.0554031280983787, time: 1.5067017078399658
Validation Loss Energy: 2.244403231152412, Validation Loss Force: 2.156082182427593, time: 0.10735678672790527
Test Loss Energy: 11.697886415387684, Test Loss Force: 8.634418719751505, time: 10.917039394378662


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.005506050265625, Training Loss Force: 2.0587481133630074, time: 1.4933114051818848
Validation Loss Energy: 1.3562793265301774, Validation Loss Force: 2.3367815343851817, time: 0.10775995254516602
Test Loss Energy: 12.9741335346631, Test Loss Force: 8.804943023220025, time: 10.85776972770691


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5290084487484148, Training Loss Force: 2.063897184707966, time: 1.633803129196167
Validation Loss Energy: 1.5235255096963876, Validation Loss Force: 2.2323706358447666, time: 0.1132042407989502
Test Loss Energy: 13.00733942662073, Test Loss Force: 8.745002055980933, time: 10.990200757980347


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.845122443519587, Training Loss Force: 2.1070257833469466, time: 1.644150972366333
Validation Loss Energy: 0.9204740853182782, Validation Loss Force: 2.1745494707142603, time: 0.09938240051269531
Test Loss Energy: 12.760638376200449, Test Loss Force: 8.681867313705013, time: 10.934805870056152


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7554433184570677, Training Loss Force: 2.0666153287801103, time: 1.4550755023956299
Validation Loss Energy: 2.065309546406109, Validation Loss Force: 2.1207160873181747, time: 0.09944558143615723
Test Loss Energy: 11.842351774356029, Test Loss Force: 8.627570526671075, time: 10.995201587677002


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9943806830902415, Training Loss Force: 2.0259710865311775, time: 1.4763147830963135
Validation Loss Energy: 1.3750869646063948, Validation Loss Force: 2.1625625225815295, time: 0.09908652305603027
Test Loss Energy: 13.042373042886874, Test Loss Force: 8.682321712649236, time: 11.18567705154419


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0200489888299833, Training Loss Force: 2.0164293463388585, time: 1.523991346359253
Validation Loss Energy: 3.1072850273885546, Validation Loss Force: 2.233120585528251, time: 0.11013197898864746
Test Loss Energy: 14.928722332328986, Test Loss Force: 8.718020211990277, time: 10.910886526107788


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0454568789863354, Training Loss Force: 2.024064174364371, time: 1.4162673950195312
Validation Loss Energy: 1.5907759894822115, Validation Loss Force: 2.1923696824628607, time: 0.1111452579498291
Test Loss Energy: 13.558715330542618, Test Loss Force: 8.674960158767385, time: 11.509291172027588


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.044318816981499, Training Loss Force: 2.014298268322175, time: 1.4880199432373047
Validation Loss Energy: 2.6851631113639938, Validation Loss Force: 2.150186348781717, time: 0.10239744186401367
Test Loss Energy: 11.447007443601082, Test Loss Force: 8.579406518902035, time: 10.880178689956665


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0591160861783333, Training Loss Force: 2.0200154960618764, time: 1.5594823360443115
Validation Loss Energy: 2.0236487058758845, Validation Loss Force: 2.24956325460557, time: 0.10358595848083496
Test Loss Energy: 11.606810169402825, Test Loss Force: 8.5858127638575, time: 11.035456657409668


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6284538253346406, Training Loss Force: 2.069296300878233, time: 1.5430166721343994
Validation Loss Energy: 1.7395493176331063, Validation Loss Force: 2.1763745783688573, time: 0.1252748966217041
Test Loss Energy: 11.16521538190213, Test Loss Force: 8.669745778977772, time: 11.207491874694824

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–„â–‚â–‚â–…â–‡â–„â–‡â–‚â–‚â–„â–„â–„â–‚â–„â–ˆâ–…â–‚â–‚â–
wandb:   test_error_force â–†â–„â–…â–†â–ˆâ–…â–…â–…â–ƒâ–‚â–‡â–…â–„â–‚â–„â–…â–„â–â–â–ƒ
wandb:          test_loss â–ƒâ–„â–…â–„â–‡â–…â–„â–‡â–‚â–ƒâ–‡â–„â–ƒâ–â–…â–ˆâ–†â–ƒâ–‚â–
wandb: train_error_energy â–ˆâ–â–‚â–‚â–‚â–ƒâ–„â–ƒâ–‡â–…â–†â–‚â–…â–„â–†â–‡â–‡â–‡â–‡â–ƒ
wandb:  train_error_force â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–†â–„â–‚â–â–â–â–â–„
wandb:         train_loss â–ˆâ–‚â–â–â–â–‚â–‚â–â–ƒâ–ƒâ–ƒâ–‚â–…â–ƒâ–‚â–â–‚â–â–â–ƒ
wandb: valid_error_energy â–â–â–„â–„â–ƒâ–ˆâ–â–…â–ƒâ–„â–‚â–ƒâ–â–„â–‚â–‡â–ƒâ–†â–„â–ƒ
wandb:  valid_error_force â–‡â–‚â–ƒâ–ƒâ–ˆâ–†â–„â–†â–…â–‚â–‡â–„â–‚â–â–‚â–„â–ƒâ–‚â–„â–‚
wandb:         valid_loss â–…â–â–„â–ƒâ–‡â–ˆâ–‚â–‡â–„â–ƒâ–†â–ƒâ–â–â–‚â–…â–ƒâ–ƒâ–„â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3084
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.16522
wandb:   test_error_force 8.66975
wandb:          test_loss 6.14026
wandb: train_error_energy 1.62845
wandb:  train_error_force 2.0693
wandb:         train_loss -2.33337
wandb: valid_error_energy 1.73955
wandb:  valid_error_force 2.17637
wandb:         valid_loss -2.19506
wandb: 
wandb: ğŸš€ View run al_58_28 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/o9ua3u8f
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_222450-o9ua3u8f/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 36.27750778198242, Uncertainty Bias: -4.847960472106934
8.201599e-05 0.011417389
-1.5758349 27.097944
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 75 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1595 steps.
Found uncertainty sample 4 after 793 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2215 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 661 steps.
Found uncertainty sample 11 after 3856 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1863 steps.
Found uncertainty sample 14 after 1050 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 40 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2044 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3158 steps.
Found uncertainty sample 23 after 2512 steps.
Found uncertainty sample 24 after 2561 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 1135 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3357 steps.
Found uncertainty sample 34 after 1036 steps.
Found uncertainty sample 35 after 288 steps.
Found uncertainty sample 36 after 1186 steps.
Found uncertainty sample 37 after 94 steps.
Found uncertainty sample 38 after 1108 steps.
Found uncertainty sample 39 after 2563 steps.
Found uncertainty sample 40 after 3741 steps.
Found uncertainty sample 41 after 2166 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 431 steps.
Found uncertainty sample 46 after 363 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1268 steps.
Found uncertainty sample 49 after 1658 steps.
Found uncertainty sample 50 after 769 steps.
Found uncertainty sample 51 after 1101 steps.
Found uncertainty sample 52 after 1453 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3137 steps.
Found uncertainty sample 55 after 1589 steps.
Found uncertainty sample 56 after 341 steps.
Found uncertainty sample 57 after 1151 steps.
Found uncertainty sample 58 after 854 steps.
Found uncertainty sample 59 after 3299 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2991 steps.
Found uncertainty sample 62 after 1091 steps.
Found uncertainty sample 63 after 680 steps.
Found uncertainty sample 64 after 1679 steps.
Found uncertainty sample 65 after 2490 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 106 steps.
Found uncertainty sample 68 after 3963 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1162 steps.
Found uncertainty sample 71 after 1623 steps.
Found uncertainty sample 72 after 2585 steps.
Found uncertainty sample 73 after 1165 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 936 steps.
Found uncertainty sample 76 after 288 steps.
Found uncertainty sample 77 after 439 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1157 steps.
Found uncertainty sample 81 after 291 steps.
Found uncertainty sample 82 after 297 steps.
Found uncertainty sample 83 after 1923 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1604 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 2623 steps.
Found uncertainty sample 90 after 746 steps.
Found uncertainty sample 91 after 2676 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1335 steps.
Found uncertainty sample 95 after 433 steps.
Found uncertainty sample 96 after 2736 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_225540-m9shhnml
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_29
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m9shhnml
Training model 29. Added 61 samples to the dataset.

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3919602920708085, Training Loss Force: 2.2394133100578686, time: 1.4655158519744873
Validation Loss Energy: 1.918261514465149, Validation Loss Force: 2.211460444358126, time: 0.11777424812316895
Test Loss Energy: 11.54809744517267, Test Loss Force: 8.598840517708002, time: 11.135586261749268


Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.516584634081386, Training Loss Force: 2.058334839138322, time: 1.5573086738586426
Validation Loss Energy: 1.7834463130613103, Validation Loss Force: 2.2410505018221776, time: 0.10910677909851074
Test Loss Energy: 11.575979376141522, Test Loss Force: 8.645275573004755, time: 11.147083282470703


Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9067778205317525, Training Loss Force: 2.065979735551686, time: 1.6273176670074463
Validation Loss Energy: 2.7127261002580925, Validation Loss Force: 2.3093856586851027, time: 0.1078023910522461
Test Loss Energy: 14.575408829040555, Test Loss Force: 8.703052876976743, time: 11.158856868743896


Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.1842945757644654, Training Loss Force: 2.084298199878275, time: 1.5968899726867676
Validation Loss Energy: 1.5532855193860686, Validation Loss Force: 2.2791795870288416, time: 0.11974596977233887
Test Loss Energy: 13.744054649339178, Test Loss Force: 8.742548950803494, time: 11.11133861541748


Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5154074014249237, Training Loss Force: 2.0877445121023395, time: 1.603980541229248
Validation Loss Energy: 1.0135542138653688, Validation Loss Force: 2.2141132132281367, time: 0.11083459854125977
Test Loss Energy: 12.076159297285944, Test Loss Force: 8.549258417584076, time: 11.13322639465332


Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9705363802793037, Training Loss Force: 2.0856358589068282, time: 1.5816168785095215
Validation Loss Energy: 1.3613604694383898, Validation Loss Force: 2.2448402193512953, time: 0.10858798027038574
Test Loss Energy: 11.69800945000017, Test Loss Force: 8.51876671096039, time: 10.941915512084961


Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.06272020562953, Training Loss Force: 2.112602461106716, time: 1.5203893184661865
Validation Loss Energy: 1.5826758426262233, Validation Loss Force: 2.1459226799754916, time: 0.11505556106567383
Test Loss Energy: 13.290590976151181, Test Loss Force: 8.553733419228507, time: 11.130306482315063


Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4211890660818214, Training Loss Force: 2.0396670429087056, time: 1.5603532791137695
Validation Loss Energy: 1.8075961736193409, Validation Loss Force: 2.184254171435804, time: 0.1080007553100586
Test Loss Energy: 11.507836723167193, Test Loss Force: 8.57930341959005, time: 10.831201553344727


Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.66053242775931, Training Loss Force: 2.0497715809441033, time: 1.5153312683105469
Validation Loss Energy: 1.122425787738869, Validation Loss Force: 2.249097319417716, time: 0.1178581714630127
Test Loss Energy: 13.139777671906161, Test Loss Force: 8.611229945568128, time: 10.893773555755615


Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.5906958415224812, Training Loss Force: 2.089533448391231, time: 1.5268936157226562
Validation Loss Energy: 3.4771816765889203, Validation Loss Force: 2.1798159300191715, time: 0.11037492752075195
Test Loss Energy: 11.2637889843001, Test Loss Force: 8.585810003226415, time: 11.178492784500122


Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0267490380423228, Training Loss Force: 2.0630191569514045, time: 1.562258243560791
Validation Loss Energy: 1.491676585081471, Validation Loss Force: 2.2983735560732437, time: 0.1076197624206543
Test Loss Energy: 12.20717034759507, Test Loss Force: 8.533809483016306, time: 10.97526478767395


Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6695890018553379, Training Loss Force: 2.068569110066014, time: 1.5442559719085693
Validation Loss Energy: 2.234229700544118, Validation Loss Force: 2.303463884083726, time: 0.10766220092773438
Test Loss Energy: 11.512739174960151, Test Loss Force: 8.669516348150971, time: 11.599486827850342


Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.2703051313197258, Training Loss Force: 2.0353644834741744, time: 1.5545003414154053
Validation Loss Energy: 1.9933817342082123, Validation Loss Force: 2.2417436708734506, time: 0.10882019996643066
Test Loss Energy: 13.724235439905595, Test Loss Force: 8.644810061587764, time: 11.133526802062988


Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9082638756132624, Training Loss Force: 2.0491791381927964, time: 1.4939355850219727
Validation Loss Energy: 1.7865904570690971, Validation Loss Force: 2.183208851130246, time: 0.11507391929626465
Test Loss Energy: 11.478708945502996, Test Loss Force: 8.618836104421298, time: 10.976084232330322


Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.5840915157018582, Training Loss Force: 2.0602832695128304, time: 1.7022497653961182
Validation Loss Energy: 3.6996120098577006, Validation Loss Force: 2.3298601979877356, time: 0.13799333572387695
Test Loss Energy: 15.296273062983403, Test Loss Force: 8.670298837840745, time: 11.12667179107666


Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8584790255169117, Training Loss Force: 2.0430954122730567, time: 1.5039489269256592
Validation Loss Energy: 1.1823522339768362, Validation Loss Force: 2.2395735373772387, time: 0.11085867881774902
Test Loss Energy: 11.992690203421857, Test Loss Force: 8.60223815975471, time: 10.928583860397339


Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.453498005986459, Training Loss Force: 2.118556323681531, time: 1.5417759418487549
Validation Loss Energy: 2.676775053302321, Validation Loss Force: 2.2725303523277187, time: 0.09918022155761719
Test Loss Energy: 14.387079005323836, Test Loss Force: 8.65591873382634, time: 11.069161891937256


Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8275121113824813, Training Loss Force: 2.0562531862636413, time: 1.5612735748291016
Validation Loss Energy: 3.1570750730983104, Validation Loss Force: 2.1195906061200827, time: 0.11390900611877441
Test Loss Energy: 11.17582868873686, Test Loss Force: 8.620028883579872, time: 10.927443742752075


Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.796853256075372, Training Loss Force: 2.0571332500759887, time: 1.5829837322235107
Validation Loss Energy: 0.8061822990946038, Validation Loss Force: 2.162295764944708, time: 0.11010479927062988
Test Loss Energy: 12.213491735787215, Test Loss Force: 8.652142950605946, time: 11.29534387588501


Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.3407735474433786, Training Loss Force: 2.0651673676580673, time: 1.5482146739959717
Validation Loss Energy: 3.7290917347599453, Validation Loss Force: 2.3865407404182273, time: 0.09575414657592773
Test Loss Energy: 15.367024428396547, Test Loss Force: 8.636210341347395, time: 9.636286735534668

wandb: - 0.039 MB of 0.055 MB uploadedwandb: \ 0.039 MB of 0.055 MB uploadedwandb: | 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‡â–…â–ƒâ–‚â–…â–‚â–„â–â–ƒâ–‚â–…â–‚â–ˆâ–‚â–†â–â–ƒâ–ˆ
wandb:   test_error_force â–„â–…â–‡â–ˆâ–‚â–â–‚â–ƒâ–„â–ƒâ–â–†â–…â–„â–†â–„â–…â–„â–…â–…
wandb:          test_loss â–â–„â–ˆâ–‡â–‚â–‚â–ƒâ–ƒâ–…â–‚â–ƒâ–„â–†â–„â–‡â–„â–†â–„â–„â–‡
wandb: train_error_energy â–ˆâ–‚â–…â–†â–‚â–…â–†â–‚â–ƒâ–ƒâ–…â–ƒâ–â–…â–ƒâ–„â–ˆâ–„â–„â–
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–ƒâ–„â–â–â–ƒâ–‚â–‚â–â–â–‚â–â–„â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–„â–ƒâ–ƒâ–„â–â–‚â–ƒâ–ƒâ–‚â–â–‚â–‚â–‚â–…â–‚â–‚â–‚
wandb: valid_error_energy â–„â–ƒâ–†â–ƒâ–â–‚â–ƒâ–ƒâ–‚â–‡â–ƒâ–„â–„â–ƒâ–ˆâ–‚â–…â–‡â–â–ˆ
wandb:  valid_error_force â–ƒâ–„â–†â–…â–ƒâ–„â–‚â–ƒâ–„â–ƒâ–†â–†â–„â–ƒâ–‡â–„â–…â–â–‚â–ˆ
wandb:         valid_loss â–ƒâ–ƒâ–†â–„â–‚â–ƒâ–â–‚â–ƒâ–„â–„â–…â–„â–‚â–‡â–ƒâ–…â–ƒâ–â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3138
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 15.36702
wandb:   test_error_force 8.63621
wandb:          test_loss 6.44123
wandb: train_error_energy 1.34077
wandb:  train_error_force 2.06517
wandb:         train_loss -2.35826
wandb: valid_error_energy 3.72909
wandb:  valid_error_force 2.38654
wandb:         valid_loss -1.80278
wandb: 
wandb: ğŸš€ View run al_58_29 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m9shhnml
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_225540-m9shhnml/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 35.67179870605469, Uncertainty Bias: -4.708547592163086
2.861023e-05 0.19771576
-1.158478 27.276728
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 831 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 994 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2649 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3447 steps.
Found uncertainty sample 14 after 45 steps.
Found uncertainty sample 15 after 1941 steps.
Found uncertainty sample 16 after 2753 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 930 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 655 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 976 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1984 steps.
Found uncertainty sample 30 after 1880 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 758 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 932 steps.
Found uncertainty sample 35 after 1096 steps.
Found uncertainty sample 36 after 605 steps.
Found uncertainty sample 37 after 961 steps.
Found uncertainty sample 38 after 538 steps.
Found uncertainty sample 39 after 451 steps.
Found uncertainty sample 40 after 1154 steps.
Found uncertainty sample 41 after 3228 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1309 steps.
Found uncertainty sample 44 after 298 steps.
Found uncertainty sample 45 after 604 steps.
Found uncertainty sample 46 after 2067 steps.
Found uncertainty sample 47 after 3964 steps.
Found uncertainty sample 48 after 1207 steps.
Found uncertainty sample 49 after 776 steps.
Found uncertainty sample 50 after 1348 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1 steps.
Found uncertainty sample 53 after 458 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 862 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 415 steps.
Found uncertainty sample 60 after 90 steps.
Found uncertainty sample 61 after 3197 steps.
Found uncertainty sample 62 after 1947 steps.
Found uncertainty sample 63 after 5 steps.
Found uncertainty sample 64 after 2669 steps.
Found uncertainty sample 65 after 706 steps.
Found uncertainty sample 66 after 3571 steps.
Found uncertainty sample 67 after 3585 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 73 steps.
Found uncertainty sample 76 after 3444 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3401 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 916 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 827 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2424 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3256 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2606 steps.
Found uncertainty sample 95 after 3501 steps.
Found uncertainty sample 96 after 1410 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1476 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241128_232832-i0porav9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_30
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/i0porav9
Training model 30. Added 53 samples to the dataset.
Epoch 0, Batch 100/100, Loss: 0.05878731608390808, Uncertainty: 0.1396026909351349

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.199236084155315, Training Loss Force: 2.2546601936629953, time: 1.5422968864440918
Validation Loss Energy: 1.3095855509618337, Validation Loss Force: 2.2944275248036843, time: 0.11237740516662598
Test Loss Energy: 11.676445983379395, Test Loss Force: 8.602743364570033, time: 10.755473136901855

Epoch 1, Batch 100/100, Loss: 0.07921621948480606, Uncertainty: 0.13838253915309906

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6230391677762117, Training Loss Force: 2.0745846649045627, time: 1.5710852146148682
Validation Loss Energy: 1.2830949923418102, Validation Loss Force: 2.2751448221046298, time: 0.10502457618713379
Test Loss Energy: 11.621948318464847, Test Loss Force: 8.675331799400974, time: 10.709537506103516

Epoch 2, Batch 100/100, Loss: 0.05329031124711037, Uncertainty: 0.13730253279209137

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.3516012593099231, Training Loss Force: 2.0239824334850356, time: 1.5249607563018799
Validation Loss Energy: 2.9036765830213316, Validation Loss Force: 2.144845963320358, time: 0.11348533630371094
Test Loss Energy: 11.29061544486434, Test Loss Force: 8.472150773705492, time: 10.843574523925781

Epoch 3, Batch 100/100, Loss: 0.079258032143116, Uncertainty: 0.13581402599811554

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0634016125093013, Training Loss Force: 2.0347807291829745, time: 1.5208895206451416
Validation Loss Energy: 2.357584844681777, Validation Loss Force: 2.1878825651686973, time: 0.11590814590454102
Test Loss Energy: 14.303359999734752, Test Loss Force: 8.59522319564463, time: 11.157610416412354

Epoch 4, Batch 100/100, Loss: 0.16754232347011566, Uncertainty: 0.13584379851818085

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.786456775420648, Training Loss Force: 2.063703600858391, time: 1.5591955184936523
Validation Loss Energy: 4.363619196434471, Validation Loss Force: 2.213092943201495, time: 0.10324406623840332
Test Loss Energy: 15.710924827868096, Test Loss Force: 8.628470884116501, time: 10.866822957992554

Epoch 5, Batch 100/100, Loss: 0.10408804565668106, Uncertainty: 0.13582557439804077

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9864526862215695, Training Loss Force: 2.0698324399519485, time: 1.5547165870666504
Validation Loss Energy: 2.0077189551762107, Validation Loss Force: 2.2571490357344652, time: 0.10724472999572754
Test Loss Energy: 13.846915260000445, Test Loss Force: 8.658918858986251, time: 10.663644313812256

Epoch 6, Batch 100/100, Loss: 0.08995991945266724, Uncertainty: 0.1336459070444107

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5355951577065883, Training Loss Force: 2.002562296253848, time: 1.5771687030792236
Validation Loss Energy: 0.9426676304274738, Validation Loss Force: 2.167939314448248, time: 0.11080360412597656
Test Loss Energy: 11.964700766390385, Test Loss Force: 8.477595768781866, time: 10.527335405349731

Epoch 7, Batch 100/100, Loss: 0.07107383757829666, Uncertainty: 0.1382591873407364

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5109142434823228, Training Loss Force: 2.057036398983884, time: 1.6628084182739258
Validation Loss Energy: 2.9284479688329332, Validation Loss Force: 2.3111090065400104, time: 0.0988774299621582
Test Loss Energy: 11.132902129747276, Test Loss Force: 8.5953283934093, time: 10.723394393920898

Epoch 8, Batch 100/100, Loss: 0.06142415106296539, Uncertainty: 0.13789746165275574

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.5818928961586767, Training Loss Force: 2.068491942746475, time: 1.551417350769043
Validation Loss Energy: 0.7851786700676031, Validation Loss Force: 2.199040070732847, time: 0.11546730995178223
Test Loss Energy: 12.262347925168964, Test Loss Force: 8.563141407484068, time: 9.730026245117188

Epoch 9, Batch 100/100, Loss: 0.10428399592638016, Uncertainty: 0.13720357418060303

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2676968703937006, Training Loss Force: 2.048210054562207, time: 1.5587029457092285
Validation Loss Energy: 1.6590071041867014, Validation Loss Force: 2.2659392342736835, time: 0.09693503379821777
Test Loss Energy: 11.790604887127007, Test Loss Force: 8.49021897826069, time: 8.761934995651245

Epoch 10, Batch 100/100, Loss: 0.02958955056965351, Uncertainty: 0.13817596435546875

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3653250398627026, Training Loss Force: 2.0422883501016114, time: 1.4907400608062744
Validation Loss Energy: 2.486819344948514, Validation Loss Force: 2.2435642138105565, time: 0.09516024589538574
Test Loss Energy: 13.59496346593715, Test Loss Force: 8.751994645922176, time: 8.488701581954956

Epoch 11, Batch 100/100, Loss: 0.21585525572299957, Uncertainty: 0.13707391917705536

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.011843939514951, Training Loss Force: 2.071241180797267, time: 1.543748140335083
Validation Loss Energy: 1.5914470029534646, Validation Loss Force: 2.143430900897987, time: 0.08915185928344727
Test Loss Energy: 11.646786826200067, Test Loss Force: 8.461911154661523, time: 8.574591875076294

Epoch 12, Batch 100/100, Loss: 0.09481115639209747, Uncertainty: 0.13892953097820282

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7428175857729267, Training Loss Force: 2.076552739510994, time: 1.4966933727264404
Validation Loss Energy: 1.538491771001632, Validation Loss Force: 2.1772396480007865, time: 0.09595298767089844
Test Loss Energy: 13.475659016311187, Test Loss Force: 8.590357560038207, time: 8.650110960006714

Epoch 13, Batch 100/100, Loss: 0.036044102162122726, Uncertainty: 0.136197030544281

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.4551288805623466, Training Loss Force: 2.023786552550709, time: 1.519953966140747
Validation Loss Energy: 1.7745370421963071, Validation Loss Force: 2.1673333203676055, time: 0.09087944030761719
Test Loss Energy: 11.487408822558365, Test Loss Force: 8.4308628218053, time: 8.611807823181152

Epoch 14, Batch 100/100, Loss: 0.034490615129470825, Uncertainty: 0.13719934225082397

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7419750391251074, Training Loss Force: 2.0323148532072155, time: 1.5195305347442627
Validation Loss Energy: 1.8383556337705191, Validation Loss Force: 2.2317191059237818, time: 0.08954071998596191
Test Loss Energy: 13.089101718346422, Test Loss Force: 8.6212426985608, time: 8.618693590164185

Epoch 15, Batch 100/100, Loss: 0.1663246750831604, Uncertainty: 0.1353088766336441

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0377345779119596, Training Loss Force: 2.01701787811971, time: 1.5205636024475098
Validation Loss Energy: 1.769585659732884, Validation Loss Force: 2.183526600001485, time: 0.0908510684967041
Test Loss Energy: 11.641119078039658, Test Loss Force: 8.484104630405202, time: 9.26820683479309

Epoch 16, Batch 100/100, Loss: 0.0221227016299963, Uncertainty: 0.1356119066476822

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5997496866028882, Training Loss Force: 2.040525963892039, time: 1.4839849472045898
Validation Loss Energy: 1.5763640630157543, Validation Loss Force: 2.173195864976165, time: 0.09093284606933594
Test Loss Energy: 11.549807012605385, Test Loss Force: 8.64969313300438, time: 8.53408670425415

Epoch 17, Batch 100/100, Loss: 0.2333858162164688, Uncertainty: 0.13607506453990936

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6926128716628022, Training Loss Force: 2.0386798785772045, time: 1.5351521968841553
Validation Loss Energy: 1.3145897616801283, Validation Loss Force: 2.2037590979424944, time: 0.0938575267791748
Test Loss Energy: 12.97745210701267, Test Loss Force: 8.523325785945802, time: 8.45658016204834

Epoch 18, Batch 100/100, Loss: 0.25315865874290466, Uncertainty: 0.13812769949436188

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2578168383166344, Training Loss Force: 2.102377143300529, time: 1.550041675567627
Validation Loss Energy: 5.803327975891726, Validation Loss Force: 2.158090101450997, time: 0.09124398231506348
Test Loss Energy: 10.664930538123501, Test Loss Force: 8.529349585567973, time: 8.693395614624023

Epoch 19, Batch 100/100, Loss: 0.07104198634624481, Uncertainty: 0.13712061941623688

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9056164470747328, Training Loss Force: 2.03415243144733, time: 1.4990694522857666
Validation Loss Energy: 2.21158870178618, Validation Loss Force: 2.129887606769794, time: 0.09330034255981445
Test Loss Energy: 13.512771564988277, Test Loss Force: 8.542173850130077, time: 9.682221412658691

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–†â–ˆâ–…â–ƒâ–‚â–ƒâ–ƒâ–…â–‚â–…â–‚â–„â–‚â–‚â–„â–â–…
wandb:   test_error_force â–…â–†â–‚â–…â–…â–†â–‚â–…â–„â–‚â–ˆâ–‚â–„â–â–…â–‚â–†â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–‚â–„â–â–‡â–ˆâ–‡â–…â–„â–ƒâ–‚â–‡â–‚â–…â–‚â–‡â–„â–†â–„â–â–…
wandb: train_error_energy â–‡â–ƒâ–â–†â–„â–†â–‚â–‚â–ƒâ–ˆâ–â–†â–„â–‚â–„â–†â–ƒâ–„â–ˆâ–…
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–„â–‚
wandb:         train_loss â–ˆâ–ƒâ–â–‚â–ƒâ–ƒâ–â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–„â–‚
wandb: valid_error_energy â–‚â–‚â–„â–ƒâ–†â–ƒâ–â–„â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ˆâ–ƒ
wandb:  valid_error_force â–‡â–‡â–‚â–ƒâ–„â–†â–‚â–ˆâ–„â–†â–…â–‚â–ƒâ–‚â–…â–ƒâ–ƒâ–„â–‚â–
wandb:         valid_loss â–…â–„â–ƒâ–„â–‡â–…â–â–ˆâ–â–…â–…â–â–‚â–‚â–„â–ƒâ–‚â–‚â–ˆâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3185
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.51277
wandb:   test_error_force 8.54217
wandb:          test_loss 6.25416
wandb: train_error_energy 1.90562
wandb:  train_error_force 2.03415
wandb:         train_loss -2.35783
wandb: valid_error_energy 2.21159
wandb:  valid_error_force 2.12989
wandb:         valid_loss -2.21945
wandb: 
wandb: ğŸš€ View run al_58_30 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/i0porav9
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241128_232832-i0porav9/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.830745697021484, Uncertainty Bias: -5.4337029457092285
9.727478e-05 0.010430336
-1.6063246 22.818628
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3204 steps.
Found uncertainty sample 1 after 1498 steps.
Found uncertainty sample 2 after 774 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2768 steps.
Found uncertainty sample 5 after 1 steps.
Found uncertainty sample 6 after 483 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3545 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1342 steps.
Found uncertainty sample 12 after 307 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1576 steps.
Found uncertainty sample 15 after 2993 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2040 steps.
Found uncertainty sample 18 after 187 steps.
Found uncertainty sample 19 after 2250 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3558 steps.
Found uncertainty sample 22 after 1143 steps.
Found uncertainty sample 23 after 3774 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3238 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3582 steps.
Found uncertainty sample 29 after 2973 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1290 steps.
Found uncertainty sample 32 after 2759 steps.
Found uncertainty sample 33 after 2433 steps.
Found uncertainty sample 34 after 1989 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 3450 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2374 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2482 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3141 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1395 steps.
Found uncertainty sample 49 after 20 steps.
Found uncertainty sample 50 after 495 steps.
Found uncertainty sample 51 after 2218 steps.
Found uncertainty sample 52 after 1106 steps.
Found uncertainty sample 53 after 953 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1373 steps.
Found uncertainty sample 56 after 1152 steps.
Found uncertainty sample 57 after 642 steps.
Found uncertainty sample 58 after 468 steps.
Found uncertainty sample 59 after 2512 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1424 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1299 steps.
Found uncertainty sample 66 after 2556 steps.
Found uncertainty sample 67 after 2652 steps.
Found uncertainty sample 68 after 2596 steps.
Found uncertainty sample 69 after 461 steps.
Found uncertainty sample 70 after 359 steps.
Found uncertainty sample 71 after 961 steps.
Found uncertainty sample 72 after 2087 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3699 steps.
Found uncertainty sample 76 after 334 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 950 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2017 steps.
Found uncertainty sample 81 after 1589 steps.
Found uncertainty sample 82 after 2566 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1329 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 980 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 743 steps.
Found uncertainty sample 90 after 79 steps.
Found uncertainty sample 91 after 726 steps.
Found uncertainty sample 92 after 76 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_000007-v49fz012
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_31
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v49fz012
Training model 31. Added 61 samples to the dataset.
Epoch 0, Batch 100/102, Loss: 0.14810651540756226, Uncertainty: 0.13938623666763306

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.413744065920056, Training Loss Force: 2.251273313260225, time: 1.497974157333374
Validation Loss Energy: 0.9624000969676592, Validation Loss Force: 2.20063026243849, time: 0.09871220588684082
Test Loss Energy: 12.830945746331452, Test Loss Force: 8.471106690904113, time: 9.815625429153442

Epoch 1, Batch 100/102, Loss: 0.05361941084265709, Uncertainty: 0.13795149326324463

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6799726338679246, Training Loss Force: 2.072759506996596, time: 1.6538479328155518
Validation Loss Energy: 1.721590216004733, Validation Loss Force: 2.2752218656291205, time: 0.11005902290344238
Test Loss Energy: 11.419013618471883, Test Loss Force: 8.48139258782461, time: 10.528661251068115

Epoch 2, Batch 100/102, Loss: 0.19966402649879456, Uncertainty: 0.1381194144487381

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6945288171954802, Training Loss Force: 2.051122071530262, time: 1.5158796310424805
Validation Loss Energy: 1.717489095675035, Validation Loss Force: 2.2073265916639766, time: 0.09071660041809082
Test Loss Energy: 13.255592133577625, Test Loss Force: 8.486911308538618, time: 8.632433891296387

Epoch 3, Batch 100/102, Loss: 0.04288475960493088, Uncertainty: 0.13654151558876038

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.019355022578607, Training Loss Force: 2.035702594466368, time: 1.5614612102508545
Validation Loss Energy: 0.8093641855226255, Validation Loss Force: 2.3283147627804235, time: 0.09180235862731934
Test Loss Energy: 12.081922515717023, Test Loss Force: 8.4586971645305, time: 8.491104364395142

Epoch 4, Batch 100/102, Loss: 0.055093467235565186, Uncertainty: 0.13666197657585144

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.763350614748042, Training Loss Force: 2.0683604837290477, time: 1.6216599941253662
Validation Loss Energy: 0.7973045637473926, Validation Loss Force: 2.1720877519714556, time: 0.09109878540039062
Test Loss Energy: 12.097736907477808, Test Loss Force: 8.501504433479832, time: 8.521569728851318

Epoch 5, Batch 100/102, Loss: 0.09682634472846985, Uncertainty: 0.13715754449367523

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7172907536790574, Training Loss Force: 2.0587313988298237, time: 1.4995768070220947
Validation Loss Energy: 5.4750134536785, Validation Loss Force: 2.345936130981711, time: 0.09276700019836426
Test Loss Energy: 16.51382900680612, Test Loss Force: 8.536674150723844, time: 8.727825164794922

Epoch 6, Batch 100/102, Loss: 0.1490950882434845, Uncertainty: 0.1371382772922516

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0062140070046603, Training Loss Force: 2.0710180694566116, time: 1.5585668087005615
Validation Loss Energy: 1.8335648514285965, Validation Loss Force: 2.1057581761059025, time: 0.09736466407775879
Test Loss Energy: 13.126509113615313, Test Loss Force: 8.479233021203466, time: 8.528668403625488

Epoch 7, Batch 100/102, Loss: 0.056694336235523224, Uncertainty: 0.13666819036006927

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.3009342401193567, Training Loss Force: 2.05004281819329, time: 1.556861400604248
Validation Loss Energy: 1.1048344242049954, Validation Loss Force: 2.2545675209911513, time: 0.09071540832519531
Test Loss Energy: 12.597873106194747, Test Loss Force: 8.479865518158608, time: 8.495551347732544

Epoch 8, Batch 100/102, Loss: 0.09847037494182587, Uncertainty: 0.13677054643630981

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4353975789747393, Training Loss Force: 2.047027266708792, time: 1.4989879131317139
Validation Loss Energy: 1.6217210443665202, Validation Loss Force: 2.2774097013224344, time: 0.09422922134399414
Test Loss Energy: 12.600385634888976, Test Loss Force: 8.708281274430288, time: 9.167864322662354

Epoch 9, Batch 100/102, Loss: 0.06648081541061401, Uncertainty: 0.13622277975082397

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.375239210268861, Training Loss Force: 2.053671392026228, time: 1.5708301067352295
Validation Loss Energy: 2.5979061984875633, Validation Loss Force: 2.2795318496176993, time: 0.09751725196838379
Test Loss Energy: 13.753255431713477, Test Loss Force: 8.596718082041301, time: 8.47233772277832

Epoch 10, Batch 100/102, Loss: 0.14998510479927063, Uncertainty: 0.13624435663223267

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7897627419817161, Training Loss Force: 2.049397587407801, time: 1.590627908706665
Validation Loss Energy: 2.4677898170683794, Validation Loss Force: 2.1758307089799285, time: 0.09478068351745605
Test Loss Energy: 13.51847410083096, Test Loss Force: 8.591866715913127, time: 8.505555391311646

Epoch 11, Batch 100/102, Loss: 0.12548941373825073, Uncertainty: 0.13440942764282227

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0300658325514744, Training Loss Force: 2.025436550285517, time: 1.570483922958374
Validation Loss Energy: 0.8571793507435046, Validation Loss Force: 2.1622396523199345, time: 0.09682893753051758
Test Loss Energy: 12.316320165510774, Test Loss Force: 8.467533340750933, time: 8.733036756515503

Epoch 12, Batch 100/102, Loss: 0.18524819612503052, Uncertainty: 0.1357254683971405

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.971052472254574, Training Loss Force: 2.048806759933936, time: 1.5762228965759277
Validation Loss Energy: 2.0875195690321036, Validation Loss Force: 2.129967878996901, time: 0.09321379661560059
Test Loss Energy: 13.670672290582942, Test Loss Force: 8.496832200599233, time: 9.203455924987793

Epoch 13, Batch 100/102, Loss: 0.10558521747589111, Uncertainty: 0.13579925894737244

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9028309192251738, Training Loss Force: 2.0710401584541906, time: 1.5394489765167236
Validation Loss Energy: 3.2447124162105583, Validation Loss Force: 2.217229356590823, time: 0.10602807998657227
Test Loss Energy: 14.51675027753225, Test Loss Force: 8.527380481507286, time: 11.61270546913147

Epoch 14, Batch 100/102, Loss: 0.11230001598596573, Uncertainty: 0.13722315430641174

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.715905738493202, Training Loss Force: 2.0625058722545693, time: 1.6280996799468994
Validation Loss Energy: 1.5327503027411704, Validation Loss Force: 2.1890482381476293, time: 0.11310219764709473
Test Loss Energy: 11.802852748705837, Test Loss Force: 8.471215262514377, time: 10.31618356704712

Epoch 15, Batch 100/102, Loss: 0.12777535617351532, Uncertainty: 0.13860425353050232

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4176579428945328, Training Loss Force: 2.092014498302137, time: 1.4905755519866943
Validation Loss Energy: 1.776958012485407, Validation Loss Force: 2.152311837114171, time: 0.09985136985778809
Test Loss Energy: 13.618486570265388, Test Loss Force: 8.471343739114156, time: 9.373806715011597

Epoch 16, Batch 100/102, Loss: 0.15814423561096191, Uncertainty: 0.13698440790176392

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.363300866988982, Training Loss Force: 2.0439029053264983, time: 1.5040616989135742
Validation Loss Energy: 4.803144042228164, Validation Loss Force: 2.325335226938764, time: 0.10304522514343262
Test Loss Energy: 10.898547861965353, Test Loss Force: 8.614038640547738, time: 9.552388191223145

Epoch 17, Batch 100/102, Loss: 0.16560044884681702, Uncertainty: 0.13421928882598877

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6805783430630423, Training Loss Force: 2.0446649304450886, time: 1.4889485836029053
Validation Loss Energy: 1.4923595113520316, Validation Loss Force: 2.1440272088707815, time: 0.09942507743835449
Test Loss Energy: 12.82411564657639, Test Loss Force: 8.37467347993298, time: 9.437294483184814

Epoch 18, Batch 100/102, Loss: 0.09925300627946854, Uncertainty: 0.13519304990768433

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.4560260492396493, Training Loss Force: 2.017660240773787, time: 1.5449330806732178
Validation Loss Energy: 1.438167630631002, Validation Loss Force: 2.2339587121935236, time: 0.10586929321289062
Test Loss Energy: 11.451448786064455, Test Loss Force: 8.390671640190156, time: 9.395373821258545

Epoch 19, Batch 100/102, Loss: 0.12620316445827484, Uncertainty: 0.13620209693908691

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5925558609174493, Training Loss Force: 2.037693412717667, time: 1.5081958770751953
Validation Loss Energy: 1.9169122507753995, Validation Loss Force: 2.194735319469198, time: 0.10360336303710938
Test Loss Energy: 11.313768918410341, Test Loss Force: 8.520093609224851, time: 9.589747667312622

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–„â–‚â–‚â–ˆâ–„â–ƒâ–ƒâ–…â–„â–ƒâ–„â–†â–‚â–„â–â–ƒâ–‚â–‚
wandb:   test_error_force â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–ƒâ–ƒâ–ˆâ–†â–†â–ƒâ–„â–„â–ƒâ–ƒâ–†â–â–â–„
wandb:          test_loss â–â–â–ƒâ–‚â–ƒâ–ˆâ–„â–ƒâ–‡â–‡â–‡â–„â–†â–†â–‚â–‚â–„â–ƒâ–‚â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–…â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚
wandb: valid_error_energy â–â–‚â–‚â–â–â–ˆâ–ƒâ–â–‚â–„â–ƒâ–â–ƒâ–…â–‚â–‚â–‡â–‚â–‚â–ƒ
wandb:  valid_error_force â–„â–†â–„â–‡â–ƒâ–ˆâ–â–…â–†â–†â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–‡â–‚â–…â–„
wandb:         valid_loss â–‚â–„â–ƒâ–„â–â–ˆâ–â–ƒâ–„â–„â–ƒâ–â–‚â–„â–‚â–‚â–‡â–â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3239
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.31377
wandb:   test_error_force 8.52009
wandb:          test_loss 6.09403
wandb: train_error_energy 1.59256
wandb:  train_error_force 2.03769
wandb:         train_loss -2.37459
wandb: valid_error_energy 1.91691
wandb:  valid_error_force 2.19474
wandb:         valid_loss -2.15838
wandb: 
wandb: ğŸš€ View run al_58_31 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v49fz012
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_000007-v49fz012/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 36.285728454589844, Uncertainty Bias: -4.778897762298584
5.5909157e-05 0.040812254
-1.1310595 25.767294
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 554 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 604 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 821 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2491 steps.
Found uncertainty sample 7 after 932 steps.
Found uncertainty sample 8 after 3008 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 18 steps.
Found uncertainty sample 17 after 3462 steps.
Found uncertainty sample 18 after 376 steps.
Found uncertainty sample 19 after 342 steps.
Found uncertainty sample 20 after 320 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 141 steps.
Found uncertainty sample 24 after 1063 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 713 steps.
Found uncertainty sample 27 after 1444 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3983 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 3752 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3828 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3463 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 5 steps.
Found uncertainty sample 47 after 2004 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 439 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 52 steps.
Found uncertainty sample 52 after 3682 steps.
Found uncertainty sample 53 after 2420 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2638 steps.
Found uncertainty sample 58 after 3001 steps.
Found uncertainty sample 59 after 3926 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1514 steps.
Found uncertainty sample 62 after 3839 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1687 steps.
Found uncertainty sample 65 after 868 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2956 steps.
Found uncertainty sample 69 after 3516 steps.
Found uncertainty sample 70 after 3494 steps.
Found uncertainty sample 71 after 1450 steps.
Found uncertainty sample 72 after 1667 steps.
Found uncertainty sample 73 after 786 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2741 steps.
Found uncertainty sample 77 after 16 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1145 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3292 steps.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3608 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3776 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3579 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1497 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_003537-kp0pi5vt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_32
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kp0pi5vt
Training model 32. Added 46 samples to the dataset.
Epoch 0, Batch 100/103, Loss: 0.1087484359741211, Uncertainty: 0.13872423768043518

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.768693828791454, Training Loss Force: 2.1778104138768906, time: 1.562974214553833
Validation Loss Energy: 2.162307900413161, Validation Loss Force: 2.160825146570428, time: 0.09990143775939941
Test Loss Energy: 11.303509308107133, Test Loss Force: 8.376442277358507, time: 9.31386399269104

Epoch 1, Batch 100/103, Loss: 0.08197073638439178, Uncertainty: 0.13923993706703186

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.888328949158392, Training Loss Force: 2.0797930523556363, time: 1.5104260444641113
Validation Loss Energy: 1.0566643521991506, Validation Loss Force: 2.136480283507851, time: 0.10662293434143066
Test Loss Energy: 12.182378094420235, Test Loss Force: 8.476751558935424, time: 9.330982208251953

Epoch 2, Batch 100/103, Loss: 0.09937542676925659, Uncertainty: 0.13610169291496277

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5654325563659985, Training Loss Force: 2.0413234260369038, time: 1.5206990242004395
Validation Loss Energy: 1.1438381538168634, Validation Loss Force: 2.141919534070002, time: 0.10071635246276855
Test Loss Energy: 12.415780989040368, Test Loss Force: 8.427178866874364, time: 10.0518319606781

Epoch 3, Batch 100/103, Loss: 0.07058566808700562, Uncertainty: 0.13566787540912628

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.771667259003849, Training Loss Force: 2.037174452378277, time: 1.5785808563232422
Validation Loss Energy: 1.9731853086688431, Validation Loss Force: 2.181997753645545, time: 0.10327768325805664
Test Loss Energy: 13.271481370150811, Test Loss Force: 8.472405430265168, time: 9.370087623596191

Epoch 4, Batch 100/103, Loss: 0.06655605882406235, Uncertainty: 0.13732990622520447

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2977209609073883, Training Loss Force: 2.096346621476809, time: 1.5766026973724365
Validation Loss Energy: 0.830889194354816, Validation Loss Force: 2.166363373567944, time: 0.1005403995513916
Test Loss Energy: 11.697566000315728, Test Loss Force: 8.365709829706828, time: 9.375014305114746

Epoch 5, Batch 100/103, Loss: 0.08078354597091675, Uncertainty: 0.13875412940979004

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6808309212310208, Training Loss Force: 2.0447622526623395, time: 1.582320213317871
Validation Loss Energy: 0.8015651151855749, Validation Loss Force: 2.1999107070934243, time: 0.10349464416503906
Test Loss Energy: 12.061362739015072, Test Loss Force: 8.360459412489783, time: 9.478629112243652

Epoch 6, Batch 100/103, Loss: 0.137020081281662, Uncertainty: 0.13536499440670013

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.945108313452948, Training Loss Force: 2.0353674274039815, time: 1.550048589706421
Validation Loss Energy: 1.8768308581645274, Validation Loss Force: 2.1591524559462183, time: 0.10456323623657227
Test Loss Energy: 11.14236911250263, Test Loss Force: 8.40335805739544, time: 9.474053621292114

Epoch 7, Batch 100/103, Loss: 0.03929755091667175, Uncertainty: 0.13637204468250275

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6986377095971514, Training Loss Force: 2.0360696480641285, time: 1.5755279064178467
Validation Loss Energy: 1.4160320908343207, Validation Loss Force: 2.094892367122918, time: 0.10009765625
Test Loss Energy: 12.62295568263005, Test Loss Force: 8.318190781370259, time: 9.530144691467285

Epoch 8, Batch 100/103, Loss: 0.048490919172763824, Uncertainty: 0.13487887382507324

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8497592092783643, Training Loss Force: 2.031150411026583, time: 1.487973690032959
Validation Loss Energy: 1.1447437492333519, Validation Loss Force: 2.1258257875443523, time: 0.1025841236114502
Test Loss Energy: 12.574115655997202, Test Loss Force: 8.485337765140505, time: 9.399406671524048

Epoch 9, Batch 100/103, Loss: 0.06873057037591934, Uncertainty: 0.13535550236701965

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.593221877637751, Training Loss Force: 2.0135929477892582, time: 1.5439889430999756
Validation Loss Energy: 1.3850978354035892, Validation Loss Force: 2.099814245924506, time: 0.09994363784790039
Test Loss Energy: 11.343965554607271, Test Loss Force: 8.405057447332636, time: 9.341479301452637

Epoch 10, Batch 100/103, Loss: 0.13213951885700226, Uncertainty: 0.1364225596189499

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7917078442449417, Training Loss Force: 2.0589067567272914, time: 1.5438690185546875
Validation Loss Energy: 2.5578334343060964, Validation Loss Force: 2.1437558865164688, time: 0.1083989143371582
Test Loss Energy: 13.713610451684257, Test Loss Force: 8.391583392233658, time: 9.545462131500244

Epoch 11, Batch 100/103, Loss: 0.06200331822037697, Uncertainty: 0.13721077144145966

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6275571097223238, Training Loss Force: 2.0441793913117547, time: 1.5273432731628418
Validation Loss Energy: 1.598857710466374, Validation Loss Force: 2.266457051372538, time: 0.09824657440185547
Test Loss Energy: 12.79091686604174, Test Loss Force: 8.567618913282034, time: 9.3580002784729

Epoch 12, Batch 100/103, Loss: 0.05804741382598877, Uncertainty: 0.13520783185958862

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6672256261762457, Training Loss Force: 2.049820516315808, time: 1.5068011283874512
Validation Loss Energy: 0.8082650071173961, Validation Loss Force: 2.1919961549705675, time: 0.10122513771057129
Test Loss Energy: 11.672196756590864, Test Loss Force: 8.364803864729506, time: 9.314893245697021

Epoch 13, Batch 100/103, Loss: 0.17065481841564178, Uncertainty: 0.1396363079547882

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.573488527717179, Training Loss Force: 2.0738904608092734, time: 1.5761499404907227
Validation Loss Energy: 1.108949127352595, Validation Loss Force: 2.1544427808407, time: 0.10119152069091797
Test Loss Energy: 12.42565163481727, Test Loss Force: 8.357285267312005, time: 9.562501907348633

Epoch 14, Batch 100/103, Loss: 0.15121889114379883, Uncertainty: 0.1367044448852539

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.582898088052223, Training Loss Force: 2.023347765282409, time: 1.5284008979797363
Validation Loss Energy: 1.1439842247765921, Validation Loss Force: 2.1496742097460837, time: 0.10413050651550293
Test Loss Energy: 12.345426226521298, Test Loss Force: 8.408032442355847, time: 9.343523263931274

Epoch 15, Batch 100/103, Loss: 0.08583301305770874, Uncertainty: 0.1355016678571701

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.061003074320711, Training Loss Force: 2.0387815539679925, time: 1.5498476028442383
Validation Loss Energy: 2.0705492854135086, Validation Loss Force: 2.2911158779308733, time: 0.11211276054382324
Test Loss Energy: 10.832098837509792, Test Loss Force: 8.509331955775037, time: 9.352682113647461

Epoch 16, Batch 100/103, Loss: 0.17806755006313324, Uncertainty: 0.13511857390403748

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0614485444845845, Training Loss Force: 2.0216415002584824, time: 1.5740666389465332
Validation Loss Energy: 1.9909089933426842, Validation Loss Force: 2.0837420983060113, time: 0.10205769538879395
Test Loss Energy: 11.306622749711991, Test Loss Force: 8.300668827364882, time: 10.021615266799927

Epoch 17, Batch 100/103, Loss: 0.06443202495574951, Uncertainty: 0.13550908863544464

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.101146023600791, Training Loss Force: 2.018684148100715, time: 1.509626865386963
Validation Loss Energy: 1.9384980204507853, Validation Loss Force: 2.175610600529179, time: 0.10196757316589355
Test Loss Energy: 13.051061495033185, Test Loss Force: 8.428692737272984, time: 9.337990760803223

Epoch 18, Batch 100/103, Loss: 0.16900445520877838, Uncertainty: 0.1377987265586853

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9261995068392879, Training Loss Force: 2.0296026323886482, time: 1.5140016078948975
Validation Loss Energy: 2.927488710152276, Validation Loss Force: 2.199002662316331, time: 0.10096859931945801
Test Loss Energy: 11.005536931131568, Test Loss Force: 8.342073245720657, time: 9.52883529663086

Epoch 19, Batch 100/103, Loss: 0.05353114753961563, Uncertainty: 0.13579922914505005

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9319504407002877, Training Loss Force: 2.0407063752441554, time: 1.5454118251800537
Validation Loss Energy: 2.4063657538221888, Validation Loss Force: 2.1440639492798597, time: 0.1001729965209961
Test Loss Energy: 11.507019720925605, Test Loss Force: 8.316453819803563, time: 9.524271488189697

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–…â–‡â–ƒâ–„â–‚â–…â–…â–‚â–ˆâ–†â–ƒâ–…â–…â–â–‚â–†â–â–ƒ
wandb:   test_error_force â–ƒâ–†â–„â–†â–ƒâ–ƒâ–„â–â–†â–„â–ƒâ–ˆâ–ƒâ–‚â–„â–†â–â–„â–‚â–
wandb:          test_loss â–â–ƒâ–…â–ˆâ–ƒâ–‚â–„â–ƒâ–‡â–…â–†â–‡â–„â–ƒâ–„â–†â–‚â–‡â–‚â–‚
wandb: train_error_energy â–ˆâ–‚â–â–‚â–ƒâ–â–‚â–â–‚â–â–‚â–â–â–â–â–ƒâ–ƒâ–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–„â–‚â–‚â–…â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–ƒâ–„â–â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–…â–‚â–‚â–…â–â–â–…â–ƒâ–‚â–ƒâ–‡â–„â–â–‚â–‚â–…â–…â–…â–ˆâ–†
wandb:  valid_error_force â–„â–ƒâ–ƒâ–„â–„â–…â–„â–â–‚â–‚â–ƒâ–‡â–…â–ƒâ–ƒâ–ˆâ–â–„â–…â–ƒ
wandb:         valid_loss â–„â–‚â–‚â–…â–‚â–ƒâ–„â–â–â–â–„â–†â–ƒâ–‚â–‚â–ˆâ–‚â–„â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3280
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.50702
wandb:   test_error_force 8.31645
wandb:          test_loss 5.88427
wandb: train_error_energy 1.93195
wandb:  train_error_force 2.04071
wandb:         train_loss -2.34811
wandb: valid_error_energy 2.40637
wandb:  valid_error_force 2.14406
wandb:         valid_loss -2.18854
wandb: 
wandb: ğŸš€ View run al_58_32 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kp0pi5vt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_003537-kp0pi5vt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.952884674072266, Uncertainty Bias: -5.2919182777404785
6.67572e-05 0.015077591
-1.3619086 26.798021
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1892 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1776 steps.
Found uncertainty sample 6 after 321 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2475 steps.
Found uncertainty sample 9 after 1139 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 278 steps.
Found uncertainty sample 12 after 251 steps.
Found uncertainty sample 13 after 586 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 920 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3852 steps.
Found uncertainty sample 20 after 305 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 1015 steps.
Found uncertainty sample 24 after 1254 steps.
Found uncertainty sample 25 after 2676 steps.
Found uncertainty sample 26 after 1194 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2445 steps.
Found uncertainty sample 30 after 894 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1992 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2097 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 922 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3670 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3514 steps.
Found uncertainty sample 46 after 2360 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2117 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 412 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2446 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 821 steps.
Found uncertainty sample 61 after 2168 steps.
Found uncertainty sample 62 after 286 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1508 steps.
Found uncertainty sample 66 after 2066 steps.
Found uncertainty sample 67 after 2465 steps.
Found uncertainty sample 68 after 891 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 351 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 328 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2410 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 501 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3213 steps.
Found uncertainty sample 87 after 903 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3140 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_011052-v2e3g5jd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_33
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v2e3g5jd
Training model 33. Added 40 samples to the dataset.
Epoch 0, Batch 100/104, Loss: 0.06855301558971405, Uncertainty: 0.1372150480747223

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.304746290676713, Training Loss Force: 2.1649916470575743, time: 1.5336973667144775
Validation Loss Energy: 0.7932083978061915, Validation Loss Force: 2.1964211475730173, time: 0.10699009895324707
Test Loss Energy: 11.913615036316942, Test Loss Force: 8.420772635908582, time: 9.631736278533936

Epoch 1, Batch 100/104, Loss: 0.08392380177974701, Uncertainty: 0.13744373619556427

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1493366256571984, Training Loss Force: 2.046349487017405, time: 1.5645902156829834
Validation Loss Energy: 2.545937112515758, Validation Loss Force: 2.155432990532641, time: 0.10771036148071289
Test Loss Energy: 13.910319672099194, Test Loss Force: 8.318503744603571, time: 9.69294023513794

Epoch 2, Batch 100/104, Loss: 0.1864708960056305, Uncertainty: 0.1371433436870575

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8687925796095781, Training Loss Force: 2.0642162023607127, time: 1.5760042667388916
Validation Loss Energy: 2.446837875116877, Validation Loss Force: 2.4983005001162697, time: 0.10226845741271973
Test Loss Energy: 10.714977851217816, Test Loss Force: 8.363238684831147, time: 9.813016176223755

Epoch 3, Batch 100/104, Loss: 0.07124509662389755, Uncertainty: 0.1383504718542099

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5948672952410925, Training Loss Force: 2.050770467293129, time: 1.5592787265777588
Validation Loss Energy: 0.8466612952991731, Validation Loss Force: 2.115941170152899, time: 0.10281920433044434
Test Loss Energy: 11.407498741752395, Test Loss Force: 8.287494405661446, time: 9.654699802398682

Epoch 4, Batch 100/104, Loss: 0.05182294547557831, Uncertainty: 0.13708728551864624

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.725435395279583, Training Loss Force: 2.053912567669187, time: 1.579890251159668
Validation Loss Energy: 2.0173324728824973, Validation Loss Force: 2.137124354012447, time: 0.10858845710754395
Test Loss Energy: 13.283852294321493, Test Loss Force: 8.282148641749275, time: 9.606509447097778

Epoch 5, Batch 100/104, Loss: 0.04883449897170067, Uncertainty: 0.135781928896904

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.670158328446939, Training Loss Force: 2.032072012035148, time: 1.763671875
Validation Loss Energy: 1.1775353436775533, Validation Loss Force: 2.23170363041814, time: 0.10659027099609375
Test Loss Energy: 11.524424035673508, Test Loss Force: 8.357336604791115, time: 9.75843358039856

Epoch 6, Batch 100/104, Loss: 0.12723349034786224, Uncertainty: 0.13512039184570312

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9309720704143487, Training Loss Force: 2.0347035085080494, time: 1.5475857257843018
Validation Loss Energy: 1.5501257885380668, Validation Loss Force: 2.231780562608058, time: 0.10521912574768066
Test Loss Energy: 12.965799380604748, Test Loss Force: 8.423701343728812, time: 9.69227910041809

Epoch 7, Batch 100/104, Loss: 0.16361096501350403, Uncertainty: 0.13594913482666016

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7700385832277852, Training Loss Force: 2.058475776791348, time: 1.5847258567810059
Validation Loss Energy: 1.8009846813384534, Validation Loss Force: 2.3510863569924476, time: 0.10686826705932617
Test Loss Energy: 12.88497277960446, Test Loss Force: 8.388333898614832, time: 9.892400741577148

Epoch 8, Batch 100/104, Loss: 0.09432897716760635, Uncertainty: 0.134893998503685

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.904585101656057, Training Loss Force: 2.066677938231914, time: 1.560030221939087
Validation Loss Energy: 0.8060685986619645, Validation Loss Force: 2.222407416244801, time: 0.10161542892456055
Test Loss Energy: 11.779165564030608, Test Loss Force: 8.31112664585056, time: 9.585376977920532

Epoch 9, Batch 100/104, Loss: 0.0648123100399971, Uncertainty: 0.13777023553848267

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7376384561294709, Training Loss Force: 2.0573912602929587, time: 1.5770204067230225
Validation Loss Energy: 3.1256887436340595, Validation Loss Force: 2.1024092321511487, time: 0.10975027084350586
Test Loss Energy: 10.597864890341548, Test Loss Force: 8.204469022622575, time: 9.731729984283447

Epoch 10, Batch 100/104, Loss: 0.052782319486141205, Uncertainty: 0.13716845214366913

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2508781303643577, Training Loss Force: 2.0423241812497963, time: 1.5520617961883545
Validation Loss Energy: 2.0971928734040715, Validation Loss Force: 2.2293828612447077, time: 0.10555481910705566
Test Loss Energy: 10.992426377001383, Test Loss Force: 8.454887141557146, time: 9.727732419967651

Epoch 11, Batch 100/104, Loss: 0.06815877556800842, Uncertainty: 0.1364540010690689

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4859777954308209, Training Loss Force: 2.0275898020263927, time: 1.5595779418945312
Validation Loss Energy: 1.1471778570020614, Validation Loss Force: 2.10272820570269, time: 0.10766863822937012
Test Loss Energy: 12.046631158165756, Test Loss Force: 8.32610140006014, time: 10.122228384017944

Epoch 12, Batch 100/104, Loss: 0.1065688282251358, Uncertainty: 0.13527989387512207

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4417699351407185, Training Loss Force: 2.024363708279231, time: 1.5915613174438477
Validation Loss Energy: 1.802565242603535, Validation Loss Force: 2.1533521473639454, time: 0.10396671295166016
Test Loss Energy: 12.77394711752858, Test Loss Force: 8.414259696292198, time: 9.656814813613892

Epoch 13, Batch 100/104, Loss: 0.07092253863811493, Uncertainty: 0.13515698909759521

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0105646149407184, Training Loss Force: 2.0451586759765275, time: 1.7788517475128174
Validation Loss Energy: 2.266010933738672, Validation Loss Force: 2.1350017603788904, time: 0.10147452354431152
Test Loss Energy: 13.17545446858322, Test Loss Force: 8.36982868895655, time: 9.649242401123047

Epoch 14, Batch 100/104, Loss: 0.11826220154762268, Uncertainty: 0.13426247239112854

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.071515735879369, Training Loss Force: 2.0013801244760856, time: 1.5192668437957764
Validation Loss Energy: 0.980034435646697, Validation Loss Force: 2.103045175231918, time: 0.10156035423278809
Test Loss Energy: 12.347850139890287, Test Loss Force: 8.326656543386115, time: 9.730112075805664

Epoch 15, Batch 100/104, Loss: 0.2094445675611496, Uncertainty: 0.13368703424930573

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6637161257368662, Training Loss Force: 2.0196574770518008, time: 1.5737521648406982
Validation Loss Energy: 1.240570195525386, Validation Loss Force: 2.2771466177265207, time: 0.10759925842285156
Test Loss Energy: 12.02865123318337, Test Loss Force: 8.355238527496848, time: 9.877257347106934

Epoch 16, Batch 100/104, Loss: 0.16333110630512238, Uncertainty: 0.13371481001377106

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6983383881411647, Training Loss Force: 2.027693285370913, time: 1.5985665321350098
Validation Loss Energy: 0.809826279667712, Validation Loss Force: 2.182132691147977, time: 0.1058807373046875
Test Loss Energy: 12.232106498665297, Test Loss Force: 8.39755942174628, time: 9.715583086013794

Epoch 17, Batch 100/104, Loss: 0.11439574509859085, Uncertainty: 0.13821105659008026

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.3395005993969908, Training Loss Force: 2.0602725390918786, time: 1.5531933307647705
Validation Loss Energy: 0.8364471275717467, Validation Loss Force: 2.3008527543440036, time: 0.1030735969543457
Test Loss Energy: 11.932137723754469, Test Loss Force: 8.488085122348158, time: 9.716815710067749

Epoch 18, Batch 100/104, Loss: 0.06577767431735992, Uncertainty: 0.1380876898765564

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.2551425262073164, Training Loss Force: 2.038515414803454, time: 1.5600035190582275
Validation Loss Energy: 0.911438338378388, Validation Loss Force: 2.1625332415888403, time: 0.10790848731994629
Test Loss Energy: 11.803958726534937, Test Loss Force: 8.321621854099842, time: 9.913205862045288

Epoch 19, Batch 100/104, Loss: 0.0572468563914299, Uncertainty: 0.13456711173057556

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.639715211568016, Training Loss Force: 2.0327002623251356, time: 1.5899429321289062
Validation Loss Energy: 2.9369700737204543, Validation Loss Force: 2.1618804869875525, time: 0.10361003875732422
Test Loss Energy: 13.719676933834021, Test Loss Force: 8.362942467250255, time: 9.65565299987793

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–ˆâ–â–ƒâ–‡â–ƒâ–†â–†â–ƒâ–â–‚â–„â–†â–†â–…â–„â–„â–„â–„â–ˆ
wandb:   test_error_force â–†â–„â–…â–ƒâ–ƒâ–…â–†â–†â–„â–â–‡â–„â–†â–…â–„â–…â–†â–ˆâ–„â–…
wandb:          test_loss â–†â–†â–„â–ƒâ–…â–…â–ˆâ–‡â–…â–â–†â–…â–ˆâ–‡â–†â–‡â–ˆâ–†â–„â–‡
wandb: train_error_energy â–ˆâ–„â–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–„â–„â–‚â–ƒâ–â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–„â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–â–ƒâ–â–â–‚â–‚â–â–‚
wandb: valid_error_energy â–â–†â–†â–â–…â–‚â–ƒâ–„â–â–ˆâ–…â–‚â–„â–…â–‚â–‚â–â–â–â–‡
wandb:  valid_error_force â–ƒâ–‚â–ˆâ–â–‚â–ƒâ–ƒâ–…â–ƒâ–â–ƒâ–â–‚â–‚â–â–„â–‚â–…â–‚â–‚
wandb:         valid_loss â–‚â–ƒâ–ˆâ–â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–â–‚â–ƒâ–â–„â–‚â–„â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3316
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 13.71968
wandb:   test_error_force 8.36294
wandb:          test_loss 6.11709
wandb: train_error_energy 1.63972
wandb:  train_error_force 2.0327
wandb:         train_loss -2.37756
wandb: valid_error_energy 2.93697
wandb:  valid_error_force 2.16188
wandb:         valid_loss -2.13016
wandb: 
wandb: ğŸš€ View run al_58_33 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/v2e3g5jd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_011052-v2e3g5jd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.69874572753906, Uncertainty Bias: -5.221124649047852
0.00024604797 0.025308609
-1.1665512 19.62229
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 773 steps.
Found uncertainty sample 5 after 1381 steps.
Found uncertainty sample 6 after 1951 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1710 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 1842 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2482 steps.
Found uncertainty sample 15 after 996 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 381 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2304 steps.
Found uncertainty sample 23 after 2670 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1631 steps.
Found uncertainty sample 26 after 2352 steps.
Found uncertainty sample 27 after 3567 steps.
Found uncertainty sample 28 after 2025 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2916 steps.
Found uncertainty sample 31 after 3942 steps.
Found uncertainty sample 32 after 2741 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1478 steps.
Found uncertainty sample 35 after 1352 steps.
Found uncertainty sample 36 after 2583 steps.
Found uncertainty sample 37 after 625 steps.
Found uncertainty sample 38 after 1424 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 284 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3355 steps.
Found uncertainty sample 46 after 735 steps.
Found uncertainty sample 47 after 3380 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2699 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3688 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2417 steps.
Found uncertainty sample 54 after 246 steps.
Found uncertainty sample 55 after 777 steps.
Found uncertainty sample 56 after 778 steps.
Found uncertainty sample 57 after 949 steps.
Found uncertainty sample 58 after 1120 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2458 steps.
Found uncertainty sample 61 after 953 steps.
Found uncertainty sample 62 after 2074 steps.
Found uncertainty sample 63 after 1094 steps.
Found uncertainty sample 64 after 2656 steps.
Found uncertainty sample 65 after 1326 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2447 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2534 steps.
Found uncertainty sample 70 after 1107 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 119 steps.
Found uncertainty sample 77 after 1177 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1931 steps.
Found uncertainty sample 80 after 1305 steps.
Found uncertainty sample 81 after 2833 steps.
Found uncertainty sample 82 after 2512 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 934 steps.
Found uncertainty sample 85 after 29 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 295 steps.
Found uncertainty sample 89 after 1073 steps.
Found uncertainty sample 90 after 2178 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2132 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1216 steps.
Found uncertainty sample 97 after 1055 steps.
Found uncertainty sample 98 after 1092 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_014225-rppbl8cm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_34
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rppbl8cm
Training model 34. Added 60 samples to the dataset.
Epoch 0, Batch 100/106, Loss: 0.058270178735256195, Uncertainty: 0.13906261324882507

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9638188471276847, Training Loss Force: 2.162976213495857, time: 1.5977520942687988
Validation Loss Energy: 1.2411490239702254, Validation Loss Force: 2.1836974985709845, time: 0.10974383354187012
Test Loss Energy: 11.108477912530642, Test Loss Force: 8.38048473660923, time: 9.46819281578064

Epoch 1, Batch 100/106, Loss: 0.08987458050251007, Uncertainty: 0.13658159971237183

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.58301595136592, Training Loss Force: 2.0431886471057723, time: 1.5862016677856445
Validation Loss Energy: 1.1821945842215194, Validation Loss Force: 2.109712891472153, time: 0.10200858116149902
Test Loss Energy: 12.531340782494084, Test Loss Force: 8.266069033548586, time: 9.439194679260254

Epoch 2, Batch 100/106, Loss: 0.113704152405262, Uncertainty: 0.13647766411304474

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7622883162856615, Training Loss Force: 2.048961635654296, time: 1.557105541229248
Validation Loss Energy: 1.4143689193160995, Validation Loss Force: 2.1242017501285284, time: 0.10097146034240723
Test Loss Energy: 11.392241694361292, Test Loss Force: 8.256835436037536, time: 9.676536083221436

Epoch 3, Batch 100/106, Loss: 0.08006533980369568, Uncertainty: 0.13621249794960022

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6660805146830444, Training Loss Force: 2.0356953555978774, time: 1.5883054733276367
Validation Loss Energy: 0.8547842379089756, Validation Loss Force: 2.2657887099310363, time: 0.13540410995483398
Test Loss Energy: 11.931475041723274, Test Loss Force: 8.366085872427826, time: 9.978650569915771

Epoch 4, Batch 100/106, Loss: 0.17093554139137268, Uncertainty: 0.13685742020606995

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.709111147527816, Training Loss Force: 2.035631370778535, time: 1.545417308807373
Validation Loss Energy: 0.8119762616062178, Validation Loss Force: 2.115349649566742, time: 0.10331296920776367
Test Loss Energy: 11.58953060533538, Test Loss Force: 8.2503380063181, time: 9.56954288482666

Epoch 5, Batch 100/106, Loss: 0.21115659177303314, Uncertainty: 0.1377004235982895

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6589730941004759, Training Loss Force: 2.0641307916148537, time: 1.7788097858428955
Validation Loss Energy: 0.9363549044731345, Validation Loss Force: 2.4734968272785087, time: 0.10284113883972168
Test Loss Energy: 11.875192969226841, Test Loss Force: 8.457051940320312, time: 9.462801218032837

Epoch 6, Batch 100/106, Loss: 0.16778573393821716, Uncertainty: 0.1382232904434204

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7704127669012482, Training Loss Force: 2.0545816273923925, time: 1.6303670406341553
Validation Loss Energy: 1.6336825525493288, Validation Loss Force: 2.3119539246142335, time: 0.10587573051452637
Test Loss Energy: 10.6685612156724, Test Loss Force: 8.336442455975243, time: 9.533260107040405

Epoch 7, Batch 100/106, Loss: 0.2922540307044983, Uncertainty: 0.13833078742027283

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.6008804622170634, Training Loss Force: 2.153435721816499, time: 1.6111938953399658
Validation Loss Energy: 0.8362628688534913, Validation Loss Force: 2.232588851607776, time: 0.10555195808410645
Test Loss Energy: 11.389449628453393, Test Loss Force: 8.218354341805046, time: 9.674160480499268

Epoch 8, Batch 100/106, Loss: 0.047339506447315216, Uncertainty: 0.13457688689231873

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8916331661820056, Training Loss Force: 2.0220265537955178, time: 1.5394377708435059
Validation Loss Energy: 0.791366033292785, Validation Loss Force: 2.128803542032845, time: 0.10435104370117188
Test Loss Energy: 11.309051121127128, Test Loss Force: 8.267459202493088, time: 9.545247077941895

Epoch 9, Batch 100/106, Loss: 0.03575994819402695, Uncertainty: 0.13392820954322815

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6699292300828974, Training Loss Force: 2.022553548644359, time: 1.5613439083099365
Validation Loss Energy: 1.1157174343795027, Validation Loss Force: 2.1541027650548683, time: 0.10372447967529297
Test Loss Energy: 11.944172844200175, Test Loss Force: 8.286797616779292, time: 9.511552333831787

Epoch 10, Batch 100/106, Loss: 0.18547514081001282, Uncertainty: 0.1348372995853424

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.3594858037194206, Training Loss Force: 2.0172106602557607, time: 1.6366300582885742
Validation Loss Energy: 0.8253768526455143, Validation Loss Force: 2.126702101968151, time: 0.10509181022644043
Test Loss Energy: 11.261216654367603, Test Loss Force: 8.235453009924663, time: 9.825193643569946

Epoch 11, Batch 100/106, Loss: 0.11736389994621277, Uncertainty: 0.13532285392284393

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9190105230563945, Training Loss Force: 2.0332914058442015, time: 1.5860693454742432
Validation Loss Energy: 1.3186845916064538, Validation Loss Force: 2.0788410390695677, time: 0.1072237491607666
Test Loss Energy: 11.003388773098184, Test Loss Force: 8.2568912828583, time: 9.56126880645752

Epoch 12, Batch 100/106, Loss: 0.0969143956899643, Uncertainty: 0.13587674498558044

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6266924376439447, Training Loss Force: 2.0296700503469065, time: 1.6025183200836182
Validation Loss Energy: 1.9477421300439772, Validation Loss Force: 2.1282989737481723, time: 0.10593318939208984
Test Loss Energy: 12.839313554907628, Test Loss Force: 8.165935059040518, time: 9.57054591178894

Epoch 13, Batch 100/106, Loss: 0.3602115213871002, Uncertainty: 0.13397276401519775

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.5059900975834757, Training Loss Force: 2.030991888970291, time: 1.6019887924194336
Validation Loss Energy: 3.3815603085802857, Validation Loss Force: 2.2134314003033055, time: 0.1040198802947998
Test Loss Energy: 10.480134261575776, Test Loss Force: 8.044481749565332, time: 9.753752708435059

Epoch 14, Batch 100/106, Loss: 0.1263139545917511, Uncertainty: 0.13363343477249146

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7408848992491324, Training Loss Force: 2.02739350305579, time: 1.5806334018707275
Validation Loss Energy: 0.8207808223053485, Validation Loss Force: 2.168802936730729, time: 0.10485100746154785
Test Loss Energy: 11.609309440539317, Test Loss Force: 8.19409625209257, time: 9.495226383209229

Epoch 15, Batch 100/106, Loss: 0.05994855985045433, Uncertainty: 0.1351621150970459

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5039032617576205, Training Loss Force: 2.0345126484292826, time: 1.679664134979248
Validation Loss Energy: 0.8621564514932825, Validation Loss Force: 2.1572648895961883, time: 0.11295819282531738
Test Loss Energy: 11.49137833026733, Test Loss Force: 8.15761621669192, time: 9.692489385604858

Epoch 16, Batch 100/106, Loss: 0.2072778046131134, Uncertainty: 0.1342654824256897

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6075101582045404, Training Loss Force: 2.0094204646495992, time: 1.5765571594238281
Validation Loss Energy: 2.0272040641289135, Validation Loss Force: 2.2709095436145104, time: 0.1042327880859375
Test Loss Energy: 13.188973605440697, Test Loss Force: 8.139983490032575, time: 9.495043754577637

Epoch 17, Batch 100/106, Loss: 0.19416943192481995, Uncertainty: 0.13526523113250732

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.013165793819705, Training Loss Force: 2.009069358469844, time: 1.54512357711792
Validation Loss Energy: 2.573116887809715, Validation Loss Force: 2.144960192592219, time: 0.10926318168640137
Test Loss Energy: 13.467239804970708, Test Loss Force: 8.294734699289137, time: 10.092845678329468

Epoch 18, Batch 100/106, Loss: 0.06264733523130417, Uncertainty: 0.1349232792854309

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7844666718405118, Training Loss Force: 2.0299111338110722, time: 1.640188455581665
Validation Loss Energy: 1.915702266636428, Validation Loss Force: 2.2514835533200515, time: 0.10348701477050781
Test Loss Energy: 12.941851209037583, Test Loss Force: 8.17038603573333, time: 9.714146137237549

Epoch 19, Batch 100/106, Loss: 0.2662229537963867, Uncertainty: 0.13621732592582703

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.153012810613976, Training Loss Force: 2.0443558430576365, time: 1.563148021697998
Validation Loss Energy: 6.437648466595112, Validation Loss Force: 2.233711104103252, time: 0.10721111297607422
Test Loss Energy: 17.010525132763075, Test Loss Force: 8.345783424315302, time: 9.475996017456055

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–„â–â–‚â–‚â–„â–„â–„â–ˆ
wandb:   test_error_force â–‡â–…â–…â–†â–„â–ˆâ–†â–„â–…â–…â–„â–…â–ƒâ–â–„â–ƒâ–ƒâ–…â–ƒâ–†
wandb:          test_loss â–ƒâ–„â–ƒâ–…â–„â–…â–ƒâ–â–„â–…â–„â–„â–ƒâ–â–„â–‚â–„â–†â–„â–ˆ
wandb: train_error_energy â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–†â–ƒâ–‚â–â–ƒâ–‚â–†â–ƒâ–‚â–‚â–„â–ƒâ–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–‚â–‚â–„â–ƒâ–ˆâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒ
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‡â–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒ
wandb: valid_error_energy â–‚â–â–‚â–â–â–â–‚â–â–â–â–â–‚â–‚â–„â–â–â–ƒâ–ƒâ–‚â–ˆ
wandb:  valid_error_force â–ƒâ–‚â–‚â–„â–‚â–ˆâ–…â–„â–‚â–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–„â–‚â–„â–„
wandb:         valid_loss â–ƒâ–â–‚â–„â–â–‡â–…â–ƒâ–â–‚â–â–â–‚â–…â–‚â–‚â–…â–ƒâ–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3370
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 17.01053
wandb:   test_error_force 8.34578
wandb:          test_loss 6.24763
wandb: train_error_energy 2.15301
wandb:  train_error_force 2.04436
wandb:         train_loss -2.32869
wandb: valid_error_energy 6.43765
wandb:  valid_error_force 2.23371
wandb:         valid_loss -1.80943
wandb: 
wandb: ğŸš€ View run al_58_34 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/rppbl8cm
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_014225-rppbl8cm/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 36.6024055480957, Uncertainty Bias: -4.842391490936279
5.340576e-05 0.7277012
-0.8208475 25.105743
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 341 steps.
Found uncertainty sample 1 after 1835 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 31 steps.
Found uncertainty sample 5 after 1243 steps.
Found uncertainty sample 6 after 2963 steps.
Found uncertainty sample 7 after 18 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1485 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3174 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1223 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1382 steps.
Found uncertainty sample 16 after 648 steps.
Found uncertainty sample 17 after 1485 steps.
Found uncertainty sample 18 after 2130 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2413 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1925 steps.
Found uncertainty sample 25 after 2641 steps.
Found uncertainty sample 26 after 2189 steps.
Found uncertainty sample 27 after 875 steps.
Found uncertainty sample 28 after 1551 steps.
Found uncertainty sample 29 after 1103 steps.
Found uncertainty sample 30 after 3719 steps.
Found uncertainty sample 31 after 488 steps.
Found uncertainty sample 32 after 1907 steps.
Found uncertainty sample 33 after 31 steps.
Found uncertainty sample 34 after 3064 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 445 steps.
Found uncertainty sample 37 after 1273 steps.
Found uncertainty sample 38 after 171 steps.
Found uncertainty sample 39 after 3243 steps.
Found uncertainty sample 40 after 122 steps.
Found uncertainty sample 41 after 3323 steps.
Found uncertainty sample 42 after 454 steps.
Found uncertainty sample 43 after 1272 steps.
Found uncertainty sample 44 after 3183 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 708 steps.
Found uncertainty sample 47 after 3231 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1585 steps.
Found uncertainty sample 50 after 2589 steps.
Found uncertainty sample 51 after 568 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2498 steps.
Found uncertainty sample 55 after 1601 steps.
Found uncertainty sample 56 after 3286 steps.
Found uncertainty sample 57 after 2659 steps.
Found uncertainty sample 58 after 891 steps.
Found uncertainty sample 59 after 3492 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2440 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 813 steps.
Found uncertainty sample 66 after 202 steps.
Found uncertainty sample 67 after 1861 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3296 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3340 steps.
Found uncertainty sample 74 after 3109 steps.
Found uncertainty sample 75 after 3230 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 867 steps.
Found uncertainty sample 78 after 799 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 70 steps.
Found uncertainty sample 81 after 2237 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2751 steps.
Found uncertainty sample 85 after 3313 steps.
Found uncertainty sample 86 after 2902 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1121 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1267 steps.
Found uncertainty sample 94 after 603 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1180 steps.
Found uncertainty sample 98 after 830 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_021251-9hx4m7lc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_35
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/9hx4m7lc
Training model 35. Added 65 samples to the dataset.
Epoch 0, Batch 100/108, Loss: 0.05150415003299713, Uncertainty: 0.13770954310894012

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.242061635713144, Training Loss Force: 2.1852945806496433, time: 1.6245079040527344
Validation Loss Energy: 1.5784544252904378, Validation Loss Force: 2.2946833716523556, time: 0.10768723487854004
Test Loss Energy: 10.912094968865492, Test Loss Force: 8.29962920727288, time: 9.794595956802368

Epoch 1, Batch 100/108, Loss: 0.06750543415546417, Uncertainty: 0.136875718832016

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.2319859450709183, Training Loss Force: 2.0298535259497568, time: 1.5812387466430664
Validation Loss Energy: 1.376925822080753, Validation Loss Force: 2.1959538763702877, time: 0.10692238807678223
Test Loss Energy: 11.07276328774653, Test Loss Force: 8.278570033806313, time: 9.686699390411377

Epoch 2, Batch 100/108, Loss: 0.06694494187831879, Uncertainty: 0.13572505116462708

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6689819201071419, Training Loss Force: 2.0465868256827924, time: 1.6541047096252441
Validation Loss Energy: 2.5629630634208347, Validation Loss Force: 2.1323129191072394, time: 0.10924959182739258
Test Loss Energy: 10.515191277920962, Test Loss Force: 8.203988761414829, time: 9.93824052810669

Epoch 3, Batch 100/108, Loss: 0.10312578082084656, Uncertainty: 0.1371205747127533

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9061933554930088, Training Loss Force: 2.0391565562730634, time: 1.585500955581665
Validation Loss Energy: 0.865282754135752, Validation Loss Force: 2.2109161296309052, time: 0.10791540145874023
Test Loss Energy: 11.903135923199743, Test Loss Force: 8.243487672815931, time: 9.640685081481934

Epoch 4, Batch 100/108, Loss: 0.18885400891304016, Uncertainty: 0.1357029676437378

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.350334885034446, Training Loss Force: 2.0219745998593726, time: 1.6242783069610596
Validation Loss Energy: 0.9975913411302382, Validation Loss Force: 2.1391120101435717, time: 0.10591006278991699
Test Loss Energy: 11.425807046600488, Test Loss Force: 8.235824519987862, time: 9.691415786743164

Epoch 5, Batch 100/108, Loss: 0.2561124563217163, Uncertainty: 0.13441705703735352

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8502816710676442, Training Loss Force: 2.027918960946801, time: 1.8087413311004639
Validation Loss Energy: 1.6844623069454472, Validation Loss Force: 2.201696736312911, time: 0.11458110809326172
Test Loss Energy: 10.744173693360624, Test Loss Force: 8.218349879095673, time: 9.705209970474243

Epoch 6, Batch 100/108, Loss: 0.1449376940727234, Uncertainty: 0.13498455286026

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.062559283499955, Training Loss Force: 2.012332326906991, time: 1.653824806213379
Validation Loss Energy: 2.335640911685167, Validation Loss Force: 2.1640397096956145, time: 0.10715198516845703
Test Loss Energy: 10.566044723271956, Test Loss Force: 8.146296813171576, time: 9.73473310470581

Epoch 7, Batch 100/108, Loss: 0.11352695524692535, Uncertainty: 0.13494178652763367

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.813946951772056, Training Loss Force: 2.042211800655214, time: 1.595055103302002
Validation Loss Energy: 2.470424772406716, Validation Loss Force: 2.3927517622401635, time: 0.1070854663848877
Test Loss Energy: 10.530031810433636, Test Loss Force: 8.369517355521488, time: 9.900665521621704

Epoch 8, Batch 100/108, Loss: 0.17322473227977753, Uncertainty: 0.13587215542793274

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6695987404441293, Training Loss Force: 2.046280042236115, time: 1.5327529907226562
Validation Loss Energy: 3.048362540662289, Validation Loss Force: 2.1190412813370787, time: 0.11155581474304199
Test Loss Energy: 10.551078050436823, Test Loss Force: 8.173866720547593, time: 9.70547890663147

Epoch 9, Batch 100/108, Loss: 0.1230863705277443, Uncertainty: 0.13398396968841553

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6881471426678927, Training Loss Force: 2.0153180923303586, time: 1.6296446323394775
Validation Loss Energy: 3.6239724143317606, Validation Loss Force: 2.255627871464059, time: 0.10802531242370605
Test Loss Energy: 14.009694314508662, Test Loss Force: 8.2622415514489, time: 9.687766313552856

Epoch 10, Batch 100/108, Loss: 0.07810401916503906, Uncertainty: 0.13660363852977753

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8545209637876445, Training Loss Force: 2.0345617856629734, time: 1.6196236610412598
Validation Loss Energy: 1.3342145398546144, Validation Loss Force: 2.1289984888701046, time: 0.10820984840393066
Test Loss Energy: 11.88029995953454, Test Loss Force: 8.240466917534519, time: 9.88609004020691

Epoch 11, Batch 100/108, Loss: 0.10985463857650757, Uncertainty: 0.13519911468029022

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5854637488596879, Training Loss Force: 2.005680739747577, time: 1.6478500366210938
Validation Loss Energy: 0.8323651289549552, Validation Loss Force: 2.1686047611908528, time: 0.1068110466003418
Test Loss Energy: 11.369219444056473, Test Loss Force: 8.171224556441384, time: 9.730807781219482

Epoch 12, Batch 100/108, Loss: 0.08874126523733139, Uncertainty: 0.13583935797214508

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8289152707051486, Training Loss Force: 2.0720816604568864, time: 1.5974199771881104
Validation Loss Energy: 0.9855598591683221, Validation Loss Force: 2.2454884092350915, time: 0.11318612098693848
Test Loss Energy: 11.749258486324724, Test Loss Force: 8.183036268619496, time: 9.911855697631836

Epoch 13, Batch 100/108, Loss: 0.16921424865722656, Uncertainty: 0.1363404095172882

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.142400128309963, Training Loss Force: 2.0456776582820884, time: 1.591597557067871
Validation Loss Energy: 1.6248354620433259, Validation Loss Force: 2.156666354931935, time: 0.10523104667663574
Test Loss Energy: 12.599590750338681, Test Loss Force: 8.201211559546778, time: 9.684590578079224

Epoch 14, Batch 100/108, Loss: 0.2231578528881073, Uncertainty: 0.13457882404327393

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.016259408104444, Training Loss Force: 2.027447038433024, time: 1.6557912826538086
Validation Loss Energy: 0.9896141076428022, Validation Loss Force: 2.1598911608378337, time: 0.10614633560180664
Test Loss Energy: 11.004180337430011, Test Loss Force: 8.118857231365313, time: 10.230859756469727

Epoch 15, Batch 100/108, Loss: 0.11533981561660767, Uncertainty: 0.1357078105211258

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4575015348631117, Training Loss Force: 2.0113113198042423, time: 1.5767767429351807
Validation Loss Energy: 1.1009204016251632, Validation Loss Force: 2.210719624109624, time: 0.10687994956970215
Test Loss Energy: 11.766742705487609, Test Loss Force: 8.095673437509642, time: 9.945554256439209

Epoch 16, Batch 100/108, Loss: 0.05977197736501694, Uncertainty: 0.13576087355613708

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.3803008219336452, Training Loss Force: 2.0445686308906543, time: 1.579817295074463
Validation Loss Energy: 1.4260597731520328, Validation Loss Force: 2.166072344994216, time: 0.10927057266235352
Test Loss Energy: 12.357371542518582, Test Loss Force: 8.194706831875234, time: 9.70201063156128

Epoch 17, Batch 100/108, Loss: 0.07537665963172913, Uncertainty: 0.1357715129852295

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0980383744384885, Training Loss Force: 2.0613111064480782, time: 1.6571240425109863
Validation Loss Energy: 0.8612260841343098, Validation Loss Force: 2.136335659897571, time: 0.1089479923248291
Test Loss Energy: 11.566250539133785, Test Loss Force: 8.167922925599813, time: 9.753010034561157

Epoch 18, Batch 100/108, Loss: 0.2017810195684433, Uncertainty: 0.1351609230041504

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6434988538097604, Training Loss Force: 2.0398113932432156, time: 1.5892341136932373
Validation Loss Energy: 1.4154527057166166, Validation Loss Force: 2.174805985570369, time: 0.10590100288391113
Test Loss Energy: 10.967656479342475, Test Loss Force: 8.169786694330597, time: 9.935879468917847

Epoch 19, Batch 100/108, Loss: 0.07946786284446716, Uncertainty: 0.13498058915138245

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4124102045041298, Training Loss Force: 2.0352722589933374, time: 1.6043102741241455
Validation Loss Energy: 0.8476049949732584, Validation Loss Force: 2.2766757838174563, time: 0.1085503101348877
Test Loss Energy: 11.046836149391064, Test Loss Force: 8.287198593781405, time: 9.696147441864014

wandb: - 0.039 MB of 0.049 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–â–„â–ƒâ–â–â–â–â–ˆâ–„â–ƒâ–ƒâ–…â–‚â–„â–…â–ƒâ–‚â–‚
wandb:   test_error_force â–†â–†â–„â–…â–…â–„â–‚â–ˆâ–ƒâ–…â–…â–ƒâ–ƒâ–„â–‚â–â–„â–ƒâ–ƒâ–†
wandb:          test_loss â–‚â–„â–‚â–ƒâ–ƒâ–ƒâ–â–„â–â–ˆâ–„â–â–‚â–‚â–â–â–„â–‚â–‚â–…
wandb: train_error_energy â–ˆâ–â–„â–†â–‚â–…â–‡â–…â–„â–„â–…â–ƒâ–…â–‡â–†â–ƒâ–‚â–‡â–„â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–â–‚â–â–„â–ƒâ–‚â–â–ƒâ–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–â–ƒâ–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–„â–ƒâ–ƒâ–â–‚â–„â–‚â–‚
wandb: valid_error_energy â–ƒâ–‚â–…â–â–â–ƒâ–…â–…â–‡â–ˆâ–‚â–â–â–ƒâ–â–‚â–‚â–â–‚â–
wandb:  valid_error_force â–…â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–ˆâ–â–„â–â–‚â–„â–‚â–‚â–ƒâ–‚â–â–‚â–…
wandb:         valid_loss â–…â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ˆâ–ƒâ–‡â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3428
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.04684
wandb:   test_error_force 8.2872
wandb:          test_loss 5.90578
wandb: train_error_energy 1.41241
wandb:  train_error_force 2.03527
wandb:         train_loss -2.38943
wandb: valid_error_energy 0.8476
wandb:  valid_error_force 2.27668
wandb:         valid_loss -2.12562
wandb: 
wandb: ğŸš€ View run al_58_35 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/9hx4m7lc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_021251-9hx4m7lc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.26137161254883, Uncertainty Bias: -5.253267765045166
3.1471252e-05 0.0012321472
-1.1593189 22.246052
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 23 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1934 steps.
Found uncertainty sample 3 after 2019 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2015 steps.
Found uncertainty sample 7 after 69 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1251 steps.
Found uncertainty sample 10 after 601 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1512 steps.
Found uncertainty sample 13 after 1941 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1538 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3099 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1922 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 850 steps.
Found uncertainty sample 24 after 3388 steps.
Found uncertainty sample 25 after 1060 steps.
Found uncertainty sample 26 after 3779 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 495 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1091 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1356 steps.
Found uncertainty sample 36 after 806 steps.
Found uncertainty sample 37 after 2481 steps.
Found uncertainty sample 38 after 2207 steps.
Found uncertainty sample 39 after 1143 steps.
Found uncertainty sample 40 after 1623 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3191 steps.
Found uncertainty sample 44 after 1670 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2487 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 271 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2550 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 959 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1163 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 623 steps.
Found uncertainty sample 59 after 1886 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2775 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3534 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 905 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3886 steps.
Found uncertainty sample 71 after 237 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3018 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1075 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1063 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 816 steps.
Found uncertainty sample 82 after 2591 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1722 steps.
Found uncertainty sample 85 after 639 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 917 steps.
Found uncertainty sample 88 after 1267 steps.
Found uncertainty sample 89 after 1908 steps.
Found uncertainty sample 90 after 3935 steps.
Found uncertainty sample 91 after 37 steps.
Found uncertainty sample 92 after 1935 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2498 steps.
Found uncertainty sample 95 after 1232 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1319 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_024536-0tgshe9n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_36
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0tgshe9n
Training model 36. Added 54 samples to the dataset.
Epoch 0, Batch 100/109, Loss: 0.25139477849006653, Uncertainty: 0.13943006098270416

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.916177810304354, Training Loss Force: 2.2213501228762675, time: 1.6627733707427979
Validation Loss Energy: 3.8394854192477212, Validation Loss Force: 2.226065462085627, time: 0.1143348217010498
Test Loss Energy: 9.912463266341902, Test Loss Force: 8.13019106291367, time: 9.691876649856567

Epoch 1, Batch 100/109, Loss: 0.030751869082450867, Uncertainty: 0.13589084148406982

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6333068811004416, Training Loss Force: 2.0476744268529337, time: 1.633265733718872
Validation Loss Energy: 0.6939255511407311, Validation Loss Force: 2.0064062834494423, time: 0.11266446113586426
Test Loss Energy: 11.436515222149453, Test Loss Force: 8.098854740742688, time: 9.600873231887817

Epoch 2, Batch 100/109, Loss: 0.19403231143951416, Uncertainty: 0.13604244589805603

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9941209457232054, Training Loss Force: 2.0169390798295646, time: 1.656693696975708
Validation Loss Energy: 1.8044464072156192, Validation Loss Force: 2.034921516946101, time: 0.11600542068481445
Test Loss Energy: 10.754103706695576, Test Loss Force: 8.0432395774938, time: 9.76762318611145

Epoch 3, Batch 100/109, Loss: 0.24525296688079834, Uncertainty: 0.1370483934879303

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.255276022038823, Training Loss Force: 2.0518841208624696, time: 1.620734691619873
Validation Loss Energy: 0.9782443427152968, Validation Loss Force: 2.1090113352163833, time: 0.11098599433898926
Test Loss Energy: 11.382326822528263, Test Loss Force: 8.00451600005882, time: 9.594956874847412

Epoch 4, Batch 100/109, Loss: 0.14743879437446594, Uncertainty: 0.13617047667503357

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8190319972303746, Training Loss Force: 2.036843558540334, time: 1.7005374431610107
Validation Loss Energy: 2.027605462375973, Validation Loss Force: 2.7451334419794713, time: 0.11219978332519531
Test Loss Energy: 10.574766340297131, Test Loss Force: 8.181633443673695, time: 9.644272327423096

Epoch 5, Batch 100/109, Loss: 0.09689190983772278, Uncertainty: 0.1345803141593933

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8718940656372534, Training Loss Force: 1.9961511337040383, time: 1.9026203155517578
Validation Loss Energy: 0.822833618439538, Validation Loss Force: 2.0309126929773895, time: 0.11855411529541016
Test Loss Energy: 11.26370611873522, Test Loss Force: 8.190564434981237, time: 9.598688840866089

Epoch 6, Batch 100/109, Loss: 0.09089405089616776, Uncertainty: 0.13527140021324158

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4871501426797262, Training Loss Force: 2.025081569572913, time: 1.6579921245574951
Validation Loss Energy: 1.7141888420401905, Validation Loss Force: 2.0068361091241314, time: 0.10909891128540039
Test Loss Energy: 10.574093716263443, Test Loss Force: 8.080290464304575, time: 9.625633001327515

Epoch 7, Batch 100/109, Loss: 0.18056562542915344, Uncertainty: 0.13514171540737152

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8167771524239904, Training Loss Force: 2.0255218712521144, time: 1.6404528617858887
Validation Loss Energy: 2.0131846291436784, Validation Loss Force: 2.137368993180773, time: 0.11004304885864258
Test Loss Energy: 12.752176071968293, Test Loss Force: 8.168391022776836, time: 9.788578271865845

Epoch 8, Batch 100/109, Loss: 0.07784934341907501, Uncertainty: 0.13681554794311523

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6614692723534703, Training Loss Force: 2.038562286521173, time: 1.5741519927978516
Validation Loss Energy: 1.5567672112633197, Validation Loss Force: 2.0630230682811495, time: 0.1136479377746582
Test Loss Energy: 10.645468480673534, Test Loss Force: 8.308979061394245, time: 10.172669649124146

Epoch 9, Batch 100/109, Loss: 0.07832301408052444, Uncertainty: 0.1371195912361145

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.238546688907321, Training Loss Force: 2.054326979120047, time: 1.6711370944976807
Validation Loss Energy: 1.6407013066981184, Validation Loss Force: 2.2319829688617063, time: 0.11011767387390137
Test Loss Energy: 10.562750185200462, Test Loss Force: 8.124689754693708, time: 9.52125334739685

Epoch 10, Batch 100/109, Loss: 0.2750113010406494, Uncertainty: 0.13614366948604584

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6383097966605846, Training Loss Force: 2.0419426094613953, time: 1.627434492111206
Validation Loss Energy: 1.3267943689030033, Validation Loss Force: 2.8281652820349703, time: 0.11156797409057617
Test Loss Energy: 10.778792837242284, Test Loss Force: 8.145076758791333, time: 9.739084482192993

Epoch 11, Batch 100/109, Loss: 0.279367059469223, Uncertainty: 0.13607054948806763

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4319213116637635, Training Loss Force: 2.0370780311938326, time: 1.6084785461425781
Validation Loss Energy: 1.610469331197881, Validation Loss Force: 2.170817164713267, time: 0.1140592098236084
Test Loss Energy: 11.166079571349739, Test Loss Force: 8.184903014821478, time: 9.610543251037598

Epoch 12, Batch 100/109, Loss: 0.09405076503753662, Uncertainty: 0.136982724070549

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5116828598522718, Training Loss Force: 2.0577675054645352, time: 1.6760830879211426
Validation Loss Energy: 0.7137210608828574, Validation Loss Force: 1.9218957347073606, time: 0.11202883720397949
Test Loss Energy: 11.517139191895337, Test Loss Force: 8.073993635003673, time: 9.646234035491943

Epoch 13, Batch 100/109, Loss: 0.23242273926734924, Uncertainty: 0.13325582444667816

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1606757427234373, Training Loss Force: 2.0351995656790782, time: 1.8476982116699219
Validation Loss Energy: 3.1988491408892394, Validation Loss Force: 2.402886065967251, time: 0.1143801212310791
Test Loss Energy: 14.190413502673156, Test Loss Force: 8.331543967926242, time: 9.682044267654419

Epoch 14, Batch 100/109, Loss: 0.14172394573688507, Uncertainty: 0.13515719771385193

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8991850416984024, Training Loss Force: 2.0466460437023195, time: 1.6619389057159424
Validation Loss Energy: 1.2529069197748448, Validation Loss Force: 2.0976548376588227, time: 0.11005258560180664
Test Loss Energy: 12.124119078976536, Test Loss Force: 8.078861453000888, time: 9.629335880279541

Epoch 15, Batch 100/109, Loss: 0.08234982192516327, Uncertainty: 0.13534721732139587

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9089965572178151, Training Loss Force: 2.0182312656544354, time: 1.6689839363098145
Validation Loss Energy: 3.3102399749240043, Validation Loss Force: 1.980380565227305, time: 0.11227178573608398
Test Loss Energy: 10.212368798552061, Test Loss Force: 8.080322733843628, time: 9.76790165901184

Epoch 16, Batch 100/109, Loss: 0.06163383275270462, Uncertainty: 0.13486206531524658

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9312506862095198, Training Loss Force: 2.039430819781882, time: 1.6509201526641846
Validation Loss Energy: 5.187522202003089, Validation Loss Force: 2.0426431633655358, time: 0.11098718643188477
Test Loss Energy: 9.928531048595909, Test Loss Force: 8.11195923733946, time: 9.685353517532349

Epoch 17, Batch 100/109, Loss: 0.169753298163414, Uncertainty: 0.1354455053806305

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6436721737643585, Training Loss Force: 2.0302063336732377, time: 1.6413235664367676
Validation Loss Energy: 1.6043052554542108, Validation Loss Force: 2.1221385720454102, time: 0.11234879493713379
Test Loss Energy: 12.076661331106095, Test Loss Force: 8.131272591437389, time: 9.611790180206299

Epoch 18, Batch 100/109, Loss: 0.06521435081958771, Uncertainty: 0.13347044587135315

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.775668835758261, Training Loss Force: 2.0105259357082113, time: 1.675419569015503
Validation Loss Energy: 3.6420642824383935, Validation Loss Force: 2.1787588824719277, time: 0.11061549186706543
Test Loss Energy: 14.52130475457467, Test Loss Force: 8.129993502919914, time: 9.830846309661865

Epoch 19, Batch 100/109, Loss: 0.12051217257976532, Uncertainty: 0.13331365585327148

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6150794983901495, Training Loss Force: 2.037802583316246, time: 1.6630322933197021
Validation Loss Energy: 0.8784570390997368, Validation Loss Force: 2.3312574839899565, time: 0.11113476753234863
Test Loss Energy: 11.127783336809038, Test Loss Force: 8.018228861404863, time: 10.135133981704712

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–…â–‚â–‚â–‚â–ƒâ–ƒâ–‡â–„â–â–â–„â–ˆâ–ƒ
wandb:   test_error_force â–„â–ƒâ–‚â–â–…â–…â–ƒâ–…â–ˆâ–„â–„â–…â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–„â–„â–
wandb:          test_loss â–‚â–‚â–‚â–â–„â–…â–‚â–…â–„â–‚â–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–†â–ƒ
wandb: train_error_energy â–…â–ƒâ–†â–ˆâ–„â–…â–â–„â–ƒâ–ˆâ–ƒâ–â–‚â–‡â–…â–…â–…â–ƒâ–„â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–ƒâ–‚â–â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–â–‚
wandb: valid_error_energy â–†â–â–ƒâ–â–ƒâ–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–…â–‚â–…â–ˆâ–‚â–†â–
wandb:  valid_error_force â–ƒâ–‚â–‚â–‚â–‡â–‚â–‚â–ƒâ–‚â–ƒâ–ˆâ–ƒâ–â–…â–‚â–â–‚â–ƒâ–ƒâ–„
wandb:         valid_loss â–…â–‚â–‚â–ƒâ–ˆâ–‚â–‚â–ƒâ–‚â–„â–ˆâ–ƒâ–â–†â–ƒâ–ƒâ–„â–ƒâ–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3476
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.12778
wandb:   test_error_force 8.01823
wandb:          test_loss 5.61321
wandb: train_error_energy 1.61508
wandb:  train_error_force 2.0378
wandb:         train_loss -2.37277
wandb: valid_error_energy 0.87846
wandb:  valid_error_force 2.33126
wandb:         valid_loss -2.05314
wandb: 
wandb: ğŸš€ View run al_58_36 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/0tgshe9n
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_024536-0tgshe9n/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.50185012817383, Uncertainty Bias: -5.539405822753906
1.2397766e-05 0.002532959
-1.0561358 19.620344
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1528 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 192 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 706 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 664 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2741 steps.
Found uncertainty sample 10 after 653 steps.
Found uncertainty sample 11 after 3393 steps.
Found uncertainty sample 12 after 3507 steps.
Found uncertainty sample 13 after 1812 steps.
Found uncertainty sample 14 after 2358 steps.
Found uncertainty sample 15 after 2260 steps.
Found uncertainty sample 16 after 3216 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 331 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 912 steps.
Found uncertainty sample 22 after 2322 steps.
Found uncertainty sample 23 after 2522 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 738 steps.
Found uncertainty sample 26 after 1921 steps.
Found uncertainty sample 27 after 2233 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1571 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1351 steps.
Found uncertainty sample 36 after 179 steps.
Found uncertainty sample 37 after 994 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2819 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1636 steps.
Found uncertainty sample 43 after 917 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1643 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3209 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 919 steps.
Found uncertainty sample 55 after 565 steps.
Found uncertainty sample 56 after 792 steps.
Found uncertainty sample 57 after 1217 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1251 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 218 steps.
Found uncertainty sample 67 after 2713 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3077 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 313 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2507 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 98 steps.
Found uncertainty sample 79 after 1995 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 503 steps.
Found uncertainty sample 82 after 1532 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 85 steps.
Found uncertainty sample 86 after 1167 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 870 steps.
Found uncertainty sample 95 after 2614 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2904 steps.
Found uncertainty sample 98 after 3702 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_031914-hdi1u47i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_37
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hdi1u47i
Training model 37. Added 48 samples to the dataset.
Epoch 0, Batch 100/110, Loss: 0.06884273886680603, Uncertainty: 0.13862593472003937

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8213545912856457, Training Loss Force: 2.2088916136590697, time: 1.6073315143585205
Validation Loss Energy: 2.6591444814430023, Validation Loss Force: 2.0462564898195548, time: 0.1131131649017334
Test Loss Energy: 10.685123556591776, Test Loss Force: 8.045424330210379, time: 10.186585187911987

Epoch 1, Batch 100/110, Loss: 0.10721761733293533, Uncertainty: 0.13611692190170288

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.149122958368901, Training Loss Force: 2.0176368099862234, time: 1.587538242340088
Validation Loss Energy: 2.640797954056477, Validation Loss Force: 3.437173931798064, time: 0.11389660835266113
Test Loss Energy: 13.515144332070507, Test Loss Force: 8.175161022847027, time: 9.676965713500977

Epoch 2, Batch 100/110, Loss: 0.24167375266551971, Uncertainty: 0.13866272568702698

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.174043753153155, Training Loss Force: 2.0453146131647575, time: 1.617405891418457
Validation Loss Energy: 1.370725506933583, Validation Loss Force: 2.206733178390079, time: 0.11896347999572754
Test Loss Energy: 12.059117016921565, Test Loss Force: 8.055205061952993, time: 9.891346216201782

Epoch 3, Batch 100/110, Loss: 0.09554445743560791, Uncertainty: 0.1370469629764557

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6062687479344722, Training Loss Force: 2.0771412799742732, time: 1.6612014770507812
Validation Loss Energy: 1.0019617612361735, Validation Loss Force: 2.140646905677976, time: 0.11485719680786133
Test Loss Energy: 12.04828007565267, Test Loss Force: 8.021778268212918, time: 9.694875001907349

Epoch 4, Batch 100/110, Loss: 0.1774853765964508, Uncertainty: 0.13631461560726166

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5170664718947886, Training Loss Force: 2.040866587463426, time: 1.6974718570709229
Validation Loss Energy: 0.7940411804119615, Validation Loss Force: 2.1318545917818716, time: 0.11131596565246582
Test Loss Energy: 11.64546745904913, Test Loss Force: 8.15982529280672, time: 9.86720609664917

Epoch 5, Batch 100/110, Loss: 0.15472225844860077, Uncertainty: 0.13781708478927612

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7828855521933982, Training Loss Force: 2.0418521332488924, time: 1.6177570819854736
Validation Loss Energy: 2.124356282515802, Validation Loss Force: 2.1167815235096303, time: 0.11195063591003418
Test Loss Energy: 12.709445293950912, Test Loss Force: 8.125814406420087, time: 9.79046082496643

Epoch 6, Batch 100/110, Loss: 0.1891014575958252, Uncertainty: 0.13346877694129944

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6333412275701316, Training Loss Force: 2.00335893236988, time: 1.681403398513794
Validation Loss Energy: 1.0579217463104427, Validation Loss Force: 2.135733562526982, time: 0.11431622505187988
Test Loss Energy: 11.342760413230765, Test Loss Force: 8.116007824072017, time: 9.734669208526611

Epoch 7, Batch 100/110, Loss: 0.255792498588562, Uncertainty: 0.13400226831436157

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.989500646419328, Training Loss Force: 2.0352260298235016, time: 1.650974988937378
Validation Loss Energy: 1.5014524842624253, Validation Loss Force: 1.9684829074220918, time: 0.11169266700744629
Test Loss Energy: 12.145525217604735, Test Loss Force: 8.05076237181667, time: 9.910899639129639

Epoch 8, Batch 100/110, Loss: 0.06242024153470993, Uncertainty: 0.13430123031139374

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.070236765218669, Training Loss Force: 2.020152954128956, time: 1.637526035308838
Validation Loss Energy: 1.7553961797432087, Validation Loss Force: 2.2037695262808286, time: 0.11912131309509277
Test Loss Energy: 12.898132288304156, Test Loss Force: 8.076851214604366, time: 9.715294122695923

Epoch 9, Batch 100/110, Loss: 0.052381303161382675, Uncertainty: 0.13694848120212555

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.051005320957007, Training Loss Force: 2.0340051348963795, time: 1.6932756900787354
Validation Loss Energy: 1.6065143189394362, Validation Loss Force: 2.2649258298790413, time: 0.1171426773071289
Test Loss Energy: 10.775775364873518, Test Loss Force: 8.001321735383026, time: 9.794808864593506

Epoch 10, Batch 100/110, Loss: 0.06254994869232178, Uncertainty: 0.13479985296726227

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6339642133308738, Training Loss Force: 2.051724424890986, time: 1.6355869770050049
Validation Loss Energy: 2.2765430730064833, Validation Loss Force: 1.9324345169380257, time: 0.11148476600646973
Test Loss Energy: 12.876409497829144, Test Loss Force: 8.017564817711039, time: 9.96755075454712

Epoch 11, Batch 100/110, Loss: 0.09223371744155884, Uncertainty: 0.13311782479286194

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9806319539697725, Training Loss Force: 2.0350361760368885, time: 1.6627397537231445
Validation Loss Energy: 6.316313302726261, Validation Loss Force: 2.2018614001463255, time: 0.1136624813079834
Test Loss Energy: 16.33517137586435, Test Loss Force: 8.06781559910922, time: 9.753706455230713

Epoch 12, Batch 100/110, Loss: 0.047794409096241, Uncertainty: 0.1338692009449005

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7880168482903336, Training Loss Force: 2.014141475237877, time: 1.611987829208374
Validation Loss Energy: 0.8630942782686439, Validation Loss Force: 2.2222585619207478, time: 0.11133861541748047
Test Loss Energy: 10.897940280638418, Test Loss Force: 8.036265554195587, time: 9.934065818786621

Epoch 13, Batch 100/110, Loss: 0.09931915998458862, Uncertainty: 0.13489603996276855

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.838933958679449, Training Loss Force: 2.030090629529354, time: 1.6564571857452393
Validation Loss Energy: 0.7141586614218919, Validation Loss Force: 1.9362149565860634, time: 0.11348342895507812
Test Loss Energy: 11.156793927548893, Test Loss Force: 7.983754454799671, time: 9.706794738769531

Epoch 14, Batch 100/110, Loss: 0.08759741485118866, Uncertainty: 0.13307076692581177

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4016720913187606, Training Loss Force: 1.9887413567773036, time: 1.6718239784240723
Validation Loss Energy: 1.3098648708496379, Validation Loss Force: 2.17043536135105, time: 0.11169242858886719
Test Loss Energy: 11.934261633001274, Test Loss Force: 8.02121302433469, time: 9.794397354125977

Epoch 15, Batch 100/110, Loss: 0.2740890681743622, Uncertainty: 0.1366966962814331

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.077074715057363, Training Loss Force: 2.0494890695776666, time: 1.6259641647338867
Validation Loss Energy: 2.146292310757732, Validation Loss Force: 2.0830439563104792, time: 0.11720538139343262
Test Loss Energy: 10.399491792803675, Test Loss Force: 8.080375456301509, time: 10.448400020599365

Epoch 16, Batch 100/110, Loss: 0.08361518383026123, Uncertainty: 0.1361653208732605

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.783908378706521, Training Loss Force: 2.0887130199869897, time: 1.7063946723937988
Validation Loss Energy: 0.8947116640833196, Validation Loss Force: 2.0648644678949237, time: 0.12154626846313477
Test Loss Energy: 11.67589155352733, Test Loss Force: 8.024422899166838, time: 9.88662338256836

Epoch 17, Batch 100/110, Loss: 0.14855559170246124, Uncertainty: 0.1383891999721527

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7209133372257492, Training Loss Force: 2.0130023241784896, time: 1.6485538482666016
Validation Loss Energy: 2.0711518652339134, Validation Loss Force: 1.9972870541355912, time: 0.11484432220458984
Test Loss Energy: 12.55254377224955, Test Loss Force: 8.01714500126705, time: 9.77297067642212

Epoch 18, Batch 100/110, Loss: 0.15394467115402222, Uncertainty: 0.13477039337158203

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.066648742414065, Training Loss Force: 1.995292244589465, time: 1.8747453689575195
Validation Loss Energy: 3.279617400630285, Validation Loss Force: 2.2127079111366617, time: 0.11598563194274902
Test Loss Energy: 10.153224777010124, Test Loss Force: 8.03571371943001, time: 9.803467273712158

Epoch 19, Batch 100/110, Loss: 0.13027945160865784, Uncertainty: 0.13427606225013733

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0591234367070053, Training Loss Force: 1.9990992442807047, time: 1.6612915992736816
Validation Loss Energy: 1.9985128106723993, Validation Loss Force: 2.093279537387439, time: 0.11718893051147461
Test Loss Energy: 10.35892276612984, Test Loss Force: 8.022776303967564, time: 9.804287672042847

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–„â–‚â–„â–ˆâ–‚â–‚â–ƒâ–â–ƒâ–„â–â–
wandb:   test_error_force â–ƒâ–ˆâ–„â–‚â–‡â–†â–†â–ƒâ–„â–‚â–‚â–„â–ƒâ–â–‚â–…â–‚â–‚â–ƒâ–‚
wandb:          test_loss â–â–†â–‚â–‚â–ƒâ–„â–†â–„â–…â–â–„â–ˆâ–ƒâ–‚â–„â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–…â–…â–‚â–‚â–ƒâ–‚â–„â–„â–„â–‚â–„â–ƒâ–ƒâ–â–„â–ˆâ–ƒâ–„â–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–„â–ƒâ–ƒâ–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–ƒâ–„â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–…â–‚â–‚â–‚
wandb: valid_error_energy â–ƒâ–ƒâ–‚â–â–â–ƒâ–â–‚â–‚â–‚â–ƒâ–ˆâ–â–â–‚â–ƒâ–â–ƒâ–„â–ƒ
wandb:  valid_error_force â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–‚â–‚â–â–‚â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–‚â–ˆâ–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–„â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 3519
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.35892
wandb:   test_error_force 8.02278
wandb:          test_loss 5.58891
wandb: train_error_energy 2.05912
wandb:  train_error_force 1.9991
wandb:         train_loss -2.39111
wandb: valid_error_energy 1.99851
wandb:  valid_error_force 2.09328
wandb:         valid_loss -2.27662
wandb: 
wandb: ğŸš€ View run al_58_37 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/hdi1u47i
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_031914-hdi1u47i/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.493499755859375, Uncertainty Bias: -5.537066459655762
0.00010204315 0.0021896362
-1.2593526 18.1415
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 912 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 355 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2805 steps.
Found uncertainty sample 7 after 1281 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2132 steps.
Found uncertainty sample 10 after 1242 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 799 steps.
Found uncertainty sample 14 after 3935 steps.
Found uncertainty sample 15 after 3370 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2903 steps.
Found uncertainty sample 18 after 2350 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2674 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2718 steps.
Found uncertainty sample 25 after 2932 steps.
Found uncertainty sample 26 after 3092 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 402 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2363 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1288 steps.
Found uncertainty sample 33 after 719 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 109 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3489 steps.
Found uncertainty sample 39 after 2837 steps.
Found uncertainty sample 40 after 3386 steps.
Found uncertainty sample 41 after 1682 steps.
Found uncertainty sample 42 after 2661 steps.
Found uncertainty sample 43 after 1088 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 994 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1811 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 439 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3406 steps.
Found uncertainty sample 57 after 2521 steps.
Found uncertainty sample 58 after 3988 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1485 steps.
Found uncertainty sample 66 after 2622 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2582 steps.
Found uncertainty sample 71 after 873 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 976 steps.
Found uncertainty sample 74 after 1870 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2762 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 511 steps.
Found uncertainty sample 81 after 1220 steps.
Found uncertainty sample 82 after 207 steps.
Found uncertainty sample 83 after 1488 steps.
Found uncertainty sample 84 after 2059 steps.
Found uncertainty sample 85 after 1964 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1047 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1265 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 15 steps.
Found uncertainty sample 95 after 59 steps.
Found uncertainty sample 96 after 2539 steps.
Found uncertainty sample 97 after 508 steps.
Found uncertainty sample 98 after 959 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_035304-w1kh6o5d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_38
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w1kh6o5d
Training model 38. Added 52 samples to the dataset.
Epoch 0, Batch 100/112, Loss: 0.08539852499961853, Uncertainty: 0.13717396557331085

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.8892009170173205, Training Loss Force: 2.1290995727098863, time: 1.6560049057006836
Validation Loss Energy: 0.9556622213906953, Validation Loss Force: 2.0432737623868036, time: 0.1160120964050293
Test Loss Energy: 10.8832433755539, Test Loss Force: 7.992856488653884, time: 9.724493980407715

Epoch 1, Batch 100/112, Loss: 0.10057036578655243, Uncertainty: 0.135492205619812

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.140910995923987, Training Loss Force: 1.998932726907389, time: 1.6180593967437744
Validation Loss Energy: 2.8575659222788867, Validation Loss Force: 2.083058504028013, time: 0.11152076721191406
Test Loss Energy: 13.43316027586516, Test Loss Force: 8.031911414099307, time: 9.676620483398438

Epoch 2, Batch 100/112, Loss: 0.16080345213413239, Uncertainty: 0.1372126042842865

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4378727674783858, Training Loss Force: 2.041493598113571, time: 1.6439926624298096
Validation Loss Energy: 1.4084644386850567, Validation Loss Force: 2.1629455135125255, time: 0.1135714054107666
Test Loss Energy: 10.920238322279344, Test Loss Force: 8.044984795306, time: 9.951902866363525

Epoch 3, Batch 100/112, Loss: 0.0586019828915596, Uncertainty: 0.13512390851974487

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8398187723502077, Training Loss Force: 2.0506016648110705, time: 1.652137041091919
Validation Loss Energy: 3.6790279544467954, Validation Loss Force: 2.419006792571082, time: 0.11377429962158203
Test Loss Energy: 10.038619000768582, Test Loss Force: 8.260120708274622, time: 9.687392711639404

Epoch 4, Batch 100/112, Loss: 0.19584962725639343, Uncertainty: 0.13487458229064941

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8856926259470466, Training Loss Force: 2.0283685233621886, time: 1.6517176628112793
Validation Loss Energy: 2.1580712116851175, Validation Loss Force: 2.0908600144477876, time: 0.12309861183166504
Test Loss Energy: 13.224206644660255, Test Loss Force: 7.909088188079635, time: 9.855329990386963

Epoch 5, Batch 100/112, Loss: 0.05568435415625572, Uncertainty: 0.13484534621238708

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8317851454164185, Training Loss Force: 2.014176204340903, time: 1.7628185749053955
Validation Loss Energy: 1.6455972816557303, Validation Loss Force: 2.3711025689697127, time: 0.12209796905517578
Test Loss Energy: 10.825957426609518, Test Loss Force: 8.011309439845489, time: 9.833965539932251

Epoch 6, Batch 100/112, Loss: 0.10604877769947052, Uncertainty: 0.13557341694831848

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.0081717658097156, Training Loss Force: 2.0511459785442328, time: 1.6828382015228271
Validation Loss Energy: 1.5918989470966494, Validation Loss Force: 2.2131671291386135, time: 0.11279010772705078
Test Loss Energy: 10.82879440873131, Test Loss Force: 8.146607048416397, time: 9.651461601257324

Epoch 7, Batch 100/112, Loss: 0.10061106085777283, Uncertainty: 0.1382881999015808

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 3.004505509375486, Training Loss Force: 2.0716616808230426, time: 1.633842945098877
Validation Loss Energy: 1.4583300805698551, Validation Loss Force: 2.051593869247444, time: 0.11393141746520996
Test Loss Energy: 12.186592291038629, Test Loss Force: 7.941647675004059, time: 10.480023622512817

Epoch 8, Batch 100/112, Loss: 0.04896362125873566, Uncertainty: 0.1339745819568634

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.855274982319012, Training Loss Force: 2.0232513319097443, time: 1.6523334980010986
Validation Loss Energy: 2.291329046526575, Validation Loss Force: 2.1045316773386076, time: 0.11339330673217773
Test Loss Energy: 10.322546904915269, Test Loss Force: 7.91017389485581, time: 9.613501071929932

Epoch 9, Batch 100/112, Loss: 0.06852194666862488, Uncertainty: 0.13578762114048004

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8871243960108024, Training Loss Force: 2.0622402649580533, time: 1.6797006130218506
Validation Loss Energy: 2.1497356664303595, Validation Loss Force: 2.2015204194608606, time: 0.11514735221862793
Test Loss Energy: 10.38616181047115, Test Loss Force: 8.099522682895277, time: 9.665152788162231

Epoch 10, Batch 100/112, Loss: 0.04803483933210373, Uncertainty: 0.1339571177959442

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.6804953358296424, Training Loss Force: 2.0379966080044767, time: 1.726454257965088
Validation Loss Energy: 0.9358382285536524, Validation Loss Force: 1.985044110708092, time: 0.11395835876464844
Test Loss Energy: 11.391459838870553, Test Loss Force: 7.981556763956487, time: 9.97722339630127

Epoch 11, Batch 100/112, Loss: 0.06300962716341019, Uncertainty: 0.1345377415418625

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6076655267077054, Training Loss Force: 2.018446596960088, time: 1.6782991886138916
Validation Loss Energy: 1.54480045179982, Validation Loss Force: 2.0732911219418906, time: 0.11559081077575684
Test Loss Energy: 10.406378000520286, Test Loss Force: 7.986348452421939, time: 9.698396444320679

Epoch 12, Batch 100/112, Loss: 0.1136106625199318, Uncertainty: 0.13759812712669373

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5119647518000507, Training Loss Force: 1.9964998726466838, time: 1.7135083675384521
Validation Loss Energy: 1.8420744497324213, Validation Loss Force: 2.031911846546692, time: 0.11626243591308594
Test Loss Energy: 10.837853657466907, Test Loss Force: 8.021149718680439, time: 9.831959962844849

Epoch 13, Batch 100/112, Loss: 0.07064642012119293, Uncertainty: 0.13411960005760193

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6395123831835225, Training Loss Force: 2.0258528739534283, time: 1.6940772533416748
Validation Loss Energy: 0.9215295463478571, Validation Loss Force: 2.603433032247113, time: 0.12025022506713867
Test Loss Energy: 11.567064514940279, Test Loss Force: 8.013608098905376, time: 9.70925521850586

Epoch 14, Batch 100/112, Loss: 0.1495419442653656, Uncertainty: 0.13612638413906097

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9725004449779013, Training Loss Force: 2.0445540195165472, time: 1.6518373489379883
Validation Loss Energy: 0.8352225214921924, Validation Loss Force: 2.1100802955629336, time: 0.11419177055358887
Test Loss Energy: 11.511689538254004, Test Loss Force: 7.970461936842401, time: 9.682459592819214

Epoch 15, Batch 100/112, Loss: 0.07620662450790405, Uncertainty: 0.135206937789917

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4521116144105837, Training Loss Force: 2.031200766545993, time: 1.7369003295898438
Validation Loss Energy: 1.0277045597526475, Validation Loss Force: 2.316319130551002, time: 0.11641788482666016
Test Loss Energy: 11.599439041913508, Test Loss Force: 8.063184917923381, time: 9.855746269226074

Epoch 16, Batch 100/112, Loss: 0.05833161249756813, Uncertainty: 0.13424429297447205

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8608641876281826, Training Loss Force: 2.001292797185078, time: 1.631425142288208
Validation Loss Energy: 2.2607319307385403, Validation Loss Force: 2.1178291818412203, time: 0.11581182479858398
Test Loss Energy: 12.393493658834585, Test Loss Force: 7.934294906644114, time: 9.703736066818237

Epoch 17, Batch 100/112, Loss: 0.0693584531545639, Uncertainty: 0.1336939036846161

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.910213770406914, Training Loss Force: 2.0266620625762584, time: 1.6784584522247314
Validation Loss Energy: 2.3867530183373447, Validation Loss Force: 2.010221867711012, time: 0.11294126510620117
Test Loss Energy: 13.23392561427715, Test Loss Force: 7.933620941932322, time: 9.774857759475708

Epoch 18, Batch 100/112, Loss: 0.1431143879890442, Uncertainty: 0.13578718900680542

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.832529439900032, Training Loss Force: 2.0276132743518427, time: 1.8391845226287842
Validation Loss Energy: 3.1219320182500625, Validation Loss Force: 2.259452548049088, time: 0.13939809799194336
Test Loss Energy: 10.293882349023031, Test Loss Force: 8.091216289034325, time: 10.252665519714355

Epoch 19, Batch 100/112, Loss: 0.14984610676765442, Uncertainty: 0.13513389229774475

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.763147687851283, Training Loss Force: 2.0325760815317575, time: 1.7091686725616455
Validation Loss Energy: 0.9331499996221527, Validation Loss Force: 2.0278036008043245, time: 0.11049962043762207
Test Loss Energy: 11.125384040621647, Test Loss Force: 8.040818105324767, time: 9.672040224075317

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ˆâ–ƒâ–â–ˆâ–ƒâ–ƒâ–…â–‚â–‚â–„â–‚â–ƒâ–„â–„â–„â–†â–ˆâ–‚â–ƒ
wandb:   test_error_force â–ƒâ–ƒâ–„â–ˆâ–â–ƒâ–†â–‚â–â–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–„â–‚â–â–…â–„
wandb:          test_loss â–‚â–‡â–ƒâ–ˆâ–…â–„â–†â–â–â–„â–…â–„â–„â–…â–ƒâ–‡â–„â–„â–„â–…
wandb: train_error_energy â–ˆâ–ƒâ–„â–‚â–‚â–‚â–…â–…â–‚â–‚â–â–â–â–â–‚â–„â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–â–ƒâ–„â–ƒâ–‚â–„â–…â–‚â–„â–ƒâ–‚â–â–ƒâ–„â–ƒâ–â–ƒâ–ƒâ–ƒ
wandb:         train_loss â–ˆâ–‚â–„â–ƒâ–‚â–‚â–…â–…â–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–†â–‚â–ˆâ–„â–ƒâ–ƒâ–ƒâ–…â–„â–â–ƒâ–ƒâ–â–â–â–…â–…â–‡â–
wandb:  valid_error_force â–‚â–‚â–ƒâ–†â–‚â–…â–„â–‚â–‚â–ƒâ–â–‚â–‚â–ˆâ–‚â–…â–ƒâ–â–„â–
wandb:         valid_loss â–‚â–ƒâ–ƒâ–ˆâ–ƒâ–†â–„â–‚â–ƒâ–„â–â–‚â–‚â–ˆâ–‚â–…â–ƒâ–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 3565
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.12538
wandb:   test_error_force 8.04082
wandb:          test_loss 5.58886
wandb: train_error_energy 1.76315
wandb:  train_error_force 2.03258
wandb:         train_loss -2.36941
wandb: valid_error_energy 0.93315
wandb:  valid_error_force 2.0278
wandb:         valid_loss -2.43054
wandb: 
wandb: ğŸš€ View run al_58_38 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/w1kh6o5d
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_035304-w1kh6o5d/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 46.2909049987793, Uncertainty Bias: -6.116397380828857
1.5258789e-05 0.0014438629
-1.4219615 21.373188
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 499 steps.
Found uncertainty sample 1 after 126 steps.
Found uncertainty sample 2 after 233 steps.
Found uncertainty sample 3 after 1463 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2440 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3433 steps.
Found uncertainty sample 8 after 3024 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3458 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 638 steps.
Found uncertainty sample 15 after 1357 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 982 steps.
Found uncertainty sample 18 after 1658 steps.
Found uncertainty sample 19 after 3722 steps.
Found uncertainty sample 20 after 2359 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 264 steps.
Found uncertainty sample 23 after 2220 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1798 steps.
Found uncertainty sample 27 after 3822 steps.
Found uncertainty sample 28 after 847 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2360 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2343 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 29 steps.
Found uncertainty sample 37 after 130 steps.
Found uncertainty sample 38 after 2822 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 758 steps.
Found uncertainty sample 41 after 3360 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3734 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1572 steps.
Found uncertainty sample 51 after 38 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1798 steps.
Found uncertainty sample 55 after 3675 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2567 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1367 steps.
Found uncertainty sample 63 after 1503 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 241 steps.
Found uncertainty sample 66 after 711 steps.
Found uncertainty sample 67 after 1046 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1506 steps.
Found uncertainty sample 70 after 3902 steps.
Found uncertainty sample 71 after 1705 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2154 steps.
Found uncertainty sample 74 after 1197 steps.
Found uncertainty sample 75 after 578 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1881 steps.
Found uncertainty sample 78 after 1576 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 628 steps.
Found uncertainty sample 82 after 481 steps.
Found uncertainty sample 83 after 3440 steps.
Found uncertainty sample 84 after 3263 steps.
Found uncertainty sample 85 after 2672 steps.
Found uncertainty sample 86 after 2303 steps.
Found uncertainty sample 87 after 1033 steps.
Found uncertainty sample 88 after 741 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3872 steps.
Found uncertainty sample 91 after 348 steps.
Found uncertainty sample 92 after 142 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3636 steps.
Found uncertainty sample 97 after 1044 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 842 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_042509-bua3pydo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_39
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bua3pydo
Training model 39. Added 59 samples to the dataset.
Epoch 0, Batch 100/114, Loss: 0.31643742322921753, Uncertainty: 0.13674314320087433

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.949773996743378, Training Loss Force: 2.1572290291208844, time: 1.6742472648620605
Validation Loss Energy: 2.084331503535282, Validation Loss Force: 2.157658828426859, time: 0.1193246841430664
Test Loss Energy: 10.108810531648192, Test Loss Force: 7.924643003575007, time: 9.531251907348633

Epoch 1, Batch 100/114, Loss: 0.1979212909936905, Uncertainty: 0.13658423721790314

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9095170666224663, Training Loss Force: 2.057319814147929, time: 1.698012351989746
Validation Loss Energy: 2.4513363485374833, Validation Loss Force: 2.2322684307067857, time: 0.11624789237976074
Test Loss Energy: 13.128334277811556, Test Loss Force: 7.951263361111453, time: 9.655304431915283

Epoch 2, Batch 100/114, Loss: 0.05366423726081848, Uncertainty: 0.135660782456398

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6055599135672032, Training Loss Force: 2.0526132446910244, time: 1.6506626605987549
Validation Loss Energy: 0.7840668273546992, Validation Loss Force: 2.211230946691723, time: 0.11417412757873535
Test Loss Energy: 11.538645478012082, Test Loss Force: 7.910830419094183, time: 9.733205795288086

Epoch 3, Batch 100/114, Loss: 0.09760089963674545, Uncertainty: 0.13539813458919525

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5285669296009092, Training Loss Force: 2.0454922678251113, time: 1.698584794998169
Validation Loss Energy: 0.9988350225332935, Validation Loss Force: 2.1842697211644944, time: 0.1114344596862793
Test Loss Energy: 11.091517774930777, Test Loss Force: 7.984675211536803, time: 9.642909526824951

Epoch 4, Batch 100/114, Loss: 0.15810784697532654, Uncertainty: 0.1319052278995514

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6796271143166503, Training Loss Force: 2.0155674565987285, time: 1.7382478713989258
Validation Loss Energy: 0.7725667824210639, Validation Loss Force: 2.103344182783375, time: 0.11367154121398926
Test Loss Energy: 11.240621950086531, Test Loss Force: 7.903733414810609, time: 9.728737592697144

Epoch 5, Batch 100/114, Loss: 0.2030857801437378, Uncertainty: 0.13384826481342316

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.033061159203113, Training Loss Force: 2.021959081653775, time: 1.7375171184539795
Validation Loss Energy: 4.5127111826889506, Validation Loss Force: 2.21649625553938, time: 0.12104916572570801
Test Loss Energy: 14.98692547297255, Test Loss Force: 8.093531826648634, time: 9.617907285690308

Epoch 6, Batch 100/114, Loss: 0.06231766566634178, Uncertainty: 0.13386307656764984

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.488674789161552, Training Loss Force: 2.007422897014319, time: 1.7156758308410645
Validation Loss Energy: 0.8022550555342322, Validation Loss Force: 2.0447391851476784, time: 0.11241888999938965
Test Loss Energy: 11.22231537063287, Test Loss Force: 7.971735170676885, time: 9.638530969619751

Epoch 7, Batch 100/114, Loss: 0.17261174321174622, Uncertainty: 0.13543885946273804

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5726305528434588, Training Loss Force: 2.032209466322463, time: 1.7185447216033936
Validation Loss Energy: 1.490963468585875, Validation Loss Force: 2.123115495811644, time: 0.1276698112487793
Test Loss Energy: 12.564272826376438, Test Loss Force: 8.012764975591102, time: 9.826143503189087

Epoch 8, Batch 100/114, Loss: 0.12572672963142395, Uncertainty: 0.13637524843215942

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9020652346575138, Training Loss Force: 2.0404764158076083, time: 1.6756150722503662
Validation Loss Energy: 2.9655314368418444, Validation Loss Force: 2.1018229071783963, time: 0.11980009078979492
Test Loss Energy: 10.288807040687635, Test Loss Force: 7.927548803286766, time: 9.563628911972046

Epoch 9, Batch 100/114, Loss: 0.0877232477068901, Uncertainty: 0.1373952329158783

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8716610939128546, Training Loss Force: 2.0312091779218115, time: 1.7515311241149902
Validation Loss Energy: 3.071461532741876, Validation Loss Force: 2.129219450885914, time: 0.11193013191223145
Test Loss Energy: 13.925214270079469, Test Loss Force: 7.987676630742537, time: 9.609738826751709

Epoch 10, Batch 100/114, Loss: 0.04347541183233261, Uncertainty: 0.1363483965396881

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.265833182233221, Training Loss Force: 2.055500313263362, time: 1.6781425476074219
Validation Loss Energy: 3.2946193632219267, Validation Loss Force: 1.9901500255587894, time: 0.12085533142089844
Test Loss Energy: 13.760611072621984, Test Loss Force: 7.961211502745979, time: 9.82758092880249

Epoch 11, Batch 100/114, Loss: 0.07953287661075592, Uncertainty: 0.13614597916603088

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.2673089858069515, Training Loss Force: 2.0253875673245783, time: 1.7246127128601074
Validation Loss Energy: 0.7577556287317204, Validation Loss Force: 2.226257328666368, time: 0.1143350601196289
Test Loss Energy: 11.35102578467336, Test Loss Force: 7.954022991935692, time: 9.725463390350342

Epoch 12, Batch 100/114, Loss: 0.07926200330257416, Uncertainty: 0.1359306126832962

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.938393070524933, Training Loss Force: 2.025968426160446, time: 1.7098870277404785
Validation Loss Energy: 0.9552612128146413, Validation Loss Force: 2.1323243494567308, time: 0.11336040496826172
Test Loss Energy: 10.867927604130236, Test Loss Force: 7.9317330130162995, time: 9.796117067337036

Epoch 13, Batch 100/114, Loss: 0.05526978522539139, Uncertainty: 0.13570570945739746

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6858280686609957, Training Loss Force: 2.028434552385073, time: 1.7067320346832275
Validation Loss Energy: 1.4341283195450611, Validation Loss Force: 2.481055850998368, time: 0.11256957054138184
Test Loss Energy: 11.64321579600291, Test Loss Force: 7.962857981364551, time: 9.636196613311768

Epoch 14, Batch 100/114, Loss: 0.05241124704480171, Uncertainty: 0.13482698798179626

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.658564402278001, Training Loss Force: 2.0336537394209513, time: 1.688326358795166
Validation Loss Energy: 5.092280225107591, Validation Loss Force: 2.3055530773453934, time: 0.11224675178527832
Test Loss Energy: 15.389176557627499, Test Loss Force: 7.937038978607507, time: 9.633876323699951

Epoch 15, Batch 100/114, Loss: 0.10100816935300827, Uncertainty: 0.13553625345230103

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6209408043545463, Training Loss Force: 2.0238731514918844, time: 1.7438914775848389
Validation Loss Energy: 2.331003492717502, Validation Loss Force: 2.1797024058662724, time: 0.11302924156188965
Test Loss Energy: 12.653880528540652, Test Loss Force: 7.910662064898564, time: 10.323723077774048

Epoch 16, Batch 100/114, Loss: 0.3190363645553589, Uncertainty: 0.1333499550819397

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7698902071559646, Training Loss Force: 2.041635243663541, time: 1.7336037158966064
Validation Loss Energy: 3.4988743645658755, Validation Loss Force: 2.4521435984145206, time: 0.11273670196533203
Test Loss Energy: 10.078086750147325, Test Loss Force: 8.02995279064397, time: 9.615171432495117

Epoch 17, Batch 100/114, Loss: 0.16403749585151672, Uncertainty: 0.13670121133327484

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2257572982421627, Training Loss Force: 2.052612278814773, time: 1.7887060642242432
Validation Loss Energy: 1.932954783397486, Validation Loss Force: 2.283221217585052, time: 0.11208724975585938
Test Loss Energy: 10.474296576053776, Test Loss Force: 8.050259155868172, time: 9.61889386177063

Epoch 18, Batch 100/114, Loss: 0.41182032227516174, Uncertainty: 0.1362863928079605

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5802726448507969, Training Loss Force: 2.027911317980286, time: 1.7264995574951172
Validation Loss Energy: 2.360267562551915, Validation Loss Force: 2.137248826065021, time: 0.1678776741027832
Test Loss Energy: 12.644962575619124, Test Loss Force: 8.058458391077002, time: 9.74317193031311

Epoch 19, Batch 100/114, Loss: 0.15817055106163025, Uncertainty: 0.13652625679969788

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6911301413565878, Training Loss Force: 2.040746212682948, time: 1.7381641864776611
Validation Loss Energy: 3.5916410027891437, Validation Loss Force: 2.230729415793182, time: 0.11096453666687012
Test Loss Energy: 14.343858411144152, Test Loss Force: 7.888457043001896, time: 9.56828260421753

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–…â–ƒâ–‚â–ƒâ–‡â–ƒâ–„â–â–†â–†â–ƒâ–‚â–ƒâ–ˆâ–„â–â–‚â–„â–‡
wandb:   test_error_force â–‚â–ƒâ–‚â–„â–‚â–ˆâ–„â–…â–‚â–„â–ƒâ–ƒâ–‚â–„â–ƒâ–‚â–†â–‡â–‡â–
wandb:          test_loss â–â–ƒâ–â–ƒâ–ƒâ–ˆâ–„â–…â–â–„â–ƒâ–‚â–‚â–„â–…â–ƒâ–„â–ƒâ–„â–„
wandb: train_error_energy â–†â–†â–ƒâ–ƒâ–„â–†â–ƒâ–ƒâ–…â–…â–ˆâ–â–†â–„â–„â–ƒâ–…â–ˆâ–ƒâ–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–â–‚â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒ
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–ƒâ–ƒâ–…â–â–ƒâ–‚â–‚â–‚â–ƒâ–„â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–„â–â–â–â–‡â–â–‚â–…â–…â–…â–â–â–‚â–ˆâ–„â–…â–ƒâ–„â–†
wandb:  valid_error_force â–ƒâ–„â–„â–„â–ƒâ–„â–‚â–ƒâ–ƒâ–ƒâ–â–„â–ƒâ–ˆâ–…â–„â–ˆâ–…â–ƒâ–„
wandb:         valid_loss â–ƒâ–„â–ƒâ–ƒâ–‚â–†â–â–‚â–ƒâ–„â–‚â–ƒâ–‚â–‡â–‡â–„â–ˆâ–…â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3618
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 14.34386
wandb:   test_error_force 7.88846
wandb:          test_loss 5.57223
wandb: train_error_energy 1.69113
wandb:  train_error_force 2.04075
wandb:         train_loss -2.36428
wandb: valid_error_energy 3.59164
wandb:  valid_error_force 2.23073
wandb:         valid_loss -2.00179
wandb: 
wandb: ğŸš€ View run al_58_39 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bua3pydo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_042509-bua3pydo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.78621292114258, Uncertainty Bias: -5.2384033203125
9.1552734e-05 0.04131794
-0.9321678 18.974403
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 273 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1355 steps.
Found uncertainty sample 4 after 1534 steps.
Found uncertainty sample 5 after 3030 steps.
Found uncertainty sample 6 after 1024 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2447 steps.
Found uncertainty sample 11 after 1656 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2970 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2129 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 34 steps.
Found uncertainty sample 22 after 2663 steps.
Found uncertainty sample 23 after 2547 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3635 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3167 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 671 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2891 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2710 steps.
Found uncertainty sample 53 after 2604 steps.
Found uncertainty sample 54 after 777 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1705 steps.
Found uncertainty sample 58 after 2401 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3631 steps.
Found uncertainty sample 61 after 1568 steps.
Found uncertainty sample 62 after 1 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1583 steps.
Found uncertainty sample 65 after 439 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1699 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 913 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2568 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2112 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1618 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3111 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 702 steps.
Found uncertainty sample 89 after 1953 steps.
Found uncertainty sample 90 after 1117 steps.
Found uncertainty sample 91 after 2178 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2527 steps.
Found uncertainty sample 94 after 1564 steps.
Found uncertainty sample 95 after 3278 steps.
Found uncertainty sample 96 after 1007 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2572 steps.
Found uncertainty sample 99 after 1409 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_045948-z9v3q613
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_40
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/z9v3q613
Training model 40. Added 43 samples to the dataset.
Epoch 0, Batch 100/115, Loss: 0.061867933720350266, Uncertainty: 0.13840311765670776

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0354231233215994, Training Loss Force: 2.1417477535370595, time: 1.7247164249420166
Validation Loss Energy: 2.4837530423629914, Validation Loss Force: 2.034978149132215, time: 0.11321067810058594
Test Loss Energy: 13.09023624912171, Test Loss Force: 7.8864398727166725, time: 8.598066329956055

Epoch 1, Batch 100/115, Loss: 0.1108689159154892, Uncertainty: 0.1363528072834015

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7383068630079617, Training Loss Force: 2.0209952757753236, time: 1.6949141025543213
Validation Loss Energy: 1.2259665138127607, Validation Loss Force: 2.078023657746391, time: 0.10714268684387207
Test Loss Energy: 10.467368133479479, Test Loss Force: 7.893986827224779, time: 8.562788724899292

Epoch 2, Batch 100/115, Loss: 0.140598863363266, Uncertainty: 0.13954909145832062

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.349762648943764, Training Loss Force: 2.0271336445274506, time: 1.667085886001587
Validation Loss Energy: 1.5217343034192579, Validation Loss Force: 2.106020220579135, time: 0.10559749603271484
Test Loss Energy: 10.472260913737177, Test Loss Force: 7.838950426552635, time: 8.805413722991943

Epoch 3, Batch 100/115, Loss: 0.05286908894777298, Uncertainty: 0.1358007788658142

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6447725254658985, Training Loss Force: 2.039468132726892, time: 1.7190840244293213
Validation Loss Energy: 0.9363052399757116, Validation Loss Force: 2.232832154761226, time: 0.10901999473571777
Test Loss Energy: 11.564409431360374, Test Loss Force: 8.021744576389267, time: 8.555546045303345

Epoch 4, Batch 100/115, Loss: 0.07505287975072861, Uncertainty: 0.13262639939785004

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5584724925827707, Training Loss Force: 1.9971383621341183, time: 1.7167236804962158
Validation Loss Energy: 0.7607263320305918, Validation Loss Force: 2.0779888471365777, time: 0.11612558364868164
Test Loss Energy: 11.423215224374166, Test Loss Force: 7.9128252641744625, time: 8.556169271469116

Epoch 5, Batch 100/115, Loss: 0.11217501759529114, Uncertainty: 0.1366938352584839

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9789555980618012, Training Loss Force: 2.04571265754215, time: 1.7344319820404053
Validation Loss Energy: 3.6178652676663994, Validation Loss Force: 2.0697992986185, time: 0.11000728607177734
Test Loss Energy: 14.138315292495754, Test Loss Force: 7.894385976241444, time: 8.79738712310791

Epoch 6, Batch 100/115, Loss: 0.17083853483200073, Uncertainty: 0.13787101209163666

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.372643256644937, Training Loss Force: 2.079573901316419, time: 1.7270796298980713
Validation Loss Energy: 1.13913831326529, Validation Loss Force: 2.012142017979396, time: 0.11955738067626953
Test Loss Energy: 10.547199503656875, Test Loss Force: 7.851076200154296, time: 8.586934804916382

Epoch 7, Batch 100/115, Loss: 0.18092596530914307, Uncertainty: 0.13461244106292725

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.629987414224007, Training Loss Force: 2.021312531870061, time: 1.7574059963226318
Validation Loss Energy: 1.1636679174959381, Validation Loss Force: 2.272228561411938, time: 0.11136102676391602
Test Loss Energy: 10.633581692853223, Test Loss Force: 7.9702426578633645, time: 8.5218505859375

Epoch 8, Batch 100/115, Loss: 0.18954823911190033, Uncertainty: 0.1359873265028

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7583107586384308, Training Loss Force: 2.016812128972899, time: 1.6913461685180664
Validation Loss Energy: 0.7535430810502478, Validation Loss Force: 2.1846084009354505, time: 0.11601543426513672
Test Loss Energy: 11.272487998658255, Test Loss Force: 7.981763382270996, time: 8.74862027168274

Epoch 9, Batch 100/115, Loss: 0.12810778617858887, Uncertainty: 0.13597992062568665

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1791748912034032, Training Loss Force: 2.055651893738846, time: 1.7373371124267578
Validation Loss Energy: 1.0641739248128517, Validation Loss Force: 2.2018745376259345, time: 0.10628890991210938
Test Loss Energy: 10.59422858427623, Test Loss Force: 7.9291578338513835, time: 8.54685640335083

Epoch 10, Batch 100/115, Loss: 0.05708777531981468, Uncertainty: 0.13463085889816284

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7639291654069518, Training Loss Force: 2.0204661867770506, time: 1.7230751514434814
Validation Loss Energy: 4.8189612707860965, Validation Loss Force: 2.1430774136288266, time: 0.10818219184875488
Test Loss Energy: 9.612560140357488, Test Loss Force: 7.839162694368091, time: 8.55753469467163

Epoch 11, Batch 100/115, Loss: 0.20648251473903656, Uncertainty: 0.13368132710456848

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.062536072948661, Training Loss Force: 1.9865022082994845, time: 1.69533109664917
Validation Loss Energy: 2.0013823479559707, Validation Loss Force: 2.181829935332564, time: 0.10333847999572754
Test Loss Energy: 12.466126510914007, Test Loss Force: 7.967009809637554, time: 9.3094642162323

Epoch 12, Batch 100/115, Loss: 0.1729649007320404, Uncertainty: 0.1326666921377182

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1309740090487126, Training Loss Force: 1.9879020779092158, time: 1.6734304428100586
Validation Loss Energy: 1.582477036190434, Validation Loss Force: 2.2510202901619487, time: 0.10800814628601074
Test Loss Energy: 12.191958258386913, Test Loss Force: 7.972889674058503, time: 8.591280460357666

Epoch 13, Batch 100/115, Loss: 0.27302196621894836, Uncertainty: 0.13256794214248657

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.033541303051839, Training Loss Force: 2.0129565952848787, time: 1.6839995384216309
Validation Loss Energy: 0.8968641510497171, Validation Loss Force: 2.0986083069416854, time: 0.10722613334655762
Test Loss Energy: 10.712933221513412, Test Loss Force: 7.926625637992278, time: 8.643814086914062

Epoch 14, Batch 100/115, Loss: 0.20017826557159424, Uncertainty: 0.13712681829929352

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8664270022221605, Training Loss Force: 2.0634668691877716, time: 1.7195508480072021
Validation Loss Energy: 2.460416573639273, Validation Loss Force: 1.9834083831621065, time: 0.10706901550292969
Test Loss Energy: 9.98388528324321, Test Loss Force: 7.819667031364194, time: 8.681565523147583

Epoch 15, Batch 100/115, Loss: 0.0941881388425827, Uncertainty: 0.13484345376491547

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.074110743348946, Training Loss Force: 2.044188930640313, time: 1.6648292541503906
Validation Loss Energy: 0.8246467947390657, Validation Loss Force: 1.99227703546374, time: 0.10851192474365234
Test Loss Energy: 11.049128074749449, Test Loss Force: 7.858156796869495, time: 8.548048734664917

Epoch 16, Batch 100/115, Loss: 0.06232914701104164, Uncertainty: 0.1344900131225586

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9553179539895427, Training Loss Force: 2.035591702023589, time: 1.717473030090332
Validation Loss Energy: 0.7937740516598968, Validation Loss Force: 2.2927524961534425, time: 0.1084136962890625
Test Loss Energy: 11.48389739774389, Test Loss Force: 8.076791921657968, time: 8.526381254196167

Epoch 17, Batch 100/115, Loss: 0.1029849648475647, Uncertainty: 0.13340434432029724

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8900971688174037, Training Loss Force: 2.010786817091173, time: 1.8738279342651367
Validation Loss Energy: 1.1253504170802955, Validation Loss Force: 2.156984957368233, time: 0.14890122413635254
Test Loss Energy: 11.831382630568037, Test Loss Force: 7.824704446307341, time: 8.624119758605957

Epoch 18, Batch 100/115, Loss: 0.07629897445440292, Uncertainty: 0.13511154055595398

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0107807532294535, Training Loss Force: 2.0141814788940926, time: 1.6410996913909912
Validation Loss Energy: 3.83569507082269, Validation Loss Force: 2.3115680389843405, time: 0.10779643058776855
Test Loss Energy: 9.748659961741785, Test Loss Force: 7.858985366248599, time: 8.556388854980469

Epoch 19, Batch 100/115, Loss: 0.15265871584415436, Uncertainty: 0.13472574949264526

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9818615369100987, Training Loss Force: 2.001183980727004, time: 1.7837865352630615
Validation Loss Energy: 1.9521187292187125, Validation Loss Force: 2.058270306695894, time: 0.10741758346557617
Test Loss Energy: 12.17711818753383, Test Loss Force: 7.92347152137956, time: 8.512908220291138

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‚â–‚â–„â–„â–ˆâ–‚â–ƒâ–„â–ƒâ–â–…â–…â–ƒâ–‚â–ƒâ–„â–„â–â–…
wandb:   test_error_force â–ƒâ–ƒâ–‚â–‡â–„â–ƒâ–‚â–…â–…â–„â–‚â–…â–…â–„â–â–‚â–ˆâ–â–‚â–„
wandb:          test_loss â–„â–ƒâ–‚â–†â–†â–‡â–‚â–†â–†â–„â–ƒâ–ˆâ–ˆâ–…â–â–ƒâ–‡â–…â–ƒâ–†
wandb: train_error_energy â–ˆâ–‚â–…â–â–â–ƒâ–…â–â–‚â–„â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–â–„â–…â–ƒâ–‚â–„â–ƒâ–â–â–‚â–„â–„â–ƒâ–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–â–ƒâ–…â–‚â–‚â–„â–‚â–‚â–‚â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–„â–‚â–‚â–â–â–†â–‚â–‚â–â–‚â–ˆâ–ƒâ–‚â–â–„â–â–â–‚â–†â–ƒ
wandb:  valid_error_force â–‚â–ƒâ–„â–†â–ƒâ–ƒâ–‚â–‡â–…â–†â–„â–…â–‡â–ƒâ–â–â–ˆâ–…â–ˆâ–ƒ
wandb:         valid_loss â–ƒâ–ƒâ–ƒâ–…â–‚â–„â–‚â–…â–„â–„â–†â–…â–…â–ƒâ–‚â–â–…â–„â–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3656
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.17712
wandb:   test_error_force 7.92347
wandb:          test_loss 5.55611
wandb: train_error_energy 1.98186
wandb:  train_error_force 2.00118
wandb:         train_loss -2.3936
wandb: valid_error_energy 1.95212
wandb:  valid_error_force 2.05827
wandb:         valid_loss -2.32422
wandb: 
wandb: ğŸš€ View run al_58_40 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/z9v3q613
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_045948-z9v3q613/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.65433883666992, Uncertainty Bias: -5.710201263427734
2.2888184e-05 0.0071201324
-1.0883712 15.98835
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2139 steps.
Found uncertainty sample 3 after 1969 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3857 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1350 steps.
Found uncertainty sample 15 after 1374 steps.
Found uncertainty sample 16 after 1076 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3892 steps.
Found uncertainty sample 20 after 2529 steps.
Found uncertainty sample 21 after 1987 steps.
Found uncertainty sample 22 after 867 steps.
Found uncertainty sample 23 after 3270 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1116 steps.
Found uncertainty sample 26 after 3714 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 987 steps.
Found uncertainty sample 29 after 494 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 107 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 828 steps.
Found uncertainty sample 36 after 2099 steps.
Found uncertainty sample 37 after 1138 steps.
Found uncertainty sample 38 after 1927 steps.
Found uncertainty sample 39 after 3810 steps.
Found uncertainty sample 40 after 2097 steps.
Found uncertainty sample 41 after 1009 steps.
Found uncertainty sample 42 after 1571 steps.
Found uncertainty sample 43 after 3273 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3353 steps.
Found uncertainty sample 46 after 531 steps.
Found uncertainty sample 47 after 767 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3412 steps.
Found uncertainty sample 51 after 464 steps.
Found uncertainty sample 52 after 2904 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3208 steps.
Found uncertainty sample 56 after 1301 steps.
Found uncertainty sample 57 after 3321 steps.
Found uncertainty sample 58 after 1867 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 840 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1360 steps.
Found uncertainty sample 63 after 2917 steps.
Found uncertainty sample 64 after 2998 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 930 steps.
Found uncertainty sample 67 after 2543 steps.
Found uncertainty sample 68 after 3387 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1342 steps.
Found uncertainty sample 71 after 2118 steps.
Found uncertainty sample 72 after 1227 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3496 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1249 steps.
Found uncertainty sample 79 after 685 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1182 steps.
Found uncertainty sample 82 after 2843 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1738 steps.
Found uncertainty sample 85 after 1173 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1722 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1286 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1772 steps.
Found uncertainty sample 96 after 1387 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_053113-3djyow08
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_41
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3djyow08
Training model 41. Added 56 samples to the dataset.
Epoch 0, Batch 100/116, Loss: 0.09839987754821777, Uncertainty: 0.13616324961185455

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2307764311267007, Training Loss Force: 2.098741248419978, time: 1.7441036701202393
Validation Loss Energy: 1.665735813217158, Validation Loss Force: 2.043005297619863, time: 0.10696792602539062
Test Loss Energy: 10.251571401439323, Test Loss Force: 7.828321700753903, time: 8.355117321014404

Epoch 1, Batch 100/116, Loss: 0.10876075178384781, Uncertainty: 0.1351986527442932

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6892237483083805, Training Loss Force: 2.0155828155162605, time: 1.765352487564087
Validation Loss Energy: 1.1254115026493283, Validation Loss Force: 2.0025416377527194, time: 0.10689163208007812
Test Loss Energy: 10.290482291424121, Test Loss Force: 7.773449375765516, time: 8.426000833511353

Epoch 2, Batch 100/116, Loss: 0.07544127106666565, Uncertainty: 0.13445155322551727

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8084790049547816, Training Loss Force: 2.015860881290484, time: 1.702031135559082
Validation Loss Energy: 1.25805395419449, Validation Loss Force: 1.9635927960853223, time: 0.10449886322021484
Test Loss Energy: 10.545960082889975, Test Loss Force: 7.8034335762707725, time: 8.531554460525513

Epoch 3, Batch 100/116, Loss: 0.10889483988285065, Uncertainty: 0.13589394092559814

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.392154033311892, Training Loss Force: 2.050202529407214, time: 1.7329223155975342
Validation Loss Energy: 1.3562530886824822, Validation Loss Force: 2.057335318952143, time: 0.10286927223205566
Test Loss Energy: 11.800528157434, Test Loss Force: 7.841801645510079, time: 8.391274213790894

Epoch 4, Batch 100/116, Loss: 0.279285728931427, Uncertainty: 0.13595522940158844

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8845276638571875, Training Loss Force: 2.022458760040485, time: 1.7092103958129883
Validation Loss Energy: 0.8804467920319855, Validation Loss Force: 2.0617126232458403, time: 0.10389351844787598
Test Loss Energy: 11.077607463176838, Test Loss Force: 7.89079773640066, time: 8.368940353393555

Epoch 5, Batch 100/116, Loss: 0.15835854411125183, Uncertainty: 0.13515113294124603

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6576721412308928, Training Loss Force: 2.010477625300069, time: 1.6964702606201172
Validation Loss Energy: 1.0951875803498687, Validation Loss Force: 2.3150286886273017, time: 0.10699176788330078
Test Loss Energy: 10.25269514150459, Test Loss Force: 8.115241233658748, time: 8.58465838432312

Epoch 6, Batch 100/116, Loss: 0.22038766741752625, Uncertainty: 0.13509303331375122

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6318939477580614, Training Loss Force: 2.05461283448406, time: 1.7521419525146484
Validation Loss Energy: 1.8939418130160621, Validation Loss Force: 2.5401174317177895, time: 0.10767889022827148
Test Loss Energy: 11.630237327811118, Test Loss Force: 7.826148156106271, time: 8.37978982925415

Epoch 7, Batch 100/116, Loss: 0.40537208318710327, Uncertainty: 0.1348603069782257

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.032810036774407, Training Loss Force: 2.023055168790264, time: 1.692967176437378
Validation Loss Energy: 3.5320859872423456, Validation Loss Force: 2.005586044538893, time: 0.10400938987731934
Test Loss Energy: 9.98592338909138, Test Loss Force: 7.8354725909707925, time: 8.35321569442749

Epoch 8, Batch 100/116, Loss: 0.1000535637140274, Uncertainty: 0.1352519541978836

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.3387526349462644, Training Loss Force: 2.0027520693735026, time: 1.6842310428619385
Validation Loss Energy: 2.059715206783819, Validation Loss Force: 2.0980156358982742, time: 0.10998725891113281
Test Loss Energy: 12.313343305196284, Test Loss Force: 7.774855698132457, time: 8.61757516860962

Epoch 9, Batch 100/116, Loss: 0.1104748472571373, Uncertainty: 0.13560503721237183

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2155131711001457, Training Loss Force: 2.092194053774538, time: 1.6898672580718994
Validation Loss Energy: 2.4726605561894526, Validation Loss Force: 2.2087432869934176, time: 0.11094331741333008
Test Loss Energy: 9.947687617967349, Test Loss Force: 7.827656267418079, time: 8.41105604171753

Epoch 10, Batch 100/116, Loss: 0.11605671048164368, Uncertainty: 0.13876616954803467

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.9644961883160534, Training Loss Force: 2.1477504433435666, time: 1.6611199378967285
Validation Loss Energy: 1.8450758442619062, Validation Loss Force: 2.1667126301233317, time: 0.10613179206848145
Test Loss Energy: 12.278389560702525, Test Loss Force: 7.899055961446056, time: 8.916625261306763

Epoch 11, Batch 100/116, Loss: 0.05132551118731499, Uncertainty: 0.13830161094665527

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.4988542206953444, Training Loss Force: 2.079751056196208, time: 1.7139225006103516
Validation Loss Energy: 2.4443889227384394, Validation Loss Force: 2.055653944231242, time: 0.11112689971923828
Test Loss Energy: 9.960196923434479, Test Loss Force: 7.735418432276372, time: 8.516739845275879

Epoch 12, Batch 100/116, Loss: 0.1610790342092514, Uncertainty: 0.13450665771961212

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0650641328546397, Training Loss Force: 2.002600546858822, time: 1.7385356426239014
Validation Loss Energy: 3.3216980096121076, Validation Loss Force: 2.0707097927561984, time: 0.10599398612976074
Test Loss Energy: 13.405766356389304, Test Loss Force: 7.769532767717107, time: 8.324469327926636

Epoch 13, Batch 100/116, Loss: 0.10787887871265411, Uncertainty: 0.13483184576034546

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.08506397177125, Training Loss Force: 1.9990768258603497, time: 1.7478141784667969
Validation Loss Energy: 3.3170391772949093, Validation Loss Force: 2.130236974659755, time: 0.11352682113647461
Test Loss Energy: 9.871721891417504, Test Loss Force: 7.663080487410721, time: 8.397603988647461

Epoch 14, Batch 100/116, Loss: 0.05066780745983124, Uncertainty: 0.13342411816120148

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7991908116695998, Training Loss Force: 2.0063394420749434, time: 1.7220814228057861
Validation Loss Energy: 0.7593106758238314, Validation Loss Force: 2.0474387887613825, time: 0.10555076599121094
Test Loss Energy: 11.153890088724586, Test Loss Force: 7.786941225743255, time: 8.630086183547974

Epoch 15, Batch 100/116, Loss: 0.14111372828483582, Uncertainty: 0.1343936026096344

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8120063505654502, Training Loss Force: 2.0010689536102277, time: 1.7576193809509277
Validation Loss Energy: 2.7632130632830774, Validation Loss Force: 2.084090055958048, time: 0.1049652099609375
Test Loss Energy: 12.70012962362377, Test Loss Force: 7.823129608863407, time: 8.377124071121216

Epoch 16, Batch 100/116, Loss: 0.0718330442905426, Uncertainty: 0.13386163115501404

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9518909236458624, Training Loss Force: 2.0320689741812528, time: 1.7639553546905518
Validation Loss Energy: 0.8020108245926737, Validation Loss Force: 2.092526024997619, time: 0.1091463565826416
Test Loss Energy: 11.138418001228862, Test Loss Force: 7.868434397907047, time: 8.475439310073853

Epoch 17, Batch 100/116, Loss: 0.15059350430965424, Uncertainty: 0.13625875115394592

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3521016361589213, Training Loss Force: 2.025006409878002, time: 1.7393114566802979
Validation Loss Energy: 1.083542429356137, Validation Loss Force: 2.0576994572287837, time: 0.10764861106872559
Test Loss Energy: 11.147163909009668, Test Loss Force: 7.812767873862908, time: 8.566648721694946

Epoch 18, Batch 100/116, Loss: 0.18197764456272125, Uncertainty: 0.1336614489555359

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6164372552594588, Training Loss Force: 2.044109502077222, time: 1.7096657752990723
Validation Loss Energy: 1.889950654132928, Validation Loss Force: 2.1706492721772377, time: 0.10440635681152344
Test Loss Energy: 10.281842812500228, Test Loss Force: 7.86134413665143, time: 8.374448537826538

Epoch 19, Batch 100/116, Loss: 0.05740943178534508, Uncertainty: 0.13247811794281006

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7345594431606424, Training Loss Force: 2.0105499390247705, time: 1.7028014659881592
Validation Loss Energy: 0.8987895711545546, Validation Loss Force: 2.114923572156009, time: 0.10735821723937988
Test Loss Energy: 11.160801673728987, Test Loss Force: 7.760337676812808, time: 8.2902352809906

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–…â–ƒâ–‚â–„â–â–†â–â–†â–â–ˆâ–â–„â–‡â–„â–„â–‚â–„
wandb:   test_error_force â–„â–ƒâ–ƒâ–„â–…â–ˆâ–„â–„â–ƒâ–„â–…â–‚â–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–„â–ƒ
wandb:          test_loss â–„â–ƒâ–„â–„â–…â–ˆâ–„â–„â–…â–‚â–ƒâ–â–†â–â–„â–†â–„â–„â–„â–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–…â–ƒâ–‚â–‚â–„â–â–„â–‡â–…â–„â–„â–ƒâ–ƒâ–ƒâ–…â–‚â–‚
wandb:  train_error_force â–†â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–â–…â–ˆâ–…â–â–â–â–â–ƒâ–‚â–ƒâ–‚
wandb:         train_loss â–‡â–‚â–‚â–„â–‚â–‚â–ƒâ–ƒâ–â–…â–ˆâ–…â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚
wandb: valid_error_energy â–ƒâ–‚â–‚â–ƒâ–â–‚â–„â–ˆâ–„â–…â–„â–…â–‡â–‡â–â–†â–â–‚â–„â–
wandb:  valid_error_force â–‚â–â–â–‚â–‚â–…â–ˆâ–‚â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–„â–ƒ
wandb:         valid_loss â–‚â–â–â–‚â–‚â–…â–ˆâ–ƒâ–ƒâ–…â–„â–ƒâ–„â–„â–‚â–ƒâ–‚â–‚â–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3706
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.1608
wandb:   test_error_force 7.76034
wandb:          test_loss 5.3686
wandb: train_error_energy 1.73456
wandb:  train_error_force 2.01055
wandb:         train_loss -2.39811
wandb: valid_error_energy 0.89879
wandb:  valid_error_force 2.11492
wandb:         valid_loss -2.32269
wandb: 
wandb: ğŸš€ View run al_58_41 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3djyow08
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_053113-3djyow08/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 46.50184631347656, Uncertainty Bias: -6.039280891418457
5.722046e-05 0.0045337677
-1.156825 16.685934
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1177 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2027 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1294 steps.
Found uncertainty sample 7 after 366 steps.
Found uncertainty sample 8 after 825 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2219 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 580 steps.
Found uncertainty sample 14 after 999 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2945 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 883 steps.
Found uncertainty sample 20 after 3114 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3785 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 399 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1225 steps.
Found uncertainty sample 33 after 453 steps.
Found uncertainty sample 34 after 912 steps.
Found uncertainty sample 35 after 2702 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2547 steps.
Found uncertainty sample 39 after 964 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1303 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2964 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2000 steps.
Found uncertainty sample 53 after 3112 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 645 steps.
Found uncertainty sample 59 after 1683 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2973 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2368 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2244 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 773 steps.
Found uncertainty sample 72 after 2185 steps.
Found uncertainty sample 73 after 3161 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2829 steps.
Found uncertainty sample 80 after 2294 steps.
Found uncertainty sample 81 after 2152 steps.
Found uncertainty sample 82 after 264 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2203 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1694 steps.
Found uncertainty sample 88 after 745 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2842 steps.
Found uncertainty sample 92 after 3024 steps.
Found uncertainty sample 93 after 1864 steps.
Found uncertainty sample 94 after 1157 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3143 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 958 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_060428-kpi7o20s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_42
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kpi7o20s
Training model 42. Added 44 samples to the dataset.
Epoch 0, Batch 100/118, Loss: 0.12295155227184296, Uncertainty: 0.13664843142032623
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.9186885306716452, Training Loss Force: 2.161877753629435, time: 1.7463645935058594
Validation Loss Energy: 1.2238879715585733, Validation Loss Force: 2.044468642135376, time: 0.12592196464538574
Test Loss Energy: 10.351308805695913, Test Loss Force: 7.79443608033444, time: 8.568730592727661

Epoch 1, Batch 100/118, Loss: 0.28037089109420776, Uncertainty: 0.13546910881996155

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8806900130854252, Training Loss Force: 2.0514749878258556, time: 1.7861928939819336
Validation Loss Energy: 2.5917452772234606, Validation Loss Force: 2.279922448411181, time: 0.11121535301208496
Test Loss Energy: 10.004963629572465, Test Loss Force: 7.906017125892545, time: 8.596745491027832

Epoch 2, Batch 100/118, Loss: 0.14000304043293, Uncertainty: 0.13508152961730957

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1007836742635924, Training Loss Force: 2.034866601010734, time: 1.6802592277526855
Validation Loss Energy: 0.9773636862431525, Validation Loss Force: 2.4759470043372493, time: 0.11112213134765625
Test Loss Energy: 11.139188058752291, Test Loss Force: 7.792490182828829, time: 8.74532413482666

Epoch 3, Batch 100/118, Loss: 0.04551442712545395, Uncertainty: 0.13462767004966736

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5456273759740706, Training Loss Force: 2.043301867761883, time: 1.6865215301513672
Validation Loss Energy: 3.2696747037032687, Validation Loss Force: 2.4226747471889016, time: 0.11179709434509277
Test Loss Energy: 9.984598039018675, Test Loss Force: 7.762924203943519, time: 9.166826963424683

Epoch 4, Batch 100/118, Loss: 0.04825969785451889, Uncertainty: 0.13550812005996704

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.595054545985274, Training Loss Force: 2.045105902989764, time: 1.7681469917297363
Validation Loss Energy: 4.594127632313794, Validation Loss Force: 2.108560281749782, time: 0.11253786087036133
Test Loss Energy: 14.986024005678814, Test Loss Force: 7.771815068172513, time: 8.66011929512024

Epoch 5, Batch 100/118, Loss: 0.061878103762865067, Uncertainty: 0.13483361899852753

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5630904801928631, Training Loss Force: 2.0122801392103087, time: 1.730194091796875
Validation Loss Energy: 6.175455918380385, Validation Loss Force: 2.2276961424643047, time: 0.1085965633392334
Test Loss Energy: 9.22045778376591, Test Loss Force: 7.692990339737378, time: 8.764488697052002

Epoch 6, Batch 100/118, Loss: 0.0629621148109436, Uncertainty: 0.1335907280445099

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5828099191727416, Training Loss Force: 2.046165111811542, time: 1.7811291217803955
Validation Loss Energy: 3.979418726637997, Validation Loss Force: 2.0500726678655137, time: 0.1192178726196289
Test Loss Energy: 9.705054194240313, Test Loss Force: 7.7675102020768705, time: 8.661487340927124

Epoch 7, Batch 100/118, Loss: 0.06099654734134674, Uncertainty: 0.13506349921226501

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.492670156039651, Training Loss Force: 2.0064102748253334, time: 1.7761297225952148
Validation Loss Energy: 0.8136177136048298, Validation Loss Force: 2.182846939545065, time: 0.10582590103149414
Test Loss Energy: 10.81310698268437, Test Loss Force: 7.792832302896379, time: 8.65254521369934

Epoch 8, Batch 100/118, Loss: 0.0638984739780426, Uncertainty: 0.13371843099594116

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.008484382252364, Training Loss Force: 2.001896330616652, time: 1.7169618606567383
Validation Loss Energy: 2.5009652188971123, Validation Loss Force: 2.150796313795462, time: 0.10927486419677734
Test Loss Energy: 9.97749979897963, Test Loss Force: 7.72617369897641, time: 8.810259342193604

Epoch 9, Batch 100/118, Loss: 0.050515905022621155, Uncertainty: 0.13169512152671814

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6726907011058787, Training Loss Force: 2.010222198884191, time: 1.6991376876831055
Validation Loss Energy: 3.161549683808778, Validation Loss Force: 2.1328288435183542, time: 0.11078858375549316
Test Loss Energy: 13.274738056799114, Test Loss Force: 7.728438001702628, time: 8.644635915756226

Epoch 10, Batch 100/118, Loss: 0.37003999948501587, Uncertainty: 0.132778599858284

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.108842085279176, Training Loss Force: 2.007969696674252, time: 1.7220714092254639
Validation Loss Energy: 0.861962450999893, Validation Loss Force: 2.255306968113253, time: 0.11260437965393066
Test Loss Energy: 10.771519492984815, Test Loss Force: 7.805228520416747, time: 8.574190855026245

Epoch 11, Batch 100/118, Loss: 0.21925629675388336, Uncertainty: 0.13270887732505798

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6402734804854284, Training Loss Force: 2.0128176681896583, time: 1.7286674976348877
Validation Loss Energy: 3.517136574569143, Validation Loss Force: 2.2387657679388613, time: 0.11043643951416016
Test Loss Energy: 13.742869881606623, Test Loss Force: 7.694784533103614, time: 8.828133344650269

Epoch 12, Batch 100/118, Loss: 0.6243599653244019, Uncertainty: 0.13444039225578308

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 3.4358231665068493, Training Loss Force: 2.0337688128723967, time: 1.7139103412628174
Validation Loss Energy: 8.37914031082442, Validation Loss Force: 2.114281468562202, time: 0.1118474006652832
Test Loss Energy: 9.285503031977122, Test Loss Force: 7.696632642714145, time: 8.618277072906494

Epoch 13, Batch 100/118, Loss: 0.13428723812103271, Uncertainty: 0.13590937852859497

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.252607142773917, Training Loss Force: 2.0789732384963155, time: 1.7052514553070068
Validation Loss Energy: 0.7961094427739117, Validation Loss Force: 2.2275423523075175, time: 0.11291694641113281
Test Loss Energy: 10.910678242836465, Test Loss Force: 7.774450039249245, time: 8.650891304016113

Epoch 14, Batch 100/118, Loss: 0.21302741765975952, Uncertainty: 0.13408100605010986

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8592732478765284, Training Loss Force: 2.0083589770651074, time: 1.9157068729400635
Validation Loss Energy: 2.7693302300600062, Validation Loss Force: 2.40099033508187, time: 0.12095975875854492
Test Loss Energy: 10.084762058705952, Test Loss Force: 7.562702630731702, time: 8.609419822692871

Epoch 15, Batch 100/118, Loss: 0.07168508321046829, Uncertainty: 0.13627350330352783

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.994102183060402, Training Loss Force: 2.0562930263808616, time: 1.7204902172088623
Validation Loss Energy: 6.422823080636192, Validation Loss Force: 2.2942513563977314, time: 0.11021232604980469
Test Loss Energy: 16.54400453723227, Test Loss Force: 7.91122917639968, time: 9.192660570144653

Epoch 16, Batch 100/118, Loss: 0.10207362473011017, Uncertainty: 0.1352541595697403

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.201575962832592, Training Loss Force: 2.0381015194925065, time: 1.7319860458374023
Validation Loss Energy: 4.160231417190864, Validation Loss Force: 2.193567345575758, time: 0.10988306999206543
Test Loss Energy: 14.258658233712499, Test Loss Force: 7.816620085061669, time: 8.68624496459961

Epoch 17, Batch 100/118, Loss: 0.04608616605401039, Uncertainty: 0.13333529233932495

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.994663732945625, Training Loss Force: 2.0300836158629725, time: 1.8384523391723633
Validation Loss Energy: 2.0767650575105585, Validation Loss Force: 2.130746293219541, time: 0.10811376571655273
Test Loss Energy: 12.464544753239448, Test Loss Force: 7.674471361897873, time: 8.638815879821777

Epoch 18, Batch 100/118, Loss: 0.23916935920715332, Uncertainty: 0.13449233770370483

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7446108920748506, Training Loss Force: 2.0232667094079386, time: 1.7408225536346436
Validation Loss Energy: 4.120453652516225, Validation Loss Force: 2.115630917809573, time: 0.11237645149230957
Test Loss Energy: 14.44045896905362, Test Loss Force: 7.6572885364991645, time: 8.59555435180664

Epoch 19, Batch 100/118, Loss: 0.05320483073592186, Uncertainty: 0.1344040185213089

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.311009071495102, Training Loss Force: 2.0013757216618524, time: 1.706885576248169
Validation Loss Energy: 6.033888367905097, Validation Loss Force: 2.169588995927378, time: 0.1159200668334961
Test Loss Energy: 15.685114200268877, Test Loss Force: 7.785722658932803, time: 8.811208486557007

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.060 MB uploadedwandb: / 0.039 MB of 0.060 MB uploadedwandb: - 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–‚â–‡â–â–â–ƒâ–‚â–…â–‚â–…â–â–ƒâ–‚â–ˆâ–†â–„â–†â–‡
wandb:   test_error_force â–†â–ˆâ–†â–…â–…â–„â–…â–†â–„â–„â–†â–„â–„â–…â–â–ˆâ–†â–ƒâ–ƒâ–…
wandb:          test_loss â–„â–„â–„â–‚â–†â–‚â–‚â–„â–ƒâ–…â–…â–…â–â–ƒâ–â–ˆâ–†â–…â–…â–‡
wandb: train_error_energy â–ƒâ–‚â–ƒâ–â–â–â–â–â–ƒâ–‚â–ƒâ–‚â–ˆâ–„â–‚â–ƒâ–„â–ƒâ–‚â–„
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–â–ƒâ–â–â–â–â–â–‚â–„â–â–ƒâ–ƒâ–‚â–‚â–
wandb:         train_loss â–ˆâ–„â–ƒâ–ƒâ–ƒâ–â–ƒâ–â–‚â–‚â–‚â–‚â–†â–…â–‚â–„â–„â–ƒâ–‚â–ƒ
wandb: valid_error_energy â–â–ƒâ–â–ƒâ–…â–†â–„â–â–ƒâ–ƒâ–â–„â–ˆâ–â–ƒâ–†â–„â–‚â–„â–†
wandb:  valid_error_force â–â–…â–ˆâ–‡â–‚â–„â–â–ƒâ–ƒâ–‚â–„â–„â–‚â–„â–‡â–…â–ƒâ–‚â–‚â–ƒ
wandb:         valid_loss â–â–…â–‡â–‡â–„â–‡â–ƒâ–ƒâ–ƒâ–„â–„â–…â–‡â–ƒâ–‡â–ˆâ–…â–ƒâ–„â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 3745
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 15.68511
wandb:   test_error_force 7.78572
wandb:          test_loss 5.67506
wandb: train_error_energy 2.31101
wandb:  train_error_force 2.00138
wandb:         train_loss -2.37138
wandb: valid_error_energy 6.03389
wandb:  valid_error_force 2.16959
wandb:         valid_loss -1.91027
wandb: 
wandb: ğŸš€ View run al_58_42 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/kpi7o20s
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_060428-kpi7o20s/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 45.21293258666992, Uncertainty Bias: -5.8644585609436035
6.67572e-05 0.5631237
-0.90311754 17.42276
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1397 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 547 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1885 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1174 steps.
Found uncertainty sample 9 after 1196 steps.
Found uncertainty sample 10 after 1607 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 936 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1388 steps.
Found uncertainty sample 16 after 783 steps.
Found uncertainty sample 17 after 1846 steps.
Found uncertainty sample 18 after 3249 steps.
Found uncertainty sample 19 after 166 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1478 steps.
Found uncertainty sample 23 after 2023 steps.
Found uncertainty sample 24 after 613 steps.
Found uncertainty sample 25 after 2708 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 702 steps.
Found uncertainty sample 29 after 2663 steps.
Found uncertainty sample 30 after 3578 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3144 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1976 steps.
Found uncertainty sample 38 after 1743 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 55 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 303 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 31 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1337 steps.
Found uncertainty sample 57 after 1737 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3902 steps.
Found uncertainty sample 61 after 1649 steps.
Found uncertainty sample 62 after 1627 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3882 steps.
Found uncertainty sample 67 after 3144 steps.
Found uncertainty sample 68 after 2627 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2906 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3880 steps.
Found uncertainty sample 73 after 3911 steps.
Found uncertainty sample 74 after 3474 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1532 steps.
Found uncertainty sample 77 after 1271 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1888 steps.
Found uncertainty sample 83 after 1259 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 111 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2156 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1586 steps.
Found uncertainty sample 94 after 13 steps.
Found uncertainty sample 95 after 596 steps.
Found uncertainty sample 96 after 1919 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_063704-13mnn8ij
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_43
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/13mnn8ij
Training model 43. Added 47 samples to the dataset.
Epoch 0, Batch 100/119, Loss: 0.10662331432104111, Uncertainty: 0.1369512975215912

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3929497918288347, Training Loss Force: 2.1266050743556053, time: 1.7271177768707275
Validation Loss Energy: 0.8124445812095095, Validation Loss Force: 2.1659269791534497, time: 0.10696792602539062
Test Loss Energy: 10.577584161214304, Test Loss Force: 7.73502897344788, time: 8.31784200668335

Epoch 1, Batch 100/119, Loss: 0.09445749223232269, Uncertainty: 0.13527245819568634

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5078691424440032, Training Loss Force: 2.005512976625427, time: 1.7657067775726318
Validation Loss Energy: 1.8283240361869912, Validation Loss Force: 2.380814803330694, time: 0.10860300064086914
Test Loss Energy: 10.263129137889075, Test Loss Force: 7.6522307875495095, time: 8.370131254196167

Epoch 2, Batch 100/119, Loss: 0.09256745874881744, Uncertainty: 0.13477596640586853

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.125800507111612, Training Loss Force: 2.0098097464164546, time: 1.7067599296569824
Validation Loss Energy: 1.4514699039644905, Validation Loss Force: 2.098122145973077, time: 0.10546445846557617
Test Loss Energy: 11.531145155785843, Test Loss Force: 7.748434313547908, time: 8.540019273757935

Epoch 3, Batch 100/119, Loss: 0.0767456442117691, Uncertainty: 0.1332896500825882

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.130119602291273, Training Loss Force: 2.012112624404688, time: 1.7286393642425537
Validation Loss Energy: 0.9811984571627965, Validation Loss Force: 2.0678390679038485, time: 0.10638427734375
Test Loss Energy: 10.912830094146571, Test Loss Force: 7.7357375672921895, time: 8.356721878051758

Epoch 4, Batch 100/119, Loss: 0.04533245041966438, Uncertainty: 0.1350921094417572

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5113512809069922, Training Loss Force: 2.0236052779077514, time: 1.7102382183074951
Validation Loss Energy: 3.269640412654796, Validation Loss Force: 2.056988029307544, time: 0.1056067943572998
Test Loss Energy: 13.566020846411348, Test Loss Force: 7.68819705178466, time: 8.305560827255249

Epoch 5, Batch 100/119, Loss: 0.059724122285842896, Uncertainty: 0.13320475816726685

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5250389853321662, Training Loss Force: 2.001233349551882, time: 1.7777056694030762
Validation Loss Energy: 0.8274582710428363, Validation Loss Force: 2.1439425574838045, time: 0.10743141174316406
Test Loss Energy: 10.774198657475077, Test Loss Force: 7.727769336749672, time: 8.543797492980957

Epoch 6, Batch 100/119, Loss: 0.2604524791240692, Uncertainty: 0.1348889023065567

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.3790304127267445, Training Loss Force: 1.9780183873892685, time: 1.8793153762817383
Validation Loss Energy: 5.8971853960378455, Validation Loss Force: 2.1600197151580827, time: 0.10818910598754883
Test Loss Energy: 9.460813001351887, Test Loss Force: 7.722980572128294, time: 8.369876146316528

Epoch 7, Batch 100/119, Loss: 0.10924821346998215, Uncertainty: 0.1332780420780182

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.747078398122277, Training Loss Force: 1.9971858344801048, time: 1.7141201496124268
Validation Loss Energy: 2.817481616413355, Validation Loss Force: 2.298582493955173, time: 0.10522723197937012
Test Loss Energy: 12.548208135842716, Test Loss Force: 7.762331358417653, time: 8.462929248809814

Epoch 8, Batch 100/119, Loss: 0.279285192489624, Uncertainty: 0.13326171040534973

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8456850123134632, Training Loss Force: 2.0164507442303474, time: 1.7463405132293701
Validation Loss Energy: 1.7719288442670063, Validation Loss Force: 2.301973967716799, time: 0.10602807998657227
Test Loss Energy: 11.802262542567123, Test Loss Force: 7.7553736843974646, time: 8.521883249282837

Epoch 9, Batch 100/119, Loss: 0.12910893559455872, Uncertainty: 0.1367538422346115

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.6433997175973287, Training Loss Force: 2.0422150089568873, time: 1.8259358406066895
Validation Loss Energy: 1.739624487025619, Validation Loss Force: 2.0511305689778165, time: 0.11022758483886719
Test Loss Energy: 9.98817082725286, Test Loss Force: 7.6548438717647445, time: 8.35090947151184

Epoch 10, Batch 100/119, Loss: 0.19296564161777496, Uncertainty: 0.13437806069850922

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.867425452374858, Training Loss Force: 2.0138842577832143, time: 1.7118892669677734
Validation Loss Energy: 2.9411110147157493, Validation Loss Force: 2.1646074417946815, time: 0.10459494590759277
Test Loss Energy: 12.745983155712693, Test Loss Force: 7.755089770744141, time: 8.30402946472168

Epoch 11, Batch 100/119, Loss: 0.1620410978794098, Uncertainty: 0.13338759541511536

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0555736444043884, Training Loss Force: 1.9801549642709557, time: 1.77070951461792
Validation Loss Energy: 1.1460566436292663, Validation Loss Force: 2.054854042436021, time: 0.11208438873291016
Test Loss Energy: 11.242465851133625, Test Loss Force: 7.729483649017063, time: 8.563058853149414

Epoch 12, Batch 100/119, Loss: 0.0969788134098053, Uncertainty: 0.132741779088974

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9466683974360741, Training Loss Force: 1.987154989886287, time: 1.7425956726074219
Validation Loss Energy: 4.338172417991747, Validation Loss Force: 2.1317241818854065, time: 0.10904335975646973
Test Loss Energy: 9.261396343294194, Test Loss Force: 7.6965287949540375, time: 8.37405252456665

Epoch 13, Batch 100/119, Loss: 0.22294509410858154, Uncertainty: 0.13455405831336975

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.223481474436161, Training Loss Force: 2.0182321666310337, time: 1.7706336975097656
Validation Loss Energy: 1.478759529370438, Validation Loss Force: 2.230289941122169, time: 0.10726451873779297
Test Loss Energy: 11.800004863956543, Test Loss Force: 7.707556268731807, time: 8.332211971282959

Epoch 14, Batch 100/119, Loss: 0.06486427038908005, Uncertainty: 0.13389545679092407

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.195235589210211, Training Loss Force: 2.0072675318418125, time: 1.7846601009368896
Validation Loss Energy: 1.6075423823861847, Validation Loss Force: 2.246787572367007, time: 0.10914111137390137
Test Loss Energy: 10.108505934246248, Test Loss Force: 7.659962450194486, time: 8.542466640472412

Epoch 15, Batch 100/119, Loss: 0.06828272342681885, Uncertainty: 0.13282549381256104

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6846912028749916, Training Loss Force: 2.0053295711603703, time: 1.7436931133270264
Validation Loss Energy: 1.0599932002634846, Validation Loss Force: 2.0177440767987447, time: 0.10736751556396484
Test Loss Energy: 11.699977854576629, Test Loss Force: 7.628800173689128, time: 8.981955766677856

Epoch 16, Batch 100/119, Loss: 0.11186690628528595, Uncertainty: 0.13402387499809265

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8980577211966863, Training Loss Force: 1.995171422499253, time: 1.7957444190979004
Validation Loss Energy: 0.8578312517797325, Validation Loss Force: 2.1291548768335944, time: 0.10455203056335449
Test Loss Energy: 10.863141397289523, Test Loss Force: 7.723227245241315, time: 8.339707612991333

Epoch 17, Batch 100/119, Loss: 0.06289654970169067, Uncertainty: 0.13524483144283295

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.110644781027346, Training Loss Force: 2.0168867584856134, time: 1.7865591049194336
Validation Loss Energy: 1.3405279338163913, Validation Loss Force: 2.0442064863275706, time: 0.10557746887207031
Test Loss Energy: 9.93456001507491, Test Loss Force: 7.710917908325299, time: 8.576773643493652

Epoch 18, Batch 100/119, Loss: 0.11612550914287567, Uncertainty: 0.13477832078933716

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.5407579698615805, Training Loss Force: 2.0075883541086164, time: 1.7189815044403076
Validation Loss Energy: 2.7867517898143475, Validation Loss Force: 2.146263289545713, time: 0.10625100135803223
Test Loss Energy: 9.699117634291067, Test Loss Force: 7.797610815410588, time: 8.382218360900879

Epoch 19, Batch 100/119, Loss: 0.06904363632202148, Uncertainty: 0.13013097643852234

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.369147603352621, Training Loss Force: 1.9826000717083576, time: 1.7782282829284668
Validation Loss Energy: 0.820909200345857, Validation Loss Force: 2.1150981447664168, time: 0.1065976619720459
Test Loss Energy: 10.44599883901718, Test Loss Force: 7.675960673405244, time: 8.359021663665771

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–…â–„â–ˆâ–ƒâ–â–†â–…â–‚â–‡â–„â–â–…â–‚â–…â–„â–‚â–‚â–ƒ
wandb:   test_error_force â–…â–‚â–†â–…â–ƒâ–…â–…â–‡â–†â–‚â–†â–…â–„â–„â–‚â–â–…â–„â–ˆâ–ƒ
wandb:          test_loss â–‚â–‚â–†â–†â–‡â–†â–„â–ˆâ–‡â–â–‡â–†â–ƒâ–†â–ƒâ–ƒâ–†â–ƒâ–…â–†
wandb: train_error_energy â–ˆâ–‚â–†â–†â–‚â–‚â–â–„â–„â–ƒâ–„â–†â–…â–‡â–‡â–ƒâ–…â–†â–‚â–
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–„â–ƒâ–â–â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–„â–ƒâ–‚â–â–‚â–ƒâ–„â–ƒâ–‚â–‚â–„â–„â–ƒâ–ƒâ–„â–‚â–
wandb: valid_error_energy â–â–‚â–‚â–â–„â–â–ˆâ–„â–‚â–‚â–„â–â–†â–‚â–‚â–â–â–‚â–„â–
wandb:  valid_error_force â–„â–ˆâ–ƒâ–‚â–‚â–ƒâ–„â–†â–†â–‚â–„â–‚â–ƒâ–…â–…â–â–ƒâ–‚â–ƒâ–ƒ
wandb:         valid_loss â–ƒâ–ˆâ–ƒâ–‚â–„â–ƒâ–ˆâ–ˆâ–‡â–‚â–…â–‚â–†â–…â–†â–â–ƒâ–‚â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3787
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.446
wandb:   test_error_force 7.67596
wandb:          test_loss 5.32879
wandb: train_error_energy 1.36915
wandb:  train_error_force 1.9826
wandb:         train_loss -2.45788
wandb: valid_error_energy 0.82091
wandb:  valid_error_force 2.1151
wandb:         valid_loss -2.32394
wandb: 
wandb: ğŸš€ View run al_58_43 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/13mnn8ij
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_063704-13mnn8ij/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 44.90291976928711, Uncertainty Bias: -5.713338375091553
5.340576e-05 0.000705719
-0.8812924 16.889793
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 817 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 683 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 737 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1593 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 844 steps.
Found uncertainty sample 13 after 14 steps.
Found uncertainty sample 14 after 2016 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 523 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2145 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2471 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3551 steps.
Found uncertainty sample 26 after 335 steps.
Found uncertainty sample 27 after 2161 steps.
Found uncertainty sample 28 after 2438 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1677 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 405 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 996 steps.
Found uncertainty sample 38 after 3653 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3996 steps.
Found uncertainty sample 42 after 2850 steps.
Found uncertainty sample 43 after 1966 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2057 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 578 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 1649 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3995 steps.
Found uncertainty sample 58 after 439 steps.
Found uncertainty sample 59 after 2884 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 997 steps.
Found uncertainty sample 62 after 1246 steps.
Found uncertainty sample 63 after 3948 steps.
Found uncertainty sample 64 after 2539 steps.
Found uncertainty sample 65 after 683 steps.
Found uncertainty sample 66 after 550 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1421 steps.
Found uncertainty sample 69 after 1468 steps.
Found uncertainty sample 70 after 710 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 2120 steps.
Found uncertainty sample 73 after 1523 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3902 steps.
Found uncertainty sample 77 after 1354 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 777 steps.
Found uncertainty sample 80 after 2694 steps.
Found uncertainty sample 81 after 1451 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2692 steps.
Found uncertainty sample 85 after 1995 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1702 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 217 steps.
Found uncertainty sample 93 after 84 steps.
Found uncertainty sample 94 after 889 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2595 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_070831-tn0tds2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_44
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/tn0tds2k
Training model 44. Added 50 samples to the dataset.
Epoch 0, Batch 100/120, Loss: 0.22752006351947784, Uncertainty: 0.13434983789920807

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.2057750160261103, Training Loss Force: 2.16398714771593, time: 1.8241643905639648
Validation Loss Energy: 1.5084305270690346, Validation Loss Force: 2.2224783363677787, time: 0.10951733589172363
Test Loss Energy: 9.858289616511469, Test Loss Force: 7.58038574123999, time: 8.534605741500854

Epoch 1, Batch 100/120, Loss: 0.07422986626625061, Uncertainty: 0.1345306783914566

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.978845768966228, Training Loss Force: 2.0294859506305265, time: 1.7691588401794434
Validation Loss Energy: 4.132382187109674, Validation Loss Force: 2.101678840240981, time: 0.10913395881652832
Test Loss Energy: 9.523146997399683, Test Loss Force: 7.673393668879338, time: 8.53035593032837

Epoch 2, Batch 100/120, Loss: 0.0451255664229393, Uncertainty: 0.1332913041114807

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.583381409709984, Training Loss Force: 2.006074915576565, time: 1.8377587795257568
Validation Loss Energy: 4.248998472214975, Validation Loss Force: 2.047048301302474, time: 0.10658597946166992
Test Loss Energy: 14.083618521727308, Test Loss Force: 7.556858572908385, time: 8.77744174003601

Epoch 3, Batch 100/120, Loss: 0.16288216412067413, Uncertainty: 0.13523158431053162

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 4.075765397639026, Training Loss Force: 2.036296484077595, time: 1.779341459274292
Validation Loss Energy: 3.2952705962507167, Validation Loss Force: 2.113365110803661, time: 0.11049962043762207
Test Loss Energy: 13.266715075294453, Test Loss Force: 7.722072140303264, time: 8.57518720626831

Epoch 4, Batch 100/120, Loss: 0.09727500379085541, Uncertainty: 0.1358095109462738

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6888816444474315, Training Loss Force: 2.04536829135788, time: 1.7503712177276611
Validation Loss Energy: 1.2246297195951832, Validation Loss Force: 2.142941956565054, time: 0.10929059982299805
Test Loss Energy: 10.12048788456417, Test Loss Force: 7.71956127171827, time: 8.506466388702393

Epoch 5, Batch 100/120, Loss: 0.047348205000162125, Uncertainty: 0.13449627161026

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.3645817149574246, Training Loss Force: 1.9931528915602137, time: 1.8376977443695068
Validation Loss Energy: 1.5452974864450553, Validation Loss Force: 2.1122463467914705, time: 0.10917472839355469
Test Loss Energy: 11.805435971939376, Test Loss Force: 7.576791809929206, time: 8.667819738388062

Epoch 6, Batch 100/120, Loss: 0.08461795747280121, Uncertainty: 0.1339091956615448

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8524542633569738, Training Loss Force: 2.0351026044846026, time: 1.7767295837402344
Validation Loss Energy: 1.1425939157409433, Validation Loss Force: 2.3015678191946267, time: 0.11028480529785156
Test Loss Energy: 11.071348137888629, Test Loss Force: 7.6055328077895, time: 8.535592079162598

Epoch 7, Batch 100/120, Loss: 0.1431281566619873, Uncertainty: 0.13400444388389587

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7208181311525668, Training Loss Force: 2.017014977297412, time: 1.749840497970581
Validation Loss Energy: 1.6659221872922998, Validation Loss Force: 2.2042046217919715, time: 0.1139993667602539
Test Loss Energy: 9.856782582405373, Test Loss Force: 7.693226173176478, time: 8.487436294555664

Epoch 8, Batch 100/120, Loss: 0.18345250189304352, Uncertainty: 0.1337951123714447

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.77738498474777, Training Loss Force: 2.0106282583858803, time: 1.8205606937408447
Validation Loss Energy: 1.3557538273457876, Validation Loss Force: 2.0326747852636893, time: 0.11048722267150879
Test Loss Energy: 11.334397291198924, Test Loss Force: 7.604007381911438, time: 8.734073638916016

Epoch 9, Batch 100/120, Loss: 0.08271022140979767, Uncertainty: 0.13310764729976654

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7401395847775296, Training Loss Force: 2.0219457610092606, time: 1.7913060188293457
Validation Loss Energy: 1.6125309134854537, Validation Loss Force: 2.0483928518286345, time: 0.11379337310791016
Test Loss Energy: 12.016391937369027, Test Loss Force: 7.54027653684476, time: 8.512014865875244

Epoch 10, Batch 100/120, Loss: 0.12221341580152512, Uncertainty: 0.1338510513305664

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9385740601085435, Training Loss Force: 2.0002756730228284, time: 1.7635796070098877
Validation Loss Energy: 1.5255695196771937, Validation Loss Force: 2.12238573479739, time: 0.10867500305175781
Test Loss Energy: 10.28086092317318, Test Loss Force: 7.667426047167137, time: 8.572097063064575

Epoch 11, Batch 100/120, Loss: 0.05817576125264168, Uncertainty: 0.1359170377254486

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.4430208327012573, Training Loss Force: 2.0156804969833755, time: 1.7960624694824219
Validation Loss Energy: 0.8341197339912229, Validation Loss Force: 2.1157088520106475, time: 0.11000227928161621
Test Loss Energy: 10.574588274928814, Test Loss Force: 7.699245687291943, time: 8.68695878982544

Epoch 12, Batch 100/120, Loss: 0.04905068129301071, Uncertainty: 0.1305813193321228

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.3240470672387714, Training Loss Force: 1.9515729587919501, time: 1.8275208473205566
Validation Loss Energy: 1.596353109357216, Validation Loss Force: 2.0733286788045038, time: 0.11184573173522949
Test Loss Energy: 9.736440769689851, Test Loss Force: 7.593006964183608, time: 8.552483320236206

Epoch 13, Batch 100/120, Loss: 0.07026057690382004, Uncertainty: 0.13323712348937988

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7839906542304922, Training Loss Force: 2.021073873990313, time: 1.7366867065429688
Validation Loss Energy: 1.9024547142455515, Validation Loss Force: 2.0736714408431354, time: 0.11031341552734375
Test Loss Energy: 9.721442690012882, Test Loss Force: 7.622360661263776, time: 8.551161527633667

Epoch 14, Batch 100/120, Loss: 0.1873382031917572, Uncertainty: 0.13066835701465607

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.001758199093581, Training Loss Force: 1.981740578270074, time: 1.775026798248291
Validation Loss Energy: 2.7262562197951508, Validation Loss Force: 2.0316205953038184, time: 0.11101007461547852
Test Loss Energy: 12.525210083028954, Test Loss Force: 7.630938065625655, time: 9.277614116668701

Epoch 15, Batch 100/120, Loss: 0.17520549893379211, Uncertainty: 0.13105925917625427

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8074489355021726, Training Loss Force: 1.977599292137603, time: 1.8238999843597412
Validation Loss Energy: 1.317495742480583, Validation Loss Force: 2.0544190953709753, time: 0.11381387710571289
Test Loss Energy: 11.32860158872029, Test Loss Force: 7.57244937686729, time: 8.557480573654175

Epoch 16, Batch 100/120, Loss: 0.06485675275325775, Uncertainty: 0.1354251503944397

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6888272897491754, Training Loss Force: 2.0188893208113257, time: 1.744748830795288
Validation Loss Energy: 1.466861945788273, Validation Loss Force: 2.2167613802691317, time: 0.11275696754455566
Test Loss Energy: 11.552149160931341, Test Loss Force: 7.551220995834346, time: 8.519555807113647

Epoch 17, Batch 100/120, Loss: 0.23793786764144897, Uncertainty: 0.13372136652469635

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6813954166061578, Training Loss Force: 2.002280057173541, time: 2.001314878463745
Validation Loss Energy: 2.6827724240787405, Validation Loss Force: 2.1507877781448683, time: 0.1115717887878418
Test Loss Energy: 9.445233589659445, Test Loss Force: 7.551086195897145, time: 8.60948634147644

Epoch 18, Batch 100/120, Loss: 0.14122715592384338, Uncertainty: 0.13147591054439545

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8744537768918785, Training Loss Force: 1.9731782639737385, time: 1.800699234008789
Validation Loss Energy: 1.2787940264536417, Validation Loss Force: 2.1064930213989883, time: 0.11041569709777832
Test Loss Energy: 11.319173637184862, Test Loss Force: 7.592154493428433, time: 8.571840524673462

Epoch 19, Batch 100/120, Loss: 0.1315305531024933, Uncertainty: 0.13114674389362335

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6143669198669557, Training Loss Force: 1.992627167851102, time: 1.781876802444458
Validation Loss Energy: 1.2061877784796275, Validation Loss Force: 2.2175744195439626, time: 0.11068153381347656
Test Loss Energy: 11.0251297454999, Test Loss Force: 7.6835456542076015, time: 8.685876846313477

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–‡â–‚â–…â–ƒâ–‚â–„â–…â–‚â–ƒâ–â–â–†â–„â–„â–â–„â–ƒ
wandb:   test_error_force â–ƒâ–†â–‚â–ˆâ–ˆâ–‚â–„â–‡â–ƒâ–â–†â–‡â–ƒâ–„â–„â–‚â–â–â–ƒâ–‡
wandb:          test_loss â–â–ƒâ–‡â–ˆâ–„â–ƒâ–ƒâ–„â–„â–„â–„â–…â–†â–…â–ˆâ–†â–ƒâ–â–…â–†
wandb: train_error_energy â–†â–ƒâ–‚â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–„â–ƒâ–„â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–†â–„â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚
wandb: valid_error_energy â–‚â–ˆâ–ˆâ–†â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–…â–‚â–‚â–…â–‚â–‚
wandb:  valid_error_force â–†â–ƒâ–â–ƒâ–„â–ƒâ–ˆâ–…â–â–â–ƒâ–ƒâ–‚â–‚â–â–‚â–†â–„â–ƒâ–†
wandb:         valid_loss â–†â–‡â–†â–†â–„â–ƒâ–ˆâ–†â–â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–†â–†â–ƒâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 3832
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.02513
wandb:   test_error_force 7.68355
wandb:          test_loss 5.2425
wandb: train_error_energy 1.61437
wandb:  train_error_force 1.99263
wandb:         train_loss -2.42892
wandb: valid_error_energy 1.20619
wandb:  valid_error_force 2.21757
wandb:         valid_loss -2.17149
wandb: 
wandb: ğŸš€ View run al_58_44 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/tn0tds2k
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_070831-tn0tds2k/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.459049224853516, Uncertainty Bias: -5.074708938598633
4.196167e-05 0.0007305145
-0.6670598 18.763556
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 176 steps.
Found uncertainty sample 5 after 2834 steps.
Found uncertainty sample 6 after 1268 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 889 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1360 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 17 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1986 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3308 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2331 steps.
Found uncertainty sample 25 after 806 steps.
Found uncertainty sample 26 after 2789 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 310 steps.
Found uncertainty sample 32 after 1387 steps.
Found uncertainty sample 33 after 3415 steps.
Found uncertainty sample 34 after 753 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 681 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3160 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2639 steps.
Found uncertainty sample 42 after 1829 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1051 steps.
Found uncertainty sample 53 after 1167 steps.
Found uncertainty sample 54 after 2921 steps.
Found uncertainty sample 55 after 3392 steps.
Found uncertainty sample 56 after 1170 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1303 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2490 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 383 steps.
Found uncertainty sample 69 after 1159 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2062 steps.
Found uncertainty sample 72 after 1413 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3800 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 15 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 337 steps.
Found uncertainty sample 84 after 888 steps.
Found uncertainty sample 85 after 952 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3055 steps.
Found uncertainty sample 88 after 1334 steps.
Found uncertainty sample 89 after 2316 steps.
Found uncertainty sample 90 after 3626 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1241 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 990 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_074149-8yt0mx5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_45
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8yt0mx5r
Training model 45. Added 41 samples to the dataset.
Epoch 0, Batch 100/121, Loss: 0.15193234384059906, Uncertainty: 0.13612376153469086

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.669066556630768, Training Loss Force: 2.1434450265869467, time: 1.804738998413086
Validation Loss Energy: 0.8485152757196923, Validation Loss Force: 2.1145233614777283, time: 0.11221051216125488
Test Loss Energy: 10.208331426883293, Test Loss Force: 7.640094330492068, time: 8.460730791091919

Epoch 1, Batch 100/121, Loss: 0.042527224868535995, Uncertainty: 0.13088029623031616

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4370090531608257, Training Loss Force: 1.968051196727332, time: 1.7612082958221436
Validation Loss Energy: 4.278131018807194, Validation Loss Force: 2.066423263250991, time: 0.11286044120788574
Test Loss Energy: 9.194751929577599, Test Loss Force: 7.536309943653413, time: 8.43667459487915

Epoch 2, Batch 100/121, Loss: 0.07981155812740326, Uncertainty: 0.13248348236083984

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9948705967305311, Training Loss Force: 1.9963884798514562, time: 1.7604284286499023
Validation Loss Energy: 0.82427282190848, Validation Loss Force: 2.0533667609873207, time: 0.1093602180480957
Test Loss Energy: 10.067476996692474, Test Loss Force: 7.647611372722968, time: 8.669476985931396

Epoch 3, Batch 100/121, Loss: 0.08266663551330566, Uncertainty: 0.13279254734516144

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5258890299656571, Training Loss Force: 1.9845374666317124, time: 1.8138351440429688
Validation Loss Energy: 0.8967226633632421, Validation Loss Force: 2.297275054953333, time: 0.11180973052978516
Test Loss Energy: 10.424678769591624, Test Loss Force: 7.639897407028961, time: 8.434574127197266

Epoch 4, Batch 100/121, Loss: 0.05270950496196747, Uncertainty: 0.13261264562606812

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8699285636595397, Training Loss Force: 1.995453078973629, time: 1.7768197059631348
Validation Loss Energy: 2.4899321111624872, Validation Loss Force: 2.060686341152259, time: 0.11005997657775879
Test Loss Energy: 9.690476028935123, Test Loss Force: 7.547012621256346, time: 8.450145721435547

Epoch 5, Batch 100/121, Loss: 0.14642605185508728, Uncertainty: 0.1323336809873581

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9496860321479872, Training Loss Force: 1.9892183143639175, time: 1.788337230682373
Validation Loss Energy: 2.327474483646741, Validation Loss Force: 1.9792088801814327, time: 0.10901165008544922
Test Loss Energy: 9.64429225635245, Test Loss Force: 7.50766055957408, time: 8.658722162246704

Epoch 6, Batch 100/121, Loss: 0.1610656976699829, Uncertainty: 0.13180683553218842

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.444374761723668, Training Loss Force: 1.98788276138881, time: 1.8251194953918457
Validation Loss Energy: 1.3586203585958891, Validation Loss Force: 2.0290828350476793, time: 0.11098003387451172
Test Loss Energy: 9.961601790874226, Test Loss Force: 7.610251043416166, time: 8.506356954574585

Epoch 7, Batch 100/121, Loss: 0.14621029794216156, Uncertainty: 0.13223601877689362

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8572639063391305, Training Loss Force: 1.9638450004838874, time: 1.734405517578125
Validation Loss Energy: 1.3067175166949971, Validation Loss Force: 2.218161449635677, time: 0.10961198806762695
Test Loss Energy: 10.949001486794824, Test Loss Force: 7.639495681578723, time: 8.454672574996948

Epoch 8, Batch 100/121, Loss: 0.08900941908359528, Uncertainty: 0.13348184525966644

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.752898954472833, Training Loss Force: 2.0285498184793136, time: 1.788543462753296
Validation Loss Energy: 1.1312118854546498, Validation Loss Force: 2.3085856826668327, time: 0.11477088928222656
Test Loss Energy: 10.919068509519589, Test Loss Force: 7.568830837701361, time: 8.691831350326538

Epoch 9, Batch 100/121, Loss: 0.10383405536413193, Uncertainty: 0.13277718424797058

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9327079127837452, Training Loss Force: 2.011933600885635, time: 1.8176417350769043
Validation Loss Energy: 0.9453696926796642, Validation Loss Force: 2.0342325043855514, time: 0.10987138748168945
Test Loss Energy: 10.089747380727024, Test Loss Force: 7.568430406296947, time: 8.48633074760437

Epoch 10, Batch 100/121, Loss: 0.09187661111354828, Uncertainty: 0.1328212469816208

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8853883191399283, Training Loss Force: 1.9942147799684276, time: 1.7744026184082031
Validation Loss Energy: 1.462188936868784, Validation Loss Force: 2.0563527542342124, time: 0.10738134384155273
Test Loss Energy: 9.80296989907921, Test Loss Force: 7.602952135341779, time: 8.452613592147827

Epoch 11, Batch 100/121, Loss: 0.18380320072174072, Uncertainty: 0.13381165266036987

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5262085169444028, Training Loss Force: 2.0179181773873673, time: 1.806992530822754
Validation Loss Energy: 1.4581183964351265, Validation Loss Force: 2.233420075529524, time: 0.11429929733276367
Test Loss Energy: 10.404142514212646, Test Loss Force: 7.520327729305022, time: 8.74195647239685

Epoch 12, Batch 100/121, Loss: 0.21560996770858765, Uncertainty: 0.13105875253677368

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7272267376283694, Training Loss Force: 1.9743976611978216, time: 1.8009135723114014
Validation Loss Energy: 1.1421663167577134, Validation Loss Force: 2.026614028003729, time: 0.1178748607635498
Test Loss Energy: 9.998000954240046, Test Loss Force: 7.490986972683073, time: 8.510928630828857

Epoch 13, Batch 100/121, Loss: 0.19271084666252136, Uncertainty: 0.1322503387928009

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.788701302374875, Training Loss Force: 1.985494082726472, time: 1.7985403537750244
Validation Loss Energy: 1.2681151111071398, Validation Loss Force: 2.018577750081098, time: 0.12198281288146973
Test Loss Energy: 11.388540993777937, Test Loss Force: 7.537303148303657, time: 8.489161252975464

Epoch 14, Batch 100/121, Loss: 0.05296362191438675, Uncertainty: 0.13450516760349274

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7143569744209475, Training Loss Force: 1.9959542106084665, time: 1.7892146110534668
Validation Loss Energy: 1.751293612064062, Validation Loss Force: 2.003708535411954, time: 0.11128807067871094
Test Loss Energy: 9.699907650431133, Test Loss Force: 7.4722666902775785, time: 8.701329708099365

Epoch 15, Batch 100/121, Loss: 0.09883800148963928, Uncertainty: 0.13194280862808228

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4482179147871463, Training Loss Force: 1.9846096289172812, time: 1.79703688621521
Validation Loss Energy: 2.5002542363141647, Validation Loss Force: 1.9966611682779123, time: 0.11857271194458008
Test Loss Energy: 12.36251310133683, Test Loss Force: 7.523279646011939, time: 9.079300165176392

Epoch 16, Batch 100/121, Loss: 0.04797661677002907, Uncertainty: 0.13224193453788757

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8299776832318548, Training Loss Force: 1.9869857967020277, time: 1.7494144439697266
Validation Loss Energy: 1.0785389052010423, Validation Loss Force: 2.179150112161323, time: 0.11565351486206055
Test Loss Energy: 10.333081743609299, Test Loss Force: 7.502581515992908, time: 8.460030555725098

Epoch 17, Batch 100/121, Loss: 0.05941815674304962, Uncertainty: 0.1309158056974411

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.808686548082192, Training Loss Force: 1.9793577986072097, time: 1.8490004539489746
Validation Loss Energy: 0.9211312469130787, Validation Loss Force: 2.1981410440561633, time: 0.16728854179382324
Test Loss Energy: 10.083601451158637, Test Loss Force: 7.5917792644407545, time: 8.578648567199707

Epoch 18, Batch 100/121, Loss: 0.14244234561920166, Uncertainty: 0.13212576508522034

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9256975170090116, Training Loss Force: 1.9835034371240456, time: 1.8504199981689453
Validation Loss Energy: 2.153889856239837, Validation Loss Force: 2.0666057777276032, time: 0.11129498481750488
Test Loss Energy: 12.044018813072189, Test Loss Force: 7.531774476260696, time: 8.514942646026611

Epoch 19, Batch 100/121, Loss: 0.11756372451782227, Uncertainty: 0.13239583373069763

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0276153795874037, Training Loss Force: 1.9966637946083485, time: 1.8063743114471436
Validation Loss Energy: 0.8759793067341878, Validation Loss Force: 2.180969096414407, time: 0.10964393615722656
Test Loss Energy: 10.425506371350878, Test Loss Force: 7.639257052534325, time: 8.454217910766602

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–ƒâ–„â–‚â–‚â–ƒâ–…â–…â–ƒâ–‚â–„â–ƒâ–†â–‚â–ˆâ–„â–ƒâ–‡â–„
wandb:   test_error_force â–ˆâ–„â–ˆâ–ˆâ–„â–‚â–‡â–ˆâ–…â–…â–†â–ƒâ–‚â–„â–â–ƒâ–‚â–†â–ƒâ–ˆ
wandb:          test_loss â–„â–‚â–†â–‡â–„â–‚â–…â–ˆâ–ƒâ–ƒâ–„â–ƒâ–‚â–†â–â–†â–‚â–†â–†â–…
wandb: train_error_energy â–ˆâ–â–„â–‚â–ƒâ–„â–â–ƒâ–ƒâ–„â–„â–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–„
wandb:  train_error_force â–ˆâ–â–‚â–‚â–‚â–‚â–‚â–â–„â–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒ
wandb: valid_error_energy â–â–ˆâ–â–â–„â–„â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–â–„â–
wandb:  valid_error_force â–„â–ƒâ–ƒâ–ˆâ–ƒâ–â–‚â–†â–ˆâ–‚â–ƒâ–†â–‚â–‚â–‚â–â–…â–†â–ƒâ–…
wandb:         valid_loss â–ƒâ–†â–â–ˆâ–„â–â–â–†â–ˆâ–â–‚â–‡â–â–â–â–‚â–…â–…â–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 3868
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.42551
wandb:   test_error_force 7.63926
wandb:          test_loss 5.08973
wandb: train_error_energy 2.02762
wandb:  train_error_force 1.99666
wandb:         train_loss -2.39626
wandb: valid_error_energy 0.87598
wandb:  valid_error_force 2.18097
wandb:         valid_loss -2.24263
wandb: 
wandb: ğŸš€ View run al_58_45 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8yt0mx5r
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_074149-8yt0mx5r/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.68406295776367, Uncertainty Bias: -5.1616034507751465
5.722046e-05 0.00011444092
-0.8564888 19.787819
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2882 steps.
Found uncertainty sample 1 after 1274 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2561 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1176 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1723 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1996 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 358 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2873 steps.
Found uncertainty sample 18 after 1288 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2226 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2983 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2854 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2201 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2934 steps.
Found uncertainty sample 33 after 1133 steps.
Found uncertainty sample 34 after 3334 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 400 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 18 steps.
Found uncertainty sample 39 after 2668 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 510 steps.
Found uncertainty sample 42 after 2880 steps.
Found uncertainty sample 43 after 808 steps.
Found uncertainty sample 44 after 1894 steps.
Found uncertainty sample 45 after 1981 steps.
Found uncertainty sample 46 after 2620 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1126 steps.
Found uncertainty sample 52 after 1808 steps.
Found uncertainty sample 53 after 3068 steps.
Found uncertainty sample 54 after 2860 steps.
Found uncertainty sample 55 after 1108 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2773 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1747 steps.
Found uncertainty sample 62 after 1034 steps.
Found uncertainty sample 63 after 379 steps.
Found uncertainty sample 64 after 1778 steps.
Found uncertainty sample 65 after 1318 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2224 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3270 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1003 steps.
Found uncertainty sample 78 after 1003 steps.
Found uncertainty sample 79 after 742 steps.
Found uncertainty sample 80 after 1932 steps.
Found uncertainty sample 81 after 2523 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1216 steps.
Found uncertainty sample 85 after 1919 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2956 steps.
Found uncertainty sample 89 after 630 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1051 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2404 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 159 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1431 steps.
Found uncertainty sample 99 after 1829 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_081318-pps84ila
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_46
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pps84ila
Training model 46. Added 52 samples to the dataset.
Epoch 0, Batch 100/123, Loss: 0.13911938667297363, Uncertainty: 0.1371343433856964

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.2548256198757373, Training Loss Force: 2.1944431395330573, time: 1.8204033374786377
Validation Loss Energy: 1.2210137953344617, Validation Loss Force: 2.0677832521712696, time: 0.11303305625915527
Test Loss Energy: 10.012498884041051, Test Loss Force: 7.586162830443314, time: 8.66333270072937

Epoch 1, Batch 100/123, Loss: 0.04546346887946129, Uncertainty: 0.13257025182247162

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8910427376746084, Training Loss Force: 1.9891192475398105, time: 1.8114676475524902
Validation Loss Energy: 2.114025176375239, Validation Loss Force: 2.023786426742641, time: 0.10955953598022461
Test Loss Energy: 11.703240883215265, Test Loss Force: 7.470506827597257, time: 8.631476402282715

Epoch 2, Batch 100/123, Loss: 0.2299053817987442, Uncertainty: 0.13458780944347382

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.004684039888672, Training Loss Force: 2.021599695343466, time: 1.7623040676116943
Validation Loss Energy: 2.0324508543259348, Validation Loss Force: 2.2528727490099705, time: 0.11090493202209473
Test Loss Energy: 9.503102204302559, Test Loss Force: 7.57167917478379, time: 8.903640031814575

Epoch 3, Batch 100/123, Loss: 0.1857713758945465, Uncertainty: 0.1305447816848755

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9852455049938333, Training Loss Force: 1.9745377449413426, time: 1.8236613273620605
Validation Loss Energy: 4.502398483864452, Validation Loss Force: 2.0874547351991137, time: 0.11199498176574707
Test Loss Energy: 9.04193742893551, Test Loss Force: 7.525756916037843, time: 8.661417484283447

Epoch 4, Batch 100/123, Loss: 0.07494095712900162, Uncertainty: 0.132560133934021

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0358685496423914, Training Loss Force: 2.0095657350558525, time: 1.8883817195892334
Validation Loss Energy: 2.9815348168057714, Validation Loss Force: 2.0944878886193403, time: 0.11146926879882812
Test Loss Energy: 12.826253578150357, Test Loss Force: 7.62751910096806, time: 8.646692037582397

Epoch 5, Batch 100/123, Loss: 0.1817215085029602, Uncertainty: 0.13288810849189758

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2338751660058436, Training Loss Force: 1.981600661804075, time: 1.900116205215454
Validation Loss Energy: 2.093332235751975, Validation Loss Force: 2.0862863159673823, time: 0.11500835418701172
Test Loss Energy: 11.890849179624295, Test Loss Force: 7.541854270153398, time: 8.862952709197998

Epoch 6, Batch 100/123, Loss: 0.04744994267821312, Uncertainty: 0.1311904340982437

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8489034635192658, Training Loss Force: 1.9908255883598294, time: 1.7916629314422607
Validation Loss Energy: 1.6289516496518983, Validation Loss Force: 2.2224778168064385, time: 0.11022520065307617
Test Loss Energy: 9.95352771437832, Test Loss Force: 7.557994236848127, time: 8.648154497146606

Epoch 7, Batch 100/123, Loss: 0.07481271028518677, Uncertainty: 0.13411599397659302

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5580250185797546, Training Loss Force: 1.9929453352679223, time: 1.7981452941894531
Validation Loss Energy: 1.9579585244628632, Validation Loss Force: 2.081761827368227, time: 0.10997939109802246
Test Loss Energy: 11.878168649744596, Test Loss Force: 7.503307813783026, time: 8.643582344055176

Epoch 8, Batch 100/123, Loss: 0.16056504845619202, Uncertainty: 0.13580670952796936

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8013047668779858, Training Loss Force: 2.0150408190576337, time: 1.7994639873504639
Validation Loss Energy: 0.7604354704587234, Validation Loss Force: 1.9950863036318138, time: 0.11033487319946289
Test Loss Energy: 10.655638715545306, Test Loss Force: 7.523712845920825, time: 8.81547737121582

Epoch 9, Batch 100/123, Loss: 0.06111200898885727, Uncertainty: 0.13235090672969818

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7386715192009141, Training Loss Force: 1.9905534459313443, time: 1.7678580284118652
Validation Loss Energy: 5.28944870665934, Validation Loss Force: 2.024070997911137, time: 0.10985660552978516
Test Loss Energy: 14.612007168208693, Test Loss Force: 7.56802852696018, time: 8.642900943756104

Epoch 10, Batch 100/123, Loss: 0.10880203545093536, Uncertainty: 0.1340198516845703

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.434223381969783, Training Loss Force: 2.0108778863161216, time: 1.8602302074432373
Validation Loss Energy: 0.9445260735087926, Validation Loss Force: 2.1568965577172996, time: 0.10978126525878906
Test Loss Energy: 10.244408193305178, Test Loss Force: 7.48536130316221, time: 8.706610918045044

Epoch 11, Batch 100/123, Loss: 0.2788703441619873, Uncertainty: 0.13400602340698242

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9952568143406264, Training Loss Force: 2.0025213775759174, time: 2.0704190731048584
Validation Loss Energy: 0.756551897884597, Validation Loss Force: 2.0598300298400694, time: 0.1256852149963379
Test Loss Energy: 10.001363626738582, Test Loss Force: 7.4749974720406405, time: 8.654704332351685

Epoch 12, Batch 100/123, Loss: 0.06247188150882721, Uncertainty: 0.13290460407733917

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.731264363079851, Training Loss Force: 1.9681103258210886, time: 1.8325715065002441
Validation Loss Energy: 2.495522145847956, Validation Loss Force: 2.0865720747046566, time: 0.10839486122131348
Test Loss Energy: 12.588665422242734, Test Loss Force: 7.572055690822447, time: 9.181375741958618

Epoch 13, Batch 100/123, Loss: 0.05967862159013748, Uncertainty: 0.13193434476852417

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.3944096604038603, Training Loss Force: 1.9950235715783244, time: 1.7779417037963867
Validation Loss Energy: 0.7987906761830769, Validation Loss Force: 2.143456396515196, time: 0.13115286827087402
Test Loss Energy: 10.310133237595027, Test Loss Force: 7.4497373968192475, time: 8.840629577636719

Epoch 14, Batch 100/123, Loss: 0.10955110192298889, Uncertainty: 0.13108916580677032

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6066451173754577, Training Loss Force: 1.98330555980044, time: 1.7912876605987549
Validation Loss Energy: 1.68641491124185, Validation Loss Force: 2.0361560689141727, time: 0.11376023292541504
Test Loss Energy: 9.85350401122719, Test Loss Force: 7.5010988822283, time: 8.673820734024048

Epoch 15, Batch 100/123, Loss: 0.055012356489896774, Uncertainty: 0.13289493322372437

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.644511696704022, Training Loss Force: 1.9796168263496372, time: 1.7998697757720947
Validation Loss Energy: 2.2393914682389187, Validation Loss Force: 2.263449607664589, time: 0.10958409309387207
Test Loss Energy: 9.56407544238603, Test Loss Force: 7.606523711136635, time: 8.660479068756104

Epoch 16, Batch 100/123, Loss: 0.1975926160812378, Uncertainty: 0.13302281498908997

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6771026866138232, Training Loss Force: 2.010726495736187, time: 1.7823803424835205
Validation Loss Energy: 1.2893877337403021, Validation Loss Force: 2.1081101189597646, time: 0.1093134880065918
Test Loss Energy: 10.952986989376468, Test Loss Force: 7.483773173186329, time: 8.911021709442139

Epoch 17, Batch 100/123, Loss: 0.22421735525131226, Uncertainty: 0.13274630904197693

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6741118084493978, Training Loss Force: 1.9900552997506977, time: 1.8387646675109863
Validation Loss Energy: 2.398706194982943, Validation Loss Force: 2.043885137638472, time: 0.11123776435852051
Test Loss Energy: 9.594701519929925, Test Loss Force: 7.463715372014178, time: 8.644701480865479

Epoch 18, Batch 100/123, Loss: 0.17719057202339172, Uncertainty: 0.13182194530963898

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1755743099841887, Training Loss Force: 1.9717736306364584, time: 1.8333942890167236
Validation Loss Energy: 1.699159862258843, Validation Loss Force: 2.0389819630451425, time: 0.11115312576293945
Test Loss Energy: 9.73888497742791, Test Loss Force: 7.459378632753878, time: 8.669402837753296

Epoch 19, Batch 100/123, Loss: 0.05471827834844589, Uncertainty: 0.13048705458641052

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7268237143925125, Training Loss Force: 1.953051902118408, time: 1.8252489566802979
Validation Loss Energy: 1.072744887022142, Validation Loss Force: 2.142472792674584, time: 0.108551025390625
Test Loss Energy: 11.166628745743637, Test Loss Force: 7.457346048167881, time: 8.866126537322998

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–„â–‚â–â–†â–…â–‚â–…â–ƒâ–ˆâ–ƒâ–‚â–…â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–„
wandb:   test_error_force â–†â–‚â–†â–„â–ˆâ–…â–…â–ƒâ–„â–†â–‚â–‚â–†â–â–ƒâ–‡â–‚â–‚â–â–
wandb:          test_loss â–â–ƒâ–â–‚â–‡â–…â–ƒâ–„â–‚â–ˆâ–ƒâ–‚â–‡â–‚â–‚â–„â–ƒâ–â–‚â–…
wandb: train_error_energy â–‡â–„â–…â–…â–…â–‡â–„â–‚â–„â–ƒâ–ˆâ–…â–ƒâ–â–‚â–ƒâ–ƒâ–ƒâ–†â–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–â–‚â–‚â–‚â–‚â–‚â–‚â–
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–‡â–„â–ƒâ–‚â–ƒâ–â–ˆâ–â–â–„â–â–‚â–ƒâ–‚â–„â–‚â–
wandb:  valid_error_force â–ƒâ–‚â–ˆâ–ƒâ–„â–ƒâ–‡â–ƒâ–â–‚â–…â–ƒâ–ƒâ–…â–‚â–ˆâ–„â–‚â–‚â–…
wandb:         valid_loss â–ƒâ–ƒâ–‡â–‡â–…â–„â–†â–„â–â–†â–„â–‚â–…â–„â–ƒâ–ˆâ–„â–„â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3914
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.16663
wandb:   test_error_force 7.45735
wandb:          test_loss 5.14519
wandb: train_error_energy 1.72682
wandb:  train_error_force 1.95305
wandb:         train_loss -2.47149
wandb: valid_error_energy 1.07274
wandb:  valid_error_force 2.14247
wandb:         valid_loss -2.26962
wandb: 
wandb: ğŸš€ View run al_58_46 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pps84ila
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_081318-pps84ila/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 41.15019607543945, Uncertainty Bias: -5.175675392150879
5.4359436e-05 0.0019788742
-0.6697888 18.963331
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 673 steps.
Found uncertainty sample 2 after 1583 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2550 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2886 steps.
Found uncertainty sample 9 after 874 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 915 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2466 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2646 steps.
Found uncertainty sample 29 after 1286 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2053 steps.
Found uncertainty sample 34 after 3801 steps.
Found uncertainty sample 35 after 940 steps.
Found uncertainty sample 36 after 868 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2171 steps.
Found uncertainty sample 39 after 2257 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2729 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2276 steps.
Found uncertainty sample 46 after 3903 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3943 steps.
Found uncertainty sample 51 after 3494 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3793 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 740 steps.
Found uncertainty sample 59 after 473 steps.
Found uncertainty sample 60 after 460 steps.
Found uncertainty sample 61 after 2763 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2255 steps.
Found uncertainty sample 65 after 27 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 462 steps.
Found uncertainty sample 70 after 2027 steps.
Found uncertainty sample 71 after 1960 steps.
Found uncertainty sample 72 after 3370 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 790 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1640 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 77 steps.
Found uncertainty sample 89 after 2172 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 1755 steps.
Found uncertainty sample 94 after 1205 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 360 steps.
Found uncertainty sample 97 after 1004 steps.
Found uncertainty sample 98 after 1507 steps.
Found uncertainty sample 99 after 1423 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_084711-ouh02xki
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_47
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ouh02xki
Training model 47. Added 41 samples to the dataset.
Epoch 0, Batch 100/124, Loss: 0.20822571218013763, Uncertainty: 0.13237230479717255

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.644653883782497, Training Loss Force: 2.10412868868316, time: 1.8459434509277344
Validation Loss Energy: 1.7086981549053302, Validation Loss Force: 2.0419824297865197, time: 0.11268329620361328
Test Loss Energy: 11.63178582734225, Test Loss Force: 7.452806257962636, time: 8.53635835647583

Epoch 1, Batch 100/124, Loss: 0.2258654236793518, Uncertainty: 0.1316160261631012

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.5212119624259475, Training Loss Force: 2.00347384602287, time: 1.8198802471160889
Validation Loss Energy: 0.8796794370435941, Validation Loss Force: 2.0472678530803585, time: 0.11246800422668457
Test Loss Energy: 10.927488891330343, Test Loss Force: 7.581783529899352, time: 8.5353364944458

Epoch 2, Batch 100/124, Loss: 0.36259979009628296, Uncertainty: 0.13342224061489105

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3091379711342683, Training Loss Force: 2.0049626316854514, time: 1.8236699104309082
Validation Loss Energy: 0.9414977545684123, Validation Loss Force: 1.991347800006259, time: 0.11252832412719727
Test Loss Energy: 10.705327645563766, Test Loss Force: 7.54753703390857, time: 8.722374200820923

Epoch 3, Batch 100/124, Loss: 0.053051866590976715, Uncertainty: 0.1312902569770813

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.907035829045092, Training Loss Force: 1.9714513633787356, time: 1.8618943691253662
Validation Loss Energy: 1.210050642823183, Validation Loss Force: 2.2358817571608047, time: 0.11266112327575684
Test Loss Energy: 11.245751305236613, Test Loss Force: 7.427373832159065, time: 8.60952115058899

Epoch 4, Batch 100/124, Loss: 0.08635598421096802, Uncertainty: 0.13241074979305267

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.12616742217079, Training Loss Force: 1.984791709844026, time: 1.7720246315002441
Validation Loss Energy: 2.320051584998092, Validation Loss Force: 2.2141214148750117, time: 0.11295294761657715
Test Loss Energy: 9.628822826896796, Test Loss Force: 7.476812216253495, time: 8.63549280166626

Epoch 5, Batch 100/124, Loss: 0.05728282034397125, Uncertainty: 0.13692158460617065

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.5862634685718637, Training Loss Force: 2.0235034205431828, time: 1.8152740001678467
Validation Loss Energy: 2.085787537080504, Validation Loss Force: 2.1705364531433013, time: 0.11777806282043457
Test Loss Energy: 9.408269177752167, Test Loss Force: 7.490123426760955, time: 8.798325061798096

Epoch 6, Batch 100/124, Loss: 0.14911723136901855, Uncertainty: 0.1327778398990631

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.080581904611458, Training Loss Force: 1.96890193903036, time: 1.8019835948944092
Validation Loss Energy: 0.7895099560711417, Validation Loss Force: 2.1244586360998805, time: 0.11063432693481445
Test Loss Energy: 10.34142597956699, Test Loss Force: 7.434885434734286, time: 8.611928224563599

Epoch 7, Batch 100/124, Loss: 0.08309338986873627, Uncertainty: 0.13224582374095917

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.774806232583334, Training Loss Force: 1.9994530185710468, time: 1.8350722789764404
Validation Loss Energy: 1.5992936038752896, Validation Loss Force: 1.9925898856137687, time: 0.1094200611114502
Test Loss Energy: 11.75074572969039, Test Loss Force: 7.580619895916943, time: 8.535454511642456

Epoch 8, Batch 100/124, Loss: 0.05914616957306862, Uncertainty: 0.1333695650100708

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8234840158308885, Training Loss Force: 2.0006887937229894, time: 1.7893273830413818
Validation Loss Energy: 2.6868903188174316, Validation Loss Force: 2.1032751553481375, time: 0.11457371711730957
Test Loss Energy: 9.323582692211135, Test Loss Force: 7.593256085491427, time: 9.36354112625122

Epoch 9, Batch 100/124, Loss: 0.048210881650447845, Uncertainty: 0.13261473178863525

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.798263931039475, Training Loss Force: 1.9910910675688747, time: 1.812112808227539
Validation Loss Energy: 2.0523479754216525, Validation Loss Force: 2.1520994478604805, time: 0.11198902130126953
Test Loss Energy: 12.271597848641898, Test Loss Force: 7.547290967015215, time: 8.582637548446655

Epoch 10, Batch 100/124, Loss: 0.165273517370224, Uncertainty: 0.1315709948539734

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8435665532849919, Training Loss Force: 1.9786407997128956, time: 1.832613229751587
Validation Loss Energy: 2.4819967765860103, Validation Loss Force: 2.177962469159993, time: 0.11203360557556152
Test Loss Energy: 12.24978589724395, Test Loss Force: 7.563216896199388, time: 8.55771279335022

Epoch 11, Batch 100/124, Loss: 0.06898876279592514, Uncertainty: 0.13231153786182404

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6624022685996354, Training Loss Force: 1.991083046990324, time: 1.8655481338500977
Validation Loss Energy: 1.290897690330363, Validation Loss Force: 2.230939615466937, time: 0.166245698928833
Test Loss Energy: 9.964016531673371, Test Loss Force: 7.496686148669851, time: 8.759486198425293

Epoch 12, Batch 100/124, Loss: 0.12256073951721191, Uncertainty: 0.13338540494441986

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.629004527438683, Training Loss Force: 2.009375786908789, time: 1.842214584350586
Validation Loss Energy: 0.7520846909232315, Validation Loss Force: 2.0321400824212676, time: 0.11503434181213379
Test Loss Energy: 10.37375160326622, Test Loss Force: 7.561681428059424, time: 8.599091529846191

Epoch 13, Batch 100/124, Loss: 0.05708182603120804, Uncertainty: 0.13070574402809143

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7295884418952592, Training Loss Force: 1.9735449992490084, time: 1.8564460277557373
Validation Loss Energy: 1.0184592069233904, Validation Loss Force: 2.0172905739715383, time: 0.11034202575683594
Test Loss Energy: 10.624011797315012, Test Loss Force: 7.484914307092734, time: 8.656014680862427

Epoch 14, Batch 100/124, Loss: 0.1380208432674408, Uncertainty: 0.1315024048089981

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.520703554474866, Training Loss Force: 1.9742800767884081, time: 2.098238229751587
Validation Loss Energy: 1.6705518499513816, Validation Loss Force: 2.2323190508259603, time: 0.11008000373840332
Test Loss Energy: 11.205799512772062, Test Loss Force: 7.633952105858477, time: 8.629126071929932

Epoch 15, Batch 100/124, Loss: 0.2147918939590454, Uncertainty: 0.13262195885181427

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7140507321010017, Training Loss Force: 1.9988989719451464, time: 1.8227591514587402
Validation Loss Energy: 2.5626840589809867, Validation Loss Force: 2.1515011358653724, time: 0.11224102973937988
Test Loss Energy: 9.211755253333704, Test Loss Force: 7.594473409551564, time: 8.559796810150146

Epoch 16, Batch 100/124, Loss: 0.06071861833333969, Uncertainty: 0.13311892747879028

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8917407832779927, Training Loss Force: 2.013533974287866, time: 1.7904987335205078
Validation Loss Energy: 0.8291312771150027, Validation Loss Force: 2.110058473986633, time: 0.11266946792602539
Test Loss Energy: 10.277918678001525, Test Loss Force: 7.365414727014904, time: 8.804672479629517

Epoch 17, Batch 100/124, Loss: 0.15610182285308838, Uncertainty: 0.13197463750839233

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.006116623063887, Training Loss Force: 1.9803568102603013, time: 1.8817944526672363
Validation Loss Energy: 2.474494830390557, Validation Loss Force: 2.032698907754498, time: 0.11445498466491699
Test Loss Energy: 9.630099744681551, Test Loss Force: 7.359670175486255, time: 8.62518835067749

Epoch 18, Batch 100/124, Loss: 0.12074516713619232, Uncertainty: 0.1320255696773529

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.3007259456121867, Training Loss Force: 1.9913989399860605, time: 1.8046374320983887
Validation Loss Energy: 1.2553566143837693, Validation Loss Force: 1.9918027501829139, time: 0.11484718322753906
Test Loss Energy: 11.226592031192826, Test Loss Force: 7.365772457238812, time: 8.586495399475098

Epoch 19, Batch 100/124, Loss: 0.15663401782512665, Uncertainty: 0.13275793194770813

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8641687875067277, Training Loss Force: 1.9791010981390633, time: 1.8417284488677979
Validation Loss Energy: 0.7536786123370692, Validation Loss Force: 2.0858680690882814, time: 0.11459708213806152
Test Loss Energy: 10.450038584269096, Test Loss Force: 7.401423687767336, time: 9.30125880241394

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–…â–„â–†â–‚â–â–„â–‡â–â–ˆâ–ˆâ–ƒâ–„â–„â–†â–â–ƒâ–‚â–†â–„
wandb:   test_error_force â–ƒâ–‡â–†â–ƒâ–„â–„â–ƒâ–‡â–‡â–†â–†â–„â–†â–„â–ˆâ–‡â–â–â–â–‚
wandb:          test_loss â–…â–…â–…â–…â–„â–â–„â–†â–„â–‡â–ˆâ–…â–…â–…â–ˆâ–„â–‚â–ƒâ–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‡â–†â–ƒâ–…â–ˆâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–â–‚â–ƒâ–„â–†â–ƒ
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–â–‚â–„â–â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–â–ƒâ–ƒâ–‚â–‚â–‚
wandb:         train_loss â–ˆâ–„â–„â–‚â–ƒâ–…â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–ƒâ–‚
wandb: valid_error_energy â–„â–â–‚â–ƒâ–‡â–†â–â–„â–ˆâ–†â–‡â–ƒâ–â–‚â–„â–ˆâ–â–‡â–ƒâ–
wandb:  valid_error_force â–‚â–ƒâ–â–ˆâ–‡â–†â–…â–â–„â–†â–†â–ˆâ–‚â–‚â–ˆâ–†â–„â–‚â–â–„
wandb:         valid_loss â–ƒâ–‚â–â–‡â–ˆâ–‡â–„â–‚â–†â–†â–‡â–‡â–‚â–‚â–ˆâ–‡â–„â–„â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 3950
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.45004
wandb:   test_error_force 7.40142
wandb:          test_loss 4.89404
wandb: train_error_energy 1.86417
wandb:  train_error_force 1.9791
wandb:         train_loss -2.42921
wandb: valid_error_energy 0.75368
wandb:  valid_error_force 2.08587
wandb:         valid_loss -2.3683
wandb: 
wandb: ğŸš€ View run al_58_47 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ouh02xki
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_084711-ouh02xki/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 46.731201171875, Uncertainty Bias: -6.035325527191162
3.0517578e-05 0.003119707
-1.1012967 17.325512
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1329 steps.
Found uncertainty sample 5 after 3883 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 566 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 956 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1363 steps.
Found uncertainty sample 21 after 2480 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1090 steps.
Found uncertainty sample 27 after 14 steps.
Found uncertainty sample 28 after 2608 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1239 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 1536 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2085 steps.
Found uncertainty sample 36 after 1375 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 998 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1604 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2361 steps.
Found uncertainty sample 47 after 2488 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 881 steps.
Found uncertainty sample 50 after 2273 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2063 steps.
Found uncertainty sample 53 after 2035 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 145 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 666 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2793 steps.
Found uncertainty sample 62 after 2821 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1155 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 79 steps.
Found uncertainty sample 71 after 3745 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1955 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1978 steps.
Found uncertainty sample 81 after 1659 steps.
Found uncertainty sample 82 after 1285 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2102 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1374 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2846 steps.
Found uncertainty sample 95 after 2646 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 17 steps.
Found uncertainty sample 98 after 1195 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_092110-424ukilb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_48
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/424ukilb
Training model 48. Added 38 samples to the dataset.
Epoch 0, Batch 100/125, Loss: 0.1964350938796997, Uncertainty: 0.13409455120563507

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.1029238855667782, Training Loss Force: 2.170076832258641, time: 1.8617076873779297
Validation Loss Energy: 0.7991364999224649, Validation Loss Force: 2.0394196563629876, time: 0.11374831199645996
Test Loss Energy: 10.836295742878065, Test Loss Force: 7.397347837471182, time: 8.646070718765259

Epoch 1, Batch 100/125, Loss: 0.20789268612861633, Uncertainty: 0.13165831565856934

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8231267689440396, Training Loss Force: 1.9678413382342341, time: 1.8243672847747803
Validation Loss Energy: 1.1617036787366606, Validation Loss Force: 2.1783935566265087, time: 0.1104135513305664
Test Loss Energy: 9.603064949734831, Test Loss Force: 7.565767696007344, time: 8.648793697357178

Epoch 2, Batch 100/125, Loss: 0.11245782673358917, Uncertainty: 0.13246479630470276

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0274342537025762, Training Loss Force: 1.9954046825082898, time: 1.8762400150299072
Validation Loss Energy: 2.011211038280272, Validation Loss Force: 2.174776073681766, time: 0.11380457878112793
Test Loss Energy: 9.41266002211751, Test Loss Force: 7.430192681318051, time: 8.854490518569946

Epoch 3, Batch 100/125, Loss: 0.10053592920303345, Uncertainty: 0.1335155963897705

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9044659290692072, Training Loss Force: 1.9900478596105782, time: 1.854341983795166
Validation Loss Energy: 1.0064478765191807, Validation Loss Force: 2.275839364282303, time: 0.1113438606262207
Test Loss Energy: 9.905622263959335, Test Loss Force: 7.489557108008631, time: 9.257595777511597

Epoch 4, Batch 100/125, Loss: 0.08651943504810333, Uncertainty: 0.1319674551486969

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.022688635343522, Training Loss Force: 2.024021568032771, time: 1.869962215423584
Validation Loss Energy: 0.9331386991629967, Validation Loss Force: 2.0589502640445083, time: 0.12004232406616211
Test Loss Energy: 10.733186059872871, Test Loss Force: 7.513774277893764, time: 8.596713542938232

Epoch 5, Batch 100/125, Loss: 0.040003444999456406, Uncertainty: 0.13306283950805664

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9264619238934888, Training Loss Force: 1.9699048007400752, time: 1.844566822052002
Validation Loss Energy: 1.1014794681833016, Validation Loss Force: 2.089793726130988, time: 0.11031031608581543
Test Loss Energy: 10.66251946728494, Test Loss Force: 7.459492893502529, time: 8.81733226776123

Epoch 6, Batch 100/125, Loss: 0.20884931087493896, Uncertainty: 0.1322270929813385

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.912865432324981, Training Loss Force: 1.9623709193357135, time: 1.8682441711425781
Validation Loss Energy: 3.7325109308302395, Validation Loss Force: 2.065738629850312, time: 0.1103219985961914
Test Loss Energy: 13.308027080125635, Test Loss Force: 7.495910339054454, time: 8.596324443817139

Epoch 7, Batch 100/125, Loss: 0.14162695407867432, Uncertainty: 0.13210293650627136

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9687533683437017, Training Loss Force: 1.9760340424194487, time: 1.8104372024536133
Validation Loss Energy: 2.267641205890582, Validation Loss Force: 2.0174177922769116, time: 0.11259841918945312
Test Loss Energy: 9.583950060296926, Test Loss Force: 7.415330324897461, time: 8.687564373016357

Epoch 8, Batch 100/125, Loss: 0.16617268323898315, Uncertainty: 0.13091513514518738

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9886269485604207, Training Loss Force: 1.9736958667535411, time: 1.8369314670562744
Validation Loss Energy: 2.5394336889936944, Validation Loss Force: 2.217626969462401, time: 0.12104940414428711
Test Loss Energy: 9.481364463517982, Test Loss Force: 7.346700884527536, time: 8.813689947128296

Epoch 9, Batch 100/125, Loss: 0.06803656369447708, Uncertainty: 0.13344117999076843

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4231763275082685, Training Loss Force: 1.9834689367003269, time: 1.883373498916626
Validation Loss Energy: 0.9679512758871632, Validation Loss Force: 2.0090141102634997, time: 0.11001086235046387
Test Loss Energy: 10.56139558269734, Test Loss Force: 7.488821530394419, time: 8.631468534469604

Epoch 10, Batch 100/125, Loss: 0.1628771722316742, Uncertainty: 0.13237391412258148

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7750772442244023, Training Loss Force: 1.9776963219250714, time: 1.8934705257415771
Validation Loss Energy: 1.775068330778491, Validation Loss Force: 2.1901217632116716, time: 0.1112523078918457
Test Loss Energy: 9.325104713932623, Test Loss Force: 7.415755501722252, time: 8.648979187011719

Epoch 11, Batch 100/125, Loss: 0.10527697205543518, Uncertainty: 0.1318211853504181

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.196567503103914, Training Loss Force: 1.9830985328108122, time: 2.057358980178833
Validation Loss Energy: 0.9592680884283254, Validation Loss Force: 2.213310973406883, time: 0.11392998695373535
Test Loss Energy: 10.092626448483204, Test Loss Force: 7.604447460081897, time: 8.633011102676392

Epoch 12, Batch 100/125, Loss: 0.13008412718772888, Uncertainty: 0.13228027522563934

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0511673092384486, Training Loss Force: 1.9808489821370134, time: 1.8244915008544922
Validation Loss Energy: 2.194302450649514, Validation Loss Force: 2.101586952106761, time: 0.11165142059326172
Test Loss Energy: 11.801579668757881, Test Loss Force: 7.3579257037905625, time: 8.69163465499878

Epoch 13, Batch 100/125, Loss: 0.15291516482830048, Uncertainty: 0.13363514840602875

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.069326306303181, Training Loss Force: 1.9920585575449232, time: 1.8664050102233887
Validation Loss Energy: 1.2930841900088008, Validation Loss Force: 2.185387965615344, time: 0.1159052848815918
Test Loss Energy: 9.74507858384128, Test Loss Force: 7.453636307916688, time: 8.741374015808105

Epoch 14, Batch 100/125, Loss: 0.05789237469434738, Uncertainty: 0.13108941912651062

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.502171452651622, Training Loss Force: 1.9560413787434883, time: 1.8738508224487305
Validation Loss Energy: 1.140505910048054, Validation Loss Force: 1.943028818009075, time: 0.11274003982543945
Test Loss Energy: 10.808012210034525, Test Loss Force: 7.407357013767835, time: 8.713949203491211

Epoch 15, Batch 100/125, Loss: 0.1549069881439209, Uncertainty: 0.13317745923995972

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.3999427108506222, Training Loss Force: 1.9897603100195866, time: 1.8219869136810303
Validation Loss Energy: 4.78618689608918, Validation Loss Force: 2.0558678550574303, time: 0.10970878601074219
Test Loss Energy: 8.778306799049671, Test Loss Force: 7.355013998100304, time: 8.711027383804321

Epoch 16, Batch 100/125, Loss: 0.06981894373893738, Uncertainty: 0.13325482606887817

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8229369394890917, Training Loss Force: 1.9748748989905518, time: 1.8287537097930908
Validation Loss Energy: 5.954361191760405, Validation Loss Force: 2.062903086723019, time: 0.11445784568786621
Test Loss Energy: 15.09750353042767, Test Loss Force: 7.357275190453324, time: 8.81243348121643

Epoch 17, Batch 100/125, Loss: 0.14023257791996002, Uncertainty: 0.13275977969169617

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7010169224905425, Training Loss Force: 1.9907579256873211, time: 1.8175806999206543
Validation Loss Energy: 1.5195568589527542, Validation Loss Force: 2.025794828215861, time: 0.1177825927734375
Test Loss Energy: 11.046931456448746, Test Loss Force: 7.498352476319199, time: 8.625239133834839

Epoch 18, Batch 100/125, Loss: 0.09429379552602768, Uncertainty: 0.13097423315048218

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9490246076861122, Training Loss Force: 1.957666786910575, time: 1.8853189945220947
Validation Loss Energy: 3.153069626278313, Validation Loss Force: 2.1748292916076433, time: 0.10972046852111816
Test Loss Energy: 12.808606290560995, Test Loss Force: 7.481755587873797, time: 8.64101505279541

Epoch 19, Batch 100/125, Loss: 0.11437751352787018, Uncertainty: 0.13258209824562073

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.082539342452855, Training Loss Force: 1.9770956273701017, time: 1.9031193256378174
Validation Loss Energy: 0.8899686442731983, Validation Loss Force: 2.116670188936667, time: 0.11332058906555176
Test Loss Energy: 10.092046832535702, Test Loss Force: 7.329261283131941, time: 9.392944812774658

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–†â–‚â–‚â–ƒâ–‚â–‚â–„â–‚â–ƒâ–â–ˆâ–„â–…â–‚
wandb:   test_error_force â–ƒâ–‡â–„â–…â–†â–„â–…â–ƒâ–â–…â–ƒâ–ˆâ–‚â–„â–ƒâ–‚â–‚â–…â–…â–
wandb:          test_loss â–ƒâ–†â–ƒâ–…â–†â–„â–ˆâ–ƒâ–‚â–„â–ƒâ–‡â–„â–ƒâ–…â–â–ˆâ–…â–ˆâ–ƒ
wandb: train_error_energy â–‡â–…â–‡â–…â–†â–†â–†â–†â–†â–â–„â–ˆâ–‡â–‡â–‚â–â–…â–„â–†â–‡
wandb:  train_error_force â–ˆâ–â–‚â–‚â–ƒâ–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–â–ƒâ–â–â–â–…â–ƒâ–ƒâ–â–‚â–â–ƒâ–‚â–â–†â–ˆâ–‚â–„â–
wandb:  valid_error_force â–ƒâ–†â–†â–ˆâ–ƒâ–„â–„â–ƒâ–‡â–‚â–†â–‡â–„â–†â–â–ƒâ–„â–ƒâ–†â–…
wandb:         valid_loss â–‚â–…â–†â–‡â–ƒâ–„â–†â–„â–‡â–‚â–†â–†â–…â–†â–â–‡â–ˆâ–ƒâ–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 3984
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.09205
wandb:   test_error_force 7.32926
wandb:          test_loss 4.81309
wandb: train_error_energy 2.08254
wandb:  train_error_force 1.9771
wandb:         train_loss -2.41724
wandb: valid_error_energy 0.88997
wandb:  valid_error_force 2.11667
wandb:         valid_loss -2.31888
wandb: 
wandb: ğŸš€ View run al_58_48 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/424ukilb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_092110-424ukilb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.43647384643555, Uncertainty Bias: -5.438803672790527
7.6293945e-06 0.002732277
-0.7148 16.795053
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2654 steps.
Found uncertainty sample 6 after 1964 steps.
Found uncertainty sample 7 after 2578 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2090 steps.
Found uncertainty sample 11 after 2897 steps.
Found uncertainty sample 12 after 1506 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3653 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2774 steps.
Found uncertainty sample 23 after 992 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2183 steps.
Found uncertainty sample 26 after 490 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 528 steps.
Found uncertainty sample 33 after 1718 steps.
Found uncertainty sample 34 after 1132 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2012 steps.
Found uncertainty sample 37 after 2019 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1818 steps.
Found uncertainty sample 44 after 2877 steps.
Found uncertainty sample 45 after 3012 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2142 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 338 steps.
Found uncertainty sample 52 after 2671 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 900 steps.
Found uncertainty sample 55 after 520 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3221 steps.
Found uncertainty sample 59 after 460 steps.
Found uncertainty sample 60 after 732 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1482 steps.
Found uncertainty sample 65 after 1083 steps.
Found uncertainty sample 66 after 3310 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2124 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2433 steps.
Found uncertainty sample 71 after 275 steps.
Found uncertainty sample 72 after 1773 steps.
Found uncertainty sample 73 after 2179 steps.
Found uncertainty sample 74 after 1130 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1339 steps.
Found uncertainty sample 77 after 2952 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 690 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3155 steps.
Found uncertainty sample 82 after 1652 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2214 steps.
Found uncertainty sample 85 after 2997 steps.
Found uncertainty sample 86 after 1374 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2679 steps.
Found uncertainty sample 89 after 1954 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2359 steps.
Found uncertainty sample 92 after 1660 steps.
Found uncertainty sample 93 after 2499 steps.
Found uncertainty sample 94 after 947 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_095344-jdrz0nlc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_49
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jdrz0nlc
Training model 49. Added 50 samples to the dataset.
Epoch 0, Batch 100/126, Loss: 0.2504529058933258, Uncertainty: 0.1358879953622818

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3318851397139024, Training Loss Force: 2.141437685107076, time: 1.899627685546875
Validation Loss Energy: 2.0380157273979127, Validation Loss Force: 2.0246166857647574, time: 0.11354947090148926
Test Loss Energy: 9.32451664821565, Test Loss Force: 7.418616147395477, time: 8.743945121765137

Epoch 1, Batch 100/126, Loss: 0.1637135148048401, Uncertainty: 0.13352549076080322

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1255971332815196, Training Loss Force: 1.9861480424810618, time: 1.8225560188293457
Validation Loss Energy: 1.4313724177489615, Validation Loss Force: 2.069213604541661, time: 0.12406325340270996
Test Loss Energy: 9.591197980634316, Test Loss Force: 7.437658591251882, time: 8.62678861618042

Epoch 2, Batch 100/126, Loss: 0.08158133924007416, Uncertainty: 0.1338304728269577

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.0932592604703837, Training Loss Force: 2.0031243028222874, time: 1.9153716564178467
Validation Loss Energy: 1.0637128512346838, Validation Loss Force: 2.0384716053626755, time: 0.1119232177734375
Test Loss Energy: 9.606372143807627, Test Loss Force: 7.320433234918238, time: 8.817129373550415

Epoch 3, Batch 100/126, Loss: 0.05077585577964783, Uncertainty: 0.13507573306560516

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9356091339253194, Training Loss Force: 2.0167119726138836, time: 1.8519563674926758
Validation Loss Energy: 3.239933973450473, Validation Loss Force: 2.148336858855641, time: 0.11482810974121094
Test Loss Energy: 8.723633288463422, Test Loss Force: 7.476888056665114, time: 9.26456618309021

Epoch 4, Batch 100/126, Loss: 0.04569833725690842, Uncertainty: 0.13303197920322418

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9606437526625387, Training Loss Force: 1.9992968446401498, time: 1.8629348278045654
Validation Loss Energy: 3.9862521458343263, Validation Loss Force: 2.059889705171178, time: 0.11406159400939941
Test Loss Energy: 13.6438417263779, Test Loss Force: 7.3008443563144985, time: 8.67320442199707

Epoch 5, Batch 100/126, Loss: 0.08375602960586548, Uncertainty: 0.13204877078533173

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7953362145579406, Training Loss Force: 2.0072545680690856, time: 1.871155023574829
Validation Loss Energy: 2.167926028522541, Validation Loss Force: 2.067232814042536, time: 0.11319851875305176
Test Loss Energy: 9.267060412167563, Test Loss Force: 7.3502833932608755, time: 8.827033996582031

Epoch 6, Batch 100/126, Loss: 0.2320709228515625, Uncertainty: 0.131463885307312

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0613130629028436, Training Loss Force: 1.9707592196402104, time: 1.8713939189910889
Validation Loss Energy: 2.4128595654594536, Validation Loss Force: 2.2395433285964415, time: 0.11906719207763672
Test Loss Energy: 11.935579484603057, Test Loss Force: 7.390492780118861, time: 8.66036319732666

Epoch 7, Batch 100/126, Loss: 0.048800840973854065, Uncertainty: 0.13453328609466553

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.568814085671752, Training Loss Force: 2.006104818584911, time: 1.8374896049499512
Validation Loss Energy: 1.661439708938676, Validation Loss Force: 2.0847538326820585, time: 0.11565423011779785
Test Loss Energy: 9.814213651048677, Test Loss Force: 7.304980248005173, time: 8.717068433761597

Epoch 8, Batch 100/126, Loss: 0.07420561462640762, Uncertainty: 0.13197723031044006

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7260939376134037, Training Loss Force: 1.9862682687985316, time: 1.997295618057251
Validation Loss Energy: 0.8034147350019863, Validation Loss Force: 2.1764452758226898, time: 0.12498998641967773
Test Loss Energy: 10.153884922245185, Test Loss Force: 7.252081170355717, time: 8.689218282699585

Epoch 9, Batch 100/126, Loss: 0.24939702451229095, Uncertainty: 0.13261663913726807

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8633471783985105, Training Loss Force: 2.0121687594834925, time: 1.8363873958587646
Validation Loss Energy: 2.315262862345769, Validation Loss Force: 2.200991060677942, time: 0.12260985374450684
Test Loss Energy: 9.43876717973391, Test Loss Force: 7.436754685089804, time: 8.703819036483765

Epoch 10, Batch 100/126, Loss: 0.19429802894592285, Uncertainty: 0.13631755113601685

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.610125303504136, Training Loss Force: 2.045404767082265, time: 1.8216345310211182
Validation Loss Energy: 0.881192770782368, Validation Loss Force: 2.0650721068735014, time: 0.12023329734802246
Test Loss Energy: 10.408422275819344, Test Loss Force: 7.45615760581152, time: 8.6519033908844

Epoch 11, Batch 100/126, Loss: 0.16577666997909546, Uncertainty: 0.13450336456298828

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.931908804804175, Training Loss Force: 2.017574885359364, time: 2.06829833984375
Validation Loss Energy: 1.1067351651461594, Validation Loss Force: 2.1399033391766746, time: 0.12833237648010254
Test Loss Energy: 9.436418493562032, Test Loss Force: 7.317996894046131, time: 8.700050115585327

Epoch 12, Batch 100/126, Loss: 0.21988371014595032, Uncertainty: 0.1364428699016571

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.49628976547686, Training Loss Force: 2.0673234686603754, time: 1.8546013832092285
Validation Loss Energy: 0.9195610768748067, Validation Loss Force: 2.27855221671019, time: 0.11358189582824707
Test Loss Energy: 10.690814658198946, Test Loss Force: 7.4611638843800625, time: 8.700680017471313

Epoch 13, Batch 100/126, Loss: 0.2706040143966675, Uncertainty: 0.13268785178661346

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3143421563536277, Training Loss Force: 1.9849797310494723, time: 1.8791780471801758
Validation Loss Energy: 0.9873707902206283, Validation Loss Force: 2.0526462036310984, time: 0.11163926124572754
Test Loss Energy: 9.778229808774874, Test Loss Force: 7.30327398913286, time: 8.8548002243042

Epoch 14, Batch 100/126, Loss: 0.0639435350894928, Uncertainty: 0.13137692213058472

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.705748802219844, Training Loss Force: 1.9818199233275984, time: 1.8627467155456543
Validation Loss Energy: 0.8511212469575339, Validation Loss Force: 1.9839495805212841, time: 0.1128852367401123
Test Loss Energy: 10.016695794072552, Test Loss Force: 7.361623858251327, time: 8.686369180679321

Epoch 15, Batch 100/126, Loss: 0.06637897342443466, Uncertainty: 0.1341547667980194

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.055073898174962, Training Loss Force: 1.9839845864084042, time: 1.9064161777496338
Validation Loss Energy: 1.7017704353257006, Validation Loss Force: 2.169016513553198, time: 0.11423492431640625
Test Loss Energy: 9.655201025325109, Test Loss Force: 7.480855633797608, time: 8.663618326187134

Epoch 16, Batch 100/126, Loss: 0.1465354859828949, Uncertainty: 0.13028717041015625

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7094169781813982, Training Loss Force: 1.9727567598073121, time: 1.913672685623169
Validation Loss Energy: 1.0534957888083603, Validation Loss Force: 1.9811461759740536, time: 0.11139273643493652
Test Loss Energy: 10.091732726811486, Test Loss Force: 7.324596877479855, time: 9.410151720046997

Epoch 17, Batch 100/126, Loss: 0.3739997446537018, Uncertainty: 0.13282784819602966

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8431132415023261, Training Loss Force: 1.9976997254499664, time: 1.9121730327606201
Validation Loss Energy: 0.78537582504056, Validation Loss Force: 2.031421306418213, time: 0.1128082275390625
Test Loss Energy: 10.139674275279864, Test Loss Force: 7.393672880239036, time: 8.629653453826904

Epoch 18, Batch 100/126, Loss: 0.17672008275985718, Uncertainty: 0.13244029879570007

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8470024740257152, Training Loss Force: 1.9997878142019818, time: 1.8848252296447754
Validation Loss Energy: 1.7174068565371392, Validation Loss Force: 2.0521233022534116, time: 0.11253571510314941
Test Loss Energy: 9.448396755266458, Test Loss Force: 7.28850778614587, time: 8.718257904052734

Epoch 19, Batch 100/126, Loss: 0.10198952257633209, Uncertainty: 0.12981028854846954

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.864435723247512, Training Loss Force: 1.9627985007810973, time: 1.8478114604949951
Validation Loss Energy: 0.8166941476364925, Validation Loss Force: 1.9936958090385435, time: 0.11332392692565918
Test Loss Energy: 9.81119518074908, Test Loss Force: 7.260795755232786, time: 8.835577011108398

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–‚â–â–ˆâ–‚â–†â–ƒâ–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒ
wandb:   test_error_force â–†â–‡â–ƒâ–ˆâ–‚â–„â–…â–ƒâ–â–‡â–‡â–ƒâ–‡â–ƒâ–„â–ˆâ–ƒâ–…â–‚â–
wandb:          test_loss â–ƒâ–†â–‚â–„â–‡â–‚â–ˆâ–â–â–…â–†â–‚â–†â–…â–…â–‡â–ƒâ–„â–â–„
wandb: train_error_energy â–…â–„â–ˆâ–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–†â–ƒâ–…â–„â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–‚â–ƒâ–„â–ƒâ–…â–‚â–‚â–‚â–â–‚â–‚â–
wandb:         train_loss â–ˆâ–‚â–…â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–ƒâ–†â–ƒâ–â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–„â–‚â–‚â–†â–ˆâ–„â–…â–ƒâ–â–„â–â–‚â–â–â–â–ƒâ–‚â–â–ƒâ–
wandb:  valid_error_force â–‚â–ƒâ–‚â–…â–ƒâ–ƒâ–‡â–ƒâ–†â–†â–ƒâ–…â–ˆâ–ƒâ–â–…â–â–‚â–ƒâ–
wandb:         valid_loss â–ƒâ–ƒâ–‚â–‡â–†â–„â–ˆâ–„â–…â–‡â–ƒâ–„â–‡â–ƒâ–â–†â–â–‚â–ƒâ–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4029
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.8112
wandb:   test_error_force 7.2608
wandb:          test_loss 4.76894
wandb: train_error_energy 1.86444
wandb:  train_error_force 1.9628
wandb:         train_loss -2.44997
wandb: valid_error_energy 0.81669
wandb:  valid_error_force 1.9937
wandb:         valid_loss -2.47994
wandb: 
wandb: ğŸš€ View run al_58_49 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jdrz0nlc
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_095344-jdrz0nlc/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.41666793823242, Uncertainty Bias: -5.380616664886475
1.9550323e-05 0.0011386946
-0.6831418 13.816297
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3357 steps.
Found uncertainty sample 2 after 1836 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2392 steps.
Found uncertainty sample 5 after 2592 steps.
Found uncertainty sample 6 after 3390 steps.
Found uncertainty sample 7 after 2147 steps.
Found uncertainty sample 8 after 1471 steps.
Found uncertainty sample 9 after 1986 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3803 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2339 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 587 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2894 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2765 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2372 steps.
Found uncertainty sample 30 after 1123 steps.
Found uncertainty sample 31 after 3502 steps.
Found uncertainty sample 32 after 3661 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1856 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1579 steps.
Found uncertainty sample 38 after 1255 steps.
Found uncertainty sample 39 after 1177 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 1043 steps.
Found uncertainty sample 44 after 2205 steps.
Found uncertainty sample 45 after 2354 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1051 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2122 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3542 steps.
Found uncertainty sample 58 after 1332 steps.
Found uncertainty sample 59 after 273 steps.
Found uncertainty sample 60 after 3099 steps.
Found uncertainty sample 61 after 1578 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2100 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1821 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3630 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3862 steps.
Found uncertainty sample 76 after 1709 steps.
Found uncertainty sample 77 after 771 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 688 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 902 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2448 steps.
Found uncertainty sample 88 after 1058 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1139 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2302 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 800 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2669 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_102826-ksqc3udt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_50
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ksqc3udt
Training model 50. Added 45 samples to the dataset.
Epoch 0, Batch 100/128, Loss: 0.10498662292957306, Uncertainty: 0.13599461317062378

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.15671178229812, Training Loss Force: 2.2166290397036006, time: 1.9429845809936523
Validation Loss Energy: 2.313029342366016, Validation Loss Force: 2.374028070431961, time: 0.1152806282043457
Test Loss Energy: 11.766789384401761, Test Loss Force: 7.506848463048548, time: 9.020689964294434

Epoch 1, Batch 100/128, Loss: 0.12993305921554565, Uncertainty: 0.13333138823509216

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1159091379785355, Training Loss Force: 1.9959154133564112, time: 1.9570484161376953
Validation Loss Energy: 1.4046144149289166, Validation Loss Force: 2.0620207231207552, time: 0.11928987503051758
Test Loss Energy: 10.594979429299524, Test Loss Force: 7.291846944316275, time: 8.525531530380249

Epoch 2, Batch 100/128, Loss: 0.11650367081165314, Uncertainty: 0.1338612586259842

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7130077321168098, Training Loss Force: 2.0073984716495232, time: 1.9553956985473633
Validation Loss Energy: 1.5599152705369226, Validation Loss Force: 2.164483192411254, time: 0.11398077011108398
Test Loss Energy: 9.525344431765317, Test Loss Force: 7.363870310140047, time: 8.717998266220093

Epoch 3, Batch 100/128, Loss: 0.08172222971916199, Uncertainty: 0.1334531307220459

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4496018239191, Training Loss Force: 1.9868433261160647, time: 1.889646291732788
Validation Loss Energy: 2.568021512631925, Validation Loss Force: 2.039242634391975, time: 0.11254215240478516
Test Loss Energy: 9.03422278940503, Test Loss Force: 7.348749643520496, time: 8.50351071357727

Epoch 4, Batch 100/128, Loss: 0.2687584161758423, Uncertainty: 0.1328853964805603

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.33384220815529, Training Loss Force: 1.9994013257997527, time: 1.830047845840454
Validation Loss Energy: 1.7923688698520206, Validation Loss Force: 2.2382511795426225, time: 0.11169910430908203
Test Loss Energy: 11.286096688149831, Test Loss Force: 7.285100141474698, time: 8.511445760726929

Epoch 5, Batch 100/128, Loss: 0.08460499346256256, Uncertainty: 0.13127392530441284

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9334515426056265, Training Loss Force: 2.0055277550912707, time: 1.9065189361572266
Validation Loss Energy: 1.4922175412157406, Validation Loss Force: 2.1617666288309354, time: 0.11009383201599121
Test Loss Energy: 11.496951330957435, Test Loss Force: 7.423663147604164, time: 8.753445386886597

Epoch 6, Batch 100/128, Loss: 0.06918182224035263, Uncertainty: 0.13399703800678253

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.635445878648845, Training Loss Force: 2.0048186834618917, time: 1.87080979347229
Validation Loss Energy: 2.8528824479095385, Validation Loss Force: 2.1055162460788517, time: 0.1111602783203125
Test Loss Energy: 12.194219905404685, Test Loss Force: 7.307183527727338, time: 8.422233581542969

Epoch 7, Batch 100/128, Loss: 0.05577531084418297, Uncertainty: 0.13219651579856873

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9195649604989184, Training Loss Force: 1.990413742370087, time: 1.8995184898376465
Validation Loss Energy: 8.181875339309437, Validation Loss Force: 2.112793296436918, time: 0.11176419258117676
Test Loss Energy: 8.794763102823305, Test Loss Force: 7.2578127371254775, time: 8.436726570129395

Epoch 8, Batch 100/128, Loss: 0.056910984218120575, Uncertainty: 0.13110850751399994

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2612869886721843, Training Loss Force: 1.9828336862736862, time: 1.8668978214263916
Validation Loss Energy: 2.601932613318803, Validation Loss Force: 2.1480653509437064, time: 0.11360383033752441
Test Loss Energy: 11.993105389280258, Test Loss Force: 7.426842310415472, time: 8.692104578018188

Epoch 9, Batch 100/128, Loss: 0.13589440286159515, Uncertainty: 0.13120758533477783

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.056033560767896, Training Loss Force: 1.987188608549078, time: 1.8710033893585205
Validation Loss Energy: 1.8486835297642283, Validation Loss Force: 2.1213752622131694, time: 0.11171817779541016
Test Loss Energy: 9.320452947960538, Test Loss Force: 7.375813774835743, time: 8.500622272491455

Epoch 10, Batch 100/128, Loss: 0.06209424510598183, Uncertainty: 0.13107207417488098

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0686820893762254, Training Loss Force: 1.9666577687445796, time: 1.9583885669708252
Validation Loss Energy: 2.0243524888231135, Validation Loss Force: 2.0843413752007516, time: 0.11341428756713867
Test Loss Energy: 9.491377654854102, Test Loss Force: 7.419486991269709, time: 8.472294569015503

Epoch 11, Batch 100/128, Loss: 0.08764584362506866, Uncertainty: 0.12999853491783142

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6086871043874846, Training Loss Force: 1.9688945733841687, time: 1.8844566345214844
Validation Loss Energy: 1.3055341786304884, Validation Loss Force: 2.13311779384672, time: 0.1679551601409912
Test Loss Energy: 10.670454136574193, Test Loss Force: 7.382852824519407, time: 8.656450510025024

Epoch 12, Batch 100/128, Loss: 0.051613949239254, Uncertainty: 0.13188481330871582

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4566939088453128, Training Loss Force: 1.9607827885861004, time: 1.8735387325286865
Validation Loss Energy: 1.0858647201020666, Validation Loss Force: 2.206595494634847, time: 0.11613583564758301
Test Loss Energy: 10.504478448470264, Test Loss Force: 7.2624656945523665, time: 8.45608115196228

Epoch 13, Batch 100/128, Loss: 0.1733088195323944, Uncertainty: 0.13040947914123535

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.587394164426975, Training Loss Force: 1.9529066903809833, time: 1.922764778137207
Validation Loss Energy: 0.8206179862145078, Validation Loss Force: 2.0264217160846965, time: 0.11197972297668457
Test Loss Energy: 10.12809799783484, Test Loss Force: 7.241565122139667, time: 8.467044591903687

Epoch 14, Batch 100/128, Loss: 0.0457194522023201, Uncertainty: 0.13212603330612183

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.632201509170953, Training Loss Force: 1.9872391657526214, time: 2.106675863265991
Validation Loss Energy: 1.122166025624382, Validation Loss Force: 2.1869571893097457, time: 0.1139841079711914
Test Loss Energy: 9.720869257505957, Test Loss Force: 7.315720434284028, time: 8.437640190124512

Epoch 15, Batch 100/128, Loss: 0.1245889961719513, Uncertainty: 0.13062646985054016

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4881063288708973, Training Loss Force: 1.9621509547988158, time: 1.8905391693115234
Validation Loss Energy: 0.896126522392307, Validation Loss Force: 2.031071344743863, time: 0.1101994514465332
Test Loss Energy: 10.084211513322971, Test Loss Force: 7.3081514413595094, time: 8.478954076766968

Epoch 16, Batch 100/128, Loss: 0.0981655940413475, Uncertainty: 0.13127748668193817

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.4695273411295997, Training Loss Force: 1.9635451924372345, time: 1.8694069385528564
Validation Loss Energy: 1.187206087354343, Validation Loss Force: 2.0138777239719032, time: 0.1159822940826416
Test Loss Energy: 10.87901053068599, Test Loss Force: 7.307559115783586, time: 9.349445581436157

Epoch 17, Batch 100/128, Loss: 0.2319314330816269, Uncertainty: 0.13228321075439453

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0018584180691694, Training Loss Force: 1.976780435109454, time: 1.8538239002227783
Validation Loss Energy: 0.9261241200606931, Validation Loss Force: 2.1251711773668487, time: 0.12210440635681152
Test Loss Energy: 9.859505870360739, Test Loss Force: 7.386861827439501, time: 8.46532940864563

Epoch 18, Batch 100/128, Loss: 0.1687229573726654, Uncertainty: 0.13036203384399414

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0595881201083834, Training Loss Force: 1.9616895399685845, time: 1.9475054740905762
Validation Loss Energy: 1.3239913354710156, Validation Loss Force: 2.197065292300662, time: 0.11346197128295898
Test Loss Energy: 10.873472499544059, Test Loss Force: 7.379211815588462, time: 8.529442548751831

Epoch 19, Batch 100/128, Loss: 0.15356194972991943, Uncertainty: 0.1304706633090973

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.028954227524581, Training Loss Force: 1.9446330068479971, time: 1.8925626277923584
Validation Loss Energy: 0.9576146401294765, Validation Loss Force: 2.131928443715271, time: 0.11056876182556152
Test Loss Energy: 10.442083811803123, Test Loss Force: 7.243016565902545, time: 8.658963203430176

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–…â–ƒâ–â–†â–‡â–ˆâ–â–ˆâ–‚â–‚â–…â–…â–„â–ƒâ–„â–…â–ƒâ–…â–„
wandb:   test_error_force â–ˆâ–‚â–„â–„â–‚â–†â–ƒâ–â–†â–…â–†â–…â–‚â–â–ƒâ–ƒâ–ƒâ–…â–…â–
wandb:          test_loss â–„â–â–‚â–â–„â–‡â–„â–â–ˆâ–ƒâ–…â–ˆâ–„â–ƒâ–ƒâ–ƒâ–…â–†â–ˆâ–…
wandb: train_error_energy â–ˆâ–„â–‚â–â–…â–ƒâ–‚â–ƒâ–„â–ƒâ–„â–‚â–â–‚â–‚â–â–â–ƒâ–„â–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–‚â–â–â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–â–â–‚â–â–â–‚â–‚â–
wandb: valid_error_energy â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ˆâ–ƒâ–‚â–‚â–â–â–â–â–â–â–â–â–
wandb:  valid_error_force â–ˆâ–‚â–„â–â–…â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–…â–â–„â–â–â–ƒâ–…â–ƒ
wandb:         valid_loss â–‡â–‚â–„â–ƒâ–…â–ƒâ–„â–ˆâ–„â–ƒâ–ƒâ–ƒâ–„â–â–„â–â–â–ƒâ–„â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4069
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.44208
wandb:   test_error_force 7.24302
wandb:          test_loss 4.86383
wandb: train_error_energy 2.02895
wandb:  train_error_force 1.94463
wandb:         train_loss -2.46234
wandb: valid_error_energy 0.95761
wandb:  valid_error_force 2.13193
wandb:         valid_loss -2.2901
wandb: 
wandb: ğŸš€ View run al_58_50 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/ksqc3udt
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_102826-ksqc3udt/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.88332748413086, Uncertainty Bias: -5.51340389251709
1.7642975e-05 0.0047836304
-0.6032802 16.24565
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3026 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 763 steps.
Found uncertainty sample 8 after 45 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 835 steps.
Found uncertainty sample 15 after 2748 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2137 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 355 steps.
Found uncertainty sample 20 after 388 steps.
Found uncertainty sample 21 after 1433 steps.
Found uncertainty sample 22 after 2588 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1444 steps.
Found uncertainty sample 25 after 3733 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 51 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2661 steps.
Found uncertainty sample 32 after 1262 steps.
Found uncertainty sample 33 after 3378 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2355 steps.
Found uncertainty sample 36 after 2633 steps.
Found uncertainty sample 37 after 3071 steps.
Found uncertainty sample 38 after 2204 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1389 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2599 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1167 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2279 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 2524 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3596 steps.
Found uncertainty sample 61 after 1239 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1303 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1860 steps.
Found uncertainty sample 68 after 1017 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1132 steps.
Found uncertainty sample 72 after 281 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2590 steps.
Found uncertainty sample 75 after 607 steps.
Found uncertainty sample 76 after 1946 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 461 steps.
Found uncertainty sample 79 after 1232 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2795 steps.
Found uncertainty sample 82 after 215 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1188 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1677 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2860 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1285 steps.
Found uncertainty sample 93 after 1230 steps.
Found uncertainty sample 94 after 2731 steps.
Found uncertainty sample 95 after 262 steps.
Found uncertainty sample 96 after 2834 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_110048-65i4r993
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_51
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/65i4r993
Training model 51. Added 47 samples to the dataset.
Epoch 0, Batch 100/129, Loss: 0.11525456607341766, Uncertainty: 0.13257469236850739

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 1.7107136192194636, Training Loss Force: 2.1227583077467553, time: 1.9120490550994873
Validation Loss Energy: 1.6523980427106568, Validation Loss Force: 1.9381213755904483, time: 0.11908411979675293
Test Loss Energy: 9.525188367507583, Test Loss Force: 7.309178582652885, time: 8.532783031463623

Epoch 1, Batch 100/129, Loss: 0.21357378363609314, Uncertainty: 0.13214489817619324

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8756327246846363, Training Loss Force: 1.977429384316344, time: 1.9142751693725586
Validation Loss Energy: 2.586065061533891, Validation Loss Force: 2.0084174311754617, time: 0.11820840835571289
Test Loss Energy: 9.208482996166484, Test Loss Force: 7.353900269985955, time: 8.588804244995117

Epoch 2, Batch 100/129, Loss: 0.24196192622184753, Uncertainty: 0.13165025413036346

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9891246401832028, Training Loss Force: 1.9758004801124818, time: 1.9757952690124512
Validation Loss Energy: 2.21809732092165, Validation Loss Force: 1.9893759533844957, time: 0.11333155632019043
Test Loss Energy: 9.109164144619042, Test Loss Force: 7.270706455808198, time: 8.761683464050293

Epoch 3, Batch 100/129, Loss: 0.07949702441692352, Uncertainty: 0.13012906908988953

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.0066672607505858, Training Loss Force: 1.967574982610158, time: 1.924654483795166
Validation Loss Energy: 1.1974952203608986, Validation Loss Force: 1.98441020876116, time: 0.1186516284942627
Test Loss Energy: 9.628894225583569, Test Loss Force: 7.277031077949096, time: 8.585813760757446

Epoch 4, Batch 100/129, Loss: 0.05528160184621811, Uncertainty: 0.13207665085792542

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.1379202348171615, Training Loss Force: 1.9909905610209075, time: 1.994459867477417
Validation Loss Energy: 1.6535709524368312, Validation Loss Force: 2.0949921600118184, time: 0.11501073837280273
Test Loss Energy: 9.012304115366797, Test Loss Force: 7.3512612768749115, time: 8.604835271835327

Epoch 5, Batch 100/129, Loss: 0.05697696655988693, Uncertainty: 0.13450592756271362

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7114178026259321, Training Loss Force: 1.9987554182005332, time: 1.9110198020935059
Validation Loss Energy: 1.1796606835639096, Validation Loss Force: 2.0628312388119325, time: 0.11343169212341309
Test Loss Energy: 9.59482244210004, Test Loss Force: 7.232579885830239, time: 8.760162591934204

Epoch 6, Batch 100/129, Loss: 0.1497100591659546, Uncertainty: 0.132206991314888

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.26606355097569, Training Loss Force: 1.9918151790913272, time: 1.9759511947631836
Validation Loss Energy: 1.3116453704520008, Validation Loss Force: 2.1054313349112044, time: 0.11625409126281738
Test Loss Energy: 9.30126800750881, Test Loss Force: 7.308753979405163, time: 8.527678489685059

Epoch 7, Batch 100/129, Loss: 0.08602291345596313, Uncertainty: 0.1312175989151001

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.622389288282389, Training Loss Force: 1.973086017217051, time: 1.8641510009765625
Validation Loss Energy: 4.0213736017754185, Validation Loss Force: 2.155477561473351, time: 0.11375641822814941
Test Loss Energy: 8.848402663803029, Test Loss Force: 7.318601103859088, time: 8.547683477401733

Epoch 8, Batch 100/129, Loss: 0.07220284640789032, Uncertainty: 0.13288143277168274

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.1754466513083734, Training Loss Force: 1.9881916435158848, time: 1.8982019424438477
Validation Loss Energy: 2.7056792897969153, Validation Loss Force: 2.015577060670575, time: 0.11801910400390625
Test Loss Energy: 12.021126610875049, Test Loss Force: 7.2643219018586445, time: 8.76351809501648

Epoch 9, Batch 100/129, Loss: 0.07423921674489975, Uncertainty: 0.13174137473106384

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4599814522363688, Training Loss Force: 1.9741667263817546, time: 1.9235899448394775
Validation Loss Energy: 1.9327004210097878, Validation Loss Force: 2.058450742927144, time: 0.12093448638916016
Test Loss Energy: 11.263326681184102, Test Loss Force: 7.268549952927978, time: 8.584035158157349

Epoch 10, Batch 100/129, Loss: 0.05705982819199562, Uncertainty: 0.13309121131896973

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8105992562916535, Training Loss Force: 1.98897425306689, time: 1.9108169078826904
Validation Loss Energy: 2.366356598793408, Validation Loss Force: 2.0616674214092168, time: 0.11409640312194824
Test Loss Energy: 11.729446612149081, Test Loss Force: 7.225073429127322, time: 8.564637660980225

Epoch 11, Batch 100/129, Loss: 0.08656425029039383, Uncertainty: 0.13062144815921783

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5876506718054892, Training Loss Force: 1.9498337890643653, time: 2.1259922981262207
Validation Loss Energy: 4.074782429333269, Validation Loss Force: 2.0871371347739722, time: 0.11937403678894043
Test Loss Energy: 13.023785238130943, Test Loss Force: 7.268017771337596, time: 8.552480936050415

Epoch 12, Batch 100/129, Loss: 0.18689128756523132, Uncertainty: 0.13119956851005554

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.774739267639157, Training Loss Force: 1.9662094027955876, time: 1.8692471981048584
Validation Loss Energy: 0.7444481968963516, Validation Loss Force: 1.93935377509011, time: 0.11565017700195312
Test Loss Energy: 10.009266147732715, Test Loss Force: 7.230423835283151, time: 9.174375057220459

Epoch 13, Batch 100/129, Loss: 0.08247452974319458, Uncertainty: 0.12998290359973907

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6766840602730697, Training Loss Force: 1.9593801841059764, time: 1.8871898651123047
Validation Loss Energy: 2.105345310397828, Validation Loss Force: 2.061821285789053, time: 0.11486363410949707
Test Loss Energy: 11.24274522047108, Test Loss Force: 7.28894006040396, time: 8.71453857421875

Epoch 14, Batch 100/129, Loss: 0.043852247297763824, Uncertainty: 0.12974479794502258

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.761333062618748, Training Loss Force: 1.9617326689607053, time: 1.940134048461914
Validation Loss Energy: 0.7994738807900698, Validation Loss Force: 1.981482591942026, time: 0.11551213264465332
Test Loss Energy: 10.040504334598117, Test Loss Force: 7.150599170827885, time: 8.601173877716064

Epoch 15, Batch 100/129, Loss: 0.19750259816646576, Uncertainty: 0.13075673580169678

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8014090749216523, Training Loss Force: 1.9637954025685904, time: 1.9121317863464355
Validation Loss Energy: 2.513670052356314, Validation Loss Force: 2.0611889796376666, time: 0.1155235767364502
Test Loss Energy: 11.59499134813334, Test Loss Force: 7.283518803490673, time: 8.537993669509888

Epoch 16, Batch 100/129, Loss: 0.10856200754642487, Uncertainty: 0.13152828812599182

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7270262136986243, Training Loss Force: 1.9484746839162013, time: 1.886462926864624
Validation Loss Energy: 2.5802443416132417, Validation Loss Force: 2.1321017545338514, time: 0.11545133590698242
Test Loss Energy: 8.882293488385148, Test Loss Force: 7.267343643412817, time: 8.791198492050171

Epoch 17, Batch 100/129, Loss: 0.10506060719490051, Uncertainty: 0.13024687767028809

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.5998751971286909, Training Loss Force: 1.9547578410477728, time: 1.8667223453521729
Validation Loss Energy: 1.1547140942459873, Validation Loss Force: 2.0674805705789048, time: 0.11419343948364258
Test Loss Energy: 10.58150036356186, Test Loss Force: 7.2905411984548705, time: 8.555378437042236

Epoch 18, Batch 100/129, Loss: 0.05626607686281204, Uncertainty: 0.13159368932247162

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.606607612996286, Training Loss Force: 1.9863418472039682, time: 1.9099528789520264
Validation Loss Energy: 0.8198321125754799, Validation Loss Force: 1.965767086072259, time: 0.1158132553100586
Test Loss Energy: 10.261012106903841, Test Loss Force: 7.27322669981346, time: 8.524041175842285

Epoch 19, Batch 100/129, Loss: 0.1270509660243988, Uncertainty: 0.13093958795070648

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.190097817647897, Training Loss Force: 1.966979281367633, time: 1.9401631355285645
Validation Loss Energy: 6.927129654839045, Validation Loss Force: 2.018295999388451, time: 0.125532865524292
Test Loss Energy: 16.049694244722925, Test Loss Force: 7.2682870074802, time: 8.766894817352295

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–â–‚â–â–‚â–â–â–„â–ƒâ–„â–…â–‚â–ƒâ–‚â–„â–â–ƒâ–‚â–ˆ
wandb:   test_error_force â–†â–ˆâ–…â–…â–ˆâ–„â–†â–‡â–…â–…â–„â–…â–„â–†â–â–†â–…â–†â–…â–…
wandb:          test_loss â–‚â–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–ƒâ–†â–‚â–„â–‚â–„â–â–„â–‚â–ˆ
wandb: train_error_energy â–‚â–ƒâ–„â–„â–…â–‚â–†â–â–†â–ˆâ–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–â–â–†
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–â–‚â–â–‚â–‚â–â–â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–„â–‚â–„â–„â–ƒâ–â–‚â–‚â–‚â–‚â–â–â–‚â–ƒ
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–…â–ƒâ–‚â–ƒâ–…â–â–ƒâ–â–ƒâ–ƒâ–â–â–ˆ
wandb:  valid_error_force â–â–ƒâ–ƒâ–‚â–†â–…â–†â–ˆâ–ƒâ–…â–…â–†â–â–…â–‚â–…â–‡â–…â–‚â–„
wandb:         valid_loss â–‚â–„â–ƒâ–‚â–…â–„â–„â–ˆâ–„â–„â–…â–‡â–â–„â–‚â–…â–†â–„â–‚â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4111
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 16.04969
wandb:   test_error_force 7.26829
wandb:          test_loss 5.21012
wandb: train_error_energy 2.1901
wandb:  train_error_force 1.96698
wandb:         train_loss -2.42286
wandb: valid_error_energy 6.92713
wandb:  valid_error_force 2.0183
wandb:         valid_loss -2.03915
wandb: 
wandb: ğŸš€ View run al_58_51 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/65i4r993
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_110048-65i4r993/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 47.059261322021484, Uncertainty Bias: -5.97125768661499
1.6212463e-05 0.07891464
-0.7954811 14.6302395
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1285 steps.
Found uncertainty sample 7 after 2802 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2403 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1174 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2634 steps.
Found uncertainty sample 19 after 2988 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2899 steps.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 755 steps.
Found uncertainty sample 29 after 1272 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1146 steps.
Found uncertainty sample 32 after 2029 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2704 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 2174 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2006 steps.
Found uncertainty sample 47 after 1706 steps.
Found uncertainty sample 48 after 3583 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3877 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1330 steps.
Found uncertainty sample 53 after 1849 steps.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1584 steps.
Found uncertainty sample 56 after 2327 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2263 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3179 steps.
Found uncertainty sample 62 after 2074 steps.
Found uncertainty sample 63 after 3986 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1837 steps.
Found uncertainty sample 70 after 2159 steps.
Found uncertainty sample 71 after 1105 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3866 steps.
Found uncertainty sample 74 after 2636 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 913 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1913 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2454 steps.
Found uncertainty sample 84 after 880 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 570 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2020 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 564 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 2701 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_113719-3xij5jti
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_52
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3xij5jti
Training model 52. Added 38 samples to the dataset.
Epoch 0, Batch 100/130, Loss: 0.13265670835971832, Uncertainty: 0.1328624188899994

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.281134029658314, Training Loss Force: 2.0419487919008747, time: 1.8962182998657227
Validation Loss Energy: 1.1462455041765374, Validation Loss Force: 2.0419726323440983, time: 0.1319715976715088
Test Loss Energy: 9.564708442969815, Test Loss Force: 7.1546115056245165, time: 9.830971717834473

Epoch 1, Batch 100/130, Loss: 0.13220269978046417, Uncertainty: 0.13048610091209412

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.70928718045516, Training Loss Force: 1.9671703273322407, time: 1.9461898803710938
Validation Loss Energy: 1.2821521369549032, Validation Loss Force: 1.9899966807402938, time: 0.1240239143371582
Test Loss Energy: 10.655979350374679, Test Loss Force: 7.257400332882691, time: 9.814423322677612

Epoch 2, Batch 100/130, Loss: 0.1830313801765442, Uncertainty: 0.1285364329814911

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.4684987074611575, Training Loss Force: 1.9402340364672568, time: 1.9400808811187744
Validation Loss Energy: 2.132260369188801, Validation Loss Force: 1.9926531236512126, time: 0.132002592086792
Test Loss Energy: 9.371874691604223, Test Loss Force: 7.167903762441011, time: 10.089152812957764

Epoch 3, Batch 100/130, Loss: 0.09089822322130203, Uncertainty: 0.13030222058296204

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8666844281041317, Training Loss Force: 1.9814630264609303, time: 1.953444242477417
Validation Loss Energy: 1.299732756702486, Validation Loss Force: 2.181338281858355, time: 0.12724685668945312
Test Loss Energy: 10.430520409531123, Test Loss Force: 7.2963979425904695, time: 9.773371458053589

Epoch 4, Batch 100/130, Loss: 0.057937704026699066, Uncertainty: 0.13069534301757812

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.6047777550997706, Training Loss Force: 1.9749129514690078, time: 1.9713284969329834
Validation Loss Energy: 0.837809547296868, Validation Loss Force: 2.089604531579998, time: 0.1274096965789795
Test Loss Energy: 10.02020110539487, Test Loss Force: 7.210977686436144, time: 10.004247903823853

Epoch 5, Batch 100/130, Loss: 0.1537543684244156, Uncertainty: 0.12912870943546295

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9288427775440213, Training Loss Force: 1.9614569376510806, time: 1.9640672206878662
Validation Loss Energy: 2.7078879450553734, Validation Loss Force: 2.160103958318292, time: 0.1258561611175537
Test Loss Energy: 8.838040117400825, Test Loss Force: 7.311654148268886, time: 9.889567375183105

Epoch 6, Batch 100/130, Loss: 0.08370935916900635, Uncertainty: 0.130686417222023

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8026194595430993, Training Loss Force: 1.9833248608218887, time: 1.9233312606811523
Validation Loss Energy: 0.9899427858579536, Validation Loss Force: 2.146772682328547, time: 0.12302517890930176
Test Loss Energy: 9.015710319100458, Test Loss Force: 7.312068928426433, time: 9.8068208694458

Epoch 7, Batch 100/130, Loss: 0.12312650680541992, Uncertainty: 0.13103723526000977

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5840521781738086, Training Loss Force: 1.9664289358517373, time: 1.9154117107391357
Validation Loss Energy: 1.1473420012741347, Validation Loss Force: 1.9506671861679337, time: 0.12571263313293457
Test Loss Energy: 10.426087227717074, Test Loss Force: 7.173364547208026, time: 10.015383005142212

Epoch 8, Batch 100/130, Loss: 0.049135614186525345, Uncertainty: 0.130774587392807

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.846005215176451, Training Loss Force: 1.9574125465684067, time: 1.8997609615325928
Validation Loss Energy: 0.9325363976790243, Validation Loss Force: 2.027893633362328, time: 0.12364721298217773
Test Loss Energy: 10.122592254884875, Test Loss Force: 7.198304226010378, time: 9.838536500930786

Epoch 9, Batch 100/130, Loss: 0.05432755500078201, Uncertainty: 0.13041600584983826

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7276596981840608, Training Loss Force: 1.9824661663788912, time: 1.941819667816162
Validation Loss Energy: 1.9452366939255221, Validation Loss Force: 2.07929777059939, time: 0.1240389347076416
Test Loss Energy: 8.999676676340005, Test Loss Force: 7.127777681822971, time: 10.046178102493286

Epoch 10, Batch 100/130, Loss: 0.10717082023620605, Uncertainty: 0.1327487975358963

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.005972986705336, Training Loss Force: 1.9873176012269054, time: 1.9499969482421875
Validation Loss Energy: 0.8219373751271785, Validation Loss Force: 1.936337944177664, time: 0.12752413749694824
Test Loss Energy: 9.864215301812584, Test Loss Force: 7.129313142968095, time: 9.97252368927002

Epoch 11, Batch 100/130, Loss: 0.11174876987934113, Uncertainty: 0.1327546238899231

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6520992024465324, Training Loss Force: 1.99168743611265, time: 2.0031497478485107
Validation Loss Energy: 1.7536214695386398, Validation Loss Force: 2.076694248722154, time: 0.13038420677185059
Test Loss Energy: 10.790485140467828, Test Loss Force: 7.163274489550084, time: 10.475264072418213

Epoch 12, Batch 100/130, Loss: 0.04213462769985199, Uncertainty: 0.13084766268730164

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.4833119038544416, Training Loss Force: 1.9549921706346425, time: 1.9456641674041748
Validation Loss Energy: 2.176725542054364, Validation Loss Force: 2.038654416731483, time: 0.12581396102905273
Test Loss Energy: 11.414572140774888, Test Loss Force: 7.31361578883286, time: 10.080135822296143

Epoch 13, Batch 100/130, Loss: 0.10524434596300125, Uncertainty: 0.12941546738147736

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2811486879687517, Training Loss Force: 1.9635071483966544, time: 1.9768304824829102
Validation Loss Energy: 2.1592873563371264, Validation Loss Force: 2.0608677422831416, time: 0.1301124095916748
Test Loss Energy: 9.01854248877076, Test Loss Force: 7.295773028044361, time: 9.986307144165039

Epoch 14, Batch 100/130, Loss: 0.12475152313709259, Uncertainty: 0.128259539604187

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6380032203748127, Training Loss Force: 1.9354086701812925, time: 1.9240622520446777
Validation Loss Energy: 1.7412844483969865, Validation Loss Force: 2.117865254242861, time: 0.12483787536621094
Test Loss Energy: 9.007775593852465, Test Loss Force: 7.1434702350893, time: 10.061847686767578

Epoch 15, Batch 100/130, Loss: 0.051666222512722015, Uncertainty: 0.1306319385766983

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.4553402429972537, Training Loss Force: 1.9896285215727298, time: 1.9664359092712402
Validation Loss Energy: 0.7923020044919303, Validation Loss Force: 2.1088013582117733, time: 0.1287095546722412
Test Loss Energy: 9.353207043055274, Test Loss Force: 7.261773424338323, time: 9.888948202133179

Epoch 16, Batch 100/130, Loss: 0.11888506263494492, Uncertainty: 0.13202229142189026

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0015246506686144, Training Loss Force: 1.9758833281914052, time: 1.8798134326934814
Validation Loss Energy: 0.8154725104788841, Validation Loss Force: 2.067402413708684, time: 0.1264948844909668
Test Loss Energy: 9.457960136274892, Test Loss Force: 7.102984400406321, time: 9.854377746582031

Epoch 17, Batch 100/130, Loss: 0.16961851716041565, Uncertainty: 0.13070249557495117

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6068510544947279, Training Loss Force: 1.9519937541622476, time: 1.9299101829528809
Validation Loss Energy: 1.1326405678064468, Validation Loss Force: 2.1158418597138153, time: 0.12790441513061523
Test Loss Energy: 9.580953120121867, Test Loss Force: 7.152635250503406, time: 10.043172121047974

Epoch 18, Batch 100/130, Loss: 0.29538220167160034, Uncertainty: 0.13108931481838226

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.277838207539697, Training Loss Force: 1.9646102033860722, time: 1.9429185390472412
Validation Loss Energy: 0.9474324254244907, Validation Loss Force: 2.1320038543326922, time: 0.12406229972839355
Test Loss Energy: 9.743964300802777, Test Loss Force: 7.236245567901523, time: 9.83575963973999

Epoch 19, Batch 100/130, Loss: 0.0611557736992836, Uncertainty: 0.13379302620887756

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.4545426875067895, Training Loss Force: 1.9897895242115322, time: 1.9529249668121338
Validation Loss Energy: 0.8440699460019142, Validation Loss Force: 2.1271763872489777, time: 0.12508344650268555
Test Loss Energy: 9.869877533374048, Test Loss Force: 7.379478398354226, time: 9.860525369644165

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–†â–‚â–…â–„â–â–â–…â–„â–â–„â–†â–ˆâ–â–â–‚â–ƒâ–ƒâ–ƒâ–„
wandb:   test_error_force â–‚â–…â–ƒâ–†â–„â–†â–†â–ƒâ–ƒâ–‚â–‚â–ƒâ–†â–†â–‚â–…â–â–‚â–„â–ˆ
wandb:          test_loss â–â–†â–ƒâ–…â–„â–…â–„â–ƒâ–„â–â–â–ƒâ–ˆâ–…â–ƒâ–„â–â–ƒâ–„â–„
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–‚â–ƒâ–‚â–â–„â–‚â–â–ƒâ–‚â–„â–
wandb:  train_error_force â–ˆâ–ƒâ–â–„â–„â–ƒâ–„â–ƒâ–‚â–„â–„â–…â–‚â–ƒâ–â–…â–„â–‚â–ƒâ–…
wandb:         train_loss â–ˆâ–‚â–â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–ƒ
wandb: valid_error_energy â–‚â–ƒâ–†â–ƒâ–â–ˆâ–‚â–‚â–‚â–…â–â–…â–†â–†â–„â–â–â–‚â–‚â–
wandb:  valid_error_force â–„â–ƒâ–ƒâ–ˆâ–…â–‡â–‡â–â–„â–…â–â–…â–„â–…â–†â–†â–…â–†â–‡â–†
wandb:         valid_loss â–„â–ƒâ–„â–‡â–„â–ˆâ–†â–‚â–ƒâ–…â–â–…â–…â–…â–†â–…â–„â–…â–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4145
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.86988
wandb:   test_error_force 7.37948
wandb:          test_loss 4.6994
wandb: train_error_energy 1.45454
wandb:  train_error_force 1.98979
wandb:         train_loss -2.4431
wandb: valid_error_energy 0.84407
wandb:  valid_error_force 2.12718
wandb:         valid_loss -2.3114
wandb: 
wandb: ğŸš€ View run al_58_52 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/3xij5jti
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_113719-3xij5jti/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 32.32945251464844, Uncertainty Bias: -4.172669887542725
0.000102996826 0.004527092
-0.2455061 18.74961
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3200 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1587 steps.
Found uncertainty sample 6 after 3344 steps.
Found uncertainty sample 7 after 1673 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3246 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2037 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3448 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2537 steps.
Found uncertainty sample 19 after 1084 steps.
Found uncertainty sample 20 after 868 steps.
Found uncertainty sample 21 after 1583 steps.
Found uncertainty sample 22 after 1819 steps.
Found uncertainty sample 23 after 831 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3956 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1096 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2370 steps.
Found uncertainty sample 30 after 2628 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 754 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 34 steps.
Found uncertainty sample 36 after 3432 steps.
Found uncertainty sample 37 after 3886 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 488 steps.
Found uncertainty sample 40 after 1860 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 307 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 991 steps.
Found uncertainty sample 52 after 2140 steps.
Found uncertainty sample 53 after 2756 steps.
Found uncertainty sample 54 after 1380 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1178 steps.
Found uncertainty sample 58 after 709 steps.
Found uncertainty sample 59 after 2532 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2471 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3806 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 14 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2124 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2055 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2005 steps.
Found uncertainty sample 77 after 2050 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1663 steps.
Found uncertainty sample 81 after 2492 steps.
Found uncertainty sample 82 after 2434 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3959 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3512 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2518 steps.
Found uncertainty sample 97 after 2644 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_121334-lslvycy1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_53
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lslvycy1
Training model 53. Added 45 samples to the dataset.
Epoch 0, Batch 100/131, Loss: 0.07659542560577393, Uncertainty: 0.13620929419994354

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.877823766257831, Training Loss Force: 2.183684120574702, time: 2.0037665367126465
Validation Loss Energy: 0.9849514342828365, Validation Loss Force: 2.104220682764795, time: 0.13096141815185547
Test Loss Energy: 9.443719625996263, Test Loss Force: 7.160832450213132, time: 9.850262641906738

Epoch 1, Batch 100/131, Loss: 0.11975977569818497, Uncertainty: 0.13184429705142975

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9389142749226302, Training Loss Force: 1.9766191482100695, time: 1.9165475368499756
Validation Loss Energy: 0.9091564713603256, Validation Loss Force: 2.0839078383736305, time: 0.12436938285827637
Test Loss Energy: 9.963844994824514, Test Loss Force: 7.258662808649751, time: 9.856593608856201

Epoch 2, Batch 100/131, Loss: 0.29304933547973633, Uncertainty: 0.13003960251808167

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.350186852681947, Training Loss Force: 1.9485181286180067, time: 2.0436577796936035
Validation Loss Energy: 2.59722316088243, Validation Loss Force: 2.2274212945151812, time: 0.1255636215209961
Test Loss Energy: 11.69780278039015, Test Loss Force: 7.244243260719727, time: 10.08031415939331

Epoch 3, Batch 100/131, Loss: 0.1447870135307312, Uncertainty: 0.12976199388504028

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4827485630522164, Training Loss Force: 1.9480416854861826, time: 1.9185714721679688
Validation Loss Energy: 1.239391459289893, Validation Loss Force: 2.131818742049377, time: 0.1280839443206787
Test Loss Energy: 10.446468510033714, Test Loss Force: 7.233894170062454, time: 9.928836345672607

Epoch 4, Batch 100/131, Loss: 0.22338224947452545, Uncertainty: 0.1299203783273697

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.5897418022090088, Training Loss Force: 1.9565435733750647, time: 1.925900936126709
Validation Loss Energy: 1.1071789818655178, Validation Loss Force: 2.030230694494937, time: 0.13723039627075195
Test Loss Energy: 9.566772653569373, Test Loss Force: 7.196475202992814, time: 10.042340278625488

Epoch 5, Batch 100/131, Loss: 0.13451892137527466, Uncertainty: 0.12928082048892975

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9897637098884848, Training Loss Force: 1.954247647109284, time: 1.9065423011779785
Validation Loss Energy: 3.2057371882493695, Validation Loss Force: 1.9968998696023468, time: 0.12659192085266113
Test Loss Energy: 8.754058879837872, Test Loss Force: 7.217733953299324, time: 9.971753120422363

Epoch 6, Batch 100/131, Loss: 0.2573002576828003, Uncertainty: 0.13242517411708832

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8953297939409712, Training Loss Force: 1.9733217079687215, time: 1.9932374954223633
Validation Loss Energy: 0.848466399842161, Validation Loss Force: 2.179812107532166, time: 0.1287853717803955
Test Loss Energy: 9.35147785742158, Test Loss Force: 7.209167134465428, time: 9.911791563034058

Epoch 7, Batch 100/131, Loss: 0.1351325511932373, Uncertainty: 0.13291804492473602

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9168995280383214, Training Loss Force: 1.9785979349701757, time: 1.961578130722046
Validation Loss Energy: 0.7719096672156689, Validation Loss Force: 2.062489144780739, time: 0.13176226615905762
Test Loss Energy: 9.479677811188582, Test Loss Force: 7.157880360966773, time: 10.021308422088623

Epoch 8, Batch 100/131, Loss: 0.07038626819849014, Uncertainty: 0.13222679495811462

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8873758922705701, Training Loss Force: 1.9882481148963742, time: 2.0781710147857666
Validation Loss Energy: 0.9112539033803922, Validation Loss Force: 2.0166034912102537, time: 0.12556886672973633
Test Loss Energy: 9.772331366052828, Test Loss Force: 7.190338716461507, time: 9.87276577949524

Epoch 9, Batch 100/131, Loss: 0.1896832138299942, Uncertainty: 0.13044482469558716

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2107180900721874, Training Loss Force: 1.9777915905010146, time: 1.9944872856140137
Validation Loss Energy: 1.0193171882541745, Validation Loss Force: 2.0679780134509076, time: 0.1250166893005371
Test Loss Energy: 10.309500969138073, Test Loss Force: 7.127299698602193, time: 10.028795003890991

Epoch 10, Batch 100/131, Loss: 0.1749051809310913, Uncertainty: 0.13180837035179138

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7499409488453674, Training Loss Force: 1.978731482065269, time: 1.9312937259674072
Validation Loss Energy: 2.430566883951069, Validation Loss Force: 2.0567173378491446, time: 0.12834620475769043
Test Loss Energy: 8.892139556617888, Test Loss Force: 7.196386079375704, time: 9.969778537750244

Epoch 11, Batch 100/131, Loss: 0.09441884607076645, Uncertainty: 0.13092170655727386

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.3687100308989806, Training Loss Force: 1.957268135376385, time: 1.976449966430664
Validation Loss Energy: 0.9058043729260042, Validation Loss Force: 2.004699375999808, time: 0.13307714462280273
Test Loss Energy: 9.39468475103685, Test Loss Force: 7.214380346116384, time: 9.8772714138031

Epoch 12, Batch 100/131, Loss: 0.1382533609867096, Uncertainty: 0.13036933541297913

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8892512747088597, Training Loss Force: 1.9934341991384277, time: 2.057230234146118
Validation Loss Energy: 0.8729970803070147, Validation Loss Force: 1.995991231040864, time: 0.1255178451538086
Test Loss Energy: 9.816191577937094, Test Loss Force: 7.169383770808149, time: 10.607407331466675

Epoch 13, Batch 100/131, Loss: 0.17517009377479553, Uncertainty: 0.12978777289390564

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9735863366505413, Training Loss Force: 1.9374492122285292, time: 1.972057580947876
Validation Loss Energy: 1.8169314662277907, Validation Loss Force: 1.9087562139637837, time: 0.13037729263305664
Test Loss Energy: 10.877861133539236, Test Loss Force: 7.171287253921789, time: 9.843887329101562

Epoch 14, Batch 100/131, Loss: 0.13151519000530243, Uncertainty: 0.12832710146903992

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.118832923358129, Training Loss Force: 1.9371415047159128, time: 2.0521810054779053
Validation Loss Energy: 2.1560758734684584, Validation Loss Force: 2.1418742580103305, time: 0.1285245418548584
Test Loss Energy: 11.14844520090246, Test Loss Force: 7.223984588661806, time: 10.084996461868286

Epoch 15, Batch 100/131, Loss: 0.25266292691230774, Uncertainty: 0.13039061427116394

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0547161918205767, Training Loss Force: 1.9610139071948252, time: 1.9188740253448486
Validation Loss Energy: 3.2038301754605953, Validation Loss Force: 2.0161968231267413, time: 0.1272425651550293
Test Loss Energy: 8.580361268241035, Test Loss Force: 7.232886721581713, time: 9.835055112838745

Epoch 16, Batch 100/131, Loss: 0.047660958021879196, Uncertainty: 0.1305522471666336

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5637335356103603, Training Loss Force: 1.9610578690532656, time: 1.9768216609954834
Validation Loss Energy: 3.2189684115695445, Validation Loss Force: 2.0516240038051925, time: 0.1323082447052002
Test Loss Energy: 12.514710344453494, Test Loss Force: 7.167151014820614, time: 9.930608749389648

Epoch 17, Batch 100/131, Loss: 0.09535626322031021, Uncertainty: 0.13303260505199432

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2410659123118286, Training Loss Force: 2.0174608305966557, time: 1.9923300743103027
Validation Loss Energy: 0.9322944490962115, Validation Loss Force: 2.078509224930611, time: 0.1263139247894287
Test Loss Energy: 10.037483075688062, Test Loss Force: 7.146031088817228, time: 9.991666793823242

Epoch 18, Batch 100/131, Loss: 0.06423965096473694, Uncertainty: 0.1296451985836029

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.681114905526952, Training Loss Force: 1.9658270129685094, time: 1.9796350002288818
Validation Loss Energy: 1.886197305897645, Validation Loss Force: 2.1018295130297258, time: 0.12895512580871582
Test Loss Energy: 9.145957066309741, Test Loss Force: 7.213281890074345, time: 9.919289350509644

Epoch 19, Batch 100/131, Loss: 0.056313011795282364, Uncertainty: 0.13169656693935394

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.4588476961302357, Training Loss Force: 1.9656372810086522, time: 1.9399638175964355
Validation Loss Energy: 1.20240295967172, Validation Loss Force: 2.161786891723214, time: 0.1265869140625
Test Loss Energy: 10.031941920183243, Test Loss Force: 7.2198883623900905, time: 10.048718929290771

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–ƒâ–‡â–„â–ƒâ–â–‚â–ƒâ–ƒâ–„â–‚â–‚â–ƒâ–…â–†â–â–ˆâ–„â–‚â–„
wandb:   test_error_force â–ƒâ–ˆâ–‡â–‡â–…â–†â–…â–ƒâ–„â–â–…â–†â–ƒâ–ƒâ–†â–‡â–ƒâ–‚â–†â–†
wandb:          test_loss â–â–†â–‡â–†â–†â–…â–ƒâ–‚â–„â–ƒâ–„â–…â–„â–†â–ˆâ–…â–‡â–ƒâ–ƒâ–…
wandb: train_error_energy â–ˆâ–„â–†â–‚â–‚â–„â–ƒâ–„â–ƒâ–…â–ƒâ–â–ƒâ–„â–„â–„â–‚â–…â–‚â–†
wandb:  train_error_force â–ˆâ–‚â–â–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚â–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–‚â–‚â–â–„â–‚â–ƒ
wandb: valid_error_energy â–‚â–â–†â–‚â–‚â–ˆâ–â–â–â–‚â–†â–â–â–„â–…â–ˆâ–ˆâ–â–„â–‚
wandb:  valid_error_force â–…â–…â–ˆâ–†â–„â–ƒâ–‡â–„â–ƒâ–„â–„â–ƒâ–ƒâ–â–†â–ƒâ–„â–…â–…â–‡
wandb:         valid_loss â–„â–ƒâ–ˆâ–…â–ƒâ–„â–…â–ƒâ–‚â–ƒâ–„â–‚â–‚â–â–†â–…â–…â–ƒâ–…â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4185
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 10.03194
wandb:   test_error_force 7.21989
wandb:          test_loss 4.70778
wandb: train_error_energy 2.45885
wandb:  train_error_force 1.96564
wandb:         train_loss -2.40669
wandb: valid_error_energy 1.2024
wandb:  valid_error_force 2.16179
wandb:         valid_loss -2.23849
wandb: 
wandb: ğŸš€ View run al_58_53 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lslvycy1
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_121334-lslvycy1/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.556907653808594, Uncertainty Bias: -5.0108184814453125
5.722046e-06 0.004058838
-0.33150983 16.214802
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 21 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 684 steps.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 1294 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2449 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 302 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 254 steps.
Found uncertainty sample 15 after 3875 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2421 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2635 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1409 steps.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3639 steps.
Found uncertainty sample 27 after 2428 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1871 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1138 steps.
Found uncertainty sample 32 after 3033 steps.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 1835 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3601 steps.
Found uncertainty sample 41 after 3196 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 1614 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 752 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2346 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1609 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3811 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 609 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2240 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2003 steps.
Found uncertainty sample 88 after 2158 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2596 steps.
Found uncertainty sample 93 after 1504 steps.
Found uncertainty sample 94 after 2791 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_125033-vhkz7gf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_54
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vhkz7gf7
Training model 54. Added 30 samples to the dataset.
Epoch 0, Batch 100/132, Loss: 0.15811023116111755, Uncertainty: 0.1348671317100525

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0920205155226057, Training Loss Force: 2.1603634328184653, time: 1.9567592144012451
Validation Loss Energy: 0.9437540424683366, Validation Loss Force: 2.1032251290133517, time: 0.11612343788146973
Test Loss Energy: 9.364265170563531, Test Loss Force: 7.135175590231767, time: 8.416022539138794

Epoch 1, Batch 100/132, Loss: 0.17856314778327942, Uncertainty: 0.13366004824638367

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8581887632118175, Training Loss Force: 1.9898918887603791, time: 1.9682555198669434
Validation Loss Energy: 1.4002999033343713, Validation Loss Force: 2.1923339811764637, time: 0.11825084686279297
Test Loss Energy: 9.04071986471912, Test Loss Force: 7.227231314654702, time: 8.472595930099487

Epoch 2, Batch 100/132, Loss: 0.05537010356783867, Uncertainty: 0.13033095002174377

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9010080172007497, Training Loss Force: 1.9640545882775522, time: 1.9593908786773682
Validation Loss Energy: 1.5345837604887393, Validation Loss Force: 2.0718444405007976, time: 0.11783242225646973
Test Loss Energy: 10.262196058571458, Test Loss Force: 7.223944403292903, time: 8.607622385025024

Epoch 3, Batch 100/132, Loss: 0.06860983371734619, Uncertainty: 0.13607598841190338

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.2441233145281663, Training Loss Force: 2.008784196779336, time: 1.9397146701812744
Validation Loss Energy: 1.375374244916166, Validation Loss Force: 1.9841905827602266, time: 0.1156930923461914
Test Loss Energy: 8.900133551496138, Test Loss Force: 7.120509809863785, time: 8.443192720413208

Epoch 4, Batch 100/132, Loss: 0.07981054484844208, Uncertainty: 0.1301703006029129

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8788817531765394, Training Loss Force: 1.9666307986032194, time: 1.994434118270874
Validation Loss Energy: 1.2495836941064455, Validation Loss Force: 2.0129436269047356, time: 0.1139984130859375
Test Loss Energy: 8.980455427993615, Test Loss Force: 7.244903678753634, time: 8.460431098937988

Epoch 5, Batch 100/132, Loss: 0.16958828270435333, Uncertainty: 0.13155309855937958

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7717853837656363, Training Loss Force: 1.9463127290781186, time: 1.9261057376861572
Validation Loss Energy: 1.0234098657120894, Validation Loss Force: 2.0159998351556436, time: 0.11228561401367188
Test Loss Energy: 9.599070265256886, Test Loss Force: 7.11777747757735, time: 8.59197187423706

Epoch 6, Batch 100/132, Loss: 0.17741866409778595, Uncertainty: 0.13153959810733795

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8567017284704086, Training Loss Force: 1.9700762232433275, time: 1.9560024738311768
Validation Loss Energy: 1.7855115508340285, Validation Loss Force: 1.9759094430001236, time: 0.11255502700805664
Test Loss Energy: 9.112639172937516, Test Loss Force: 7.146461985091389, time: 8.445886611938477

Epoch 7, Batch 100/132, Loss: 0.09573248773813248, Uncertainty: 0.12966299057006836

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0763293855056233, Training Loss Force: 1.9549655264157557, time: 1.9652431011199951
Validation Loss Energy: 1.981558707678409, Validation Loss Force: 2.0321432740123595, time: 0.11212015151977539
Test Loss Energy: 11.110726992148447, Test Loss Force: 7.048070551702542, time: 8.53046989440918

Epoch 8, Batch 100/132, Loss: 0.06344036012887955, Uncertainty: 0.13089528679847717

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7443526141497192, Training Loss Force: 1.9596652952746119, time: 1.8898463249206543
Validation Loss Energy: 0.8348542823921142, Validation Loss Force: 1.937236525516056, time: 0.11944746971130371
Test Loss Energy: 9.83306603804548, Test Loss Force: 7.129012215526732, time: 8.647743225097656

Epoch 9, Batch 100/132, Loss: 0.11583742499351501, Uncertainty: 0.12981736660003662

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.137984125552558, Training Loss Force: 1.9471104050253243, time: 1.941605806350708
Validation Loss Energy: 0.9282464724693417, Validation Loss Force: 1.9380063669765766, time: 0.11341118812561035
Test Loss Energy: 9.982876230611971, Test Loss Force: 7.141694606034477, time: 8.446356773376465

Epoch 10, Batch 100/132, Loss: 0.10851924121379852, Uncertainty: 0.12990255653858185

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0707902362023836, Training Loss Force: 1.935438062249034, time: 2.0327517986297607
Validation Loss Energy: 3.2571747258583206, Validation Loss Force: 2.176414399034454, time: 0.11428499221801758
Test Loss Energy: 8.697714506612865, Test Loss Force: 7.1935533664393185, time: 8.420320510864258

Epoch 11, Batch 100/132, Loss: 0.30593711137771606, Uncertainty: 0.12959355115890503

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.749768798305483, Training Loss Force: 1.9630499472633134, time: 1.9894390106201172
Validation Loss Energy: 4.985365634690364, Validation Loss Force: 2.084543818565924, time: 0.11430883407592773
Test Loss Energy: 8.784545512869295, Test Loss Force: 7.073751788709257, time: 8.695309162139893

Epoch 12, Batch 100/132, Loss: 0.06739471852779388, Uncertainty: 0.13018926978111267

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3666829554296798, Training Loss Force: 1.967606232847818, time: 1.9233717918395996
Validation Loss Energy: 5.61274233652409, Validation Loss Force: 2.1096570757395736, time: 0.1124265193939209
Test Loss Energy: 14.231652374096678, Test Loss Force: 7.156628496375453, time: 8.421289205551147

Epoch 13, Batch 100/132, Loss: 0.18531420826911926, Uncertainty: 0.1298542320728302

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.5971762502288005, Training Loss Force: 1.9584450810065837, time: 1.9372611045837402
Validation Loss Energy: 3.3961841047390933, Validation Loss Force: 2.1902667208256705, time: 0.11628103256225586
Test Loss Energy: 8.636770772774133, Test Loss Force: 7.139590837270208, time: 8.452422618865967

Epoch 14, Batch 100/132, Loss: 0.07869671285152435, Uncertainty: 0.12985338270664215

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9117987137236732, Training Loss Force: 1.9570805341163637, time: 2.159327983856201
Validation Loss Energy: 0.8015757290815309, Validation Loss Force: 2.019575938750768, time: 0.11407661437988281
Test Loss Energy: 9.86968081509298, Test Loss Force: 7.0961151831616105, time: 8.389383792877197

Epoch 15, Batch 100/132, Loss: 0.10272866487503052, Uncertainty: 0.1286180317401886

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.5656677162175896, Training Loss Force: 1.9298013682561685, time: 1.9690759181976318
Validation Loss Energy: 1.0010127453362294, Validation Loss Force: 2.0242044138410717, time: 0.1112668514251709
Test Loss Energy: 9.081768481095844, Test Loss Force: 7.141022338737745, time: 9.059487342834473

Epoch 16, Batch 100/132, Loss: 0.13230377435684204, Uncertainty: 0.12963619828224182

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8528091871373307, Training Loss Force: 1.9495333751195185, time: 2.013049602508545
Validation Loss Energy: 1.933291013807837, Validation Loss Force: 1.972205712872858, time: 0.11280345916748047
Test Loss Energy: 8.908650103061794, Test Loss Force: 7.176038694064756, time: 8.616857290267944

Epoch 17, Batch 100/132, Loss: 0.04371947422623634, Uncertainty: 0.1291470229625702

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3596605795334935, Training Loss Force: 1.963069610467097, time: 1.933788776397705
Validation Loss Energy: 1.6788742577265297, Validation Loss Force: 2.1115543653089754, time: 0.11396479606628418
Test Loss Energy: 10.57341894714479, Test Loss Force: 7.231257800017267, time: 8.463124752044678

Epoch 18, Batch 100/132, Loss: 0.08781948685646057, Uncertainty: 0.12992295622825623

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9643040009156938, Training Loss Force: 1.9459478603792033, time: 1.9984424114227295
Validation Loss Energy: 3.2809182337807954, Validation Loss Force: 2.1429062552786564, time: 0.12666988372802734
Test Loss Energy: 12.487285992750488, Test Loss Force: 7.113723374245847, time: 8.399927377700806

Epoch 19, Batch 100/132, Loss: 0.12182163447141647, Uncertainty: 0.13163602352142334

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8429946732044593, Training Loss Force: 1.9587633806465814, time: 1.9783999919891357
Validation Loss Energy: 0.8690116737101504, Validation Loss Force: 2.1391582882144005, time: 0.11134862899780273
Test Loss Energy: 9.547555714045824, Test Loss Force: 7.13942990693386, time: 8.580004215240479

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–â–â–‚â–‚â–„â–‚â–ƒâ–â–â–ˆâ–â–ƒâ–‚â–â–ƒâ–†â–‚
wandb:   test_error_force â–„â–‡â–‡â–„â–ˆâ–ƒâ–„â–â–„â–„â–†â–‚â–…â–„â–ƒâ–„â–†â–ˆâ–ƒâ–„
wandb:          test_loss â–â–„â–†â–‚â–„â–ƒâ–„â–„â–„â–…â–…â–‚â–ˆâ–ƒâ–„â–…â–…â–‡â–‡â–ƒ
wandb: train_error_energy â–ˆâ–‚â–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–†â–…â–†â–ƒâ–â–‚â–…â–ƒâ–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–‚â–‚
wandb: valid_error_energy â–â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–â–…â–‡â–ˆâ–…â–â–â–ƒâ–‚â–…â–
wandb:  valid_error_force â–†â–ˆâ–…â–‚â–ƒâ–ƒâ–‚â–„â–â–â–ˆâ–…â–†â–ˆâ–ƒâ–ƒâ–‚â–†â–‡â–‡
wandb:         valid_loss â–„â–†â–„â–‚â–ƒâ–‚â–‚â–„â–â–â–‡â–‡â–ˆâ–‡â–‚â–ƒâ–ƒâ–…â–‡â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4212
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.54756
wandb:   test_error_force 7.13943
wandb:          test_loss 4.54816
wandb: train_error_energy 1.84299
wandb:  train_error_force 1.95876
wandb:         train_loss -2.45647
wandb: valid_error_energy 0.86901
wandb:  valid_error_force 2.13916
wandb:         valid_loss -2.29182
wandb: 
wandb: ğŸš€ View run al_58_54 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vhkz7gf7
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_125033-vhkz7gf7/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.466796875, Uncertainty Bias: -5.423453330993652
3.0517578e-05 0.0037326813
-0.64163625 15.774473
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2181 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1479 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2579 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 2372 steps.
Found uncertainty sample 9 after 3345 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 518 steps.
Found uncertainty sample 15 after 3254 steps.
Found uncertainty sample 16 after 3198 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2766 steps.
Found uncertainty sample 19 after 3856 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 30 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1617 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 373 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 1014 steps.
Found uncertainty sample 33 after 1921 steps.
Found uncertainty sample 34 after 2156 steps.
Found uncertainty sample 35 after 1283 steps.
Found uncertainty sample 36 after 3527 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 762 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 464 steps.
Found uncertainty sample 44 after 1549 steps.
Found uncertainty sample 45 after 1249 steps.
Found uncertainty sample 46 after 3642 steps.
Found uncertainty sample 47 after 1251 steps.
Found uncertainty sample 48 after 1325 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2347 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2116 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1927 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3133 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3312 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2054 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1664 steps.
Found uncertainty sample 73 after 1802 steps.
Found uncertainty sample 74 after 3222 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1352 steps.
Found uncertainty sample 83 after 955 steps.
Found uncertainty sample 84 after 2689 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2513 steps.
Found uncertainty sample 87 after 730 steps.
Found uncertainty sample 88 after 2769 steps.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 895 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1643 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_132513-c5c2xslh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_55
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/c5c2xslh
Training model 55. Added 42 samples to the dataset.
Epoch 0, Batch 100/133, Loss: 0.16362899541854858, Uncertainty: 0.13280299305915833

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.722966836349008, Training Loss Force: 2.066847431790011, time: 1.9767663478851318
Validation Loss Energy: 1.571394087678646, Validation Loss Force: 2.0342929961701954, time: 0.13049101829528809
Test Loss Energy: 10.914695940345512, Test Loss Force: 7.116065317389767, time: 9.812255382537842

Epoch 1, Batch 100/133, Loss: 0.060783226042985916, Uncertainty: 0.1315382719039917

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7236655661097606, Training Loss Force: 1.9560916554610777, time: 1.957782506942749
Validation Loss Energy: 2.574728901091659, Validation Loss Force: 1.9677169255601, time: 0.12858939170837402
Test Loss Energy: 11.508376650379589, Test Loss Force: 7.054600682309638, time: 9.942986249923706

Epoch 2, Batch 100/133, Loss: 0.039988741278648376, Uncertainty: 0.12990613281726837

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8015898605002478, Training Loss Force: 1.963418860788611, time: 1.956683874130249
Validation Loss Energy: 0.9017709625724305, Validation Loss Force: 1.963710662286567, time: 0.1309823989868164
Test Loss Energy: 9.813796669847425, Test Loss Force: 7.062566609217431, time: 10.031769752502441

Epoch 3, Batch 100/133, Loss: 0.1399925947189331, Uncertainty: 0.12903346121311188

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9487146940432056, Training Loss Force: 1.9537700240725313, time: 2.031752347946167
Validation Loss Energy: 1.7872220952130455, Validation Loss Force: 2.02344581717242, time: 0.1298527717590332
Test Loss Energy: 10.801733658256504, Test Loss Force: 7.219656975339067, time: 9.885884284973145

Epoch 4, Batch 100/133, Loss: 0.04492699354887009, Uncertainty: 0.13004323840141296

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7956033959079178, Training Loss Force: 1.9710286834884496, time: 1.9672737121582031
Validation Loss Energy: 2.8717020730081124, Validation Loss Force: 2.031708178501217, time: 0.13683748245239258
Test Loss Energy: 12.063752829990023, Test Loss Force: 7.1673501020216, time: 10.11157512664795

Epoch 5, Batch 100/133, Loss: 0.09880413115024567, Uncertainty: 0.12986084818840027

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.364314688543583, Training Loss Force: 1.957296018459768, time: 1.9824631214141846
Validation Loss Energy: 0.7752288477279171, Validation Loss Force: 2.0801931232351656, time: 0.12743854522705078
Test Loss Energy: 9.666458491848672, Test Loss Force: 7.137626107317562, time: 9.989512205123901

Epoch 6, Batch 100/133, Loss: 0.16454291343688965, Uncertainty: 0.12818215787410736

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5831567585924062, Training Loss Force: 1.9296196784138617, time: 1.934295892715454
Validation Loss Energy: 1.2563066694063947, Validation Loss Force: 2.0100081053309213, time: 0.12998747825622559
Test Loss Energy: 10.111879210925682, Test Loss Force: 7.086118107942103, time: 9.987303018569946

Epoch 7, Batch 100/133, Loss: 0.12437936663627625, Uncertainty: 0.1301085203886032

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5392705613621267, Training Loss Force: 1.9468245908554058, time: 1.9943528175354004
Validation Loss Energy: 2.9022556198665934, Validation Loss Force: 2.0283069072971696, time: 0.12500357627868652
Test Loss Energy: 8.728324554309866, Test Loss Force: 6.984943324218844, time: 10.131805181503296

Epoch 8, Batch 100/133, Loss: 0.1339682638645172, Uncertainty: 0.13004586100578308

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.611696843974795, Training Loss Force: 1.93183840819552, time: 1.9199128150939941
Validation Loss Energy: 1.6414566004411055, Validation Loss Force: 2.0779174445637834, time: 0.12677645683288574
Test Loss Energy: 9.320644629955163, Test Loss Force: 7.075397220433098, time: 9.928238153457642

Epoch 9, Batch 100/133, Loss: 0.05389966070652008, Uncertainty: 0.12858420610427856

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7202662738149654, Training Loss Force: 1.9581284586907983, time: 1.9978053569793701
Validation Loss Energy: 2.278951982050179, Validation Loss Force: 1.9764059209724938, time: 0.12927961349487305
Test Loss Energy: 9.125049174960404, Test Loss Force: 7.04092855659342, time: 10.068068742752075

Epoch 10, Batch 100/133, Loss: 0.34398218989372253, Uncertainty: 0.13203822076320648

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.887780533213183, Training Loss Force: 2.0673879142640357, time: 1.962263584136963
Validation Loss Energy: 1.9227569076292366, Validation Loss Force: 1.9804841063801615, time: 0.12919998168945312
Test Loss Energy: 11.015588304980081, Test Loss Force: 6.9982890029774465, time: 9.873677492141724

Epoch 11, Batch 100/133, Loss: 0.17106452584266663, Uncertainty: 0.13357818126678467

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.012124526592495, Training Loss Force: 2.0182172638016778, time: 1.9707896709442139
Validation Loss Energy: 3.0202126701225747, Validation Loss Force: 2.044730909277755, time: 0.1300976276397705
Test Loss Energy: 8.522315320356425, Test Loss Force: 6.959321725237412, time: 9.96291708946228

Epoch 12, Batch 100/133, Loss: 0.08627006411552429, Uncertainty: 0.13059930503368378

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6584646101564449, Training Loss Force: 1.9536364820192211, time: 1.9705123901367188
Validation Loss Energy: 1.8501103565398094, Validation Loss Force: 2.1420867585985937, time: 0.12836503982543945
Test Loss Energy: 8.71765301541315, Test Loss Force: 7.1157840547816695, time: 10.024087190628052

Epoch 13, Batch 100/133, Loss: 0.11926720291376114, Uncertainty: 0.1293175220489502

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.10393991050493, Training Loss Force: 1.9340412388978971, time: 2.050812005996704
Validation Loss Energy: 0.7870695022317732, Validation Loss Force: 1.97986412125485, time: 0.1294705867767334
Test Loss Energy: 9.65020723021842, Test Loss Force: 7.077918072989639, time: 9.911898612976074

Epoch 14, Batch 100/133, Loss: 0.05951334536075592, Uncertainty: 0.1296198070049286

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6121563581713563, Training Loss Force: 1.9611104321736343, time: 1.9535822868347168
Validation Loss Energy: 0.7786213606122244, Validation Loss Force: 1.969293386001744, time: 0.1354057788848877
Test Loss Energy: 9.711712057662293, Test Loss Force: 7.120771869298207, time: 10.111608743667603

Epoch 15, Batch 100/133, Loss: 0.06391401588916779, Uncertainty: 0.12992753088474274

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0851891011942922, Training Loss Force: 1.9524971032528555, time: 2.005946159362793
Validation Loss Energy: 1.626767302441871, Validation Loss Force: 1.9406953566943248, time: 0.13770413398742676
Test Loss Energy: 8.808117604409638, Test Loss Force: 7.0252198685575635, time: 9.914077281951904

Epoch 16, Batch 100/133, Loss: 0.10614897310733795, Uncertainty: 0.1286005973815918

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6808473729764535, Training Loss Force: 1.9279799185472897, time: 1.9538836479187012
Validation Loss Energy: 2.047737759201315, Validation Loss Force: 2.0933571004732703, time: 0.1350572109222412
Test Loss Energy: 8.838367811771978, Test Loss Force: 7.028025676998925, time: 9.940326452255249

Epoch 17, Batch 100/133, Loss: 0.13022834062576294, Uncertainty: 0.12974248826503754

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8395470120607245, Training Loss Force: 1.945221995808653, time: 1.9994797706604004
Validation Loss Energy: 1.337138612523176, Validation Loss Force: 2.0360334524378154, time: 0.12954258918762207
Test Loss Energy: 8.856929073433069, Test Loss Force: 6.996714349731025, time: 10.108593225479126

Epoch 18, Batch 100/133, Loss: 0.12396153807640076, Uncertainty: 0.12961387634277344

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7677577523904728, Training Loss Force: 1.9690172519848341, time: 1.9389066696166992
Validation Loss Energy: 0.7861182410846075, Validation Loss Force: 1.894047766417999, time: 0.1331801414489746
Test Loss Energy: 9.513476557998533, Test Loss Force: 7.095423833935137, time: 10.522019863128662

Epoch 19, Batch 100/133, Loss: 0.051219724118709564, Uncertainty: 0.12899982929229736

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1610957933833848, Training Loss Force: 1.9151522068778226, time: 1.968475103378296
Validation Loss Energy: 1.9118272668244194, Validation Loss Force: 2.007102866760953, time: 0.13547444343566895
Test Loss Energy: 8.455746446273231, Test Loss Force: 7.087761574115266, time: 10.170609712600708

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–‡â–„â–†â–ˆâ–ƒâ–„â–‚â–ƒâ–‚â–†â–â–‚â–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–
wandb:   test_error_force â–…â–„â–„â–ˆâ–‡â–†â–„â–‚â–„â–ƒâ–‚â–â–…â–„â–…â–ƒâ–ƒâ–‚â–…â–„
wandb:          test_loss â–†â–†â–„â–ˆâ–ˆâ–…â–†â–‚â–…â–ƒâ–‚â–â–„â–…â–…â–ƒâ–…â–ƒâ–…â–…
wandb: train_error_energy â–‡â–‚â–‚â–ƒâ–‚â–…â–â–â–â–‚â–ˆâ–ƒâ–‚â–„â–â–„â–‚â–ƒâ–‚â–„
wandb:  train_error_force â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–ˆâ–†â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–ƒâ–ƒâ–â–‚â–â–‚â–ˆâ–…â–‚â–‚â–‚â–ƒâ–â–‚â–ƒâ–‚
wandb: valid_error_energy â–ƒâ–‡â–â–„â–ˆâ–â–ƒâ–ˆâ–„â–†â–…â–ˆâ–„â–â–â–„â–…â–ƒâ–â–…
wandb:  valid_error_force â–…â–ƒâ–ƒâ–…â–…â–†â–„â–…â–†â–ƒâ–ƒâ–…â–ˆâ–ƒâ–ƒâ–‚â–‡â–…â–â–„
wandb:         valid_loss â–…â–…â–ƒâ–…â–‡â–…â–„â–‡â–†â–…â–„â–‡â–ˆâ–ƒâ–ƒâ–ƒâ–‡â–…â–â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4249
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.45575
wandb:   test_error_force 7.08776
wandb:          test_loss 4.54182
wandb: train_error_energy 2.1611
wandb:  train_error_force 1.91515
wandb:         train_loss -2.49148
wandb: valid_error_energy 1.91183
wandb:  valid_error_force 2.0071
wandb:         valid_loss -2.38822
wandb: 
wandb: ğŸš€ View run al_58_55 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/c5c2xslh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_132513-c5c2xslh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 41.86295700073242, Uncertainty Bias: -5.242400169372559
9.536743e-05 0.033493042
-0.4466921 15.754622
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1614 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 226 steps.
Found uncertainty sample 5 after 107 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 750 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3056 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1259 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1865 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3091 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1866 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1966 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 622 steps.
Found uncertainty sample 43 after 1850 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2856 steps.
Found uncertainty sample 46 after 2032 steps.
Found uncertainty sample 47 after 1843 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3390 steps.
Found uncertainty sample 51 after 3001 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3206 steps.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3510 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3449 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2248 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2232 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 979 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3766 steps.
Found uncertainty sample 75 after 3416 steps.
Found uncertainty sample 76 after 2500 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3291 steps.
Found uncertainty sample 84 after 3092 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2104 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2754 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3426 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3097 steps.
Found uncertainty sample 96 after 3910 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_140341-brvycqfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_56
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/brvycqfl
Training model 56. Added 33 samples to the dataset.
Epoch 0, Batch 100/134, Loss: 0.14973871409893036, Uncertainty: 0.13187146186828613

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7180557265623424, Training Loss Force: 2.1092722907156336, time: 2.042112350463867
Validation Loss Energy: 2.7469020287825265, Validation Loss Force: 2.096833782294738, time: 0.11971163749694824
Test Loss Energy: 11.932213305356921, Test Loss Force: 7.198639857195907, time: 8.570634126663208

Epoch 1, Batch 100/134, Loss: 0.20934611558914185, Uncertainty: 0.12692420184612274

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7551428088425034, Training Loss Force: 1.9454619979896766, time: 1.9890782833099365
Validation Loss Energy: 1.020791666226984, Validation Loss Force: 2.02122743869459, time: 0.1180732250213623
Test Loss Energy: 9.13041759050349, Test Loss Force: 7.0290106160772075, time: 8.524659633636475

Epoch 2, Batch 100/134, Loss: 0.0941752940416336, Uncertainty: 0.13070471584796906

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3829604623305194, Training Loss Force: 1.9602086560040253, time: 2.033350706100464
Validation Loss Energy: 1.5323886509366593, Validation Loss Force: 1.9711617656937, time: 0.12013459205627441
Test Loss Energy: 8.837315160288808, Test Loss Force: 7.03700277830678, time: 8.74669337272644

Epoch 3, Batch 100/134, Loss: 0.07295973598957062, Uncertainty: 0.12785637378692627

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.9292260153156526, Training Loss Force: 1.9382970706859908, time: 2.0193698406219482
Validation Loss Energy: 1.629477631286104, Validation Loss Force: 2.128061645550137, time: 0.1150972843170166
Test Loss Energy: 10.33261586379728, Test Loss Force: 7.1034016940438605, time: 9.068212985992432

Epoch 4, Batch 100/134, Loss: 0.7341196537017822, Uncertainty: 0.1314033418893814

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.4738353994537396, Training Loss Force: 1.9545865359132157, time: 1.9277548789978027
Validation Loss Energy: 2.5599324621217088, Validation Loss Force: 2.0719127257055487, time: 0.1147153377532959
Test Loss Energy: 11.53465978890131, Test Loss Force: 7.12006711562231, time: 8.445718765258789

Epoch 5, Batch 100/134, Loss: 0.0937645360827446, Uncertainty: 0.12886351346969604

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.008466448021395, Training Loss Force: 1.9494002283614336, time: 2.018383741378784
Validation Loss Energy: 2.391315583360454, Validation Loss Force: 2.0690230739757953, time: 0.11894607543945312
Test Loss Energy: 8.82578828041997, Test Loss Force: 7.0270786592922585, time: 8.710581541061401

Epoch 6, Batch 100/134, Loss: 0.053257666528224945, Uncertainty: 0.13042783737182617

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6752398141227929, Training Loss Force: 1.9196658862759508, time: 1.9850780963897705
Validation Loss Energy: 0.8047573000615956, Validation Loss Force: 2.0254580782441693, time: 0.11582136154174805
Test Loss Energy: 9.996129209057447, Test Loss Force: 6.999774954628909, time: 8.463094234466553

Epoch 7, Batch 100/134, Loss: 0.06690482050180435, Uncertainty: 0.12809370458126068

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4804553882484635, Training Loss Force: 1.91148150733782, time: 1.9319610595703125
Validation Loss Energy: 1.221521443875653, Validation Loss Force: 2.0588122091740333, time: 0.1142427921295166
Test Loss Energy: 9.217708223182942, Test Loss Force: 7.09136793992401, time: 8.510437965393066

Epoch 8, Batch 100/134, Loss: 0.048949651420116425, Uncertainty: 0.12942983210086823

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7808323384739924, Training Loss Force: 1.9600263572727674, time: 1.946563720703125
Validation Loss Energy: 0.8198834192578541, Validation Loss Force: 1.9783660032410477, time: 0.13811373710632324
Test Loss Energy: 9.639320266500768, Test Loss Force: 7.009094821861421, time: 8.640617370605469

Epoch 9, Batch 100/134, Loss: 0.10930462181568146, Uncertainty: 0.12857511639595032

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8325575842830515, Training Loss Force: 1.935958107449284, time: 1.9835081100463867
Validation Loss Energy: 1.5402343982934248, Validation Loss Force: 1.9038020110245117, time: 0.11591768264770508
Test Loss Energy: 10.503460857468216, Test Loss Force: 7.009452619702135, time: 8.81328535079956

Epoch 10, Batch 100/134, Loss: 0.23637191951274872, Uncertainty: 0.12874194979667664

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7350721660295056, Training Loss Force: 1.936567528806893, time: 1.9762494564056396
Validation Loss Energy: 1.399222333114178, Validation Loss Force: 2.0436540070649993, time: 0.1234738826751709
Test Loss Energy: 10.548579898475097, Test Loss Force: 6.935010812807651, time: 9.705806255340576

Epoch 11, Batch 100/134, Loss: 0.07955680787563324, Uncertainty: 0.13179802894592285

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.800565052193547, Training Loss Force: 1.9768742318518076, time: 2.004882574081421
Validation Loss Energy: 0.9348203707760921, Validation Loss Force: 1.9960124588327763, time: 0.11662411689758301
Test Loss Energy: 9.639303366961816, Test Loss Force: 6.9931341119898125, time: 10.447495698928833

Epoch 12, Batch 100/134, Loss: 0.11769798398017883, Uncertainty: 0.12753504514694214

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7581452638199482, Training Loss Force: 1.9168109288363073, time: 2.235487937927246
Validation Loss Energy: 0.8323814301920134, Validation Loss Force: 2.040446754910104, time: 0.13669371604919434
Test Loss Energy: 9.564795663989823, Test Loss Force: 7.061201556419945, time: 10.089602947235107

Epoch 13, Batch 100/134, Loss: 0.18266147375106812, Uncertainty: 0.12821027636528015

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.0976322399254554, Training Loss Force: 1.9293614417762657, time: 2.072957754135132
Validation Loss Energy: 0.8470843295649116, Validation Loss Force: 2.023622839143433, time: 0.13631200790405273
Test Loss Energy: 9.716666872844566, Test Loss Force: 7.077625933401797, time: 10.072534322738647

Epoch 14, Batch 100/134, Loss: 0.04339443892240524, Uncertainty: 0.12911656498908997

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9603016818557213, Training Loss Force: 1.9286118069868345, time: 2.0545573234558105
Validation Loss Energy: 2.1025732279771243, Validation Loss Force: 2.2091374113817097, time: 0.19844889640808105
Test Loss Energy: 8.845225769652233, Test Loss Force: 6.97216841060064, time: 12.280357360839844

Epoch 15, Batch 100/134, Loss: 0.048746392130851746, Uncertainty: 0.12807011604309082

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.421389832857092, Training Loss Force: 1.9389477963393142, time: 2.2855513095855713
Validation Loss Energy: 1.6566924027474954, Validation Loss Force: 2.141333246208774, time: 0.16648650169372559
Test Loss Energy: 8.58943042633653, Test Loss Force: 7.0183350784623215, time: 10.8923180103302

Epoch 16, Batch 100/134, Loss: 0.2517941892147064, Uncertainty: 0.12798288464546204

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1769409784688483, Training Loss Force: 1.9110362122504256, time: 2.0299243927001953
Validation Loss Energy: 1.3107816739464713, Validation Loss Force: 2.055239334281525, time: 0.13235211372375488
Test Loss Energy: 8.906507718104908, Test Loss Force: 7.032315779314128, time: 10.180061101913452

Epoch 17, Batch 100/134, Loss: 0.051678385585546494, Uncertainty: 0.12867003679275513

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6513801280195275, Training Loss Force: 1.9276568895236679, time: 1.954998254776001
Validation Loss Energy: 1.8324097552340959, Validation Loss Force: 1.986018696448294, time: 0.1303248405456543
Test Loss Energy: 10.84546872774914, Test Loss Force: 7.014363164527612, time: 10.00968623161316

Epoch 18, Batch 100/134, Loss: 0.4079212248325348, Uncertainty: 0.12769989669322968

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 3.465770937215144, Training Loss Force: 1.939795751188643, time: 2.043213367462158
Validation Loss Energy: 2.030387082458427, Validation Loss Force: 1.9938219139981872, time: 0.12810969352722168
Test Loss Energy: 9.107798014615845, Test Loss Force: 6.938607448790784, time: 10.011171579360962

Epoch 19, Batch 100/134, Loss: 0.11853618174791336, Uncertainty: 0.12957589328289032

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9876220207868929, Training Loss Force: 1.9469430693509902, time: 2.009033679962158
Validation Loss Energy: 2.5342293914920213, Validation Loss Force: 2.0437918392663286, time: 0.12931346893310547
Test Loss Energy: 11.256412484771912, Test Loss Force: 7.128239947633144, time: 9.921942710876465

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–‚â–…â–‡â–â–„â–‚â–ƒâ–…â–…â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–†â–‚â–‡
wandb:   test_error_force â–ˆâ–ƒâ–„â–…â–†â–ƒâ–ƒâ–…â–ƒâ–ƒâ–â–ƒâ–„â–…â–‚â–ƒâ–„â–ƒâ–â–†
wandb:          test_loss â–ˆâ–ƒâ–ƒâ–‡â–‡â–ƒâ–…â–‡â–ƒâ–…â–„â–â–„â–…â–ƒâ–ƒâ–„â–†â–â–‡
wandb: train_error_energy â–…â–‚â–„â–ƒâ–…â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–â–„â–‚â–ˆâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–ƒâ–‚â–â–â–ƒâ–‚â–‚â–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–„â–‚â–„â–ƒâ–â–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–…â–ƒ
wandb: valid_error_energy â–ˆâ–‚â–„â–„â–‡â–‡â–â–ƒâ–â–„â–ƒâ–â–â–â–†â–„â–ƒâ–…â–…â–‡
wandb:  valid_error_force â–…â–„â–ƒâ–†â–…â–…â–„â–…â–ƒâ–â–„â–ƒâ–„â–„â–ˆâ–†â–„â–ƒâ–ƒâ–„
wandb:         valid_loss â–†â–ƒâ–‚â–†â–†â–…â–ƒâ–„â–‚â–â–„â–‚â–ƒâ–ƒâ–ˆâ–†â–„â–ƒâ–ƒâ–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 4278
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.25641
wandb:   test_error_force 7.12824
wandb:          test_loss 4.70409
wandb: train_error_energy 1.98762
wandb:  train_error_force 1.94694
wandb:         train_loss -2.46186
wandb: valid_error_energy 2.53423
wandb:  valid_error_force 2.04379
wandb:         valid_loss -2.30004
wandb: 
wandb: ğŸš€ View run al_58_56 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/brvycqfl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_140341-brvycqfl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.4230842590332, Uncertainty Bias: -5.104686737060547
5.1498413e-05 7.43866e-05
-0.43420127 16.47699
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 3208 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1671 steps.
Found uncertainty sample 4 after 1764 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2850 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 940 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 11 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2198 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3196 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3700 steps.
Found uncertainty sample 25 after 1006 steps.
Found uncertainty sample 26 after 2521 steps.
Found uncertainty sample 27 after 387 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1008 steps.
Found uncertainty sample 30 after 965 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3833 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1324 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3412 steps.
Found uncertainty sample 40 after 3135 steps.
Found uncertainty sample 41 after 1785 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1702 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 974 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1615 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1619 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3722 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2134 steps.
Found uncertainty sample 68 after 710 steps.
Found uncertainty sample 69 after 2702 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1796 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3794 steps.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 1713 steps.
Found uncertainty sample 83 after 1133 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 1732 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1599 steps.
Found uncertainty sample 89 after 2450 steps.
Found uncertainty sample 90 after 465 steps.
Found uncertainty sample 91 after 3539 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3903 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 608 steps.
Found uncertainty sample 99 after 1822 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_144047-x0ex1usy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_57
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/x0ex1usy
Training model 57. Added 39 samples to the dataset.
Epoch 0, Batch 100/135, Loss: 0.16853347420692444, Uncertainty: 0.1319151520729065

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8712013870012334, Training Loss Force: 2.081977498930069, time: 2.039931058883667
Validation Loss Energy: 0.7781322307216696, Validation Loss Force: 2.020135988764301, time: 0.128082275390625
Test Loss Energy: 9.480414769118337, Test Loss Force: 6.967048258331386, time: 9.841686725616455

Epoch 1, Batch 100/135, Loss: 0.061183422803878784, Uncertainty: 0.12901586294174194

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9116874306007767, Training Loss Force: 1.9349747677897968, time: 2.00996732711792
Validation Loss Energy: 1.702737710095611, Validation Loss Force: 1.99269509678522, time: 0.1312117576599121
Test Loss Energy: 8.900237532158254, Test Loss Force: 7.0416971242154425, time: 9.688108444213867

Epoch 2, Batch 100/135, Loss: 0.06058482825756073, Uncertainty: 0.1290167272090912

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6833669825720188, Training Loss Force: 1.9499425613886454, time: 1.9667770862579346
Validation Loss Energy: 2.0570938713749087, Validation Loss Force: 1.96393251497896, time: 0.127763032913208
Test Loss Energy: 10.99557061456518, Test Loss Force: 7.01180982559191, time: 9.989356994628906

Epoch 3, Batch 100/135, Loss: 0.10334955155849457, Uncertainty: 0.1274183690547943

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.078883795256738, Training Loss Force: 1.9264733826786542, time: 2.042823076248169
Validation Loss Energy: 1.1621174351213188, Validation Loss Force: 1.9437647395363664, time: 0.1287548542022705
Test Loss Energy: 10.338937643700595, Test Loss Force: 7.046052565352386, time: 9.739808320999146

Epoch 4, Batch 100/135, Loss: 0.204230397939682, Uncertainty: 0.1281731277704239

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.0724171632751855, Training Loss Force: 1.9248950287245694, time: 1.9805150032043457
Validation Loss Energy: 3.008885045330936, Validation Loss Force: 2.0847534615668155, time: 0.13000988960266113
Test Loss Energy: 8.639307489632968, Test Loss Force: 7.008930736851205, time: 9.903175830841064

Epoch 5, Batch 100/135, Loss: 0.25107109546661377, Uncertainty: 0.1282331645488739

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.161164565273068, Training Loss Force: 1.919008157924167, time: 2.0455517768859863
Validation Loss Energy: 3.0644529471507505, Validation Loss Force: 2.0022633013203097, time: 0.13353443145751953
Test Loss Energy: 8.789956930371106, Test Loss Force: 6.95155874435193, time: 9.685642957687378

Epoch 6, Batch 100/135, Loss: 0.0797104761004448, Uncertainty: 0.12844708561897278

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.199706940083884, Training Loss Force: 1.9310814629245923, time: 2.0561330318450928
Validation Loss Energy: 1.7441669747140702, Validation Loss Force: 1.9449075147047923, time: 0.1271224021911621
Test Loss Energy: 10.496230195738349, Test Loss Force: 6.924001772770904, time: 9.727753162384033

Epoch 7, Batch 100/135, Loss: 0.07794162631034851, Uncertainty: 0.12750962376594543

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8089487563164157, Training Loss Force: 1.9412040897167269, time: 2.017026901245117
Validation Loss Energy: 2.201190794901839, Validation Loss Force: 1.9710447530575148, time: 0.1302504539489746
Test Loss Energy: 8.768904010293541, Test Loss Force: 6.9889151029199335, time: 10.574071168899536

Epoch 8, Batch 100/135, Loss: 0.051744841039180756, Uncertainty: 0.13046912848949432

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6890775187893088, Training Loss Force: 1.9430024910937218, time: 1.9694995880126953
Validation Loss Energy: 1.6632891988647522, Validation Loss Force: 2.047779695223798, time: 0.12738966941833496
Test Loss Energy: 8.760528647287703, Test Loss Force: 6.980013991246998, time: 9.759909629821777

Epoch 9, Batch 100/135, Loss: 0.1802874207496643, Uncertainty: 0.13150370121002197

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.230337208833646, Training Loss Force: 1.959168886314682, time: 2.035648822784424
Validation Loss Energy: 3.504073318008046, Validation Loss Force: 2.039644329531229, time: 0.13085293769836426
Test Loss Energy: 8.374291918281422, Test Loss Force: 7.018816419207395, time: 9.905937194824219

Epoch 10, Batch 100/135, Loss: 0.14240308105945587, Uncertainty: 0.12801381945610046

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8350561627764879, Training Loss Force: 1.9430082359576866, time: 2.0213990211486816
Validation Loss Energy: 2.9770594638648173, Validation Loss Force: 2.0125531394458274, time: 0.13079500198364258
Test Loss Energy: 8.768769644036562, Test Loss Force: 6.962246856361621, time: 9.86597228050232

Epoch 11, Batch 100/135, Loss: 0.09602232277393341, Uncertainty: 0.12799090147018433

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.7107254836683046, Training Loss Force: 1.9289229857458192, time: 2.018693208694458
Validation Loss Energy: 4.594462675155365, Validation Loss Force: 2.1141565511713365, time: 0.12751388549804688
Test Loss Energy: 8.329385301308143, Test Loss Force: 7.0395275899440515, time: 9.727444171905518

Epoch 12, Batch 100/135, Loss: 0.08702357858419418, Uncertainty: 0.12908105552196503

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.1470999754591404, Training Loss Force: 1.9365893178506035, time: 1.9936418533325195
Validation Loss Energy: 2.661659084107965, Validation Loss Force: 2.0289168723109143, time: 0.1293797492980957
Test Loss Energy: 11.135423653808678, Test Loss Force: 6.983275884389573, time: 9.94438648223877

Epoch 13, Batch 100/135, Loss: 0.059407614171504974, Uncertainty: 0.12733477354049683

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.1830188182711567, Training Loss Force: 1.9225207142191452, time: 2.0778398513793945
Validation Loss Energy: 1.0381040809882967, Validation Loss Force: 2.0055393582412964, time: 0.1254420280456543
Test Loss Energy: 8.957293919705446, Test Loss Force: 6.924520703798392, time: 10.193307876586914

Epoch 14, Batch 100/135, Loss: 0.18008773028850555, Uncertainty: 0.1280454397201538

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.18949770365334, Training Loss Force: 1.927960830716864, time: 2.0483436584472656
Validation Loss Energy: 1.478192762171003, Validation Loss Force: 1.9644236488918276, time: 0.15500664710998535
Test Loss Energy: 10.22014954866855, Test Loss Force: 7.0009424660855535, time: 9.993649244308472

Epoch 15, Batch 100/135, Loss: 0.09323634207248688, Uncertainty: 0.12957456707954407

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7966908705521745, Training Loss Force: 1.9574920301280432, time: 1.9865596294403076
Validation Loss Energy: 2.0053630042777217, Validation Loss Force: 2.000068154656705, time: 0.13366937637329102
Test Loss Energy: 11.061463427815516, Test Loss Force: 7.025551113976983, time: 10.768478155136108

Epoch 16, Batch 100/135, Loss: 0.1430107206106186, Uncertainty: 0.12822739779949188

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8228346203280141, Training Loss Force: 1.9194314016638427, time: 2.2487943172454834
Validation Loss Energy: 0.8970459975188914, Validation Loss Force: 2.0448659210032356, time: 0.16892242431640625
Test Loss Energy: 8.981237982968581, Test Loss Force: 6.89391188019879, time: 11.940064191818237

Epoch 17, Batch 100/135, Loss: 0.10752403736114502, Uncertainty: 0.1276627480983734

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7043920874196188, Training Loss Force: 1.925874595656035, time: 2.159168243408203
Validation Loss Energy: 1.1677189001562782, Validation Loss Force: 2.089377037935908, time: 0.1279449462890625
Test Loss Energy: 9.858929029034012, Test Loss Force: 6.932507160568278, time: 9.919531106948853

Epoch 18, Batch 100/135, Loss: 0.05295557528734207, Uncertainty: 0.12776291370391846

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4707544540762503, Training Loss Force: 1.922894229340931, time: 2.275315284729004
Validation Loss Energy: 2.183909739378578, Validation Loss Force: 2.4012435099007896, time: 0.12879562377929688
Test Loss Energy: 8.597246386157442, Test Loss Force: 7.344823949171964, time: 9.974616289138794

Epoch 19, Batch 100/135, Loss: 0.22191715240478516, Uncertainty: 0.12820833921432495

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9253009863285662, Training Loss Force: 1.9730949981867576, time: 2.0916073322296143
Validation Loss Energy: 2.75389324618027, Validation Loss Force: 1.9956420858200496, time: 0.13483500480651855
Test Loss Energy: 11.597393246402058, Test Loss Force: 7.014654163956164, time: 10.62436318397522

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.039 MB of 0.049 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‡â–…â–‚â–‚â–†â–‚â–‚â–â–‚â–â–‡â–‚â–…â–‡â–‚â–„â–‚â–ˆ
wandb:   test_error_force â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–â–ƒâ–ƒâ–â–‚â–ˆâ–ƒ
wandb:          test_loss â–â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–â–ƒâ–„â–‚â–ƒâ–„â–‚â–‚â–ˆâ–„
wandb: train_error_energy â–ˆâ–‚â–â–ƒâ–ƒâ–„â–„â–‚â–â–„â–‚â–â–„â–„â–„â–‚â–‚â–â–†â–‚
wandb:  train_error_force â–ˆâ–‚â–‚â–â–â–â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–â–â–ƒâ–â–â–â–ƒ
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–ƒ
wandb: valid_error_energy â–â–ƒâ–ƒâ–‚â–…â–…â–ƒâ–„â–ƒâ–†â–…â–ˆâ–„â–â–‚â–ƒâ–â–‚â–„â–…
wandb:  valid_error_force â–‚â–‚â–â–â–ƒâ–‚â–â–â–ƒâ–‚â–‚â–„â–‚â–‚â–â–‚â–ƒâ–ƒâ–ˆâ–‚
wandb:         valid_loss â–‚â–‚â–‚â–â–„â–ƒâ–â–‚â–ƒâ–„â–ƒâ–†â–ƒâ–‚â–â–‚â–‚â–ƒâ–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4313
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 11.59739
wandb:   test_error_force 7.01465
wandb:          test_loss 4.55228
wandb: train_error_energy 1.9253
wandb:  train_error_force 1.97309
wandb:         train_loss -2.43141
wandb: valid_error_energy 2.75389
wandb:  valid_error_force 1.99564
wandb:         valid_loss -2.34777
wandb: 
wandb: ğŸš€ View run al_58_57 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/x0ex1usy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_144047-x0ex1usy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 38.643280029296875, Uncertainty Bias: -4.897074222564697
0.0 0.05121231
-0.47903436 15.695018
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 3288 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1023 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3996 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1320 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 643 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1273 steps.
Found uncertainty sample 20 after 378 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 890 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2160 steps.
Found uncertainty sample 27 after 148 steps.
Found uncertainty sample 28 after 1572 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 931 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 13 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1462 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2632 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 441 steps.
Found uncertainty sample 43 after 1698 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 1409 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1597 steps.
Found uncertainty sample 49 after 822 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3011 steps.
Found uncertainty sample 52 after 615 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3125 steps.
Found uncertainty sample 57 after 1238 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3978 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3790 steps.
Found uncertainty sample 65 after 3024 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1425 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1745 steps.
Found uncertainty sample 74 after 1411 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1157 steps.
Found uncertainty sample 79 after 1998 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1789 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 706 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2048 steps.
Found uncertainty sample 87 after 1902 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2689 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2156 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3431 steps.
Found uncertainty sample 98 after 1499 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_151649-xwzjy6om
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_58
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xwzjy6om
Training model 58. Added 40 samples to the dataset.
Epoch 0, Batch 100/136, Loss: 0.04971443861722946, Uncertainty: 0.13360489904880524

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1519855371187067, Training Loss Force: 2.103767724330905, time: 2.0208425521850586
Validation Loss Energy: 6.220876712997222, Validation Loss Force: 2.039964601986122, time: 0.1454315185546875
Test Loss Energy: 14.510416550438318, Test Loss Force: 7.055543202332718, time: 10.047808647155762

Epoch 1, Batch 100/136, Loss: 0.04515225440263748, Uncertainty: 0.12955474853515625

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.6817286842070496, Training Loss Force: 1.912584500736068, time: 2.0682218074798584
Validation Loss Energy: 2.1838554823300202, Validation Loss Force: 2.0010723182817904, time: 0.13051795959472656
Test Loss Energy: 8.50593320388002, Test Loss Force: 6.952154982376302, time: 9.823197603225708

Epoch 2, Batch 100/136, Loss: 0.13283473253250122, Uncertainty: 0.12957629561424255

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.061335083069979, Training Loss Force: 1.937897798576569, time: 2.116191864013672
Validation Loss Energy: 0.8023816986109785, Validation Loss Force: 1.9568383502127489, time: 0.15376663208007812
Test Loss Energy: 9.05018223087857, Test Loss Force: 6.964529595160478, time: 10.192192792892456

Epoch 3, Batch 100/136, Loss: 0.05703248083591461, Uncertainty: 0.13061431050300598

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.988061527728885, Training Loss Force: 1.9592151242238074, time: 2.0283069610595703
Validation Loss Energy: 1.1133634318360406, Validation Loss Force: 2.144150085127809, time: 0.1342475414276123
Test Loss Energy: 9.858084639653283, Test Loss Force: 7.0055116532812916, time: 9.87803339958191

Epoch 4, Batch 100/136, Loss: 0.07934968173503876, Uncertainty: 0.12792983651161194

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.781988633647273, Training Loss Force: 1.9149172326456376, time: 2.0931284427642822
Validation Loss Energy: 0.8286630410126409, Validation Loss Force: 2.019609376234182, time: 0.1367194652557373
Test Loss Energy: 9.081591977908968, Test Loss Force: 6.907615128299927, time: 10.046871900558472

Epoch 5, Batch 100/136, Loss: 0.05161973834037781, Uncertainty: 0.1279466152191162

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1869545632600818, Training Loss Force: 1.9175317810116592, time: 2.0107181072235107
Validation Loss Energy: 0.9398682246469886, Validation Loss Force: 2.0395116929433046, time: 0.1321249008178711
Test Loss Energy: 9.69413904130827, Test Loss Force: 6.955627709391663, time: 9.882019996643066

Epoch 6, Batch 100/136, Loss: 0.12089382857084274, Uncertainty: 0.1272134780883789

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.74492201508904, Training Loss Force: 1.9267317227062108, time: 2.0012876987457275
Validation Loss Energy: 2.597660260415886, Validation Loss Force: 2.0855049699343216, time: 0.13044452667236328
Test Loss Energy: 8.489338218031717, Test Loss Force: 7.077137329678822, time: 10.61040711402893

Epoch 7, Batch 100/136, Loss: 0.13761430978775024, Uncertainty: 0.1274677813053131

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5786208479645134, Training Loss Force: 1.9354800275191688, time: 2.257760763168335
Validation Loss Energy: 1.758353968231616, Validation Loss Force: 1.9703210412217251, time: 0.12789583206176758
Test Loss Energy: 8.76673732292296, Test Loss Force: 6.908271125593514, time: 9.864672899246216

Epoch 8, Batch 100/136, Loss: 0.06629176437854767, Uncertainty: 0.12868176400661469

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8966037620765226, Training Loss Force: 1.934586630606149, time: 2.041184425354004
Validation Loss Energy: 2.80122328027734, Validation Loss Force: 1.96999215889319, time: 0.12977838516235352
Test Loss Energy: 11.374336436988633, Test Loss Force: 7.020721037817098, time: 9.842849254608154

Epoch 9, Batch 100/136, Loss: 0.060683473944664, Uncertainty: 0.1276988387107849

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.4771892724202507, Training Loss Force: 1.9068766825316483, time: 1.9627645015716553
Validation Loss Energy: 3.3560100632077527, Validation Loss Force: 2.004155246830209, time: 0.13124799728393555
Test Loss Energy: 8.433662283593096, Test Loss Force: 6.919182370740338, time: 10.045021057128906

Epoch 10, Batch 100/136, Loss: 0.0546543188393116, Uncertainty: 0.12957850098609924

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7998535824515869, Training Loss Force: 1.9492376775389626, time: 1.9904975891113281
Validation Loss Energy: 1.0974300813185074, Validation Loss Force: 2.0063796373749794, time: 0.13151860237121582
Test Loss Energy: 8.761003191377695, Test Loss Force: 6.879612137595729, time: 9.86997365951538

Epoch 11, Batch 100/136, Loss: 0.27003952860832214, Uncertainty: 0.12880949676036835

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.14822325420348, Training Loss Force: 1.9361976508819392, time: 1.9951648712158203
Validation Loss Energy: 1.436007795582789, Validation Loss Force: 1.9807156822919263, time: 0.13436388969421387
Test Loss Energy: 8.783708517036857, Test Loss Force: 6.920107601844917, time: 9.840264797210693

Epoch 12, Batch 100/136, Loss: 0.1318512111902237, Uncertainty: 0.12922275066375732

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6572058479177705, Training Loss Force: 1.9255533510368688, time: 2.0747900009155273
Validation Loss Energy: 1.610579403979018, Validation Loss Force: 2.0106400403670643, time: 0.12775468826293945
Test Loss Energy: 8.707948688332767, Test Loss Force: 6.99313053995702, time: 10.082555294036865

Epoch 13, Batch 100/136, Loss: 0.0709066092967987, Uncertainty: 0.12876848876476288

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8817047566769871, Training Loss Force: 1.9549252598661098, time: 2.0667362213134766
Validation Loss Energy: 0.8522773451631908, Validation Loss Force: 1.9867536530759526, time: 0.13414216041564941
Test Loss Energy: 9.227944829781498, Test Loss Force: 6.846535146591643, time: 9.842247009277344

Epoch 14, Batch 100/136, Loss: 0.04765781760215759, Uncertainty: 0.1260267049074173

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.551838433129194, Training Loss Force: 1.9096465843774193, time: 2.0184824466705322
Validation Loss Energy: 2.1152045806181703, Validation Loss Force: 2.02020219572369, time: 0.1318349838256836
Test Loss Energy: 8.511590165993631, Test Loss Force: 6.954522209543453, time: 10.07913088798523

Epoch 15, Batch 100/136, Loss: 0.1876411736011505, Uncertainty: 0.1275952309370041

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1592530193085664, Training Loss Force: 1.899823351630224, time: 2.0342419147491455
Validation Loss Energy: 2.2451124323821925, Validation Loss Force: 1.9778530477518785, time: 0.12880492210388184
Test Loss Energy: 8.499234166484763, Test Loss Force: 6.936083530161711, time: 9.978670597076416

Epoch 16, Batch 100/136, Loss: 0.0896470844745636, Uncertainty: 0.12708237767219543

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1772580341687386, Training Loss Force: 1.9071491157757814, time: 2.0552051067352295
Validation Loss Energy: 3.1206206454266456, Validation Loss Force: 2.108927611617514, time: 0.12891364097595215
Test Loss Energy: 11.740324641121529, Test Loss Force: 7.040735941953157, time: 9.938201189041138

Epoch 17, Batch 100/136, Loss: 0.16623230278491974, Uncertainty: 0.1303703784942627

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9732694722848658, Training Loss Force: 1.942759551796937, time: 2.007791757583618
Validation Loss Energy: 1.3113936058710052, Validation Loss Force: 1.965154894367055, time: 0.1380627155303955
Test Loss Energy: 9.851359546470533, Test Loss Force: 6.917721089897601, time: 10.06248688697815

Epoch 18, Batch 100/136, Loss: 0.10108262300491333, Uncertainty: 0.12920980155467987

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.041235730226641, Training Loss Force: 1.9326804157151476, time: 2.1207332611083984
Validation Loss Energy: 1.6748768269957857, Validation Loss Force: 2.1105120510368875, time: 0.12761354446411133
Test Loss Energy: 8.868319264757291, Test Loss Force: 7.01554142472523, time: 10.642709493637085

Epoch 19, Batch 100/136, Loss: 0.14707441627979279, Uncertainty: 0.1301211714744568

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.4865989213226865, Training Loss Force: 1.9487438563151276, time: 2.0587193965911865
Validation Loss Energy: 1.167557390802432, Validation Loss Force: 1.9137285644384485, time: 0.13599205017089844
Test Loss Energy: 9.952393649925847, Test Loss Force: 6.956812610026219, time: 10.074679374694824

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–â–‚â–ƒâ–‚â–‚â–â–â–„â–â–â–â–â–‚â–â–â–…â–ƒâ–‚â–ƒ
wandb:   test_error_force â–‡â–„â–…â–†â–ƒâ–„â–ˆâ–ƒâ–†â–ƒâ–‚â–ƒâ–…â–â–„â–„â–‡â–ƒâ–†â–„
wandb:          test_loss â–ˆâ–ƒâ–„â–…â–ƒâ–„â–†â–‚â–ˆâ–ƒâ–â–‚â–„â–‚â–„â–ƒâ–ˆâ–„â–…â–„
wandb: train_error_energy â–ˆâ–‚â–ƒâ–ƒâ–‚â–„â–‚â–â–ƒâ–â–‚â–„â–‚â–ƒâ–â–„â–„â–ƒâ–ƒâ–…
wandb:  train_error_force â–ˆâ–â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–â–â–â–‚â–‚â–ƒ
wandb:         train_loss â–ˆâ–â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–ƒ
wandb: valid_error_energy â–ˆâ–ƒâ–â–â–â–â–ƒâ–‚â–„â–„â–â–‚â–‚â–â–ƒâ–ƒâ–„â–‚â–‚â–
wandb:  valid_error_force â–…â–„â–‚â–ˆâ–„â–…â–†â–ƒâ–ƒâ–„â–„â–ƒâ–„â–ƒâ–„â–ƒâ–‡â–ƒâ–‡â–
wandb:         valid_loss â–ˆâ–„â–â–…â–ƒâ–ƒâ–†â–ƒâ–„â–…â–ƒâ–‚â–ƒâ–‚â–„â–ƒâ–†â–‚â–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4349
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.95239
wandb:   test_error_force 6.95681
wandb:          test_loss 4.47412
wandb: train_error_energy 2.4866
wandb:  train_error_force 1.94874
wandb:         train_loss -2.42619
wandb: valid_error_energy 1.16756
wandb:  valid_error_force 1.91373
wandb:         valid_loss -2.55972
wandb: 
wandb: ğŸš€ View run al_58_58 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/xwzjy6om
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_151649-xwzjy6om/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 46.73747253417969, Uncertainty Bias: -5.882496356964111
0.0001373291 0.0027093887
-0.5802936 15.4472885
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1620 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3618 steps.
Found uncertainty sample 5 after 1653 steps.
Found uncertainty sample 6 after 3827 steps.
Found uncertainty sample 7 after 2315 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1635 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 1476 steps.
Found uncertainty sample 13 after 2062 steps.
Found uncertainty sample 14 after 3264 steps.
Found uncertainty sample 15 after 2879 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3718 steps.
Found uncertainty sample 18 after 3124 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3856 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3473 steps.
Found uncertainty sample 24 after 1667 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2393 steps.
Found uncertainty sample 28 after 2195 steps.
Found uncertainty sample 29 after 2114 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2299 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1217 steps.
Found uncertainty sample 41 after 1759 steps.
Found uncertainty sample 42 after 3087 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 613 steps.
Found uncertainty sample 49 after 2821 steps.
Found uncertainty sample 50 after 1000 steps.
Found uncertainty sample 51 after 717 steps.
Found uncertainty sample 52 after 3143 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2435 steps.
Found uncertainty sample 55 after 1473 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2398 steps.
Found uncertainty sample 58 after 3203 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1212 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1577 steps.
Found uncertainty sample 66 after 597 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1421 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2803 steps.
Found uncertainty sample 74 after 1980 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2702 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1302 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2419 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2121 steps.
Found uncertainty sample 86 after 9 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3442 steps.
Found uncertainty sample 90 after 3406 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2360 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_155401-wkx33qo0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_59
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wkx33qo0
Training model 59. Added 45 samples to the dataset.
Epoch 0, Batch 100/138, Loss: 0.0594385489821434, Uncertainty: 0.13063600659370422

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.764581802858759, Training Loss Force: 2.02650168819252, time: 2.0721380710601807
Validation Loss Energy: 4.872299586447736, Validation Loss Force: 1.9188835778358226, time: 0.12847185134887695
Test Loss Energy: 8.081165733582356, Test Loss Force: 6.817416336315255, time: 9.993281364440918

Epoch 1, Batch 100/138, Loss: 0.06343679130077362, Uncertainty: 0.12815585732460022

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4487013842501215, Training Loss Force: 1.926516321178429, time: 2.0622971057891846
Validation Loss Energy: 0.7942788055021907, Validation Loss Force: 2.223609644075189, time: 0.13287639617919922
Test Loss Energy: 9.436303377111008, Test Loss Force: 7.02491839318689, time: 9.836621761322021

Epoch 2, Batch 100/138, Loss: 0.11199527978897095, Uncertainty: 0.13160347938537598

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.5520100995619959, Training Loss Force: 1.9702966589502462, time: 2.028862714767456
Validation Loss Energy: 1.1805636811736957, Validation Loss Force: 1.9804383107591492, time: 0.12797260284423828
Test Loss Energy: 9.771854830764402, Test Loss Force: 6.835085431491228, time: 10.090892553329468

Epoch 3, Batch 100/138, Loss: 0.12731212377548218, Uncertainty: 0.1276196539402008

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7319519088989008, Training Loss Force: 1.9127997089707056, time: 2.0316648483276367
Validation Loss Energy: 1.297339397387481, Validation Loss Force: 1.9588281959238085, time: 0.13179636001586914
Test Loss Energy: 8.959234934811148, Test Loss Force: 6.895523051185141, time: 9.93623161315918

Epoch 4, Batch 100/138, Loss: 0.1258324682712555, Uncertainty: 0.12774191796779633

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8475874921234376, Training Loss Force: 1.9491346689981746, time: 1.9942028522491455
Validation Loss Energy: 3.852636852790605, Validation Loss Force: 2.449816854285672, time: 0.13793730735778809
Test Loss Energy: 8.300185481431688, Test Loss Force: 7.198208196152321, time: 10.073589324951172

Epoch 5, Batch 100/138, Loss: 0.2077811360359192, Uncertainty: 0.1307419240474701

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7085861373996418, Training Loss Force: 1.9315544316606474, time: 2.0269832611083984
Validation Loss Energy: 0.8672906824370368, Validation Loss Force: 2.034142249158402, time: 0.13361382484436035
Test Loss Energy: 9.338303832092537, Test Loss Force: 6.97233729407266, time: 10.665853500366211

Epoch 6, Batch 100/138, Loss: 0.0741037130355835, Uncertainty: 0.1263127326965332

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9737963773470504, Training Loss Force: 1.9141161394494701, time: 2.019819736480713
Validation Loss Energy: 1.8498808959849307, Validation Loss Force: 1.9517652048380276, time: 0.13002753257751465
Test Loss Energy: 8.744366327408661, Test Loss Force: 6.938148069518858, time: 9.939764022827148

Epoch 7, Batch 100/138, Loss: 0.14119282364845276, Uncertainty: 0.1291603446006775

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.767060172903256, Training Loss Force: 1.9264755928940316, time: 2.1082229614257812
Validation Loss Energy: 2.6515067812915816, Validation Loss Force: 1.9720818346046736, time: 0.19308686256408691
Test Loss Energy: 8.382677237279438, Test Loss Force: 6.998462934393977, time: 10.05716848373413

Epoch 8, Batch 100/138, Loss: 0.12160329520702362, Uncertainty: 0.12894222140312195

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2180765550068617, Training Loss Force: 1.9223129973242952, time: 2.0568060874938965
Validation Loss Energy: 0.8524888808518222, Validation Loss Force: 1.9472589751088385, time: 0.1301860809326172
Test Loss Energy: 9.413148546565605, Test Loss Force: 6.95678147132, time: 9.941890478134155

Epoch 9, Batch 100/138, Loss: 0.0694780945777893, Uncertainty: 0.1281431019306183

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.214772573680753, Training Loss Force: 1.9067776122378215, time: 2.085968494415283
Validation Loss Energy: 1.9692194969568204, Validation Loss Force: 1.9500321708752717, time: 0.13287067413330078
Test Loss Energy: 10.59167783110055, Test Loss Force: 6.819388033130813, time: 10.07785677909851

Epoch 10, Batch 100/138, Loss: 0.15686610341072083, Uncertainty: 0.1302952766418457

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.100791580337824, Training Loss Force: 1.9635494651535883, time: 2.0619399547576904
Validation Loss Energy: 2.993805000092122, Validation Loss Force: 2.0682489275784532, time: 0.13714599609375
Test Loss Energy: 8.616338843136154, Test Loss Force: 6.9629055373430315, time: 9.947371244430542

Epoch 11, Batch 100/138, Loss: 0.3039878010749817, Uncertainty: 0.12840646505355835

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.9923939855750747, Training Loss Force: 1.9350298105449022, time: 2.111154079437256
Validation Loss Energy: 3.5948317774272396, Validation Loss Force: 2.2177403822807276, time: 0.14154434204101562
Test Loss Energy: 8.253977870426526, Test Loss Force: 7.030498402708963, time: 9.91060209274292

Epoch 12, Batch 100/138, Loss: 0.08529694378376007, Uncertainty: 0.12997721135616302

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.423489823160323, Training Loss Force: 1.9622681607325938, time: 2.1922144889831543
Validation Loss Energy: 3.9476033137295423, Validation Loss Force: 2.1163504360431147, time: 0.19287729263305664
Test Loss Energy: 12.333291019209012, Test Loss Force: 7.025985307153472, time: 10.000173568725586

Epoch 13, Batch 100/138, Loss: 0.08249851316213608, Uncertainty: 0.12717874348163605

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6521066333404186, Training Loss Force: 1.9065637546586032, time: 2.0416862964630127
Validation Loss Energy: 1.1008572192550063, Validation Loss Force: 1.959728187500124, time: 0.1292107105255127
Test Loss Energy: 9.628975188551351, Test Loss Force: 6.920017135218087, time: 9.891463279724121

Epoch 14, Batch 100/138, Loss: 0.1324644237756729, Uncertainty: 0.12896257638931274

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.6894311029831928, Training Loss Force: 1.9373605643319214, time: 2.089810609817505
Validation Loss Energy: 1.7064568043939454, Validation Loss Force: 1.9615196721136865, time: 0.13018536567687988
Test Loss Energy: 10.517692097249208, Test Loss Force: 6.827486286133252, time: 10.07008171081543

Epoch 15, Batch 100/138, Loss: 0.11228479444980621, Uncertainty: 0.12851150333881378

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.598139684358142, Training Loss Force: 1.922051276366742, time: 2.030794858932495
Validation Loss Energy: 3.19371409349195, Validation Loss Force: 2.2231341712255843, time: 0.12940025329589844
Test Loss Energy: 11.606906078016946, Test Loss Force: 6.93801975380045, time: 9.844451189041138

Epoch 16, Batch 100/138, Loss: 0.13431952893733978, Uncertainty: 0.1271560937166214

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.146937004090519, Training Loss Force: 1.9246996281585862, time: 2.139906644821167
Validation Loss Energy: 1.0517359603250445, Validation Loss Force: 1.9619255237436641, time: 0.1282799243927002
Test Loss Energy: 8.899270541845263, Test Loss Force: 6.813354832440619, time: 9.923165798187256

Epoch 17, Batch 100/138, Loss: 0.11537409573793411, Uncertainty: 0.12816104292869568

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.390544693095985, Training Loss Force: 1.9238550852334677, time: 2.083503007888794
Validation Loss Energy: 2.4635473018310172, Validation Loss Force: 1.9806667693028708, time: 0.18918514251708984
Test Loss Energy: 11.000566102423704, Test Loss Force: 6.8777912262635965, time: 10.092352628707886

Epoch 18, Batch 100/138, Loss: 0.10311916470527649, Uncertainty: 0.127518892288208

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.047969833294955, Training Loss Force: 1.939041543734411, time: 2.079563617706299
Validation Loss Energy: 1.5047459835998431, Validation Loss Force: 1.959076026683226, time: 0.13524651527404785
Test Loss Energy: 8.581534300959854, Test Loss Force: 6.833131550538957, time: 10.553354263305664

Epoch 19, Batch 100/138, Loss: 0.1912071406841278, Uncertainty: 0.1278500109910965

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.328631033644868, Training Loss Force: 1.9199502380746374, time: 2.047252893447876
Validation Loss Energy: 3.724480961866743, Validation Loss Force: 2.0842477057133646, time: 0.13479256629943848
Test Loss Energy: 12.786891716694052, Test Loss Force: 6.9447471133121015, time: 10.061603546142578

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–ƒâ–„â–‚â–â–ƒâ–‚â–â–ƒâ–…â–‚â–â–‡â–ƒâ–…â–†â–‚â–…â–‚â–ˆ
wandb:   test_error_force â–â–…â–â–‚â–ˆâ–„â–ƒâ–„â–„â–â–„â–…â–…â–ƒâ–â–ƒâ–â–‚â–â–ƒ
wandb:          test_loss â–â–†â–ƒâ–…â–‡â–…â–…â–†â–†â–…â–…â–†â–‡â–…â–ƒâ–‡â–ƒâ–†â–ƒâ–ˆ
wandb: train_error_energy â–ˆâ–â–‚â–ƒâ–ƒâ–‚â–„â–ƒâ–…â–…â–„â–„â–†â–‚â–‚â–‚â–…â–†â–„â–†
wandb:  train_error_force â–ˆâ–‚â–…â–â–ƒâ–‚â–â–‚â–‚â–â–„â–ƒâ–„â–â–ƒâ–‚â–‚â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–â–ƒâ–â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–…â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–ˆâ–â–‚â–‚â–†â–â–ƒâ–„â–â–ƒâ–…â–†â–†â–‚â–ƒâ–…â–â–„â–‚â–†
wandb:  valid_error_force â–â–…â–‚â–‚â–ˆâ–ƒâ–â–‚â–â–â–ƒâ–…â–„â–‚â–‚â–…â–‚â–‚â–‚â–ƒ
wandb:         valid_loss â–ƒâ–„â–‚â–â–ˆâ–‚â–‚â–‚â–â–‚â–ƒâ–…â–„â–â–‚â–…â–â–‚â–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4389
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 12.78689
wandb:   test_error_force 6.94475
wandb:          test_loss 4.64621
wandb: train_error_energy 2.32863
wandb:  train_error_force 1.91995
wandb:         train_loss -2.47404
wandb: valid_error_energy 3.72448
wandb:  valid_error_force 2.08425
wandb:         valid_loss -2.16552
wandb: 
wandb: ğŸš€ View run al_58_59 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wkx33qo0
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_155401-wkx33qo0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.287841796875, Uncertainty Bias: -4.633162498474121
6.484985e-05 0.258255
-0.19396798 16.844175
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3127 steps.
Found uncertainty sample 6 after 2981 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2937 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1176 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2883 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 900 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 2565 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2704 steps.
Found uncertainty sample 27 after 2307 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 525 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2801 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1764 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 2670 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1489 steps.
Found uncertainty sample 49 after 399 steps.
Found uncertainty sample 50 after 1905 steps.
Found uncertainty sample 51 after 3330 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2164 steps.
Found uncertainty sample 58 after 637 steps.
Found uncertainty sample 59 after 481 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1674 steps.
Found uncertainty sample 64 after 2547 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3035 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2654 steps.
Found uncertainty sample 70 after 2377 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3286 steps.
Found uncertainty sample 79 after 898 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2677 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1326 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 2449 steps.
Found uncertainty sample 91 after 1133 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 433 steps.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 2177 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_163239-qklhehbo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_60
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qklhehbo
Training model 60. Added 33 samples to the dataset.
Epoch 0, Batch 100/139, Loss: 0.11520010977983475, Uncertainty: 0.13036878407001495

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5312429192661754, Training Loss Force: 2.049474685602295, time: 2.0365216732025146
Validation Loss Energy: 1.429494648841353, Validation Loss Force: 1.9828400572786504, time: 0.12954401969909668
Test Loss Energy: 9.692030198951734, Test Loss Force: 6.879122088272016, time: 9.867132186889648

Epoch 1, Batch 100/139, Loss: 0.3085569739341736, Uncertainty: 0.12947966158390045

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.03631473643302, Training Loss Force: 1.9298259775293034, time: 2.0584232807159424
Validation Loss Energy: 1.6544310491245016, Validation Loss Force: 2.1307932021862825, time: 0.12801909446716309
Test Loss Energy: 10.350494601391242, Test Loss Force: 6.881310914318417, time: 9.911084175109863

Epoch 2, Batch 100/139, Loss: 0.07085969299077988, Uncertainty: 0.1264539361000061

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6594170853414751, Training Loss Force: 1.9089571192031176, time: 2.0607783794403076
Validation Loss Energy: 1.2459426453437588, Validation Loss Force: 2.0131853713741648, time: 0.1277914047241211
Test Loss Energy: 8.719650795995573, Test Loss Force: 6.844676183317505, time: 10.020542860031128

Epoch 3, Batch 100/139, Loss: 0.0849897712469101, Uncertainty: 0.12826168537139893

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8291300273425792, Training Loss Force: 1.9230054085320072, time: 2.0847809314727783
Validation Loss Energy: 1.1476396356991911, Validation Loss Force: 2.131810725960124, time: 0.12850093841552734
Test Loss Energy: 8.84096155524831, Test Loss Force: 7.0443183784064605, time: 9.900615453720093

Epoch 4, Batch 100/139, Loss: 0.09069746732711792, Uncertainty: 0.12827175855636597

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8522244798016763, Training Loss Force: 1.9290875593842858, time: 2.0745949745178223
Validation Loss Energy: 0.8418260533511134, Validation Loss Force: 2.069763671555151, time: 0.13488221168518066
Test Loss Energy: 8.859882200247698, Test Loss Force: 6.956979478983661, time: 10.784795999526978

Epoch 5, Batch 100/139, Loss: 0.05110040679574013, Uncertainty: 0.12656986713409424

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6222006364618298, Training Loss Force: 1.9299680052018064, time: 2.073051929473877
Validation Loss Energy: 0.8478243519156404, Validation Loss Force: 2.296178780524882, time: 0.13910174369812012
Test Loss Energy: 8.937697736154753, Test Loss Force: 6.977925520202796, time: 9.950680255889893

Epoch 6, Batch 100/139, Loss: 0.1791536509990692, Uncertainty: 0.12834665179252625

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.5955040440034027, Training Loss Force: 1.930731449596696, time: 2.067333698272705
Validation Loss Energy: 3.7169344076190556, Validation Loss Force: 2.054009903703809, time: 0.13756752014160156
Test Loss Energy: 8.291002477614853, Test Loss Force: 6.773422842374563, time: 9.797889709472656

Epoch 7, Batch 100/139, Loss: 0.14659494161605835, Uncertainty: 0.128537118434906

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.6537557034835098, Training Loss Force: 1.9389531858208833, time: 2.074028491973877
Validation Loss Energy: 0.9043909434107033, Validation Loss Force: 2.0759792580945793, time: 0.17755460739135742
Test Loss Energy: 9.564816979605865, Test Loss Force: 6.85701981361361, time: 9.950640439987183

Epoch 8, Batch 100/139, Loss: 0.20751017332077026, Uncertainty: 0.12689532339572906

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2579596551510175, Training Loss Force: 1.9228575866559008, time: 2.15687894821167
Validation Loss Energy: 0.8495248019600424, Validation Loss Force: 2.0504578854879685, time: 0.13234639167785645
Test Loss Energy: 9.249861596559404, Test Loss Force: 6.906738308498773, time: 9.84483528137207

Epoch 9, Batch 100/139, Loss: 0.13176625967025757, Uncertainty: 0.12822659313678741

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.325548453609538, Training Loss Force: 1.9216454102671003, time: 2.029310941696167
Validation Loss Energy: 0.8375205784127401, Validation Loss Force: 2.115944139074845, time: 0.12990403175354004
Test Loss Energy: 9.45452149978919, Test Loss Force: 6.990182663937331, time: 9.975326776504517

Epoch 10, Batch 100/139, Loss: 0.09051622450351715, Uncertainty: 0.12759926915168762

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9104261740875668, Training Loss Force: 1.9235171254574253, time: 2.02984881401062
Validation Loss Energy: 0.8308304097002912, Validation Loss Force: 2.0298607668205024, time: 0.13170647621154785
Test Loss Energy: 9.325999298301557, Test Loss Force: 6.818877948247194, time: 9.807884931564331

Epoch 11, Batch 100/139, Loss: 0.11302812397480011, Uncertainty: 0.12845203280448914

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.797316239598503, Training Loss Force: 1.9234722103674002, time: 2.0718352794647217
Validation Loss Energy: 4.379494467416442, Validation Loss Force: 1.993295895252457, time: 0.13635730743408203
Test Loss Energy: 12.395491852112702, Test Loss Force: 6.943699458477932, time: 9.764191389083862

Epoch 12, Batch 100/139, Loss: 0.16311930119991302, Uncertainty: 0.1282217651605606

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.585626770426816, Training Loss Force: 1.9238225225988104, time: 2.070716142654419
Validation Loss Energy: 1.2731425350838974, Validation Loss Force: 2.027425879709782, time: 0.13456249237060547
Test Loss Energy: 8.79045642506351, Test Loss Force: 6.824806883818357, time: 10.004045009613037

Epoch 13, Batch 100/139, Loss: 0.24488335847854614, Uncertainty: 0.12736502289772034

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2102867388700935, Training Loss Force: 1.9029592037683556, time: 2.1225788593292236
Validation Loss Energy: 1.7490362293741706, Validation Loss Force: 1.9095704779189173, time: 0.14573979377746582
Test Loss Energy: 8.357425108198875, Test Loss Force: 6.77865812741614, time: 9.777686595916748

Epoch 14, Batch 100/139, Loss: 0.06849798560142517, Uncertainty: 0.12588812410831451

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.577712664304843, Training Loss Force: 1.9118923983505718, time: 2.043858289718628
Validation Loss Energy: 3.8623110849506816, Validation Loss Force: 1.998445787259475, time: 0.1343076229095459
Test Loss Energy: 7.971696074171765, Test Loss Force: 6.774124131271916, time: 10.02094578742981

Epoch 15, Batch 100/139, Loss: 0.14570492506027222, Uncertainty: 0.12978163361549377

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.649481097056701, Training Loss Force: 1.9407899251349665, time: 2.0879087448120117
Validation Loss Energy: 1.0895115582625479, Validation Loss Force: 2.1966349841761565, time: 0.1371915340423584
Test Loss Energy: 8.795635758361687, Test Loss Force: 6.9838661534818645, time: 10.052355766296387

Epoch 16, Batch 100/139, Loss: 0.10629621148109436, Uncertainty: 0.12735146284103394

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9994537776433963, Training Loss Force: 1.9271399164181038, time: 2.074263572692871
Validation Loss Energy: 2.3671412106406087, Validation Loss Force: 1.9807349802845733, time: 0.14117741584777832
Test Loss Energy: 10.96252784699276, Test Loss Force: 6.748303218922932, time: 9.819738388061523

Epoch 17, Batch 100/139, Loss: 0.24185128509998322, Uncertainty: 0.12765392661094666

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.816854131150893, Training Loss Force: 1.9209825106032143, time: 2.13027024269104
Validation Loss Energy: 1.909321904929013, Validation Loss Force: 2.1107123048221257, time: 0.13762950897216797
Test Loss Energy: 10.449642881378061, Test Loss Force: 6.944842070627672, time: 10.163180589675903

Epoch 18, Batch 100/139, Loss: 0.11259970813989639, Uncertainty: 0.1274687647819519

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.207723952364082, Training Loss Force: 1.912180978364662, time: 2.0671939849853516
Validation Loss Energy: 2.094228553287383, Validation Loss Force: 2.0174988438460293, time: 0.13250422477722168
Test Loss Energy: 8.52096538574472, Test Loss Force: 6.796668652501893, time: 9.788900375366211

Epoch 19, Batch 100/139, Loss: 0.19439062476158142, Uncertainty: 0.12895885109901428

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.161891160689131, Training Loss Force: 1.9130411036201969, time: 2.0742580890655518
Validation Loss Energy: 0.9525064800315578, Validation Loss Force: 1.9529030070621944, time: 0.13447999954223633
Test Loss Energy: 9.51982919914599, Test Loss Force: 6.888155337178859, time: 10.705155372619629

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–…â–‚â–‚â–‚â–ƒâ–‚â–„â–ƒâ–ƒâ–ƒâ–ˆâ–‚â–‚â–â–‚â–†â–…â–‚â–ƒ
wandb:   test_error_force â–„â–„â–ƒâ–ˆâ–†â–†â–‚â–„â–…â–‡â–ƒâ–†â–ƒâ–‚â–‚â–‡â–â–†â–‚â–„
wandb:          test_loss â–„â–…â–ƒâ–‡â–…â–†â–â–„â–„â–†â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–„â–ƒâ–‡â–ƒâ–„
wandb: train_error_energy â–…â–ƒâ–â–‚â–‚â–â–â–â–„â–ˆâ–‚â–‚â–…â–„â–â–â–ƒâ–‚â–„â–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–â–â–ƒâ–‚â–‚â–â–
wandb:         train_loss â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–…â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–ƒâ–‚â–‚â–â–â–‡â–â–â–â–â–ˆâ–‚â–ƒâ–‡â–‚â–„â–ƒâ–ƒâ–
wandb:  valid_error_force â–‚â–…â–ƒâ–…â–„â–ˆâ–„â–„â–„â–…â–ƒâ–ƒâ–ƒâ–â–ƒâ–†â–‚â–…â–ƒâ–‚
wandb:         valid_loss â–‚â–…â–ƒâ–…â–ƒâ–ˆâ–†â–„â–ƒâ–„â–‚â–…â–ƒâ–â–…â–†â–ƒâ–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4418
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.51983
wandb:   test_error_force 6.88816
wandb:          test_loss 4.37844
wandb: train_error_energy 2.16189
wandb:  train_error_force 1.91304
wandb:         train_loss -2.49408
wandb: valid_error_energy 0.95251
wandb:  valid_error_force 1.9529
wandb:         valid_loss -2.52261
wandb: 
wandb: ğŸš€ View run al_58_60 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qklhehbo
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_163239-qklhehbo/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 38.206207275390625, Uncertainty Bias: -4.739235877990723
3.2424927e-05 0.00031280518
-0.3853922 16.2337
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3489 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1862 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1226 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2568 steps.
Found uncertainty sample 10 after 1954 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 2078 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1766 steps.
Found uncertainty sample 17 after 627 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1783 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2296 steps.
Found uncertainty sample 22 after 780 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2506 steps.
Found uncertainty sample 25 after 2576 steps.
Found uncertainty sample 26 after 1758 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2436 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1651 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 815 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2756 steps.
Found uncertainty sample 43 after 2376 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 610 steps.
Found uncertainty sample 47 after 1600 steps.
Found uncertainty sample 48 after 2474 steps.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 1764 steps.
Found uncertainty sample 51 after 2084 steps.
Found uncertainty sample 52 after 1482 steps.
Found uncertainty sample 53 after 3835 steps.
Found uncertainty sample 54 after 1842 steps.
Found uncertainty sample 55 after 1455 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 1464 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2250 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2337 steps.
Found uncertainty sample 65 after 2045 steps.
Found uncertainty sample 66 after 1624 steps.
Found uncertainty sample 67 after 2390 steps.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 3183 steps.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1096 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2054 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 444 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1069 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3716 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1510 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_170928-n26nybdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_61
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n26nybdy
Training model 61. Added 41 samples to the dataset.
Epoch 0, Batch 100/140, Loss: 0.060891781002283096, Uncertainty: 0.1298031359910965

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.008962344458553, Training Loss Force: 2.114395231554268, time: 2.102726459503174
Validation Loss Energy: 0.9071202733553888, Validation Loss Force: 1.9852566484078802, time: 0.13509273529052734
Test Loss Energy: 9.227363894140424, Test Loss Force: 6.929296439360214, time: 9.829530239105225

Epoch 1, Batch 100/140, Loss: 0.16077154874801636, Uncertainty: 0.12836752831935883

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9451797103727975, Training Loss Force: 1.9093787388427703, time: 2.149777412414551
Validation Loss Energy: 1.3382904800150603, Validation Loss Force: 2.034212464162418, time: 0.13288426399230957
Test Loss Energy: 8.378012498206537, Test Loss Force: 6.858702250384729, time: 9.685121536254883

Epoch 2, Batch 100/140, Loss: 0.18675440549850464, Uncertainty: 0.12887254357337952

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.1153266430724855, Training Loss Force: 1.945803808647874, time: 2.0496411323547363
Validation Loss Energy: 2.5333930461799166, Validation Loss Force: 1.9930350012364784, time: 0.13211989402770996
Test Loss Energy: 8.340079365928615, Test Loss Force: 6.772965671141183, time: 9.877084493637085

Epoch 3, Batch 100/140, Loss: 0.11052917689085007, Uncertainty: 0.12808284163475037

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.766416680364166, Training Loss Force: 1.900862571268976, time: 2.0708065032958984
Validation Loss Energy: 3.3146479333367913, Validation Loss Force: 1.958110533266483, time: 0.13816523551940918
Test Loss Energy: 8.190469295799769, Test Loss Force: 6.678605195150735, time: 9.696035623550415

Epoch 4, Batch 100/140, Loss: 0.06495948880910873, Uncertainty: 0.1280294954776764

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7897925467458773, Training Loss Force: 1.9293215609251138, time: 2.082383632659912
Validation Loss Energy: 2.431310227783225, Validation Loss Force: 1.9367369301756423, time: 0.13109517097473145
Test Loss Energy: 10.80964133211778, Test Loss Force: 6.80664070017572, time: 9.905165195465088

Epoch 5, Batch 100/140, Loss: 0.23987391591072083, Uncertainty: 0.131353497505188

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.7388876409599754, Training Loss Force: 2.0361083917388774, time: 2.1575257778167725
Validation Loss Energy: 3.8495426423387933, Validation Loss Force: 2.311745432070597, time: 0.13667821884155273
Test Loss Energy: 12.29041081270761, Test Loss Force: 6.941037422024803, time: 9.836796045303345

Epoch 6, Batch 100/140, Loss: 0.32918781042099, Uncertainty: 0.13273407518863678

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2731700012592744, Training Loss Force: 1.9848084774463899, time: 2.076727867126465
Validation Loss Energy: 0.7700154207912613, Validation Loss Force: 1.9622434210610002, time: 0.13053011894226074
Test Loss Energy: 9.24398318240242, Test Loss Force: 6.790374133830559, time: 9.733659029006958

Epoch 7, Batch 100/140, Loss: 0.14595279097557068, Uncertainty: 0.12943042814731598

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9589592974200376, Training Loss Force: 1.9254326538344482, time: 2.1437785625457764
Validation Loss Energy: 1.0125645237347685, Validation Loss Force: 2.1098996366625378, time: 0.14165616035461426
Test Loss Energy: 8.602413611383634, Test Loss Force: 6.852377280833332, time: 9.971769571304321

Epoch 8, Batch 100/140, Loss: 0.17523552477359772, Uncertainty: 0.1288074553012848

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6173151543910502, Training Loss Force: 1.938506791229394, time: 2.077341079711914
Validation Loss Energy: 1.55234411134861, Validation Loss Force: 1.9727655031057205, time: 0.13335752487182617
Test Loss Energy: 8.319070548331625, Test Loss Force: 6.731341393234462, time: 10.482106924057007

Epoch 9, Batch 100/140, Loss: 0.19916215538978577, Uncertainty: 0.1281537264585495

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8243053287566477, Training Loss Force: 1.9160807198883287, time: 2.0350558757781982
Validation Loss Energy: 1.0876212827712424, Validation Loss Force: 2.0561032163446757, time: 0.13438892364501953
Test Loss Energy: 9.698662363323171, Test Loss Force: 6.768690701001446, time: 9.946953535079956

Epoch 10, Batch 100/140, Loss: 0.31567665934562683, Uncertainty: 0.1298079788684845

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.985368470864848, Training Loss Force: 1.9262571380382985, time: 2.0206668376922607
Validation Loss Energy: 0.7797183030481133, Validation Loss Force: 1.9163174643751022, time: 0.150099515914917
Test Loss Energy: 8.790870605996236, Test Loss Force: 6.777724308976858, time: 9.779496192932129

Epoch 11, Batch 100/140, Loss: 0.13822981715202332, Uncertainty: 0.1289159655570984

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1662369873559624, Training Loss Force: 1.9702523480552891, time: 2.075269937515259
Validation Loss Energy: 3.0370736231905178, Validation Loss Force: 2.204856374382102, time: 0.1299593448638916
Test Loss Energy: 8.366842220060382, Test Loss Force: 6.95451601211319, time: 9.70851731300354

Epoch 12, Batch 100/140, Loss: 0.049884404987096786, Uncertainty: 0.12614648044109344

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7244071540645545, Training Loss Force: 1.8977360388001383, time: 2.08599591255188
Validation Loss Energy: 1.1692542039174503, Validation Loss Force: 1.9135469035268955, time: 0.1309490203857422
Test Loss Energy: 8.65667463378899, Test Loss Force: 6.7026138674404, time: 10.055853843688965

Epoch 13, Batch 100/140, Loss: 0.05377518758177757, Uncertainty: 0.12564310431480408

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.782055992759663, Training Loss Force: 1.924256448604914, time: 2.088754177093506
Validation Loss Energy: 1.0544125919051937, Validation Loss Force: 1.9987321397811382, time: 0.1373915672302246
Test Loss Energy: 8.723292317881619, Test Loss Force: 6.815048586866547, time: 9.67385220527649

Epoch 14, Batch 100/140, Loss: 0.0780584067106247, Uncertainty: 0.1264859288930893

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.079974247284647, Training Loss Force: 1.9169816710626302, time: 2.128957986831665
Validation Loss Energy: 6.461976629471745, Validation Loss Force: 2.2372852407875876, time: 0.13553166389465332
Test Loss Energy: 8.008514461751593, Test Loss Force: 6.9368852556677565, time: 9.914923191070557

Epoch 15, Batch 100/140, Loss: 0.0615856871008873, Uncertainty: 0.12565162777900696

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.004203950536776, Training Loss Force: 1.9173167730175598, time: 2.0610949993133545
Validation Loss Energy: 1.727933874414594, Validation Loss Force: 1.9892976480681777, time: 0.13534975051879883
Test Loss Energy: 10.20832634396457, Test Loss Force: 6.77139808035385, time: 9.784839630126953

Epoch 16, Batch 100/140, Loss: 0.037357211112976074, Uncertainty: 0.12703916430473328

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.680016369128835, Training Loss Force: 1.900864460775728, time: 2.0996251106262207
Validation Loss Energy: 0.8714081689489604, Validation Loss Force: 2.0416978586180234, time: 0.12800812721252441
Test Loss Energy: 8.827953592138236, Test Loss Force: 6.847506443395865, time: 9.70432710647583

Epoch 17, Batch 100/140, Loss: 0.08948172628879547, Uncertainty: 0.12923604249954224

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9089717990498831, Training Loss Force: 1.9469656787558924, time: 2.084899663925171
Validation Loss Energy: 0.8389513018983749, Validation Loss Force: 2.1447382285652536, time: 0.12976741790771484
Test Loss Energy: 9.216068772049248, Test Loss Force: 6.79570523189008, time: 9.995498180389404

Epoch 18, Batch 100/140, Loss: 0.15954157710075378, Uncertainty: 0.12847471237182617

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7116395318824358, Training Loss Force: 1.9109197962156235, time: 2.1202714443206787
Validation Loss Energy: 1.153634891118724, Validation Loss Force: 1.9146886395726403, time: 0.12964487075805664
Test Loss Energy: 8.683059596229786, Test Loss Force: 6.712502130893391, time: 9.771129369735718

Epoch 19, Batch 100/140, Loss: 0.19601187109947205, Uncertainty: 0.12666986882686615

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9762585655564002, Training Loss Force: 1.923052264997194, time: 2.110450029373169
Validation Loss Energy: 3.5781966850963145, Validation Loss Force: 1.9731501269437866, time: 0.12874436378479004
Test Loss Energy: 8.057275304438212, Test Loss Force: 6.726136918141516, time: 9.961802005767822

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.039 MB of 0.049 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–‚â–‚â–â–†â–ˆâ–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–‚â–â–…â–‚â–ƒâ–‚â–
wandb:   test_error_force â–‡â–†â–ƒâ–â–„â–ˆâ–„â–…â–‚â–ƒâ–„â–ˆâ–‚â–„â–ˆâ–ƒâ–…â–„â–‚â–‚
wandb:          test_loss â–†â–†â–‚â–â–ˆâ–ˆâ–ƒâ–…â–â–ƒâ–„â–…â–„â–ƒâ–ˆâ–…â–‡â–ƒâ–ƒâ–‚
wandb: train_error_energy â–ƒâ–ƒâ–„â–ˆâ–‚â–ˆâ–…â–ƒâ–â–‚â–ƒâ–„â–‚â–‚â–„â–ƒâ–â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–â–ƒâ–â–‚â–…â–„â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–‚â–â–ƒâ–â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–‚â–‡â–„â–‚â–‚â–‚â–‚â–„â–â–‚â–‚â–‚â–â–ƒâ–â–‚
wandb: valid_error_energy â–â–‚â–ƒâ–„â–ƒâ–…â–â–â–‚â–â–â–„â–â–â–ˆâ–‚â–â–â–â–„
wandb:  valid_error_force â–‚â–ƒâ–‚â–‚â–â–ˆâ–‚â–„â–‚â–„â–â–†â–â–‚â–‡â–‚â–ƒâ–…â–â–‚
wandb:         valid_loss â–‚â–ƒâ–ƒâ–ƒâ–‚â–‡â–‚â–ƒâ–‚â–ƒâ–â–†â–â–‚â–ˆâ–‚â–ƒâ–„â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4454
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.05728
wandb:   test_error_force 6.72614
wandb:          test_loss 4.13179
wandb: train_error_energy 1.97626
wandb:  train_error_force 1.92305
wandb:         train_loss -2.49312
wandb: valid_error_energy 3.5782
wandb:  valid_error_force 1.97315
wandb:         valid_loss -2.31959
wandb: 
wandb: ğŸš€ View run al_58_61 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/n26nybdy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_170928-n26nybdy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 41.90648651123047, Uncertainty Bias: -5.172347068786621
7.6293945e-06 0.13639832
-0.42512348 14.574212
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 597 steps.
Found uncertainty sample 4 after 1338 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3383 steps.
Found uncertainty sample 7 after 2978 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3532 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1594 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3069 steps.
Found uncertainty sample 20 after 1201 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3487 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 2309 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 529 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 2793 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 739 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1775 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 825 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3133 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1647 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 3126 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2907 steps.
Found uncertainty sample 70 after 2699 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1298 steps.
Found uncertainty sample 73 after 686 steps.
Found uncertainty sample 74 after 2971 steps.
Found uncertainty sample 75 after 7 steps.
Found uncertainty sample 76 after 1555 steps.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 3008 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 981 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1792 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 110 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1277 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_174748-pbtup6de
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_62
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pbtup6de
Training model 62. Added 32 samples to the dataset.
Epoch 0, Batch 100/141, Loss: 0.06581033021211624, Uncertainty: 0.1299571990966797

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.23568892502272, Training Loss Force: 1.9972581655775314, time: 2.1221508979797363
Validation Loss Energy: 1.3438830382841827, Validation Loss Force: 2.1680471605379257, time: 0.1368861198425293
Test Loss Energy: 9.690445312251056, Test Loss Force: 6.736991430454216, time: 9.911534547805786

Epoch 1, Batch 100/141, Loss: 0.05925672501325607, Uncertainty: 0.12743043899536133

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5709963468907497, Training Loss Force: 1.9295517726894376, time: 2.1355738639831543
Validation Loss Energy: 3.878105601255729, Validation Loss Force: 1.9275835953709402, time: 0.1334092617034912
Test Loss Energy: 8.164203122102194, Test Loss Force: 6.704730478735095, time: 10.035066843032837

Epoch 2, Batch 100/141, Loss: 0.1454440951347351, Uncertainty: 0.12621834874153137

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.087930372681757, Training Loss Force: 1.9319818439876717, time: 2.1194987297058105
Validation Loss Energy: 2.042989339664405, Validation Loss Force: 2.1588616129301124, time: 0.1390523910522461
Test Loss Energy: 8.18523653356464, Test Loss Force: 6.732120159336528, time: 10.099149703979492

Epoch 3, Batch 100/141, Loss: 0.23359812796115875, Uncertainty: 0.12606549263000488

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5878749914961017, Training Loss Force: 1.9088298108541544, time: 2.1895833015441895
Validation Loss Energy: 0.984332636726303, Validation Loss Force: 2.0191265553027615, time: 0.13841581344604492
Test Loss Energy: 9.445777317402817, Test Loss Force: 6.759211031933811, time: 9.864728927612305

Epoch 4, Batch 100/141, Loss: 0.10506637394428253, Uncertainty: 0.12728704512119293

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8650431456189367, Training Loss Force: 1.9323825386949827, time: 2.118452787399292
Validation Loss Energy: 3.3574365559796155, Validation Loss Force: 2.136460503065388, time: 0.14115333557128906
Test Loss Energy: 11.71834695859382, Test Loss Force: 6.833617106842312, time: 10.128174543380737

Epoch 5, Batch 100/141, Loss: 0.1659248173236847, Uncertainty: 0.12702760100364685

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.10775554637592, Training Loss Force: 1.9021258200729123, time: 2.10884690284729
Validation Loss Energy: 1.1836844263653978, Validation Loss Force: 1.9653707721040317, time: 0.13950538635253906
Test Loss Energy: 8.759511088928253, Test Loss Force: 6.709559983649527, time: 10.637709379196167

Epoch 6, Batch 100/141, Loss: 0.08751894533634186, Uncertainty: 0.1262805461883545

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.620834966058594, Training Loss Force: 1.9010315022903608, time: 2.1088180541992188
Validation Loss Energy: 2.6576048727450092, Validation Loss Force: 2.077855616764264, time: 0.13439226150512695
Test Loss Energy: 11.184810378661252, Test Loss Force: 6.83842730599205, time: 9.96874475479126

Epoch 7, Batch 100/141, Loss: 0.0733642578125, Uncertainty: 0.12671053409576416

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8259739110082138, Training Loss Force: 1.9128265964760605, time: 2.3050270080566406
Validation Loss Energy: 0.9161207272356494, Validation Loss Force: 1.8854236048385944, time: 0.13672733306884766
Test Loss Energy: 8.47462413827779, Test Loss Force: 6.619863647507157, time: 10.025869607925415

Epoch 8, Batch 100/141, Loss: 0.1366986632347107, Uncertainty: 0.12785391509532928

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.87449846479311, Training Loss Force: 1.9268809447200062, time: 2.152289867401123
Validation Loss Energy: 1.2313167709395894, Validation Loss Force: 2.0749939471238488, time: 0.13364052772521973
Test Loss Energy: 8.618056477953632, Test Loss Force: 6.812933071430476, time: 10.128700971603394

Epoch 9, Batch 100/141, Loss: 0.09109573066234589, Uncertainty: 0.12689387798309326

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.0342677113780288, Training Loss Force: 1.9124809010477937, time: 2.0880613327026367
Validation Loss Energy: 1.5802361681288655, Validation Loss Force: 1.9800084850844595, time: 0.1372394561767578
Test Loss Energy: 10.089167582913625, Test Loss Force: 6.709053389192208, time: 10.242726564407349

Epoch 10, Batch 100/141, Loss: 0.18046480417251587, Uncertainty: 0.12439598143100739

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5420740165540316, Training Loss Force: 1.8996522982861601, time: 2.1016461849212646
Validation Loss Energy: 0.8265723261784762, Validation Loss Force: 1.9480420282720177, time: 0.1329336166381836
Test Loss Energy: 8.685036940214678, Test Loss Force: 6.7282305000838125, time: 10.017781496047974

Epoch 11, Batch 100/141, Loss: 0.25303059816360474, Uncertainty: 0.1280204951763153

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6612026843444947, Training Loss Force: 1.8985816556821082, time: 2.130566120147705
Validation Loss Energy: 3.876397580460365, Validation Loss Force: 2.0848263486005827, time: 0.13459253311157227
Test Loss Energy: 7.9988734636416, Test Loss Force: 6.725924647994446, time: 10.061248540878296

Epoch 12, Batch 100/141, Loss: 0.05276362970471382, Uncertainty: 0.1255713403224945

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.823107948275081, Training Loss Force: 1.9088642748265383, time: 2.2865347862243652
Validation Loss Energy: 2.1699662716836285, Validation Loss Force: 2.091560828473071, time: 0.13585877418518066
Test Loss Energy: 8.426336242525508, Test Loss Force: 6.813282144371254, time: 10.146937131881714

Epoch 13, Batch 100/141, Loss: 0.05210025608539581, Uncertainty: 0.1284521222114563

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.1315568944516126, Training Loss Force: 1.9028366107813834, time: 2.0949325561523438
Validation Loss Energy: 1.257615629980731, Validation Loss Force: 2.074002030301789, time: 0.13790535926818848
Test Loss Energy: 9.9490195105492, Test Loss Force: 6.712185826457082, time: 10.043591499328613

Epoch 14, Batch 100/141, Loss: 0.12828093767166138, Uncertainty: 0.1274920254945755

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0436566344819607, Training Loss Force: 1.9179485379780163, time: 2.0964467525482178
Validation Loss Energy: 4.461096623108987, Validation Loss Force: 2.1285558968310485, time: 0.1353294849395752
Test Loss Energy: 12.546390250945679, Test Loss Force: 6.7814796019725945, time: 10.129561185836792

Epoch 15, Batch 100/141, Loss: 0.08291956037282944, Uncertainty: 0.1281449943780899

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.082697983335387, Training Loss Force: 1.9277990411929424, time: 2.0864572525024414
Validation Loss Energy: 2.972132834788116, Validation Loss Force: 2.001344494201163, time: 0.14044713973999023
Test Loss Energy: 11.4000833788805, Test Loss Force: 6.785928783322556, time: 9.966397047042847

Epoch 16, Batch 100/141, Loss: 0.0714418813586235, Uncertainty: 0.12817543745040894

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.7388094425440643, Training Loss Force: 1.9020819953107237, time: 2.1297783851623535
Validation Loss Energy: 1.061223001956444, Validation Loss Force: 2.0606472256056243, time: 0.1340799331665039
Test Loss Energy: 9.499643264121332, Test Loss Force: 6.73353850583735, time: 10.060417890548706

Epoch 17, Batch 100/141, Loss: 0.06571841239929199, Uncertainty: 0.12580254673957825

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8683283023646478, Training Loss Force: 1.8891114512334501, time: 2.261451005935669
Validation Loss Energy: 1.182092898644879, Validation Loss Force: 1.9537717507350318, time: 0.13219499588012695
Test Loss Energy: 8.4134393831586, Test Loss Force: 6.719048554819772, time: 10.01699423789978

Epoch 18, Batch 100/141, Loss: 0.09320507943630219, Uncertainty: 0.12582090497016907

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.7161859288413306, Training Loss Force: 1.9107524736516952, time: 2.133748769760132
Validation Loss Energy: 1.454334728084473, Validation Loss Force: 2.046248028392009, time: 0.13455653190612793
Test Loss Energy: 8.213835918511352, Test Loss Force: 6.713010303853451, time: 10.002655029296875

Epoch 19, Batch 100/141, Loss: 0.045438893139362335, Uncertainty: 0.13047242164611816

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.892204380153263, Training Loss Force: 1.981101433688646, time: 2.0901734828948975
Validation Loss Energy: 1.5878162711945392, Validation Loss Force: 2.2719337474627292, time: 0.13295888900756836
Test Loss Energy: 8.56899078371913, Test Loss Force: 6.925175234506715, time: 10.258728742599487

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–â–â–ƒâ–‡â–‚â–†â–‚â–‚â–„â–‚â–â–‚â–„â–ˆâ–†â–ƒâ–‚â–â–‚
wandb:   test_error_force â–„â–ƒâ–„â–„â–†â–ƒâ–†â–â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–…â–…â–„â–ƒâ–ƒâ–ˆ
wandb:          test_loss â–ƒâ–‚â–‚â–…â–‡â–‚â–ˆâ–â–„â–ƒâ–ƒâ–‚â–…â–…â–‡â–†â–„â–„â–‚â–…
wandb: train_error_energy â–ˆâ–â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–…â–‚â–‚â–‚â–‚â–â–‚
wandb:  train_error_force â–ˆâ–„â–„â–‚â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–„â–‚â–â–‚â–‡
wandb:         train_loss â–ˆâ–‚â–ƒâ–â–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–„â–‚â–ƒâ–â–â–‚â–„
wandb: valid_error_energy â–‚â–‡â–ƒâ–â–†â–‚â–…â–â–‚â–‚â–â–‡â–„â–‚â–ˆâ–…â–â–‚â–‚â–‚
wandb:  valid_error_force â–†â–‚â–†â–ƒâ–†â–‚â–„â–â–„â–ƒâ–‚â–…â–…â–„â–…â–ƒâ–„â–‚â–„â–ˆ
wandb:         valid_loss â–†â–„â–†â–ƒâ–‡â–ƒâ–†â–â–„â–ƒâ–‚â–‡â–…â–„â–ˆâ–…â–„â–‚â–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4482
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.56899
wandb:   test_error_force 6.92518
wandb:          test_loss 4.2842
wandb: train_error_energy 1.8922
wandb:  train_error_force 1.9811
wandb:         train_loss -2.42321
wandb: valid_error_energy 1.58782
wandb:  valid_error_force 2.27193
wandb:         valid_loss -2.06887
wandb: 
wandb: ğŸš€ View run al_58_62 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/pbtup6de
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_174748-pbtup6de/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.72865676879883, Uncertainty Bias: -4.999425888061523
1.9073486e-05 0.019077301
0.10942496 19.05465
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2864 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2294 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3040 steps.
Found uncertainty sample 8 after 3226 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 852 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1160 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2185 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1672 steps.
Found uncertainty sample 25 after 2589 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2174 steps.
Found uncertainty sample 34 after 856 steps.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 1611 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1080 steps.
Found uncertainty sample 39 after 2068 steps.
Found uncertainty sample 40 after 1848 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2261 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3848 steps.
Found uncertainty sample 46 after 3905 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2541 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1354 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1170 steps.
Found uncertainty sample 62 after 996 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3457 steps.
Found uncertainty sample 65 after 595 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 1674 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3056 steps.
Found uncertainty sample 74 after 1904 steps.
Found uncertainty sample 75 after 773 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 1862 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 813 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 817 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_182516-clnmn65p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_63
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/clnmn65p
Training model 63. Added 31 samples to the dataset.
Epoch 0, Batch 100/141, Loss: 0.3801819682121277, Uncertainty: 0.1314702332019806

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6110132486213766, Training Loss Force: 2.035232694708714, time: 2.1283888816833496
Validation Loss Energy: 1.7945139159577916, Validation Loss Force: 1.9635141938768104, time: 0.12400650978088379
Test Loss Energy: 10.207002831203772, Test Loss Force: 6.720891446277962, time: 8.568981170654297

Epoch 1, Batch 100/141, Loss: 0.06236390769481659, Uncertainty: 0.12754036486148834

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8422412806419732, Training Loss Force: 1.900150769226347, time: 2.153883695602417
Validation Loss Energy: 0.7844486121611546, Validation Loss Force: 2.052892549929543, time: 0.12247920036315918
Test Loss Energy: 9.09586836240204, Test Loss Force: 6.759360688916017, time: 8.542929887771606

Epoch 2, Batch 100/141, Loss: 0.05035313963890076, Uncertainty: 0.12583670020103455

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7256866389629801, Training Loss Force: 1.8729724460194808, time: 2.0973384380340576
Validation Loss Energy: 1.2320783365301866, Validation Loss Force: 1.882903101441265, time: 0.11988639831542969
Test Loss Energy: 8.552223036924573, Test Loss Force: 6.623780484053749, time: 8.688608407974243

Epoch 3, Batch 100/141, Loss: 0.10440286993980408, Uncertainty: 0.12519797682762146

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6981619708761713, Training Loss Force: 1.9047698290439703, time: 2.1293632984161377
Validation Loss Energy: 3.6937803791489006, Validation Loss Force: 2.0280305006640247, time: 0.12488508224487305
Test Loss Energy: 8.234794734644105, Test Loss Force: 6.83087862842113, time: 8.595385789871216

Epoch 4, Batch 100/141, Loss: 0.06612903624773026, Uncertainty: 0.12641024589538574

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.746663729104655, Training Loss Force: 1.897475537619232, time: 2.0808770656585693
Validation Loss Energy: 1.2076473376196601, Validation Loss Force: 1.9235334662756596, time: 0.1289501190185547
Test Loss Energy: 8.485447749708909, Test Loss Force: 6.685888399804198, time: 8.54395604133606

Epoch 5, Batch 100/141, Loss: 0.17894630134105682, Uncertainty: 0.12566831707954407

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5735333949214645, Training Loss Force: 1.8790602544222428, time: 2.0757713317871094
Validation Loss Energy: 1.4122936799875772, Validation Loss Force: 2.010547558448456, time: 0.1206669807434082
Test Loss Energy: 8.505265653438599, Test Loss Force: 6.561717999803911, time: 8.725403070449829

Epoch 6, Batch 100/141, Loss: 0.19219468533992767, Uncertainty: 0.12487095594406128

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.4483530199505315, Training Loss Force: 1.8800944602210705, time: 2.0948307514190674
Validation Loss Energy: 2.0441728261750107, Validation Loss Force: 1.8921621298672342, time: 0.1271684169769287
Test Loss Energy: 10.261239243422372, Test Loss Force: 6.639057608973815, time: 8.547431468963623

Epoch 7, Batch 100/141, Loss: 0.22392535209655762, Uncertainty: 0.126316636800766

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.4757420777898287, Training Loss Force: 1.9293014609851387, time: 2.0766260623931885
Validation Loss Energy: 2.4395763744875016, Validation Loss Force: 1.9388278305674287, time: 0.12016677856445312
Test Loss Energy: 8.183345659820016, Test Loss Force: 6.578056664320071, time: 9.352050065994263

Epoch 8, Batch 100/141, Loss: 0.2091577649116516, Uncertainty: 0.12814128398895264

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.446860294294148, Training Loss Force: 1.9181041939759094, time: 2.255540132522583
Validation Loss Energy: 1.7905721154020051, Validation Loss Force: 1.961962338375791, time: 0.12955832481384277
Test Loss Energy: 8.254727803788711, Test Loss Force: 6.643209420925519, time: 8.562725067138672

Epoch 9, Batch 100/141, Loss: 0.17037710547447205, Uncertainty: 0.12770366668701172

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9292247984459767, Training Loss Force: 1.9029432148194068, time: 2.0455145835876465
Validation Loss Energy: 2.845643845090669, Validation Loss Force: 2.0486806145882217, time: 0.13182687759399414
Test Loss Energy: 8.0109534163631, Test Loss Force: 6.652413835954576, time: 8.63640832901001

Epoch 10, Batch 100/141, Loss: 0.29263365268707275, Uncertainty: 0.12599517405033112

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0933710236117458, Training Loss Force: 1.8736372942400552, time: 2.128694534301758
Validation Loss Energy: 1.5463398007171432, Validation Loss Force: 1.9859522668197587, time: 0.12753891944885254
Test Loss Energy: 9.725304486477182, Test Loss Force: 6.759409202810458, time: 8.860487937927246

Epoch 11, Batch 100/141, Loss: 0.19150546193122864, Uncertainty: 0.1251208484172821

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.813463673800808, Training Loss Force: 1.8932769987485842, time: 2.062387704849243
Validation Loss Energy: 1.269438470952913, Validation Loss Force: 1.8922277059307098, time: 0.12079715728759766
Test Loss Energy: 8.468793909257663, Test Loss Force: 6.559431999076938, time: 8.617095708847046

Epoch 12, Batch 100/141, Loss: 0.08327097445726395, Uncertainty: 0.12720879912376404

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.8595431194084613, Training Loss Force: 1.9375320651140056, time: 2.1070334911346436
Validation Loss Energy: 1.6299997533217805, Validation Loss Force: 1.99954733152438, time: 0.12485074996948242
Test Loss Energy: 8.168009554389844, Test Loss Force: 6.601682355005197, time: 8.593706130981445

Epoch 13, Batch 100/141, Loss: 0.26208025217056274, Uncertainty: 0.1279701292514801

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.966025441107249, Training Loss Force: 1.9133362585148481, time: 2.095001220703125
Validation Loss Energy: 6.929656652753131, Validation Loss Force: 1.9516871964139044, time: 0.12668132781982422
Test Loss Energy: 8.055637923777834, Test Loss Force: 6.677120029253219, time: 8.774006843566895

Epoch 14, Batch 100/141, Loss: 0.2175603210926056, Uncertainty: 0.1274549961090088

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1720194004397246, Training Loss Force: 1.9157090217234614, time: 2.1232855319976807
Validation Loss Energy: 0.8163060909824269, Validation Loss Force: 2.022975391490123, time: 0.11864733695983887
Test Loss Energy: 8.82498072587869, Test Loss Force: 6.743411786338177, time: 8.658329725265503

Epoch 15, Batch 100/141, Loss: 0.11448295414447784, Uncertainty: 0.12647664546966553

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.005534317390844, Training Loss Force: 1.8990893567321578, time: 2.092355728149414
Validation Loss Energy: 2.9762931851106313, Validation Loss Force: 2.0108125347321097, time: 0.12511634826660156
Test Loss Energy: 8.012117407082462, Test Loss Force: 6.65479044786845, time: 8.584160089492798

Epoch 16, Batch 100/141, Loss: 0.12339942157268524, Uncertainty: 0.12735921144485474

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2381496033265376, Training Loss Force: 1.879256390407495, time: 2.0647525787353516
Validation Loss Energy: 1.6862695825126082, Validation Loss Force: 1.9568492610008994, time: 0.11977648735046387
Test Loss Energy: 10.177151343841102, Test Loss Force: 6.632834565932517, time: 8.764970064163208

Epoch 17, Batch 100/141, Loss: 0.14064663648605347, Uncertainty: 0.12524062395095825

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1890128144080574, Training Loss Force: 1.8672905310958612, time: 2.075678586959839
Validation Loss Energy: 0.8360894281445758, Validation Loss Force: 1.8941680077568002, time: 0.12017512321472168
Test Loss Energy: 9.044993634077601, Test Loss Force: 6.6408676549842705, time: 8.57577109336853

Epoch 18, Batch 100/141, Loss: 0.16329419612884521, Uncertainty: 0.12975391745567322

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.073355465823798, Training Loss Force: 1.9418718449189727, time: 2.0986554622650146
Validation Loss Energy: 1.3244345955175094, Validation Loss Force: 1.9064325872029784, time: 0.12294268608093262
Test Loss Energy: 9.796730196655211, Test Loss Force: 6.646753166574554, time: 8.538638591766357

Epoch 19, Batch 100/141, Loss: 0.14176422357559204, Uncertainty: 0.12466539442539215

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.5859394063868313, Training Loss Force: 1.8799704721975268, time: 2.0599684715270996
Validation Loss Energy: 1.167636772352955, Validation Loss Force: 1.9418013543421484, time: 0.12350702285766602
Test Loss Energy: 8.76388152234382, Test Loss Force: 6.60049577794011, time: 8.792707204818726

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.058 MB uploadedwandb: | 0.039 MB of 0.058 MB uploadedwandb: / 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–ƒâ–‚â–‚â–ƒâ–ˆâ–‚â–‚â–â–†â–‚â–â–â–„â–â–ˆâ–„â–‡â–ƒ
wandb:   test_error_force â–…â–†â–ƒâ–ˆâ–„â–â–ƒâ–â–ƒâ–ƒâ–†â–â–‚â–„â–†â–ƒâ–ƒâ–ƒâ–ƒâ–‚
wandb:          test_loss â–…â–†â–…â–‡â–…â–ƒâ–‡â–â–„â–„â–ˆâ–„â–â–„â–†â–„â–†â–†â–„â–„
wandb: train_error_energy â–…â–‚â–‚â–‚â–‚â–â–â–â–ˆâ–ƒâ–ƒâ–‚â–‚â–ƒâ–„â–ƒâ–„â–„â–ƒâ–
wandb:  train_error_force â–ˆâ–‚â–â–ƒâ–‚â–â–‚â–„â–ƒâ–‚â–â–‚â–„â–ƒâ–ƒâ–‚â–â–â–„â–‚
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–â–â–ƒâ–†â–ƒâ–‚â–‚â–„â–ƒâ–ƒâ–ƒâ–‚â–‚â–„â–
wandb: valid_error_energy â–‚â–â–‚â–„â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–ˆâ–â–ƒâ–‚â–â–‚â–
wandb:  valid_error_force â–„â–ˆâ–â–‡â–ƒâ–†â–â–ƒâ–„â–ˆâ–…â–â–†â–„â–‡â–†â–„â–â–‚â–ƒ
wandb:         valid_loss â–ƒâ–„â–â–†â–‚â–„â–‚â–ƒâ–ƒâ–†â–ƒâ–â–„â–ˆâ–ƒâ–…â–ƒâ–â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4509
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.76388
wandb:   test_error_force 6.6005
wandb:          test_loss 3.99294
wandb: train_error_energy 1.58594
wandb:  train_error_force 1.87997
wandb:         train_loss -2.57619
wandb: valid_error_energy 1.16764
wandb:  valid_error_force 1.9418
wandb:         valid_loss -2.5225
wandb: 
wandb: ğŸš€ View run al_58_63 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/clnmn65p
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_182516-clnmn65p/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.41238021850586, Uncertainty Bias: -4.8744964599609375
6.866455e-05 0.00070762634
-0.38722342 16.032656
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 1744 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2459 steps.
Found uncertainty sample 11 after 3494 steps.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2026 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 1916 steps.
Found uncertainty sample 17 after 1306 steps.
Found uncertainty sample 18 after 3042 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1370 steps.
Found uncertainty sample 23 after 3986 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2101 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2242 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2732 steps.
Found uncertainty sample 34 after 1078 steps.
Found uncertainty sample 35 after 3278 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 919 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 2567 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3221 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2974 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2574 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 3506 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3059 steps.
Found uncertainty sample 61 after 1322 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3539 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3224 steps.
Found uncertainty sample 72 after 1322 steps.
Found uncertainty sample 73 after 3454 steps.
Found uncertainty sample 74 after 1681 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1769 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1220 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2293 steps.
Found uncertainty sample 86 after 106 steps.
Found uncertainty sample 87 after 43 steps.
Found uncertainty sample 88 after 3636 steps.
Found uncertainty sample 89 after 1010 steps.
Found uncertainty sample 90 after 2922 steps.
Found uncertainty sample 91 after 604 steps.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3769 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1890 steps.
Found uncertainty sample 98 after 1676 steps.
Found uncertainty sample 99 after 3897 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_190101-lq1xwoau
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_64
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lq1xwoau
Training model 64. Added 40 samples to the dataset.
Epoch 0, Batch 100/143, Loss: 0.10447029024362564, Uncertainty: 0.12843146920204163
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.924675706307022, Training Loss Force: 1.9831535056249272, time: 2.129706859588623
Validation Loss Energy: 1.7244197099535616, Validation Loss Force: 2.135900638609477, time: 0.12503361701965332
Test Loss Energy: 8.297146453290626, Test Loss Force: 6.702371883203322, time: 8.515307426452637

Epoch 1, Batch 100/143, Loss: 0.24144189059734344, Uncertainty: 0.12723404169082642

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.1293234721528957, Training Loss Force: 1.9119511705256766, time: 2.1114041805267334
Validation Loss Energy: 3.7807707570576548, Validation Loss Force: 1.9073929221178407, time: 0.12108421325683594
Test Loss Energy: 7.902771148347773, Test Loss Force: 6.539755004113376, time: 8.522639513015747

Epoch 2, Batch 100/143, Loss: 0.210160031914711, Uncertainty: 0.12838852405548096

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.0828846663815, Training Loss Force: 1.9400611251555337, time: 2.095252275466919
Validation Loss Energy: 4.8196828672650005, Validation Loss Force: 2.0000508606863714, time: 0.12405252456665039
Test Loss Energy: 12.775099825567347, Test Loss Force: 6.667346234062534, time: 8.835655689239502

Epoch 3, Batch 100/143, Loss: 0.047818683087825775, Uncertainty: 0.12868580222129822

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3735480261173145, Training Loss Force: 1.9046227528870483, time: 2.1484484672546387
Validation Loss Energy: 1.3543509375033942, Validation Loss Force: 2.0402958594522134, time: 0.12415122985839844
Test Loss Energy: 9.874124330620692, Test Loss Force: 6.726932376268877, time: 8.462873697280884

Epoch 4, Batch 100/143, Loss: 0.04393504559993744, Uncertainty: 0.12646004557609558

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4549925626824933, Training Loss Force: 1.8828442241376893, time: 2.1006431579589844
Validation Loss Energy: 1.4140987845305648, Validation Loss Force: 2.0593278366929533, time: 0.12254738807678223
Test Loss Energy: 8.368512168706419, Test Loss Force: 6.604318424272168, time: 8.436363697052002

Epoch 5, Batch 100/143, Loss: 0.05535305663943291, Uncertainty: 0.12733405828475952

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.637202981331858, Training Loss Force: 1.912757270983544, time: 2.1011414527893066
Validation Loss Energy: 3.100108512149875, Validation Loss Force: 2.0592092282612224, time: 0.13510465621948242
Test Loss Energy: 8.166633489378993, Test Loss Force: 6.67462548663011, time: 8.60970425605774

Epoch 6, Batch 100/143, Loss: 0.0570792555809021, Uncertainty: 0.12709224224090576

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.904814596759689, Training Loss Force: 1.9060443739278996, time: 2.181241512298584
Validation Loss Energy: 3.0829255052738715, Validation Loss Force: 1.9134835912664034, time: 0.12702202796936035
Test Loss Energy: 8.094431682797032, Test Loss Force: 6.534709545101603, time: 8.506534337997437

Epoch 7, Batch 100/143, Loss: 0.15080344676971436, Uncertainty: 0.12472358345985413

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7901141885177698, Training Loss Force: 1.890750202719865, time: 2.1433098316192627
Validation Loss Energy: 1.1365719400238994, Validation Loss Force: 2.017779258523801, time: 0.1210777759552002
Test Loss Energy: 9.498211447885891, Test Loss Force: 6.750484000900709, time: 8.505539894104004

Epoch 8, Batch 100/143, Loss: 0.044670507311820984, Uncertainty: 0.1262616515159607

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.521249769907775, Training Loss Force: 1.8958909473849408, time: 2.2881460189819336
Validation Loss Energy: 1.972742122845398, Validation Loss Force: 2.1313150644412886, time: 0.13259673118591309
Test Loss Energy: 8.067305019923415, Test Loss Force: 6.596688221814468, time: 9.090030908584595

Epoch 9, Batch 100/143, Loss: 0.049918271601200104, Uncertainty: 0.12667718529701233

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.967142504433175, Training Loss Force: 1.9048311930074135, time: 2.1310677528381348
Validation Loss Energy: 2.7505293091696905, Validation Loss Force: 1.9098289967973392, time: 0.12330102920532227
Test Loss Energy: 7.942534411159952, Test Loss Force: 6.533832032811065, time: 8.489710569381714

Epoch 10, Batch 100/143, Loss: 0.10868129134178162, Uncertainty: 0.12684577703475952

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.4522602250174501, Training Loss Force: 1.8932942311903187, time: 2.139683246612549
Validation Loss Energy: 2.1519367509378555, Validation Loss Force: 2.155660447065206, time: 0.12408781051635742
Test Loss Energy: 8.131083649089321, Test Loss Force: 6.5858227136097005, time: 8.645528078079224

Epoch 11, Batch 100/143, Loss: 0.17096906900405884, Uncertainty: 0.12648648023605347

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8303046508605376, Training Loss Force: 1.9005722025889427, time: 2.1183927059173584
Validation Loss Energy: 1.7837520934659559, Validation Loss Force: 1.9890441763570632, time: 0.12096428871154785
Test Loss Energy: 8.111752831201834, Test Loss Force: 6.625618742594736, time: 8.453330516815186

Epoch 12, Batch 100/143, Loss: 0.07703765481710434, Uncertainty: 0.12633083760738373

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0250752396520877, Training Loss Force: 1.8667786826300452, time: 2.1027510166168213
Validation Loss Energy: 3.4947547626970654, Validation Loss Force: 1.9374174813086462, time: 0.12143731117248535
Test Loss Energy: 7.849433020769669, Test Loss Force: 6.477707689344828, time: 8.410655736923218

Epoch 13, Batch 100/143, Loss: 0.10284236818552017, Uncertainty: 0.12386724352836609

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.884492046277547, Training Loss Force: 1.8902968024035132, time: 2.181788682937622
Validation Loss Energy: 4.633613255068973, Validation Loss Force: 2.129592941266683, time: 0.14027619361877441
Test Loss Energy: 7.913644343884205, Test Loss Force: 6.659763440314196, time: 8.628051042556763

Epoch 14, Batch 100/143, Loss: 0.17588558793067932, Uncertainty: 0.12729406356811523

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9362460019332848, Training Loss Force: 1.938123043273353, time: 2.059936046600342
Validation Loss Energy: 4.531896950086479, Validation Loss Force: 2.1212383949114724, time: 0.13037538528442383
Test Loss Energy: 12.483027224997088, Test Loss Force: 6.570925870285055, time: 8.455472946166992

Epoch 15, Batch 100/143, Loss: 0.13918007910251617, Uncertainty: 0.12749193608760834

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0659303845774373, Training Loss Force: 1.9491577078753504, time: 2.1313281059265137
Validation Loss Energy: 3.8230677262262716, Validation Loss Force: 2.01279414168477, time: 0.11985063552856445
Test Loss Energy: 11.538464414188038, Test Loss Force: 6.707457574216274, time: 8.41494631767273

Epoch 16, Batch 100/143, Loss: 0.21502640843391418, Uncertainty: 0.13116399943828583

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 3.0836519982680546, Training Loss Force: 2.0552260597747485, time: 2.168423652648926
Validation Loss Energy: 1.6006675096171887, Validation Loss Force: 2.2000116875511027, time: 0.12297821044921875
Test Loss Energy: 8.199660399643966, Test Loss Force: 6.803377841744913, time: 8.612975120544434

Epoch 17, Batch 100/143, Loss: 0.17659875750541687, Uncertainty: 0.126485213637352

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2166709720542643, Training Loss Force: 1.9120833051996982, time: 2.150542736053467
Validation Loss Energy: 1.9266744001365925, Validation Loss Force: 2.0008275306673675, time: 0.12053346633911133
Test Loss Energy: 10.448323663450424, Test Loss Force: 6.593982535213895, time: 8.456616640090942

Epoch 18, Batch 100/143, Loss: 0.11196506768465042, Uncertainty: 0.12648731470108032

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8836609438116962, Training Loss Force: 1.896066655919418, time: 2.187126874923706
Validation Loss Energy: 0.9606313802742683, Validation Loss Force: 2.1567097383038667, time: 0.12101483345031738
Test Loss Energy: 8.868705900001117, Test Loss Force: 6.56562297076638, time: 8.457860708236694

Epoch 19, Batch 100/143, Loss: 0.10780701041221619, Uncertainty: 0.12539175152778625

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.611996468477294, Training Loss Force: 1.8788152548397798, time: 2.0919361114501953
Validation Loss Energy: 0.7807090137456324, Validation Loss Force: 1.9802506748921804, time: 0.12474513053894043
Test Loss Energy: 8.82874751373191, Test Loss Force: 6.630524129889841, time: 8.619152307510376

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.057 MB uploadedwandb: | 0.039 MB of 0.057 MB uploadedwandb: / 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–„â–‚â–â–â–ƒâ–â–â–â–â–â–â–ˆâ–†â–â–…â–‚â–‚
wandb:   test_error_force â–†â–‚â–…â–†â–„â–…â–‚â–‡â–„â–‚â–ƒâ–„â–â–…â–ƒâ–†â–ˆâ–ƒâ–ƒâ–„
wandb:          test_loss â–„â–â–‡â–‡â–„â–ƒâ–‚â–ˆâ–„â–â–„â–ƒâ–‚â–…â–‡â–ˆâ–‚â–„â–„â–†
wandb: train_error_energy â–‡â–„â–„â–…â–â–‚â–ƒâ–‚â–â–ƒâ–â–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–„â–ƒâ–‚
wandb:  train_error_force â–…â–ƒâ–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–„â–„â–ˆâ–ƒâ–‚â–
wandb:         train_loss â–†â–ƒâ–ƒâ–ƒâ–â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–ƒâ–„â–ˆâ–ƒâ–‚â–
wandb: valid_error_energy â–ƒâ–†â–ˆâ–‚â–‚â–…â–…â–‚â–ƒâ–„â–ƒâ–ƒâ–†â–ˆâ–ˆâ–†â–‚â–ƒâ–â–
wandb:  valid_error_force â–†â–â–ƒâ–„â–…â–…â–â–„â–†â–â–‡â–ƒâ–‚â–†â–†â–„â–ˆâ–ƒâ–‡â–ƒ
wandb:         valid_loss â–…â–ƒâ–…â–ƒâ–ƒâ–…â–‚â–‚â–…â–‚â–†â–‚â–ƒâ–ˆâ–ˆâ–…â–†â–ƒâ–…â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4545
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.82875
wandb:   test_error_force 6.63052
wandb:          test_loss 4.15593
wandb: train_error_energy 1.612
wandb:  train_error_force 1.87882
wandb:         train_loss -2.57609
wandb: valid_error_energy 0.78071
wandb:  valid_error_force 1.98025
wandb:         valid_loss -2.49549
wandb: 
wandb: ğŸš€ View run al_58_64 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/lq1xwoau
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_190101-lq1xwoau/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.76065444946289, Uncertainty Bias: -4.828807830810547
3.0517578e-05 0.0028982162
-0.046044417 10.973128
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 1161 steps.
Found uncertainty sample 14 after 1528 steps.
Found uncertainty sample 15 after 3462 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3387 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2265 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2924 steps.
Found uncertainty sample 23 after 2359 steps.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3852 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3421 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3337 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1558 steps.
Found uncertainty sample 38 after 3787 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 3225 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3813 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 2366 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3137 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1759 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3381 steps.
Found uncertainty sample 64 after 1 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 862 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1092 steps.
Found uncertainty sample 79 after 3144 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 952 steps.
Found uncertainty sample 82 after 2456 steps.
Found uncertainty sample 83 after 467 steps.
Found uncertainty sample 84 after 579 steps.
Found uncertainty sample 85 after 3838 steps.
Found uncertainty sample 86 after 3831 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1748 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3821 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2605 steps.
Found uncertainty sample 97 after 3332 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_193832-miev17v0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_65
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/miev17v0
Training model 65. Added 33 samples to the dataset.
Epoch 0, Batch 100/143, Loss: 0.25572746992111206, Uncertainty: 0.12924829125404358

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6681569363597606, Training Loss Force: 2.0657652068921486, time: 2.182171583175659
Validation Loss Energy: 1.7251617548823661, Validation Loss Force: 2.0645887663807407, time: 0.12115144729614258
Test Loss Energy: 8.08135990574083, Test Loss Force: 6.617747803313498, time: 8.548554420471191

Epoch 1, Batch 100/143, Loss: 0.20968669652938843, Uncertainty: 0.1271992325782776

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.267990428189178, Training Loss Force: 1.9319299657817492, time: 2.066197156906128
Validation Loss Energy: 2.794124513682114, Validation Loss Force: 2.1846668886977807, time: 0.1349039077758789
Test Loss Energy: 7.801518826797833, Test Loss Force: 6.5876024579633965, time: 8.599006414413452

Epoch 2, Batch 100/143, Loss: 0.1497645080089569, Uncertainty: 0.12779782712459564

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8059697545779314, Training Loss Force: 1.91447677662784, time: 2.10508394241333
Validation Loss Energy: 0.916712748827385, Validation Loss Force: 2.024506909875815, time: 0.12539124488830566
Test Loss Energy: 8.731813054694571, Test Loss Force: 6.549069720810353, time: 8.73365044593811

Epoch 3, Batch 100/143, Loss: 0.1661166399717331, Uncertainty: 0.12565892934799194

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7289131354282965, Training Loss Force: 1.882891824728294, time: 2.064723491668701
Validation Loss Energy: 2.091311142137437, Validation Loss Force: 1.9125906137681845, time: 0.12197542190551758
Test Loss Energy: 10.327386356495426, Test Loss Force: 6.494138000284547, time: 8.593108415603638

Epoch 4, Batch 100/143, Loss: 0.11631697416305542, Uncertainty: 0.1255195438861847

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8043177573915878, Training Loss Force: 1.8889791810893886, time: 2.126753568649292
Validation Loss Energy: 1.0712781839136778, Validation Loss Force: 1.8584331354302008, time: 0.12316298484802246
Test Loss Energy: 8.354793664854268, Test Loss Force: 6.483305197630671, time: 8.522559881210327

Epoch 5, Batch 100/143, Loss: 0.1647961437702179, Uncertainty: 0.12605299055576324

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.129929828654823, Training Loss Force: 1.8872477517458979, time: 2.049219846725464
Validation Loss Energy: 2.0171692935100567, Validation Loss Force: 1.9027739475777636, time: 0.1219017505645752
Test Loss Energy: 9.95732118056, Test Loss Force: 6.589121003248273, time: 8.701528072357178

Epoch 6, Batch 100/143, Loss: 0.21620675921440125, Uncertainty: 0.126027911901474

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8547586918753296, Training Loss Force: 1.8912941523008289, time: 2.066343069076538
Validation Loss Energy: 2.269858471022683, Validation Loss Force: 1.8626790649278007, time: 0.12186551094055176
Test Loss Energy: 10.532471205720206, Test Loss Force: 6.574244123203496, time: 8.61597466468811

Epoch 7, Batch 100/143, Loss: 0.41630446910858154, Uncertainty: 0.12424362450838089

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.736207281867366, Training Loss Force: 1.8929096667825958, time: 2.1295533180236816
Validation Loss Energy: 0.8492753011820303, Validation Loss Force: 1.9356286687248356, time: 0.12282061576843262
Test Loss Energy: 8.948065209257535, Test Loss Force: 6.46284549846884, time: 8.558658361434937

Epoch 8, Batch 100/143, Loss: 0.08832528442144394, Uncertainty: 0.13327857851982117

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.816039018018501, Training Loss Force: 2.0055204905347144, time: 2.293994188308716
Validation Loss Energy: 3.02590565217651, Validation Loss Force: 1.9829094929406554, time: 0.12706661224365234
Test Loss Energy: 10.807769843412734, Test Loss Force: 6.639291556137112, time: 8.618206977844238

Epoch 9, Batch 100/143, Loss: 0.1493728756904602, Uncertainty: 0.12761816382408142

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1421026362322566, Training Loss Force: 1.9603432495092377, time: 2.1394474506378174
Validation Loss Energy: 1.5804586888286958, Validation Loss Force: 2.0370471166131274, time: 0.12257719039916992
Test Loss Energy: 9.197764239752763, Test Loss Force: 6.593245064329037, time: 8.608595371246338

Epoch 10, Batch 100/143, Loss: 0.1930324137210846, Uncertainty: 0.1269935965538025

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8190937428509744, Training Loss Force: 1.8907080357235593, time: 2.116518259048462
Validation Loss Energy: 1.0768760120192538, Validation Loss Force: 1.9953995248970855, time: 0.12303495407104492
Test Loss Energy: 8.361643310530278, Test Loss Force: 6.61006621441279, time: 9.418923616409302

Epoch 11, Batch 100/143, Loss: 0.19451899826526642, Uncertainty: 0.12580373883247375

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.879114709027134, Training Loss Force: 1.8971467258473191, time: 2.150075912475586
Validation Loss Energy: 0.7696711557358947, Validation Loss Force: 1.920948871275827, time: 0.12226748466491699
Test Loss Energy: 8.433675102807385, Test Loss Force: 6.5942679527583055, time: 8.573467254638672

Epoch 12, Batch 100/143, Loss: 0.08682204782962799, Uncertainty: 0.12839238345623016

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6252675164856436, Training Loss Force: 1.8894071714305116, time: 2.036738395690918
Validation Loss Energy: 2.0812028535889, Validation Loss Force: 1.9482084363470744, time: 0.1289808750152588
Test Loss Energy: 10.04676112309019, Test Loss Force: 6.52949506272097, time: 8.64544129371643

Epoch 13, Batch 100/143, Loss: 0.14227423071861267, Uncertainty: 0.12688405811786652

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.010142449178725, Training Loss Force: 1.9034955463923573, time: 2.1185317039489746
Validation Loss Energy: 2.47481072368558, Validation Loss Force: 1.8929159391492483, time: 0.1317613124847412
Test Loss Energy: 7.81936299821286, Test Loss Force: 6.527537108438877, time: 8.757358074188232

Epoch 14, Batch 100/143, Loss: 0.044431447982788086, Uncertainty: 0.12426644563674927

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.4082799688463468, Training Loss Force: 1.84922106709664, time: 2.1016199588775635
Validation Loss Energy: 0.7679330560500689, Validation Loss Force: 1.8847916698024516, time: 0.1261746883392334
Test Loss Energy: 8.499063030673529, Test Loss Force: 6.521836939184499, time: 8.653719425201416

Epoch 15, Batch 100/143, Loss: 0.12426877021789551, Uncertainty: 0.12567643821239471

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2572700431796977, Training Loss Force: 1.894808408632348, time: 2.1597988605499268
Validation Loss Energy: 7.156623164751228, Validation Loss Force: 1.8821083581479243, time: 0.12281346321105957
Test Loss Energy: 14.85847158311463, Test Loss Force: 6.490293987040937, time: 8.573558330535889

Epoch 16, Batch 100/143, Loss: 0.05795145779848099, Uncertainty: 0.12514998018741608

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.528603863007314, Training Loss Force: 1.8820257141570353, time: 2.130765914916992
Validation Loss Energy: 1.768034064012535, Validation Loss Force: 1.9650047411396507, time: 0.12011528015136719
Test Loss Energy: 8.008071464400286, Test Loss Force: 6.58634203867997, time: 8.79109239578247

Epoch 17, Batch 100/143, Loss: 0.2867429554462433, Uncertainty: 0.1249692291021347

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8919380285538456, Training Loss Force: 1.9039023660362209, time: 2.1298062801361084
Validation Loss Energy: 2.2310700253634024, Validation Loss Force: 1.9149332787409665, time: 0.1253376007080078
Test Loss Energy: 7.9925904258380625, Test Loss Force: 6.463182955308203, time: 8.525049686431885

Epoch 18, Batch 100/143, Loss: 0.2936897575855255, Uncertainty: 0.12457118928432465

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8307846013582885, Training Loss Force: 1.8828635364039998, time: 2.098759651184082
Validation Loss Energy: 1.244226868239812, Validation Loss Force: 1.9228867979643607, time: 0.12253808975219727
Test Loss Energy: 8.071120067525142, Test Loss Force: 6.496537170564778, time: 8.56083869934082

Epoch 19, Batch 100/143, Loss: 0.1618809551000595, Uncertainty: 0.12655377388000488

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8196064638627847, Training Loss Force: 1.882223137604621, time: 2.123483180999756
Validation Loss Energy: 1.2882205763003975, Validation Loss Force: 1.9705478668583771, time: 0.12546038627624512
Test Loss Energy: 9.358615958735164, Test Loss Force: 6.5129307212767, time: 8.732803106307983

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–‚â–„â–‚â–ƒâ–„â–‚â–„â–‚â–‚â–‚â–ƒâ–â–‚â–ˆâ–â–â–â–ƒ
wandb:   test_error_force â–‡â–†â–„â–‚â–‚â–†â–…â–â–ˆâ–†â–‡â–†â–„â–„â–ƒâ–‚â–†â–â–‚â–ƒ
wandb:          test_loss â–ƒâ–‚â–ƒâ–„â–ƒâ–†â–†â–‚â–…â–ƒâ–„â–„â–…â–ƒâ–…â–ˆâ–„â–â–ƒâ–ƒ
wandb: train_error_energy â–‡â–…â–ƒâ–ƒâ–ƒâ–…â–ƒâ–ˆâ–ˆâ–…â–ƒâ–ƒâ–‚â–„â–â–…â–‡â–ƒâ–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–†â–…â–‚â–ƒâ–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–„â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–„â–‡â–…â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–‚â–‚
wandb: valid_error_energy â–‚â–ƒâ–â–‚â–â–‚â–ƒâ–â–ƒâ–‚â–â–â–‚â–ƒâ–â–ˆâ–‚â–ƒâ–‚â–‚
wandb:  valid_error_force â–…â–ˆâ–…â–‚â–â–‚â–â–ƒâ–„â–…â–„â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒ
wandb:         valid_loss â–…â–ˆâ–„â–ƒâ–â–ƒâ–‚â–‚â–…â–„â–ƒâ–‚â–ƒâ–ƒâ–â–‡â–ƒâ–ƒâ–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4574
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.35862
wandb:   test_error_force 6.51293
wandb:          test_loss 3.96158
wandb: train_error_energy 1.81961
wandb:  train_error_force 1.88222
wandb:         train_loss -2.5576
wandb: valid_error_energy 1.28822
wandb:  valid_error_force 1.97055
wandb:         valid_loss -2.47588
wandb: 
wandb: ğŸš€ View run al_58_65 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/miev17v0
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_193832-miev17v0/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 37.78215789794922, Uncertainty Bias: -4.633784294128418
4.5776367e-05 0.0027976036
-0.18773325 17.78072
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3237 steps.
Found uncertainty sample 6 after 3155 steps.
Found uncertainty sample 7 after 3718 steps.
Found uncertainty sample 8 after 584 steps.
Found uncertainty sample 9 after 539 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2662 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 988 steps.
Found uncertainty sample 15 after 3076 steps.
Found uncertainty sample 16 after 2811 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2101 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1705 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3803 steps.
Found uncertainty sample 26 after 1934 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 451 steps.
Found uncertainty sample 30 after 2377 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 3501 steps.
Found uncertainty sample 33 after 3169 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3421 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2500 steps.
Found uncertainty sample 42 after 2319 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1654 steps.
Found uncertainty sample 45 after 2674 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2109 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2472 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 63 steps.
Found uncertainty sample 59 after 3399 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1241 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2612 steps.
Found uncertainty sample 66 after 2776 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2529 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1932 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1729 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1712 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2207 steps.
Found uncertainty sample 85 after 3431 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 3411 steps.
Found uncertainty sample 91 after 1353 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2561 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2496 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_201441-l50vla7x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_66
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/l50vla7x
Training model 66. Added 39 samples to the dataset.
Epoch 0, Batch 100/145, Loss: 0.19927671551704407, Uncertainty: 0.1290048062801361
/home/ws/fq0795/miniconda3/envs/torch/lib/python3.12/site-packages/torch/nn/modules/loss.py:101: UserWarning: Using a target size (torch.Size([1])) that is different to the input size (torch.Size([])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.l1_loss(input, target, reduction=self.reduction)

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.14262102031683, Training Loss Force: 2.0335618295249644, time: 2.172370433807373
Validation Loss Energy: 4.150749868065063, Validation Loss Force: 2.324558705403865, time: 0.1242828369140625
Test Loss Energy: 11.77386872437696, Test Loss Force: 6.743460370181044, time: 8.768478631973267

Epoch 1, Batch 100/145, Loss: 0.05918189138174057, Uncertainty: 0.12935788929462433

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7711312922711284, Training Loss Force: 1.9188347800204635, time: 2.170637845993042
Validation Loss Energy: 0.8945315989673127, Validation Loss Force: 1.9642059155786349, time: 0.12885522842407227
Test Loss Energy: 8.25509048402934, Test Loss Force: 6.487117773721457, time: 8.706676483154297

Epoch 2, Batch 100/145, Loss: 0.0617549866437912, Uncertainty: 0.12712708115577698

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6565658948078859, Training Loss Force: 1.8958310724194254, time: 2.1264474391937256
Validation Loss Energy: 1.0902148216484362, Validation Loss Force: 2.082287178106519, time: 0.12749576568603516
Test Loss Energy: 8.788824822142859, Test Loss Force: 6.5960273840900205, time: 8.922603368759155

Epoch 3, Batch 100/145, Loss: 0.1740606278181076, Uncertainty: 0.1252349615097046

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7906223034918478, Training Loss Force: 1.88277260388482, time: 2.1277129650115967
Validation Loss Energy: 3.5369470031440464, Validation Loss Force: 1.9448542225558672, time: 0.12646865844726562
Test Loss Energy: 11.503615177301176, Test Loss Force: 6.446992259685643, time: 8.754798650741577

Epoch 4, Batch 100/145, Loss: 0.20043952763080597, Uncertainty: 0.12516625225543976

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.7903573195299476, Training Loss Force: 1.8706639183069753, time: 2.1486575603485107
Validation Loss Energy: 2.104739279205661, Validation Loss Force: 1.9052607908225336, time: 0.12690448760986328
Test Loss Energy: 7.8385755216593145, Test Loss Force: 6.458640868463076, time: 8.717087745666504

Epoch 5, Batch 100/145, Loss: 0.06500281393527985, Uncertainty: 0.1266508549451828

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.067633884812386, Training Loss Force: 1.9260612875537022, time: 2.1246042251586914
Validation Loss Energy: 4.153852243052226, Validation Loss Force: 1.9866518190532154, time: 0.1282339096069336
Test Loss Energy: 7.690635987743254, Test Loss Force: 6.459761134423343, time: 8.857164144515991

Epoch 6, Batch 100/145, Loss: 0.08163948357105255, Uncertainty: 0.12446390092372894

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9206726362514897, Training Loss Force: 1.894849304959414, time: 2.1320722103118896
Validation Loss Energy: 2.451587742003236, Validation Loss Force: 1.866175118964964, time: 0.12888479232788086
Test Loss Energy: 10.11113370063543, Test Loss Force: 6.431563530885606, time: 8.73500919342041

Epoch 7, Batch 100/145, Loss: 0.07039351761341095, Uncertainty: 0.12577004730701447

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.107352571267543, Training Loss Force: 1.8863118090269608, time: 2.170701265335083
Validation Loss Energy: 1.7013713008816251, Validation Loss Force: 2.08014858940598, time: 0.12622618675231934
Test Loss Energy: 9.629599310348667, Test Loss Force: 6.473442346439685, time: 8.85452389717102

Epoch 8, Batch 100/145, Loss: 0.1192120686173439, Uncertainty: 0.12514105439186096

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6810061412704194, Training Loss Force: 1.9134743658533409, time: 2.215336799621582
Validation Loss Energy: 1.7642214115613861, Validation Loss Force: 2.0330750701650184, time: 0.12473249435424805
Test Loss Energy: 7.926809147679504, Test Loss Force: 6.455739473170336, time: 8.712818622589111

Epoch 9, Batch 100/145, Loss: 0.04621697589755058, Uncertainty: 0.12578698992729187

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.943920159272984, Training Loss Force: 1.8746599311215488, time: 2.092390775680542
Validation Loss Energy: 3.4658203916447228, Validation Loss Force: 1.973583441101762, time: 0.13000774383544922
Test Loss Energy: 7.747296040531995, Test Loss Force: 6.453462663666121, time: 8.742873430252075

Epoch 10, Batch 100/145, Loss: 0.061357252299785614, Uncertainty: 0.1263098120689392

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7709867592641557, Training Loss Force: 1.9085533070884693, time: 2.1641180515289307
Validation Loss Energy: 0.7776927560506568, Validation Loss Force: 1.9151414001693603, time: 0.13034319877624512
Test Loss Energy: 8.86079499918593, Test Loss Force: 6.47949584383056, time: 8.940036535263062

Epoch 11, Batch 100/145, Loss: 0.07484911382198334, Uncertainty: 0.1251288503408432

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8489852410821879, Training Loss Force: 1.8886428056246132, time: 2.096859931945801
Validation Loss Energy: 0.7914579399827667, Validation Loss Force: 2.1106244247325328, time: 0.12752580642700195
Test Loss Energy: 8.419271472806777, Test Loss Force: 6.543759301836227, time: 8.763823747634888

Epoch 12, Batch 100/145, Loss: 0.04905295372009277, Uncertainty: 0.1277657449245453

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3541536709309936, Training Loss Force: 1.938217932610369, time: 2.147615432739258
Validation Loss Energy: 3.6863341002399292, Validation Loss Force: 2.5202938656632763, time: 0.13579368591308594
Test Loss Energy: 11.52563997242326, Test Loss Force: 6.772977396828459, time: 8.73221492767334

Epoch 13, Batch 100/145, Loss: 0.07530111819505692, Uncertainty: 0.127628892660141

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.092654142553618, Training Loss Force: 1.9361353971561648, time: 2.1849989891052246
Validation Loss Energy: 1.0044474911352141, Validation Loss Force: 2.1095097429880183, time: 0.12689590454101562
Test Loss Energy: 8.622772062535068, Test Loss Force: 6.645009958613701, time: 8.905685424804688

Epoch 14, Batch 100/145, Loss: 0.0901571735739708, Uncertainty: 0.12658411264419556

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0574079966257246, Training Loss Force: 1.8738979427155156, time: 2.1750495433807373
Validation Loss Energy: 1.3451247156649249, Validation Loss Force: 1.9610684702009877, time: 0.1309065818786621
Test Loss Energy: 8.211839135859762, Test Loss Force: 6.515369016041416, time: 8.786814451217651

Epoch 15, Batch 100/145, Loss: 0.3587281107902527, Uncertainty: 0.12508371472358704

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2137385251688975, Training Loss Force: 1.883720501448174, time: 2.2033255100250244
Validation Loss Energy: 3.267727981583471, Validation Loss Force: 1.9744640975739063, time: 0.12442708015441895
Test Loss Energy: 11.15228809263969, Test Loss Force: 6.510298732334391, time: 8.725997686386108

Epoch 16, Batch 100/145, Loss: 0.6519272327423096, Uncertainty: 0.1259804517030716

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.9114475457937004, Training Loss Force: 1.9145631603900792, time: 2.1691575050354004
Validation Loss Energy: 1.842517375775196, Validation Loss Force: 2.283118270216585, time: 0.1278994083404541
Test Loss Energy: 9.57556934390513, Test Loss Force: 6.514754575105818, time: 8.867693424224854

Epoch 17, Batch 100/145, Loss: 0.08061368763446808, Uncertainty: 0.12356719374656677

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.565563661558737, Training Loss Force: 1.8671783161547684, time: 2.1184608936309814
Validation Loss Energy: 2.7195303497963046, Validation Loss Force: 2.0981194739433255, time: 0.12456035614013672
Test Loss Energy: 7.7198117383674205, Test Loss Force: 6.517012528846862, time: 8.782423734664917

Epoch 18, Batch 100/145, Loss: 0.0837479829788208, Uncertainty: 0.12600500881671906

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.878126397164137, Training Loss Force: 1.9071212097086103, time: 2.1218183040618896
Validation Loss Energy: 0.8553005427132145, Validation Loss Force: 1.9599646992446236, time: 0.12876558303833008
Test Loss Energy: 8.630146797031388, Test Loss Force: 6.334731711832276, time: 9.55328631401062

Epoch 19, Batch 100/145, Loss: 0.27640655636787415, Uncertainty: 0.12459669262170792

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8503795069741542, Training Loss Force: 1.879879388041053, time: 2.1305065155029297
Validation Loss Energy: 1.794427668775269, Validation Loss Force: 1.9542191672722493, time: 0.13005638122558594
Test Loss Energy: 7.801245002038695, Test Loss Force: 6.47887956791467, time: 8.77403712272644

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.060 MB uploadedwandb: | 0.039 MB of 0.060 MB uploadedwandb: / 0.039 MB of 0.060 MB uploadedwandb: - 0.060 MB of 0.060 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–‚â–ƒâ–ˆâ–â–â–…â–„â–â–â–ƒâ–‚â–ˆâ–ƒâ–‚â–‡â–„â–â–ƒâ–
wandb:   test_error_force â–ˆâ–ƒâ–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–ˆâ–†â–„â–„â–„â–„â–â–ƒ
wandb:          test_loss â–ˆâ–‚â–…â–…â–‚â–ƒâ–„â–„â–‚â–‚â–ƒâ–ƒâ–ˆâ–„â–ƒâ–†â–…â–…â–â–ƒ
wandb: train_error_energy â–ˆâ–‚â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–…â–ƒâ–ƒâ–„â–‡â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–â–ƒâ–‚â–„â–„â–â–‚â–ƒâ–â–ƒâ–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–„â–„â–‚â–‚â–„â–â–ƒâ–‚
wandb: valid_error_energy â–ˆâ–â–‚â–‡â–„â–ˆâ–„â–ƒâ–ƒâ–‡â–â–â–‡â–â–‚â–†â–ƒâ–…â–â–ƒ
wandb:  valid_error_force â–†â–‚â–ƒâ–‚â–â–‚â–â–ƒâ–ƒâ–‚â–‚â–„â–ˆâ–„â–‚â–‚â–…â–ƒâ–‚â–‚
wandb:         valid_loss â–†â–‚â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–ƒâ–â–ƒâ–ˆâ–ƒâ–‚â–ƒâ–…â–„â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4609
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.80125
wandb:   test_error_force 6.47888
wandb:          test_loss 3.87634
wandb: train_error_energy 1.85038
wandb:  train_error_force 1.87988
wandb:         train_loss -2.55866
wandb: valid_error_energy 1.79443
wandb:  valid_error_force 1.95422
wandb:         valid_loss -2.4626
wandb: 
wandb: ğŸš€ View run al_58_66 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/l50vla7x
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_201441-l50vla7x/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.682796478271484, Uncertainty Bias: -4.949695110321045
2.5749207e-05 0.005464554
-0.27585322 13.66394
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 885 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2614 steps.
Found uncertainty sample 3 after 3147 steps.
Found uncertainty sample 4 after 2801 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 3890 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 575 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3502 steps.
Found uncertainty sample 12 after 3408 steps.
Found uncertainty sample 13 after 647 steps.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2187 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 2967 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 1093 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1228 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1903 steps.
Found uncertainty sample 30 after 2914 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 791 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1747 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 721 steps.
Found uncertainty sample 40 after 1510 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3806 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 393 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1167 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1383 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 1043 steps.
Found uncertainty sample 63 after 2712 steps.
Found uncertainty sample 64 after 1640 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2743 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3829 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2906 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1028 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1558 steps.
Found uncertainty sample 89 after 3916 steps.
Found uncertainty sample 90 after 2892 steps.
Found uncertainty sample 91 after 2911 steps.
Found uncertainty sample 92 after 1742 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2573 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2004 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_205037-at3l1wjh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_67
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/at3l1wjh
Training model 67. Added 37 samples to the dataset.
Epoch 0, Batch 100/146, Loss: 0.16412362456321716, Uncertainty: 0.12859277427196503

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.784479042826293, Training Loss Force: 2.054015061951501, time: 2.1238908767700195
Validation Loss Energy: 1.5827817218051117, Validation Loss Force: 2.1104331519361805, time: 0.12397980690002441
Test Loss Energy: 9.485226558428886, Test Loss Force: 6.451798632656653, time: 8.734503030776978

Epoch 1, Batch 100/146, Loss: 0.15354615449905396, Uncertainty: 0.12654776871204376

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.108814183166594, Training Loss Force: 1.8867494890305874, time: 2.154245615005493
Validation Loss Energy: 3.861921117053113, Validation Loss Force: 1.9748676111778518, time: 0.12517738342285156
Test Loss Energy: 7.656383658054011, Test Loss Force: 6.454491945381233, time: 8.72925329208374

Epoch 2, Batch 100/146, Loss: 0.310779869556427, Uncertainty: 0.12713947892189026

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.675582777842258, Training Loss Force: 1.9468201699703946, time: 2.144352436065674
Validation Loss Energy: 0.8396809886895801, Validation Loss Force: 2.050390787851996, time: 0.12412452697753906
Test Loss Energy: 8.597666827474011, Test Loss Force: 6.506892810726036, time: 8.864356279373169

Epoch 3, Batch 100/146, Loss: 0.05443692207336426, Uncertainty: 0.12545108795166016

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.633675722810338, Training Loss Force: 1.8785877688177908, time: 2.208695650100708
Validation Loss Energy: 0.9916995340847511, Validation Loss Force: 2.105464735283094, time: 0.12597203254699707
Test Loss Energy: 8.191605071656985, Test Loss Force: 6.455155919126634, time: 8.647783041000366

Epoch 4, Batch 100/146, Loss: 0.0637076273560524, Uncertainty: 0.12563133239746094

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8631972545399358, Training Loss Force: 1.9333445237963258, time: 2.1877565383911133
Validation Loss Energy: 1.2505805838727644, Validation Loss Force: 2.17524501490309, time: 0.1283891201019287
Test Loss Energy: 8.846031838955335, Test Loss Force: 6.555844374782275, time: 8.731135606765747

Epoch 5, Batch 100/146, Loss: 0.06779545545578003, Uncertainty: 0.12899041175842285

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.5681589829434648, Training Loss Force: 1.9147238027419349, time: 2.1555016040802
Validation Loss Energy: 1.6988355446477996, Validation Loss Force: 2.086937771665318, time: 0.13594746589660645
Test Loss Energy: 8.016876844661772, Test Loss Force: 6.523138756276156, time: 8.878482341766357

Epoch 6, Batch 100/146, Loss: 0.1577519178390503, Uncertainty: 0.12789879739284515

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9293431051018486, Training Loss Force: 1.9103359203928636, time: 2.114870548248291
Validation Loss Energy: 2.4976675630689704, Validation Loss Force: 1.9284147450696398, time: 0.1252143383026123
Test Loss Energy: 7.613961210352738, Test Loss Force: 6.437645054277888, time: 8.705066204071045

Epoch 7, Batch 100/146, Loss: 0.14574524760246277, Uncertainty: 0.12522774934768677

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.824538325050275, Training Loss Force: 1.899389053740237, time: 2.2024831771850586
Validation Loss Energy: 2.692712968537346, Validation Loss Force: 2.0171882203874603, time: 0.12501311302185059
Test Loss Energy: 10.107150986664243, Test Loss Force: 6.465934196984934, time: 8.828920364379883

Epoch 8, Batch 100/146, Loss: 0.05406900867819786, Uncertainty: 0.125565767288208

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9745403465050753, Training Loss Force: 1.8845140707709462, time: 2.108694314956665
Validation Loss Energy: 0.7853701098658146, Validation Loss Force: 1.9328192149991403, time: 0.12649130821228027
Test Loss Energy: 8.492948701470953, Test Loss Force: 6.357229570469402, time: 9.38517689704895

Epoch 9, Batch 100/146, Loss: 0.1239088773727417, Uncertainty: 0.12617148458957672

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1953585631642767, Training Loss Force: 1.895974412474082, time: 2.1091208457946777
Validation Loss Energy: 0.7996342211308999, Validation Loss Force: 2.103801916324354, time: 0.13273310661315918
Test Loss Energy: 8.420783785687178, Test Loss Force: 6.463467617409648, time: 8.734502792358398

Epoch 10, Batch 100/146, Loss: 0.11016847938299179, Uncertainty: 0.12472376972436905

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7990326564647878, Training Loss Force: 1.883423158195194, time: 2.1423752307891846
Validation Loss Energy: 2.9197940809225464, Validation Loss Force: 1.9359181386145419, time: 0.12711024284362793
Test Loss Energy: 7.683120255879475, Test Loss Force: 6.404446625816969, time: 8.960480690002441

Epoch 11, Batch 100/146, Loss: 0.06527823954820633, Uncertainty: 0.12497305124998093

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6128358499842033, Training Loss Force: 1.8583602534802037, time: 2.1231236457824707
Validation Loss Energy: 1.8717729841820645, Validation Loss Force: 1.9475501892401876, time: 0.1514737606048584
Test Loss Energy: 7.766013030698389, Test Loss Force: 6.4204131833767235, time: 8.694067001342773

Epoch 12, Batch 100/146, Loss: 0.16667190194129944, Uncertainty: 0.12734180688858032

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9605287787817134, Training Loss Force: 1.8905813039919002, time: 2.1668612957000732
Validation Loss Energy: 1.4230228072264859, Validation Loss Force: 1.9772608220467596, time: 0.12812352180480957
Test Loss Energy: 7.9299334942434765, Test Loss Force: 6.418131608053298, time: 8.709294080734253

Epoch 13, Batch 100/146, Loss: 0.11795219033956528, Uncertainty: 0.12557744979858398

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9573011746414615, Training Loss Force: 1.879690841264094, time: 2.1206040382385254
Validation Loss Energy: 1.3246571162173397, Validation Loss Force: 1.9190484272268578, time: 0.12389731407165527
Test Loss Energy: 9.040197858292643, Test Loss Force: 6.39912214720986, time: 8.870660305023193

Epoch 14, Batch 100/146, Loss: 0.0546705387532711, Uncertainty: 0.12466345727443695

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.852626934376688, Training Loss Force: 1.8675755693601053, time: 2.1352341175079346
Validation Loss Energy: 2.5334059609903803, Validation Loss Force: 2.0073523304274405, time: 0.12535333633422852
Test Loss Energy: 10.391550958726755, Test Loss Force: 6.367955508254532, time: 8.707226514816284

Epoch 15, Batch 100/146, Loss: 0.1473802626132965, Uncertainty: 0.125101238489151

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2454075837666645, Training Loss Force: 1.8826176678111113, time: 2.1451239585876465
Validation Loss Energy: 1.0913576339283864, Validation Loss Force: 1.906581627084653, time: 0.1256237030029297
Test Loss Energy: 8.061827095461199, Test Loss Force: 6.415823177198745, time: 8.709877729415894

Epoch 16, Batch 100/146, Loss: 0.053860507905483246, Uncertainty: 0.12478633224964142

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8747763723121336, Training Loss Force: 1.8910840718592656, time: 2.1512038707733154
Validation Loss Energy: 0.9623282490565731, Validation Loss Force: 2.043474164618138, time: 0.18860554695129395
Test Loss Energy: 8.430893732013336, Test Loss Force: 6.336236976243277, time: 8.879222631454468

Epoch 17, Batch 100/146, Loss: 0.2958090305328369, Uncertainty: 0.12592312693595886

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.7252567544111983, Training Loss Force: 1.888714824867529, time: 2.1514458656311035
Validation Loss Energy: 2.157634409043856, Validation Loss Force: 1.9980258332502554, time: 0.12585139274597168
Test Loss Energy: 7.621222427885303, Test Loss Force: 6.367612833262826, time: 8.740204572677612

Epoch 18, Batch 100/146, Loss: 0.09118160605430603, Uncertainty: 0.12817901372909546

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9155411666531976, Training Loss Force: 1.904280326972743, time: 2.215834856033325
Validation Loss Energy: 1.4018396975899863, Validation Loss Force: 1.9998256679567896, time: 0.12537837028503418
Test Loss Energy: 9.296082437142932, Test Loss Force: 6.447206812482912, time: 8.857976913452148

Epoch 19, Batch 100/146, Loss: 0.11728819459676743, Uncertainty: 0.12604697048664093

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8008181038467461, Training Loss Force: 1.8721322189079128, time: 2.1648950576782227
Validation Loss Energy: 1.1159498453005647, Validation Loss Force: 1.9070540939007874, time: 0.12854766845703125
Test Loss Energy: 8.914522886370744, Test Loss Force: 6.349096795588692, time: 8.729939460754395

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–ƒâ–‚â–„â–‚â–â–‡â–ƒâ–ƒâ–â–â–‚â–…â–ˆâ–‚â–ƒâ–â–…â–„
wandb:   test_error_force â–…â–…â–†â–…â–ˆâ–‡â–„â–…â–‚â–…â–ƒâ–„â–„â–ƒâ–‚â–„â–â–‚â–…â–
wandb:          test_loss â–…â–„â–…â–„â–‡â–…â–ƒâ–ˆâ–‚â–…â–„â–†â–„â–†â–ˆâ–„â–â–ƒâ–ˆâ–…
wandb: train_error_energy â–ˆâ–„â–‡â–‡â–ƒâ–â–ƒâ–‚â–ƒâ–…â–‚â–â–ƒâ–ƒâ–ƒâ–…â–ƒâ–‚â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–„â–‚â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‚â–ƒâ–
wandb:         train_loss â–ˆâ–‚â–…â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–‚
wandb: valid_error_energy â–ƒâ–ˆâ–â–â–‚â–ƒâ–…â–…â–â–â–†â–ƒâ–‚â–‚â–…â–‚â–â–„â–‚â–‚
wandb:  valid_error_force â–†â–ƒâ–…â–†â–ˆâ–†â–‚â–„â–‚â–†â–‚â–‚â–ƒâ–â–„â–â–…â–ƒâ–ƒâ–
wandb:         valid_loss â–‡â–†â–„â–†â–ˆâ–†â–ƒâ–†â–â–†â–„â–ƒâ–ƒâ–‚â–…â–â–„â–…â–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 4642
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.91452
wandb:   test_error_force 6.3491
wandb:          test_loss 3.83194
wandb: train_error_energy 1.80082
wandb:  train_error_force 1.87213
wandb:         train_loss -2.57249
wandb: valid_error_energy 1.11595
wandb:  valid_error_force 1.90705
wandb:         valid_loss -2.57072
wandb: 
wandb: ğŸš€ View run al_58_67 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/at3l1wjh
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_205037-at3l1wjh/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.0203971862793, Uncertainty Bias: -5.078526020050049
3.1471252e-05 0.0026817322
-0.23015083 14.469689
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 874 steps.
Found uncertainty sample 1 after 1186 steps.
Found uncertainty sample 2 after 1769 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3299 steps.
Found uncertainty sample 8 after 2557 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 352 steps.
Found uncertainty sample 11 after 983 steps.
Found uncertainty sample 12 after 2594 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2742 steps.
Found uncertainty sample 16 after 1790 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 1839 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3679 steps.
Found uncertainty sample 24 after 1889 steps.
Found uncertainty sample 25 after 2132 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1340 steps.
Found uncertainty sample 31 after 2355 steps.
Found uncertainty sample 32 after 2794 steps.
Found uncertainty sample 33 after 3882 steps.
Found uncertainty sample 34 after 3610 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1473 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2705 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3586 steps.
Found uncertainty sample 45 after 2300 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2555 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 98 steps.
Found uncertainty sample 55 after 3934 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2086 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2193 steps.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3229 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2329 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2443 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2199 steps.
Found uncertainty sample 80 after 1957 steps.
Found uncertainty sample 81 after 1133 steps.
Found uncertainty sample 82 after 884 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 107 steps.
Found uncertainty sample 86 after 2799 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2128 steps.
Found uncertainty sample 89 after 114 steps.
Found uncertainty sample 90 after 3502 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2991 steps.
Found uncertainty sample 94 after 3900 steps.
Found uncertainty sample 95 after 2072 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2496 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_212615-cvouj0jb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_68
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cvouj0jb
Training model 68. Added 44 samples to the dataset.
Epoch 0, Batch 100/147, Loss: 0.11227497458457947, Uncertainty: 0.12831628322601318

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7274951876559284, Training Loss Force: 2.0162168694088987, time: 2.343140125274658
Validation Loss Energy: 2.4666939879782204, Validation Loss Force: 1.9637649193351248, time: 0.15645170211791992
Test Loss Energy: 7.563236770877923, Test Loss Force: 6.462876800388044, time: 11.260504722595215

Epoch 1, Batch 100/147, Loss: 0.2558712363243103, Uncertainty: 0.1282387375831604

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.743754193314137, Training Loss Force: 1.9967989232266805, time: 2.3672707080841064
Validation Loss Energy: 1.6879316592408615, Validation Loss Force: 1.9725198990377624, time: 0.154038667678833
Test Loss Energy: 7.715093306885173, Test Loss Force: 6.389409216473468, time: 11.515436887741089

Epoch 2, Batch 100/147, Loss: 0.0848829597234726, Uncertainty: 0.12664549052715302

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.136594865717882, Training Loss Force: 1.8838516098979177, time: 2.4830691814422607
Validation Loss Energy: 0.8425613625382534, Validation Loss Force: 2.016798178266843, time: 0.15918707847595215
Test Loss Energy: 8.550703325832652, Test Loss Force: 6.37734705163589, time: 11.30471396446228

Epoch 3, Batch 100/147, Loss: 0.0887121707201004, Uncertainty: 0.12813448905944824

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.5077510180882239, Training Loss Force: 1.8996669972698161, time: 2.3066341876983643
Validation Loss Energy: 2.2488098535503234, Validation Loss Force: 2.209580671428204, time: 0.1596238613128662
Test Loss Energy: 7.421064454111113, Test Loss Force: 6.617122147314108, time: 11.32824993133545

Epoch 4, Batch 100/147, Loss: 0.05613890290260315, Uncertainty: 0.12487642467021942

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.817097676627177, Training Loss Force: 1.89114615871839, time: 2.3322677612304688
Validation Loss Energy: 1.199879153348726, Validation Loss Force: 2.1754071922643736, time: 0.15794038772583008
Test Loss Energy: 8.641057240102965, Test Loss Force: 6.480703556977405, time: 11.475098133087158

Epoch 5, Batch 100/147, Loss: 0.16784557700157166, Uncertainty: 0.1260424256324768

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.1303077925366964, Training Loss Force: 1.8968739104837238, time: 2.30119252204895
Validation Loss Energy: 4.888048529800916, Validation Loss Force: 2.0789984290442143, time: 0.15688586235046387
Test Loss Energy: 7.48452801925941, Test Loss Force: 6.323179869702952, time: 11.31602168083191

Epoch 6, Batch 100/147, Loss: 0.09442946314811707, Uncertainty: 0.12586992979049683

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.7473994153693757, Training Loss Force: 1.8828228587519016, time: 2.249561309814453
Validation Loss Energy: 2.9055876409662567, Validation Loss Force: 1.9582758651073346, time: 0.1584339141845703
Test Loss Energy: 7.530466818475736, Test Loss Force: 6.361684676450772, time: 11.418985366821289

Epoch 7, Batch 100/147, Loss: 0.24995657801628113, Uncertainty: 0.12523722648620605

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9840865693821577, Training Loss Force: 1.877442178506288, time: 2.2586960792541504
Validation Loss Energy: 1.0026056090716238, Validation Loss Force: 1.9392583984726042, time: 0.14853930473327637
Test Loss Energy: 8.460847873349701, Test Loss Force: 6.385261680702011, time: 11.40827465057373

Epoch 8, Batch 100/147, Loss: 0.15684601664543152, Uncertainty: 0.12458456307649612

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8225213804901497, Training Loss Force: 1.8700507087744713, time: 2.4690041542053223
Validation Loss Energy: 0.7791892040458644, Validation Loss Force: 1.9674739935218926, time: 0.1557455062866211
Test Loss Energy: 8.328916054645372, Test Loss Force: 6.43102161247477, time: 11.153634786605835

Epoch 9, Batch 100/147, Loss: 0.07922659069299698, Uncertainty: 0.12646377086639404

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8827099904883915, Training Loss Force: 1.9061361342876755, time: 2.24678897857666
Validation Loss Energy: 0.7732352723086636, Validation Loss Force: 2.0710478787427653, time: 0.1609787940979004
Test Loss Energy: 7.986617518356713, Test Loss Force: 6.325259844345398, time: 10.93305230140686

Epoch 10, Batch 100/147, Loss: 0.03347963094711304, Uncertainty: 0.12367149442434311

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.7750139979921287, Training Loss Force: 1.8628468211357816, time: 2.2127902507781982
Validation Loss Energy: 3.9595726709997443, Validation Loss Force: 2.0307127731958707, time: 0.13454818725585938
Test Loss Energy: 11.442594057190684, Test Loss Force: 6.326410843311032, time: 9.060491561889648

Epoch 11, Batch 100/147, Loss: 0.06748540699481964, Uncertainty: 0.1263732761144638

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0017583551039912, Training Loss Force: 1.944986361546414, time: 2.4250519275665283
Validation Loss Energy: 2.4393923755499167, Validation Loss Force: 2.019524613512632, time: 0.13007402420043945
Test Loss Energy: 9.949828030378713, Test Loss Force: 6.494567374014705, time: 9.035002708435059

Epoch 12, Batch 100/147, Loss: 0.09134089946746826, Uncertainty: 0.1228335052728653

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6429894578711848, Training Loss Force: 1.8636942075050609, time: 2.244126796722412
Validation Loss Energy: 0.8676758629479675, Validation Loss Force: 1.9760993797816002, time: 0.1334826946258545
Test Loss Energy: 8.255395344903677, Test Loss Force: 6.3532478264496755, time: 9.064422130584717

Epoch 13, Batch 100/147, Loss: 0.16769595444202423, Uncertainty: 0.12539887428283691

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8537577127468747, Training Loss Force: 1.8571590733215313, time: 2.218445301055908
Validation Loss Energy: 0.7885668223478026, Validation Loss Force: 2.0643757462311365, time: 0.14051580429077148
Test Loss Energy: 8.145217732842655, Test Loss Force: 6.4458500322522285, time: 9.065110206604004

Epoch 14, Batch 100/147, Loss: 0.24786581099033356, Uncertainty: 0.12486922740936279

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8744351763497404, Training Loss Force: 1.8619516487559808, time: 2.3049073219299316
Validation Loss Energy: 4.236324738213155, Validation Loss Force: 1.9845490058621218, time: 0.12997817993164062
Test Loss Energy: 11.672206530717146, Test Loss Force: 6.391643021687346, time: 9.047781944274902

Epoch 15, Batch 100/147, Loss: 0.14734026789665222, Uncertainty: 0.12379853427410126

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1087967495663555, Training Loss Force: 1.8565090142287146, time: 2.2509772777557373
Validation Loss Energy: 0.8422378428249826, Validation Loss Force: 2.0658051337018954, time: 0.13303685188293457
Test Loss Energy: 7.622575745669057, Test Loss Force: 6.362085382985652, time: 8.946439743041992

Epoch 16, Batch 100/147, Loss: 0.06786490976810455, Uncertainty: 0.12538501620292664

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8141464451392146, Training Loss Force: 1.8892557930990967, time: 2.2392196655273438
Validation Loss Energy: 1.3920960668794296, Validation Loss Force: 2.0483229337168134, time: 0.13164448738098145
Test Loss Energy: 9.001674808996157, Test Loss Force: 6.328998746094059, time: 9.139764308929443

Epoch 17, Batch 100/147, Loss: 0.14431814849376678, Uncertainty: 0.12291936576366425

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.6212593626137803, Training Loss Force: 1.8705711320111875, time: 2.2030370235443115
Validation Loss Energy: 1.4526885722001532, Validation Loss Force: 1.915035929217239, time: 0.13805770874023438
Test Loss Energy: 8.894761200188462, Test Loss Force: 6.350125515384808, time: 8.964284896850586

Epoch 18, Batch 100/147, Loss: 0.04767390340566635, Uncertainty: 0.12635967135429382

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.02150356604458, Training Loss Force: 1.8802155015122337, time: 2.248141050338745
Validation Loss Energy: 2.0365683779493824, Validation Loss Force: 1.9391846949853022, time: 0.12957191467285156
Test Loss Energy: 9.59252806388363, Test Loss Force: 6.351733890765864, time: 9.140303373336792

Epoch 19, Batch 100/147, Loss: 0.2284885048866272, Uncertainty: 0.12441881000995636

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.055916221598225, Training Loss Force: 1.8791665685133896, time: 2.3629767894744873
Validation Loss Energy: 2.495347944352792, Validation Loss Force: 1.9591924826465466, time: 0.12934041023254395
Test Loss Energy: 9.983436214368803, Test Loss Force: 6.395584589664629, time: 8.891742706298828

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–ƒâ–â–ƒâ–â–â–ƒâ–‚â–‚â–ˆâ–…â–‚â–‚â–ˆâ–â–„â–ƒâ–…â–…
wandb:   test_error_force â–„â–ƒâ–‚â–ˆâ–…â–â–‚â–‚â–„â–â–â–…â–‚â–„â–ƒâ–‚â–â–‚â–‚â–ƒ
wandb:          test_loss â–„â–â–ƒâ–‡â–…â–‚â–ƒâ–…â–…â–ƒâ–†â–…â–ƒâ–†â–ˆâ–„â–…â–…â–†â–†
wandb: train_error_energy â–ˆâ–ˆâ–…â–â–ƒâ–…â–‚â–„â–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–„â–„
wandb:  train_error_force â–ˆâ–‡â–‚â–ƒâ–ƒâ–ƒâ–‚â–‚â–‚â–ƒâ–â–…â–â–â–â–â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‡â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–â–„â–â–â–â–‚â–‚â–â–‚â–‚
wandb: valid_error_energy â–„â–ƒâ–â–„â–‚â–ˆâ–…â–â–â–â–†â–„â–â–â–‡â–â–‚â–‚â–ƒâ–„
wandb:  valid_error_force â–‚â–‚â–ƒâ–ˆâ–‡â–…â–‚â–‚â–‚â–…â–„â–ƒâ–‚â–…â–ƒâ–…â–„â–â–‚â–‚
wandb:         valid_loss â–ƒâ–‚â–‚â–ˆâ–†â–ˆâ–ƒâ–â–â–„â–†â–„â–‚â–ƒâ–…â–„â–„â–â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4681
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.98344
wandb:   test_error_force 6.39558
wandb:          test_loss 3.93912
wandb: train_error_energy 2.05592
wandb:  train_error_force 1.87917
wandb:         train_loss -2.54577
wandb: valid_error_energy 2.49535
wandb:  valid_error_force 1.95919
wandb:         valid_loss -2.40854
wandb: 
wandb: ğŸš€ View run al_58_68 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cvouj0jb
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_212615-cvouj0jb/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.26789855957031, Uncertainty Bias: -4.755597114562988
3.71933e-05 0.028018951
0.015576152 15.549695
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 1861 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2791 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1091 steps.
Found uncertainty sample 10 after 1254 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 625 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 3534 steps.
Found uncertainty sample 16 after 3337 steps.
Found uncertainty sample 17 after 3311 steps.
Found uncertainty sample 18 after 3005 steps.
Found uncertainty sample 19 after 3445 steps.
Found uncertainty sample 20 after 893 steps.
Found uncertainty sample 21 after 2414 steps.
Found uncertainty sample 22 after 986 steps.
Found uncertainty sample 23 after 3537 steps.
Found uncertainty sample 24 after 2951 steps.
Found uncertainty sample 25 after 1493 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 1166 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2102 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 977 steps.
Found uncertainty sample 32 after 1956 steps.
Found uncertainty sample 33 after 1603 steps.
Found uncertainty sample 34 after 3712 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2306 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3091 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3670 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2954 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 488 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 428 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 3326 steps.
Found uncertainty sample 66 after 2122 steps.
Found uncertainty sample 67 after 3048 steps.
Found uncertainty sample 68 after 3526 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1325 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1382 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2146 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1489 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1183 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Found uncertainty sample 90 after 1914 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 3656 steps.
Found uncertainty sample 93 after 295 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3971 steps.
Found uncertainty sample 98 after 1858 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_220252-s6knteib
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_69
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s6knteib
Training model 69. Added 42 samples to the dataset.
Epoch 0, Batch 100/148, Loss: 0.06141810119152069, Uncertainty: 0.12702816724777222

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8756837535327078, Training Loss Force: 1.9517741951047944, time: 2.614100456237793
Validation Loss Energy: 2.539552445871522, Validation Loss Force: 1.8943417639136726, time: 0.18050312995910645
Test Loss Energy: 9.931918478172891, Test Loss Force: 6.307431977907727, time: 12.443984746932983

Epoch 1, Batch 100/148, Loss: 0.2588236331939697, Uncertainty: 0.12460196018218994

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.125378422286234, Training Loss Force: 1.8748940631267321, time: 2.594768762588501
Validation Loss Energy: 1.1225970017563254, Validation Loss Force: 1.9779597804958267, time: 0.17867684364318848
Test Loss Energy: 8.40804956572975, Test Loss Force: 6.34265813187087, time: 12.612003803253174

Epoch 2, Batch 100/148, Loss: 0.1240396499633789, Uncertainty: 0.12444637715816498

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.202865430370526, Training Loss Force: 1.8666603080128417, time: 2.5503313541412354
Validation Loss Energy: 1.8799676540904988, Validation Loss Force: 1.9128533633603793, time: 0.17009401321411133
Test Loss Energy: 9.1094471046422, Test Loss Force: 6.3131646521941835, time: 12.457754611968994

Epoch 3, Batch 100/148, Loss: 0.11753048002719879, Uncertainty: 0.12518903613090515

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.527404805668843, Training Loss Force: 1.8482604433417529, time: 2.635599136352539
Validation Loss Energy: 0.7815256713940847, Validation Loss Force: 1.9899417556842984, time: 0.1707768440246582
Test Loss Energy: 8.063998031032659, Test Loss Force: 6.407622193279346, time: 12.579119443893433

Epoch 4, Batch 100/148, Loss: 0.2796285152435303, Uncertainty: 0.12451354414224625

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.401653197182334, Training Loss Force: 1.8720254067403561, time: 2.535186290740967
Validation Loss Energy: 0.7565638106839042, Validation Loss Force: 1.852239778693841, time: 0.17808818817138672
Test Loss Energy: 8.123257057108143, Test Loss Force: 6.284789405310278, time: 12.602941513061523

Epoch 5, Batch 100/148, Loss: 0.06770233064889908, Uncertainty: 0.12719327211380005

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.6179061798929946, Training Loss Force: 1.888965430675184, time: 2.6269009113311768
Validation Loss Energy: 1.7581661839185505, Validation Loss Force: 2.0164519277449258, time: 0.17110419273376465
Test Loss Energy: 7.45666988008077, Test Loss Force: 6.290357873342586, time: 12.574959993362427

Epoch 6, Batch 100/148, Loss: 0.07234247028827667, Uncertainty: 0.12337175011634827

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0001936885251554, Training Loss Force: 1.855471867987142, time: 2.602085590362549
Validation Loss Energy: 1.5028828366328166, Validation Loss Force: 1.9575343768513953, time: 0.17327451705932617
Test Loss Energy: 7.434803485493743, Test Loss Force: 6.317910522111084, time: 12.152191877365112

Epoch 7, Batch 100/148, Loss: 0.09179171919822693, Uncertainty: 0.12422267347574234

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7912778396831617, Training Loss Force: 1.8438740845883823, time: 2.5781214237213135
Validation Loss Energy: 1.4205396751341477, Validation Loss Force: 1.9125711302179156, time: 0.17995429039001465
Test Loss Energy: 7.633243038696507, Test Loss Force: 6.322350775710679, time: 12.263061285018921

Epoch 8, Batch 100/148, Loss: 0.053924161940813065, Uncertainty: 0.1236664205789566

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.185080821989064, Training Loss Force: 1.9002671641605227, time: 2.2855255603790283
Validation Loss Energy: 1.5592601036865545, Validation Loss Force: 2.416711147899615, time: 0.1514878273010254
Test Loss Energy: 7.45307894023087, Test Loss Force: 6.53932998350673, time: 11.54636287689209

Epoch 9, Batch 100/148, Loss: 0.04382980614900589, Uncertainty: 0.12370903044939041

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.5065343846189885, Training Loss Force: 1.8728428755765187, time: 2.3767778873443604
Validation Loss Energy: 1.8266232892503949, Validation Loss Force: 1.951229314426828, time: 0.16264653205871582
Test Loss Energy: 7.744609055808066, Test Loss Force: 6.352249923597033, time: 11.630131483078003

Epoch 10, Batch 100/148, Loss: 0.046490903943777084, Uncertainty: 0.12465991079807281

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.670538937570351, Training Loss Force: 1.8651426778628668, time: 2.500157594680786
Validation Loss Energy: 0.8430837629103621, Validation Loss Force: 1.922027666176323, time: 0.17428827285766602
Test Loss Energy: 8.333734703564586, Test Loss Force: 6.284709004261492, time: 11.422874212265015

Epoch 11, Batch 100/148, Loss: 0.05078425258398056, Uncertainty: 0.125809445977211

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3810636622423247, Training Loss Force: 1.8726832248079313, time: 2.5662734508514404
Validation Loss Energy: 1.6688293185500083, Validation Loss Force: 1.8598538016927444, time: 0.16061663627624512
Test Loss Energy: 7.446060397093154, Test Loss Force: 6.231383910406172, time: 10.512157917022705

Epoch 12, Batch 100/148, Loss: 0.07181446254253387, Uncertainty: 0.12436647713184357

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.5517392062906035, Training Loss Force: 1.867888335122979, time: 2.183413505554199
Validation Loss Energy: 0.831596410118045, Validation Loss Force: 2.3563224590704643, time: 0.15633058547973633
Test Loss Energy: 8.003171523755706, Test Loss Force: 6.544990505995065, time: 12.040318489074707

Epoch 13, Batch 100/148, Loss: 0.10106076300144196, Uncertainty: 0.12389291822910309

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.161899924273793, Training Loss Force: 1.9011707209507096, time: 2.4782423973083496
Validation Loss Energy: 8.358476317190128, Validation Loss Force: 1.9998805187897364, time: 0.12808465957641602
Test Loss Energy: 7.761353920141909, Test Loss Force: 6.31649346266124, time: 8.948257207870483

Epoch 14, Batch 100/148, Loss: 0.17417952418327332, Uncertainty: 0.1266702562570572

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2481704921972594, Training Loss Force: 1.8915166812211672, time: 2.335421323776245
Validation Loss Energy: 1.8471214314824962, Validation Loss Force: 1.8879352756931356, time: 0.1284172534942627
Test Loss Energy: 9.333129005804404, Test Loss Force: 6.3373862381564114, time: 9.03944444656372

Epoch 15, Batch 100/148, Loss: 0.1011705994606018, Uncertainty: 0.12385788559913635

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.2016321919748876, Training Loss Force: 1.8541267620418842, time: 2.3209855556488037
Validation Loss Energy: 2.4201073719363544, Validation Loss Force: 1.9611253250562484, time: 0.12699604034423828
Test Loss Energy: 9.66837561490476, Test Loss Force: 6.340384106313881, time: 8.877795934677124

Epoch 16, Batch 100/148, Loss: 0.15970060229301453, Uncertainty: 0.1249755248427391

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.158539110022457, Training Loss Force: 1.878410550568584, time: 2.295945167541504
Validation Loss Energy: 2.33726940248391, Validation Loss Force: 1.9065969912557217, time: 0.14104485511779785
Test Loss Energy: 9.463812846718108, Test Loss Force: 6.355551239670699, time: 9.720982313156128

Epoch 17, Batch 100/148, Loss: 0.07311641424894333, Uncertainty: 0.1249927207827568

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8214453948430016, Training Loss Force: 1.8567162710588934, time: 2.4030890464782715
Validation Loss Energy: 0.7572832918059212, Validation Loss Force: 1.8685758263617844, time: 0.16388607025146484
Test Loss Energy: 7.850888118171833, Test Loss Force: 6.286811152553966, time: 12.344768524169922

Epoch 18, Batch 100/148, Loss: 0.10120899975299835, Uncertainty: 0.12280333042144775

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.613566628676558, Training Loss Force: 1.8626376996203808, time: 2.4667916297912598
Validation Loss Energy: 2.43383670613597, Validation Loss Force: 1.918139788665375, time: 0.17129087448120117
Test Loss Energy: 7.148491286764742, Test Loss Force: 6.309487780706866, time: 11.234807252883911

Epoch 19, Batch 100/148, Loss: 0.2758379578590393, Uncertainty: 0.12461644411087036

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7869290390461718, Training Loss Force: 1.87933680230966, time: 2.2574479579925537
Validation Loss Energy: 0.8284981545100812, Validation Loss Force: 1.9043787241124648, time: 0.13917326927185059
Test Loss Energy: 7.81933052582338, Test Loss Force: 6.309434160577559, time: 11.384399890899658

wandb: - 0.039 MB of 0.059 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–„â–†â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–„â–‚â–ƒâ–ƒâ–†â–‡â–‡â–ƒâ–â–ƒ
wandb:   test_error_force â–ƒâ–ƒâ–ƒâ–…â–‚â–‚â–ƒâ–ƒâ–ˆâ–„â–‚â–â–ˆâ–ƒâ–ƒâ–ƒâ–„â–‚â–ƒâ–ƒ
wandb:          test_loss â–…â–ƒâ–„â–…â–ƒâ–‚â–ƒâ–„â–‡â–„â–ƒâ–â–ˆâ–‚â–„â–†â–„â–„â–ƒâ–‚
wandb: train_error_energy â–ˆâ–„â–…â–â–†â–â–ƒâ–‚â–„â–†â–‡â–…â–â–„â–…â–…â–„â–ƒâ–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–â–ƒâ–„â–‚â–â–…â–ƒâ–‚â–ƒâ–ƒâ–…â–„â–‚â–ƒâ–‚â–‚â–ƒ
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–â–„â–ƒâ–‚â–â–…â–„â–„â–„â–‚â–„â–„â–ƒâ–„â–‚â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–‚â–â–ˆâ–‚â–ƒâ–‚â–â–ƒâ–
wandb:  valid_error_force â–‚â–ƒâ–‚â–ƒâ–â–ƒâ–‚â–‚â–ˆâ–‚â–‚â–â–‡â–ƒâ–â–‚â–‚â–â–‚â–‚
wandb:         valid_loss â–ƒâ–ƒâ–‚â–ƒâ–â–ƒâ–ƒâ–‚â–ˆâ–ƒâ–‚â–‚â–‡â–‡â–‚â–ƒâ–ƒâ–â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4718
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.81933
wandb:   test_error_force 6.30943
wandb:          test_loss 3.61618
wandb: train_error_energy 1.78693
wandb:  train_error_force 1.87934
wandb:         train_loss -2.56366
wandb: valid_error_energy 0.8285
wandb:  valid_error_force 1.90438
wandb:         valid_loss -2.59431
wandb: 
wandb: ğŸš€ View run al_58_69 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/s6knteib
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_220252-s6knteib/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.066829681396484, Uncertainty Bias: -5.165290832519531
1.7166138e-05 0.0001077652
-0.26560688 17.225365
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2783 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 1512 steps.
Found uncertainty sample 4 after 1212 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 2714 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3432 steps.
Found uncertainty sample 11 after 3843 steps.
Found uncertainty sample 12 after 1495 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3630 steps.
Found uncertainty sample 15 after 1273 steps.
Found uncertainty sample 16 after 2404 steps.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3538 steps.
Found uncertainty sample 19 after 1974 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3750 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 694 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2368 steps.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 782 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 3030 steps.
Found uncertainty sample 40 after 2949 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1446 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3097 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 49 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1718 steps.
Found uncertainty sample 52 after 2845 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2000 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 3276 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2315 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 3671 steps.
Found uncertainty sample 65 after 3279 steps.
Found uncertainty sample 66 after 384 steps.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2441 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 2957 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3931 steps.
Found uncertainty sample 75 after 2440 steps.
Found uncertainty sample 76 after 3388 steps.
Found uncertainty sample 77 after 2829 steps.
Found uncertainty sample 78 after 1862 steps.
Found uncertainty sample 79 after 3106 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2451 steps.
Found uncertainty sample 85 after 864 steps.
Found uncertainty sample 86 after 1797 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3651 steps.
Found uncertainty sample 92 after 3081 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1289 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1036 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_224003-vs6icznx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_70
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vs6icznx
Training model 70. Added 44 samples to the dataset.
Epoch 0, Batch 100/149, Loss: 0.09905222058296204, Uncertainty: 0.12970781326293945

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5861832646031666, Training Loss Force: 2.082134514496205, time: 2.511035680770874
Validation Loss Energy: 1.3180409849959116, Validation Loss Force: 1.9720776038909011, time: 0.18842482566833496
Test Loss Energy: 7.546817038471342, Test Loss Force: 6.421216792826955, time: 11.980058908462524

Epoch 1, Batch 100/149, Loss: 0.1425148844718933, Uncertainty: 0.1262071430683136

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.199476609110167, Training Loss Force: 1.8967020526263065, time: 2.5166666507720947
Validation Loss Energy: 2.121361902064414, Validation Loss Force: 1.925582913094779, time: 0.16861319541931152
Test Loss Energy: 9.33422764837557, Test Loss Force: 6.284496183853495, time: 12.513120174407959

Epoch 2, Batch 100/149, Loss: 0.14327582716941833, Uncertainty: 0.12493478506803513

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8302468334535273, Training Loss Force: 1.88329391792248, time: 2.637702226638794
Validation Loss Energy: 1.4988770186975755, Validation Loss Force: 1.9294393200331024, time: 0.17986440658569336
Test Loss Energy: 8.808860759769656, Test Loss Force: 6.2318175066894534, time: 12.187795162200928

Epoch 3, Batch 100/149, Loss: 0.06264887750148773, Uncertainty: 0.12618285417556763

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8729021752872357, Training Loss Force: 1.9089335901132363, time: 2.5408143997192383
Validation Loss Energy: 2.8334585729719657, Validation Loss Force: 1.9396727115301273, time: 0.18953967094421387
Test Loss Energy: 9.818947513152995, Test Loss Force: 6.335993376197631, time: 12.460975646972656

Epoch 4, Batch 100/149, Loss: 0.15201830863952637, Uncertainty: 0.1261177808046341

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.208922914243252, Training Loss Force: 1.8766443140986793, time: 2.5771660804748535
Validation Loss Energy: 2.0074165333645166, Validation Loss Force: 1.9363485209620956, time: 0.17191362380981445
Test Loss Energy: 9.335283286656395, Test Loss Force: 6.340192251779812, time: 12.108447074890137

Epoch 5, Batch 100/149, Loss: 0.08274467289447784, Uncertainty: 0.1266302764415741

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8541434922930102, Training Loss Force: 1.8951239410954357, time: 2.51410174369812
Validation Loss Energy: 2.5471263884241586, Validation Loss Force: 2.022225664475785, time: 0.17138338088989258
Test Loss Energy: 9.813098155570845, Test Loss Force: 6.4253717874318985, time: 13.1465744972229

Epoch 6, Batch 100/149, Loss: 0.0903092548251152, Uncertainty: 0.125120148062706

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.2976625507003337, Training Loss Force: 1.8867117069927681, time: 2.5696861743927
Validation Loss Energy: 1.4875261620917122, Validation Loss Force: 2.0257004164979873, time: 0.173478364944458
Test Loss Energy: 7.637663720727401, Test Loss Force: 6.290719376118096, time: 12.450973749160767

Epoch 7, Batch 100/149, Loss: 0.3090638518333435, Uncertainty: 0.12642207741737366

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.7984878619255658, Training Loss Force: 1.8876600548852747, time: 2.5864744186401367
Validation Loss Energy: 5.36823840259272, Validation Loss Force: 1.9466634835895789, time: 0.1805415153503418
Test Loss Energy: 7.2193764705055505, Test Loss Force: 6.296307259500963, time: 12.541138887405396

Epoch 8, Batch 100/149, Loss: 0.056057535111904144, Uncertainty: 0.12651532888412476

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.10784477841031, Training Loss Force: 1.905390452510817, time: 2.457190990447998
Validation Loss Energy: 1.0639738565852357, Validation Loss Force: 1.822555457958013, time: 0.19039225578308105
Test Loss Energy: 7.919474458655242, Test Loss Force: 6.218100348178632, time: 12.432982921600342

Epoch 9, Batch 100/149, Loss: 0.050307780504226685, Uncertainty: 0.12449667602777481

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9116507335299888, Training Loss Force: 1.8641339731719022, time: 2.4983596801757812
Validation Loss Energy: 3.5302356808627344, Validation Loss Force: 1.8758926231623987, time: 0.1786489486694336
Test Loss Energy: 10.730967156004665, Test Loss Force: 6.27793787569008, time: 12.40679407119751

Epoch 10, Batch 100/149, Loss: 0.042962804436683655, Uncertainty: 0.12569528818130493

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.95412736207855, Training Loss Force: 1.8801198469573168, time: 2.558220148086548
Validation Loss Energy: 0.7842652255637209, Validation Loss Force: 1.9029075119537957, time: 0.17775869369506836
Test Loss Energy: 8.144072402030881, Test Loss Force: 6.1417579726881275, time: 12.325486898422241

Epoch 11, Batch 100/149, Loss: 0.08854924142360687, Uncertainty: 0.12478214502334595

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2176189491389473, Training Loss Force: 1.8696450793663288, time: 2.6318857669830322
Validation Loss Energy: 3.2590681558291927, Validation Loss Force: 2.042588312532589, time: 0.17541933059692383
Test Loss Energy: 7.162517904092889, Test Loss Force: 6.277166510131147, time: 12.496155261993408

Epoch 12, Batch 100/149, Loss: 0.08420318365097046, Uncertainty: 0.1239868625998497

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2309044428329594, Training Loss Force: 1.900967369781981, time: 2.529360055923462
Validation Loss Energy: 2.85004170916884, Validation Loss Force: 1.8542388280629323, time: 0.17498135566711426
Test Loss Energy: 7.205232927393842, Test Loss Force: 6.2404682333197306, time: 12.38226318359375

Epoch 13, Batch 100/149, Loss: 0.09245018661022186, Uncertainty: 0.12549340724945068

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9904133370543327, Training Loss Force: 1.8748813109610742, time: 2.5290310382843018
Validation Loss Energy: 3.25833780103055, Validation Loss Force: 1.9939456438202747, time: 0.17153453826904297
Test Loss Energy: 10.3721753948332, Test Loss Force: 6.34836967007557, time: 12.522042989730835

Epoch 14, Batch 100/149, Loss: 0.1039043664932251, Uncertainty: 0.12510472536087036

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9995760890951342, Training Loss Force: 1.8891302503376197, time: 2.4367849826812744
Validation Loss Energy: 1.017383325277554, Validation Loss Force: 1.9523067362009243, time: 0.1534576416015625
Test Loss Energy: 7.52418292263821, Test Loss Force: 6.326380492690378, time: 12.328389644622803

Epoch 15, Batch 100/149, Loss: 0.10547046363353729, Uncertainty: 0.1260456144809723

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.723239608561929, Training Loss Force: 1.897357870049168, time: 2.5567409992218018
Validation Loss Energy: 2.7936254379030405, Validation Loss Force: 2.002521300637391, time: 0.17905187606811523
Test Loss Energy: 9.82091788094852, Test Loss Force: 6.380793664573406, time: 11.247593879699707

Epoch 16, Batch 100/149, Loss: 0.0592489093542099, Uncertainty: 0.1244860365986824

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.974745248379934, Training Loss Force: 1.8894024745766944, time: 2.5491857528686523
Validation Loss Energy: 1.6551255913021745, Validation Loss Force: 1.9391248712080964, time: 0.16984868049621582
Test Loss Energy: 7.384085679461024, Test Loss Force: 6.312266365222072, time: 12.715842247009277

Epoch 17, Batch 100/149, Loss: 0.21871860325336456, Uncertainty: 0.12789958715438843

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9195693314316742, Training Loss Force: 1.9023905820445355, time: 2.5567893981933594
Validation Loss Energy: 1.7442784948446557, Validation Loss Force: 1.8832649759149218, time: 0.17206811904907227
Test Loss Energy: 7.536895577496889, Test Loss Force: 6.17488209027627, time: 9.065597295761108

Epoch 18, Batch 100/149, Loss: 0.07654637098312378, Uncertainty: 0.12331017851829529

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1050120013369322, Training Loss Force: 1.8547581465595633, time: 2.2289135456085205
Validation Loss Energy: 2.9080057536679838, Validation Loss Force: 1.909547802777557, time: 0.12948918342590332
Test Loss Energy: 7.278689163342624, Test Loss Force: 6.232315017178265, time: 9.850339412689209

Epoch 19, Batch 100/149, Loss: 0.15521004796028137, Uncertainty: 0.12389947474002838

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1747798753713727, Training Loss Force: 1.8563790979902446, time: 2.368084192276001
Validation Loss Energy: 0.7630441137263162, Validation Loss Force: 1.898727418300342, time: 0.13207507133483887
Test Loss Energy: 7.936654975755997, Test Loss Force: 6.209094826826592, time: 9.128141403198242

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–„â–†â–…â–†â–‚â–â–‚â–ˆâ–ƒâ–â–â–‡â–‚â–†â–â–‚â–â–ƒ
wandb:   test_error_force â–ˆâ–…â–ƒâ–†â–†â–ˆâ–…â–…â–ƒâ–„â–â–„â–ƒâ–†â–†â–‡â–…â–‚â–ƒâ–ƒ
wandb:          test_loss â–†â–…â–„â–†â–‡â–ˆâ–„â–„â–ƒâ–ˆâ–‚â–„â–‚â–ˆâ–…â–‡â–ƒâ–â–„â–„
wandb: train_error_energy â–‡â–„â–‚â–‚â–„â–‚â–…â–ˆâ–„â–‚â–ƒâ–„â–„â–ƒâ–ƒâ–â–ƒâ–‚â–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–
wandb:         train_loss â–ˆâ–‚â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–
wandb: valid_error_energy â–‚â–ƒâ–‚â–„â–ƒâ–„â–‚â–ˆâ–â–…â–â–…â–„â–…â–â–„â–‚â–‚â–„â–
wandb:  valid_error_force â–†â–„â–„â–…â–…â–‡â–‡â–…â–â–ƒâ–„â–ˆâ–‚â–†â–…â–‡â–…â–ƒâ–„â–ƒ
wandb:         valid_loss â–„â–„â–„â–…â–„â–‡â–†â–ˆâ–â–…â–‚â–ˆâ–„â–‡â–„â–†â–„â–ƒâ–…â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4757
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.93665
wandb:   test_error_force 6.20909
wandb:          test_loss 3.60623
wandb: train_error_energy 2.17478
wandb:  train_error_force 1.85638
wandb:         train_loss -2.56853
wandb: valid_error_energy 0.76304
wandb:  valid_error_force 1.89873
wandb:         valid_loss -2.60542
wandb: 
wandb: ğŸš€ View run al_58_70 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vs6icznx
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_224003-vs6icznx/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 44.99448776245117, Uncertainty Bias: -5.4381513595581055
1.5258789e-05 0.0002641678
-0.11300904 14.140787
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3324 steps.
Found uncertainty sample 5 after 470 steps.
Found uncertainty sample 6 after 2254 steps.
Found uncertainty sample 7 after 2451 steps.
Found uncertainty sample 8 after 2094 steps.
Found uncertainty sample 9 after 2621 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2627 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2083 steps.
Found uncertainty sample 18 after 1608 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1283 steps.
Found uncertainty sample 27 after 2097 steps.
Found uncertainty sample 28 after 2950 steps.
Found uncertainty sample 29 after 1160 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1544 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2637 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1851 steps.
Found uncertainty sample 50 after 3181 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 122 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 1859 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 301 steps.
Found uncertainty sample 62 after 3096 steps.
Found uncertainty sample 63 after 2795 steps.
Found uncertainty sample 64 after 1788 steps.
Found uncertainty sample 65 after 3640 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2439 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3901 steps.
Found uncertainty sample 71 after 1579 steps.
Found uncertainty sample 72 after 1545 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1843 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2641 steps.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 1300 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 2575 steps.
Found uncertainty sample 88 after 2374 steps.
Found uncertainty sample 89 after 2756 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 627 steps.
Found uncertainty sample 93 after 3056 steps.
Found uncertainty sample 94 after 3149 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_231809-m1aisvgz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_71
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m1aisvgz
Training model 71. Added 37 samples to the dataset.
Epoch 0, Batch 100/150, Loss: 0.25047028064727783, Uncertainty: 0.1276967078447342

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5002549010238257, Training Loss Force: 2.075367021113316, time: 2.7755422592163086
Validation Loss Energy: 2.2783477322111794, Validation Loss Force: 1.961092518468748, time: 0.18940162658691406
Test Loss Energy: 7.2633005033307825, Test Loss Force: 6.329178096181745, time: 12.617631912231445

Epoch 1, Batch 100/150, Loss: 0.22179773449897766, Uncertainty: 0.12738031148910522

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.521052844580629, Training Loss Force: 1.9096033149378673, time: 2.612682342529297
Validation Loss Energy: 2.5512060582927987, Validation Loss Force: 2.063591728168325, time: 0.17716264724731445
Test Loss Energy: 9.68554364388043, Test Loss Force: 6.347849237488604, time: 12.813922643661499

Epoch 2, Batch 100/150, Loss: 0.193312406539917, Uncertainty: 0.12540078163146973

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.345014013514595, Training Loss Force: 1.8604735359441515, time: 2.6208293437957764
Validation Loss Energy: 2.69363244366393, Validation Loss Force: 1.9687663652448573, time: 0.17348146438598633
Test Loss Energy: 9.782853343563517, Test Loss Force: 6.269013361606488, time: 12.2313392162323

Epoch 3, Batch 100/150, Loss: 0.07090777158737183, Uncertainty: 0.12623639404773712

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7307644542466247, Training Loss Force: 1.8856274777396838, time: 2.7668356895446777
Validation Loss Energy: 1.1803330330500386, Validation Loss Force: 1.8871977583702986, time: 0.18019914627075195
Test Loss Energy: 7.256742976258089, Test Loss Force: 6.240553192674067, time: 12.395535945892334

Epoch 4, Batch 100/150, Loss: 0.04142745956778526, Uncertainty: 0.1265181303024292

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 3.6822291099204754, Training Loss Force: 1.8841496419161539, time: 2.4817137718200684
Validation Loss Energy: 1.0345582603970183, Validation Loss Force: 1.9527728940579239, time: 0.16657233238220215
Test Loss Energy: 7.512285565611214, Test Loss Force: 6.252686847131368, time: 11.698805809020996

Epoch 5, Batch 100/150, Loss: 0.15257206559181213, Uncertainty: 0.12335962057113647

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0479297619813503, Training Loss Force: 1.883626084406717, time: 2.5494611263275146
Validation Loss Energy: 3.095205560225691, Validation Loss Force: 2.063140006694286, time: 0.1582953929901123
Test Loss Energy: 10.163428484533824, Test Loss Force: 6.3378431692335395, time: 11.743642568588257

Epoch 6, Batch 100/150, Loss: 0.20052382349967957, Uncertainty: 0.12637338042259216

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.1853874746298767, Training Loss Force: 1.8917709313515194, time: 2.5749313831329346
Validation Loss Energy: 1.7627103787371203, Validation Loss Force: 1.9857379848783276, time: 0.15640020370483398
Test Loss Energy: 8.765433631213568, Test Loss Force: 6.259999740227087, time: 11.584811687469482

Epoch 7, Batch 100/150, Loss: 0.05192442238330841, Uncertainty: 0.12406112253665924

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.5322307447407095, Training Loss Force: 1.881685295677427, time: 2.5539934635162354
Validation Loss Energy: 0.7959392122118499, Validation Loss Force: 1.9709159018450713, time: 0.16686248779296875
Test Loss Energy: 7.627192005821727, Test Loss Force: 6.361243180658942, time: 11.73890209197998

Epoch 8, Batch 100/150, Loss: 0.14752197265625, Uncertainty: 0.1276479810476303

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9822921267756153, Training Loss Force: 1.924107023399584, time: 2.544261932373047
Validation Loss Energy: 0.8303226498245272, Validation Loss Force: 1.9411883461834092, time: 0.164262056350708
Test Loss Energy: 7.8581762401994215, Test Loss Force: 6.269380427613225, time: 11.137075901031494

Epoch 9, Batch 100/150, Loss: 0.08748038113117218, Uncertainty: 0.12396803498268127

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.071016555131777, Training Loss Force: 1.854935263670576, time: 2.5575695037841797
Validation Loss Energy: 1.0561105183659416, Validation Loss Force: 2.093406161908423, time: 0.15860199928283691
Test Loss Energy: 7.3042367708824125, Test Loss Force: 6.304478846429871, time: 11.121495962142944

Epoch 10, Batch 100/150, Loss: 0.14360398054122925, Uncertainty: 0.12308846414089203

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.5650633789640815, Training Loss Force: 1.8717896509676366, time: 2.25923490524292
Validation Loss Energy: 0.9440042112537865, Validation Loss Force: 1.9453550425765826, time: 0.14036297798156738
Test Loss Energy: 7.924763629630132, Test Loss Force: 6.206500358218279, time: 9.265828371047974

Epoch 11, Batch 100/150, Loss: 0.4759155511856079, Uncertainty: 0.12236647307872772

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.2049107661454936, Training Loss Force: 1.881398350113606, time: 2.425340175628662
Validation Loss Energy: 4.620442671979538, Validation Loss Force: 2.4379376037965224, time: 0.13643169403076172
Test Loss Energy: 7.033364245550002, Test Loss Force: 6.544450324636728, time: 9.020334243774414

Epoch 12, Batch 100/150, Loss: 0.32472699880599976, Uncertainty: 0.1243310272693634

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9311743862229303, Training Loss Force: 1.901758507987128, time: 2.315340995788574
Validation Loss Energy: 1.6514832807476607, Validation Loss Force: 2.048302002817096, time: 0.13061785697937012
Test Loss Energy: 7.109100702154421, Test Loss Force: 6.232297212973046, time: 10.72579312324524

Epoch 13, Batch 100/150, Loss: 0.10643794387578964, Uncertainty: 0.12481968104839325

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.07151874382551, Training Loss Force: 1.8758093797866549, time: 2.587925434112549
Validation Loss Energy: 3.6340435171329286, Validation Loss Force: 2.05731089956914, time: 0.16640615463256836
Test Loss Energy: 7.0683408212089605, Test Loss Force: 6.227696681889051, time: 12.228998899459839

Epoch 14, Batch 100/150, Loss: 0.061504293233156204, Uncertainty: 0.12439939379692078

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1641280629571424, Training Loss Force: 1.8800933827392858, time: 2.352681875228882
Validation Loss Energy: 1.0682982027337262, Validation Loss Force: 1.962479227686538, time: 0.17769074440002441
Test Loss Energy: 7.776952779827507, Test Loss Force: 6.189728188351787, time: 10.736713886260986

Epoch 15, Batch 100/150, Loss: 0.23396876454353333, Uncertainty: 0.12357210367918015

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.4518401430468737, Training Loss Force: 1.8639922621537532, time: 2.4530205726623535
Validation Loss Energy: 0.7567970751700256, Validation Loss Force: 2.0043033960353003, time: 0.1698627471923828
Test Loss Energy: 7.580434674824971, Test Loss Force: 6.228716620826491, time: 11.594782829284668

Epoch 16, Batch 100/150, Loss: 0.16091401875019073, Uncertainty: 0.12428884208202362

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.112346946113794, Training Loss Force: 1.8758674556110653, time: 2.556678295135498
Validation Loss Energy: 6.9168579271373964, Validation Loss Force: 1.9242172461112796, time: 0.17041492462158203
Test Loss Energy: 7.3796564404064044, Test Loss Force: 6.242672242837107, time: 11.59262466430664

Epoch 17, Batch 100/150, Loss: 0.07432065159082413, Uncertainty: 0.12311232089996338

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.927782790364389, Training Loss Force: 1.8680382919100573, time: 2.626206874847412
Validation Loss Energy: 0.9507388395723724, Validation Loss Force: 1.9372361915123368, time: 0.16120481491088867
Test Loss Energy: 7.355066818485979, Test Loss Force: 6.225475329826048, time: 11.50162386894226

Epoch 18, Batch 100/150, Loss: 0.05208541452884674, Uncertainty: 0.12382026761770248

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6727299082424971, Training Loss Force: 1.8496630839953059, time: 2.344325304031372
Validation Loss Energy: 1.5778202821185978, Validation Loss Force: 1.9149138694137464, time: 0.16611838340759277
Test Loss Energy: 8.20819079866572, Test Loss Force: 6.2131092577442955, time: 11.82213306427002

Epoch 19, Batch 100/150, Loss: 0.08130981773138046, Uncertainty: 0.12360630184412003

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7708483927080647, Training Loss Force: 1.8777956449778472, time: 2.596146583557129
Validation Loss Energy: 0.776781686684331, Validation Loss Force: 1.9593799700674177, time: 0.17503786087036133
Test Loss Energy: 7.355779203534803, Test Loss Force: 6.1901984026344055, time: 12.672047853469849

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‡â–‡â–â–‚â–ˆâ–…â–‚â–ƒâ–‚â–ƒâ–â–â–â–ƒâ–‚â–‚â–‚â–„â–‚
wandb:   test_error_force â–„â–„â–ƒâ–‚â–‚â–„â–‚â–„â–ƒâ–ƒâ–â–ˆâ–‚â–‚â–â–‚â–‚â–‚â–â–
wandb:          test_loss â–‚â–†â–…â–‚â–ƒâ–†â–„â–„â–‚â–…â–ƒâ–ˆâ–‚â–â–‚â–ƒâ–„â–ƒâ–…â–
wandb: train_error_energy â–‡â–„â–„â–‚â–ˆâ–ƒâ–ƒâ–â–‚â–ƒâ–â–ƒâ–‚â–ƒâ–ƒâ–„â–ƒâ–‚â–â–‚
wandb:  train_error_force â–ˆâ–ƒâ–â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–„â–‚â–‚â–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚
wandb: valid_error_energy â–ƒâ–ƒâ–ƒâ–â–â–„â–‚â–â–â–â–â–…â–‚â–„â–â–â–ˆâ–â–‚â–
wandb:  valid_error_force â–‚â–ƒâ–‚â–â–‚â–ƒâ–‚â–‚â–‚â–„â–‚â–ˆâ–ƒâ–ƒâ–‚â–‚â–â–‚â–â–‚
wandb:         valid_loss â–‚â–ƒâ–ƒâ–â–‚â–„â–‚â–‚â–â–ƒâ–â–ˆâ–ƒâ–„â–‚â–‚â–„â–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4790
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.35578
wandb:   test_error_force 6.1902
wandb:          test_loss 3.45204
wandb: train_error_energy 1.77085
wandb:  train_error_force 1.8778
wandb:         train_loss -2.56628
wandb: valid_error_energy 0.77678
wandb:  valid_error_force 1.95938
wandb:         valid_loss -2.52442
wandb: 
wandb: ğŸš€ View run al_58_71 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m1aisvgz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_231809-m1aisvgz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.62880325317383, Uncertainty Bias: -4.842303276062012
3.8146973e-06 0.0022506714
-0.07235856 17.124262
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2581 steps.
Found uncertainty sample 5 after 1999 steps.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3401 steps.
Found uncertainty sample 12 after 1841 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3965 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1173 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2285 steps.
Found uncertainty sample 22 after 3192 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2776 steps.
Found uncertainty sample 26 after 2122 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 2573 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2168 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3077 steps.
Found uncertainty sample 47 after 1254 steps.
Found uncertainty sample 48 after 2673 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2088 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3129 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 1693 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 1362 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 3570 steps.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 3152 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 2002 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 2555 steps.
Found uncertainty sample 76 after 2031 steps.
Found uncertainty sample 77 after 1767 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 1209 steps.
Found uncertainty sample 81 after 1935 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2191 steps.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3253 steps.
Found uncertainty sample 86 after 2467 steps.
Found uncertainty sample 87 after 1737 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3317 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3953 steps.
Found uncertainty sample 98 after 641 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241129_235701-wc9ngbvd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_72
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wc9ngbvd
Training model 72. Added 34 samples to the dataset.
Epoch 0, Batch 100/151, Loss: 0.19309425354003906, Uncertainty: 0.12972450256347656

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.968718168658621, Training Loss Force: 2.069429449836776, time: 2.5505220890045166
Validation Loss Energy: 3.895600716051275, Validation Loss Force: 2.1652038982135733, time: 0.1832594871520996
Test Loss Energy: 10.568567772208974, Test Loss Force: 6.3779073851348365, time: 11.901527643203735

Epoch 1, Batch 100/151, Loss: 0.17512424290180206, Uncertainty: 0.12370052188634872

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7472367601301304, Training Loss Force: 1.8616931058571393, time: 2.581663131713867
Validation Loss Energy: 0.8519799519630421, Validation Loss Force: 1.919589105024695, time: 0.174668550491333
Test Loss Energy: 7.924842477823932, Test Loss Force: 6.180645562853288, time: 12.294423341751099

Epoch 2, Batch 100/151, Loss: 0.1334085464477539, Uncertainty: 0.1236019879579544

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.076363948413886, Training Loss Force: 1.8872096274222459, time: 2.590142011642456
Validation Loss Energy: 3.8365849309528657, Validation Loss Force: 1.9662505750111166, time: 0.1724836826324463
Test Loss Energy: 10.688756206686197, Test Loss Force: 6.241309964660392, time: 11.972718477249146

Epoch 3, Batch 100/151, Loss: 0.14387845993041992, Uncertainty: 0.1255933791399002

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.358497084044206, Training Loss Force: 1.877955146755522, time: 2.5029139518737793
Validation Loss Energy: 4.773130171156363, Validation Loss Force: 1.9892004900975049, time: 0.17716383934020996
Test Loss Energy: 7.190608148459694, Test Loss Force: 6.277931787845683, time: 12.22998046875

Epoch 4, Batch 100/151, Loss: 0.15651318430900574, Uncertainty: 0.12605097889900208

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.175801196470313, Training Loss Force: 1.8781787530288816, time: 2.5007612705230713
Validation Loss Energy: 1.8751262701851639, Validation Loss Force: 1.9136100673412904, time: 0.1780393123626709
Test Loss Energy: 6.946848741654633, Test Loss Force: 6.173437571407251, time: 12.172444820404053

Epoch 5, Batch 100/151, Loss: 0.13597965240478516, Uncertainty: 0.122823566198349

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9517114648930938, Training Loss Force: 1.83914848228706, time: 2.4983482360839844
Validation Loss Energy: 4.40119877130051, Validation Loss Force: 1.9185564768604546, time: 0.16786408424377441
Test Loss Energy: 10.982925114855625, Test Loss Force: 6.161450640761625, time: 12.089144229888916

Epoch 6, Batch 100/151, Loss: 0.17700506746768951, Uncertainty: 0.12384577095508575

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8556581149716997, Training Loss Force: 1.870488893244457, time: 2.674152135848999
Validation Loss Energy: 0.9712885668232804, Validation Loss Force: 2.2408694718065383, time: 0.17409563064575195
Test Loss Energy: 8.245803040222413, Test Loss Force: 6.461856059375357, time: 11.75046992301941

Epoch 7, Batch 100/151, Loss: 0.2631571888923645, Uncertainty: 0.12371163070201874

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.589998838771801, Training Loss Force: 1.8821034884277728, time: 2.475648880004883
Validation Loss Energy: 1.813881344266872, Validation Loss Force: 1.963728178926047, time: 0.1635150909423828
Test Loss Energy: 8.463834943802302, Test Loss Force: 6.1894793398428165, time: 12.233633279800415

Epoch 8, Batch 100/151, Loss: 0.048179641366004944, Uncertainty: 0.12417042255401611

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.713686598264108, Training Loss Force: 1.8688028078176844, time: 2.748171329498291
Validation Loss Energy: 1.2256530327668187, Validation Loss Force: 1.9025770709412388, time: 0.16103649139404297
Test Loss Energy: 8.181610931939622, Test Loss Force: 6.190823767182033, time: 11.479403018951416

Epoch 9, Batch 100/151, Loss: 0.1301531195640564, Uncertainty: 0.12297813594341278

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.9566331703425597, Training Loss Force: 1.8640075046285156, time: 2.5144214630126953
Validation Loss Energy: 2.2865570240601967, Validation Loss Force: 1.945693462566869, time: 0.1578996181488037
Test Loss Energy: 7.09766886353926, Test Loss Force: 6.117511678611354, time: 11.260876178741455

Epoch 10, Batch 100/151, Loss: 0.24629896879196167, Uncertainty: 0.12397535145282745

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.099490397245836, Training Loss Force: 1.8539693701326156, time: 2.5257766246795654
Validation Loss Energy: 0.7919362518639819, Validation Loss Force: 1.9469112401259479, time: 0.17257094383239746
Test Loss Energy: 7.404082515919471, Test Loss Force: 6.159408256401594, time: 11.650179147720337

Epoch 11, Batch 100/151, Loss: 0.26360079646110535, Uncertainty: 0.12420892715454102

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.639462552525789, Training Loss Force: 1.8763862870489847, time: 2.328537702560425
Validation Loss Energy: 1.1579146663265047, Validation Loss Force: 1.9184286647706923, time: 0.15549612045288086
Test Loss Energy: 7.933304693454753, Test Loss Force: 6.156866629163482, time: 11.64289116859436

Epoch 12, Batch 100/151, Loss: 0.11501531302928925, Uncertainty: 0.12255565822124481

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.548464420861122, Training Loss Force: 1.8384940960075613, time: 2.4587910175323486
Validation Loss Energy: 0.9610669396794652, Validation Loss Force: 1.8862399841506143, time: 0.16525793075561523
Test Loss Energy: 7.9845538090541845, Test Loss Force: 6.21158829690722, time: 11.682244539260864

Epoch 13, Batch 100/151, Loss: 0.05401656776666641, Uncertainty: 0.12312671542167664

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.618147974331294, Training Loss Force: 1.8820448003615196, time: 2.3452420234680176
Validation Loss Energy: 1.1700971550808843, Validation Loss Force: 1.9180712065684293, time: 0.14917445182800293
Test Loss Energy: 7.092602060932077, Test Loss Force: 6.178132877940918, time: 11.028579473495483

Epoch 14, Batch 100/151, Loss: 0.15676981210708618, Uncertainty: 0.12308010458946228

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.262488833187069, Training Loss Force: 1.8443611832141604, time: 2.5533199310302734
Validation Loss Energy: 6.965589811954179, Validation Loss Force: 1.9147205183720324, time: 0.1709609031677246
Test Loss Energy: 13.45276566695991, Test Loss Force: 6.215468830222376, time: 12.15815019607544

Epoch 15, Batch 100/151, Loss: 0.21103857457637787, Uncertainty: 0.12347046285867691

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.433667706275617, Training Loss Force: 1.8737099027151496, time: 2.312453508377075
Validation Loss Energy: 3.5673683587528955, Validation Loss Force: 1.997556298244542, time: 0.13076543807983398
Test Loss Energy: 10.0339604358098, Test Loss Force: 6.160533857094907, time: 9.011040925979614

Epoch 16, Batch 100/151, Loss: 0.07176923751831055, Uncertainty: 0.12377604842185974

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1652400143625736, Training Loss Force: 1.8659047703580638, time: 2.2806262969970703
Validation Loss Energy: 3.363778321701736, Validation Loss Force: 2.1797098281711365, time: 0.1344282627105713
Test Loss Energy: 7.050687191629272, Test Loss Force: 6.231524558031521, time: 9.004668235778809

Epoch 17, Batch 100/151, Loss: 0.2668476104736328, Uncertainty: 0.12419477105140686

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.973285498724785, Training Loss Force: 1.8480662547632791, time: 2.6848270893096924
Validation Loss Energy: 1.6862115772000934, Validation Loss Force: 1.9356601021859356, time: 0.15289950370788574
Test Loss Energy: 7.0309795942307325, Test Loss Force: 6.176710987386672, time: 11.88213849067688

Epoch 18, Batch 100/151, Loss: 0.06812124699354172, Uncertainty: 0.12264804542064667

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.582506773704027, Training Loss Force: 1.8681560697072275, time: 2.5688865184783936
Validation Loss Energy: 1.28085419850329, Validation Loss Force: 1.8877656760269872, time: 0.16655635833740234
Test Loss Energy: 8.194507173428793, Test Loss Force: 6.121511744454626, time: 10.925573348999023

Epoch 19, Batch 100/151, Loss: 0.07048812508583069, Uncertainty: 0.12182675302028656

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.6139435451029818, Training Loss Force: 1.8491070007662498, time: 2.386629104614258
Validation Loss Energy: 0.9199974712893009, Validation Loss Force: 1.9864651480858793, time: 0.14113187789916992
Test Loss Energy: 7.235021899519436, Test Loss Force: 6.1248664055271345, time: 10.287776231765747

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–…â–â–â–…â–‚â–ƒâ–‚â–â–â–‚â–‚â–â–ˆâ–„â–â–â–‚â–
wandb:   test_error_force â–†â–‚â–„â–„â–‚â–‚â–ˆâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–ƒâ–‚â–ƒâ–‚â–â–
wandb:          test_loss â–‡â–ƒâ–…â–„â–‚â–†â–‡â–ƒâ–ƒâ–â–ƒâ–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–„â–ƒâ–‚
wandb: train_error_energy â–ˆâ–‚â–„â–…â–„â–ƒâ–‡â–â–‚â–ˆâ–„â–â–â–â–…â–…â–„â–ƒâ–â–
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–‚â–‚â–â–‚â–â–‚â–â–‚â–‚â–â–‚â–
wandb:         train_loss â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–â–‚â–‚â–ƒâ–‚â–‚â–‚â–
wandb: valid_error_energy â–…â–â–„â–†â–‚â–…â–â–‚â–â–ƒâ–â–â–â–â–ˆâ–„â–„â–‚â–‚â–
wandb:  valid_error_force â–‡â–‚â–ƒâ–ƒâ–‚â–‚â–ˆâ–ƒâ–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–‡â–‚â–â–ƒ
wandb:         valid_loss â–ˆâ–â–…â–†â–‚â–„â–‡â–ƒâ–â–ƒâ–‚â–‚â–â–‚â–†â–…â–ˆâ–‚â–â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4820
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.23502
wandb:   test_error_force 6.12487
wandb:          test_loss 3.44159
wandb: train_error_energy 1.61394
wandb:  train_error_force 1.84911
wandb:         train_loss -2.6156
wandb: valid_error_energy 0.92
wandb:  valid_error_force 1.98647
wandb:         valid_loss -2.47628
wandb: 
wandb: ğŸš€ View run al_58_72 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/wc9ngbvd
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241129_235701-wc9ngbvd/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.8155632019043, Uncertainty Bias: -4.79302453994751
1.4305115e-05 0.00457561
-0.02141899 16.279722
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2404 steps.
Found uncertainty sample 3 after 2953 steps.
Found uncertainty sample 4 after 2215 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1774 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 3361 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 2145 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 2816 steps.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2788 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2509 steps.
Found uncertainty sample 22 after 1533 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 1549 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2371 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1394 steps.
Found uncertainty sample 36 after 1684 steps.
Found uncertainty sample 37 after 1697 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 3717 steps.
Found uncertainty sample 41 after 1103 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3147 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1282 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 1738 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3396 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2376 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 3068 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1189 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3129 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1754 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 120 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3799 steps.
Found uncertainty sample 89 after 1680 steps.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 3105 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2593 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1403 steps.
Found uncertainty sample 97 after 3896 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_003551-b4auwtzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_73
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/b4auwtzs
Training model 73. Added 33 samples to the dataset.
Epoch 0, Batch 100/152, Loss: 0.046945564448833466, Uncertainty: 0.12646403908729553

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5325959481359424, Training Loss Force: 2.0061061720742916, time: 2.467196464538574
Validation Loss Energy: 2.1833625670639845, Validation Loss Force: 1.8727802651751932, time: 0.16879796981811523
Test Loss Energy: 8.870604815482748, Test Loss Force: 6.119033851887757, time: 11.693355321884155

Epoch 1, Batch 100/152, Loss: 0.0635942816734314, Uncertainty: 0.1234663724899292

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.5560819413511673, Training Loss Force: 1.8435205493527085, time: 2.512322425842285
Validation Loss Energy: 0.8625945715936575, Validation Loss Force: 1.8639505428625724, time: 0.17138314247131348
Test Loss Energy: 7.355831543607973, Test Loss Force: 6.140469965746745, time: 11.863536357879639

Epoch 2, Batch 100/152, Loss: 0.06143210828304291, Uncertainty: 0.12330508232116699

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9553876026181953, Training Loss Force: 1.8548521001529723, time: 2.485393524169922
Validation Loss Energy: 1.1016365612657537, Validation Loss Force: 2.1361587863726554, time: 0.1651473045349121
Test Loss Energy: 8.01332911894748, Test Loss Force: 6.266770705585514, time: 11.780994176864624

Epoch 3, Batch 100/152, Loss: 0.05136825889348984, Uncertainty: 0.12293664366006851

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.864355061163377, Training Loss Force: 1.8821852000005792, time: 2.5639872550964355
Validation Loss Energy: 1.8092428861765255, Validation Loss Force: 2.1343559827441756, time: 0.1766369342803955
Test Loss Energy: 8.595285190931763, Test Loss Force: 6.235560362855616, time: 12.432740688323975

Epoch 4, Batch 100/152, Loss: 0.40002554655075073, Uncertainty: 0.12499634921550751

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9745378266974587, Training Loss Force: 1.8742635861894457, time: 2.4495935440063477
Validation Loss Energy: 4.599852456055596, Validation Loss Force: 1.975455569057674, time: 0.1629810333251953
Test Loss Energy: 6.920261870759797, Test Loss Force: 6.143374347837137, time: 11.719173431396484

Epoch 5, Batch 100/152, Loss: 0.16397276520729065, Uncertainty: 0.12391213327646255

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8815616059016045, Training Loss Force: 1.8764796334775768, time: 2.507354974746704
Validation Loss Energy: 1.4436713995781858, Validation Loss Force: 1.9600280486166402, time: 0.16489505767822266
Test Loss Energy: 7.13866907327579, Test Loss Force: 6.1211161255016995, time: 11.660790920257568

Epoch 6, Batch 100/152, Loss: 0.14062319695949554, Uncertainty: 0.12423166632652283

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.336648246392344, Training Loss Force: 1.863346257865287, time: 2.707650661468506
Validation Loss Energy: 1.928339074671549, Validation Loss Force: 1.982477366351458, time: 0.16868925094604492
Test Loss Energy: 8.721065768650801, Test Loss Force: 6.16952596467107, time: 11.609592914581299

Epoch 7, Batch 100/152, Loss: 0.07004478573799133, Uncertainty: 0.12331832200288773

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0331187869302823, Training Loss Force: 1.8350802607270298, time: 2.462240695953369
Validation Loss Energy: 1.466114408353869, Validation Loss Force: 1.9620105833574086, time: 0.17200279235839844
Test Loss Energy: 7.0081427678683115, Test Loss Force: 6.133430832124971, time: 11.627629280090332

Epoch 8, Batch 100/152, Loss: 0.14534083008766174, Uncertainty: 0.1225978285074234

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.6965774579376418, Training Loss Force: 1.8504685437882014, time: 2.4971799850463867
Validation Loss Energy: 0.8013055015171853, Validation Loss Force: 1.9397272654708797, time: 0.20842576026916504
Test Loss Energy: 7.6201087673877606, Test Loss Force: 6.074662993200876, time: 11.638045310974121

Epoch 9, Batch 100/152, Loss: 0.14221791923046112, Uncertainty: 0.124533511698246

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8037358567866066, Training Loss Force: 1.8887134989867485, time: 2.4882049560546875
Validation Loss Energy: 2.54958035085838, Validation Loss Force: 1.9694626516641736, time: 0.16657638549804688
Test Loss Energy: 9.156362565706775, Test Loss Force: 6.129825981865386, time: 11.543372631072998

Epoch 10, Batch 100/152, Loss: 0.06972461938858032, Uncertainty: 0.12462861090898514

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2206502596691586, Training Loss Force: 1.879034104174161, time: 2.471285820007324
Validation Loss Energy: 1.0355073876315355, Validation Loss Force: 1.8752851817323075, time: 0.1739811897277832
Test Loss Energy: 6.906891155129058, Test Loss Force: 6.102231275441872, time: 11.786529779434204

Epoch 11, Batch 100/152, Loss: 0.09712491929531097, Uncertainty: 0.12430571019649506

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8849435766714568, Training Loss Force: 1.875177411574762, time: 2.508927822113037
Validation Loss Energy: 2.456143626951967, Validation Loss Force: 2.106107358438242, time: 0.17098069190979004
Test Loss Energy: 6.89712131202426, Test Loss Force: 6.114730685538789, time: 11.443022966384888

Epoch 12, Batch 100/152, Loss: 0.04510869085788727, Uncertainty: 0.12444259226322174

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.122218967082364, Training Loss Force: 1.912834328322414, time: 2.5090339183807373
Validation Loss Energy: 0.952112615423936, Validation Loss Force: 1.9481384811237288, time: 0.15920162200927734
Test Loss Energy: 7.31207978908488, Test Loss Force: 6.1348155380976515, time: 12.39113736152649

Epoch 13, Batch 100/152, Loss: 0.21293753385543823, Uncertainty: 0.1225450336933136

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2149878558021805, Training Loss Force: 1.8615822062369962, time: 2.7182068824768066
Validation Loss Energy: 1.6114899723397655, Validation Loss Force: 1.8434067163440317, time: 0.18398237228393555
Test Loss Energy: 8.603670157856051, Test Loss Force: 6.111464334350067, time: 12.564453601837158

Epoch 14, Batch 100/152, Loss: 0.09256032109260559, Uncertainty: 0.12267608940601349

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.812893635574269, Training Loss Force: 1.8607763490187406, time: 2.634549379348755
Validation Loss Energy: 2.314770392418026, Validation Loss Force: 1.92544971983399, time: 0.17469286918640137
Test Loss Energy: 6.9970300619373536, Test Loss Force: 6.077102728903106, time: 12.643407106399536

Epoch 15, Batch 100/152, Loss: 0.0796656534075737, Uncertainty: 0.12345721572637558

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8841772706940143, Training Loss Force: 1.8621681205414329, time: 2.4585063457489014
Validation Loss Energy: 0.9091579558212984, Validation Loss Force: 1.981310505803748, time: 0.1763925552368164
Test Loss Energy: 7.4643220020425645, Test Loss Force: 6.18003262114555, time: 13.082521915435791

Epoch 16, Batch 100/152, Loss: 0.2134961485862732, Uncertainty: 0.12347264587879181

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9456405694889074, Training Loss Force: 1.8632446181897422, time: 2.633732795715332
Validation Loss Energy: 3.3452339898905774, Validation Loss Force: 1.9356895316247222, time: 0.18587183952331543
Test Loss Energy: 6.688632595343141, Test Loss Force: 6.073758166051232, time: 12.769437313079834

Epoch 17, Batch 100/152, Loss: 0.07250893861055374, Uncertainty: 0.12308003008365631

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.113844381236484, Training Loss Force: 1.8634169047790825, time: 2.687145709991455
Validation Loss Energy: 1.6429063250271927, Validation Loss Force: 1.835389105518134, time: 0.17762398719787598
Test Loss Energy: 6.858211883961499, Test Loss Force: 6.051283509305954, time: 12.630378723144531

Epoch 18, Batch 100/152, Loss: 0.07622188329696655, Uncertainty: 0.12275414913892746

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2314745624641237, Training Loss Force: 1.880014955902258, time: 2.6020774841308594
Validation Loss Energy: 0.9801490545895631, Validation Loss Force: 1.9319679508542584, time: 0.18077969551086426
Test Loss Energy: 7.910174314546347, Test Loss Force: 6.089477803346873, time: 12.675119876861572

Epoch 19, Batch 100/152, Loss: 0.2975180149078369, Uncertainty: 0.12424780428409576

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.50342816366307, Training Loss Force: 1.8661026045113691, time: 2.6833043098449707
Validation Loss Energy: 2.630055949118628, Validation Loss Force: 1.8692777537327976, time: 0.18224382400512695
Test Loss Energy: 9.233869209378723, Test Loss Force: 6.060257670448436, time: 12.60840129852295

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‡â–ƒâ–…â–†â–‚â–‚â–‡â–‚â–„â–ˆâ–‚â–‚â–ƒâ–†â–‚â–ƒâ–â–â–„â–ˆ
wandb:   test_error_force â–ƒâ–„â–ˆâ–‡â–„â–ƒâ–…â–„â–‚â–„â–ƒâ–ƒâ–„â–ƒâ–‚â–…â–‚â–â–‚â–
wandb:          test_loss â–ƒâ–…â–ˆâ–†â–ƒâ–ƒâ–†â–…â–ƒâ–…â–‚â–ƒâ–ƒâ–ƒâ–‚â–†â–‚â–‚â–â–„
wandb: train_error_energy â–ˆâ–â–„â–ƒâ–„â–ƒâ–‡â–„â–‚â–ƒâ–†â–ƒâ–…â–†â–ƒâ–ƒâ–„â–…â–†â–ˆ
wandb:  train_error_force â–ˆâ–â–‚â–ƒâ–ƒâ–ƒâ–‚â–â–‚â–ƒâ–ƒâ–ƒâ–„â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–ƒ
wandb: valid_error_energy â–„â–â–‚â–ƒâ–ˆâ–‚â–ƒâ–‚â–â–„â–â–„â–â–‚â–„â–â–†â–ƒâ–â–„
wandb:  valid_error_force â–‚â–‚â–ˆâ–ˆâ–„â–„â–„â–„â–ƒâ–„â–‚â–‡â–„â–â–ƒâ–„â–ƒâ–â–ƒâ–‚
wandb:         valid_loss â–ƒâ–â–‡â–ˆâ–‡â–„â–…â–„â–ƒâ–…â–â–ˆâ–ƒâ–â–„â–„â–…â–â–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4849
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.23387
wandb:   test_error_force 6.06026
wandb:          test_loss 3.46938
wandb: train_error_energy 2.50343
wandb:  train_error_force 1.8661
wandb:         train_loss -2.53311
wandb: valid_error_energy 2.63006
wandb:  valid_error_force 1.86928
wandb:         valid_loss -2.52043
wandb: 
wandb: ğŸš€ View run al_58_73 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/b4auwtzs
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_003551-b4auwtzs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.98225402832031, Uncertainty Bias: -5.330667018890381
3.0517578e-05 0.025331497
-0.1100235 15.094026
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3310 steps.
Found uncertainty sample 1 after 1502 steps.
Found uncertainty sample 2 after 3843 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 835 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3628 steps.
Found uncertainty sample 8 after 3870 steps.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 281 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Found uncertainty sample 15 after 1665 steps.
Found uncertainty sample 16 after 2551 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 592 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2471 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3064 steps.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 2945 steps.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1203 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1790 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2870 steps.
Found uncertainty sample 44 after 2507 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1780 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1391 steps.
Found uncertainty sample 54 after 1952 steps.
Found uncertainty sample 55 after 1610 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3471 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 1876 steps.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2331 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2565 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 1426 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2494 steps.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2891 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3509 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2703 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 997 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2097 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 954 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_011443-du01yhxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_74
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/du01yhxr
Training model 74. Added 33 samples to the dataset.
Epoch 0, Batch 100/153, Loss: 0.09919590502977371, Uncertainty: 0.12623795866966248

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 4.102899468908306, Training Loss Force: 1.9478057908617274, time: 2.295048475265503
Validation Loss Energy: 3.5034836158865814, Validation Loss Force: 1.9964760188830735, time: 0.1595461368560791
Test Loss Energy: 10.155345906972933, Test Loss Force: 6.022217475114569, time: 9.92863154411316

Epoch 1, Batch 100/153, Loss: 0.11146632581949234, Uncertainty: 0.12354099750518799

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.8082353650500043, Training Loss Force: 1.8771895290404237, time: 2.323584794998169
Validation Loss Energy: 1.5456739457477704, Validation Loss Force: 1.8994408502438944, time: 0.15281200408935547
Test Loss Energy: 6.766645663264577, Test Loss Force: 6.073881673981378, time: 10.123011350631714

Epoch 2, Batch 100/153, Loss: 0.19106848537921906, Uncertainty: 0.12351661175489426

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2230114987181024, Training Loss Force: 1.950347723617483, time: 2.5104610919952393
Validation Loss Energy: 5.804276249561184, Validation Loss Force: 2.362911758659808, time: 0.14525604248046875
Test Loss Energy: 7.060188756884858, Test Loss Force: 6.2785693234188775, time: 11.079832792282104

Epoch 3, Batch 100/153, Loss: 0.2220638394355774, Uncertainty: 0.13146010041236877

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.950829573680919, Training Loss Force: 1.9601470994759551, time: 2.553934335708618
Validation Loss Energy: 1.9692096252913511, Validation Loss Force: 1.888870226325362, time: 0.18034029006958008
Test Loss Energy: 8.403358514391803, Test Loss Force: 6.0518216085329035, time: 12.230607032775879

Epoch 4, Batch 100/153, Loss: 0.039468586444854736, Uncertainty: 0.12584847211837769

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.322767168397563, Training Loss Force: 1.8825922815099196, time: 2.497689962387085
Validation Loss Energy: 3.836682311592685, Validation Loss Force: 2.1028986218223733, time: 0.17996501922607422
Test Loss Energy: 6.865143378618648, Test Loss Force: 6.139955572040282, time: 11.698369026184082

Epoch 5, Batch 100/153, Loss: 0.34977635741233826, Uncertainty: 0.1261570155620575

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.3964412604616907, Training Loss Force: 1.9224276330828263, time: 2.477914333343506
Validation Loss Energy: 2.351290136372496, Validation Loss Force: 1.9258553487948216, time: 0.17901992797851562
Test Loss Energy: 6.682831315643598, Test Loss Force: 5.9630515247420846, time: 11.171107292175293

Epoch 6, Batch 100/153, Loss: 0.2898297905921936, Uncertainty: 0.12357465922832489

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.848631583306881, Training Loss Force: 1.8589986786770103, time: 2.473940134048462
Validation Loss Energy: 1.232560044115877, Validation Loss Force: 1.9331882148854669, time: 0.1585690975189209
Test Loss Energy: 6.7870125781751725, Test Loss Force: 6.050151895379892, time: 12.566604852676392

Epoch 7, Batch 100/153, Loss: 0.04699833691120148, Uncertainty: 0.12537971138954163

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8416528060573292, Training Loss Force: 1.8763725981492774, time: 2.5868194103240967
Validation Loss Energy: 1.804201730935769, Validation Loss Force: 1.8388651564436884, time: 0.15427207946777344
Test Loss Energy: 8.11900585311086, Test Loss Force: 6.089295186667844, time: 12.417500972747803

Epoch 8, Batch 100/153, Loss: 0.16277313232421875, Uncertainty: 0.12452264130115509

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 3.3602173337760024, Training Loss Force: 1.8825730271778895, time: 2.679354190826416
Validation Loss Energy: 15.598873849375474, Validation Loss Force: 2.075171191764008, time: 0.17964911460876465
Test Loss Energy: 11.219130749512972, Test Loss Force: 6.218192565847645, time: 12.366448402404785

Epoch 9, Batch 100/153, Loss: 0.11589948832988739, Uncertainty: 0.12432504445314407

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.637851365971645, Training Loss Force: 1.8630582712109922, time: 2.602972984313965
Validation Loss Energy: 1.533276507044522, Validation Loss Force: 1.865888989112447, time: 0.16803359985351562
Test Loss Energy: 8.277870356054299, Test Loss Force: 6.011023568391193, time: 12.043594360351562

Epoch 10, Batch 100/153, Loss: 0.18138793110847473, Uncertainty: 0.12337329238653183

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.034102004620983, Training Loss Force: 1.8439133570526505, time: 2.5325088500976562
Validation Loss Energy: 0.994473731862341, Validation Loss Force: 1.9382848889666082, time: 0.17868447303771973
Test Loss Energy: 7.845173966227734, Test Loss Force: 6.055664103895739, time: 12.33063292503357

Epoch 11, Batch 100/153, Loss: 0.13066688179969788, Uncertainty: 0.12475874274969101

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6376773323529532, Training Loss Force: 1.8661498074500231, time: 2.634084939956665
Validation Loss Energy: 0.9595458496321082, Validation Loss Force: 1.9350930380943059, time: 0.17348456382751465
Test Loss Energy: 7.517210673698323, Test Loss Force: 6.099338742614303, time: 12.187316656112671

Epoch 12, Batch 100/153, Loss: 0.05502142757177353, Uncertainty: 0.12509696185588837

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2506254078981156, Training Loss Force: 1.8624855727167586, time: 2.613515615463257
Validation Loss Energy: 1.7752917792664293, Validation Loss Force: 1.933583155727294, time: 0.17888283729553223
Test Loss Energy: 6.779663899466348, Test Loss Force: 6.031439169735674, time: 12.32949161529541

Epoch 13, Batch 100/153, Loss: 0.09593656659126282, Uncertainty: 0.12199905514717102

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6197705041257788, Training Loss Force: 1.8466728921397488, time: 2.5566413402557373
Validation Loss Energy: 0.8581517654595334, Validation Loss Force: 1.917755127715785, time: 0.16409635543823242
Test Loss Energy: 7.436490247409007, Test Loss Force: 6.088080418056751, time: 12.031455755233765

Epoch 14, Batch 100/153, Loss: 0.08416027575731277, Uncertainty: 0.12414909899234772

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.7786832725283968, Training Loss Force: 1.86255427269737, time: 2.5659334659576416
Validation Loss Energy: 3.0127376668937784, Validation Loss Force: 1.9166751081349866, time: 0.16180944442749023
Test Loss Energy: 9.550913849223337, Test Loss Force: 6.075177174730457, time: 12.323744535446167

Epoch 15, Batch 100/153, Loss: 0.05569553002715111, Uncertainty: 0.12251287698745728

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7541911605440499, Training Loss Force: 1.8435753256418543, time: 2.522573471069336
Validation Loss Energy: 3.6840496632488073, Validation Loss Force: 1.9217823590005594, time: 0.17684102058410645
Test Loss Energy: 10.057658816895904, Test Loss Force: 6.0216030644899545, time: 12.287863969802856

Epoch 16, Batch 100/153, Loss: 0.19286999106407166, Uncertainty: 0.12231320142745972

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0891753622699154, Training Loss Force: 1.836294607064296, time: 2.545292615890503
Validation Loss Energy: 4.690507151652788, Validation Loss Force: 1.967721230496921, time: 0.17851591110229492
Test Loss Energy: 6.7809924555084296, Test Loss Force: 6.090216780454434, time: 12.454487323760986

Epoch 17, Batch 100/153, Loss: 0.06226196512579918, Uncertainty: 0.1246141791343689

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3697638231225624, Training Loss Force: 1.861749753791917, time: 2.6768553256988525
Validation Loss Energy: 1.0985318482525581, Validation Loss Force: 1.86769654301604, time: 0.17961835861206055
Test Loss Energy: 7.011294489913354, Test Loss Force: 6.066040702936083, time: 12.25045895576477

Epoch 18, Batch 100/153, Loss: 0.15723446011543274, Uncertainty: 0.12441534548997879

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8316265481672422, Training Loss Force: 1.8745257380476894, time: 2.5970277786254883
Validation Loss Energy: 0.7670077915256903, Validation Loss Force: 1.8738529737857004, time: 0.17739653587341309
Test Loss Energy: 7.244417968563749, Test Loss Force: 5.970116592907419, time: 12.278976202011108

Epoch 19, Batch 100/153, Loss: 0.21315453946590424, Uncertainty: 0.12246948480606079

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.967301840073497, Training Loss Force: 1.8549306327199286, time: 2.5804338455200195
Validation Loss Energy: 2.8458227968609466, Validation Loss Force: 1.8918019625236957, time: 0.17369318008422852
Test Loss Energy: 9.121063793622692, Test Loss Force: 6.04805973339058, time: 11.855216979980469

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–†â–â–‚â–„â–â–â–â–ƒâ–ˆâ–ƒâ–ƒâ–‚â–â–‚â–…â–†â–â–‚â–‚â–…
wandb:   test_error_force â–‚â–ƒâ–ˆâ–ƒâ–…â–â–ƒâ–„â–‡â–‚â–ƒâ–„â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–â–ƒ
wandb:          test_loss â–„â–ƒâ–„â–‚â–„â–â–ƒâ–„â–ˆâ–„â–„â–„â–ƒâ–„â–…â–†â–…â–„â–‚â–…
wandb: train_error_energy â–ˆâ–‚â–ƒâ–…â–ƒâ–ƒâ–„â–‚â–†â–„â–‚â–â–ƒâ–â–„â–â–‚â–ƒâ–‚â–‚
wandb:  train_error_force â–‡â–ƒâ–‡â–ˆâ–„â–†â–‚â–ƒâ–„â–ƒâ–â–ƒâ–‚â–‚â–‚â–â–â–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–‚â–…â–‡â–ƒâ–…â–ƒâ–‚â–…â–ƒâ–‚â–‚â–‚â–â–ƒâ–â–â–ƒâ–‚â–‚
wandb: valid_error_energy â–‚â–â–ƒâ–‚â–‚â–‚â–â–â–ˆâ–â–â–â–â–â–‚â–‚â–ƒâ–â–â–‚
wandb:  valid_error_force â–ƒâ–‚â–ˆâ–‚â–…â–‚â–‚â–â–„â–â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–â–â–‚
wandb:         valid_loss â–ƒâ–â–†â–‚â–„â–‚â–‚â–â–ˆâ–â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–â–â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 4878
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.12106
wandb:   test_error_force 6.04806
wandb:          test_loss 3.46843
wandb: train_error_energy 1.9673
wandb:  train_error_force 1.85493
wandb:         train_loss -2.58414
wandb: valid_error_energy 2.84582
wandb:  valid_error_force 1.8918
wandb:         valid_loss -2.47569
wandb: 
wandb: ğŸš€ View run al_58_74 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/du01yhxr
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_011443-du01yhxr/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 45.0268669128418, Uncertainty Bias: -5.457268238067627
8.392334e-05 0.0015239716
-0.08542657 16.974735
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 2422 steps.
Found uncertainty sample 7 after 2770 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2250 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2902 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 1182 steps.
Found uncertainty sample 18 after 2266 steps.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2804 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 3037 steps.
Found uncertainty sample 27 after 1785 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2653 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3778 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3711 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2852 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 1541 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3115 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2132 steps.
Found uncertainty sample 57 after 3815 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 36 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 3824 steps.
Found uncertainty sample 78 after 2107 steps.
Found uncertainty sample 79 after 3632 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1469 steps.
Found uncertainty sample 82 after 2128 steps.
Found uncertainty sample 83 after 2570 steps.
Found uncertainty sample 84 after 1124 steps.
Found uncertainty sample 85 after 1303 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2265 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3333 steps.
Found uncertainty sample 97 after 1856 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_015442-5ejwvr87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_75
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5ejwvr87
Training model 75. Added 29 samples to the dataset.
Epoch 0, Batch 100/154, Loss: 0.11056101322174072, Uncertainty: 0.12599226832389832

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1802028674560217, Training Loss Force: 1.982465126295982, time: 2.4358749389648438
Validation Loss Energy: 1.20107696490772, Validation Loss Force: 1.8450752875890417, time: 0.16866445541381836
Test Loss Energy: 8.204686942270595, Test Loss Force: 6.012796604691143, time: 12.495040655136108

Epoch 1, Batch 100/154, Loss: 0.08707955479621887, Uncertainty: 0.12486124783754349

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7468858459564474, Training Loss Force: 1.8822911162592832, time: 2.4753732681274414
Validation Loss Energy: 1.0021746329396806, Validation Loss Force: 1.992961371972225, time: 0.17099809646606445
Test Loss Energy: 7.1667562655597425, Test Loss Force: 6.028766340240907, time: 11.513876914978027

Epoch 2, Batch 100/154, Loss: 0.11574368178844452, Uncertainty: 0.12358933687210083

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.3546366860314714, Training Loss Force: 1.8479464674190398, time: 2.4013617038726807
Validation Loss Energy: 2.839932678389816, Validation Loss Force: 1.857636981898936, time: 0.15385174751281738
Test Loss Energy: 9.30471775646728, Test Loss Force: 5.9788506514253985, time: 11.275208711624146

Epoch 3, Batch 100/154, Loss: 0.11313670873641968, Uncertainty: 0.1232421025633812

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.3328498457558373, Training Loss Force: 1.8427403579592412, time: 2.37605357170105
Validation Loss Energy: 0.7068048644315295, Validation Loss Force: 1.9394483352540808, time: 0.17137765884399414
Test Loss Energy: 7.019460098583726, Test Loss Force: 6.087786520431883, time: 11.298383951187134

Epoch 4, Batch 100/154, Loss: 0.05635511130094528, Uncertainty: 0.12333427369594574

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.712577769531861, Training Loss Force: 1.8665675745395816, time: 2.7248830795288086
Validation Loss Energy: 3.1003604994000167, Validation Loss Force: 1.9010171251279173, time: 0.16181683540344238
Test Loss Energy: 9.297294895124457, Test Loss Force: 5.939570135321589, time: 11.370157957077026

Epoch 5, Batch 100/154, Loss: 0.0931195616722107, Uncertainty: 0.12437428534030914

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.018105196992719, Training Loss Force: 1.8852640421528875, time: 2.5430104732513428
Validation Loss Energy: 3.1220069835291917, Validation Loss Force: 1.87612056214478, time: 0.16208124160766602
Test Loss Energy: 6.695223762943974, Test Loss Force: 6.0363361562252, time: 11.227776527404785

Epoch 6, Batch 100/154, Loss: 0.14682021737098694, Uncertainty: 0.12495804578065872

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0607234338798337, Training Loss Force: 1.8580615813552623, time: 2.559201717376709
Validation Loss Energy: 2.180063797890113, Validation Loss Force: 2.030642335522709, time: 0.16562819480895996
Test Loss Energy: 8.672502450983727, Test Loss Force: 6.175761852574411, time: 11.43581223487854

Epoch 7, Batch 100/154, Loss: 0.07780995219945908, Uncertainty: 0.12274754047393799

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8745038437722086, Training Loss Force: 1.854877248458442, time: 2.4842259883880615
Validation Loss Energy: 0.996086413151723, Validation Loss Force: 1.9383297567995124, time: 0.16129469871520996
Test Loss Energy: 7.507578213959141, Test Loss Force: 6.042325627493071, time: 11.22001600265503

Epoch 8, Batch 100/154, Loss: 0.10919836163520813, Uncertainty: 0.12303191423416138

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7596194937429692, Training Loss Force: 1.851011276868169, time: 2.5324552059173584
Validation Loss Energy: 2.023720739344592, Validation Loss Force: 2.02352456782703, time: 0.1641407012939453
Test Loss Energy: 6.5968572848207705, Test Loss Force: 6.114611027103511, time: 12.140183448791504

Epoch 9, Batch 100/154, Loss: 0.18651464581489563, Uncertainty: 0.12383218109607697

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.9335651994126448, Training Loss Force: 1.8658979838374163, time: 2.4880919456481934
Validation Loss Energy: 7.864606245856909, Validation Loss Force: 2.0120031466553856, time: 0.16968822479248047
Test Loss Energy: 7.459944986480413, Test Loss Force: 5.939107365882771, time: 11.871886968612671

Epoch 10, Batch 100/154, Loss: 0.09294255077838898, Uncertainty: 0.12383341044187546

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2764346826546134, Training Loss Force: 1.8579512097540591, time: 2.664977788925171
Validation Loss Energy: 2.4299786662905767, Validation Loss Force: 1.9790614732068288, time: 0.18090462684631348
Test Loss Energy: 6.679328611065834, Test Loss Force: 6.057825720005666, time: 12.6208975315094

Epoch 11, Batch 100/154, Loss: 0.06734928488731384, Uncertainty: 0.12249555438756943

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1556613843721792, Training Loss Force: 1.8297549360728582, time: 2.7184267044067383
Validation Loss Energy: 2.4742422493560263, Validation Loss Force: 1.9614117889124845, time: 0.17837238311767578
Test Loss Energy: 9.099020261649754, Test Loss Force: 6.086687740295484, time: 11.76526165008545

Epoch 12, Batch 100/154, Loss: 0.14688576757907867, Uncertainty: 0.12331177294254303

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9691438264382377, Training Loss Force: 1.8699113558957283, time: 2.634794235229492
Validation Loss Energy: 4.115317120657963, Validation Loss Force: 1.9657929156931866, time: 0.1696028709411621
Test Loss Energy: 6.667812382010173, Test Loss Force: 5.925254658986628, time: 10.705907106399536

Epoch 13, Batch 100/154, Loss: 0.09334000945091248, Uncertainty: 0.12307367473840714

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.7281461573943744, Training Loss Force: 1.862417728706321, time: 2.5825846195220947
Validation Loss Energy: 1.402451295510801, Validation Loss Force: 1.9722139516312573, time: 0.1810753345489502
Test Loss Energy: 8.115393625624284, Test Loss Force: 6.060769128652755, time: 12.500399112701416

Epoch 14, Batch 100/154, Loss: 0.06542789936065674, Uncertainty: 0.12881255149841309

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.860828133348018, Training Loss Force: 1.958853794682137, time: 2.3391025066375732
Validation Loss Energy: 1.7354076900746118, Validation Loss Force: 1.8496079407235477, time: 0.1495828628540039
Test Loss Energy: 8.344984088713703, Test Loss Force: 5.951519869727581, time: 10.219723463058472

Epoch 15, Batch 100/154, Loss: 0.04948163405060768, Uncertainty: 0.12397390604019165

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9164618937523392, Training Loss Force: 1.8452266404344202, time: 2.3197274208068848
Validation Loss Energy: 5.912155294272473, Validation Loss Force: 1.9140085337779282, time: 0.14645695686340332
Test Loss Energy: 6.944415005195468, Test Loss Force: 5.967518964962008, time: 10.096264839172363

Epoch 16, Batch 100/154, Loss: 0.09847566485404968, Uncertainty: 0.1224999949336052

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9092730406187106, Training Loss Force: 1.8307532478853135, time: 2.336153745651245
Validation Loss Energy: 1.6958085431665326, Validation Loss Force: 1.9646700694133212, time: 0.14546918869018555
Test Loss Energy: 8.071034823713882, Test Loss Force: 5.976083496482477, time: 10.041009187698364

Epoch 17, Batch 100/154, Loss: 0.19788965582847595, Uncertainty: 0.12516531348228455

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1206052092892547, Training Loss Force: 1.8594566288578112, time: 2.5876660346984863
Validation Loss Energy: 0.8159463875329426, Validation Loss Force: 1.9102702157099951, time: 0.14449286460876465
Test Loss Energy: 6.863179516026444, Test Loss Force: 6.0354422200449855, time: 10.162587642669678

Epoch 18, Batch 100/154, Loss: 0.16019922494888306, Uncertainty: 0.12267132103443146

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.1419791338526504, Training Loss Force: 1.8457997582832084, time: 2.3623576164245605
Validation Loss Energy: 3.5073831464161653, Validation Loss Force: 1.9508166713878996, time: 0.1494452953338623
Test Loss Energy: 6.751055871226191, Test Loss Force: 6.093328990967048, time: 9.996256113052368

Epoch 19, Batch 100/154, Loss: 0.12541088461875916, Uncertainty: 0.12211928516626358

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7473614130307655, Training Loss Force: 1.8503718744631672, time: 2.3696208000183105
Validation Loss Energy: 2.1996499986350675, Validation Loss Force: 2.338562887552604, time: 0.14425969123840332
Test Loss Energy: 8.502635294294544, Test Loss Force: 6.13661344106191, time: 10.240436792373657

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–‚â–ˆâ–‚â–ˆâ–â–†â–ƒâ–â–ƒâ–â–‡â–â–…â–†â–‚â–…â–‚â–â–†
wandb:   test_error_force â–ƒâ–„â–‚â–†â–â–„â–ˆâ–„â–†â–â–…â–†â–â–…â–‚â–‚â–‚â–„â–†â–‡
wandb:          test_loss â–…â–ƒâ–…â–…â–ƒâ–ƒâ–ˆâ–„â–†â–ƒâ–„â–ˆâ–â–…â–‚â–„â–…â–…â–…â–‡
wandb: train_error_energy â–ˆâ–â–„â–„â–†â–‚â–ƒâ–‚â–â–‚â–„â–ƒâ–‚â–â–†â–‚â–‚â–ƒâ–ƒâ–
wandb:  train_error_force â–ˆâ–ƒâ–‚â–‚â–ƒâ–„â–‚â–‚â–‚â–ƒâ–‚â–â–ƒâ–‚â–‡â–‚â–â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–â–‚â–‚â–‡â–â–â–‚â–‚â–
wandb: valid_error_energy â–â–â–ƒâ–â–ƒâ–ƒâ–‚â–â–‚â–ˆâ–ƒâ–ƒâ–„â–‚â–‚â–†â–‚â–â–„â–‚
wandb:  valid_error_force â–â–ƒâ–â–‚â–‚â–â–„â–‚â–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–â–‚â–ƒâ–‚â–‚â–ˆ
wandb:         valid_loss â–â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–‚â–„â–‡â–ƒâ–ƒâ–„â–ƒâ–â–…â–ƒâ–‚â–„â–ˆ
wandb: 
wandb: Run summary:
wandb:       dataset_size 4904
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.50264
wandb:   test_error_force 6.13661
wandb:          test_loss 3.61825
wandb: train_error_energy 1.74736
wandb:  train_error_force 1.85037
wandb:         train_loss -2.60519
wandb: valid_error_energy 2.19965
wandb:  valid_error_force 2.33856
wandb:         valid_loss -1.90682
wandb: 
wandb: ğŸš€ View run al_58_75 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/5ejwvr87
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_015442-5ejwvr87/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 41.886993408203125, Uncertainty Bias: -4.967653751373291
3.2424927e-05 0.00793457
0.6219274 16.50527
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1345 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3354 steps.
Found uncertainty sample 12 after 3720 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 3026 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3052 steps.
Found uncertainty sample 19 after 2780 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2926 steps.
Found uncertainty sample 23 after 1040 steps.
Found uncertainty sample 24 after 1477 steps.
Found uncertainty sample 25 after 2659 steps.
Found uncertainty sample 26 after 1634 steps.
Found uncertainty sample 27 after 292 steps.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2638 steps.
Found uncertainty sample 30 after 2924 steps.
Found uncertainty sample 31 after 2689 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1763 steps.
Found uncertainty sample 36 after 927 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3216 steps.
Found uncertainty sample 39 after 2524 steps.
Found uncertainty sample 40 after 2763 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 981 steps.
Found uncertainty sample 43 after 2151 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1413 steps.
Found uncertainty sample 48 after 3913 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2273 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2689 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2542 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 697 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 736 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 464 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 3086 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 2120 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1894 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3563 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2559 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2084 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1396 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_023241-h9q9c9iy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_76
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/h9q9c9iy
Training model 76. Added 37 samples to the dataset.
Epoch 0, Batch 100/155, Loss: 0.2396983951330185, Uncertainty: 0.1252261996269226

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0504735127621476, Training Loss Force: 1.9895143654833214, time: 2.572669267654419
Validation Loss Energy: 3.2474689489025717, Validation Loss Force: 1.9839629406700399, time: 0.16632580757141113
Test Loss Energy: 9.111429760043997, Test Loss Force: 6.086625994491061, time: 12.280120134353638

Epoch 1, Batch 100/155, Loss: 0.12353391200304031, Uncertainty: 0.12321090698242188

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7132967926892233, Training Loss Force: 1.8596798027546744, time: 2.498497724533081
Validation Loss Energy: 0.9891873251131073, Validation Loss Force: 1.9190277932193354, time: 0.1575453281402588
Test Loss Energy: 6.837713041662266, Test Loss Force: 6.002714418562381, time: 12.063249588012695

Epoch 2, Batch 100/155, Loss: 0.15103332698345184, Uncertainty: 0.1231715977191925

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8580429898761743, Training Loss Force: 1.872731550433506, time: 2.596689224243164
Validation Loss Energy: 0.8142287919643044, Validation Loss Force: 1.9908027430485522, time: 0.16355657577514648
Test Loss Energy: 7.057863281931282, Test Loss Force: 5.961899343648103, time: 11.951497077941895

Epoch 3, Batch 100/155, Loss: 0.0853942483663559, Uncertainty: 0.12413617968559265

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7553672765697796, Training Loss Force: 1.8440818635602358, time: 2.5531585216522217
Validation Loss Energy: 1.1518806293640562, Validation Loss Force: 1.873800275421164, time: 0.19419026374816895
Test Loss Energy: 7.5630651500909565, Test Loss Force: 5.896745020197987, time: 12.095793008804321

Epoch 4, Batch 100/155, Loss: 0.1789010614156723, Uncertainty: 0.12173155695199966

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.772374622749426, Training Loss Force: 1.839000412865801, time: 2.5295677185058594
Validation Loss Energy: 0.934500636438302, Validation Loss Force: 1.9352984874929489, time: 0.17546486854553223
Test Loss Energy: 6.8815023631516326, Test Loss Force: 5.879862952032811, time: 11.884907960891724

Epoch 5, Batch 100/155, Loss: 0.11398083716630936, Uncertainty: 0.1230020672082901

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.9454335268662197, Training Loss Force: 1.8995968192063035, time: 2.6471786499023438
Validation Loss Energy: 3.773431062446535, Validation Loss Force: 1.99745580023668, time: 0.17983126640319824
Test Loss Energy: 9.879729768726067, Test Loss Force: 5.994417309188749, time: 11.883610248565674

Epoch 6, Batch 100/155, Loss: 0.04489794373512268, Uncertainty: 0.12555792927742004

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0495055200933825, Training Loss Force: 1.850912926294485, time: 2.628459930419922
Validation Loss Energy: 3.864471272558376, Validation Loss Force: 1.9897406112224767, time: 0.16992545127868652
Test Loss Energy: 10.038110135319135, Test Loss Force: 5.941491278080373, time: 11.822449445724487

Epoch 7, Batch 100/155, Loss: 0.05132042616605759, Uncertainty: 0.12161171436309814

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7865291641543866, Training Loss Force: 1.8265894689197077, time: 2.6498401165008545
Validation Loss Energy: 2.1338183109798083, Validation Loss Force: 1.8693456307107812, time: 0.1692054271697998
Test Loss Energy: 8.287245676064794, Test Loss Force: 5.872994872615776, time: 11.934803247451782

Epoch 8, Batch 100/155, Loss: 0.24004413187503815, Uncertainty: 0.12297603487968445

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.35982149052931, Training Loss Force: 1.8832926805058297, time: 2.798508882522583
Validation Loss Energy: 2.641342231672173, Validation Loss Force: 2.125715083867302, time: 0.16435575485229492
Test Loss Energy: 8.914640019667956, Test Loss Force: 6.072570441832012, time: 12.003129720687866

Epoch 9, Batch 100/155, Loss: 0.08935487270355225, Uncertainty: 0.12444978952407837

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1927015428116516, Training Loss Force: 1.859504292060704, time: 2.6280276775360107
Validation Loss Energy: 1.0146727180968884, Validation Loss Force: 1.9070094116255045, time: 0.1793053150177002
Test Loss Energy: 6.655530394927475, Test Loss Force: 5.937451863917659, time: 12.043047666549683

Epoch 10, Batch 100/155, Loss: 0.05581570416688919, Uncertainty: 0.1217506006360054

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.567524909946516, Training Loss Force: 1.8494038112980247, time: 2.7640528678894043
Validation Loss Energy: 0.7683554408641319, Validation Loss Force: 2.0271620909949064, time: 0.1744675636291504
Test Loss Energy: 6.835669251338937, Test Loss Force: 6.003701833814833, time: 12.0394446849823

Epoch 11, Batch 100/155, Loss: 0.04866420105099678, Uncertainty: 0.12432928383350372

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.3629222661294893, Training Loss Force: 1.8519319795419873, time: 2.5815179347991943
Validation Loss Energy: 1.5066162559795393, Validation Loss Force: 1.847720782600285, time: 0.16607046127319336
Test Loss Energy: 8.01019993894749, Test Loss Force: 5.883156562121898, time: 11.57982850074768

Epoch 12, Batch 100/155, Loss: 0.07672682404518127, Uncertainty: 0.12434321641921997

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6823542471425317, Training Loss Force: 1.889926533078694, time: 2.6490585803985596
Validation Loss Energy: 1.6696904914718844, Validation Loss Force: 1.9181401968921428, time: 0.23821640014648438
Test Loss Energy: 6.580640904137356, Test Loss Force: 5.951156450365286, time: 12.247766733169556

Epoch 13, Batch 100/155, Loss: 0.06214821711182594, Uncertainty: 0.12184569239616394

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.255570333397608, Training Loss Force: 1.827220575770286, time: 2.607407331466675
Validation Loss Energy: 3.3224034996894556, Validation Loss Force: 1.9534038270829104, time: 0.1530923843383789
Test Loss Energy: 9.039854211017861, Test Loss Force: 5.985802610659445, time: 11.152828454971313

Epoch 14, Batch 100/155, Loss: 0.1987067013978958, Uncertainty: 0.12369216233491898

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2618124401914597, Training Loss Force: 1.8729740112750688, time: 2.6652140617370605
Validation Loss Energy: 4.262934591828109, Validation Loss Force: 1.8661347045149783, time: 0.178208589553833
Test Loss Energy: 6.642242866624363, Test Loss Force: 5.898045501274768, time: 11.448998212814331

Epoch 15, Batch 100/155, Loss: 0.13523976504802704, Uncertainty: 0.12253261357545853

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6903615345000793, Training Loss Force: 1.8319250411360768, time: 2.6345670223236084
Validation Loss Energy: 2.1328652870352376, Validation Loss Force: 1.971691792484057, time: 0.1520369052886963
Test Loss Energy: 8.52623958076229, Test Loss Force: 5.979107471722954, time: 11.34942889213562

Epoch 16, Batch 100/155, Loss: 0.062369201332330704, Uncertainty: 0.12260791659355164

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8014054211542718, Training Loss Force: 1.853789575343263, time: 2.5097532272338867
Validation Loss Energy: 0.8795178905782235, Validation Loss Force: 2.1719711846735623, time: 0.15615248680114746
Test Loss Energy: 7.257927198392941, Test Loss Force: 6.0066474435056225, time: 12.084072828292847

Epoch 17, Batch 100/155, Loss: 0.24034395813941956, Uncertainty: 0.12192745506763458

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9132610607499763, Training Loss Force: 1.843917663740591, time: 2.4892351627349854
Validation Loss Energy: 0.7817325124748895, Validation Loss Force: 1.8515120959249491, time: 0.16910839080810547
Test Loss Energy: 7.18275521157087, Test Loss Force: 5.956900223134827, time: 11.220470428466797

Epoch 18, Batch 100/155, Loss: 0.16957569122314453, Uncertainty: 0.12238479405641556

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.790989531701249, Training Loss Force: 1.8560242462591283, time: 2.4599111080169678
Validation Loss Energy: 4.364766239428193, Validation Loss Force: 2.036790453310921, time: 0.1555624008178711
Test Loss Energy: 10.54401219185431, Test Loss Force: 5.991225814470502, time: 11.170746326446533

Epoch 19, Batch 100/155, Loss: 0.07749348878860474, Uncertainty: 0.12201738357543945

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.7517675967415411, Training Loss Force: 1.8526132530328547, time: 2.660977840423584
Validation Loss Energy: 2.954318041322067, Validation Loss Force: 2.002042339304501, time: 0.16992473602294922
Test Loss Energy: 6.628684959687744, Test Loss Force: 5.942948396991954, time: 10.770431756973267

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–‚â–ƒâ–‚â–‡â–‡â–„â–…â–â–â–„â–â–…â–â–„â–‚â–‚â–ˆâ–
wandb:   test_error_force â–ˆâ–…â–„â–‚â–â–…â–ƒâ–â–ˆâ–ƒâ–…â–â–„â–…â–‚â–„â–…â–„â–…â–ƒ
wandb:          test_loss â–ˆâ–„â–ƒâ–ƒâ–â–„â–†â–ƒâ–†â–‚â–‚â–â–â–‡â–â–†â–„â–‚â–…â–ƒ
wandb: train_error_energy â–ˆâ–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–…â–„â–â–…â–‚â–„â–„â–‚â–‚â–ƒâ–‚â–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–„â–‚â–â–ƒâ–‚â–‚â–‚â–„â–â–ƒâ–â–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–â–â–ƒâ–‚â–â–„â–ƒâ–â–ƒâ–ƒâ–‚â–ƒâ–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–†â–â–â–‚â–â–‡â–‡â–„â–…â–â–â–‚â–ƒâ–†â–ˆâ–„â–â–â–ˆâ–…
wandb:  valid_error_force â–„â–ƒâ–„â–‚â–ƒâ–„â–„â–â–‡â–‚â–…â–â–ƒâ–ƒâ–â–„â–ˆâ–â–…â–„
wandb:         valid_loss â–†â–ƒâ–„â–‚â–ƒâ–‡â–‡â–ƒâ–ˆâ–‚â–„â–‚â–ƒâ–…â–…â–…â–‡â–â–ˆâ–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 4937
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.62868
wandb:   test_error_force 5.94295
wandb:          test_loss 3.23686
wandb: train_error_energy 1.75177
wandb:  train_error_force 1.85261
wandb:         train_loss -2.60213
wandb: valid_error_energy 2.95432
wandb:  valid_error_force 2.00204
wandb:         valid_loss -2.31659
wandb: 
wandb: ğŸš€ View run al_58_76 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/h9q9c9iy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_023241-h9q9c9iy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.87711715698242, Uncertainty Bias: -5.10957145690918
3.8146973e-05 0.15396118
0.09401982 13.933438
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2636 steps.
Found uncertainty sample 4 after 3744 steps.
Found uncertainty sample 5 after 1553 steps.
Found uncertainty sample 6 after 1731 steps.
Found uncertainty sample 7 after 2671 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1836 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 3290 steps.
Found uncertainty sample 12 after 2047 steps.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1398 steps.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3339 steps.
Found uncertainty sample 17 after 1942 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2139 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 206 steps.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3321 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3700 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 1735 steps.
Found uncertainty sample 38 after 2035 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2096 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3149 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 3233 steps.
Found uncertainty sample 49 after 3488 steps.
Found uncertainty sample 50 after 1671 steps.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 20 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2270 steps.
Found uncertainty sample 57 after 3508 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 3067 steps.
Found uncertainty sample 61 after 1553 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1341 steps.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Found uncertainty sample 68 after 2342 steps.
Found uncertainty sample 69 after 698 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3073 steps.
Found uncertainty sample 74 after 2488 steps.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 1395 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 1645 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 896 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2524 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1118 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2729 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_031049-vawm2lr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_77
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vawm2lr5
Training model 77. Added 38 samples to the dataset.
Epoch 0, Batch 100/156, Loss: 0.09588247537612915, Uncertainty: 0.12471278756856918

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.049642393312103, Training Loss Force: 1.980238757097091, time: 2.6607472896575928
Validation Loss Energy: 1.2290418344986938, Validation Loss Force: 1.8629407753973144, time: 0.1743018627166748
Test Loss Energy: 7.569453220114565, Test Loss Force: 5.901892116599705, time: 12.151081562042236

Epoch 1, Batch 100/156, Loss: 0.20222599804401398, Uncertainty: 0.1244494765996933

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2844040953239224, Training Loss Force: 1.8521355766703784, time: 2.713899612426758
Validation Loss Energy: 1.5169393460308485, Validation Loss Force: 1.844907023937769, time: 0.18116140365600586
Test Loss Energy: 6.6971314429629825, Test Loss Force: 5.876315074763601, time: 12.436005353927612

Epoch 2, Batch 100/156, Loss: 0.22846761345863342, Uncertainty: 0.1254836916923523

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.6616013585592495, Training Loss Force: 1.8900383144081074, time: 2.6487433910369873
Validation Loss Energy: 1.4082710876433426, Validation Loss Force: 1.8950885220060656, time: 0.18530488014221191
Test Loss Energy: 6.78325490693306, Test Loss Force: 5.929578385508671, time: 12.355979919433594

Epoch 3, Batch 100/156, Loss: 0.09474851191043854, Uncertainty: 0.12608829140663147

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.672738148014327, Training Loss Force: 1.8805013377933675, time: 2.6878271102905273
Validation Loss Energy: 2.5687776970514955, Validation Loss Force: 2.0671092326665463, time: 0.18723034858703613
Test Loss Energy: 8.905684280608426, Test Loss Force: 5.997367355941162, time: 12.44925045967102

Epoch 4, Batch 100/156, Loss: 0.20551015436649323, Uncertainty: 0.12415388226509094

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.4998228116043693, Training Loss Force: 1.8551388353402773, time: 2.7145307064056396
Validation Loss Energy: 3.0801148268678733, Validation Loss Force: 1.8953132322858313, time: 0.17016863822937012
Test Loss Energy: 6.596372220487991, Test Loss Force: 5.853993418535135, time: 12.319547414779663

Epoch 5, Batch 100/156, Loss: 0.06404611468315125, Uncertainty: 0.12402193248271942

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.4664734216717377, Training Loss Force: 1.8597906856951214, time: 2.6090991497039795
Validation Loss Energy: 2.2684282670983884, Validation Loss Force: 1.8587556345765528, time: 0.18347477912902832
Test Loss Energy: 6.4635351432854105, Test Loss Force: 5.8848572997320385, time: 12.584148645401001

Epoch 6, Batch 100/156, Loss: 0.042816437780857086, Uncertainty: 0.12205737829208374

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.049412306829107, Training Loss Force: 1.8395618460939902, time: 2.6826558113098145
Validation Loss Energy: 0.7270034424393094, Validation Loss Force: 1.9451153392409914, time: 0.18887591361999512
Test Loss Energy: 7.025914001731265, Test Loss Force: 5.922435070705974, time: 12.265540361404419

Epoch 7, Batch 100/156, Loss: 0.08357804268598557, Uncertainty: 0.12268704175949097

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.095860385907523, Training Loss Force: 1.8479987907384412, time: 2.700937509536743
Validation Loss Energy: 2.9951347060085545, Validation Loss Force: 1.9807320113626277, time: 0.19319438934326172
Test Loss Energy: 9.41811431567089, Test Loss Force: 5.994902634662308, time: 13.129649877548218

Epoch 8, Batch 100/156, Loss: 0.07351681590080261, Uncertainty: 0.12201706320047379

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2997004789821935, Training Loss Force: 1.83254579751806, time: 2.7358617782592773
Validation Loss Energy: 1.8811586371290179, Validation Loss Force: 1.9756128476977477, time: 0.1835165023803711
Test Loss Energy: 8.518692194905576, Test Loss Force: 5.971992026703514, time: 12.340198040008545

Epoch 9, Batch 100/156, Loss: 0.10313719511032104, Uncertainty: 0.12311965972185135

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.028833150139412, Training Loss Force: 1.8408591722054517, time: 2.7200498580932617
Validation Loss Energy: 0.9362069872150709, Validation Loss Force: 1.9411553169267632, time: 0.17319321632385254
Test Loss Energy: 7.261135002751773, Test Loss Force: 5.96616442541247, time: 12.390994310379028

Epoch 10, Batch 100/156, Loss: 0.13797806203365326, Uncertainty: 0.1225099265575409

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.2560621658658553, Training Loss Force: 1.8355719447205843, time: 2.6370842456817627
Validation Loss Energy: 1.257872738621229, Validation Loss Force: 1.9090747792885576, time: 0.18900823593139648
Test Loss Energy: 6.66763556172378, Test Loss Force: 5.90876937324981, time: 11.768645763397217

Epoch 11, Batch 100/156, Loss: 0.1449771523475647, Uncertainty: 0.1234348714351654

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1309364044965493, Training Loss Force: 1.8529598407539503, time: 2.7248129844665527
Validation Loss Energy: 3.570118396928152, Validation Loss Force: 1.9529706613710323, time: 0.1837153434753418
Test Loss Energy: 6.468668585754999, Test Loss Force: 5.866923389153783, time: 12.558994054794312

Epoch 12, Batch 100/156, Loss: 0.1709868311882019, Uncertainty: 0.1222481057047844

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.000907644099971, Training Loss Force: 1.8340407724712253, time: 2.489046335220337
Validation Loss Energy: 1.540908714690343, Validation Loss Force: 1.9128698037656535, time: 0.17395305633544922
Test Loss Energy: 7.86019786153595, Test Loss Force: 5.893642541842596, time: 11.382720232009888

Epoch 13, Batch 100/156, Loss: 0.25516560673713684, Uncertainty: 0.12219143658876419

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8730082965795436, Training Loss Force: 1.8443590287464917, time: 2.446871757507324
Validation Loss Energy: 2.0994306983206457, Validation Loss Force: 1.8431802989341473, time: 0.15373706817626953
Test Loss Energy: 6.571010244404254, Test Loss Force: 5.830467217823378, time: 10.358532667160034

Epoch 14, Batch 100/156, Loss: 0.12266962230205536, Uncertainty: 0.12481659650802612

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.2407897244933954, Training Loss Force: 1.8599224380296102, time: 2.6300835609436035
Validation Loss Energy: 1.9759838144948636, Validation Loss Force: 1.790517413015155, time: 0.16210174560546875
Test Loss Energy: 8.244884395927652, Test Loss Force: 5.818748359844924, time: 11.02422833442688

Epoch 15, Batch 100/156, Loss: 0.3265695571899414, Uncertainty: 0.1217980682849884

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7355529392281817, Training Loss Force: 1.8415725870206086, time: 2.4849753379821777
Validation Loss Energy: 1.5386289908628097, Validation Loss Force: 1.8258078748380073, time: 0.14175057411193848
Test Loss Energy: 6.565467820501372, Test Loss Force: 5.859250240696095, time: 9.382848739624023

Epoch 16, Batch 100/156, Loss: 0.11424566805362701, Uncertainty: 0.12205041944980621

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.349667831779384, Training Loss Force: 1.8406469863514612, time: 2.4749646186828613
Validation Loss Energy: 3.198257212076314, Validation Loss Force: 1.9164741492307868, time: 0.14279580116271973
Test Loss Energy: 6.638245640687057, Test Loss Force: 5.89581031108212, time: 9.563910484313965

Epoch 17, Batch 100/156, Loss: 0.15459206700325012, Uncertainty: 0.12397103011608124

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8167539792921992, Training Loss Force: 1.8291328682995938, time: 2.6075892448425293
Validation Loss Energy: 1.928976799105486, Validation Loss Force: 1.8915512741769056, time: 0.14010858535766602
Test Loss Energy: 8.082587514550736, Test Loss Force: 5.909363475515672, time: 9.31821084022522

Epoch 18, Batch 100/156, Loss: 0.046834055334329605, Uncertainty: 0.1208881363272667

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.985341513186122, Training Loss Force: 1.8204494196327197, time: 2.406644344329834
Validation Loss Energy: 1.6236802916257769, Validation Loss Force: 1.8628952395569722, time: 0.14209413528442383
Test Loss Energy: 7.886491538953371, Test Loss Force: 5.824318357416079, time: 9.582505464553833

Epoch 19, Batch 100/156, Loss: 0.21848323941230774, Uncertainty: 0.12237053364515305

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.250282583356232, Training Loss Force: 1.8500467830712803, time: 2.5766026973724365
Validation Loss Energy: 2.8195943754929664, Validation Loss Force: 1.8796607046728375, time: 0.13670706748962402
Test Loss Energy: 8.795467919452784, Test Loss Force: 5.893597970707586, time: 9.291903734207153

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–„â–‚â–‚â–‡â–â–â–‚â–ˆâ–†â–ƒâ–â–â–„â–â–…â–â–â–…â–„â–‡
wandb:   test_error_force â–„â–ƒâ–…â–ˆâ–‚â–„â–…â–ˆâ–‡â–‡â–…â–ƒâ–„â–â–â–ƒâ–„â–…â–â–„
wandb:          test_loss â–‚â–‚â–â–†â–‚â–ƒâ–„â–ˆâ–‡â–…â–ƒâ–â–„â–â–ƒâ–‚â–ƒâ–†â–‚â–…
wandb: train_error_energy â–ˆâ–…â–†â–‚â–â–â–„â–„â–…â–ƒâ–„â–„â–ƒâ–ƒâ–„â–‚â–…â–ƒâ–ƒâ–„
wandb:  train_error_force â–ˆâ–‚â–„â–„â–ƒâ–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–â–â–‚
wandb:         train_loss â–ˆâ–ƒâ–„â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–â–‚â–â–â–‚
wandb: valid_error_energy â–‚â–ƒâ–ƒâ–†â–‡â–…â–â–‡â–„â–‚â–‚â–ˆâ–ƒâ–„â–„â–ƒâ–‡â–„â–ƒâ–†
wandb:  valid_error_force â–ƒâ–‚â–„â–ˆâ–„â–ƒâ–…â–†â–†â–…â–„â–…â–„â–‚â–â–‚â–„â–„â–ƒâ–ƒ
wandb:         valid_loss â–‚â–‚â–ƒâ–ˆâ–…â–ƒâ–ƒâ–‡â–…â–ƒâ–ƒâ–‡â–ƒâ–‚â–â–â–…â–ƒâ–‚â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 4971
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 8.79547
wandb:   test_error_force 5.8936
wandb:          test_loss 3.29836
wandb: train_error_energy 2.25028
wandb:  train_error_force 1.85005
wandb:         train_loss -2.57162
wandb: valid_error_energy 2.81959
wandb:  valid_error_force 1.87966
wandb:         valid_loss -2.49319
wandb: 
wandb: ğŸš€ View run al_58_77 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/vawm2lr5
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_031049-vawm2lr5/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.29354476928711, Uncertainty Bias: -5.0548834800720215
0.0 0.046398163
0.10910432 15.532516
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1250 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 3005 steps.
Found uncertainty sample 6 after 3133 steps.
Did not find any uncertainty samples for sample 7.
Found uncertainty sample 8 after 3301 steps.
Found uncertainty sample 9 after 469 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 2267 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2442 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3559 steps.
Found uncertainty sample 26 after 2024 steps.
Found uncertainty sample 27 after 2434 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 922 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 2079 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1510 steps.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 1403 steps.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 2237 steps.
Found uncertainty sample 44 after 2001 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2006 steps.
Found uncertainty sample 49 after 3112 steps.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 416 steps.
Found uncertainty sample 53 after 2037 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2501 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 2642 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2274 steps.
Found uncertainty sample 62 after 1362 steps.
Found uncertainty sample 63 after 3507 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 2329 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 518 steps.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 3790 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 3251 steps.
Found uncertainty sample 75 after 2698 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1339 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 2314 steps.
Found uncertainty sample 89 after 3081 steps.
Found uncertainty sample 90 after 1536 steps.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1271 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3828 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 3323 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_034857-m6wd1akf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_78
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m6wd1akf
Training model 78. Added 37 samples to the dataset.
Epoch 0, Batch 100/157, Loss: 0.28213852643966675, Uncertainty: 0.12508054077625275

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.5307186620925903, Training Loss Force: 1.9254587124054536, time: 2.674933910369873
Validation Loss Energy: 2.1893581564872364, Validation Loss Force: 1.9989885804141985, time: 0.19691967964172363
Test Loss Energy: 8.43880935901029, Test Loss Force: 6.017301525607622, time: 12.301973819732666

Epoch 1, Batch 100/157, Loss: 0.05264400690793991, Uncertainty: 0.1234593540430069

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2714512891369036, Training Loss Force: 1.8773359969502443, time: 2.737875461578369
Validation Loss Energy: 1.1683594079545394, Validation Loss Force: 1.919212719945028, time: 0.1867380142211914
Test Loss Energy: 7.412453343935899, Test Loss Force: 5.853951218651656, time: 12.379608869552612

Epoch 2, Batch 100/157, Loss: 0.053057968616485596, Uncertainty: 0.12175381183624268

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.633486567180336, Training Loss Force: 1.8376390422652478, time: 2.5658583641052246
Validation Loss Energy: 1.0797990641208963, Validation Loss Force: 1.9932367394826889, time: 0.17962288856506348
Test Loss Energy: 6.7839968941544155, Test Loss Force: 5.882765095773673, time: 12.336936235427856

Epoch 3, Batch 100/157, Loss: 0.048968955874443054, Uncertainty: 0.12274208664894104

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.83699620034121, Training Loss Force: 1.8428824312028838, time: 2.5324904918670654
Validation Loss Energy: 1.9420393134360967, Validation Loss Force: 1.8639705088626572, time: 0.17295455932617188
Test Loss Energy: 8.047061524341629, Test Loss Force: 5.8961753649058934, time: 12.369253635406494

Epoch 4, Batch 100/157, Loss: 0.05510294437408447, Uncertainty: 0.12286907434463501

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.00833202077508, Training Loss Force: 1.8516998095606532, time: 2.485785961151123
Validation Loss Energy: 1.6630666039418731, Validation Loss Force: 2.0459406707475805, time: 0.16791081428527832
Test Loss Energy: 7.980797872532955, Test Loss Force: 5.920110064406828, time: 12.409463167190552

Epoch 5, Batch 100/157, Loss: 0.19828692078590393, Uncertainty: 0.12383171170949936

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.5878159245111547, Training Loss Force: 1.8540390858021443, time: 2.453554391860962
Validation Loss Energy: 2.036113613330349, Validation Loss Force: 2.001964553549523, time: 0.17559385299682617
Test Loss Energy: 6.642609307758522, Test Loss Force: 5.8123703064354615, time: 12.493231058120728

Epoch 6, Batch 100/157, Loss: 0.037653978914022446, Uncertainty: 0.12267561256885529

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.0078476402141217, Training Loss Force: 1.8438222956845849, time: 2.4990313053131104
Validation Loss Energy: 0.7265632997608588, Validation Loss Force: 1.9271918090086801, time: 0.1774272918701172
Test Loss Energy: 7.035039057943036, Test Loss Force: 5.882086087780596, time: 12.440872430801392

Epoch 7, Batch 100/157, Loss: 0.24095837771892548, Uncertainty: 0.12389881908893585

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9999679446768197, Training Loss Force: 1.8486246004456721, time: 2.6212682723999023
Validation Loss Energy: 1.6120040040631398, Validation Loss Force: 1.8842929651386218, time: 0.19381260871887207
Test Loss Energy: 7.978862399673951, Test Loss Force: 5.849951446591761, time: 12.359513282775879

Epoch 8, Batch 100/157, Loss: 0.23732009530067444, Uncertainty: 0.12449581176042557

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.4334268184504384, Training Loss Force: 1.851217047251259, time: 2.61564564704895
Validation Loss Energy: 0.749397055776121, Validation Loss Force: 1.8224047851692686, time: 0.17305207252502441
Test Loss Energy: 7.103705549992522, Test Loss Force: 5.858625771488278, time: 12.384430170059204

Epoch 9, Batch 100/157, Loss: 0.2306424379348755, Uncertainty: 0.1226777508854866

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.263172437526835, Training Loss Force: 1.8358912390977078, time: 2.7531893253326416
Validation Loss Energy: 1.1021106609889582, Validation Loss Force: 2.1074297904959067, time: 0.18486785888671875
Test Loss Energy: 7.162019146190537, Test Loss Force: 5.946742399444873, time: 12.381990909576416

Epoch 10, Batch 100/157, Loss: 0.09182627499103546, Uncertainty: 0.12768694758415222

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0502601880248954, Training Loss Force: 1.8820439289960158, time: 2.7191171646118164
Validation Loss Energy: 4.5754528163831205, Validation Loss Force: 2.0115251502221274, time: 0.17536163330078125
Test Loss Energy: 6.606771629709014, Test Loss Force: 5.895790149615053, time: 12.305994987487793

Epoch 11, Batch 100/157, Loss: 0.05225783959031105, Uncertainty: 0.12307529151439667

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5700301944841817, Training Loss Force: 1.8234390195297365, time: 2.659562349319458
Validation Loss Energy: 1.500777017408253, Validation Loss Force: 1.9948217355749274, time: 0.18726801872253418
Test Loss Energy: 7.695849693696397, Test Loss Force: 5.947757264790045, time: 12.380599021911621

Epoch 12, Batch 100/157, Loss: 0.13139097392559052, Uncertainty: 0.12157690525054932

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6790828320573479, Training Loss Force: 1.8291673832854778, time: 2.7660367488861084
Validation Loss Energy: 1.7355328672461472, Validation Loss Force: 1.8587989066139115, time: 0.17831683158874512
Test Loss Energy: 7.85711887885578, Test Loss Force: 5.842541530370385, time: 12.172002077102661

Epoch 13, Batch 100/157, Loss: 0.1969779133796692, Uncertainty: 0.12004312872886658

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3467898427143545, Training Loss Force: 1.822285918138763, time: 2.673828601837158
Validation Loss Energy: 1.298890287988868, Validation Loss Force: 1.8400394392962627, time: 0.1788160800933838
Test Loss Energy: 6.445875710318239, Test Loss Force: 5.759105279622418, time: 11.760778665542603

Epoch 14, Batch 100/157, Loss: 0.13020148873329163, Uncertainty: 0.1221570074558258

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9478903298342034, Training Loss Force: 1.83009337703949, time: 2.7445902824401855
Validation Loss Energy: 0.7351541537471852, Validation Loss Force: 1.8263648074834968, time: 0.19057488441467285
Test Loss Energy: 6.78986981736021, Test Loss Force: 5.7396812018344185, time: 12.21565866470337

Epoch 15, Batch 100/157, Loss: 0.15536533296108246, Uncertainty: 0.12227705121040344

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.813106090433278, Training Loss Force: 1.832900812323745, time: 2.728682518005371
Validation Loss Energy: 0.7865171899710615, Validation Loss Force: 2.0430084149879058, time: 0.17411088943481445
Test Loss Energy: 6.963430959584156, Test Loss Force: 5.953368828045643, time: 11.950634956359863

Epoch 16, Batch 100/157, Loss: 0.05206730589270592, Uncertainty: 0.12294584512710571

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.8545998588994534, Training Loss Force: 1.858766805618132, time: 2.5179879665374756
Validation Loss Energy: 1.70001769514353, Validation Loss Force: 1.840439093301679, time: 0.13809943199157715
Test Loss Energy: 7.958066836165184, Test Loss Force: 5.75279305700527, time: 9.818970680236816

Epoch 17, Batch 100/157, Loss: 0.0799923986196518, Uncertainty: 0.12153182178735733

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.825726507466364, Training Loss Force: 1.8362580262389439, time: 2.4577410221099854
Validation Loss Energy: 0.7619051981564199, Validation Loss Force: 2.1142594985398038, time: 0.14287710189819336
Test Loss Energy: 6.900319127748316, Test Loss Force: 6.062558623816592, time: 9.141587257385254

Epoch 18, Batch 100/157, Loss: 0.09215404838323593, Uncertainty: 0.12270258367061615

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.6021374149538055, Training Loss Force: 1.8461750044068475, time: 2.3704397678375244
Validation Loss Energy: 1.8629293450478233, Validation Loss Force: 2.0092832430378778, time: 0.1486361026763916
Test Loss Energy: 6.293480797621959, Test Loss Force: 5.733466226177882, time: 9.328706979751587

Epoch 19, Batch 100/157, Loss: 0.057411856949329376, Uncertainty: 0.12287463247776031

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9309121545799701, Training Loss Force: 1.8508724100169431, time: 2.447655439376831
Validation Loss Energy: 1.3948773158466405, Validation Loss Force: 1.9108044361026002, time: 0.1412513256072998
Test Loss Energy: 7.2383039448026185, Test Loss Force: 5.824758046206983, time: 9.089980363845825

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ˆâ–…â–ƒâ–‡â–‡â–‚â–ƒâ–†â–„â–„â–‚â–†â–†â–â–ƒâ–ƒâ–†â–ƒâ–â–„
wandb:   test_error_force â–‡â–„â–„â–„â–…â–ƒâ–„â–ƒâ–„â–†â–„â–†â–ƒâ–‚â–â–†â–â–ˆâ–â–ƒ
wandb:          test_loss â–ˆâ–„â–„â–†â–†â–‚â–…â–…â–ƒâ–†â–ƒâ–ˆâ–…â–‚â–ƒâ–†â–ƒâ–ˆâ–â–„
wandb: train_error_energy â–ˆâ–†â–â–ƒâ–„â–ˆâ–„â–„â–‡â–†â–„â–â–‚â–†â–„â–ƒâ–ƒâ–ƒâ–â–ƒ
wandb:  train_error_force â–ˆâ–…â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–â–â–â–‚â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:         train_loss â–ˆâ–…â–‚â–ƒâ–ƒâ–…â–ƒâ–ƒâ–„â–ƒâ–…â–â–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚â–ƒ
wandb: valid_error_energy â–„â–‚â–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–â–‚â–ˆâ–‚â–ƒâ–‚â–â–â–ƒâ–â–ƒâ–‚
wandb:  valid_error_force â–…â–ƒâ–…â–‚â–†â–…â–„â–‚â–â–ˆâ–†â–…â–‚â–â–â–†â–â–ˆâ–…â–ƒ
wandb:         valid_loss â–†â–ƒâ–…â–ƒâ–†â–†â–ƒâ–ƒâ–â–‡â–ˆâ–…â–ƒâ–‚â–â–…â–‚â–‡â–…â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 5004
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.2383
wandb:   test_error_force 5.82476
wandb:          test_loss 3.13641
wandb: train_error_energy 1.93091
wandb:  train_error_force 1.85087
wandb:         train_loss -2.59231
wandb: valid_error_energy 1.39488
wandb:  valid_error_force 1.9108
wandb:         valid_loss -2.54556
wandb: 
wandb: ğŸš€ View run al_58_78 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/m6wd1akf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_034857-m6wd1akf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 49.18539810180664, Uncertainty Bias: -5.875030994415283
7.6293945e-06 0.016878128
-0.079704866 13.304378
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3035 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 867 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 711 steps.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3536 steps.
Found uncertainty sample 17 after 987 steps.
Found uncertainty sample 18 after 1150 steps.
Found uncertainty sample 19 after 3678 steps.
Found uncertainty sample 20 after 3818 steps.
Found uncertainty sample 21 after 1746 steps.
Did not find any uncertainty samples for sample 22.
Found uncertainty sample 23 after 3613 steps.
Found uncertainty sample 24 after 2368 steps.
Found uncertainty sample 25 after 3760 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2758 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2599 steps.
Did not find any uncertainty samples for sample 32.
Found uncertainty sample 33 after 2058 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 3853 steps.
Found uncertainty sample 39 after 1507 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2321 steps.
Found uncertainty sample 47 after 3003 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2754 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2446 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1544 steps.
Found uncertainty sample 65 after 2222 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 3389 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 1921 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 2271 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 2228 steps.
Found uncertainty sample 86 after 2148 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3504 steps.
Found uncertainty sample 89 after 3241 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 2877 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 2239 steps.
Found uncertainty sample 97 after 1508 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 3021 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_042821-7cxzqc1h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_79
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7cxzqc1h
Training model 79. Added 34 samples to the dataset.
Epoch 0, Batch 100/158, Loss: 0.10725295543670654, Uncertainty: 0.12431473284959793

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.6858640921562533, Training Loss Force: 1.9774707511352236, time: 2.631399631500244
Validation Loss Energy: 0.728540323440265, Validation Loss Force: 1.9413563129424876, time: 0.18335342407226562
Test Loss Energy: 6.7922802003726135, Test Loss Force: 5.770518425687392, time: 12.213167905807495

Epoch 1, Batch 100/158, Loss: 0.06220740079879761, Uncertainty: 0.1215614527463913

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0526769306813795, Training Loss Force: 1.8583930650839056, time: 2.577016830444336
Validation Loss Energy: 3.4463528735545474, Validation Loss Force: 1.948216600882425, time: 0.1804976463317871
Test Loss Energy: 9.39001658915446, Test Loss Force: 5.875973054955456, time: 12.475490093231201

Epoch 2, Batch 100/158, Loss: 0.04432675987482071, Uncertainty: 0.12249031662940979

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8180948677700393, Training Loss Force: 1.8357855590069019, time: 2.6310741901397705
Validation Loss Energy: 0.7698719105267108, Validation Loss Force: 1.971290320013949, time: 0.18020343780517578
Test Loss Energy: 6.933273149425112, Test Loss Force: 5.836192011254199, time: 12.316032409667969

Epoch 3, Batch 100/158, Loss: 0.2562514841556549, Uncertainty: 0.12135827541351318

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.856371587905322, Training Loss Force: 1.8384747385101672, time: 2.670140504837036
Validation Loss Energy: 3.6423172345881674, Validation Loss Force: 1.9253838468783195, time: 0.18140673637390137
Test Loss Energy: 9.608249293671694, Test Loss Force: 5.813696071535473, time: 12.56442928314209

Epoch 4, Batch 100/158, Loss: 0.16855305433273315, Uncertainty: 0.12306651473045349

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.270163945139811, Training Loss Force: 1.8389501152925978, time: 2.6449224948883057
Validation Loss Energy: 1.9191595391306757, Validation Loss Force: 2.162991902917927, time: 0.18587708473205566
Test Loss Energy: 6.53932230550152, Test Loss Force: 5.7500723827893045, time: 12.247599124908447

Epoch 5, Batch 100/158, Loss: 0.056934941560029984, Uncertainty: 0.12366056442260742

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.140174581670746, Training Loss Force: 1.849887994386048, time: 2.6282668113708496
Validation Loss Energy: 2.4190336613146908, Validation Loss Force: 1.989140220982007, time: 0.19495391845703125
Test Loss Energy: 8.411676214249493, Test Loss Force: 5.907969158629699, time: 13.168328046798706

Epoch 6, Batch 100/158, Loss: 0.16911634802818298, Uncertainty: 0.12208355218172073

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.174716358420536, Training Loss Force: 1.8338094605318902, time: 2.5556375980377197
Validation Loss Energy: 3.8087840942993925, Validation Loss Force: 1.9471777008705748, time: 0.176283597946167
Test Loss Energy: 6.57407629595266, Test Loss Force: 5.774118304945729, time: 12.235842943191528

Epoch 7, Batch 100/158, Loss: 0.08320291340351105, Uncertainty: 0.12047472596168518

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.205379300657394, Training Loss Force: 1.8296178428106027, time: 2.6083645820617676
Validation Loss Energy: 1.06806696082568, Validation Loss Force: 1.9116287943923493, time: 0.18535065650939941
Test Loss Energy: 6.6228801126186365, Test Loss Force: 5.686156321293884, time: 12.371849060058594

Epoch 8, Batch 100/158, Loss: 0.41959643363952637, Uncertainty: 0.12232957035303116

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.288657186361015, Training Loss Force: 1.8414738671227207, time: 2.7429163455963135
Validation Loss Energy: 1.0775992042937028, Validation Loss Force: 1.9851138432622921, time: 0.18767237663269043
Test Loss Energy: 6.482483236045908, Test Loss Force: 5.684150494311225, time: 12.129526853561401

Epoch 9, Batch 100/158, Loss: 0.34627002477645874, Uncertainty: 0.12326130270957947

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8750021180433252, Training Loss Force: 1.838315909172096, time: 2.7141225337982178
Validation Loss Energy: 2.32427576714244, Validation Loss Force: 1.8614213924800762, time: 0.1992189884185791
Test Loss Energy: 8.441348183648262, Test Loss Force: 5.626019547434837, time: 12.291230201721191

Epoch 10, Batch 100/158, Loss: 0.20702996850013733, Uncertainty: 0.12221424281597137

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8069309939387812, Training Loss Force: 1.8449487861467835, time: 2.616168975830078
Validation Loss Energy: 1.2733423806423676, Validation Loss Force: 1.9419559609524708, time: 0.18692874908447266
Test Loss Energy: 7.562217244636177, Test Loss Force: 5.8680686546803615, time: 12.305994033813477

Epoch 11, Batch 100/158, Loss: 0.10454250872135162, Uncertainty: 0.12182879447937012

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1256875815266247, Training Loss Force: 1.8526950532440092, time: 2.683481216430664
Validation Loss Energy: 1.2836914116491778, Validation Loss Force: 1.8883789810779208, time: 0.1800384521484375
Test Loss Energy: 7.186949734029539, Test Loss Force: 5.614452766654018, time: 12.369228839874268

Epoch 12, Batch 100/158, Loss: 0.04374578595161438, Uncertainty: 0.12320883572101593

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.5627343533173503, Training Loss Force: 1.8773592069502658, time: 2.6738200187683105
Validation Loss Energy: 1.0208536424726005, Validation Loss Force: 1.8679536145450137, time: 0.19440507888793945
Test Loss Energy: 6.424131783761473, Test Loss Force: 5.7370390680391905, time: 12.18860411643982

Epoch 13, Batch 100/158, Loss: 0.07855003327131271, Uncertainty: 0.12269288301467896

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3053914269442664, Training Loss Force: 1.8180028740558818, time: 2.6325900554656982
Validation Loss Energy: 2.932244626217099, Validation Loss Force: 1.9487400960445014, time: 0.18400287628173828
Test Loss Energy: 8.67036068157296, Test Loss Force: 5.794001081174338, time: 12.492213487625122

Epoch 14, Batch 100/158, Loss: 0.24613875150680542, Uncertainty: 0.12197059392929077

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.470848291588543, Training Loss Force: 1.8330233820748294, time: 2.6845901012420654
Validation Loss Energy: 1.1024871945147219, Validation Loss Force: 2.077481087260814, time: 0.18523836135864258
Test Loss Energy: 7.246569971428771, Test Loss Force: 5.847733624592494, time: 11.583419561386108

Epoch 15, Batch 100/158, Loss: 0.27551233768463135, Uncertainty: 0.13168081641197205

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 3.1472911645222705, Training Loss Force: 2.0447799965500444, time: 2.6017048358917236
Validation Loss Energy: 2.066529624879696, Validation Loss Force: 2.086300715238819, time: 0.19230055809020996
Test Loss Energy: 6.374092260589846, Test Loss Force: 5.834151333635685, time: 12.843775987625122

Epoch 16, Batch 100/158, Loss: 0.16120189428329468, Uncertainty: 0.12346519529819489

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 4.15986475544801, Training Loss Force: 1.8720377194756932, time: 2.4641852378845215
Validation Loss Energy: 4.740665751910577, Validation Loss Force: 1.9824167261207173, time: 0.1419994831085205
Test Loss Energy: 6.631133944903079, Test Loss Force: 5.787187542874178, time: 9.261795282363892

Epoch 17, Batch 100/158, Loss: 0.5036640167236328, Uncertainty: 0.12250466644763947

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.2167731469711716, Training Loss Force: 1.8671451336458313, time: 2.4964759349823
Validation Loss Energy: 2.206110595458065, Validation Loss Force: 1.832490584134068, time: 0.142258882522583
Test Loss Energy: 6.515099103730728, Test Loss Force: 5.596343413773296, time: 9.224045038223267

Epoch 18, Batch 100/158, Loss: 0.4000092148780823, Uncertainty: 0.12369437515735626

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0297847079258218, Training Loss Force: 1.859607445529211, time: 2.4274239540100098
Validation Loss Energy: 3.1138954434352377, Validation Loss Force: 1.8959054208794262, time: 0.1411130428314209
Test Loss Energy: 6.44502406262284, Test Loss Force: 5.7021840720655215, time: 9.414241552352905

Epoch 19, Batch 100/158, Loss: 0.08044184744358063, Uncertainty: 0.12205630540847778

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9083453869232747, Training Loss Force: 1.847624921888782, time: 2.4770901203155518
Validation Loss Energy: 2.0665102526640005, Validation Loss Force: 1.9390502028211618, time: 0.14048242568969727
Test Loss Energy: 7.81803337195991, Test Loss Force: 5.668487048915237, time: 10.006248474121094

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.059 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–‚â–ˆâ–â–…â–â–‚â–â–…â–„â–ƒâ–â–†â–ƒâ–â–‚â–â–â–„
wandb:   test_error_force â–…â–‡â–†â–†â–„â–ˆâ–…â–ƒâ–ƒâ–‚â–‡â–â–„â–…â–‡â–†â–…â–â–ƒâ–ƒ
wandb:          test_loss â–…â–‡â–†â–‡â–…â–ˆâ–†â–…â–„â–…â–‡â–„â–„â–‡â–†â–â–…â–ƒâ–„â–…
wandb: train_error_energy â–„â–‚â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–‚â–ƒâ–…â–ˆâ–‚â–‚â–
wandb:  train_error_force â–†â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–‚â–‚â–‚â–ƒâ–â–â–ˆâ–ƒâ–ƒâ–‚â–‚
wandb:         train_loss â–†â–‚â–â–â–‚â–‚â–â–â–‚â–â–â–‚â–ƒâ–â–‚â–ˆâ–…â–‚â–‚â–
wandb: valid_error_energy â–â–†â–â–†â–ƒâ–„â–†â–‚â–‚â–„â–‚â–‚â–‚â–…â–‚â–ƒâ–ˆâ–„â–…â–ƒ
wandb:  valid_error_force â–ƒâ–ƒâ–„â–ƒâ–ˆâ–„â–ƒâ–ƒâ–„â–‚â–ƒâ–‚â–‚â–ƒâ–†â–†â–„â–â–‚â–ƒ
wandb:         valid_loss â–‚â–…â–ƒâ–…â–ˆâ–…â–…â–‚â–ƒâ–‚â–ƒâ–‚â–â–…â–…â–†â–‡â–â–„â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 5034
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.81803
wandb:   test_error_force 5.66849
wandb:          test_loss 2.91203
wandb: train_error_energy 1.90835
wandb:  train_error_force 1.84762
wandb:         train_loss -2.59797
wandb: valid_error_energy 2.06651
wandb:  valid_error_force 1.93905
wandb:         valid_loss -2.46297
wandb: 
wandb: ğŸš€ View run al_58_79 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/7cxzqc1h
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_042821-7cxzqc1h/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 42.431053161621094, Uncertainty Bias: -5.0906147956848145
3.0517578e-05 0.0027160645
0.13497669 14.791231
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 2491 steps.
Found uncertainty sample 1 after 2087 steps.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3561 steps.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 223 steps.
Found uncertainty sample 10 after 3290 steps.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3702 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 2786 steps.
Found uncertainty sample 17 after 2044 steps.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2355 steps.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3496 steps.
Found uncertainty sample 31 after 1588 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3847 steps.
Found uncertainty sample 36 after 632 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 2428 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 3056 steps.
Found uncertainty sample 43 after 977 steps.
Found uncertainty sample 44 after 616 steps.
Found uncertainty sample 45 after 3664 steps.
Found uncertainty sample 46 after 453 steps.
Found uncertainty sample 47 after 3041 steps.
Found uncertainty sample 48 after 2060 steps.
Found uncertainty sample 49 after 3184 steps.
Found uncertainty sample 50 after 1893 steps.
Found uncertainty sample 51 after 3804 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 1350 steps.
Found uncertainty sample 54 after 446 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2960 steps.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 3530 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2171 steps.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 1261 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 2495 steps.
Found uncertainty sample 67 after 3022 steps.
Found uncertainty sample 68 after 1421 steps.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 1456 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1828 steps.
Found uncertainty sample 76 after 2061 steps.
Found uncertainty sample 77 after 2064 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1924 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 3721 steps.
Found uncertainty sample 84 after 2373 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Found uncertainty sample 93 after 3282 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1463 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_050556-bbne0gdz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_80
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bbne0gdz
Training model 80. Added 42 samples to the dataset.
Epoch 0, Batch 100/159, Loss: 0.16508089005947113, Uncertainty: 0.12622180581092834

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.8188355312974496, Training Loss Force: 1.9889123968352853, time: 2.3710265159606934
Validation Loss Energy: 1.7141495409359344, Validation Loss Force: 1.8509710470118688, time: 0.15085363388061523
Test Loss Energy: 6.397232436940672, Test Loss Force: 5.679272067469884, time: 10.079209804534912

Epoch 1, Batch 100/159, Loss: 0.178275465965271, Uncertainty: 0.12320791184902191

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.06834018446665, Training Loss Force: 1.8296613688717802, time: 2.412579298019409
Validation Loss Energy: 1.8967151943401168, Validation Loss Force: 1.8370825043729149, time: 0.15651249885559082
Test Loss Energy: 6.417145722339694, Test Loss Force: 5.59203297511997, time: 10.804297924041748

Epoch 2, Batch 100/159, Loss: 0.1745501458644867, Uncertainty: 0.12223587930202484

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.190826497054184, Training Loss Force: 1.838432902414917, time: 2.8135929107666016
Validation Loss Energy: 2.3066549927255413, Validation Loss Force: 1.8187567594400094, time: 0.18143534660339355
Test Loss Energy: 6.4604131026877765, Test Loss Force: 5.62743920430278, time: 12.358236074447632

Epoch 3, Batch 100/159, Loss: 0.10422113537788391, Uncertainty: 0.12223806977272034

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.341630943132488, Training Loss Force: 1.8283269378880627, time: 2.671924591064453
Validation Loss Energy: 1.2382830865045131, Validation Loss Force: 1.8149690830447291, time: 0.1720883846282959
Test Loss Energy: 6.481409956772853, Test Loss Force: 5.654422158141744, time: 11.294486999511719

Epoch 4, Batch 100/159, Loss: 0.06362803280353546, Uncertainty: 0.12314055114984512

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.2693229678317275, Training Loss Force: 1.8577058202754644, time: 2.6226916313171387
Validation Loss Energy: 0.7631276703233256, Validation Loss Force: 1.9617505800180135, time: 0.19134974479675293
Test Loss Energy: 6.58656258372546, Test Loss Force: 5.6656525989263535, time: 11.17555570602417

Epoch 5, Batch 100/159, Loss: 0.19811363518238068, Uncertainty: 0.1229880154132843

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.973773322215952, Training Loss Force: 1.8485417000215343, time: 2.5345633029937744
Validation Loss Energy: 1.9110792098286753, Validation Loss Force: 1.842548660790199, time: 0.16585373878479004
Test Loss Energy: 7.680128333337943, Test Loss Force: 5.662310013283231, time: 11.649327993392944

Epoch 6, Batch 100/159, Loss: 0.04926620423793793, Uncertainty: 0.1224537342786789

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.00942230797201, Training Loss Force: 1.8291472440194858, time: 2.5548224449157715
Validation Loss Energy: 1.1317465882970712, Validation Loss Force: 1.8699528865832507, time: 0.16344928741455078
Test Loss Energy: 7.251319233844176, Test Loss Force: 5.65561762565137, time: 11.851827144622803

Epoch 7, Batch 100/159, Loss: 0.10726694762706757, Uncertainty: 0.12414667755365372

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2723749306642964, Training Loss Force: 1.9115115940978904, time: 2.6110386848449707
Validation Loss Energy: 1.073760536664005, Validation Loss Force: 1.9357690245098187, time: 0.17469406127929688
Test Loss Energy: 6.361162938159917, Test Loss Force: 5.781011857246733, time: 11.658451080322266

Epoch 8, Batch 100/159, Loss: 0.6275904774665833, Uncertainty: 0.12482542544603348

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.9062299504239912, Training Loss Force: 1.8766022158137277, time: 2.5253565311431885
Validation Loss Energy: 1.4031175587069413, Validation Loss Force: 2.0131778748462517, time: 0.17183446884155273
Test Loss Energy: 7.559624846501177, Test Loss Force: 5.755030655755276, time: 12.515944719314575

Epoch 9, Batch 100/159, Loss: 0.15125280618667603, Uncertainty: 0.12307369709014893

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.68779090643259, Training Loss Force: 1.8446579124806533, time: 2.6304988861083984
Validation Loss Energy: 0.7288343209359384, Validation Loss Force: 1.8389597166076588, time: 0.18128442764282227
Test Loss Energy: 6.773064002302347, Test Loss Force: 5.655474560142208, time: 11.73598599433899

Epoch 10, Batch 100/159, Loss: 0.3053531050682068, Uncertainty: 0.12127675861120224

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8523447101284245, Training Loss Force: 1.8463870105211788, time: 2.6640396118164062
Validation Loss Energy: 0.9616407024012347, Validation Loss Force: 1.8984534610278023, time: 0.17833352088928223
Test Loss Energy: 6.968848800682798, Test Loss Force: 5.655274011019187, time: 11.82558012008667

Epoch 11, Batch 100/159, Loss: 0.05576884746551514, Uncertainty: 0.12288794666528702

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.1307063003004534, Training Loss Force: 1.8324143647655031, time: 2.6794087886810303
Validation Loss Energy: 2.6445132629793306, Validation Loss Force: 1.9197425982892877, time: 0.1776292324066162
Test Loss Energy: 8.725841378305464, Test Loss Force: 5.659890156922766, time: 11.675869941711426

Epoch 12, Batch 100/159, Loss: 0.14110726118087769, Uncertainty: 0.1225605309009552

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.7716985234950027, Training Loss Force: 1.8171124290225558, time: 2.484539747238159
Validation Loss Energy: 1.984318246403892, Validation Loss Force: 1.840237651947663, time: 0.18576431274414062
Test Loss Energy: 8.07555786826671, Test Loss Force: 5.62955167698246, time: 11.66997218132019

Epoch 13, Batch 100/159, Loss: 0.217481330037117, Uncertainty: 0.12016028165817261

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.6051979567166497, Training Loss Force: 1.8152616226876923, time: 2.516767978668213
Validation Loss Energy: 2.8457980063627004, Validation Loss Force: 2.113387229272156, time: 0.18089938163757324
Test Loss Energy: 6.352956523911293, Test Loss Force: 5.797300378070199, time: 11.551209211349487

Epoch 14, Batch 100/159, Loss: 0.06933382153511047, Uncertainty: 0.12238337099552155

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.7290690165127063, Training Loss Force: 1.822074607438469, time: 2.6340487003326416
Validation Loss Energy: 3.5016282623396617, Validation Loss Force: 1.8755292642277688, time: 0.1787726879119873
Test Loss Energy: 6.400621470668148, Test Loss Force: 5.7028144728995915, time: 11.654283046722412

Epoch 15, Batch 100/159, Loss: 0.05867365002632141, Uncertainty: 0.12120295315980911

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.5136750904207954, Training Loss Force: 1.8317961819998825, time: 2.748526096343994
Validation Loss Energy: 2.407672487705066, Validation Loss Force: 2.1573194806484657, time: 0.18128156661987305
Test Loss Energy: 6.286018116973649, Test Loss Force: 5.638143402118103, time: 11.960882186889648

Epoch 16, Batch 100/159, Loss: 0.0929400622844696, Uncertainty: 0.12335137277841568

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0949794797741963, Training Loss Force: 1.8487196714873952, time: 2.6773293018341064
Validation Loss Energy: 1.052858843716434, Validation Loss Force: 1.8228676772121284, time: 0.1981489658355713
Test Loss Energy: 6.590926246133698, Test Loss Force: 5.667162477601642, time: 12.397349834442139

Epoch 17, Batch 100/159, Loss: 0.1088026911020279, Uncertainty: 0.1231384426355362

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8779927940829824, Training Loss Force: 1.852186725319063, time: 2.754023790359497
Validation Loss Energy: 2.5162559833710216, Validation Loss Force: 1.8464231781523912, time: 0.19215893745422363
Test Loss Energy: 8.489028586674946, Test Loss Force: 5.678331200561198, time: 12.245685338973999

Epoch 18, Batch 100/159, Loss: 0.2735353410243988, Uncertainty: 0.1223006322979927

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.4173144303882212, Training Loss Force: 1.895375223236014, time: 2.5671544075012207
Validation Loss Energy: 2.0006004823615693, Validation Loss Force: 1.9330541680596183, time: 0.18914246559143066
Test Loss Energy: 6.379536761364031, Test Loss Force: 5.6665573071636794, time: 12.438501596450806

Epoch 19, Batch 100/159, Loss: 0.12444008141756058, Uncertainty: 0.12297546118497849

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.9163077697108437, Training Loss Force: 1.8371754540367737, time: 2.7035481929779053
Validation Loss Energy: 1.091336554582572, Validation Loss Force: 1.7910783908167962, time: 0.1842803955078125
Test Loss Energy: 7.184335295146515, Test Loss Force: 5.61783733300889, time: 12.222300291061401

wandb: - 0.039 MB of 0.040 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–â–‚â–‚â–‚â–…â–„â–â–…â–‚â–ƒâ–ˆâ–†â–â–â–â–‚â–‡â–â–„
wandb:   test_error_force â–„â–â–‚â–ƒâ–„â–ƒâ–ƒâ–‡â–‡â–ƒâ–ƒâ–ƒâ–‚â–ˆâ–…â–ƒâ–„â–„â–„â–‚
wandb:          test_loss â–â–â–ƒâ–ƒâ–‚â–…â–„â–„â–†â–ƒâ–„â–ˆâ–‡â–ˆâ–†â–ƒâ–„â–†â–â–ƒ
wandb: train_error_energy â–‡â–ƒâ–„â–…â–…â–ƒâ–ƒâ–…â–ˆâ–â–‚â–„â–‚â–â–‚â–†â–„â–‚â–…â–ˆ
wandb:  train_error_force â–ˆâ–‚â–‚â–‚â–ƒâ–‚â–‚â–…â–ƒâ–‚â–‚â–‚â–â–â–â–‚â–‚â–‚â–„â–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–…â–‚â–‚â–‚â–â–â–â–ƒâ–ƒâ–ƒâ–…â–„
wandb: valid_error_energy â–ƒâ–„â–…â–‚â–â–„â–‚â–‚â–ƒâ–â–‚â–†â–„â–†â–ˆâ–…â–‚â–†â–„â–‚
wandb:  valid_error_force â–‚â–‚â–‚â–â–„â–‚â–ƒâ–„â–…â–‚â–ƒâ–ƒâ–‚â–‡â–ƒâ–ˆâ–‚â–‚â–„â–
wandb:         valid_loss â–‚â–‚â–‚â–‚â–ƒâ–‚â–‚â–ƒâ–…â–â–ƒâ–„â–ƒâ–ˆâ–„â–ˆâ–â–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 5071
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.18434
wandb:   test_error_force 5.61784
wandb:          test_loss 2.81237
wandb: train_error_energy 2.91631
wandb:  train_error_force 1.83718
wandb:         train_loss -2.54435
wandb: valid_error_energy 1.09134
wandb:  valid_error_force 1.79108
wandb:         valid_loss -2.72983
wandb: 
wandb: ğŸš€ View run al_58_80 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/bbne0gdz
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_050556-bbne0gdz/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.60556411743164, Uncertainty Bias: -4.742549419403076
5.340576e-05 1.6212463e-05
-0.02037868 15.7142
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3647 steps.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 1508 steps.
Found uncertainty sample 3 after 2883 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1890 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3503 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3080 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3227 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 1467 steps.
Found uncertainty sample 27 after 1620 steps.
Found uncertainty sample 28 after 2421 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Found uncertainty sample 32 after 2710 steps.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2229 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3843 steps.
Found uncertainty sample 44 after 1233 steps.
Found uncertainty sample 45 after 1244 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2762 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2028 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 3564 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2590 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1811 steps.
Found uncertainty sample 76 after 2096 steps.
Found uncertainty sample 77 after 2425 steps.
Found uncertainty sample 78 after 1096 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1324 steps.
Found uncertainty sample 86 after 3876 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 539 steps.
Found uncertainty sample 90 after 1787 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 1515 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2106 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_054533-jrp0k9rp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_81
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jrp0k9rp
Training model 81. Added 29 samples to the dataset.
Epoch 0, Batch 100/160, Loss: 0.11716371029615402, Uncertainty: 0.12453250586986542

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.413247968990298, Training Loss Force: 1.98779932686878, time: 2.6794865131378174
Validation Loss Energy: 1.953158000345806, Validation Loss Force: 1.866663209732838, time: 0.16392803192138672
Test Loss Energy: 6.346267092766102, Test Loss Force: 5.632600479249802, time: 10.749683141708374

Epoch 1, Batch 100/160, Loss: 0.15120930969715118, Uncertainty: 0.1240728497505188

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.739494155778261, Training Loss Force: 1.8668088977480246, time: 2.4560048580169678
Validation Loss Energy: 3.9609766741878683, Validation Loss Force: 1.8503338792507964, time: 0.15378308296203613
Test Loss Energy: 9.570487558345784, Test Loss Force: 5.649778396600843, time: 10.017560243606567

Epoch 2, Batch 100/160, Loss: 0.2952807545661926, Uncertainty: 0.12233064323663712

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9454246504592554, Training Loss Force: 1.8558266091431235, time: 2.5974342823028564
Validation Loss Energy: 2.3613604969431776, Validation Loss Force: 1.9312824267769955, time: 0.14915966987609863
Test Loss Energy: 6.316775298846405, Test Loss Force: 5.619365664078116, time: 10.108388185501099

Epoch 3, Batch 100/160, Loss: 0.06386975198984146, Uncertainty: 0.12234488874673843

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.838016812395903, Training Loss Force: 1.8270178232571368, time: 2.472661256790161
Validation Loss Energy: 3.686775282041061, Validation Loss Force: 1.9276073467465056, time: 0.14932799339294434
Test Loss Energy: 6.3644387114011876, Test Loss Force: 5.644184870711872, time: 9.965407371520996

Epoch 4, Batch 100/160, Loss: 0.24714438617229462, Uncertainty: 0.11974911391735077

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8547685347663916, Training Loss Force: 1.8264659614375514, time: 2.5783371925354004
Validation Loss Energy: 1.985694044833531, Validation Loss Force: 2.0474278037501836, time: 0.15800976753234863
Test Loss Energy: 6.055570771715189, Test Loss Force: 5.634447094295702, time: 10.19492220878601

Epoch 5, Batch 100/160, Loss: 0.05773322284221649, Uncertainty: 0.12145224213600159

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.7226606283396726, Training Loss Force: 1.8134477928270876, time: 2.5494418144226074
Validation Loss Energy: 0.7693956212235712, Validation Loss Force: 1.9608961985050886, time: 0.1536884307861328
Test Loss Energy: 6.608870084724763, Test Loss Force: 5.67143105212392, time: 10.012476921081543

Epoch 6, Batch 100/160, Loss: 0.04126633703708649, Uncertainty: 0.1212257593870163

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.9467506876695615, Training Loss Force: 1.8386664381477693, time: 2.41660475730896
Validation Loss Energy: 4.005650933381457, Validation Loss Force: 1.98165927990932, time: 0.1484370231628418
Test Loss Energy: 6.429086433399146, Test Loss Force: 5.709152674360967, time: 10.34963083267212

Epoch 7, Batch 100/160, Loss: 0.0844275951385498, Uncertainty: 0.11985694617033005

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.8950024560901446, Training Loss Force: 1.8241286521216231, time: 2.634504556655884
Validation Loss Energy: 3.916337448273238, Validation Loss Force: 1.968733261765163, time: 0.18698573112487793
Test Loss Energy: 9.376637405101333, Test Loss Force: 5.634672342206816, time: 12.346293449401855

Epoch 8, Batch 100/160, Loss: 0.05823977291584015, Uncertainty: 0.1214885488152504

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9278087585272758, Training Loss Force: 1.826314355062023, time: 2.741142749786377
Validation Loss Energy: 4.109901807029, Validation Loss Force: 1.848456407235382, time: 0.18801498413085938
Test Loss Energy: 9.651220521724081, Test Loss Force: 5.574402598727634, time: 11.591222524642944

Epoch 9, Batch 100/160, Loss: 0.17088529467582703, Uncertainty: 0.11994598805904388

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.8872750399884126, Training Loss Force: 1.8114592648070889, time: 2.4686970710754395
Validation Loss Energy: 2.6537342892043947, Validation Loss Force: 1.8945017516950216, time: 0.17098450660705566
Test Loss Energy: 6.40246429450953, Test Loss Force: 5.656135672997117, time: 11.710294246673584

Epoch 10, Batch 100/160, Loss: 0.05938519537448883, Uncertainty: 0.12101228535175323

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.154604993921826, Training Loss Force: 1.8326819418230316, time: 2.5183181762695312
Validation Loss Energy: 3.062750715753181, Validation Loss Force: 1.922757649859723, time: 0.17298245429992676
Test Loss Energy: 9.011464519784646, Test Loss Force: 5.634588518348541, time: 11.512189626693726

Epoch 11, Batch 100/160, Loss: 0.13915657997131348, Uncertainty: 0.1219053566455841

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.474699812299967, Training Loss Force: 1.8308819853443083, time: 2.7328717708587646
Validation Loss Energy: 2.4086599511442066, Validation Loss Force: 1.9233397441187023, time: 0.1804792881011963
Test Loss Energy: 6.548090421906562, Test Loss Force: 5.561577492452839, time: 11.650744438171387

Epoch 12, Batch 100/160, Loss: 0.12608002126216888, Uncertainty: 0.12512826919555664

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9963086261928873, Training Loss Force: 1.8838820712122242, time: 2.5855579376220703
Validation Loss Energy: 1.9773567924486544, Validation Loss Force: 1.794517070437359, time: 0.1786494255065918
Test Loss Energy: 6.326990069878978, Test Loss Force: 5.617519872091992, time: 11.541354894638062

Epoch 13, Batch 100/160, Loss: 0.0866793543100357, Uncertainty: 0.12235516309738159

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.9291756374339915, Training Loss Force: 1.8443459034887062, time: 2.785142183303833
Validation Loss Energy: 1.9473743919494775, Validation Loss Force: 1.9858676525443064, time: 0.22602248191833496
Test Loss Energy: 6.268472560038804, Test Loss Force: 5.708990965265514, time: 11.739083290100098

Epoch 14, Batch 100/160, Loss: 0.07152578234672546, Uncertainty: 0.12501610815525055

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9597774325213488, Training Loss Force: 1.8567991215088508, time: 2.5540072917938232
Validation Loss Energy: 0.9873651678246936, Validation Loss Force: 1.8794060453929446, time: 0.18546271324157715
Test Loss Energy: 6.513063548668376, Test Loss Force: 5.547260034245898, time: 11.668744564056396

Epoch 15, Batch 100/160, Loss: 0.22521346807479858, Uncertainty: 0.12240691483020782

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.3583084019828604, Training Loss Force: 1.8995954890948539, time: 2.5746982097625732
Validation Loss Energy: 1.4779069292106806, Validation Loss Force: 2.249055754510476, time: 0.17843222618103027
Test Loss Energy: 6.134102754342817, Test Loss Force: 5.6676181472755465, time: 11.750730752944946

Epoch 16, Batch 100/160, Loss: 0.11690109968185425, Uncertainty: 0.12131741642951965

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.5259370088925333, Training Loss Force: 1.7992444287203226, time: 2.550344705581665
Validation Loss Energy: 2.4966712670870406, Validation Loss Force: 1.9032528717991297, time: 0.1754457950592041
Test Loss Energy: 6.3105540511479585, Test Loss Force: 5.596189217138451, time: 11.65387511253357

Epoch 17, Batch 100/160, Loss: 0.03868762403726578, Uncertainty: 0.12172825634479523

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.451583093436894, Training Loss Force: 1.85631060140703, time: 2.543797731399536
Validation Loss Energy: 1.5091873052729945, Validation Loss Force: 1.9357806033054068, time: 0.1835803985595703
Test Loss Energy: 6.394214766384704, Test Loss Force: 5.70951701471083, time: 12.799729824066162

Epoch 18, Batch 100/160, Loss: 0.09681600332260132, Uncertainty: 0.12129353731870651

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.821351808524296, Training Loss Force: 1.833687768276354, time: 2.5261003971099854
Validation Loss Energy: 2.3179751952123158, Validation Loss Force: 1.8372629777156895, time: 0.1809990406036377
Test Loss Energy: 8.202293078744042, Test Loss Force: 5.609944812307602, time: 11.989675283432007

Epoch 19, Batch 100/160, Loss: 0.08614645898342133, Uncertainty: 0.12161245942115784

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2629767406238592, Training Loss Force: 1.8152108996496832, time: 2.74078369140625
Validation Loss Energy: 1.4462697629535415, Validation Loss Force: 1.897956908832383, time: 0.19523191452026367
Test Loss Energy: 7.352950179211912, Test Loss Force: 5.653406299528968, time: 12.563628196716309

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.039 MB of 0.056 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–‚â–‚â–â–‚â–‚â–‡â–ˆâ–‚â–‡â–‚â–‚â–â–‚â–â–â–‚â–…â–„
wandb:   test_error_force â–…â–…â–„â–…â–…â–†â–ˆâ–…â–‚â–†â–…â–‚â–„â–ˆâ–â–†â–ƒâ–ˆâ–„â–†
wandb:          test_loss â–‚â–ˆâ–ƒâ–…â–„â–‡â–†â–ˆâ–‡â–†â–ˆâ–‚â–ƒâ–…â–â–‚â–„â–†â–…â–†
wandb: train_error_energy â–†â–ˆâ–ƒâ–ƒâ–ƒâ–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–†â–„â–ƒâ–„â–†â–â–†â–ƒâ–…
wandb:  train_error_force â–ˆâ–„â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–‚â–„â–ƒâ–ƒâ–…â–â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–…â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–…â–â–„â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–ˆâ–„â–‡â–„â–â–ˆâ–ˆâ–ˆâ–…â–†â–„â–„â–ƒâ–â–‚â–…â–ƒâ–„â–‚
wandb:  valid_error_force â–‚â–‚â–ƒâ–ƒâ–…â–„â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–â–„â–‚â–ˆâ–ƒâ–ƒâ–‚â–ƒ
wandb:         valid_loss â–‚â–„â–„â–…â–…â–ƒâ–†â–…â–„â–ƒâ–„â–ƒâ–â–„â–‚â–ˆâ–ƒâ–ƒâ–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 5097
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.35295
wandb:   test_error_force 5.65341
wandb:          test_loss 2.93414
wandb: train_error_energy 2.26298
wandb:  train_error_force 1.81521
wandb:         train_loss -2.61873
wandb: valid_error_energy 1.44627
wandb:  valid_error_force 1.89796
wandb:         valid_loss -2.55908
wandb: 
wandb: ğŸš€ View run al_58_81 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/jrp0k9rp
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_054533-jrp0k9rp/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.11677932739258, Uncertainty Bias: -5.105991840362549
5.340576e-05 0.0061945915
0.075294234 13.754832
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Found uncertainty sample 5 after 2216 steps.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 1813 steps.
Found uncertainty sample 8 after 2372 steps.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 1905 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1859 steps.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3225 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 1827 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2144 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1956 steps.
Found uncertainty sample 39 after 1731 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 1036 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 1354 steps.
Found uncertainty sample 45 after 3852 steps.
Found uncertainty sample 46 after 1128 steps.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 2330 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 3696 steps.
Found uncertainty sample 52 after 3522 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 516 steps.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3466 steps.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 826 steps.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 2167 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2110 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 3971 steps.
Did not find any uncertainty samples for sample 74.
Found uncertainty sample 75 after 1563 steps.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3696 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 1208 steps.
Found uncertainty sample 84 after 1515 steps.
Found uncertainty sample 85 after 2234 steps.
Found uncertainty sample 86 after 3968 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1449 steps.
Found uncertainty sample 89 after 1458 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1843 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_062425-2vkb2y5j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_82
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2vkb2y5j
Training model 82. Added 32 samples to the dataset.
Epoch 0, Batch 100/161, Loss: 0.1252875030040741, Uncertainty: 0.12504632771015167

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1183398008771794, Training Loss Force: 1.9658851256142875, time: 2.7850182056427
Validation Loss Energy: 0.8017347148517233, Validation Loss Force: 1.8934159056049047, time: 0.19252967834472656
Test Loss Energy: 6.769008243524838, Test Loss Force: 5.607555045427013, time: 11.967672348022461

Epoch 1, Batch 100/161, Loss: 0.07806295156478882, Uncertainty: 0.12192074209451675

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.876968065578362, Training Loss Force: 1.8042893459430454, time: 2.795686721801758
Validation Loss Energy: 3.7749639168471014, Validation Loss Force: 1.8502883805219785, time: 0.1879734992980957
Test Loss Energy: 9.539367141308245, Test Loss Force: 5.632027715916124, time: 12.262826681137085

Epoch 2, Batch 100/161, Loss: 0.24219733476638794, Uncertainty: 0.12137755006551743

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2544256506641145, Training Loss Force: 1.8257919749701523, time: 2.534916639328003
Validation Loss Energy: 1.5430284136250023, Validation Loss Force: 2.0078038292323335, time: 0.17766022682189941
Test Loss Energy: 7.713820352844379, Test Loss Force: 5.687896992458603, time: 12.078716278076172

Epoch 3, Batch 100/161, Loss: 0.0620788112282753, Uncertainty: 0.12330068647861481

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7459515673026544, Training Loss Force: 1.8552304749620416, time: 2.597963333129883
Validation Loss Energy: 3.009409356946547, Validation Loss Force: 2.024242304707404, time: 0.17754483222961426
Test Loss Energy: 8.906674633694633, Test Loss Force: 5.711328912022876, time: 12.225347995758057

Epoch 4, Batch 100/161, Loss: 0.056317899376153946, Uncertainty: 0.12438123673200607

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.553688280461272, Training Loss Force: 1.8705732518135534, time: 2.6234774589538574
Validation Loss Energy: 1.0793921362567136, Validation Loss Force: 1.9134189429910358, time: 0.17939186096191406
Test Loss Energy: 6.466349753569975, Test Loss Force: 5.679324836560048, time: 12.215781450271606

Epoch 5, Batch 100/161, Loss: 0.360866904258728, Uncertainty: 0.12381119281053543

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.82317130257207, Training Loss Force: 1.870692269163571, time: 2.686385154724121
Validation Loss Energy: 2.262985490941427, Validation Loss Force: 2.0676886177842504, time: 0.1927657127380371
Test Loss Energy: 6.312828062715264, Test Loss Force: 5.688103995489436, time: 12.232597351074219

Epoch 6, Batch 100/161, Loss: 0.1203404888510704, Uncertainty: 0.12489259988069534

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.8377649083905894, Training Loss Force: 1.847269949958779, time: 2.7794301509857178
Validation Loss Energy: 1.1972238608950614, Validation Loss Force: 1.9348603117252872, time: 0.1786050796508789
Test Loss Energy: 7.32346993844005, Test Loss Force: 5.658728178386366, time: 12.027647733688354

Epoch 7, Batch 100/161, Loss: 0.2563742995262146, Uncertainty: 0.12095958739519119

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.1211290628625306, Training Loss Force: 1.8351796003600473, time: 2.664302349090576
Validation Loss Energy: 4.293514636314956, Validation Loss Force: 1.9525615439269142, time: 0.17964839935302734
Test Loss Energy: 6.514178230412892, Test Loss Force: 5.667159031476012, time: 12.330195665359497

Epoch 8, Batch 100/161, Loss: 0.08405591547489166, Uncertainty: 0.12189170718193054

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.0881259700717285, Training Loss Force: 1.8468258522521654, time: 2.610539436340332
Validation Loss Energy: 1.543373476578142, Validation Loss Force: 1.9398176691441265, time: 0.19362783432006836
Test Loss Energy: 7.518647661453821, Test Loss Force: 5.556832804664286, time: 12.630565404891968

Epoch 9, Batch 100/161, Loss: 0.2160591185092926, Uncertainty: 0.12322306632995605

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.3907762398486945, Training Loss Force: 1.8406554232921388, time: 2.6880478858947754
Validation Loss Energy: 1.801728544731949, Validation Loss Force: 1.8832891726287793, time: 0.1363217830657959
Test Loss Energy: 6.422582195366554, Test Loss Force: 5.585416551475275, time: 8.778811931610107

Epoch 10, Batch 100/161, Loss: 0.3587958812713623, Uncertainty: 0.12120452523231506

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.061576455991965, Training Loss Force: 1.8366682265828655, time: 2.6693496704101562
Validation Loss Energy: 2.402467596419004, Validation Loss Force: 1.9249293420399567, time: 0.14449119567871094
Test Loss Energy: 6.319299795715774, Test Loss Force: 5.583280377938333, time: 8.866523027420044

Epoch 11, Batch 100/161, Loss: 0.10328280925750732, Uncertainty: 0.12222462892532349

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5598821816943822, Training Loss Force: 1.8201610823404568, time: 2.499152183532715
Validation Loss Energy: 2.513915879093418, Validation Loss Force: 1.825160909634514, time: 0.14188241958618164
Test Loss Energy: 8.153148561963498, Test Loss Force: 5.5437028491732265, time: 8.853286027908325

Epoch 12, Batch 100/161, Loss: 0.0907796323299408, Uncertainty: 0.12255851924419403

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.06975311182819, Training Loss Force: 1.8504131573039635, time: 2.3898189067840576
Validation Loss Energy: 3.4557381553862583, Validation Loss Force: 1.973266137568815, time: 0.13471174240112305
Test Loss Energy: 6.313682762493511, Test Loss Force: 5.635184700414175, time: 9.139188528060913

Epoch 13, Batch 100/161, Loss: 0.36433231830596924, Uncertainty: 0.12088187783956528

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2998371219901177, Training Loss Force: 1.8562714663581166, time: 2.470804452896118
Validation Loss Energy: 1.0015511964426072, Validation Loss Force: 1.9175248507073712, time: 0.13695955276489258
Test Loss Energy: 6.839308716741354, Test Loss Force: 5.550231506200214, time: 8.918376922607422

Epoch 14, Batch 100/161, Loss: 0.08544972538948059, Uncertainty: 0.12391939759254456

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0899110705810817, Training Loss Force: 1.8559157275028098, time: 2.4875288009643555
Validation Loss Energy: 0.8540176529847138, Validation Loss Force: 1.8676093680454093, time: 0.13944625854492188
Test Loss Energy: 6.582245770439203, Test Loss Force: 5.555456070480191, time: 8.903462171554565

Epoch 15, Batch 100/161, Loss: 0.05508646368980408, Uncertainty: 0.121756412088871

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.8725645408402, Training Loss Force: 1.831930369308486, time: 2.531776189804077
Validation Loss Energy: 1.6370383992476063, Validation Loss Force: 1.8725757806761827, time: 0.13918805122375488
Test Loss Energy: 6.24897243898876, Test Loss Force: 5.554968086966564, time: 9.053844213485718

Epoch 16, Batch 100/161, Loss: 0.15394580364227295, Uncertainty: 0.12317202240228653

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.3154945051043794, Training Loss Force: 1.85275847125586, time: 2.542806386947632
Validation Loss Energy: 6.790442269812008, Validation Loss Force: 1.8941686386527137, time: 0.13834857940673828
Test Loss Energy: 12.434230547733465, Test Loss Force: 5.549929161137485, time: 8.909697532653809

Epoch 17, Batch 100/161, Loss: 0.2449694573879242, Uncertainty: 0.12196037918329239

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.9608964796075972, Training Loss Force: 1.8168819555357376, time: 2.545423984527588
Validation Loss Energy: 1.5168008087105573, Validation Loss Force: 1.8785253146977514, time: 0.13812947273254395
Test Loss Energy: 7.137144974086144, Test Loss Force: 5.566084267002522, time: 8.871378660202026

Epoch 18, Batch 100/161, Loss: 0.32722097635269165, Uncertainty: 0.12147864699363708

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.5756217352149204, Training Loss Force: 1.8289424211371366, time: 2.6362545490264893
Validation Loss Energy: 0.841290756724303, Validation Loss Force: 1.9219134369044621, time: 0.1447305679321289
Test Loss Energy: 6.3259818939346415, Test Loss Force: 5.5183644223918344, time: 8.967171669006348

Epoch 19, Batch 100/161, Loss: 0.41242241859436035, Uncertainty: 0.12269197404384613

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.0999919462757424, Training Loss Force: 1.8592414917377764, time: 2.4563302993774414
Validation Loss Energy: 2.867504833830422, Validation Loss Force: 1.9446092864953464, time: 0.16989398002624512
Test Loss Energy: 6.317224570571236, Test Loss Force: 5.549978563376898, time: 12.42504334449768

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–…â–ƒâ–„â–â–â–‚â–â–‚â–â–â–ƒâ–â–‚â–â–â–ˆâ–‚â–â–
wandb:   test_error_force â–„â–…â–‡â–ˆâ–‡â–‡â–†â–†â–‚â–ƒâ–ƒâ–‚â–…â–‚â–‚â–‚â–‚â–ƒâ–â–‚
wandb:          test_loss â–‚â–ˆâ–‡â–ˆâ–„â–…â–†â–…â–„â–ƒâ–ƒâ–…â–ƒâ–‚â–‚â–ƒâ–ˆâ–„â–ƒâ–
wandb: train_error_energy â–ˆâ–‚â–„â–‚â–…â–‡â–‡â–„â–ƒâ–…â–ƒâ–â–ƒâ–„â–ƒâ–‚â–„â–ƒâ–†â–ƒ
wandb:  train_error_force â–ˆâ–â–‚â–ƒâ–„â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒ
wandb:         train_loss â–ˆâ–â–‚â–‚â–„â–…â–„â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚â–ƒâ–ƒ
wandb: valid_error_energy â–â–„â–‚â–„â–â–ƒâ–â–…â–‚â–‚â–ƒâ–ƒâ–„â–â–â–‚â–ˆâ–‚â–â–ƒ
wandb:  valid_error_force â–ƒâ–‚â–†â–‡â–„â–ˆâ–„â–…â–„â–ƒâ–„â–â–…â–„â–‚â–‚â–ƒâ–ƒâ–„â–„
wandb:         valid_loss â–â–„â–…â–‡â–‚â–‡â–ƒâ–‡â–ƒâ–‚â–„â–‚â–†â–‚â–â–‚â–ˆâ–‚â–‚â–…
wandb: 
wandb: Run summary:
wandb:       dataset_size 5125
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.31722
wandb:   test_error_force 5.54998
wandb:          test_loss 2.61702
wandb: train_error_energy 2.09999
wandb:  train_error_force 1.85924
wandb:         train_loss -2.56927
wandb: valid_error_energy 2.8675
wandb:  valid_error_force 1.94461
wandb:         valid_loss -2.40279
wandb: 
wandb: ğŸš€ View run al_58_82 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2vkb2y5j
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_062425-2vkb2y5j/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 40.56157684326172, Uncertainty Bias: -4.891207218170166
4.386902e-05 0.00950098
0.039588794 15.929586
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 3705 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Found uncertainty sample 7 after 3398 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3723 steps.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 2949 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Found uncertainty sample 24 after 3607 steps.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 174 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2614 steps.
Found uncertainty sample 32 after 2096 steps.
Found uncertainty sample 33 after 2252 steps.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Found uncertainty sample 36 after 2381 steps.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 489 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3327 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3456 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 601 steps.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3477 steps.
Found uncertainty sample 55 after 2070 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 2165 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 932 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1569 steps.
Found uncertainty sample 93 after 3523 steps.
Found uncertainty sample 94 after 2326 steps.
Found uncertainty sample 95 after 1785 steps.
Found uncertainty sample 96 after 3436 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 784 steps.
Found uncertainty sample 99 after 3920 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_070425-cz2moxov
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_83
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cz2moxov
Training model 83. Added 25 samples to the dataset.
Epoch 0, Batch 100/161, Loss: 0.11549587547779083, Uncertainty: 0.12520970404148102

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.7667444532540544, Training Loss Force: 1.9597134961771265, time: 2.598099946975708
Validation Loss Energy: 4.802004866877598, Validation Loss Force: 1.9856195248926938, time: 0.18256211280822754
Test Loss Energy: 6.57401577657725, Test Loss Force: 5.4909249898088754, time: 11.802662372589111

Epoch 1, Batch 100/161, Loss: 0.0687001496553421, Uncertainty: 0.12140961736440659

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9047095303623527, Training Loss Force: 1.8298488837185591, time: 2.6397883892059326
Validation Loss Energy: 2.069422022862249, Validation Loss Force: 1.9838631106696158, time: 0.19224333763122559
Test Loss Energy: 7.699933436506255, Test Loss Force: 5.705822241090502, time: 11.879582405090332

Epoch 2, Batch 100/161, Loss: 0.2081267088651657, Uncertainty: 0.12369590252637863

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.9189344240410158, Training Loss Force: 1.8589687427795873, time: 2.633953332901001
Validation Loss Energy: 1.6963653273659254, Validation Loss Force: 1.9031901533230267, time: 0.18137216567993164
Test Loss Energy: 6.358112727597661, Test Loss Force: 5.567108204658132, time: 11.64334750175476

Epoch 3, Batch 100/161, Loss: 0.07654614746570587, Uncertainty: 0.1203705370426178

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.7950362165206457, Training Loss Force: 1.8245237317311618, time: 2.572722911834717
Validation Loss Energy: 1.2805566754128062, Validation Loss Force: 1.9341375276776056, time: 0.1811351776123047
Test Loss Energy: 6.343953415779837, Test Loss Force: 5.598197818741882, time: 11.823912620544434

Epoch 4, Batch 100/161, Loss: 0.04839233309030533, Uncertainty: 0.12207771837711334

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.000780569029921, Training Loss Force: 1.8340602169772624, time: 2.8092737197875977
Validation Loss Energy: 1.208925532740334, Validation Loss Force: 2.0088883764190992, time: 0.17675185203552246
Test Loss Energy: 7.318898037245509, Test Loss Force: 5.64260161614106, time: 11.722564935684204

Epoch 5, Batch 100/161, Loss: 0.09995821863412857, Uncertainty: 0.12016364932060242

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.925522007435962, Training Loss Force: 1.8202162724787692, time: 2.629234790802002
Validation Loss Energy: 1.5974513506964563, Validation Loss Force: 1.9230850477272856, time: 0.1853010654449463
Test Loss Energy: 6.246920483352876, Test Loss Force: 5.534553632776219, time: 11.820614337921143

Epoch 6, Batch 100/161, Loss: 0.18393437564373016, Uncertainty: 0.12302421033382416

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 3.1411131093650195, Training Loss Force: 1.8469499004035381, time: 2.8598318099975586
Validation Loss Energy: 12.090117873451616, Validation Loss Force: 1.998542611226429, time: 0.18248200416564941
Test Loss Energy: 17.213649458267035, Test Loss Force: 5.653208086683267, time: 11.682221412658691

Epoch 7, Batch 100/161, Loss: 0.049515001475811005, Uncertainty: 0.12276627123355865

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.600816260172656, Training Loss Force: 1.840364912666207, time: 2.6011292934417725
Validation Loss Energy: 2.080387142284317, Validation Loss Force: 1.8114700971971438, time: 0.18821215629577637
Test Loss Energy: 7.554690069210423, Test Loss Force: 5.477577525033877, time: 11.73627233505249

Epoch 8, Batch 100/161, Loss: 0.04508532956242561, Uncertainty: 0.12179382890462875

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7614982309501794, Training Loss Force: 1.8325933535516234, time: 2.6655478477478027
Validation Loss Energy: 2.1909218134529898, Validation Loss Force: 1.8716796115868721, time: 0.22110414505004883
Test Loss Energy: 7.9725886463577345, Test Loss Force: 5.528045295766054, time: 11.921767950057983

Epoch 9, Batch 100/161, Loss: 0.2097637951374054, Uncertainty: 0.12105010449886322

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.60490719096861, Training Loss Force: 1.828908930176247, time: 2.5897791385650635
Validation Loss Energy: 3.4568410356660384, Validation Loss Force: 1.957157360875815, time: 0.16841554641723633
Test Loss Energy: 6.345249002798637, Test Loss Force: 5.5280308467535155, time: 11.889850378036499

Epoch 10, Batch 100/161, Loss: 0.08958916366100311, Uncertainty: 0.12256871163845062

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9564335744712174, Training Loss Force: 1.8235057713782705, time: 2.5725150108337402
Validation Loss Energy: 0.7429313932300537, Validation Loss Force: 1.9836169128172683, time: 0.17319369316101074
Test Loss Energy: 6.335631069015259, Test Loss Force: 5.672851557699394, time: 12.098642826080322

Epoch 11, Batch 100/161, Loss: 0.08874139934778214, Uncertainty: 0.12120738625526428

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.746016599140609, Training Loss Force: 1.8331975690451745, time: 2.7102389335632324
Validation Loss Energy: 0.8427464933773302, Validation Loss Force: 1.7807610530517566, time: 0.16689729690551758
Test Loss Energy: 6.281689097687611, Test Loss Force: 5.438019831309862, time: 11.810710191726685

Epoch 12, Batch 100/161, Loss: 0.060694072395563126, Uncertainty: 0.12126550823450089

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.831728091331628, Training Loss Force: 1.828060702491675, time: 2.5826616287231445
Validation Loss Energy: 3.1286933668661607, Validation Loss Force: 1.75907634405253, time: 0.173295259475708
Test Loss Energy: 6.29046458199319, Test Loss Force: 5.438986730689905, time: 11.937077522277832

Epoch 13, Batch 100/161, Loss: 0.2235037386417389, Uncertainty: 0.12158561497926712

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.28889727724491, Training Loss Force: 1.8098540276947435, time: 2.677802562713623
Validation Loss Energy: 2.514774565543164, Validation Loss Force: 1.8550966238360946, time: 0.18704819679260254
Test Loss Energy: 8.145659188997044, Test Loss Force: 5.516701480246149, time: 11.7319016456604

Epoch 14, Batch 100/161, Loss: 0.04896685481071472, Uncertainty: 0.11996623873710632

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.160138003935116, Training Loss Force: 1.8334910165526679, time: 2.767667770385742
Validation Loss Energy: 2.433168847144284, Validation Loss Force: 1.9741546616841152, time: 0.19399213790893555
Test Loss Energy: 8.18561563769494, Test Loss Force: 5.595868543257333, time: 12.125810146331787

Epoch 15, Batch 100/161, Loss: 0.2500721514225006, Uncertainty: 0.12073786556720734

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9375321764338655, Training Loss Force: 1.8437431334645358, time: 2.809427499771118
Validation Loss Energy: 0.8952558118086807, Validation Loss Force: 1.8725860234568954, time: 0.18109703063964844
Test Loss Energy: 6.212908799554221, Test Loss Force: 5.505223097950456, time: 12.409888982772827

Epoch 16, Batch 100/161, Loss: 0.036237671971321106, Uncertainty: 0.12166187167167664

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0197209967502876, Training Loss Force: 1.8257942894845356, time: 2.721266269683838
Validation Loss Energy: 1.5846372980211767, Validation Loss Force: 1.8155493959505413, time: 0.18045878410339355
Test Loss Energy: 6.099101008909718, Test Loss Force: 5.477498800415624, time: 12.663554430007935

Epoch 17, Batch 100/161, Loss: 0.08662265539169312, Uncertainty: 0.12182492017745972

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.389202649441766, Training Loss Force: 1.826432603092735, time: 2.685426712036133
Validation Loss Energy: 0.9701171601138409, Validation Loss Force: 1.888795038377087, time: 0.17651152610778809
Test Loss Energy: 6.686325395580829, Test Loss Force: 5.516453771896473, time: 11.286551713943481

Epoch 18, Batch 100/161, Loss: 0.15175960958003998, Uncertainty: 0.12106376886367798

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2134604800639406, Training Loss Force: 1.8324923260706472, time: 2.652569055557251
Validation Loss Energy: 0.7229182615093072, Validation Loss Force: 1.8794415982332444, time: 0.1763768196105957
Test Loss Energy: 6.429956391260021, Test Loss Force: 5.601258766387037, time: 11.366708517074585

Epoch 19, Batch 100/161, Loss: 0.08094944059848785, Uncertainty: 0.1224304735660553

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8884909221131239, Training Loss Force: 1.8272800237745328, time: 2.6859700679779053
Validation Loss Energy: 3.842456716330981, Validation Loss Force: 1.8778649522339783, time: 0.1771857738494873
Test Loss Energy: 9.557979553919319, Test Loss Force: 5.561181395519025, time: 11.255857229232788

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.039 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–â–â–‚â–â–ˆâ–‚â–‚â–â–â–â–â–‚â–‚â–â–â–â–â–ƒ
wandb:   test_error_force â–‚â–ˆâ–„â–…â–†â–„â–‡â–‚â–ƒâ–ƒâ–‡â–â–â–ƒâ–…â–ƒâ–‚â–ƒâ–…â–„
wandb:          test_loss â–â–„â–‚â–‚â–„â–‚â–ˆâ–‚â–‚â–‚â–„â–â–â–ƒâ–ƒâ–‚â–â–‚â–ƒâ–„
wandb: train_error_energy â–†â–‚â–‡â–â–‚â–‚â–ˆâ–…â–â–…â–‚â–â–â–„â–ƒâ–‚â–‚â–„â–ƒâ–‚
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–â–„â–â–‚â–â–„â–ƒâ–â–ƒâ–â–â–â–â–‚â–‚â–â–‚â–‚â–
wandb: valid_error_energy â–„â–‚â–‚â–â–â–‚â–ˆâ–‚â–‚â–ƒâ–â–â–‚â–‚â–‚â–â–‚â–â–â–ƒ
wandb:  valid_error_force â–‡â–‡â–…â–†â–ˆâ–†â–ˆâ–‚â–„â–‡â–‡â–‚â–â–„â–‡â–„â–ƒâ–…â–„â–„
wandb:         valid_loss â–…â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ˆâ–‚â–‚â–„â–ƒâ–â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 5147
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 9.55798
wandb:   test_error_force 5.56118
wandb:          test_loss 3.00564
wandb: train_error_energy 1.88849
wandb:  train_error_force 1.82728
wandb:         train_loss -2.62721
wandb: valid_error_energy 3.84246
wandb:  valid_error_force 1.87786
wandb:         valid_loss -2.42563
wandb: 
wandb: ğŸš€ View run al_58_83 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/cz2moxov
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_070425-cz2moxov/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.95058822631836, Uncertainty Bias: -5.16718053817749
4.386902e-05 0.13784409
0.1502037 13.178372
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 3600 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2428 steps.
Found uncertainty sample 12 after 173 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 2250 steps.
Found uncertainty sample 18 after 3920 steps.
Found uncertainty sample 19 after 1833 steps.
Found uncertainty sample 20 after 2287 steps.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 1586 steps.
Found uncertainty sample 23 after 1991 steps.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 1704 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1572 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 1114 steps.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2508 steps.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3231 steps.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3345 steps.
Found uncertainty sample 46 after 3309 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 3270 steps.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2659 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3079 steps.
Found uncertainty sample 60 after 1256 steps.
Found uncertainty sample 61 after 1990 steps.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3098 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 2361 steps.
Found uncertainty sample 72 after 3749 steps.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2143 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3417 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1931 steps.
Found uncertainty sample 88 after 776 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 1656 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 660 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 1984 steps.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_074359-uscru23y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_84
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/uscru23y
Training model 84. Added 31 samples to the dataset.
Epoch 0, Batch 100/162, Loss: 0.1939227432012558, Uncertainty: 0.12390069663524628

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.0427909648366684, Training Loss Force: 1.9458864919753718, time: 2.5732266902923584
Validation Loss Energy: 0.837904385797271, Validation Loss Force: 1.818603451733038, time: 0.17854714393615723
Test Loss Energy: 6.68699990122709, Test Loss Force: 5.491509837898398, time: 9.948650598526001

Epoch 1, Batch 100/162, Loss: 0.18793363869190216, Uncertainty: 0.12257654964923859

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9324224361059836, Training Loss Force: 1.8671835029950656, time: 2.5899524688720703
Validation Loss Energy: 4.1529421200297705, Validation Loss Force: 2.038522893489288, time: 0.16412782669067383
Test Loss Energy: 6.430148178177279, Test Loss Force: 5.627735377583005, time: 11.778368473052979

Epoch 2, Batch 100/162, Loss: 0.056155670434236526, Uncertainty: 0.12113653868436813

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8942241667709794, Training Loss Force: 1.8306455682084235, time: 2.5413310527801514
Validation Loss Energy: 1.1673530547495188, Validation Loss Force: 1.809741108390539, time: 0.1928544044494629
Test Loss Energy: 6.996792081081674, Test Loss Force: 5.482142375427401, time: 11.591342687606812

Epoch 3, Batch 100/162, Loss: 0.09178608655929565, Uncertainty: 0.11950497329235077

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6003300761749244, Training Loss Force: 1.816874730266858, time: 2.703934907913208
Validation Loss Energy: 1.4129277303806063, Validation Loss Force: 1.8862048024255575, time: 0.18260431289672852
Test Loss Energy: 7.2052065754913555, Test Loss Force: 5.510363507282955, time: 11.24298882484436

Epoch 4, Batch 100/162, Loss: 0.06467780470848083, Uncertainty: 0.11955632269382477

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.559975514567779, Training Loss Force: 1.790944873861045, time: 2.753793478012085
Validation Loss Energy: 1.1888971481830917, Validation Loss Force: 1.9112636912160763, time: 0.1552286148071289
Test Loss Energy: 6.172095223867806, Test Loss Force: 5.515451923952784, time: 10.392332077026367

Epoch 5, Batch 100/162, Loss: 0.17294327914714813, Uncertainty: 0.12065096199512482

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.037836276683809, Training Loss Force: 1.8141187927337354, time: 2.4585657119750977
Validation Loss Energy: 1.2163018193144353, Validation Loss Force: 1.9116473501545101, time: 0.1540524959564209
Test Loss Energy: 6.370010979964469, Test Loss Force: 5.487130423105345, time: 10.522427320480347

Epoch 6, Batch 100/162, Loss: 0.05049550160765648, Uncertainty: 0.1210993155837059

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.864038359725124, Training Loss Force: 1.8118196850072488, time: 2.585111141204834
Validation Loss Energy: 0.83202413899161, Validation Loss Force: 1.862124247639197, time: 0.1698901653289795
Test Loss Energy: 6.144871880615802, Test Loss Force: 5.494255504685834, time: 11.763853788375854

Epoch 7, Batch 100/162, Loss: 0.038268767297267914, Uncertainty: 0.12035559117794037

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7209360573507755, Training Loss Force: 1.819249131778189, time: 2.6938393115997314
Validation Loss Energy: 0.7294057456316755, Validation Loss Force: 1.8647868139516286, time: 0.16883468627929688
Test Loss Energy: 6.440896131062681, Test Loss Force: 5.460895451067571, time: 11.021876335144043

Epoch 8, Batch 100/162, Loss: 0.08469243347644806, Uncertainty: 0.12027633190155029

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.4683981663415457, Training Loss Force: 1.8107110483176965, time: 2.6081881523132324
Validation Loss Energy: 0.80270505132239, Validation Loss Force: 1.8242045456527543, time: 0.17051434516906738
Test Loss Energy: 6.661793730591922, Test Loss Force: 5.475315975943901, time: 11.333131551742554

Epoch 9, Batch 100/162, Loss: 0.1909143626689911, Uncertainty: 0.12084846198558807

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.229073409204531, Training Loss Force: 1.8095809969041092, time: 2.627049684524536
Validation Loss Energy: 3.357991150599073, Validation Loss Force: 2.1915750505040936, time: 0.17486143112182617
Test Loss Energy: 9.120904455778772, Test Loss Force: 5.7046929401256214, time: 11.185445308685303

Epoch 10, Batch 100/162, Loss: 0.05524727702140808, Uncertainty: 0.12050016224384308

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.357593772065128, Training Loss Force: 1.840441524106522, time: 2.662797689437866
Validation Loss Energy: 1.9484425358424933, Validation Loss Force: 1.99549772199044, time: 0.17830157279968262
Test Loss Energy: 6.09492754558954, Test Loss Force: 5.47524871820376, time: 12.26738953590393

Epoch 11, Batch 100/162, Loss: 0.08857421576976776, Uncertainty: 0.12147868424654007

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.497872304241254, Training Loss Force: 1.8359269346628542, time: 2.7049074172973633
Validation Loss Energy: 2.6803187585367128, Validation Loss Force: 1.8875083447173433, time: 0.18591856956481934
Test Loss Energy: 8.279709554235767, Test Loss Force: 5.485597230620737, time: 12.370186805725098

Epoch 12, Batch 100/162, Loss: 0.08183544129133224, Uncertainty: 0.12239542603492737

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2849581853693866, Training Loss Force: 1.8097808610183412, time: 2.674145460128784
Validation Loss Energy: 1.5142104243129308, Validation Loss Force: 1.8705531654891476, time: 0.18940472602844238
Test Loss Energy: 6.229391825956981, Test Loss Force: 5.4850282048644505, time: 12.078633069992065

Epoch 13, Batch 100/162, Loss: 0.0756465345621109, Uncertainty: 0.12006164342164993

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.8854977467916836, Training Loss Force: 1.8019037338060107, time: 2.576188325881958
Validation Loss Energy: 2.960953136532423, Validation Loss Force: 1.920104027424653, time: 0.16810178756713867
Test Loss Energy: 6.335978787288248, Test Loss Force: 5.5057808596790565, time: 11.654101133346558

Epoch 14, Batch 100/162, Loss: 0.1321457028388977, Uncertainty: 0.1212901696562767

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.432088559879435, Training Loss Force: 1.8316911331751418, time: 2.5718162059783936
Validation Loss Energy: 0.9152895218696632, Validation Loss Force: 1.9951023358103208, time: 0.1698606014251709
Test Loss Energy: 6.405387110340945, Test Loss Force: 5.412991436922867, time: 11.78461766242981

Epoch 15, Batch 100/162, Loss: 0.11897195875644684, Uncertainty: 0.11930696666240692

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.6507593572387327, Training Loss Force: 1.8040012393618756, time: 2.6238372325897217
Validation Loss Energy: 0.7908553044950754, Validation Loss Force: 1.899668937672373, time: 0.17589688301086426
Test Loss Energy: 6.677754501085496, Test Loss Force: 5.513067946469987, time: 11.76650857925415

Epoch 16, Batch 100/162, Loss: 0.04752778261899948, Uncertainty: 0.12137985229492188

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.075885171446169, Training Loss Force: 1.8077158383550143, time: 2.733912944793701
Validation Loss Energy: 0.8148622114614202, Validation Loss Force: 1.8904092412389664, time: 0.17751383781433105
Test Loss Energy: 6.3873298224029345, Test Loss Force: 5.448451810848156, time: 11.932312965393066

Epoch 17, Batch 100/162, Loss: 0.49963241815567017, Uncertainty: 0.11882016062736511

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.138173164175792, Training Loss Force: 1.8097209664543392, time: 2.659475088119507
Validation Loss Energy: 1.2172842726977928, Validation Loss Force: 1.8747136271462352, time: 0.17810392379760742
Test Loss Energy: 6.088787657233271, Test Loss Force: 5.449248355507685, time: 11.691981315612793

Epoch 18, Batch 100/162, Loss: 0.13758881390094757, Uncertainty: 0.12066374719142914

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.9731240928658498, Training Loss Force: 1.7927583126902447, time: 2.678760290145874
Validation Loss Energy: 1.5116267942127306, Validation Loss Force: 1.9214975280513933, time: 0.17299103736877441
Test Loss Energy: 7.554482294415326, Test Loss Force: 5.4884325596281345, time: 11.905994892120361

Epoch 19, Batch 100/162, Loss: 0.09358486533164978, Uncertainty: 0.12097931653261185

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.1493773433234047, Training Loss Force: 1.8503680727097052, time: 2.5258588790893555
Validation Loss Energy: 1.0491980887343324, Validation Loss Force: 1.8979530492338539, time: 0.1929929256439209
Test Loss Energy: 6.789025190154845, Test Loss Force: 5.427984062954473, time: 11.98882269859314

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–‚â–ƒâ–„â–â–‚â–â–‚â–‚â–ˆâ–â–†â–â–‚â–‚â–‚â–‚â–â–„â–ƒ
wandb:   test_error_force â–ƒâ–†â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–‚â–‚â–ˆâ–‚â–ƒâ–ƒâ–ƒâ–â–ƒâ–‚â–‚â–ƒâ–
wandb:          test_loss â–ƒâ–„â–ƒâ–„â–ƒâ–ƒâ–‚â–‚â–ƒâ–ˆâ–‚â–ƒâ–ƒâ–ƒâ–â–„â–‚â–â–…â–‚
wandb: train_error_energy â–ˆâ–ƒâ–ƒâ–‚â–â–„â–ƒâ–‚â–â–„â–…â–â–…â–ƒâ–…â–‚â–„â–„â–ƒâ–„
wandb:  train_error_force â–ˆâ–„â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–â–ƒâ–‚â–‚â–‚â–â–„
wandb:         train_loss â–ˆâ–„â–ƒâ–‚â–â–‚â–‚â–‚â–â–ƒâ–„â–‚â–ƒâ–‚â–„â–‚â–‚â–‚â–‚â–„
wandb: valid_error_energy â–â–ˆâ–‚â–‚â–‚â–‚â–â–â–â–†â–ƒâ–…â–ƒâ–†â–â–â–â–‚â–ƒâ–‚
wandb:  valid_error_force â–â–…â–â–‚â–ƒâ–ƒâ–‚â–‚â–â–ˆâ–„â–‚â–‚â–ƒâ–„â–ƒâ–‚â–‚â–ƒâ–ƒ
wandb:         valid_loss â–â–†â–â–‚â–ƒâ–ƒâ–‚â–‚â–â–ˆâ–„â–ƒâ–‚â–„â–„â–‚â–‚â–‚â–ƒâ–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 5174
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.78903
wandb:   test_error_force 5.42798
wandb:          test_loss 2.59293
wandb: train_error_energy 2.14938
wandb:  train_error_force 1.85037
wandb:         train_loss -2.57713
wandb: valid_error_energy 1.0492
wandb:  valid_error_force 1.89795
wandb:         valid_loss -2.58548
wandb: 
wandb: ğŸš€ View run al_58_84 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/uscru23y
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_074359-uscru23y/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 39.36348342895508, Uncertainty Bias: -4.647340297698975
3.4332275e-05 0.007385254
0.2861637 16.919506
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1609 steps.
Found uncertainty sample 10 after 948 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Found uncertainty sample 14 after 1955 steps.
Found uncertainty sample 15 after 2442 steps.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 3847 steps.
Found uncertainty sample 26 after 2028 steps.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Found uncertainty sample 37 after 646 steps.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 2118 steps.
Found uncertainty sample 42 after 636 steps.
Did not find any uncertainty samples for sample 43.
Found uncertainty sample 44 after 3775 steps.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 2231 steps.
Found uncertainty sample 51 after 1139 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3878 steps.
Found uncertainty sample 64 after 1495 steps.
Did not find any uncertainty samples for sample 65.
Found uncertainty sample 66 after 1787 steps.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2177 steps.
Found uncertainty sample 70 after 2341 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 533 steps.
Found uncertainty sample 74 after 2862 steps.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 2265 steps.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 3242 steps.
Found uncertainty sample 81 after 3368 steps.
Did not find any uncertainty samples for sample 82.
Found uncertainty sample 83 after 2221 steps.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 3965 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 1552 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 2164 steps.
Found uncertainty sample 95 after 2422 steps.
Did not find any uncertainty samples for sample 96.
Found uncertainty sample 97 after 2534 steps.
Did not find any uncertainty samples for sample 98.
Found uncertainty sample 99 after 1609 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_082313-p4hk33gf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_85
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p4hk33gf
Training model 85. Added 29 samples to the dataset.
Epoch 0, Batch 100/163, Loss: 0.12848901748657227, Uncertainty: 0.12263152748346329

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.9175215508111023, Training Loss Force: 1.9616361069029467, time: 2.6303019523620605
Validation Loss Energy: 0.9805274065800189, Validation Loss Force: 1.8840350400445889, time: 0.1858203411102295
Test Loss Energy: 6.839798577204324, Test Loss Force: 5.4680298241302205, time: 11.477507591247559

Epoch 1, Batch 100/163, Loss: 0.27649790048599243, Uncertainty: 0.12274843454360962

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.780476959551838, Training Loss Force: 1.862820325277729, time: 2.6095054149627686
Validation Loss Energy: 0.7905470932855869, Validation Loss Force: 1.8771828053054287, time: 0.17795610427856445
Test Loss Energy: 6.31996909719938, Test Loss Force: 5.573034081151603, time: 11.671361207962036

Epoch 2, Batch 100/163, Loss: 0.11849761009216309, Uncertainty: 0.12034085392951965

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4995263361127225, Training Loss Force: 1.7974024286141947, time: 2.6126039028167725
Validation Loss Energy: 4.906752886504948, Validation Loss Force: 1.8759903006944125, time: 0.18599224090576172
Test Loss Energy: 9.972098740839236, Test Loss Force: 5.456818365015949, time: 11.925378322601318

Epoch 3, Batch 100/163, Loss: 0.10041022300720215, Uncertainty: 0.1198577880859375

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.078051605399422, Training Loss Force: 1.809207247729274, time: 2.4532182216644287
Validation Loss Energy: 4.859538269248517, Validation Loss Force: 1.969623270341436, time: 0.18422985076904297
Test Loss Energy: 6.555721393796913, Test Loss Force: 5.464116944332745, time: 11.818914890289307

Epoch 4, Batch 100/163, Loss: 0.4887675344944, Uncertainty: 0.11987701058387756

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.5294524528870603, Training Loss Force: 1.826684286708017, time: 2.6555352210998535
Validation Loss Energy: 1.3995974192904932, Validation Loss Force: 1.8264619283426458, time: 0.17654871940612793
Test Loss Energy: 7.3230090086447515, Test Loss Force: 5.438880840435846, time: 11.69114065170288

Epoch 5, Batch 100/163, Loss: 0.06207413598895073, Uncertainty: 0.11743316054344177

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8152132530824057, Training Loss Force: 1.799204954475437, time: 2.6927947998046875
Validation Loss Energy: 2.5615246207381412, Validation Loss Force: 1.890156029308522, time: 0.18111753463745117
Test Loss Energy: 8.427302272213492, Test Loss Force: 5.528316959118928, time: 11.582771062850952

Epoch 6, Batch 100/163, Loss: 0.4169032573699951, Uncertainty: 0.11934297531843185

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.027265407771031, Training Loss Force: 1.7897917959693317, time: 2.810401678085327
Validation Loss Energy: 1.3016635208668257, Validation Loss Force: 1.83764515219315, time: 0.1793212890625
Test Loss Energy: 7.000290334608131, Test Loss Force: 5.411082577107129, time: 11.601861715316772

Epoch 7, Batch 100/163, Loss: 0.1604510247707367, Uncertainty: 0.11991660296916962

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.950929924717742, Training Loss Force: 1.8239969180580795, time: 2.589815139770508
Validation Loss Energy: 0.7633917002631095, Validation Loss Force: 1.9553339232398124, time: 0.18719983100891113
Test Loss Energy: 6.563773606747466, Test Loss Force: 5.497419353455777, time: 11.558335304260254

Epoch 8, Batch 100/163, Loss: 0.4565678834915161, Uncertainty: 0.12009178847074509

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.5209716551752113, Training Loss Force: 1.822867801068994, time: 2.5535898208618164
Validation Loss Energy: 1.7215366640751375, Validation Loss Force: 2.0048583617700007, time: 0.20343637466430664
Test Loss Energy: 7.296074713260302, Test Loss Force: 5.463118563499217, time: 11.779421091079712

Epoch 9, Batch 100/163, Loss: 0.06519949436187744, Uncertainty: 0.1219729632139206

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2616142897872424, Training Loss Force: 1.8105092775556852, time: 2.5814859867095947
Validation Loss Energy: 0.7689539569726235, Validation Loss Force: 1.9136342640551482, time: 0.19957756996154785
Test Loss Energy: 6.454423999814935, Test Loss Force: 5.514578121260268, time: 11.73880386352539

Epoch 10, Batch 100/163, Loss: 0.06949891149997711, Uncertainty: 0.12223218381404877

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.835797920036589, Training Loss Force: 1.8492298430494882, time: 2.5218136310577393
Validation Loss Energy: 1.7261491069869341, Validation Loss Force: 2.520640413077389, time: 0.17080903053283691
Test Loss Energy: 6.039353901392816, Test Loss Force: 5.69099541380547, time: 11.997045993804932

Epoch 11, Batch 100/163, Loss: 0.12059016525745392, Uncertainty: 0.12005045264959335

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.8017263348886667, Training Loss Force: 1.8236833076909975, time: 2.5213348865509033
Validation Loss Energy: 0.8228200727331606, Validation Loss Force: 1.8783124429942444, time: 0.17122817039489746
Test Loss Energy: 6.677760222866482, Test Loss Force: 5.450012052387866, time: 11.667747259140015

Epoch 12, Batch 100/163, Loss: 0.08435511589050293, Uncertainty: 0.1217399314045906

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3623927896237915, Training Loss Force: 1.8122038300552128, time: 2.6889140605926514
Validation Loss Energy: 2.219727259069841, Validation Loss Force: 1.8426989253521757, time: 0.15943193435668945
Test Loss Energy: 6.159909273638004, Test Loss Force: 5.418065756653888, time: 11.103682041168213

Epoch 13, Batch 100/163, Loss: 0.16791613399982452, Uncertainty: 0.12114006280899048

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.339418329134592, Training Loss Force: 1.802371330221556, time: 2.911172389984131
Validation Loss Energy: 2.9993484969260913, Validation Loss Force: 1.9369607126672996, time: 0.1847531795501709
Test Loss Energy: 6.309713413334307, Test Loss Force: 5.447307853357083, time: 11.602848291397095

Epoch 14, Batch 100/163, Loss: 0.0790148451924324, Uncertainty: 0.12020781636238098

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.3096901030748724, Training Loss Force: 1.8146659961854117, time: 2.5331151485443115
Validation Loss Energy: 1.0902546423140331, Validation Loss Force: 1.864238788071976, time: 0.15897583961486816
Test Loss Energy: 6.061128516654284, Test Loss Force: 5.449799183015971, time: 10.22245979309082

Epoch 15, Batch 100/163, Loss: 0.3481155037879944, Uncertainty: 0.12173684686422348

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.0085631929483805, Training Loss Force: 1.8228416360782793, time: 2.5376667976379395
Validation Loss Energy: 3.595575343928541, Validation Loss Force: 1.7879265461677125, time: 0.15765070915222168
Test Loss Energy: 6.290515091749295, Test Loss Force: 5.386769843686759, time: 10.890919208526611

Epoch 16, Batch 100/163, Loss: 0.12248930335044861, Uncertainty: 0.12080919742584229

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0891835277472275, Training Loss Force: 1.8295079923974422, time: 2.5344321727752686
Validation Loss Energy: 2.7567969260662175, Validation Loss Force: 1.8907521517236952, time: 0.15851330757141113
Test Loss Energy: 6.248327122819333, Test Loss Force: 5.364171333932449, time: 10.27036738395691

Epoch 17, Batch 100/163, Loss: 0.24532559514045715, Uncertainty: 0.11916807293891907

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.0260048026021735, Training Loss Force: 1.8064653784152511, time: 2.505707263946533
Validation Loss Energy: 2.0646736033253394, Validation Loss Force: 1.9266711714339768, time: 0.15949559211730957
Test Loss Energy: 7.69459966408537, Test Loss Force: 5.465685978389201, time: 10.04838252067566

Epoch 18, Batch 100/163, Loss: 0.08791050314903259, Uncertainty: 0.12185420095920563

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.045344894516903, Training Loss Force: 1.8339957920427619, time: 2.4536869525909424
Validation Loss Energy: 3.4186902402176464, Validation Loss Force: 1.971512766490731, time: 0.15325188636779785
Test Loss Energy: 6.287113185180409, Test Loss Force: 5.444764862124725, time: 10.210854053497314

Epoch 19, Batch 100/163, Loss: 0.12628048658370972, Uncertainty: 0.12208397686481476

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.8396981446427494, Training Loss Force: 1.843494225318381, time: 2.5501644611358643
Validation Loss Energy: 1.2032144402625295, Validation Loss Force: 1.7830597037566933, time: 0.15604066848754883
Test Loss Energy: 7.0772375168048045, Test Loss Force: 5.363093594281631, time: 10.150009870529175

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ˆâ–‚â–ƒâ–…â–ƒâ–‚â–ƒâ–‚â–â–‚â–â–â–â–â–â–„â–â–ƒ
wandb:   test_error_force â–ƒâ–…â–ƒâ–ƒâ–ƒâ–…â–‚â–„â–ƒâ–„â–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–â–ƒâ–ƒâ–
wandb:          test_loss â–„â–…â–ˆâ–…â–…â–ˆâ–…â–…â–„â–…â–‡â–„â–ƒâ–…â–ƒâ–ƒâ–â–…â–„â–‚
wandb: train_error_energy â–ˆâ–â–…â–ƒâ–†â–â–ƒâ–‚â–†â–„â–â–â–…â–„â–„â–‚â–ƒâ–ƒâ–ƒâ–
wandb:  train_error_force â–ˆâ–„â–â–‚â–ƒâ–â–â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒ
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–ƒâ–â–â–‚â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–â–ˆâ–ˆâ–‚â–„â–‚â–â–ƒâ–â–ƒâ–â–ƒâ–…â–‚â–†â–„â–ƒâ–…â–‚
wandb:  valid_error_force â–‚â–‚â–‚â–ƒâ–â–‚â–‚â–ƒâ–ƒâ–‚â–ˆâ–‚â–‚â–‚â–‚â–â–‚â–‚â–ƒâ–
wandb:         valid_loss â–‚â–‚â–„â–„â–â–ƒâ–‚â–‚â–ƒâ–‚â–ˆâ–‚â–‚â–ƒâ–‚â–‚â–ƒâ–ƒâ–„â–
wandb: 
wandb: Run summary:
wandb:       dataset_size 5200
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.07724
wandb:   test_error_force 5.36309
wandb:          test_loss 2.48772
wandb: train_error_energy 1.8397
wandb:  train_error_force 1.84349
wandb:         train_loss -2.60815
wandb: valid_error_energy 1.20321
wandb:  valid_error_force 1.78306
wandb:         valid_loss -2.73327
wandb: 
wandb: ğŸš€ View run al_58_85 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/p4hk33gf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_082313-p4hk33gf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 44.24954605102539, Uncertainty Bias: -5.299810886383057
7.6293945e-06 0.0032372475
0.26716736 17.340525
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 1210 steps.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1516 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Found uncertainty sample 10 after 2291 steps.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3497 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2557 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 2008 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1030 steps.
Did not find any uncertainty samples for sample 26.
Found uncertainty sample 27 after 2440 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1049 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 3891 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 1321 steps.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 1813 steps.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2245 steps.
Found uncertainty sample 50 after 3028 steps.
Found uncertainty sample 51 after 2098 steps.
Did not find any uncertainty samples for sample 52.
Found uncertainty sample 53 after 3356 steps.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 590 steps.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 2679 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 1125 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3736 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Found uncertainty sample 80 after 2330 steps.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 2731 steps.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 1667 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Found uncertainty sample 95 after 3749 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 3067 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_090325-8qe960kl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_86
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8qe960kl
Training model 86. Added 25 samples to the dataset.
Epoch 0, Batch 100/164, Loss: 0.09826037287712097, Uncertainty: 0.12454695999622345

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.80946277180957, Training Loss Force: 1.9215729115140396, time: 2.483475923538208
Validation Loss Energy: 0.9695843314033977, Validation Loss Force: 1.9303880761523764, time: 0.15550446510314941
Test Loss Energy: 6.766861213992679, Test Loss Force: 5.364034517149056, time: 10.023064374923706

Epoch 1, Batch 100/164, Loss: 0.06438291072845459, Uncertainty: 0.12130171060562134

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.4683866958465714, Training Loss Force: 1.8060621692141, time: 2.4419050216674805
Validation Loss Energy: 0.7282638054725471, Validation Loss Force: 1.7831956432702822, time: 0.15453100204467773
Test Loss Energy: 6.245690011320864, Test Loss Force: 5.345856267403487, time: 9.984845399856567

Epoch 2, Batch 100/164, Loss: 0.33521851897239685, Uncertainty: 0.12070739269256592

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.9792321581587733, Training Loss Force: 1.7980384107736822, time: 2.7659618854522705
Validation Loss Energy: 7.161539402601118, Validation Loss Force: 2.1171216877415593, time: 0.15316271781921387
Test Loss Energy: 7.369618128260041, Test Loss Force: 5.592504313240583, time: 10.022341966629028

Epoch 3, Batch 100/164, Loss: 0.13953948020935059, Uncertainty: 0.12021958827972412

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.4175089080883354, Training Loss Force: 1.827724987166062, time: 2.515413761138916
Validation Loss Energy: 0.7966366305326579, Validation Loss Force: 1.872453386868971, time: 0.1833360195159912
Test Loss Energy: 6.445654871489374, Test Loss Force: 5.447643286355414, time: 10.121124982833862

Epoch 4, Batch 100/164, Loss: 0.13473424315452576, Uncertainty: 0.12073417007923126

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9745062835334541, Training Loss Force: 1.8033661292118894, time: 2.5870559215545654
Validation Loss Energy: 1.1782737887884986, Validation Loss Force: 1.810487495367689, time: 0.15873050689697266
Test Loss Energy: 6.9325832434677634, Test Loss Force: 5.390440338209533, time: 10.295433044433594

Epoch 5, Batch 100/164, Loss: 0.3484269678592682, Uncertainty: 0.12355589866638184

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.057520844780035, Training Loss Force: 1.8749193575967877, time: 2.3845975399017334
Validation Loss Energy: 6.259324845978476, Validation Loss Force: 2.0609805613170784, time: 0.16823792457580566
Test Loss Energy: 11.500372830079549, Test Loss Force: 5.4863962141486065, time: 12.506802320480347

Epoch 6, Batch 100/164, Loss: 0.14139562845230103, Uncertainty: 0.1223888173699379

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.405372955940861, Training Loss Force: 1.855235087385917, time: 2.8562519550323486
Validation Loss Energy: 1.9981023572134058, Validation Loss Force: 1.9868402713737188, time: 0.18581652641296387
Test Loss Energy: 7.667314773216138, Test Loss Force: 5.498879151391953, time: 12.052942276000977

Epoch 7, Batch 100/164, Loss: 0.07048085331916809, Uncertainty: 0.12035303562879562

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.159955393079437, Training Loss Force: 1.8308946362952288, time: 2.6936533451080322
Validation Loss Energy: 1.8438356142306127, Validation Loss Force: 1.8460666848497607, time: 0.18327546119689941
Test Loss Energy: 7.480150196958783, Test Loss Force: 5.417032047203611, time: 10.937997579574585

Epoch 8, Batch 100/164, Loss: 0.09434729814529419, Uncertainty: 0.1200561672449112

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.7530550190317553, Training Loss Force: 1.8103051902091254, time: 2.606083869934082
Validation Loss Energy: 1.949170738172726, Validation Loss Force: 2.032692673018412, time: 0.16715645790100098
Test Loss Energy: 7.591311493689706, Test Loss Force: 5.515305134855915, time: 10.861050128936768

Epoch 9, Batch 100/164, Loss: 0.19733300805091858, Uncertainty: 0.12098197638988495

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.1637200677972004, Training Loss Force: 1.8205276686551024, time: 2.5291600227355957
Validation Loss Energy: 3.3360373830485166, Validation Loss Force: 1.8928665065988524, time: 0.16238760948181152
Test Loss Energy: 6.2300045484929925, Test Loss Force: 5.455318505286418, time: 10.632901668548584

Epoch 10, Batch 100/164, Loss: 0.14528170228004456, Uncertainty: 0.12244760990142822

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0769275836975423, Training Loss Force: 1.8544381144593503, time: 2.4797260761260986
Validation Loss Energy: 2.0119897122835813, Validation Loss Force: 1.8970885362747891, time: 0.16687870025634766
Test Loss Energy: 6.131780625255466, Test Loss Force: 5.429322586646805, time: 10.871302127838135

Epoch 11, Batch 100/164, Loss: 0.04421713948249817, Uncertainty: 0.12011242657899857

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.5858048811121626, Training Loss Force: 1.8051963107359887, time: 2.682868242263794
Validation Loss Energy: 0.9471113736275871, Validation Loss Force: 1.8447248434648753, time: 0.16398882865905762
Test Loss Energy: 6.109194813471505, Test Loss Force: 5.424762156993603, time: 10.881938934326172

Epoch 12, Batch 100/164, Loss: 0.14903253316879272, Uncertainty: 0.12119321525096893

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.6273325878958103, Training Loss Force: 1.8101119059228974, time: 2.494285821914673
Validation Loss Energy: 2.0677905260300364, Validation Loss Force: 1.8177373429784274, time: 0.1676180362701416
Test Loss Energy: 7.809739356638179, Test Loss Force: 5.340154981305959, time: 10.99253511428833

Epoch 13, Batch 100/164, Loss: 0.09047965705394745, Uncertainty: 0.12099285423755646

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.2636450238268577, Training Loss Force: 1.8196129125756408, time: 2.4965875148773193
Validation Loss Energy: 3.669388532896533, Validation Loss Force: 2.080344167139153, time: 0.16942691802978516
Test Loss Energy: 6.401178225139462, Test Loss Force: 5.444319122795247, time: 11.762325525283813

Epoch 14, Batch 100/164, Loss: 0.03826923668384552, Uncertainty: 0.11924108862876892

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.7826415580397037, Training Loss Force: 1.811271249802904, time: 2.6934444904327393
Validation Loss Energy: 2.4361872758634324, Validation Loss Force: 1.9136743073898905, time: 0.1813516616821289
Test Loss Energy: 6.24550878195222, Test Loss Force: 5.482315409172505, time: 11.59025526046753

Epoch 15, Batch 100/164, Loss: 0.051964715123176575, Uncertainty: 0.12037529051303864

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.9863001771772306, Training Loss Force: 1.7959212351963867, time: 2.7365269660949707
Validation Loss Energy: 1.0877994923110332, Validation Loss Force: 2.0414813499851334, time: 0.1849963665008545
Test Loss Energy: 6.905532989919602, Test Loss Force: 5.452374627984899, time: 11.760562419891357

Epoch 16, Batch 100/164, Loss: 0.06936688721179962, Uncertainty: 0.11963386833667755

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.651613763509436, Training Loss Force: 1.820046452797109, time: 2.655355930328369
Validation Loss Energy: 2.0892420262104276, Validation Loss Force: 1.888579754424499, time: 0.17775464057922363
Test Loss Energy: 7.760554568219011, Test Loss Force: 5.39132514612057, time: 11.505135536193848

Epoch 17, Batch 100/164, Loss: 0.24483197927474976, Uncertainty: 0.11880816519260406

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.1334006697653107, Training Loss Force: 1.795466605898644, time: 2.7157421112060547
Validation Loss Energy: 2.5709099025698516, Validation Loss Force: 1.8602140061478067, time: 0.18334746360778809
Test Loss Energy: 6.2435687367979815, Test Loss Force: 5.435045745616147, time: 11.678932905197144

Epoch 18, Batch 100/164, Loss: 0.14889898896217346, Uncertainty: 0.12060636281967163

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.7124601542095754, Training Loss Force: 1.7871176235566042, time: 2.620497941970825
Validation Loss Energy: 1.6079741007486141, Validation Loss Force: 1.9511426219060137, time: 0.1791832447052002
Test Loss Energy: 6.165906744673828, Test Loss Force: 5.424768132920525, time: 11.649541139602661

Epoch 19, Batch 100/164, Loss: 0.091421939432621, Uncertainty: 0.12113778293132782

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.333170467774075, Training Loss Force: 1.8114362469611673, time: 2.634106159210205
Validation Loss Energy: 2.641984112596834, Validation Loss Force: 1.8513390077755145, time: 0.1749742031097412
Test Loss Energy: 6.175462424360911, Test Loss Force: 5.364378616756973, time: 11.94298791885376

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.039 MB of 0.040 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–â–ƒâ–â–‚â–ˆâ–ƒâ–ƒâ–ƒâ–â–â–â–ƒâ–â–â–‚â–ƒâ–â–â–
wandb:   test_error_force â–‚â–â–ˆâ–„â–‚â–…â–…â–ƒâ–†â–„â–ƒâ–ƒâ–â–„â–…â–„â–‚â–„â–ƒâ–‚
wandb:          test_loss â–â–â–ˆâ–„â–ƒâ–ˆâ–…â–ƒâ–…â–ƒâ–‚â–ƒâ–ƒâ–„â–„â–…â–ƒâ–ƒâ–„â–
wandb: train_error_energy â–ˆâ–â–ƒâ–„â–ƒâ–ƒâ–„â–ƒâ–‚â–ƒâ–ƒâ–â–â–ƒâ–…â–ƒâ–‚â–ƒâ–…â–„
wandb:  train_error_force â–ˆâ–‚â–‚â–ƒâ–‚â–†â–…â–ƒâ–‚â–ƒâ–…â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–â–‚
wandb:         train_loss â–ˆâ–â–‚â–ƒâ–‚â–„â–„â–ƒâ–‚â–‚â–ƒâ–â–â–ƒâ–ƒâ–â–‚â–‚â–‚â–‚
wandb: valid_error_energy â–â–â–ˆâ–â–â–‡â–‚â–‚â–‚â–„â–‚â–â–‚â–„â–ƒâ–â–‚â–ƒâ–‚â–ƒ
wandb:  valid_error_force â–„â–â–ˆâ–ƒâ–‚â–‡â–…â–‚â–†â–ƒâ–ƒâ–‚â–‚â–‡â–„â–†â–ƒâ–ƒâ–…â–‚
wandb:         valid_loss â–ƒâ–â–ˆâ–‚â–‚â–‡â–„â–‚â–„â–„â–ƒâ–‚â–‚â–†â–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 5222
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.17546
wandb:   test_error_force 5.36438
wandb:          test_loss 2.4529
wandb: train_error_energy 2.33317
wandb:  train_error_force 1.81144
wandb:         train_loss -2.61917
wandb: valid_error_energy 2.64198
wandb:  valid_error_force 1.85134
wandb:         valid_loss -2.54352
wandb: 
wandb: ğŸš€ View run al_58_86 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8qe960kl
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_090325-8qe960kl/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 44.499603271484375, Uncertainty Bias: -5.299290180206299
2.4795532e-05 0.10732651
0.29874006 19.951717
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2742 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2978 steps.
Found uncertainty sample 12 after 3146 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Found uncertainty sample 16 after 3644 steps.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 3077 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 2600 steps.
Found uncertainty sample 32 after 2045 steps.
Found uncertainty sample 33 after 1598 steps.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 1525 steps.
Found uncertainty sample 36 after 1639 steps.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2513 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3781 steps.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 3416 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Found uncertainty sample 50 after 3801 steps.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 2258 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Found uncertainty sample 59 after 3611 steps.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 2722 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2226 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Found uncertainty sample 78 after 1805 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3709 steps.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 1923 steps.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 1582 steps.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_094438-fb0u079m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_87
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fb0u079m
Training model 87. Added 22 samples to the dataset.
Epoch 0, Batch 100/164, Loss: 0.05680510401725769, Uncertainty: 0.12135036289691925

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.5370509817150526, Training Loss Force: 1.8998984916849322, time: 2.705552339553833
Validation Loss Energy: 3.1079022291495426, Validation Loss Force: 1.849828939850881, time: 0.1840965747833252
Test Loss Energy: 6.197288710522302, Test Loss Force: 5.366380673519642, time: 11.414820671081543

Epoch 1, Batch 100/164, Loss: 0.34295758605003357, Uncertainty: 0.11984621733427048

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.2843476421852476, Training Loss Force: 1.800477364311793, time: 2.507282257080078
Validation Loss Energy: 1.0478782173718455, Validation Loss Force: 1.8845633225933025, time: 0.17780756950378418
Test Loss Energy: 6.733381114891196, Test Loss Force: 5.309655876470754, time: 11.735118389129639

Epoch 2, Batch 100/164, Loss: 0.2180313616991043, Uncertainty: 0.11958086490631104

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.6783572220062937, Training Loss Force: 1.7928242800758032, time: 2.51313853263855
Validation Loss Energy: 0.8234646071318107, Validation Loss Force: 1.9306253301273626, time: 0.17050981521606445
Test Loss Energy: 6.54271639883158, Test Loss Force: 5.4094330230895675, time: 11.559147119522095

Epoch 3, Batch 100/164, Loss: 0.0632614940404892, Uncertainty: 0.12072136998176575

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.4850652633665067, Training Loss Force: 1.7919325444559104, time: 2.70500111579895
Validation Loss Energy: 1.4811322917894445, Validation Loss Force: 1.809628808917943, time: 0.16777563095092773
Test Loss Energy: 7.2160712349885925, Test Loss Force: 5.362665143870654, time: 11.503800630569458

Epoch 4, Batch 100/164, Loss: 0.07789087295532227, Uncertainty: 0.12219841033220291

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.094016181344861, Training Loss Force: 1.8543271166055826, time: 2.879338264465332
Validation Loss Energy: 1.0292075579318978, Validation Loss Force: 1.7868813371967276, time: 0.1772902011871338
Test Loss Energy: 6.846888966698716, Test Loss Force: 5.305597583228724, time: 11.942856311798096

Epoch 5, Batch 100/164, Loss: 0.11203572899103165, Uncertainty: 0.12108869105577469

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 3.1236931661159555, Training Loss Force: 1.803342353849607, time: 2.9094080924987793
Validation Loss Energy: 0.8356365747690452, Validation Loss Force: 1.9400937788850767, time: 0.19703054428100586
Test Loss Energy: 6.513396440207346, Test Loss Force: 5.392000882859073, time: 12.149342775344849

Epoch 6, Batch 100/164, Loss: 0.064718097448349, Uncertainty: 0.12054409086704254

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6819948894339065, Training Loss Force: 1.81559687018916, time: 2.9644358158111572
Validation Loss Energy: 0.8412134905306661, Validation Loss Force: 1.816491657553059, time: 0.19029927253723145
Test Loss Energy: 6.366404963897836, Test Loss Force: 5.347464129829443, time: 12.32399034500122

Epoch 7, Batch 100/164, Loss: 0.21035552024841309, Uncertainty: 0.12015587091445923

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.9089865261602583, Training Loss Force: 1.8033779585102667, time: 2.787827968597412
Validation Loss Energy: 2.2089472519310873, Validation Loss Force: 1.809930191606956, time: 0.1909620761871338
Test Loss Energy: 7.555565986676923, Test Loss Force: 5.345649241056513, time: 12.243889331817627

Epoch 8, Batch 100/164, Loss: 0.4812077581882477, Uncertainty: 0.11726801097393036

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.4100347008338496, Training Loss Force: 1.7915325743236679, time: 2.8939905166625977
Validation Loss Energy: 2.0502855395690207, Validation Loss Force: 1.90857377371022, time: 0.19956016540527344
Test Loss Energy: 7.496548606754476, Test Loss Force: 5.39412786051003, time: 12.204039096832275

Epoch 9, Batch 100/164, Loss: 0.20252561569213867, Uncertainty: 0.11928777396678925

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.2021228364657675, Training Loss Force: 1.7941337355458942, time: 2.7474594116210938
Validation Loss Energy: 2.524271478840033, Validation Loss Force: 1.8211752061454554, time: 0.19282746315002441
Test Loss Energy: 6.215072033804331, Test Loss Force: 5.358649052843717, time: 12.149834632873535

Epoch 10, Batch 100/164, Loss: 0.09147230535745621, Uncertainty: 0.11971151828765869

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.376382691764833, Training Loss Force: 1.790426597720795, time: 3.0888960361480713
Validation Loss Energy: 2.1940354703435467, Validation Loss Force: 1.785172611282402, time: 0.19910430908203125
Test Loss Energy: 6.216391002249261, Test Loss Force: 5.281874267861505, time: 12.052455425262451

Epoch 11, Batch 100/164, Loss: 0.09767578542232513, Uncertainty: 0.11939884722232819

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.795190648224427, Training Loss Force: 1.8048052399020211, time: 2.7621958255767822
Validation Loss Energy: 2.6401045623360577, Validation Loss Force: 1.8189651777605977, time: 0.19040489196777344
Test Loss Energy: 6.179315502920117, Test Loss Force: 5.301770024185773, time: 12.266299724578857

Epoch 12, Batch 100/164, Loss: 0.08375407010316849, Uncertainty: 0.11949413269758224

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.2849759771772415, Training Loss Force: 1.808080174199397, time: 2.9221105575561523
Validation Loss Energy: 0.9518545233280434, Validation Loss Force: 1.8044139346318382, time: 0.19273066520690918
Test Loss Energy: 6.456943555994038, Test Loss Force: 5.311719844582447, time: 12.25289273262024

Epoch 13, Batch 100/164, Loss: 0.10146064311265945, Uncertainty: 0.11928628385066986

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.049238696785806, Training Loss Force: 1.8040386083620643, time: 2.924584150314331
Validation Loss Energy: 2.7013871193400116, Validation Loss Force: 1.869695369715985, time: 0.19134235382080078
Test Loss Energy: 6.152486729394695, Test Loss Force: 5.266689551802805, time: 12.22055435180664

Epoch 14, Batch 100/164, Loss: 0.1523866206407547, Uncertainty: 0.11991500854492188

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.060250868642339, Training Loss Force: 1.8065176131550598, time: 2.960244655609131
Validation Loss Energy: 0.7450377320159576, Validation Loss Force: 1.9301598773893247, time: 0.19107866287231445
Test Loss Energy: 6.442450394343854, Test Loss Force: 5.3860917566812505, time: 13.237844228744507

Epoch 15, Batch 100/164, Loss: 0.2328166514635086, Uncertainty: 0.12056908011436462

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7858528163051837, Training Loss Force: 1.8147861881749925, time: 2.7342045307159424
Validation Loss Energy: 1.7857751539912827, Validation Loss Force: 1.8637351104638873, time: 0.17603802680969238
Test Loss Energy: 6.202669779735075, Test Loss Force: 5.329843812020305, time: 12.40705132484436

Epoch 16, Batch 100/164, Loss: 0.11924093961715698, Uncertainty: 0.12085314095020294

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.1339546512526026, Training Loss Force: 1.8128720311914965, time: 2.7921206951141357
Validation Loss Energy: 4.208611187864885, Validation Loss Force: 1.8390192806041947, time: 0.17652606964111328
Test Loss Energy: 6.480550262677217, Test Loss Force: 5.283512595157204, time: 12.256991863250732

Epoch 17, Batch 100/164, Loss: 0.15576346218585968, Uncertainty: 0.12000394612550735

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.157466654318304, Training Loss Force: 1.7894607852354583, time: 2.756897449493408
Validation Loss Energy: 0.7463961065849278, Validation Loss Force: 1.8394019004199473, time: 0.18155550956726074
Test Loss Energy: 6.405620395325842, Test Loss Force: 5.309999843176667, time: 12.283244848251343

Epoch 18, Batch 100/164, Loss: 0.26900792121887207, Uncertainty: 0.126426562666893

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2362486057101694, Training Loss Force: 1.8605309777136432, time: 2.8799116611480713
Validation Loss Energy: 1.6904403240619326, Validation Loss Force: 1.8168852994915348, time: 0.1812434196472168
Test Loss Energy: 6.2358819414030044, Test Loss Force: 5.308509608350113, time: 12.343933582305908

Epoch 19, Batch 100/164, Loss: 0.23212525248527527, Uncertainty: 0.12108275294303894

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.210438036232475, Training Loss Force: 1.8103165049245382, time: 2.751452922821045
Validation Loss Energy: 2.100876785977349, Validation Loss Force: 1.8301459893620209, time: 0.18805670738220215
Test Loss Energy: 6.093875570274455, Test Loss Force: 5.314104850307057, time: 12.49212121963501

wandb: - 0.039 MB of 0.056 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–ƒâ–†â–…â–ƒâ–‚â–ˆâ–ˆâ–‚â–‚â–â–ƒâ–â–ƒâ–‚â–ƒâ–‚â–‚â–
wandb:   test_error_force â–†â–ƒâ–ˆâ–†â–ƒâ–‡â–…â–…â–‡â–†â–‚â–ƒâ–ƒâ–â–‡â–„â–‚â–ƒâ–ƒâ–ƒ
wandb:          test_loss â–‚â–„â–ˆâ–‡â–‚â–†â–„â–‡â–‡â–…â–‚â–â–‚â–â–†â–ƒâ–â–…â–‚â–‚
wandb: train_error_energy â–ˆâ–„â–‚â–â–ƒâ–‡â–‚â–‚â–„â–ƒâ–„â–‚â–„â–ƒâ–ƒâ–‚â–ƒâ–ƒâ–„â–ƒ
wandb:  train_error_force â–ˆâ–‚â–â–â–…â–‚â–ƒâ–‚â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–‚â–â–†â–‚
wandb:         train_loss â–ˆâ–ƒâ–â–â–„â–„â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–ƒâ–‚â–…â–ƒ
wandb: valid_error_energy â–†â–‚â–â–‚â–‚â–â–â–„â–„â–…â–„â–…â–â–…â–â–ƒâ–ˆâ–â–ƒâ–„
wandb:  valid_error_force â–„â–…â–ˆâ–‚â–â–ˆâ–‚â–‚â–‡â–ƒâ–â–ƒâ–‚â–…â–ˆâ–…â–ƒâ–ƒâ–‚â–ƒ
wandb:         valid_loss â–‡â–„â–†â–ƒâ–â–†â–‚â–„â–‡â–…â–ƒâ–…â–â–‡â–…â–…â–ˆâ–‚â–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 5241
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.09388
wandb:   test_error_force 5.3141
wandb:          test_loss 2.44184
wandb: train_error_energy 2.21044
wandb:  train_error_force 1.81032
wandb:         train_loss -2.62879
wandb: valid_error_energy 2.10088
wandb:  valid_error_force 1.83015
wandb:         valid_loss -2.60849
wandb: 
wandb: ğŸš€ View run al_58_87 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/fb0u079m
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_094438-fb0u079m/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.19465637207031, Uncertainty Bias: -5.069128513336182
5.2452087e-05 0.0142326355
0.2056394 14.789029
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Found uncertainty sample 1 after 1848 steps.
Found uncertainty sample 2 after 903 steps.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1078 steps.
Found uncertainty sample 7 after 2893 steps.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Found uncertainty sample 20 after 3026 steps.
Found uncertainty sample 21 after 3406 steps.
Found uncertainty sample 22 after 3843 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1299 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3841 steps.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Found uncertainty sample 34 after 946 steps.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1439 steps.
Found uncertainty sample 39 after 720 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Found uncertainty sample 48 after 1867 steps.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 2117 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1923 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3498 steps.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 2295 steps.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3925 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Found uncertainty sample 91 after 2997 steps.
Found uncertainty sample 92 after 3290 steps.
Found uncertainty sample 93 after 3462 steps.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 1616 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_102542-90ou9zxs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_88
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/90ou9zxs
Training model 88. Added 22 samples to the dataset.
Epoch 0, Batch 100/165, Loss: 0.0536789745092392, Uncertainty: 0.12295469641685486

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.32652607435153, Training Loss Force: 1.9484291554510877, time: 2.8198444843292236
Validation Loss Energy: 2.7453752606719486, Validation Loss Force: 1.79893709009555, time: 0.1964120864868164
Test Loss Energy: 8.1884616641478, Test Loss Force: 5.324397571862004, time: 12.219572067260742

Epoch 1, Batch 100/165, Loss: 0.2438810169696808, Uncertainty: 0.12149663269519806

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.0385799828219064, Training Loss Force: 1.823954113038104, time: 2.699082374572754
Validation Loss Energy: 2.5062893866223424, Validation Loss Force: 1.8791792939793417, time: 0.1869964599609375
Test Loss Energy: 6.185508789902354, Test Loss Force: 5.343531769396217, time: 12.355023860931396

Epoch 2, Batch 100/165, Loss: 0.13038909435272217, Uncertainty: 0.1203264370560646

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 3.1013826867429555, Training Loss Force: 1.808011861827529, time: 2.8260622024536133
Validation Loss Energy: 0.7588042334071808, Validation Loss Force: 1.9209853519042348, time: 0.1911756992340088
Test Loss Energy: 6.221675223207432, Test Loss Force: 5.3693547615449715, time: 12.304208517074585

Epoch 3, Batch 100/165, Loss: 0.1558372974395752, Uncertainty: 0.12010064721107483

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8741243922925992, Training Loss Force: 1.8220663759750626, time: 2.897554636001587
Validation Loss Energy: 3.1699309504615, Validation Loss Force: 1.8733953144677697, time: 0.19234585762023926
Test Loss Energy: 8.569855975760799, Test Loss Force: 5.328047513206543, time: 12.254520416259766

Epoch 4, Batch 100/165, Loss: 0.1035400927066803, Uncertainty: 0.11989237368106842

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.5376691217060996, Training Loss Force: 1.7860828348433504, time: 2.902625799179077
Validation Loss Energy: 1.0249864189325446, Validation Loss Force: 1.802467843407954, time: 0.1977686882019043
Test Loss Energy: 6.2700814040742925, Test Loss Force: 5.297951103773038, time: 12.309356689453125

Epoch 5, Batch 100/165, Loss: 0.11392835527658463, Uncertainty: 0.11966057121753693

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.04898582651179, Training Loss Force: 1.7840490355923955, time: 2.823415994644165
Validation Loss Energy: 1.6302862171780166, Validation Loss Force: 1.812117359292832, time: 0.18712520599365234
Test Loss Energy: 7.301146608112664, Test Loss Force: 5.35528437982029, time: 12.455507516860962

Epoch 6, Batch 100/165, Loss: 0.023490983992815018, Uncertainty: 0.11770277470350266

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.780748089321556, Training Loss Force: 1.7869856630896348, time: 2.6646478176116943
Validation Loss Energy: 2.5228984266631937, Validation Loss Force: 1.7742757770650854, time: 0.19191741943359375
Test Loss Energy: 6.226569656579525, Test Loss Force: 5.198261089572895, time: 12.200160264968872

Epoch 7, Batch 100/165, Loss: 0.20722344517707825, Uncertainty: 0.11923307180404663

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2795647358262876, Training Loss Force: 1.8028178030580386, time: 2.7296271324157715
Validation Loss Energy: 2.28867624054504, Validation Loss Force: 1.8833361558185697, time: 0.18340802192687988
Test Loss Energy: 6.140464915470619, Test Loss Force: 5.329614866169237, time: 12.403787612915039

Epoch 8, Batch 100/165, Loss: 0.08961823582649231, Uncertainty: 0.11908221244812012

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2055901323075258, Training Loss Force: 1.8078572005620523, time: 2.867013931274414
Validation Loss Energy: 4.781905710643475, Validation Loss Force: 1.8306285876242951, time: 0.19448637962341309
Test Loss Energy: 10.025490586474435, Test Loss Force: 5.354301182457734, time: 12.920537948608398

Epoch 9, Batch 100/165, Loss: 0.07393157482147217, Uncertainty: 0.11881846189498901

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 3.404310077842234, Training Loss Force: 1.8014182026462102, time: 2.8565828800201416
Validation Loss Energy: 1.6250729015759333, Validation Loss Force: 1.8253214540887281, time: 0.1861097812652588
Test Loss Energy: 7.1924308784508195, Test Loss Force: 5.220196257449224, time: 11.671817779541016

Epoch 10, Batch 100/165, Loss: 0.1002715677022934, Uncertainty: 0.12101096659898758

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.334591158914095, Training Loss Force: 1.7725804605566295, time: 2.728996515274048
Validation Loss Energy: 1.2344053033281808, Validation Loss Force: 1.7676993551746811, time: 0.19307827949523926
Test Loss Energy: 6.039281824206344, Test Loss Force: 5.287413886832634, time: 12.579099655151367

Epoch 11, Batch 100/165, Loss: 0.05716051906347275, Uncertainty: 0.11996512115001678

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.0801942605346975, Training Loss Force: 1.8195866513954115, time: 2.968474864959717
Validation Loss Energy: 7.063805757962689, Validation Loss Force: 1.8065575333881607, time: 0.18333935737609863
Test Loss Energy: 7.404400051448021, Test Loss Force: 5.270365873029197, time: 11.613642692565918

Epoch 12, Batch 100/165, Loss: 0.13639047741889954, Uncertainty: 0.12163164466619492

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.3524240037629522, Training Loss Force: 1.8319126213998778, time: 2.7978885173797607
Validation Loss Energy: 1.3346993462525856, Validation Loss Force: 1.8892348099402945, time: 0.1770496368408203
Test Loss Energy: 7.077375608981105, Test Loss Force: 5.366018333694671, time: 11.153306007385254

Epoch 13, Batch 100/165, Loss: 0.5915364623069763, Uncertainty: 0.11942103505134583

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.3039740013847285, Training Loss Force: 1.8011648334978534, time: 2.7074596881866455
Validation Loss Energy: 0.9601511571495506, Validation Loss Force: 1.970545899947588, time: 0.18245553970336914
Test Loss Energy: 6.2463331754104825, Test Loss Force: 5.343630669471221, time: 11.352952003479004

Epoch 14, Batch 100/165, Loss: 0.1130637601017952, Uncertainty: 0.11929973214864731

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.092000585191669, Training Loss Force: 1.8140647649394324, time: 2.722823143005371
Validation Loss Energy: 2.5306263820417634, Validation Loss Force: 1.906572646095767, time: 0.17667078971862793
Test Loss Energy: 6.177500819329228, Test Loss Force: 5.314333982687253, time: 11.333510160446167

Epoch 15, Batch 100/165, Loss: 0.04667384922504425, Uncertainty: 0.11844898760318756

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.181097287379095, Training Loss Force: 1.7948429858682138, time: 2.6636247634887695
Validation Loss Energy: 2.1026298601632383, Validation Loss Force: 1.887791876763158, time: 0.16536450386047363
Test Loss Energy: 6.079248900401279, Test Loss Force: 5.299192476100936, time: 11.18066954612732

Epoch 16, Batch 100/165, Loss: 0.12978723645210266, Uncertainty: 0.11794029176235199

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.9017720410081114, Training Loss Force: 1.786149920333734, time: 2.933513879776001
Validation Loss Energy: 2.6128542380343664, Validation Loss Force: 1.7934066565181415, time: 0.17663002014160156
Test Loss Energy: 8.138993155599282, Test Loss Force: 5.3056558082958665, time: 11.514352798461914

Epoch 17, Batch 100/165, Loss: 0.20807181298732758, Uncertainty: 0.11874488741159439

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8445242003460098, Training Loss Force: 1.814579918780351, time: 2.906893014907837
Validation Loss Energy: 0.8879598531289729, Validation Loss Force: 1.9633235148648474, time: 0.18006348609924316
Test Loss Energy: 6.4759890705862055, Test Loss Force: 5.331833117185497, time: 10.948095798492432

Epoch 18, Batch 100/165, Loss: 0.21893778443336487, Uncertainty: 0.1183774322271347

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.0818900706264265, Training Loss Force: 1.7955415961437073, time: 2.5089638233184814
Validation Loss Energy: 0.7801286266167717, Validation Loss Force: 1.8418524857054557, time: 0.16180729866027832
Test Loss Energy: 6.25733199131943, Test Loss Force: 5.330966649750918, time: 12.234874486923218

Epoch 19, Batch 100/165, Loss: 0.07277051359415054, Uncertainty: 0.11929132044315338

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9607211835927867, Training Loss Force: 1.790137032711207, time: 2.807959794998169
Validation Loss Energy: 2.49463993069179, Validation Loss Force: 1.942709992903631, time: 0.19568586349487305
Test Loss Energy: 6.0431167021859356, Test Loss Force: 5.301674745107456, time: 9.240253686904907

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.040 MB uploadedwandb: | 0.039 MB of 0.040 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–…â–â–â–…â–â–ƒâ–â–â–ˆâ–ƒâ–â–ƒâ–ƒâ–â–â–â–…â–‚â–â–
wandb:   test_error_force â–†â–‡â–ˆâ–†â–…â–‡â–â–†â–‡â–‚â–…â–„â–ˆâ–‡â–†â–…â–…â–†â–†â–…
wandb:          test_loss â–…â–ƒâ–ƒâ–…â–ƒâ–†â–â–„â–ˆâ–‚â–„â–…â–„â–„â–ƒâ–ƒâ–†â–ƒâ–„â–„
wandb: train_error_energy â–ƒâ–‚â–‡â–â–„â–‚â–â–ƒâ–ƒâ–ˆâ–ƒâ–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚
wandb:  train_error_force â–ˆâ–ƒâ–‚â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–ƒâ–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–„â–‚â–‚â–â–â–ƒâ–ƒâ–„â–â–ƒâ–„â–‚â–ƒâ–‚â–â–‚â–‚â–
wandb: valid_error_energy â–ƒâ–ƒâ–â–„â–â–‚â–ƒâ–ƒâ–…â–‚â–‚â–ˆâ–‚â–â–ƒâ–‚â–ƒâ–â–â–ƒ
wandb:  valid_error_force â–‚â–…â–†â–…â–‚â–ƒâ–â–…â–ƒâ–ƒâ–â–‚â–…â–ˆâ–†â–…â–‚â–ˆâ–„â–‡
wandb:         valid_loss â–ƒâ–…â–„â–…â–‚â–‚â–ƒâ–…â–†â–ƒâ–â–ˆâ–„â–…â–…â–…â–ƒâ–…â–‚â–†
wandb: 
wandb: Run summary:
wandb:       dataset_size 5260
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.04312
wandb:   test_error_force 5.30167
wandb:          test_loss 2.51043
wandb: train_error_energy 1.96072
wandb:  train_error_force 1.79014
wandb:         train_loss -2.6737
wandb: valid_error_energy 2.49464
wandb:  valid_error_force 1.94271
wandb:         valid_loss -2.42175
wandb: 
wandb: ğŸš€ View run al_58_88 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/90ou9zxs
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_102542-90ou9zxs/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 45.341915130615234, Uncertainty Bias: -5.233770847320557
3.0517578e-05 0.0071907043
0.29085222 12.934519
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3701 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Found uncertainty sample 6 after 1874 steps.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 1659 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Found uncertainty sample 13 after 3209 steps.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1501 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Found uncertainty sample 26 after 2043 steps.
Found uncertainty sample 27 after 2628 steps.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Found uncertainty sample 30 after 3410 steps.
Found uncertainty sample 31 after 235 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 95 steps.
Found uncertainty sample 44 after 1557 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 2263 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2258 steps.
Found uncertainty sample 50 after 2117 steps.
Found uncertainty sample 51 after 2792 steps.
Found uncertainty sample 52 after 3512 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Found uncertainty sample 56 after 2136 steps.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 1931 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 994 steps.
Found uncertainty sample 66 after 1380 steps.
Found uncertainty sample 67 after 82 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1765 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 3111 steps.
Did not find any uncertainty samples for sample 85.
Found uncertainty sample 86 after 783 steps.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 3166 steps.
Found uncertainty sample 89 after 2201 steps.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2096 steps.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1772 steps.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 1887 steps.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2162 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_110522-j382asfy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_89
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/j382asfy
Training model 89. Added 30 samples to the dataset.
Epoch 0, Batch 100/166, Loss: 0.10331045091152191, Uncertainty: 0.12199590355157852

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.1138931182641008, Training Loss Force: 1.9869508594684917, time: 2.765068292617798
Validation Loss Energy: 2.3230130104158833, Validation Loss Force: 1.9429589370087783, time: 0.1979966163635254
Test Loss Energy: 5.9972046069458225, Test Loss Force: 5.348875050139377, time: 11.373822212219238

Epoch 1, Batch 100/166, Loss: 0.15195316076278687, Uncertainty: 0.11973755061626434

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.998610898778596, Training Loss Force: 1.7994266988589063, time: 2.6753644943237305
Validation Loss Energy: 0.7977116771691972, Validation Loss Force: 1.8688044333516036, time: 0.18012285232543945
Test Loss Energy: 6.6182618566043026, Test Loss Force: 5.229488142980999, time: 11.597551107406616

Epoch 2, Batch 100/166, Loss: 0.05481330677866936, Uncertainty: 0.11990244686603546

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.7793456890423596, Training Loss Force: 1.846523971040377, time: 2.695364236831665
Validation Loss Energy: 2.715919101587648, Validation Loss Force: 1.9021051979094936, time: 0.17593860626220703
Test Loss Energy: 6.193984498583932, Test Loss Force: 5.346944711494608, time: 12.39350962638855

Epoch 3, Batch 100/166, Loss: 0.1138947457075119, Uncertainty: 0.1206432357430458

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8722779900920916, Training Loss Force: 1.7917731337544018, time: 2.6623971462249756
Validation Loss Energy: 1.5425910171993518, Validation Loss Force: 1.9985252801445714, time: 0.16430974006652832
Test Loss Energy: 7.077058835890364, Test Loss Force: 5.391355398813433, time: 11.611482858657837

Epoch 4, Batch 100/166, Loss: 0.04677218198776245, Uncertainty: 0.11984339356422424

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.8348042751784892, Training Loss Force: 1.8079751994298832, time: 2.6617820262908936
Validation Loss Energy: 2.3899219713991404, Validation Loss Force: 1.8544360758146998, time: 0.14643597602844238
Test Loss Energy: 6.210099234882554, Test Loss Force: 5.237572513553127, time: 10.01861310005188

Epoch 5, Batch 100/166, Loss: 0.05635257065296173, Uncertainty: 0.11827830970287323

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.8784307892978895, Training Loss Force: 1.7699527170768323, time: 2.7414956092834473
Validation Loss Energy: 0.8983334148533594, Validation Loss Force: 1.9095855080862674, time: 0.18789052963256836
Test Loss Energy: 6.522043135476856, Test Loss Force: 5.3252393078658935, time: 11.420816659927368

Epoch 6, Batch 100/166, Loss: 0.4372888505458832, Uncertainty: 0.12033801525831223

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.094421833683063, Training Loss Force: 1.803522880225982, time: 2.7033674716949463
Validation Loss Energy: 3.202572540124395, Validation Loss Force: 1.834593026209918, time: 0.16951632499694824
Test Loss Energy: 8.430519403028699, Test Loss Force: 5.33393506029593, time: 8.868863105773926

Epoch 7, Batch 100/166, Loss: 0.1020188108086586, Uncertainty: 0.11961698532104492

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 1.7907965082217432, Training Loss Force: 1.8198389001903423, time: 2.5217227935791016
Validation Loss Energy: 0.7924035416224733, Validation Loss Force: 1.8486838637679472, time: 0.1595616340637207
Test Loss Energy: 6.280342888995228, Test Loss Force: 5.270778260950684, time: 8.81316590309143

Epoch 8, Batch 100/166, Loss: 0.15233580768108368, Uncertainty: 0.11987680941820145

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.9903912647749356, Training Loss Force: 1.7981640286513856, time: 2.5675246715545654
Validation Loss Energy: 0.813003703434934, Validation Loss Force: 1.898253281465613, time: 0.1399378776550293
Test Loss Energy: 6.295438628328504, Test Loss Force: 5.29753014250653, time: 9.192379713058472

Epoch 9, Batch 100/166, Loss: 0.056070588529109955, Uncertainty: 0.11981147527694702

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.4695622896268827, Training Loss Force: 1.795019384979401, time: 2.462679624557495
Validation Loss Energy: 4.196315100734558, Validation Loss Force: 1.9096912388190586, time: 0.15011048316955566
Test Loss Energy: 9.517125137680441, Test Loss Force: 5.332338219409796, time: 9.013957977294922

Epoch 10, Batch 100/166, Loss: 0.13637371361255646, Uncertainty: 0.11943025887012482

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.8768084554351698, Training Loss Force: 1.7952079911115233, time: 2.4764933586120605
Validation Loss Energy: 4.127437299163007, Validation Loss Force: 1.814258954026841, time: 0.1518230438232422
Test Loss Energy: 9.391826872989553, Test Loss Force: 5.287079561350997, time: 8.939462900161743

Epoch 11, Batch 100/166, Loss: 0.13726109266281128, Uncertainty: 0.11894315481185913

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.045025820141697, Training Loss Force: 1.7976353537489054, time: 2.5355777740478516
Validation Loss Energy: 0.9343629155715455, Validation Loss Force: 1.870154513494888, time: 0.14604425430297852
Test Loss Energy: 6.117491372584213, Test Loss Force: 5.235424786868352, time: 9.036329984664917

Epoch 12, Batch 100/166, Loss: 0.04704626277089119, Uncertainty: 0.12025588005781174

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 1.9631718077600346, Training Loss Force: 1.8203987098732208, time: 2.5250587463378906
Validation Loss Energy: 1.7200291939572063, Validation Loss Force: 1.8464124900333865, time: 0.1676328182220459
Test Loss Energy: 5.93282612109047, Test Loss Force: 5.312455587741259, time: 8.96074891090393

Epoch 13, Batch 100/166, Loss: 0.1591988056898117, Uncertainty: 0.11983458697795868

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 1.637169037625866, Training Loss Force: 1.8034542310600166, time: 2.5978362560272217
Validation Loss Energy: 0.7759257279316225, Validation Loss Force: 1.8078329822560353, time: 0.1458745002746582
Test Loss Energy: 6.494804412898293, Test Loss Force: 5.262364099886331, time: 8.912306308746338

Epoch 14, Batch 100/166, Loss: 0.12436693906784058, Uncertainty: 0.12248925864696503

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.9160040158576346, Training Loss Force: 1.8256795179242404, time: 2.8218491077423096
Validation Loss Energy: 3.552748941753958, Validation Loss Force: 1.860548974766331, time: 0.1503441333770752
Test Loss Energy: 8.7410370529504, Test Loss Force: 5.324768193580235, time: 8.814966201782227

Epoch 15, Batch 100/166, Loss: 0.05482584610581398, Uncertainty: 0.12191004306077957

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.694010612835416, Training Loss Force: 1.82866385188358, time: 2.468033790588379
Validation Loss Energy: 0.7239703546680539, Validation Loss Force: 1.8015097351845508, time: 0.1491396427154541
Test Loss Energy: 6.302827396810054, Test Loss Force: 5.2275358358682436, time: 8.904991388320923

Epoch 16, Batch 100/166, Loss: 0.1205112487077713, Uncertainty: 0.11697298288345337

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.2430834003666824, Training Loss Force: 1.8274355793642738, time: 2.6353230476379395
Validation Loss Energy: 1.0662550277622171, Validation Loss Force: 1.9829011799592073, time: 0.19127225875854492
Test Loss Energy: 6.114602544691437, Test Loss Force: 5.305846205571126, time: 12.230589389801025

Epoch 17, Batch 100/166, Loss: 0.04457928240299225, Uncertainty: 0.118893563747406

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 1.8169643380958032, Training Loss Force: 1.7986115882691789, time: 2.7330141067504883
Validation Loss Energy: 0.9123916684930347, Validation Loss Force: 1.8698957348357956, time: 0.18138790130615234
Test Loss Energy: 6.66082685219641, Test Loss Force: 5.204541138247166, time: 10.905609130859375

Epoch 18, Batch 100/166, Loss: 0.07452262938022614, Uncertainty: 0.1199236512184143

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.960537964761393, Training Loss Force: 1.824695699909892, time: 2.6053507328033447
Validation Loss Energy: 2.6649040415715706, Validation Loss Force: 1.9955856763030813, time: 0.17351508140563965
Test Loss Energy: 6.1508818724193075, Test Loss Force: 5.412127198511361, time: 9.949220895767212

Epoch 19, Batch 100/166, Loss: 0.11439698934555054, Uncertainty: 0.1216067373752594

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9576144315513142, Training Loss Force: 1.8047470454385122, time: 2.402953624725342
Validation Loss Energy: 1.1849209823557836, Validation Loss Force: 1.840984372928532, time: 0.16915035247802734
Test Loss Energy: 6.165890486328753, Test Loss Force: 5.1600211215434975, time: 9.623042821884155

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.039 MB of 0.049 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‚â–ƒâ–‚â–‚â–†â–‚â–‚â–ˆâ–ˆâ–â–â–‚â–†â–‚â–â–‚â–â–
wandb:   test_error_force â–†â–ƒâ–†â–‡â–ƒâ–†â–†â–„â–…â–†â–…â–ƒâ–…â–„â–†â–ƒâ–…â–‚â–ˆâ–
wandb:          test_loss â–„â–ƒâ–ƒâ–‡â–‚â–†â–†â–‚â–„â–ˆâ–‡â–‚â–„â–„â–…â–‚â–‚â–‚â–†â–
wandb: train_error_energy â–ˆâ–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–…â–‚â–ƒâ–ƒâ–â–‚â–†â–„â–‚â–ƒâ–ƒ
wandb:  train_error_force â–ˆâ–‚â–ƒâ–‚â–‚â–â–‚â–ƒâ–‚â–‚â–‚â–‚â–ƒâ–‚â–ƒâ–ƒâ–ƒâ–‚â–ƒâ–‚
wandb:         train_loss â–ˆâ–‚â–ƒâ–‚â–‚â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–‚â–‚â–‚
wandb: valid_error_energy â–„â–â–…â–ƒâ–„â–â–†â–â–â–ˆâ–ˆâ–â–ƒâ–â–‡â–â–‚â–â–…â–‚
wandb:  valid_error_force â–†â–ƒâ–…â–ˆâ–ƒâ–…â–‚â–ƒâ–„â–…â–â–ƒâ–ƒâ–â–ƒâ–â–‡â–ƒâ–ˆâ–‚
wandb:         valid_loss â–†â–ƒâ–†â–‡â–„â–„â–…â–‚â–ƒâ–ˆâ–…â–ƒâ–ƒâ–â–†â–â–†â–ƒâ–ˆâ–ƒ
wandb: 
wandb: Run summary:
wandb:       dataset_size 5287
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.16589
wandb:   test_error_force 5.16002
wandb:          test_loss 2.28203
wandb: train_error_energy 1.95761
wandb:  train_error_force 1.80475
wandb:         train_loss -2.65364
wandb: valid_error_energy 1.18492
wandb:  valid_error_force 1.84098
wandb:         valid_loss -2.65404
wandb: 
wandb: ğŸš€ View run al_58_89 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/j382asfy
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_110522-j382asfy/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 45.04508972167969, Uncertainty Bias: -5.246730804443359
3.0517578e-05 0.0005569458
0.1753564 13.084716
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3591 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 590 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Found uncertainty sample 12 after 3031 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 2262 steps.
Found uncertainty sample 20 after 2457 steps.
Found uncertainty sample 21 after 2881 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 3328 steps.
Found uncertainty sample 29 after 1666 steps.
Found uncertainty sample 30 after 3588 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Found uncertainty sample 38 after 1152 steps.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Found uncertainty sample 45 after 3297 steps.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Found uncertainty sample 52 after 3155 steps.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 1110 steps.
Did not find any uncertainty samples for sample 56.
Found uncertainty sample 57 after 2085 steps.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Found uncertainty sample 61 after 2875 steps.
Found uncertainty sample 62 after 3753 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Found uncertainty sample 65 after 1753 steps.
Did not find any uncertainty samples for sample 66.
Found uncertainty sample 67 after 1720 steps.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Found uncertainty sample 71 after 276 steps.
Found uncertainty sample 72 after 1197 steps.
Did not find any uncertainty samples for sample 73.
Found uncertainty sample 74 after 2371 steps.
Found uncertainty sample 75 after 3970 steps.
Did not find any uncertainty samples for sample 76.
Found uncertainty sample 77 after 2542 steps.
Found uncertainty sample 78 after 2877 steps.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Did not find any uncertainty samples for sample 81.
Found uncertainty sample 82 after 3280 steps.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 3065 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Found uncertainty sample 89 after 3319 steps.
Found uncertainty sample 90 after 3199 steps.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 3613 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2496 steps.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_114548-8tm3ijkn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_90
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8tm3ijkn
Training model 90. Added 30 samples to the dataset.
Epoch 0, Batch 100/167, Loss: 0.0983039140701294, Uncertainty: 0.12246912717819214

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.68473373924991, Training Loss Force: 1.916759423073773, time: 2.5306408405303955
Validation Loss Energy: 2.2043925545511347, Validation Loss Force: 1.9341917847261634, time: 0.17890357971191406
Test Loss Energy: 6.010703461092298, Test Loss Force: 5.133196467980182, time: 11.154126644134521

Epoch 1, Batch 100/167, Loss: 0.054008156061172485, Uncertainty: 0.12101976573467255

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.9539905282820738, Training Loss Force: 1.8257609298708644, time: 2.6528100967407227
Validation Loss Energy: 1.1262367145041365, Validation Loss Force: 2.008116902051508, time: 0.18060827255249023
Test Loss Energy: 6.829323341561369, Test Loss Force: 5.39681136646573, time: 11.393455028533936

Epoch 2, Batch 100/167, Loss: 0.045916151255369186, Uncertainty: 0.12025213241577148

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.2855770465932954, Training Loss Force: 1.8041000040253352, time: 2.5503039360046387
Validation Loss Energy: 4.321875411647389, Validation Loss Force: 1.908572845922112, time: 0.1739044189453125
Test Loss Energy: 9.426862666983261, Test Loss Force: 5.208864885753737, time: 11.327391386032104

Epoch 3, Batch 100/167, Loss: 0.1634242683649063, Uncertainty: 0.11948172748088837

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.99044991623119, Training Loss Force: 1.8188483515709335, time: 2.5805270671844482
Validation Loss Energy: 2.291857737302056, Validation Loss Force: 1.8229900710193399, time: 0.18019437789916992
Test Loss Energy: 7.767849221097678, Test Loss Force: 5.2311333065692205, time: 11.512784481048584

Epoch 4, Batch 100/167, Loss: 0.12139824777841568, Uncertainty: 0.12106411159038544

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 2.542793359178988, Training Loss Force: 1.8155866052537288, time: 2.6576554775238037
Validation Loss Energy: 2.0144351390672086, Validation Loss Force: 1.9955738748383471, time: 0.16817998886108398
Test Loss Energy: 7.567130785585767, Test Loss Force: 5.293722369540774, time: 11.469584226608276

Epoch 5, Batch 100/167, Loss: 0.0654461532831192, Uncertainty: 0.11928943544626236

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.466196256325224, Training Loss Force: 1.7998569827823392, time: 2.515110969543457
Validation Loss Energy: 4.765615829711787, Validation Loss Force: 2.133508429751726, time: 0.15802454948425293
Test Loss Energy: 9.659195378713852, Test Loss Force: 5.484013472421279, time: 11.213675260543823

Epoch 6, Batch 100/167, Loss: 0.06637222319841385, Uncertainty: 0.12039710581302643

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.6723582438420586, Training Loss Force: 1.8031089936578129, time: 2.523367404937744
Validation Loss Energy: 2.6931486578328774, Validation Loss Force: 1.8817453332170135, time: 0.16965103149414062
Test Loss Energy: 6.1197903790546, Test Loss Force: 5.229668278822633, time: 11.512345314025879

Epoch 7, Batch 100/167, Loss: 0.23778516054153442, Uncertainty: 0.12306937575340271

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.0811035709279024, Training Loss Force: 1.8465720229207818, time: 2.515700578689575
Validation Loss Energy: 1.6640256028418596, Validation Loss Force: 2.1418792309545895, time: 0.14478302001953125
Test Loss Energy: 6.175344703496945, Test Loss Force: 5.387856588031207, time: 10.145132064819336

Epoch 8, Batch 100/167, Loss: 0.11440469324588776, Uncertainty: 0.11940018832683563

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.322450106815022, Training Loss Force: 1.7938570606441795, time: 2.5217854976654053
Validation Loss Energy: 2.3384187463921404, Validation Loss Force: 1.8375805410293067, time: 0.16898250579833984
Test Loss Energy: 6.082262131564011, Test Loss Force: 5.22578879473382, time: 11.046369075775146

Epoch 9, Batch 100/167, Loss: 0.15927942097187042, Uncertainty: 0.11952882260084152

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.067438941782065, Training Loss Force: 1.7966539377853985, time: 2.4790165424346924
Validation Loss Energy: 1.6503278134379171, Validation Loss Force: 1.9538683149213156, time: 0.1480259895324707
Test Loss Energy: 6.042128058172858, Test Loss Force: 5.29055413966795, time: 8.881277322769165

Epoch 10, Batch 100/167, Loss: 0.3320060968399048, Uncertainty: 0.11942432820796967

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9765702250241237, Training Loss Force: 1.8163335162367134, time: 2.567805290222168
Validation Loss Energy: 4.551923813071223, Validation Loss Force: 1.8891566901815982, time: 0.14250946044921875
Test Loss Energy: 10.004113355197767, Test Loss Force: 5.266552690718747, time: 8.902379274368286

Epoch 11, Batch 100/167, Loss: 0.18471956253051758, Uncertainty: 0.11845014989376068

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.059697086915401, Training Loss Force: 1.8093821128378256, time: 2.7120256423950195
Validation Loss Energy: 2.5135224969356122, Validation Loss Force: 1.9786924362089777, time: 0.14599847793579102
Test Loss Energy: 7.62218709824227, Test Loss Force: 5.229587430103941, time: 8.826012134552002

Epoch 12, Batch 100/167, Loss: 0.13190072774887085, Uncertainty: 0.11978666484355927

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.18878880759239, Training Loss Force: 1.7827199439737118, time: 2.5735714435577393
Validation Loss Energy: 3.1683818412132805, Validation Loss Force: 1.9970476476921946, time: 0.14290428161621094
Test Loss Energy: 6.298788141197097, Test Loss Force: 5.256478439072744, time: 8.89993143081665

Epoch 13, Batch 100/167, Loss: 0.16540689766407013, Uncertainty: 0.12183937430381775

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.75133791150623, Training Loss Force: 1.8189828664019925, time: 2.536909580230713
Validation Loss Energy: 0.7967188325590296, Validation Loss Force: 1.8771444691008046, time: 0.14272689819335938
Test Loss Energy: 6.56641128016493, Test Loss Force: 5.1660218241964575, time: 9.082235336303711

Epoch 14, Batch 100/167, Loss: 0.050401169806718826, Uncertainty: 0.12034457921981812

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 1.8707074933185885, Training Loss Force: 1.8098021155142543, time: 2.55487060546875
Validation Loss Energy: 3.2323255171802177, Validation Loss Force: 1.9149600361500019, time: 0.14701032638549805
Test Loss Energy: 8.692679707740727, Test Loss Force: 5.239463214758305, time: 9.6720290184021

Epoch 15, Batch 100/167, Loss: 0.03895660117268562, Uncertainty: 0.1208806186914444

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.7033758667010266, Training Loss Force: 1.7748485103309481, time: 2.5830137729644775
Validation Loss Energy: 1.3522852729481463, Validation Loss Force: 1.876144684635589, time: 0.14244771003723145
Test Loss Energy: 5.968937845402459, Test Loss Force: 5.171132778248113, time: 8.852492570877075

Epoch 16, Batch 100/167, Loss: 0.08503775298595428, Uncertainty: 0.11910606920719147

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.0999198487669846, Training Loss Force: 1.8306424028892299, time: 2.5462758541107178
Validation Loss Energy: 2.8779296836814203, Validation Loss Force: 2.145970628064915, time: 0.15417981147766113
Test Loss Energy: 6.172113370820294, Test Loss Force: 5.330608525484229, time: 9.134114980697632

Epoch 17, Batch 100/167, Loss: 0.4375147819519043, Uncertainty: 0.12151936441659927

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3077844038562794, Training Loss Force: 1.8222027669199405, time: 2.6324777603149414
Validation Loss Energy: 2.359949294119336, Validation Loss Force: 1.848925830906522, time: 0.14112615585327148
Test Loss Energy: 6.116171352581326, Test Loss Force: 5.177122837082735, time: 8.882522106170654

Epoch 18, Batch 100/167, Loss: 0.2465973198413849, Uncertainty: 0.11843422800302505

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.2810796171843135, Training Loss Force: 1.783799527994105, time: 2.502690076828003
Validation Loss Energy: 0.955005662858165, Validation Loss Force: 1.7391712068675587, time: 0.14164090156555176
Test Loss Energy: 6.152035858182598, Test Loss Force: 5.175377197248383, time: 9.440978765487671

Epoch 19, Batch 100/167, Loss: 0.14758992195129395, Uncertainty: 0.11841146647930145

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.331781378712037, Training Loss Force: 1.7929855022733356, time: 2.5237607955932617
Validation Loss Energy: 0.8012859622996301, Validation Loss Force: 1.9710231170388355, time: 0.18096446990966797
Test Loss Energy: 6.429921626893887, Test Loss Force: 5.1700541129465005, time: 11.833298683166504

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.055 MB uploadedwandb: / 0.039 MB of 0.055 MB uploadedwandb: - 0.058 MB of 0.058 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–‚â–‡â–„â–„â–‡â–â–â–â–â–ˆâ–„â–‚â–‚â–†â–â–â–â–â–‚
wandb:   test_error_force â–â–†â–ƒâ–ƒâ–„â–ˆâ–ƒâ–†â–ƒâ–„â–„â–ƒâ–ƒâ–‚â–ƒâ–‚â–…â–‚â–‚â–‚
wandb:          test_loss â–â–…â–„â–„â–„â–ˆâ–ƒâ–…â–ƒâ–ƒâ–…â–ƒâ–ƒâ–‚â–„â–ƒâ–ƒâ–â–‚â–
wandb: train_error_energy â–ˆâ–ƒâ–…â–ƒâ–‡â–†â–â–„â–…â–„â–ƒâ–„â–„â–ˆâ–‚â–â–„â–…â–…â–…
wandb:  train_error_force â–ˆâ–„â–‚â–ƒâ–ƒâ–‚â–‚â–…â–‚â–‚â–ƒâ–ƒâ–â–ƒâ–ƒâ–â–„â–ƒâ–â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–ƒâ–„â–ƒâ–‚â–„â–ƒâ–‚â–ƒâ–ƒâ–‚â–…â–ƒâ–â–„â–„â–‚â–ƒ
wandb: valid_error_energy â–ƒâ–‚â–‡â–„â–ƒâ–ˆâ–„â–ƒâ–„â–ƒâ–ˆâ–„â–…â–â–…â–‚â–…â–„â–â–
wandb:  valid_error_force â–„â–†â–„â–‚â–…â–ˆâ–ƒâ–ˆâ–ƒâ–…â–„â–…â–…â–ƒâ–„â–ƒâ–ˆâ–ƒâ–â–…
wandb:         valid_loss â–„â–„â–…â–ƒâ–…â–ˆâ–„â–†â–ƒâ–„â–…â–…â–…â–ƒâ–„â–ƒâ–‡â–ƒâ–â–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 5314
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.42992
wandb:   test_error_force 5.17005
wandb:          test_loss 2.24662
wandb: train_error_energy 2.33178
wandb:  train_error_force 1.79299
wandb:         train_loss -2.64471
wandb: valid_error_energy 0.80129
wandb:  valid_error_force 1.97102
wandb:         valid_loss -2.50004
wandb: 
wandb: ğŸš€ View run al_58_90 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/8tm3ijkn
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_114548-8tm3ijkn/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.426300048828125, Uncertainty Bias: -5.104832172393799
9.1552734e-05 0.001364708
0.30625737 13.18946
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Found uncertainty sample 2 after 2077 steps.
Did not find any uncertainty samples for sample 3.
Found uncertainty sample 4 after 2211 steps.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Found uncertainty sample 17 after 3461 steps.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 3564 steps.
Did not find any uncertainty samples for sample 20.
Found uncertainty sample 21 after 2633 steps.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 1044 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 736 steps.
Found uncertainty sample 29 after 2716 steps.
Did not find any uncertainty samples for sample 30.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 2415 steps.
Found uncertainty sample 40 after 57 steps.
Found uncertainty sample 41 after 1867 steps.
Found uncertainty sample 42 after 1434 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Found uncertainty sample 47 after 2000 steps.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Found uncertainty sample 54 after 2992 steps.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Found uncertainty sample 60 after 2013 steps.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Found uncertainty sample 70 after 848 steps.
Found uncertainty sample 71 after 2136 steps.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3985 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Found uncertainty sample 84 after 2010 steps.
Found uncertainty sample 85 after 1419 steps.
Did not find any uncertainty samples for sample 86.
Found uncertainty sample 87 after 3447 steps.
Found uncertainty sample 88 after 3738 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1926 steps.
Did not find any uncertainty samples for sample 95.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Found uncertainty sample 98 after 2522 steps.
Found uncertainty sample 99 after 2688 steps.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_122604-qvukfylf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_91
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qvukfylf
Training model 91. Added 25 samples to the dataset.
Epoch 0, Batch 100/167, Loss: 0.06431630253791809, Uncertainty: 0.12386393547058105

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.3290422158800923, Training Loss Force: 1.9720549260828444, time: 2.6815977096557617
Validation Loss Energy: 4.190302291564021, Validation Loss Force: 1.9232084064341295, time: 0.17426466941833496
Test Loss Energy: 6.427915443174271, Test Loss Force: 5.188773866075597, time: 10.93970251083374

Epoch 1, Batch 100/167, Loss: 0.07306043803691864, Uncertainty: 0.12205170094966888

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 2.121191497944864, Training Loss Force: 1.7966331028867506, time: 2.679353952407837
Validation Loss Energy: 4.97390871334799, Validation Loss Force: 1.8853542062881135, time: 0.1792163848876953
Test Loss Energy: 9.959511419564537, Test Loss Force: 5.241300048683081, time: 11.187953233718872

Epoch 2, Batch 100/167, Loss: 0.06418228894472122, Uncertainty: 0.11898502707481384

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.4319964388681368, Training Loss Force: 1.8090034386215605, time: 2.638773202896118
Validation Loss Energy: 2.2659928604263277, Validation Loss Force: 1.918997992665305, time: 0.17904353141784668
Test Loss Energy: 7.456404390842017, Test Loss Force: 5.302724206942547, time: 11.045753240585327

Epoch 3, Batch 100/167, Loss: 0.04211382195353508, Uncertainty: 0.11869341880083084

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.6974622630239606, Training Loss Force: 1.7618604983854236, time: 2.6860485076904297
Validation Loss Energy: 1.2730432988678622, Validation Loss Force: 1.8019810886549557, time: 0.17954325675964355
Test Loss Energy: 6.880517734178024, Test Loss Force: 5.213448885693811, time: 11.125025749206543

Epoch 4, Batch 100/167, Loss: 0.059938106685876846, Uncertainty: 0.11797221750020981

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9538307090026006, Training Loss Force: 1.7843697190094394, time: 2.725975275039673
Validation Loss Energy: 1.7236773310210385, Validation Loss Force: 1.7799188070072844, time: 0.18240952491760254
Test Loss Energy: 7.181171243526146, Test Loss Force: 5.141081814304904, time: 11.078548908233643

Epoch 5, Batch 100/167, Loss: 0.05756067484617233, Uncertainty: 0.11924391984939575

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.0705213829361684, Training Loss Force: 1.7847836996188164, time: 2.5203137397766113
Validation Loss Energy: 1.009322015631768, Validation Loss Force: 1.9309613007570432, time: 0.18191003799438477
Test Loss Energy: 6.020936271823112, Test Loss Force: 5.23029751618127, time: 11.073710441589355

Epoch 6, Batch 100/167, Loss: 0.2576841711997986, Uncertainty: 0.11880013346672058

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.284068498463361, Training Loss Force: 1.7908490018182697, time: 2.471085548400879
Validation Loss Energy: 3.6361477405619467, Validation Loss Force: 1.881322670066518, time: 0.14960503578186035
Test Loss Energy: 8.556164381066901, Test Loss Force: 5.1249672971780065, time: 10.768841981887817

Epoch 7, Batch 100/167, Loss: 0.18136785924434662, Uncertainty: 0.12303583323955536

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.113401697877698, Training Loss Force: 1.840333160122189, time: 2.6717183589935303
Validation Loss Energy: 2.2832206980237117, Validation Loss Force: 2.0038602844349036, time: 0.17891502380371094
Test Loss Energy: 7.524388398461815, Test Loss Force: 5.3007335144669705, time: 10.860217332839966

Epoch 8, Batch 100/167, Loss: 0.05975005775690079, Uncertainty: 0.11882384121417999

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.2514768132450054, Training Loss Force: 1.7778066626011835, time: 2.5906717777252197
Validation Loss Energy: 0.8787048698591547, Validation Loss Force: 2.0451427729746725, time: 0.1655867099761963
Test Loss Energy: 6.493294611166268, Test Loss Force: 5.3946930740772725, time: 9.186681985855103

Epoch 9, Batch 100/167, Loss: 0.07600365579128265, Uncertainty: 0.11736196279525757

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.7155549491397017, Training Loss Force: 1.7708161080997102, time: 2.5626392364501953
Validation Loss Energy: 1.2318380394102062, Validation Loss Force: 1.836583799709085, time: 0.14847826957702637
Test Loss Energy: 6.950274442345345, Test Loss Force: 5.250625402203555, time: 8.942595481872559

Epoch 10, Batch 100/167, Loss: 0.15037982165813446, Uncertainty: 0.12128382176160812

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 1.9945764088433902, Training Loss Force: 1.7923360123750651, time: 2.6204471588134766
Validation Loss Energy: 0.7209618532816614, Validation Loss Force: 1.8572534342950755, time: 0.14592790603637695
Test Loss Energy: 6.119549024353325, Test Loss Force: 5.1286997403556285, time: 8.969144582748413

Epoch 11, Batch 100/167, Loss: 0.04907159507274628, Uncertainty: 0.1183539405465126

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.339481754450194, Training Loss Force: 1.7927700478744057, time: 2.54616117477417
Validation Loss Energy: 1.9211729135481548, Validation Loss Force: 1.9114394142837376, time: 0.14637303352355957
Test Loss Energy: 7.348496033855548, Test Loss Force: 5.122177364697007, time: 9.205210447311401

Epoch 12, Batch 100/167, Loss: 0.055952299386262894, Uncertainty: 0.12102136015892029

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.274346008877085, Training Loss Force: 1.82213342281451, time: 2.4758243560791016
Validation Loss Energy: 0.9589265510699966, Validation Loss Force: 1.8836867855003574, time: 0.14916181564331055
Test Loss Energy: 6.532410676196448, Test Loss Force: 5.141186522430614, time: 9.055004835128784

Epoch 13, Batch 100/167, Loss: 0.08381690084934235, Uncertainty: 0.11977127194404602

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 2.068820775167788, Training Loss Force: 1.80864760065956, time: 2.6033823490142822
Validation Loss Energy: 0.8069384556805312, Validation Loss Force: 1.9105536735327615, time: 0.14809608459472656
Test Loss Energy: 6.19355848237807, Test Loss Force: 5.2544862823435174, time: 9.160377979278564

Epoch 14, Batch 100/167, Loss: 0.05217095836997032, Uncertainty: 0.11923199892044067

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.0660194796440394, Training Loss Force: 1.7861699603871684, time: 2.5057590007781982
Validation Loss Energy: 0.9198800133148239, Validation Loss Force: 1.820394602342881, time: 0.1461467742919922
Test Loss Energy: 6.2195807319356415, Test Loss Force: 5.190751531823234, time: 9.083303689956665

Epoch 15, Batch 100/167, Loss: 0.19312268495559692, Uncertainty: 0.1194206029176712

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.1773792448884315, Training Loss Force: 1.8152493008314199, time: 2.729559898376465
Validation Loss Energy: 0.7118213961758988, Validation Loss Force: 1.787898304297704, time: 0.14281821250915527
Test Loss Energy: 6.18041654239057, Test Loss Force: 5.164288611865223, time: 8.88842225074768

Epoch 16, Batch 100/167, Loss: 0.07927002757787704, Uncertainty: 0.11857791244983673

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 1.6956106657410874, Training Loss Force: 1.7793176740918788, time: 2.5531527996063232
Validation Loss Energy: 0.8632115692412613, Validation Loss Force: 1.8433496388196253, time: 0.14952564239501953
Test Loss Energy: 6.124708939969333, Test Loss Force: 5.185490564052417, time: 9.263526916503906

Epoch 17, Batch 100/167, Loss: 0.1585989147424698, Uncertainty: 0.11860919743776321

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.120624449631188, Training Loss Force: 1.776918084040833, time: 2.5701329708099365
Validation Loss Energy: 2.3878813571228092, Validation Loss Force: 1.8080513093536172, time: 0.14453601837158203
Test Loss Energy: 6.0883262471254715, Test Loss Force: 5.110391353901046, time: 10.11152696609497

Epoch 18, Batch 100/167, Loss: 0.10541178286075592, Uncertainty: 0.12010334432125092

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.968366068010057, Training Loss Force: 1.7870267072597634, time: 2.7008321285247803
Validation Loss Energy: 2.267949676880741, Validation Loss Force: 1.8125054345026597, time: 0.19943952560424805
Test Loss Energy: 6.037189981648163, Test Loss Force: 5.155071228398577, time: 11.957005023956299

Epoch 19, Batch 100/167, Loss: 0.11798787862062454, Uncertainty: 0.11809951066970825

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 1.9710360717386324, Training Loss Force: 1.7932634360345954, time: 2.6535286903381348
Validation Loss Energy: 0.8129428034235228, Validation Loss Force: 1.9027958062655888, time: 0.18187904357910156
Test Loss Energy: 6.396505831377491, Test Loss Force: 5.227037455687374, time: 10.438281059265137

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.039 MB uploadedwandb: | 0.039 MB of 0.059 MB uploadedwandb: / 0.039 MB of 0.059 MB uploadedwandb: - 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–‚â–ˆâ–„â–ƒâ–ƒâ–â–†â–„â–‚â–ƒâ–â–ƒâ–‚â–â–â–â–â–â–â–‚
wandb:   test_error_force â–ƒâ–„â–†â–„â–‚â–„â–â–†â–ˆâ–„â–â–â–‚â–…â–ƒâ–‚â–ƒâ–â–‚â–„
wandb:          test_loss â–â–‡â–…â–…â–ƒâ–„â–„â–†â–ˆâ–…â–‚â–‚â–â–ƒâ–ƒâ–â–‚â–â–ƒâ–„
wandb: train_error_energy â–‡â–…â–ˆâ–â–ƒâ–…â–‡â–…â–†â–â–„â–‡â–‡â–…â–…â–†â–â–…â–„â–„
wandb:  train_error_force â–ˆâ–‚â–ƒâ–â–‚â–‚â–‚â–„â–‚â–â–‚â–‚â–ƒâ–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚
wandb:         train_loss â–ˆâ–ƒâ–ƒâ–â–‚â–‚â–ƒâ–„â–‚â–â–‚â–ƒâ–„â–ƒâ–‚â–ƒâ–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‡â–ˆâ–„â–‚â–ƒâ–â–†â–„â–â–‚â–â–ƒâ–â–â–â–â–â–„â–„â–
wandb:  valid_error_force â–…â–„â–…â–‚â–â–…â–„â–‡â–ˆâ–‚â–ƒâ–„â–„â–„â–‚â–â–ƒâ–‚â–‚â–„
wandb:         valid_loss â–ˆâ–ˆâ–†â–‚â–‚â–…â–†â–ˆâ–‡â–ƒâ–ƒâ–…â–ƒâ–„â–‚â–â–‚â–ƒâ–ƒâ–„
wandb: 
wandb: Run summary:
wandb:       dataset_size 5336
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 6.39651
wandb:   test_error_force 5.22704
wandb:          test_loss 2.38448
wandb: train_error_energy 1.97104
wandb:  train_error_force 1.79326
wandb:         train_loss -2.66852
wandb: valid_error_energy 0.81294
wandb:  valid_error_force 1.9028
wandb:         valid_loss -2.59208
wandb: 
wandb: ğŸš€ View run al_58_91 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/qvukfylf
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_122604-qvukfylf/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 43.242855072021484, Uncertainty Bias: -5.0273566246032715
1.9073486e-05 0.000374794
0.34635204 15.5534935
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3198 steps.
Found uncertainty sample 1 after 2302 steps.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 282 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 2057 steps.
Did not find any uncertainty samples for sample 10.
Found uncertainty sample 11 after 2954 steps.
Found uncertainty sample 12 after 2105 steps.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Found uncertainty sample 19 after 1009 steps.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Found uncertainty sample 22 after 3978 steps.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Found uncertainty sample 25 after 2314 steps.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Did not find any uncertainty samples for sample 29.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 3176 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Did not find any uncertainty samples for sample 35.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Found uncertainty sample 40 after 2497 steps.
Did not find any uncertainty samples for sample 41.
Found uncertainty sample 42 after 1247 steps.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Found uncertainty sample 49 after 2591 steps.
Did not find any uncertainty samples for sample 50.
Found uncertainty sample 51 after 1533 steps.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Found uncertainty sample 55 after 3106 steps.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Did not find any uncertainty samples for sample 63.
Found uncertainty sample 64 after 2696 steps.
Found uncertainty sample 65 after 3798 steps.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 1852 steps.
Found uncertainty sample 70 after 1364 steps.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Did not find any uncertainty samples for sample 73.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Did not find any uncertainty samples for sample 76.
Did not find any uncertainty samples for sample 77.
Did not find any uncertainty samples for sample 78.
Found uncertainty sample 79 after 3428 steps.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 1514 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Did not find any uncertainty samples for sample 85.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Found uncertainty sample 88 after 998 steps.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Did not find any uncertainty samples for sample 92.
Did not find any uncertainty samples for sample 93.
Found uncertainty sample 94 after 1470 steps.
Found uncertainty sample 95 after 246 steps.
Did not find any uncertainty samples for sample 96.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_130610-2z0qu8wj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_92
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2z0qu8wj
Training model 92. Added 24 samples to the dataset.
Epoch 0, Batch 100/168, Loss: 0.3396047353744507, Uncertainty: 0.1214304268360138

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 2.2605242516662623, Training Loss Force: 1.9179263669160613, time: 2.7315621376037598
Validation Loss Energy: 1.3661621625684635, Validation Loss Force: 1.8644230467902314, time: 0.1850736141204834
Test Loss Energy: 7.0151598584104455, Test Loss Force: 5.207230158470199, time: 11.023239374160767

Epoch 1, Batch 100/168, Loss: 0.3832664489746094, Uncertainty: 0.11956217885017395

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 1.7725201289299017, Training Loss Force: 1.7718276716246486, time: 2.7015395164489746
Validation Loss Energy: 2.739190179805512, Validation Loss Force: 1.9333645688490417, time: 0.17447447776794434
Test Loss Energy: 6.203742828178337, Test Loss Force: 5.166856796187861, time: 12.072025775909424

Epoch 2, Batch 100/168, Loss: 0.07149015367031097, Uncertainty: 0.11872144043445587

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 2.509193959172991, Training Loss Force: 1.777864611238464, time: 2.6471869945526123
Validation Loss Energy: 5.913632629832655, Validation Loss Force: 1.869389051194237, time: 0.17687559127807617
Test Loss Energy: 10.909705502763119, Test Loss Force: 5.181144127609102, time: 11.122514724731445

Epoch 3, Batch 100/168, Loss: 0.05649968236684799, Uncertainty: 0.11718213558197021

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 1.8286911316225496, Training Loss Force: 1.7724940541078311, time: 2.748911142349243
Validation Loss Energy: 0.7639271453360172, Validation Loss Force: 1.8907981700138536, time: 0.18454337120056152
Test Loss Energy: 6.340985550832523, Test Loss Force: 5.125394122453959, time: 10.951383829116821

Epoch 4, Batch 100/168, Loss: 0.22023358941078186, Uncertainty: 0.11964200437068939

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9765039991101585, Training Loss Force: 1.788971176596542, time: 2.9051315784454346
Validation Loss Energy: 0.866485622139935, Validation Loss Force: 2.061462862687158, time: 0.18213725090026855
Test Loss Energy: 6.379248168161223, Test Loss Force: 5.235259829834468, time: 11.128135442733765

Epoch 5, Batch 100/168, Loss: 0.19526231288909912, Uncertainty: 0.11838153749704361

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 2.2515307770720443, Training Loss Force: 1.790393741511178, time: 2.639099359512329
Validation Loss Energy: 0.8577328320172324, Validation Loss Force: 1.8014273847120819, time: 0.19844722747802734
Test Loss Energy: 6.321998869858776, Test Loss Force: 5.089090142570278, time: 10.972394943237305

Epoch 6, Batch 100/168, Loss: 0.09743572771549225, Uncertainty: 0.11873827874660492

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 2.044613152754319, Training Loss Force: 1.8356439702368224, time: 2.646854877471924
Validation Loss Energy: 0.7261117081771551, Validation Loss Force: 1.8232652529721822, time: 0.17716193199157715
Test Loss Energy: 6.206578740089258, Test Loss Force: 5.099869660847276, time: 11.286071062088013

Epoch 7, Batch 100/168, Loss: 0.09988001734018326, Uncertainty: 0.12072356790304184

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.6748852844495934, Training Loss Force: 1.8308825888373372, time: 2.669731378555298
Validation Loss Energy: 1.4001617000177988, Validation Loss Force: 2.0454825660913585, time: 0.18460893630981445
Test Loss Energy: 6.021759429525904, Test Loss Force: 5.2958267468563225, time: 11.00593900680542

Epoch 8, Batch 100/168, Loss: 0.16327068209648132, Uncertainty: 0.11885841190814972

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 2.161932000268458, Training Loss Force: 1.8010407111250029, time: 2.571103811264038
Validation Loss Energy: 4.302146479979895, Validation Loss Force: 2.0849667786086137, time: 0.17572450637817383
Test Loss Energy: 9.412517108163263, Test Loss Force: 5.251388977839802, time: 11.232332229614258

Epoch 9, Batch 100/168, Loss: 0.10347612202167511, Uncertainty: 0.11960159242153168

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 1.898389185524442, Training Loss Force: 1.8028742457464442, time: 2.6801159381866455
Validation Loss Energy: 3.035035755166987, Validation Loss Force: 1.9392641507588742, time: 0.1831495761871338
Test Loss Energy: 8.203508896581477, Test Loss Force: 5.205552965499175, time: 11.060485601425171

Epoch 10, Batch 100/168, Loss: 0.15097464621067047, Uncertainty: 0.11905084550380707

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.1124215304166176, Training Loss Force: 1.7794442904421373, time: 2.622520685195923
Validation Loss Energy: 1.2240392010201828, Validation Loss Force: 1.8476223999493093, time: 0.18808341026306152
Test Loss Energy: 6.739489132414422, Test Loss Force: 5.193847668188288, time: 11.321349620819092

Epoch 11, Batch 100/168, Loss: 0.09742490947246552, Uncertainty: 0.11829319596290588

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 2.727404621335746, Training Loss Force: 1.7953719204832783, time: 2.6749093532562256
Validation Loss Energy: 1.5110023185929762, Validation Loss Force: 1.7605418781479782, time: 0.1793069839477539
Test Loss Energy: 6.038179168927325, Test Loss Force: 5.089290101794935, time: 11.197789669036865

Epoch 12, Batch 100/168, Loss: 0.05915866047143936, Uncertainty: 0.11867232620716095

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.005955308513477, Training Loss Force: 1.7641466981104579, time: 2.7598276138305664
Validation Loss Energy: 1.1154621998709828, Validation Loss Force: 1.9305217518629816, time: 0.1837611198425293
Test Loss Energy: 6.072833515518565, Test Loss Force: 5.160261116913754, time: 11.318624019622803

Epoch 13, Batch 100/168, Loss: 0.5447855591773987, Uncertainty: 0.1187429428100586

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.377874201456779, Training Loss Force: 1.7839311916942127, time: 2.625465154647827
Validation Loss Energy: 1.4890741208826779, Validation Loss Force: 1.8298609357437092, time: 0.1919565200805664
Test Loss Energy: 5.928109289095492, Test Loss Force: 5.044335546835893, time: 11.122976779937744

Epoch 14, Batch 100/168, Loss: 0.09220132976770401, Uncertainty: 0.11792762577533722

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.6095720590372777, Training Loss Force: 1.7922055552875984, time: 2.5460970401763916
Validation Loss Energy: 3.325618174149215, Validation Loss Force: 1.818451220260272, time: 0.20191669464111328
Test Loss Energy: 8.434667820150283, Test Loss Force: 5.1538317330200245, time: 11.420548677444458

Epoch 15, Batch 100/168, Loss: 0.0990767776966095, Uncertainty: 0.11898587644100189

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 2.229309182940226, Training Loss Force: 1.7903417290471357, time: 2.565812110900879
Validation Loss Energy: 2.630820223850501, Validation Loss Force: 1.9428153896327034, time: 0.18244576454162598
Test Loss Energy: 6.150148244034479, Test Loss Force: 5.211950410943052, time: 11.408472061157227

Epoch 16, Batch 100/168, Loss: 0.28696519136428833, Uncertainty: 0.11744211614131927

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.330871389276387, Training Loss Force: 1.7623883070360038, time: 2.4627456665039062
Validation Loss Energy: 2.0315079989390274, Validation Loss Force: 1.9180493478806042, time: 0.1866593360900879
Test Loss Energy: 6.135287972076888, Test Loss Force: 5.185679518058553, time: 11.29130244255066

Epoch 17, Batch 100/168, Loss: 0.263580322265625, Uncertainty: 0.11812123656272888

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.3486239861471443, Training Loss Force: 1.7677488241738954, time: 2.738307237625122
Validation Loss Energy: 3.1146424241967767, Validation Loss Force: 1.9255722991988231, time: 0.1489865779876709
Test Loss Energy: 6.232233681152226, Test Loss Force: 5.208464834402421, time: 10.5347421169281

Epoch 18, Batch 100/168, Loss: 0.15744757652282715, Uncertainty: 0.11920281499624252

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 1.8629154812426663, Training Loss Force: 1.7824430812005674, time: 2.660372018814087
Validation Loss Energy: 0.892577417431126, Validation Loss Force: 1.8512820044741571, time: 0.19147372245788574
Test Loss Energy: 6.381866533482381, Test Loss Force: 5.14771999657232, time: 10.645896911621094

Epoch 19, Batch 100/168, Loss: 0.19250819087028503, Uncertainty: 0.1180298775434494

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.2000657739529195, Training Loss Force: 1.7812985511872061, time: 2.634582281112671
Validation Loss Energy: 2.4546032018004387, Validation Loss Force: 1.8123802202195998, time: 0.14292001724243164
Test Loss Energy: 7.791437673574117, Test Loss Force: 5.167041609247366, time: 10.0029616355896

wandb: - 0.039 MB of 0.039 MB uploadedwandb: \ 0.039 MB of 0.056 MB uploadedwandb: | 0.039 MB of 0.056 MB uploadedwandb: / 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–ƒâ–â–ˆâ–‚â–‚â–‚â–â–â–†â–„â–‚â–â–â–â–…â–â–â–â–‚â–„
wandb:   test_error_force â–†â–„â–…â–ƒâ–†â–‚â–ƒâ–ˆâ–‡â–…â–…â–‚â–„â–â–„â–†â–…â–†â–„â–„
wandb:          test_loss â–„â–„â–ˆâ–ƒâ–†â–‚â–â–…â–ˆâ–…â–…â–‚â–„â–â–„â–„â–„â–…â–„â–…
wandb: train_error_energy â–ƒâ–â–„â–â–‚â–ƒâ–‚â–…â–ƒâ–‚â–‚â–…â–‚â–ˆâ–…â–ƒâ–ƒâ–„â–â–ƒ
wandb:  train_error_force â–ˆâ–â–‚â–â–‚â–‚â–„â–„â–ƒâ–ƒâ–‚â–‚â–â–‚â–‚â–‚â–â–â–‚â–‚
wandb:         train_loss â–ˆâ–â–ƒâ–â–‚â–ƒâ–„â–…â–ƒâ–ƒâ–‚â–„â–â–…â–„â–ƒâ–‚â–‚â–‚â–‚
wandb: valid_error_energy â–‚â–„â–ˆâ–â–â–â–â–‚â–†â–„â–‚â–‚â–‚â–‚â–…â–„â–ƒâ–„â–â–ƒ
wandb:  valid_error_force â–ƒâ–…â–ƒâ–„â–‡â–‚â–‚â–‡â–ˆâ–…â–ƒâ–â–…â–‚â–‚â–…â–„â–…â–ƒâ–‚
wandb:         valid_loss â–‚â–…â–†â–‚â–…â–â–â–…â–ˆâ–…â–‚â–â–ƒâ–‚â–ƒâ–…â–„â–…â–‚â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 5357
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.79144
wandb:   test_error_force 5.16704
wandb:          test_loss 2.43911
wandb: train_error_energy 2.20007
wandb:  train_error_force 1.7813
wandb:         train_loss -2.67005
wandb: valid_error_energy 2.4546
wandb:  valid_error_force 1.81238
wandb:         valid_loss -2.60879
wandb: 
wandb: ğŸš€ View run al_58_92 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/2z0qu8wj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_130610-2z0qu8wj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 41.9719123840332, Uncertainty Bias: -4.843329906463623
7.43866e-05 0.0070991516
0.17610458 14.20969
(48745, 22, 3)
(48745,)
Did not find any uncertainty samples for sample 0.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Found uncertainty sample 3 after 2583 steps.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Did not find any uncertainty samples for sample 9.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Found uncertainty sample 18 after 3876 steps.
Found uncertainty sample 19 after 1932 steps.
Found uncertainty sample 20 after 1134 steps.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Did not find any uncertainty samples for sample 28.
Found uncertainty sample 29 after 2178 steps.
Found uncertainty sample 30 after 3607 steps.
Did not find any uncertainty samples for sample 31.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 545 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Did not find any uncertainty samples for sample 39.
Did not find any uncertainty samples for sample 40.
Found uncertainty sample 41 after 3521 steps.
Did not find any uncertainty samples for sample 42.
Did not find any uncertainty samples for sample 43.
Did not find any uncertainty samples for sample 44.
Did not find any uncertainty samples for sample 45.
Did not find any uncertainty samples for sample 46.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Found uncertainty sample 58 after 2633 steps.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Did not find any uncertainty samples for sample 62.
Found uncertainty sample 63 after 3786 steps.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Found uncertainty sample 69 after 2405 steps.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Did not find any uncertainty samples for sample 72.
Found uncertainty sample 73 after 662 steps.
Did not find any uncertainty samples for sample 74.
Did not find any uncertainty samples for sample 75.
Found uncertainty sample 76 after 3232 steps.
Found uncertainty sample 77 after 1471 steps.
Did not find any uncertainty samples for sample 78.
Did not find any uncertainty samples for sample 79.
Did not find any uncertainty samples for sample 80.
Found uncertainty sample 81 after 3287 steps.
Did not find any uncertainty samples for sample 82.
Did not find any uncertainty samples for sample 83.
Did not find any uncertainty samples for sample 84.
Found uncertainty sample 85 after 1365 steps.
Did not find any uncertainty samples for sample 86.
Did not find any uncertainty samples for sample 87.
Did not find any uncertainty samples for sample 88.
Did not find any uncertainty samples for sample 89.
Did not find any uncertainty samples for sample 90.
Did not find any uncertainty samples for sample 91.
Found uncertainty sample 92 after 2687 steps.
Did not find any uncertainty samples for sample 93.
Did not find any uncertainty samples for sample 94.
Did not find any uncertainty samples for sample 95.
Found uncertainty sample 96 after 3390 steps.
Did not find any uncertainty samples for sample 97.
Did not find any uncertainty samples for sample 98.
Did not find any uncertainty samples for sample 99.
wandb: wandb version 0.18.7 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.17.4
wandb: Run data is saved locally in /home/ws/fq0795/git/gnn_uncertainty/wandb/run-20241130_134822-oe27uyuj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run al_58_93
wandb: â­ï¸ View project at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: ğŸš€ View run at https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/oe27uyuj
Training model 93. Added 18 samples to the dataset.
Epoch 0, Batch 100/168, Loss: 0.07721602916717529, Uncertainty: 0.12110017985105515

Training and Validation Results of Epoch 0:
================================
Training Loss Energy: 3.733397602185823, Training Loss Force: 1.9498742103109385, time: 2.523437738418579
Validation Loss Energy: 1.0578793649496676, Validation Loss Force: 2.0574612754656894, time: 0.15854263305664062
Test Loss Energy: 6.040136029682404, Test Loss Force: 5.278066737383615, time: 9.811132192611694

Epoch 1, Batch 100/168, Loss: 0.18461352586746216, Uncertainty: 0.11963288486003876

Training and Validation Results of Epoch 1:
================================
Training Loss Energy: 3.3286507764884785, Training Loss Force: 1.7776344747236776, time: 2.5565223693847656
Validation Loss Energy: 3.806966817176427, Validation Loss Force: 1.9178728454709322, time: 0.1562039852142334
Test Loss Energy: 8.828235936615272, Test Loss Force: 5.168235712762747, time: 9.904140949249268

Epoch 2, Batch 100/168, Loss: 0.24450494349002838, Uncertainty: 0.11824997514486313

Training and Validation Results of Epoch 2:
================================
Training Loss Energy: 1.8643646637354163, Training Loss Force: 1.8202982369683345, time: 2.6531612873077393
Validation Loss Energy: 1.3704236789062778, Validation Loss Force: 1.8013236208900796, time: 0.1600937843322754
Test Loss Energy: 6.919710700504237, Test Loss Force: 5.0452175684680896, time: 9.986085414886475

Epoch 3, Batch 100/168, Loss: 0.07317676395177841, Uncertainty: 0.11972533166408539

Training and Validation Results of Epoch 3:
================================
Training Loss Energy: 2.5303089071993696, Training Loss Force: 1.7891470388324193, time: 2.5629067420959473
Validation Loss Energy: 1.0066078271890058, Validation Loss Force: 1.968545551675146, time: 0.16671419143676758
Test Loss Energy: 6.6249214547471675, Test Loss Force: 5.1982669629087965, time: 10.029178619384766

Epoch 4, Batch 100/168, Loss: 0.08526381850242615, Uncertainty: 0.11911584436893463

Training and Validation Results of Epoch 4:
================================
Training Loss Energy: 1.9504739020595043, Training Loss Force: 1.7805736690129887, time: 2.5511512756347656
Validation Loss Energy: 2.1368490607250314, Validation Loss Force: 1.843741833408653, time: 0.15671253204345703
Test Loss Energy: 7.213879932768025, Test Loss Force: 5.202008923735148, time: 10.280311346054077

Epoch 5, Batch 100/168, Loss: 0.13241612911224365, Uncertainty: 0.11671485006809235

Training and Validation Results of Epoch 5:
================================
Training Loss Energy: 1.896844552522491, Training Loss Force: 1.7891456193166142, time: 2.602095127105713
Validation Loss Energy: 8.466423350213974, Validation Loss Force: 2.049904552660338, time: 0.16677570343017578
Test Loss Energy: 13.51856011407487, Test Loss Force: 5.213437600681599, time: 9.946426630020142

Epoch 6, Batch 100/168, Loss: 0.041393980383872986, Uncertainty: 0.11889198422431946

Training and Validation Results of Epoch 6:
================================
Training Loss Energy: 1.8930767848032448, Training Loss Force: 1.7897721983645505, time: 2.5201334953308105
Validation Loss Energy: 1.3170360791403395, Validation Loss Force: 1.8576128965196517, time: 0.15987777709960938
Test Loss Energy: 5.965756882585069, Test Loss Force: 5.133726201375765, time: 10.06749153137207

Epoch 7, Batch 100/168, Loss: 0.05648794770240784, Uncertainty: 0.11794030666351318

Training and Validation Results of Epoch 7:
================================
Training Loss Energy: 2.2066886970803274, Training Loss Force: 1.7902197746138637, time: 2.5586183071136475
Validation Loss Energy: 0.9593935810478179, Validation Loss Force: 1.952662858388311, time: 0.15779519081115723
Test Loss Energy: 5.983927999923126, Test Loss Force: 5.127320793469758, time: 10.02442193031311

Epoch 8, Batch 100/168, Loss: 0.060236942023038864, Uncertainty: 0.11907073110342026

Training and Validation Results of Epoch 8:
================================
Training Loss Energy: 1.8802886657937021, Training Loss Force: 1.793438072086185, time: 2.5416009426116943
Validation Loss Energy: 0.9349414656799525, Validation Loss Force: 1.7746528301521896, time: 0.16877102851867676
Test Loss Energy: 6.047431922979768, Test Loss Force: 5.058436705866611, time: 9.962747812271118

Epoch 9, Batch 100/168, Loss: 0.14976653456687927, Uncertainty: 0.11880289018154144

Training and Validation Results of Epoch 9:
================================
Training Loss Energy: 2.102315799581082, Training Loss Force: 1.779758010062164, time: 2.5728132724761963
Validation Loss Energy: 0.8587221881441138, Validation Loss Force: 1.8025785470850042, time: 0.15810060501098633
Test Loss Energy: 6.495597448478611, Test Loss Force: 5.1566133159909535, time: 10.171397686004639

Epoch 10, Batch 100/168, Loss: 0.1571042388677597, Uncertainty: 0.11837983131408691

Training and Validation Results of Epoch 10:
================================
Training Loss Energy: 2.0402887390098376, Training Loss Force: 1.7726156155565689, time: 2.4993069171905518
Validation Loss Energy: 1.799704407972417, Validation Loss Force: 1.9399274450330684, time: 0.1698017120361328
Test Loss Energy: 5.998602260371566, Test Loss Force: 5.189956397790231, time: 9.934492588043213

Epoch 11, Batch 100/168, Loss: 0.04231338948011398, Uncertainty: 0.11636251211166382

Training and Validation Results of Epoch 11:
================================
Training Loss Energy: 1.6966810271508568, Training Loss Force: 1.789190432144938, time: 2.5945870876312256
Validation Loss Energy: 1.8074697346559783, Validation Loss Force: 1.989345596157601, time: 0.1601552963256836
Test Loss Energy: 7.063207241174143, Test Loss Force: 5.2130144220500885, time: 10.06542420387268

Epoch 12, Batch 100/168, Loss: 0.3028270900249481, Uncertainty: 0.11979249119758606

Training and Validation Results of Epoch 12:
================================
Training Loss Energy: 2.0395826302966333, Training Loss Force: 1.7836903206710173, time: 2.6112687587738037
Validation Loss Energy: 2.597449986519082, Validation Loss Force: 1.8900907872487653, time: 0.15877318382263184
Test Loss Energy: 7.703883321351007, Test Loss Force: 5.126650347163633, time: 10.0122549533844

Epoch 13, Batch 100/168, Loss: 0.17315486073493958, Uncertainty: 0.11898396909236908

Training and Validation Results of Epoch 13:
================================
Training Loss Energy: 3.3632341292437338, Training Loss Force: 1.7858932740088453, time: 2.4522197246551514
Validation Loss Energy: 1.592264124495971, Validation Loss Force: 1.807803627040297, time: 0.16577363014221191
Test Loss Energy: 7.0437875864580795, Test Loss Force: 5.084566466150032, time: 10.57617449760437

Epoch 14, Batch 100/168, Loss: 0.1590832769870758, Uncertainty: 0.11749699711799622

Training and Validation Results of Epoch 14:
================================
Training Loss Energy: 2.1147062662880516, Training Loss Force: 1.7723546738257732, time: 2.8440072536468506
Validation Loss Energy: 0.8734990322292223, Validation Loss Force: 1.7915564985846275, time: 0.19515490531921387
Test Loss Energy: 6.059727333164804, Test Loss Force: 5.0174188155004105, time: 12.156372547149658

Epoch 15, Batch 100/168, Loss: 0.04609259217977524, Uncertainty: 0.12057439982891083

Training and Validation Results of Epoch 15:
================================
Training Loss Energy: 1.767074862655929, Training Loss Force: 1.8068832208120758, time: 2.6662216186523438
Validation Loss Energy: 3.548863736272761, Validation Loss Force: 1.9259942943418806, time: 0.17824125289916992
Test Loss Energy: 8.660127327576063, Test Loss Force: 5.06232261821548, time: 11.10100531578064

Epoch 16, Batch 100/168, Loss: 0.2034023404121399, Uncertainty: 0.12039367854595184

Training and Validation Results of Epoch 16:
================================
Training Loss Energy: 2.6247212539805473, Training Loss Force: 1.8836133749290154, time: 2.8350770473480225
Validation Loss Energy: 1.1077258201763922, Validation Loss Force: 2.013266942504623, time: 0.18483376502990723
Test Loss Energy: 6.599008037940639, Test Loss Force: 5.139526954130522, time: 11.144413232803345

Epoch 17, Batch 100/168, Loss: 0.17823180556297302, Uncertainty: 0.11939457058906555

Training and Validation Results of Epoch 17:
================================
Training Loss Energy: 2.28040131464579, Training Loss Force: 1.7737230048865544, time: 2.6274642944335938
Validation Loss Energy: 1.7631861855904436, Validation Loss Force: 1.7817054671226848, time: 0.17825031280517578
Test Loss Energy: 7.211798624442318, Test Loss Force: 4.997711787015711, time: 11.219258785247803

Epoch 18, Batch 100/168, Loss: 0.22863507270812988, Uncertainty: 0.11941041052341461

Training and Validation Results of Epoch 18:
================================
Training Loss Energy: 2.073184463089638, Training Loss Force: 1.829702600087898, time: 2.5589439868927
Validation Loss Energy: 0.8545536547304863, Validation Loss Force: 2.2139662887033484, time: 0.18697381019592285
Test Loss Energy: 6.263957249449924, Test Loss Force: 5.260955483211122, time: 11.45357346534729

Epoch 19, Batch 100/168, Loss: 0.06947989761829376, Uncertainty: 0.12342488765716553

Training and Validation Results of Epoch 19:
================================
Training Loss Energy: 2.178663564172532, Training Loss Force: 1.8351024388739259, time: 2.6761276721954346
Validation Loss Energy: 1.7079827560509886, Validation Loss Force: 1.8495284478384513, time: 0.1775040626525879
Test Loss Energy: 7.234115253710798, Test Loss Force: 5.152202743838768, time: 11.248688697814941

wandb: - 0.039 MB of 0.049 MB uploadedwandb: \ 0.039 MB of 0.049 MB uploadedwandb: | 0.059 MB of 0.059 MB uploadedwandb:                                                                                
wandb: 
wandb: Run history:
wandb:       dataset_size â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:                 lr â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:    max_uncertainty â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:  test_error_energy â–â–„â–‚â–‚â–‚â–ˆâ–â–â–â–â–â–‚â–ƒâ–‚â–â–ƒâ–‚â–‚â–â–‚
wandb:   test_error_force â–ˆâ–…â–‚â–†â–†â–†â–„â–„â–ƒâ–…â–†â–†â–„â–ƒâ–â–ƒâ–…â–â–ˆâ–…
wandb:          test_loss â–ƒâ–…â–â–„â–…â–ˆâ–‚â–‚â–â–ƒâ–„â–„â–„â–‚â–â–ƒâ–â–â–ƒâ–ƒ
wandb: train_error_energy â–ˆâ–‡â–‚â–„â–‚â–‚â–‚â–ƒâ–‚â–‚â–‚â–â–‚â–‡â–‚â–â–„â–ƒâ–‚â–ƒ
wandb:  train_error_force â–ˆâ–â–ƒâ–‚â–â–‚â–‚â–‚â–‚â–â–â–‚â–â–‚â–â–‚â–…â–â–ƒâ–ƒ
wandb:         train_loss â–ˆâ–ƒâ–‚â–‚â–â–â–â–‚â–â–â–â–â–â–ƒâ–â–‚â–…â–â–ƒâ–ƒ
wandb: valid_error_energy â–â–„â–â–â–‚â–ˆâ–â–â–â–â–‚â–‚â–ƒâ–‚â–â–ƒâ–â–‚â–â–‚
wandb:  valid_error_force â–†â–ƒâ–â–„â–‚â–…â–‚â–„â–â–â–„â–„â–ƒâ–‚â–â–ƒâ–…â–â–ˆâ–‚
wandb:         valid_loss â–„â–„â–‚â–ƒâ–‚â–ˆâ–‚â–ƒâ–â–â–ƒâ–„â–ƒâ–‚â–â–„â–„â–‚â–†â–‚
wandb: 
wandb: Run summary:
wandb:       dataset_size 5373
wandb:                 lr 0.0001
wandb:    max_uncertainty 4
wandb:  test_error_energy 7.23412
wandb:   test_error_force 5.1522
wandb:          test_loss 2.32595
wandb: train_error_energy 2.17866
wandb:  train_error_force 1.8351
wandb:         train_loss -2.59746
wandb: valid_error_energy 1.70798
wandb:  valid_error_force 1.84953
wandb:         valid_loss -2.60754
wandb: 
wandb: ğŸš€ View run al_58_93 at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE/runs/oe27uyuj
wandb: â­ï¸ View project at: https://wandb.ai/l-baer-99-Karlsruhe%20Institute%20of%20Technology/GNN-Uncertainty-MVE
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20241130_134822-oe27uyuj/logs
wandb: WARNING The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require("core")`! See https://wandb.me/wandb-core for more information.
Uncertainty Slope: 49.01396942138672, Uncertainty Bias: -5.745605945587158
4.5776367e-05 0.021055698
0.27737093 13.495311
(48745, 22, 3)
(48745,)
Found uncertainty sample 0 after 3194 steps.
Did not find any uncertainty samples for sample 1.
Did not find any uncertainty samples for sample 2.
Did not find any uncertainty samples for sample 3.
Did not find any uncertainty samples for sample 4.
Did not find any uncertainty samples for sample 5.
Did not find any uncertainty samples for sample 6.
Did not find any uncertainty samples for sample 7.
Did not find any uncertainty samples for sample 8.
Found uncertainty sample 9 after 3479 steps.
Did not find any uncertainty samples for sample 10.
Did not find any uncertainty samples for sample 11.
Did not find any uncertainty samples for sample 12.
Did not find any uncertainty samples for sample 13.
Did not find any uncertainty samples for sample 14.
Did not find any uncertainty samples for sample 15.
Did not find any uncertainty samples for sample 16.
Did not find any uncertainty samples for sample 17.
Did not find any uncertainty samples for sample 18.
Did not find any uncertainty samples for sample 19.
Did not find any uncertainty samples for sample 20.
Did not find any uncertainty samples for sample 21.
Did not find any uncertainty samples for sample 22.
Did not find any uncertainty samples for sample 23.
Did not find any uncertainty samples for sample 24.
Did not find any uncertainty samples for sample 25.
Did not find any uncertainty samples for sample 26.
Did not find any uncertainty samples for sample 27.
Found uncertainty sample 28 after 2054 steps.
Found uncertainty sample 29 after 1678 steps.
Did not find any uncertainty samples for sample 30.
Found uncertainty sample 31 after 1266 steps.
Did not find any uncertainty samples for sample 32.
Did not find any uncertainty samples for sample 33.
Did not find any uncertainty samples for sample 34.
Found uncertainty sample 35 after 3223 steps.
Did not find any uncertainty samples for sample 36.
Did not find any uncertainty samples for sample 37.
Did not find any uncertainty samples for sample 38.
Found uncertainty sample 39 after 46 steps.
Did not find any uncertainty samples for sample 40.
Did not find any uncertainty samples for sample 41.
Did not find any uncertainty samples for sample 42.
Found uncertainty sample 43 after 3379 steps.
Found uncertainty sample 44 after 2315 steps.
Did not find any uncertainty samples for sample 45.
Found uncertainty sample 46 after 3822 steps.
Did not find any uncertainty samples for sample 47.
Did not find any uncertainty samples for sample 48.
Did not find any uncertainty samples for sample 49.
Did not find any uncertainty samples for sample 50.
Did not find any uncertainty samples for sample 51.
Did not find any uncertainty samples for sample 52.
Did not find any uncertainty samples for sample 53.
Did not find any uncertainty samples for sample 54.
Did not find any uncertainty samples for sample 55.
Did not find any uncertainty samples for sample 56.
Did not find any uncertainty samples for sample 57.
Did not find any uncertainty samples for sample 58.
Did not find any uncertainty samples for sample 59.
Did not find any uncertainty samples for sample 60.
Did not find any uncertainty samples for sample 61.
Found uncertainty sample 62 after 3210 steps.
Did not find any uncertainty samples for sample 63.
Did not find any uncertainty samples for sample 64.
Did not find any uncertainty samples for sample 65.
Did not find any uncertainty samples for sample 66.
Did not find any uncertainty samples for sample 67.
Did not find any uncertainty samples for sample 68.
Did not find any uncertainty samples for sample 69.
Did not find any uncertainty samples for sample 70.
Did not find any uncertainty samples for sample 71.
Found uncertainty sample 72 after 1926 steps.
Found uncertainty sample 73 after 2894 steps.
Did not find any uncertainty samples for sample 74.
slurmstepd: error: *** JOB 5123591 ON aimat01 CANCELLED AT 2024-11-30T14:21:54 ***
